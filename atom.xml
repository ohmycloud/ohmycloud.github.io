<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.79.0">Hugo</generator><title type="html"><![CDATA[焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2020-12-23T23:14:52+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/</id>
    
        
        <entry>
            <title type="html"><![CDATA[FlinkCEP - Flink 的复杂事件处理]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-20-flink-cep-complex-event-processing-for-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-10-execution-mode/?utm_source=atom_feed" rel="related" type="text/html" title="执行模式(批/流)" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-20-flink-cep-complex-event-processing-for-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-20T00:00:00+08:00</published>
            <updated>2020-12-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Cep Complex Event Processing for Flink</blockquote><p>FlinkCEP 是在 Flink 之上实现的复杂事件处理（CEP）库。它允许你在无尽的事件流中检测事件模式, 让你有机会掌握数据中的重要内容。</p>
<p>本页介绍了 Flink CEP 中可用的 API 调用。我们首先介绍 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#the-pattern-api">Pattern API</a>, 它允许你指定你想在你的流中检测的模式, 然后介绍你如何<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#detecting-patterns">检测并对匹配的事件序列采取行动</a>。然后, 我们将介绍 CEP 库在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#handling-lateness-in-event-time">处理事件时间的延迟</a>时做出的假设, 以及如何将你的工作从旧版 Flink <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#migrating-from-an-older-flink-versionpre-13">迁移</a>到 Flink-1.3。</p>
<h1 id="入门">入门</h1>
<p>如果你想直接进入, <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">设置一个 Flink 程序</a>, 并将 FlinkCEP 依赖关系添加到项目的 pom.xml 中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="o">&lt;</span><span class="n">dependency</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">flink</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">flink</span><span class="o">-</span><span class="n">cep</span><span class="o">-</span><span class="n">scala_2</span><span class="o">.</span><span class="mi">11</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="mf">1.12</span><span class="o">.</span><span class="mi">0</span><span class="o">&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">dependency</span><span class="o">&gt;</span>
</code></pre></div><p>信息：FlinkCEP 不是二进制发行版的一部分。请在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">这里</a>查看如何与它链接进行集群执行。</p>
<p>现在你可以开始使用模式 API 编写你的第一个 CEP 程序了。</p>
<p>注意: 你想应用模式匹配的 DataStream 中的事件必须实现适当的 <code>equals()</code> 和 <code>hashCode()</code> 方法, 因为 FlinkCEP 使用它们来比较和匹配事件。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">pattern</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getId</span> <span class="o">==</span> <span class="mi">42</span><span class="o">)</span>
  <span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">subtype</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubEvent</span><span class="o">]).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getVolume</span> <span class="o">&gt;=</span> <span class="mf">10.0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;end&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span> <span class="o">==</span> <span class="s">&#34;end&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">patternStream</span> <span class="k">=</span> <span class="nc">CEP</span><span class="o">.</span><span class="n">pattern</span><span class="o">(</span><span class="n">input</span><span class="o">,</span> <span class="n">pattern</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Alert</span><span class="o">]</span> <span class="k">=</span> <span class="n">patternStream</span><span class="o">.</span><span class="n">process</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">PatternProcessFunction</span><span class="o">[</span><span class="kt">Event</span>, <span class="kt">Alert</span><span class="o">]()</span> <span class="o">{</span>
        <span class="k">override</span> <span class="k">def</span> <span class="n">processMatch</span><span class="o">(</span>
              <span class="n">`match`</span><span class="k">:</span> <span class="kt">util.Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">util.List</span><span class="o">[</span><span class="kt">Event</span><span class="o">]],</span>
              <span class="n">ctx</span><span class="k">:</span> <span class="kt">PatternProcessFunction.Context</span><span class="o">,</span>
              <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Alert</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">createAlertFrom</span><span class="o">(</span><span class="n">pattern</span><span class="o">))</span>
        <span class="o">}</span>
    <span class="o">})</span>
</code></pre></div><h1 id="pattern-api">Pattern API</h1>
<p>模式 API 允许你定义你想从输入流中提取的复杂模式序列。</p>
<p>每个复杂模式序列由多个简单模式组成, 即寻找具有相同属性的单个事件的模式。从现在开始, 我们将把这些简单模式称为模式, 而最终我们要在流中寻找的复杂模式序列, 就是模式序列。你可以把模式序列看成是这样的模式图, 根据用户指定的条件, 从一个模式过渡到下一个模式, 例如 event.getName().equals(&ldquo;end&rdquo;)。一个匹配是一个输入事件的序列, 它通过有效的模式转换序列, 访问复杂模式图的所有模式。</p>
<p>注意: 每个模式必须有一个唯一的名称, 你以后用它来识别匹配事件。</p>
<p>注意: 模式名称不能包含字符 &ldquo;:&quot;。</p>
<p>在本节的其余部分, 我们将首先介绍如何定义 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#individual-patterns">单个模式</a>, 然后介绍如何将单个模式组合成 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#combining-patterns">复杂模式</a>。</p>
<h2 id="单个模式">单个模式</h2>
<p>模式可以是单个模式, 也可以是循环模式。单元模式只接受一个事件, 而循环模式可以接受多个事件。在模式匹配符号中, 模式 &ldquo;a b+ c?d&rdquo;(或 &ldquo;a&rdquo;, 后面跟着一个或多个 &ldquo;b&rdquo;, 可选地跟着一个 &ldquo;c&rdquo;, 后面跟着一个 &ldquo;d&rdquo;), a、c? 和 d 是单个模式, 而 b+ 是循环模式。默认情况下, 模式是一个单个模式, 你可以通过使用量词将其转换为一个循环模式。每个模式可以有一个或多个条件, 基于这些条件, 它可以接受事件。</p>
<h3 id="量词">量词</h3>
<p>在 FlinkCEP 中, 你可以使用这些方法来指定循环模式：pattern.oneOrMore(), 用于期望给定事件出现一次或多次的模式(例如前面提到的 b+)；以及 pattern.times(#ofTimes), 用于期望给定事件出现的特定次数的模式, 例如 4 个 a；以及 pattern.times(#fromTimes, #toTimes), 用于期望给定事件的特定最小出现次数和最大出现次数的模式, 例如 2-4 个 a。</p>
<p>你可以使用 pattern.greedy() 方法使循环模式变得贪婪, 但你还不能使分组模式变得贪婪。你可以使用 pattern.option() 方法使所有模式, 不管是否循环, 都是可选的。</p>
<p>对于名为 start 的模式, 以下是有效的量词。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// expecting 4 occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>

<span class="c1">// expecting 0 or 4 occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">4</span><span class="o">).</span><span class="n">optional</span><span class="o">()</span>

<span class="c1">// expecting 2, 3 or 4 occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>

<span class="c1">// expecting 2, 3 or 4 occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">greedy</span><span class="o">()</span>

<span class="c1">// expecting 0, 2, 3 or 4 occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">optional</span><span class="o">()</span>

<span class="c1">// expecting 0, 2, 3 or 4 occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">optional</span><span class="o">().</span><span class="n">greedy</span><span class="o">()</span>

<span class="c1">// expecting 1 or more occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">()</span>

<span class="c1">// expecting 1 or more occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">greedy</span><span class="o">()</span>

<span class="c1">// expecting 0 or more occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">optional</span><span class="o">()</span>

<span class="c1">// expecting 0 or more occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">optional</span><span class="o">().</span><span class="n">greedy</span><span class="o">()</span>

<span class="c1">// expecting 2 or more occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">timesOrMore</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>

<span class="c1">// expecting 2 or more occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">timesOrMore</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">greedy</span><span class="o">()</span>

<span class="c1">// expecting 0, 2 or more occurrences
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">timesOrMore</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">optional</span><span class="o">()</span>

<span class="c1">// expecting 0, 2 or more occurrences and repeating as many as possible
</span><span class="c1"></span><span class="n">start</span><span class="o">.</span><span class="n">timesOrMore</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">optional</span><span class="o">().</span><span class="n">greedy</span><span class="o">()</span>
</code></pre></div><p>条件</p>
<p>对于每个模式, 你可以指定一个条件, 传入的事件必须满足这个条件才能被&quot;接受&quot;到模式中, 例如, 它的值应该大于 5, 或者大于之前接受的事件的平均值。你可以通过 pattern.where()、pattern.or() 或 pattern.until() 方法来指定事件属性的条件。这些条件可以是 IterativeConditions 或 SimpleConditions。</p>
<p>迭代条件。这是最通用的条件类型。你可以通过这种方式指定一个条件, 该条件基于之前接受的事件的属性或其中一个子集的统计量来接受后续事件。</p>
<p>下面是一个迭代条件的代码, 如果一个名为 &ldquo;middle&rdquo; 的模式的名称以 &ldquo;foo&rdquo; 开头, 并且如果该模式之前接受的事件的价格加上当前事件的价格之和不超过 5.0 的值, 则接受该模式的下一个事件。迭代条件可以发挥强大的作用, 尤其是与循环模式相结合, 例如 oneOrMore()。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">middle</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">()</span>
    <span class="o">.</span><span class="n">subtype</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubEvent</span><span class="o">])</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(</span>
        <span class="o">(</span><span class="n">value</span><span class="o">,</span> <span class="n">ctx</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
            <span class="k">lazy</span> <span class="k">val</span> <span class="n">sum</span> <span class="k">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">getEventsForPattern</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getPrice</span><span class="o">).</span><span class="n">sum</span>
            <span class="n">value</span><span class="o">.</span><span class="n">getName</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&#34;foo&#34;</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">sum</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">getPrice</span> <span class="o">&lt;</span> <span class="mf">5.0</span>
        <span class="o">}</span>
    <span class="o">)</span>
</code></pre></div><p>注意：调用 ctx.getEventsForPattern(&hellip;) 可以为给定的潜在匹配找到所有之前接受的事件。这个操作的成本可能会有所不同, 所以在实现你的条件时, 尽量减少它的使用。</p>
<p>描述的上下文使人们也可以访问事件的时间特征。更多信息请看时间上下文。</p>
<p>简单条件。这种类型的条件扩展了前面提到的 IterativeCondition 类, 仅根据事件本身的属性来决定是否接受一个事件。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">start</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="n">event</span><span class="o">.</span><span class="n">getName</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&#34;foo&#34;</span><span class="o">))</span>
</code></pre></div><p>最后, 你还可以通过 pattern.subtype(subClass) 方法将接受的事件类型限制为初始事件类型的一个子类型（这里是 Event）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">start</span><span class="o">.</span><span class="n">subtype</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubEvent</span><span class="o">]).</span><span class="n">where</span><span class="o">(</span><span class="n">subEvent</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* some condition */</span><span class="o">)</span>
</code></pre></div><p>组合条件。如上所示, 你可以将子类型条件与其他条件结合起来。这对每个条件都适用。你可以通过依次调用 where() 来任意组合条件。最后的结果将是各个条件的结果的逻辑 AND。要使用 OR 组合条件, 可以使用 or() 方法, 如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* some condition */</span><span class="o">).</span><span class="n">or</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* or condition */</span><span class="o">)</span>
</code></pre></div><p><strong>停止条件</strong>：如果是循环模式(oneOrMore() 和 oneOrMore().option()), 你也可以指定一个停止条件, 例如, 接受值大于 5 的事件, 直到值的总和小于 50。</p>
<p>为了更好地理解它, 请看下面的例子。给定：</p>
<p>像 &ldquo;(a+ until b)&rdquo; (一个或多个 &ldquo;a&rdquo; 直到 &ldquo;b&rdquo;) 这样的模式</p>
<p>输入事件的序列 &ldquo;a1&rdquo; &ldquo;c&rdquo; &ldquo;a2&rdquo; &ldquo;b&rdquo; &ldquo;a3&rdquo;</p>
<p>该库将输出结果: {a1 a2} {a1} {a2} {a3}.</p>
<p>正如你所看到的 {a1 a2 a3} 或 {a2 a3} 由于停止条件没有返回。</p>
<ul>
<li>where(条件) - 定义当前模式的条件。要匹配模式, 一个事件必须满足条件。多个连续的 where() 子句会导致其条件被 AND 化。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* some condition */</span><span class="o">)</span>
</code></pre></div><ul>
<li>or(条件) - 添加一个新的条件, 该条件与现有的条件相匹配。一个事件只有在通过至少一个条件的情况下才能与模式匹配。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* some condition */</span><span class="o">)</span>
       <span class="o">.</span><span class="n">or</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* alternative condition */</span><span class="o">)</span>
</code></pre></div><ul>
<li>until(条件) - 指定循环模式的停止条件。意思是如果发生了与给定条件相匹配的事件, 则不会再接受更多的事件进入模式。</li>
</ul>
<p>仅与 oneOrMore() 结合使用。</p>
<p>注意：它允许在事件条件下对相应的模式进行清洗状态。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">until</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="o">...</span> <span class="cm">/* some condition */</span><span class="o">)</span>
</code></pre></div><ul>
<li>subtype(subClass)	- 为当前模式定义一个子类型条件。只有当一个事件属于这个子类型时, 它才能与模式相匹配。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">subtype</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubEvent</span><span class="o">])</span>
</code></pre></div><ul>
<li>oneOrMore() - 指定该模式期望匹配事件至少出现一次。</li>
</ul>
<p>默认情况下, 使用的是放宽的内部连续（在后续事件之间）。关于内部连续性的更多信息, 请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#consecutive_scala">consecutive</a>。</p>
<p>注意：建议使用 until() 或 within() 来启用状态清除。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">()</span>
</code></pre></div><ul>
<li>timesOrMore(#times) - 指定该模式期望一个匹配事件至少出现 #times 次。</li>
</ul>
<p>默认情况下, 使用的是放宽的内部连续（在后续事件之间）。关于内部相邻性的更多信息, 请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#consecutive_scala">consecutive</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">timesOrMore</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
</code></pre></div><ul>
<li>times(#ofTimes) - 指定该模式期望匹配事件的准确出现次数。</li>
</ul>
<p>默认情况下, 使用的是放宽的内部连续性（在后续事件之间）。关于内部相邻性的更多信息, 请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#consecutive_scala">consecutive</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
</code></pre></div><ul>
<li>times(#fromTimes, #toTimes) - 指定该模式期望匹配事件的 #fromTimes 和 #toTimes 之间出现。</li>
</ul>
<p>默认情况下, 使用的是放宽的内部连续性（在后续事件之间）。关于内部相邻性的更多信息, 请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#consecutive_scala">consecutive</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">times</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
</code></pre></div><ul>
<li>optional() - 指定该模式是可选的, 即它可能根本不会出现。这适用于上述所有量词。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">optional</span><span class="o">()</span>
</code></pre></div><ul>
<li>greedy() - 指定该模式是贪婪的, 即会尽可能多的重复。这只适用于量词, 目前不支持组模式。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">greedy</span><span class="o">()</span>
</code></pre></div><h3 id="组合模式">组合模式</h3>
<p>现在你已经看到了单个模式的样子, 现在是时候看看如何将它们组合成一个完整的模式序列了。</p>
<p>一个模式序列必须从一个初始模式开始, 如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">start</span> <span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">)</span>
</code></pre></div><p>下一步, 你可以通过指定它们之间所需的毗连条件, 将更多的模式附加到你的模式序列中。FlinkCEP 支持以下形式的事件之间的相邻性。</p>
<ul>
<li><strong>严格相邻</strong>: 希望所有匹配的事件严格地一个接一个出现, 中间没有任何非匹配的事件。</li>
<li><strong>Relaxed Contiguity</strong>: 忽略匹配事件之间出现的非匹配事件。</li>
<li>非决定性的松弛相邻性（Non-Deterministic Relaxed Contiguity）。进一步放宽相邻性, 允许忽略一些匹配事件的额外匹配。</li>
</ul>
<p>要在连续模式之间应用它们, 你可以使用:</p>
<ul>
<li>next(), 用于严格相邻,</li>
<li>followedBy(), 用于松散相邻, 和</li>
<li>followedByAny(), 用于非确定性的松散相邻。</li>
</ul>
<p>或</p>
<ul>
<li>notNext(), 如果你不希望一个事件类型直接跟随另一个事件类型</li>
<li>notFollowedBy(), 如果你不想让一个事件类型位于两个其他事件类型之间的任何地方。</li>
</ul>
<p>注意：模式序列不能以 notFollowedBy() 结束。</p>
<p>注意： NOT 模式不能在前面加上一个可选模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// strict contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">strict</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>

<span class="c1">// relaxed contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">relaxed</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>

<span class="c1">// non-deterministic relaxed contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">nonDetermin</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedByAny</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>

<span class="c1">// NOT pattern with strict contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">strictNot</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">notNext</span><span class="o">(</span><span class="s">&#34;not&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>

<span class="c1">// NOT pattern with relaxed contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">relaxedNot</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">notFollowedBy</span><span class="o">(</span><span class="s">&#34;not&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
</code></pre></div><p>松散毗连意味着只有第一个后续的匹配事件才会被匹配, 而对于非确定性的松散毗连, 同一开头会发出多个匹配。举个例子, 一个模式 &ldquo;a b&rdquo;, 给定事件序列 &ldquo;a&rdquo;, &ldquo;c&rdquo;, &ldquo;b1&rdquo;, &ldquo;b2&rdquo;, 将得到以下结果。</p>
<p>&ldquo;a&rdquo; 和 &ldquo;b&rdquo; 之间有严格的毗连性。{} (不匹配), &ldquo;a&rdquo; 后面的 &ldquo;c&rdquo; 会导致 &ldquo;a&rdquo; 被丢弃。</p>
<p>&ldquo;a&rdquo; 和 &ldquo;b&rdquo; 之间的松散相邻性。{a b1}, 因为松散连续性被看作是 &ldquo;跳过非匹配事件, 直到下一个匹配事件&rdquo;。</p>
<p>&ldquo;a&rdquo; 和 &ldquo;b&rdquo; 之间的非确定性松散相邻性。{a b1}, {a b2}, 因为这是最一般的形式。</p>
<p>也可以定义一个时间约束, 让模式有效。例如, 你可以通过 pattern.within() 方法定义一个模式应该在 10 秒内发生。处理时间和事件时间都支持时间模式。</p>
<p>注意: 模式序列只能有一个时间约束。如果在不同的单个模式上定义了多个这样的约束, 那么就采用最小的约束。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">next</span><span class="o">.</span><span class="n">within</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
</code></pre></div><p>循环模式中的相邻性</p>
<p>你可以在循环模式中应用与上一节讨论的相同的相邻性条件。相邻性将被应用在这样一个模式中的元素之间。为了举例说明, 模式序列 &ldquo;a b+ c&rdquo;（&ldquo;a&rdquo; 后面跟着一个或多个 &ldquo;b&rdquo; 的任意（非确定的松散的）序列, 后面跟着一个 &ldquo;c&rdquo;）, 输入 &ldquo;a&rdquo;、&ldquo;b1&rdquo;、&ldquo;d1&rdquo;、&ldquo;b2&rdquo;、&ldquo;d2&rdquo;、&ldquo;b3&rdquo;、&ldquo;c&rdquo;, 会有以下结果。</p>
<p>严格相邻性：{a b3 c} - &ldquo;b1&rdquo; 后面的 &ldquo;d1&rdquo; 会导致 &ldquo;b1&rdquo; 被丢弃, &ldquo;b2&rdquo; 也会因为 &ldquo;d2&rdquo; 而被丢弃。</p>
<p>放宽相邻性：{a b1 c}, {a b1 b2 c}, {a b1 b2 b3 c}, {a b2 c}, {a b2 b3 c}, {a b3 c} - &ldquo;d&rdquo; 被忽略。</p>
<p>非确定性的松弛相邻性：{a b1 c}, {a b1 b2 c}, {a b1 b3 c}, {a b1 b2 b3 c}, {a b2 c}, {a b2 b3 c}, {a b3 c} - 注意{a b1 b3 c}, 这是 &ldquo;b&rdquo; 之间松弛相邻性的结果。</p>
<p>对于循环模式(例如 oneOrMore() 和 times()), 默认是放宽毗连性。如果你想要严格的相邻性, 你必须通过使用 continuous() 调用来明确指定, 如果你想要非确定性的松弛相邻性, 你可以使用 allowCombinations() 调用。</p>
<ul>
<li>consecutive()</li>
</ul>
<p>与 oneOrMore() 和 times() 一起使用, 并在匹配的事件之间施加严格的毗连性, 即任何不匹配的元素都会中断匹配（如 next()）。</p>
<p>如果不应用, 则使用宽松的连续性（如 followedBy()）。</p>
<p>例如, 像这样的模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;c&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">))</span>
                       <span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">consecutive</span><span class="o">()</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;end1&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;b&#34;</span><span class="o">))</span>
</code></pre></div><p>将为一个输入序列生成以下匹配。C D A1 A2 A3 D A4 B</p>
<p>与连续应用。{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}。</p>
<p>不连续应用。{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}。</p>
<ul>
<li>allowCombinations()</li>
</ul>
<p>与 oneOrMore()和 times()一起使用, 并在匹配的事件之间施加非确定性的松散相邻性（如 followedByAny()）。</p>
<p>如果不应用, 则使用松散的相邻性（如 followedBy()）。</p>
<p>例如, 像这样的模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;c&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">))</span>
                       <span class="o">.</span><span class="n">oneOrMore</span><span class="o">().</span><span class="n">allowCombinations</span><span class="o">()</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;end1&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span><span class="o">().</span><span class="n">equals</span><span class="o">(</span><span class="s">&#34;b&#34;</span><span class="o">))</span>
</code></pre></div><p>将为一个输入序列生成以下匹配。C D A1 A2 A3 D A4 B</p>
<p>启用组合。{C A1 B}、{C A1 A2 B}、{C A1 A3 B}、{C A1 A4 B}、{C A1 A2 A3 B}、{C A1 A2 A4 B}、{C A1 A3 A4 B}、{C A1 A2 A3 A4 B}、{C A1 A2 A3 A4 B}。</p>
<p>不启用组合。{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}。</p>
<h3 id="模式组">模式组</h3>
<p>也可以定义一个模式序列作为 begin、followBy、followByAny 和 next 的条件。该模式序列将被视为逻辑上的匹配条件, 并将返回一个 GroupPattern, 并且可以对 GroupPattern 应用 oneOrMore()、times(#ofTimes)、times(#fromTimes、#toTimes)、optional()、continuous()、allowCombinations()。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">start</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;start_middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">)</span>

<span class="c1">// strict contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">strict</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">next</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;next_start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;next_middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">).</span><span class="n">times</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="c1">// relaxed contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">relaxed</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedBy</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;followedby_start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;followedby_middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">).</span><span class="n">oneOrMore</span><span class="o">()</span>

<span class="c1">// non-deterministic relaxed contiguity
</span><span class="c1"></span><span class="k">val</span> <span class="n">nonDetermin</span><span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedByAny</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;followedbyany_start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;followedbyany_middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">).</span><span class="n">optional</span><span class="o">()</span>
</code></pre></div><ul>
<li>begin(#name) - 定义一个起始模式。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">start</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>begin(#pattern_sequence) - 定义一个起始模式。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">start</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>next(#name) - 添加一个新的模式。一个匹配事件必须直接接替前一个匹配事件（严格相邻）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>next(#pattern_sequence) - 添加一个新的模式。一个匹配事件的序列必须直接接替前一个匹配事件（严格相邻）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">next</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>followedBy(#name) - 添加一个新的模式。其他事件可以发生在一个匹配事件和上一个匹配事件之间（松散的相邻性）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">followedBy</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>followedBy(#pattern_sequence)	- 添加一个新的模式。其他事件可以发生在一系列匹配事件和前一个匹配事件之间（放松的相邻性）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">followedBy</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedBy</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>followedByAny(#name) - 添加一个新的模式。在一个匹配事件和上一个匹配事件之间可以发生其他事件, 并且对每一个备选匹配事件都会呈现备选匹配（非确定性的松散毗连性）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">followedByAny</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedByAny</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>followedByAny(#pattern_sequence) - 添加一个新的模式。在一个匹配事件序列和前一个匹配事件之间可以发生其他事件, 并且将为每一个可供选择的匹配事件序列呈现备选匹配（非确定性的松散毗连性）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">followedByAny</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">followedByAny</span><span class="o">(</span>
    <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...).</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(...)</span>
<span class="o">)</span>
</code></pre></div><p>notNext() - 添加一个新的否定模式。一个匹配（负值）事件必须直接接替前一个匹配事件（严格的相邻性）, 以使部分匹配被丢弃。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">notNext</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">notNext</span><span class="o">(</span><span class="s">&#34;not&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>notFollowedBy() - 添加一个新的负模式。即使在匹配（负值）事件和前一个匹配事件之间发生了其他事件, 部分匹配事件序列也会被丢弃（松散的相邻性）。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">notFollowedBy</span> <span class="k">=</span> <span class="n">start</span><span class="o">.</span><span class="n">notFollowedBy</span><span class="o">(</span><span class="s">&#34;not&#34;</span><span class="o">)</span>
</code></pre></div><p>within(time) - 定义事件序列匹配模式的最大时间间隔。如果一个未完成的事件序列超过了这个时间, 它将被丢弃。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">pattern</span><span class="o">.</span><span class="n">within</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
</code></pre></div><h3 id="after-match-skip-strategy">After Match Skip Strategy</h3>
<p>对于一个给定的模式, 同一个事件可能会被分配给多个成功的匹配。要控制一个事件将被分配到多少个匹配中, 你需要指定名为 AfterMatchSkipStrategy 的跳过策略。有五种类型的跳过策略, 如下所示。</p>
<ul>
<li>NO_SKIP: 每一个可能的匹配都会被发出。</li>
<li>SKIP_TO_NEXT：丢弃每一个局部的匹配, 从相同的事件开始, 发射匹配开始。</li>
<li>SKIP_PAST_LAST_EVENT: 丢弃每一个在匹配开始后但结束前开始的部分匹配。</li>
<li>SKIP_TO_FIRST: 丢弃每个在匹配开始后但在 PatternName 的第一个事件发生之前开始的部分匹配。</li>
<li>SKIP_TO_LAST: 丢弃在匹配开始后但在 PatternName 的最后一个事件发生之前开始的每一个部分匹配。</li>
</ul>
<p>注意, 当使用 SKIP_TO_FIRST 和 SKIP_TO_LAST 跳过策略时, 还应该指定一个有效的 PatternName。</p>
<p>例如, 对于给定的模式 b+ c 和数据流 b1 b2 b3 c, 这四种跳过策略的区别如下。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Skip Strategy</th>
<th style="text-align:left">结果</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">NO_SKIP</td>
<td style="text-align:left">b1 b2 b3 c <!-- raw HTML omitted --> b2 b3 c <!-- raw HTML omitted --> b3 c</td>
<td style="text-align:left">找到匹配的 b1 b2 b3 c 后, 匹配过程不会丢弃任何结果。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_TO_NEXT</td>
<td style="text-align:left">b1 b2 b3 c <!-- raw HTML omitted --> b2 b3 c <!-- raw HTML omitted --> b3 c</td>
<td style="text-align:left">找到匹配的 b1 b2 b3 c 后, 匹配过程不会丢弃任何结果, 因为没有其他匹配可以从 b1 开始。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_PAST_LAST_EVENT</td>
<td style="text-align:left">b1 b2 b3 c</td>
<td style="text-align:left">在找到匹配的 b1 b2 b3 c 后, 匹配过程将放弃所有开始的部分匹配。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_TO_FIRST[b]</td>
<td style="text-align:left">b1 b2 b3 c <!-- raw HTML omitted --> b2 b3 c <!-- raw HTML omitted --> b3 c</td>
<td style="text-align:left">找到匹配的 b1 b2 b3 c 后, 匹配过程会尝试丢弃所有在 b1 之前开始的部分匹配, 但没有这样的匹配。因此, 没有任何匹配结果会被丢弃。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_TO_LAST[b]</td>
<td style="text-align:left">b1 b2 b3 c <!-- raw HTML omitted --> b3 c</td>
<td style="text-align:left">找到匹配的 b1 b2 b3 c 后, 匹配过程会尝试丢弃所有在 b3 之前开始的部分匹配。有一个这样的匹配 b2 b3 c。</td>
</tr>
</tbody>
</table>
<p>还可以看看另一个例子, 以更好地了解 NO_SKIP 和 SKIP_TO_FIRST 的区别：模式: (a | b | c) (b | c) c+.greedy d 和序列: a b c1 c2 c3 d 那么结果将是:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Skip Strategy</th>
<th style="text-align:left">结果</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">NO_SKIP</td>
<td style="text-align:left">a b c1 c2 c3 d <!-- raw HTML omitted --> b c1 c2 c3 d <!-- raw HTML omitted --> c1 c2 c3 d</td>
<td style="text-align:left">找到匹配的 a b c1 c2 c3 d 后, 匹配过程不会丢弃任何结果。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_TO_FIRST[c*]</td>
<td style="text-align:left">a b c1 c2 c3 d <!-- raw HTML omitted --> c1 c2 c3 d</td>
<td style="text-align:left">在找到匹配的 a b c1 c2 c3 d 后, 匹配过程将丢弃所有在 c1 之前开始的部分匹配, 有一个这样的匹配 b c1 c2 c3 d。有一个这样的匹配 b c1 c2 c3 d。</td>
</tr>
</tbody>
</table>
<p>为了更好地理解 NO_SKIP 和 SKIP_TO_NEXT 的区别, 请看下面的例子: Pattern: a b+ 和序列: a b1 b2 b3 那么结果将是:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Skip Strategy</th>
<th style="text-align:left">结果</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">NO_SKIP</td>
<td style="text-align:left">a b1 <!-- raw HTML omitted --> a b1 b2 <!-- raw HTML omitted --> a b1 b2 b3</td>
<td style="text-align:left">找到匹配的 b1 后, 匹配过程不会丢弃任何结果。</td>
</tr>
<tr>
<td style="text-align:left">SKIP_TO_NEXT</td>
<td style="text-align:left">a b1</td>
<td style="text-align:left">在找到匹配的 b1 后, 匹配过程将丢弃从 a 开始的所有部分匹配, 这意味着既不能生成 b1 b2, 也不能生成 b1 b2 b3。</td>
</tr>
</tbody>
</table>
<p>要指定使用哪种跳过策略, 只需调用 AfterMatchSkipStrategy 来创建一个 AfterMatchSkipStrategy。</p>
<table>
<thead>
<tr>
<th style="text-align:left">功能</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">AfterMatchSkipStrategy.noSkip()</td>
<td style="text-align:left">创建一个 NO_SKIP 跳过策略</td>
</tr>
<tr>
<td style="text-align:left">AfterMatchSkipStrategy.skipToNext()</td>
<td style="text-align:left">创建一个 SKIP_TO_NEXT 跳过策略。</td>
</tr>
<tr>
<td style="text-align:left">AfterMatchSkipStrategy.skipPastLastEvent()</td>
<td style="text-align:left">创建一个 SKIP_PAST_LAST_EVENT 跳过策略。</td>
</tr>
<tr>
<td style="text-align:left">AfterMatchSkipStrategy.skipToFirst(patternName)</td>
<td style="text-align:left">用引用的模式名 patternName 创建一个 SKIP_TO_FIRST 跳过策略。</td>
</tr>
<tr>
<td style="text-align:left">AfterMatchSkipStrategy.skipToLast(patternName)</td>
<td style="text-align:left">用引用的模式名 patternName 创建一个 SKIP_TO_LAST 跳过策略。</td>
</tr>
</tbody>
</table>
<p>然后通过调用跳过策略来应用于模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">skipStrategy</span> <span class="k">=</span> <span class="o">...</span>
<span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">(</span><span class="s">&#34;patternName&#34;</span><span class="o">,</span> <span class="n">skipStrategy</span><span class="o">)</span>
</code></pre></div><p>注意 对于 SKIP_TO_FIRST/LAST 有两个选项来处理没有元素映射到指定变量的情况。默认情况下, 将使用 NO_SKIP 策略。另一个选项是在这种情况下抛出异常。我们可以通过以下方式启用这个选项</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">AfterMatchSkipStrategy</span><span class="o">.</span><span class="n">skipToFirst</span><span class="o">(</span><span class="n">patternName</span><span class="o">).</span><span class="n">throwExceptionOnMiss</span><span class="o">()</span>
</code></pre></div><h2 id="检测模式">检测模式</h2>
<p>在指定了你要寻找的模式序列后, 现在是时候将其应用到你的输入流中以检测潜在的匹配。要针对你的模式序列运行事件流, 你必须创建一个 PatternStream。给定一个输入流输入、一个模式模式和一个可选的比较器比较器, 用于在 EventTime 的情况下对具有相同时间戳的事件或在同一时刻到达的事件进行排序, 你可以通过调用创建 PatternStream。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span> <span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">pattern</span> <span class="k">:</span> <span class="kt">Pattern</span><span class="o">[</span><span class="kt">Event</span>, <span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">var</span> <span class="n">comparator</span> <span class="k">:</span> <span class="kt">EventComparator</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// optional
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">patternStream</span><span class="k">:</span> <span class="kt">PatternStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="nc">CEP</span><span class="o">.</span><span class="n">pattern</span><span class="o">(</span><span class="n">input</span><span class="o">,</span> <span class="n">pattern</span><span class="o">,</span> <span class="n">comparator</span><span class="o">)</span>
</code></pre></div><p>输入流可以是 keyed 的, 也可以是 non-keyed 的, 这取决于你的使用情况。</p>
<p>注意: 在 non-keyed 流上应用模式将导致作业的并行度等于 1。</p>
<h3 id="从模式中选择">从模式中选择</h3>
<p>一旦你获得了一个 PatternStream, 你就可以对检测到的事件序列进行转换。建议的方法是通过 PatternProcessFunction 来实现。</p>
<p>PatternProcessFunction 有一个 processMatch 方法, 它对每个匹配的事件序列都会被调用。它以 <code>Map&lt;String, List&lt;IN&gt;&gt;</code> 的形式接收匹配, 其中键是你的模式序列中每个模式的名称, 值是该模式的所有接受事件的列表（IN 是你的输入元素的类型）。给定模式的事件是按时间戳排序的。返回每个模式所接受的事件列表的原因是, 当使用循环模式(例如 oneToMany() 和 times())时, 一个给定模式可能会接受多个事件。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyPatternProcessFunction</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">,</span> <span class="nc">OUT</span><span class="o">&gt;</span> <span class="k">extends</span> <span class="nc">PatternProcessFunction</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">,</span> <span class="nc">OUT</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="n">public</span> <span class="n">void</span> <span class="n">processMatch</span><span class="o">(</span><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">&gt;&gt;</span> <span class="k">match</span><span class="o">,</span> <span class="nc">Context</span> <span class="n">ctx</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="n">throws</span> <span class="nc">Exception</span><span class="o">;</span>
        <span class="nc">IN</span> <span class="n">startEvent</span> <span class="k">=</span> <span class="k">match</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
        <span class="nc">IN</span> <span class="n">endEvent</span> <span class="k">=</span> <span class="k">match</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&#34;end&#34;</span><span class="o">).</span><span class="n">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">OUT</span><span class="o">(</span><span class="n">startEvent</span><span class="o">,</span> <span class="n">endEvent</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>PatternProcessFunction 提供了对 Context 对象的访问。通过它, 我们可以访问与时间相关的特性, 如当前处理时间或当前匹配的时间戳（这是分配给匹配的最后一个元素的时间戳）。更多信息请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#time-context">时间上下文</a>。通过这个上下文, 我们还可以将结果发送到一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/side_output.html">侧输出</a>。</p>
<h3 id="处理超时的部分模式">处理超时的部分模式</h3>
<p>当一个模式通过 within 关键字附加了一个窗口长度时, 部分事件序列有可能因为超过窗口长度而被丢弃。要对一个超时的部分匹配采取行动, 可以使用 TimedOutPartialMatchHandler 接口。该接口应该以混搭的方式使用。这意味着你可以在你的 PatternProcessFunction 中额外实现这个接口。TimedOutPartialMatchHandler 提供了额外的 processTimedOutMatch 方法, 该方法将为每个超时部分匹配调用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyPatternProcessFunction</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">,</span> <span class="nc">OUT</span><span class="o">&gt;</span> <span class="k">extends</span> <span class="nc">PatternProcessFunction</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">,</span> <span class="nc">OUT</span><span class="o">&gt;</span> <span class="n">implements</span> <span class="nc">TimedOutPartialMatchHandler</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="n">public</span> <span class="n">void</span> <span class="n">processMatch</span><span class="o">(</span><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">&gt;&gt;</span> <span class="k">match</span><span class="o">,</span> <span class="nc">Context</span> <span class="n">ctx</span><span class="o">,</span> <span class="nc">Collector</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="n">throws</span> <span class="nc">Exception</span><span class="o">;</span>
        <span class="o">...</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="n">public</span> <span class="n">void</span> <span class="n">processTimedOutMatch</span><span class="o">(</span><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">IN</span><span class="o">&gt;&gt;</span> <span class="k">match</span><span class="o">,</span> <span class="nc">Context</span> <span class="n">ctx</span><span class="o">)</span> <span class="n">throws</span> <span class="nc">Exception</span><span class="o">;</span>
        <span class="nc">IN</span> <span class="n">startEvent</span> <span class="k">=</span> <span class="k">match</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">).</span><span class="n">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">output</span><span class="o">(</span><span class="n">outputTag</span><span class="o">,</span> <span class="n">T</span><span class="o">(</span><span class="n">startEvent</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>注意: processTimedOutMatch 不给人访问主输出的机会。但你仍然可以通过 Context 对象, 通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/side_output.html">侧输出</a>来发出结果。</p>
<h4 id="方便的-api">方便的 API</h4>
<p>前面提到的 PatternProcessFunction 是在 Flink 1.8 中引入的, 从那时起, 它就是推荐的与匹配交互的方式。人们仍然可以使用老式的 API, 比如 select/flatSelect, 内部会被翻译成 PatternProcessFunction。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">patternStream</span><span class="k">:</span> <span class="kt">PatternStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="nc">CEP</span><span class="o">.</span><span class="n">pattern</span><span class="o">(</span><span class="n">input</span><span class="o">,</span> <span class="n">pattern</span><span class="o">)</span>

<span class="k">val</span> <span class="n">outputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;side-output&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">SingleOutputStreamOperator</span><span class="o">[</span><span class="kt">ComplexEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">patternStream</span><span class="o">.</span><span class="n">flatSelect</span><span class="o">(</span><span class="n">outputTag</span><span class="o">){</span>
    <span class="o">(</span><span class="n">pattern</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Iterable</span><span class="o">[</span><span class="kt">Event</span><span class="o">]],</span> <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">TimeoutEvent</span><span class="o">])</span> <span class="k">=&gt;</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">TimeoutEvent</span><span class="o">())</span>
<span class="o">}</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">pattern</span><span class="k">:</span> <span class="kt">mutable.Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Iterable</span><span class="o">[</span><span class="kt">Event</span><span class="o">]],</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">ComplexEvent</span><span class="o">])</span> <span class="k">=&gt;</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">ComplexEvent</span><span class="o">())</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">timeoutResult</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">TimeoutEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">getSideOutput</span><span class="o">(</span><span class="n">outputTag</span><span class="o">)</span>
</code></pre></div><h2 id="在-cep-库中的时间">在 CEP 库中的时间</h2>
<h3 id="处理事件时间的延迟">处理事件时间的延迟</h3>
<p>在 CEP 中, 处理元素的顺序很重要。为了保证元素在事件时间工作时以正确的顺序进行处理, 一个传入的元素最初会被放在一个缓冲区中, 在这个缓冲区中, 元素根据其时间戳按升序排序, 当一个水印到达时, 这个缓冲区中所有时间戳小于水印的元素都会被处理。这意味着水印之间的元素是按事件时间顺序处理的。</p>
<p>注意: 当在事件时间内工作时, 该库假定水印的正确性。</p>
<p>为了保证水印之间的元素按事件时间顺序处理, Flink 的 CEP 库假设水印的正确性, 并将时间戳小于最后看到的水印的元素视为迟到元素。迟到的元素不会被进一步处理。另外, 你可以指定一个 sideOutput 标签来收集最后一次看到的水印之后的迟到元素, 你可以这样使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">patternStream</span><span class="k">:</span> <span class="kt">PatternStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="nc">CEP</span><span class="o">.</span><span class="n">pattern</span><span class="o">(</span><span class="n">input</span><span class="o">,</span> <span class="n">pattern</span><span class="o">)</span>

<span class="k">val</span> <span class="n">lateDataOutputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;late-data&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">SingleOutputStreamOperator</span><span class="o">[</span><span class="kt">ComplexEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">patternStream</span>
      <span class="o">.</span><span class="n">sideOutputLateData</span><span class="o">(</span><span class="n">lateDataOutputTag</span><span class="o">)</span>
      <span class="o">.</span><span class="n">select</span><span class="o">{</span>
          <span class="n">pattern</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Iterable</span><span class="o">[</span><span class="kt">ComplexEvent</span><span class="o">]]</span> <span class="k">=&gt;</span> <span class="nc">ComplexEvent</span><span class="o">()</span>
      <span class="o">}</span>

<span class="k">val</span> <span class="n">lateData</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">getSideOutput</span><span class="o">(</span><span class="n">lateDataOutputTag</span><span class="o">)</span>
</code></pre></div><h3 id="时间上下文">时间上下文</h3>
<p>在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#selecting-from-patterns">PatternProcessFunction</a> 以及 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#conditions">IterativeCondition</a> 中, 用户可以访问一个实现 TimeContext 的上下文, 如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * Enables access to time related characteristics such as current processing time or timestamp of
</span><span class="cm"> * currently processed element. Used in {@link PatternProcessFunction} and
</span><span class="cm"> * {@link org.apache.flink.cep.pattern.conditions.IterativeCondition}
</span><span class="cm"> */</span>
<span class="nd">@PublicEvolving</span>
<span class="kd">public</span> <span class="kd">interface</span> <span class="nc">TimeContext</span> <span class="o">{</span>

	<span class="cm">/**
</span><span class="cm">	 * Timestamp of the element currently being processed.
</span><span class="cm">	 *
</span><span class="cm">	 * &lt;p&gt;In case of {@link org.apache.flink.streaming.api.TimeCharacteristic#ProcessingTime} this
</span><span class="cm">	 * will be set to the time when event entered the cep operator.
</span><span class="cm">	 */</span>
	<span class="kt">long</span> <span class="nf">timestamp</span><span class="o">();</span>

	<span class="cm">/** Returns the current processing time. */</span>
	<span class="kt">long</span> <span class="nf">currentProcessingTime</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>这个上下文让用户可以访问处理事件的时间特征（在 IterativeCondition 的情况下是传入记录, 在 PatternProcessFunction 的情况下是匹配）。调用 TimeContext#currentProcessingTime 总是给你当前处理时间的值, 这个调用应该比调用 System.currentTimeMillis()更可取。</p>
<p>在 TimeContext#timestamp() 的情况下, 返回的值等于 EventTime 中分配的时间戳。在 ProcessingTime 中, 这将等于所述事件进入 cep 运算符的时间点(或者在 PatternProcessFunction 的情况下生成匹配时)。这意味着该值将在对该方法的多次调用中保持一致。</p>
<h2 id="例子">例子</h2>
<p>下面的例子是在事件的键控数据流上检测模式 start, middle(name = &ldquo;error&rdquo;) -&gt; end(name = &ldquo;critical&rdquo;)。这些事件通过其 id 进行 keyed, 一个有效的模式必须在 10 秒内出现。整个处理过程是以事件时间来完成的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">:</span> <span class="kt">StreamExecutionEnvironment</span> <span class="o">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">input</span> <span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Event</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">partitionedInput</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="k">=&gt;</span> <span class="n">event</span><span class="o">.</span><span class="n">getId</span><span class="o">)</span>

<span class="k">val</span> <span class="n">pattern</span> <span class="k">=</span> <span class="nc">Pattern</span><span class="o">.</span><span class="n">begin</span><span class="o">[</span><span class="kt">Event</span><span class="o">](</span><span class="s">&#34;start&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="s">&#34;middle&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span> <span class="o">==</span> <span class="s">&#34;error&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">followedBy</span><span class="o">(</span><span class="s">&#34;end&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getName</span> <span class="o">==</span> <span class="s">&#34;critical&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">within</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>

<span class="k">val</span> <span class="n">patternStream</span> <span class="k">=</span> <span class="nc">CEP</span><span class="o">.</span><span class="n">pattern</span><span class="o">(</span><span class="n">partitionedInput</span><span class="o">,</span> <span class="n">pattern</span><span class="o">)</span>

<span class="k">val</span> <span class="n">alerts</span> <span class="k">=</span> <span class="n">patternStream</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">createAlert</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
</code></pre></div><h2 id="从旧版本13-前迁移到-14-以上版本">从旧版本(1.3 前)迁移到 1.4 以上版本</h2>
<h3 id="迁移到-14-版本">迁移到 1.4+ 版本</h3>
<p>在 Flink-1.4 中, CEP 库与 &lt;= Flink 1.2 的向后兼容性被取消。不幸的是, 无法恢复曾经在 1.2.x 下运行的 CEP 作业。</p>
<h3 id="迁移到-13x">迁移到 1.3.x</h3>
<p>Flink-1.3 中的 CEP 库有很多新的特性, 这导致了 API 的一些变化。在这里, 我们描述了为了能够在 Flink-1.3 中运行, 你需要对你的旧 CEP 作业进行的修改。在做了这些改变并重新编译你的作业后, 你将能够从旧版作业的保存点恢复执行, 也就是说, 不需要重新处理你过去的数据。</p>
<p>所需的更改是:</p>
<ul>
<li>
<p>改变你的条件（在 where(&hellip;) 子句中的条件）来扩展 SimpleCondition 类, 而不是实现 FilterFunction 接口。</p>
</li>
<li>
<p>改变你的函数作为参数提供给 select(&hellip;) 和 flatSelect(&hellip;) 方法, 以期望与每个模式相关联的事件列表(Java 中为 List, Scala 中为 Iterable)。这是因为增加了循环模式后, 多个输入事件可以匹配一个（循环）模式。</p>
</li>
<li>
<p>Flink 1.1 和 1.2 中的 followBy() 暗示了非确定性的松散毗连性（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/libs/cep.html#conditions-on-contiguity">这里</a>）。在 Flink 1.3 中, 这一点发生了变化, followBy() 意味着松散毗连, 而 followByAny() 应该在需要非确定性松散毗连的情况下使用。</p>
</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[执行模式(批/流)]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-10-execution-mode/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="分布式架构" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-10-execution-mode/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-10T00:00:00+08:00</published>
            <updated>2020-12-10T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Execution Mode(Batch/Streaming)</blockquote><h1 id="执行模式流批">执行模式(流/批)</h1>
<p>DataStream API 支持不同的运行时执行模式，你可以根据用例的要求和作业的特点从中选择。</p>
<p>DataStream API 有一种&quot;经典&quot;的执行行为，我们称之为 <strong>STREAMING</strong> 执行模式。这应该用于需要连续增量处理并预计无限期保持在线的无边界作业。</p>
<p>此外，还有一种批式执行模式，我们称之为 <strong>BATCH</strong> 执行模式。这种执行作业的方式更容易让人联想到批处理框架，如 MapReduce。这应该用于有边界的作业，对于这些作业，你有一个已知的固定输入，并且不会连续运行。</p>
<p>Apache Flink 对流和批处理的统一方法意味着，无论配置何种执行模式，在有界输入上执行的 DataStream 应用都会产生相同的最终结果。重要的是要注意这里的 final 是什么意思：在 streaming 模式下执行的作业可能会产生增量更新（想想数据库中的 upserts），而 batch 作业在最后只会产生一个最终结果。如果解释正确的话，最终的结果是一样的，但是到达那里的方式可能是不同的。</p>
<p>通过启用 <strong>BATCH</strong> 执行，我们允许 Flink 应用额外的优化，而这些优化只有在我们知道我们的输入是有边界的情况下才能进行。例如，可以使用不同的 join/aggregation 策略，此外还可以使用不同的 shuffle 实现，允许更高效的任务调度和故障恢复行为。下面我们将介绍一些执行行为的细节。</p>
<h2 id="什么时候可以应该使用-batch-执行模式">什么时候可以/应该使用 BATCH 执行模式？</h2>
<p><strong>BATCH</strong> 执行模式只能用于有边界的 Job/Link 程序。边界性是数据源的一个属性，它告诉我们在执行之前，来自该数据源的所有输入是否都是已知的，或者是否会有新的数据出现，可能是无限的。而一个作业，如果它的所有源都是有界的，则是有界的，否则就是无界的。</p>
<p>另一方面，<strong>STREAMING</strong> 执行模式既可以用于有界作业，也可以用于无界作业。</p>
<p>作为经验法则，当你的程序是有界的时候，你应该使用 <strong>BATCH</strong> 执行模式，因为这样会更有效率。当你的程序是无边界的时候，你必须使用 <strong>STREAMING</strong> 执行模式，因为只有这种模式足够通用，能够处理连续的数据流。</p>
<p>一个明显的例外情况是，当你想使用一个有界作业来引导一些作业状态，然后你想在一个无界作业中使用。例如，通过使用 <strong>STREAMING</strong> 模式运行一个有界作业，取一个保存点，然后在一个无界作业上恢复该保存点。这是一个非常特殊的用例，当我们允许将保存点作为 <strong>BATCH</strong> 执行作业的额外输出时，这个用例可能很快就会过时。</p>
<p>另一个可能使用 <strong>STREAMING</strong> 模式运行有边界作业的情况是为最终将在无边界源中运行的代码编写测试时。对于测试来说，在这些情况下使用有界源可能更自然。</p>
<h2 id="配置-batch-执行模式">配置 BATCH 执行模式</h2>
<p>执行模式可以通过 <code>execute.runtim-mode</code> 设置来配置。有三种可能的值:</p>
<ul>
<li><strong>STREAMING</strong>: 经典的 DataStream 执行模式(默认)</li>
<li><strong>BATCH</strong>: 在 DataStream API 上进行批量式执行</li>
<li><strong>AUTOMATIC</strong>：让系统根据源的边界性来决定</li>
</ul>
<p>这可以通过 <code>bin/flink run ...</code> 的命令行参数进行配置，或者在创建/配置 StreamExecutionEnvironment 时进行编程。</p>
<p>下面是如何通过命令行配置执行模式:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ bin/flink run -Dexecution.runtime-mode<span class="o">=</span>BATCH examples/streaming/WordCount.jar
</code></pre></div><p>这个例子展示了如何在代码中配置执行模式:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setRuntimeMode</span><span class="o">(</span><span class="n">RuntimeExecutionMode</span><span class="o">.</span><span class="na">BATCH</span><span class="o">);</span>
</code></pre></div><blockquote>
<p>注意：我们建议用户不要在程序中设置运行模式，而是在提交应用程序时使用命令行进行设置。保持应用程序代码的免配置可以让程序更加灵活，因为同一个应用程序可以在任何执行模式下执行。</p>
</blockquote>
<h2 id="执行行为">执行行为</h2>
<p>本节概述了 BATCH 执行模式的执行行为，并与 STREAMING 执行模式进行了对比。详细内容请参考介绍该功能的 <a href="https://cwiki.apache.org/confluence/x/4i94CQ">FLIP-134</a> 和 <a href="https://cwiki.apache.org/confluence/x/kDh4CQ">FLIP-140</a>。</p>
<h3 id="任务调度和网络洗牌shuffle">任务调度和网络洗牌(Shuffle)</h3>
<p>Flink 作业(job)由不同的操作(operation)组成，这些操作在数据流图中连接在一起。系统决定如何在不同的进程/机器（TaskManager）上安排这些操作的执行，以及如何在它们之间洗牌（发送）数据。</p>
<p>多个操作/运算符可以使用一种称为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/#task-chaining-and-resource-groups">链式</a>的功能链在一起。Flink 认为作为调度单位的一组一个或多个（链式）运算符(operators )被称为任务(<em>task</em>)。通常，子任务(subtask)一词用来指在多个 TaskManager 上并行运行的单个任务实例，但我们在这里只使用任务(task)一词。</p>
<p>任务调度和网络洗牌对于 <strong>BATCH</strong> 和 <strong>STREAMING</strong> 执行模式的工作方式不同。主要是由于我们知道我们的输入数据在 <strong>BATCH</strong> 执行模式下是有边界的，这使得 Flink 可以使用更高效的数据结构和算法。</p>
<p>我们将用这个例子来解释任务调度和网络传输的差异。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataStreamSource</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">source</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(...);</span>

<span class="n">source</span><span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;source&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map1&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map2&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">rebalance</span><span class="o">()</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map3&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map4&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">keyBy</span><span class="o">((</span><span class="n">value</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">value</span><span class="o">)</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map5&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">map</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;map6&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="na">sinkTo</span><span class="o">(...).</span><span class="na">name</span><span class="o">(</span><span class="s">&#34;sink&#34;</span><span class="o">);</span>
</code></pre></div><p>暗示操作之间1对1连接模式的操作，如 <code>map()</code>、<code>flatMap()</code> 或 <code>filter()</code>，可以直接将数据转发到下一个操作，这使得这些操作可以链在一起。这意味着 Flink 通常不会在它们之间插入网络洗牌。</p>
<p>而 <code>keyBy()</code> 或 <code>rebalance()</code> 等操作则需要在不同的任务并行实例之间进行数据洗牌。这就会引起网络洗牌。</p>
<p>对于上面的例子，Flink 会把操作分组为这样的任务。</p>
<ul>
<li>Task1: source, map1 和 map2</li>
<li>Task2: map3, map4</li>
<li>Task3: map5, map6 和 sink</li>
</ul>
<p>而我们在任务1和2，以及任务2和3之间进行网络洗牌。这是该作业的可视化表示。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.12/fig/datastream-example-job-graph.svg" alt="img"></p>
<h3 id="streaming-执行模式">STREAMING 执行模式</h3>
<p>在 <strong>STREAMING</strong> 执行模式下，所有任务需要一直在线/运行。这使得 Flink 可以通过整个管道立即处理新的记录，而我们需要的是连续和低延迟的流处理。这也意味着分配给一个任务的 TaskManagers 需要有足够的资源来同时运行所有的任务。</p>
<p>网络洗牌是流水线式的，这意味着记录会被立即发送到下游任务，并在网络层上进行一些缓冲。同样，这也是需要的，因为当处理连续的数据流时，在任务（或任务的管道）之间没有自然的数据点（时间点）可以物化。这与 <strong>BATCH</strong> 执行模式形成了鲜明的对比，在 <strong>BATCH</strong> 执行模式下，中间的结果可以被具体化，如下所述。</p>
<h3 id="batch-执行模式">BATCH 执行模式</h3>
<p>在 <strong>BATCH</strong> 执行模式下，一个作业的任务可以被分离成可以一个接一个执行的阶段。我们之所以能做到这一点，是因为输入是有边界的，因此 Flink 可以在进入下一个阶段之前完全处理管道的一个阶段。在上面的例子中，工作会有三个阶段，对应着被洗牌障碍分开的三个任务。</p>
<p>分阶段处理并不是像上面针对 STREAMING 模式所解释的那样，立即向下游任务发送记录，而是需要 Flink 将任务的中间结果物化到一些非永续存储中，让下游任务在上游任务已经下线后再读取。这将增加处理的延迟，但也会带来其他有趣的特性。首先，这允许 Flink 在故障发生时回溯到最新的可用结果，而不是重新启动整个任务。另一个副作用是，BATCH 作业可以在更少的资源上执行（就 TaskManagers 的可用槽而言），因为系统可以一个接一个地顺序执行任务。</p>
<p>TaskManagers 将至少在下游任务没有消耗它们的情况下保留中间结果。(从技术上讲，它们将被保留到消耗的流水线区域产生它们的输出为止)。在这之后，只要空间允许，它们就会被保留，以便在失败的情况下，可以回溯到前面提到的结果。</p>
<h3 id="状态后端状态">状态后端/状态</h3>
<p>在 STREAMING 模式下，Flink 使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state_backends.html">StateBackend</a> 来控制状态的存储方式和检查点的工作方式。</p>
<p>在 BATCH 模式下，配置的状态后端被忽略。取而代之的是，keyed 操作的输入按键分组（使用排序），然后我们依次处理一个键的所有记录。这样就可以同时只保留一个键的状态。当转到下一个键时，一个给定键的状态将被丢弃。</p>
<p>关于这方面的背景信息，请参见 <a href="https://cwiki.apache.org/confluence/x/kDh4CQ">FLIP-140</a>。</p>
<h3 id="事件时间水印">事件时间/水印</h3>
<p>在支持<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/event_time.html">事件时间</a>方面，Flink 的流运行时建立在一个悲观的假设上，即事件可能会出现顺序外，即一个时间戳t的事件可能会在一个时间戳t+1的事件之后出现。正因为如此，系统永远无法确定在给定的时间戳T下，未来不会再有时间戳 <code>t&lt;T</code> 的元素出现。为了摊平这种失序性对最终结果的影响，同时使系统实用，在 STREAMING 模式下，Flink 使用了一种名为 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html#event-time-and-watermarks">Watermarks</a> 的启发式方法。一个带有时间戳T的水印标志着没有时间戳 <code>t&lt;T</code> 的元素会跟随。</p>
<p>在 BATCH 模式下，输入的数据集是事先已知的，不需要这样的启发式，因为至少可以按照时间戳对元素进行排序，从而按照时间顺序进行处理。对于熟悉流的读者来说，在 BATCH 中，我们可以假设&quot;完美的水印&quot;。</p>
<p>鉴于上述情况，在 BATCH 模式下，我们只需要在输入的末尾有一个与每个键相关的 MAX_WATERMARK，如果输入流没有键，则在输入的末尾有一个。基于这个方案，所有注册的定时器都会在时间结束时触发，用户定义的 WatermarkAssigners 或 WatermarkStrategies 会被忽略。</p>
<h3 id="处理时间">处理时间</h3>
<p>处理时间是指在处理记录的具体实例上，处理记录的机器上的挂钟时间。根据这个定义，我们看到，基于处理时间的计算结果是不可重复的。这是因为同一条记录被处理两次，会有两个不同的时间戳。</p>
<p>尽管如此，在 STREAMING 模式下使用处理时间还是很有用的。原因与流媒体管道经常实时摄取其无限制的输入有关，所以事件时间和处理时间之间存在相关性。此外，由于上述原因，在 STREAMING 模式下，事件时间的1h往往可以几乎是1h的处理时间，也就是挂钟时间。所以使用处理时间可以用于早期（不完全）发射，给出预期结果的提示。</p>
<p>在批处理世界中，这种相关性并不存在，因为在批处理世界中，输入的数据集是静态的，是预先知道的。鉴于此，在 BATCH 模式中，我们允许用户请求当前的处理时间，并注册处理时间计时器，但与事件时间的情况一样，所有的计时器都要在输入结束时发射。</p>
<p>在概念上，我们可以想象，在作业执行过程中，处理时间不会提前，当整个输入处理完毕后，我们会快进到时间结束。</p>
<h3 id="故障恢复">故障恢复</h3>
<p>在 STREAMING 执行模式下，Flink 使用检查点进行故障恢复。请看一下<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/checkpointing.html">检查点文档</a>，了解关于这个和如何配置它的实践文档。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/fault_tolerance.html">通过状态快照进行容错</a>，也有一个比较入门的章节，从更高的层面解释了这些概念。</p>
<p>Checkpointing 用于故障恢复的特点之一是，Flink 在发生故障时，会从检查点重新启动所有正在运行的任务。这可能比我们在 BATCH 模式下所要做的事情更昂贵（如下文所解释），这也是如果你的任务允许的话应该使用 BATCH 执行模式的原因之一。</p>
<p>在 BATCH 执行模式下，Flink 会尝试并回溯到之前的处理阶段，对于这些阶段，仍然有中间结果。潜在地，只有失败的任务（或它们在图中的前辈）才需要重新启动，与从检查点重新启动所有任务相比，可以提高作业的处理效率和整体处理时间。</p>
<h3 id="重要的考虑因素">重要的考虑因素</h3>
<p>与经典的 STREAMING 执行模式相比，在 BATCH 模式下，有些东西可能无法按照预期工作。一些功能的工作方式会略有不同，而其他功能则不支持。</p>
<p>BATCH 模式下的行为变化。</p>
<ul>
<li>&ldquo;滚动&quot;操作，如 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/#reduce"><code>reduce()</code></a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/#aggregations"><code>sum()</code></a>，会对 STREAMING 模式下每一条新记录发出增量更新。在 BATCH 模式下，这些操作不是&quot;滚动&rdquo;。它们只发出最终结果。</li>
</ul>
<p>BATCH 模式下不支持的:</p>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/stateful-stream-processing.html#stateful-stream-processing">Checkpointing</a> 和任何依赖于 checkpointing 的操作都不工作。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/broadcast_state.html">广播状态</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/operators/#iterate">迭代</a></li>
</ul>
<p>自定义操作符应谨慎执行，否则可能会有不恰当的行为。更多细节请参见下面的补充说明。</p>
<h3 id="检查点">检查点</h3>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_execution_mode.html#failure-recovery">如上</a>所述，批处理程序的故障恢复不使用检查点。</p>
<p>重要的是要记住，因为没有检查点，某些功能如 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/api/common/state/CheckpointListener.html">CheckpointListener</a>，以及因此，Kafka 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/kafka.html#kafka-producers-and-fault-tolerance">EXACTLY_ONCE</a> 模式或 StreamingFileSink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html#rolling-policy">OnCheckpointRollingPolicy</a> 将无法工作。如果你需要一个在 BATCH 模式下工作的事务型接收器，请确保它使用 <a href="https://cwiki.apache.org/confluence/x/KEJ4CQ">FLIP-143</a> 中提出的统一接收器 API。</p>
<p>你仍然可以使用所有的状态<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/stream/state/state.html#working-with-state">原语</a>，只是用于故障恢复的机制会有所不同。</p>
<h3 id="广播状态">广播状态</h3>
<p>引入这个特性是为了让用户实现这样的用例：一个&quot;控制&quot;流需要被广播到所有下游任务，而广播的元素，例如规则，需要应用到另一个流的所有输入元素。</p>
<p>在这种模式下，Flink 不提供关于读取输入的顺序的保证。像上面这样的用例在流媒体世界中是有意义的，因为在这个世界中，作业预计会运行很长时间，而输入数据是事先不知道的。在这些设置中，需求可能会随着时间的推移而改变，这取决于输入的数据。</p>
<p>但在批处理世界中，我们认为这种用例没有太大意义，因为输入（包括元素和控制流）是静态的，而且是预先知道的。</p>
<p>我们计划在未来为BATCH处理支持这种模式的变化，即完全先处理广播端。</p>
<h3 id="编写自定义操作符">编写自定义操作符</h3>
<blockquote>
<p>注意：自定义操作符是 Apache Flink 的一种高级使用模式。对于大多数的使用情况，可以考虑使用(keyed-)过程函数来代替。</p>
</blockquote>
<p>在编写自定义操作符时，记住 BATCH 执行模式的假设是很重要的。否则，一个在 STREAMING 模式下运行良好的操作符可能会在 BATCH 模式下产生错误的结果。操作符永远不会被限定在一个特定的键上，这意味着他们看到了 Flink 试图利用的 BATCH 处理的一些属性。</p>
<p>首先你不应该在一个操作符内缓存最后看到的水印。在 BATCH 模式下，我们会逐个键处理记录。因此，水印会在每个键之间从 MAX_VALUE 切换到 MIN_VALUE。你不应该认为水印在一个操作符中总是上升的。出于同样的原因，定时器将首先按键的顺序发射，然后按每个键内的时间戳顺序发射。此外，不支持手动更改键的操作。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Application Building Blocks]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="分布式架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-02T00:00:00+08:00</published>
            <updated>2020-12-02T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Application Building Block</blockquote><h2 id="应用构件">应用构件</h2>
<p>Stateful Functions 为构建事件驱动应用程序提供了一个框架。在这里，我们将解释 Stateful Function 架构的重要方面。</p>
<h2 id="事件输入">事件输入</h2>
<p>有状态函数应用正好坐在事件驱动的领域，所以自然要从把事件摄入系统开始。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/statefun-app-ingress.svg" alt="img"></p>
<p>在有状态函数中，将记录摄入系统的组件称为事件入口。这可以是任何东西，从 Kafka 主题，到 messsage 队列，再到 http 请求 - 任何能够将数据引入系统并触发初始函数开始计算的东西。</p>
<h2 id="有状态函数">有状态函数</h2>
<p>该图的核心是命名的有状态函数。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/statefun-app-functions.svg" alt="img"></p>
<p>把这些函数看作是你的服务的构件。它们可以任意地相互发送消息，这也是这个框架摆脱传统的流处理观点的一种方式。这些函数可以以任意的、可能是循环的、甚至是往返的方式相互通信，而不是建立一个静态的数据流 DAG。</p>
<p>如果你熟悉 actor 编程，这在组件之间动态消息的能力上确实有某些相似之处。然而，也有一些显著的区别。</p>
<h2 id="持续状态">持续状态</h2>
<p>首先是所有函数都有本地嵌入的状态，即所谓的持久化状态。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/statefun-app-state.svg" alt="img"></p>
<p>Apache Flink 的核心优势之一就是它能够提供容错的本地状态。当在一个函数内部，当它在执行一些计算时，你总是在本地变量中处理本地状态。</p>
<h2 id="容错">容错</h2>
<p>对于状态和消息传递，Stateful Functions 能够提供用户从现代数据处理框架中期望的精确的一次保证。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/statefun-app-fault-tolerance.svg" alt="img"></p>
<p>在失败的情况下，整个世界的状态（包括持久化的状态和消息）都会被回滚，以模拟完全无故障的执行。</p>
<p>这些保证是在不需要数据库的情况下提供的，相反，Stateful Function 利用了 Apache Flink 的成熟快照机制。</p>
<h2 id="事件出口">事件出口</h2>
<p>最后，应用程序可以通过事件出口向外部系统输出数据。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/statefun-app-egress.svg" alt="img"></p>
<p>当然，函数执行任意计算，可以随心所欲，这包括进行 RPC 调用和连接到其他系统。通过使用事件出口，应用程序可以利用建立在 Apache Flink 连接器生态系统之上的预建集成。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Logical Functions]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="分布式架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-02T00:00:00+08:00</published>
            <updated>2020-12-02T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Logical Functions</blockquote><h2 id="逻辑函数">逻辑函数</h2>
<p>有状态函数是以逻辑方式分配的，这意味着系统可以用有限的资源支持无限制的实例数量。逻辑实例在不被主动调用时不使用CPU、内存或线程，所以理论上没有可以创建的实例数量上限。我们鼓励用户根据对其应用最合理的情况，尽可能地对其应用进行细化建模，而不是围绕资源限制来设计应用。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/address.svg" alt="img"></p>
<h2 id="函数地址">函数地址</h2>
<p>在本地环境中，对象的地址和对它的引用是一样的。但是在有状态函数应用程序中，函数实例是虚拟的，它们的运行位置不会暴露给用户。相反，地址是用来引用系统中特定的有状态函数的。</p>
<p>一个地址由两个组件组成，一个是 FunctionType，一个是 ID。函数类型类似于面向对象语言中的类，它声明了地址所引用的函数类型。ID 是一个主键，它将函数调用的范围限定在函数类型的一个特定实例上。</p>
<p>当一个函数被调用时，所有的操作&ndash;包括对持久化状态的读和写 - 都会被限定在当前地址上。</p>
<p>例如，想象有一个有状态函数应用程序来跟踪仓库的库存。一个可能的实现可以包括一个库存函数，它可以跟踪一个特定物品的库存单位数量；这将是函数类型。然后，仓库管理的每个 SKU 都会有一个该类型的逻辑实例。如果是服装，可能会有一个衬衫的实例和另一个裤子的实例；&ldquo;衬衫&quot;和 &ldquo;裤子&quot;将是两个 ID。每个实例都可以独立地进行交互和消息传递。应用程序可以根据库存中物品的类型自由创建实例。</p>
<h2 id="函数生命周期">函数生命周期</h2>
<p>逻辑函数既不被创建也不被销毁，而是在应用程序的整个生命周期中始终存在。当应用程序启动时，框架的每个并行工作者将为每个函数类型创建一个物理对象。这个对象将用于执行该类型的所有逻辑实例，该类型的逻辑实例由该特定的 worker 运行。第一次向一个地址发送消息时，它将像该实例一直存在一样，其持久化状态为空。</p>
<p>清除一个类型的所有持久化状态与销毁它是一样的。如果一个实例没有状态，也没有主动运行，那么它就不占用 CPU，不占用线程，也不占用内存。</p>
<p>一个实例在其一个或多个持久化值中存储了数据，它只占用存储该数据所需的资源。状态存储由 Apache Flink 运行时管理，并存储在配置的状态后端。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Python 演练]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="分布式架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-02T00:00:00+08:00</published>
            <updated>2020-12-02T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Python Walkthrough</blockquote><h2 id="python-演练">Python 演练</h2>
<p>Stateful Functions 为构建健壮的、有状态的事件驱动的应用程序提供了一个平台。它提供了对状态和时间的精细控制，这使得高级系统的实现成为可能。在本步骤指南中，您将学习如何使用 Stateful Functions API 构建有状态的应用程序。</p>
<h2 id="你要构建什么">你要构建什么？</h2>
<p>就像软件中所有伟大的介绍一样，这个演练将从开头开始：打招呼。该应用程序将运行一个简单的函数，该函数将接受一个请求并以问候语进行响应。它不会试图涵盖所有复杂的应用程序开发，而是专注于构建一个有状态的函数 - 这是你实现业务逻辑的地方。</p>
<h2 id="先决条件">先决条件</h2>
<p>这个演练假设您对 Python 有一定的了解，但即使您来自不同的编程语言，您也应该能够跟上。</p>
<h2 id="帮助我卡住了">帮助，我卡住了</h2>
<p>如果你被卡住了，请查看<a href="https://flink.apache.org/gettinghelp.html">社区支持资源</a>。特别是 Apache Flink 的<a href="https://flink.apache.org/community.html#mailing-lists">用户邮件列表</a>，一直被认为是 Apache 项目中最活跃的一个，也是快速获得帮助的好方法。</p>
<h2 id="如何跟进">如何跟进</h2>
<p>如果你想跟上，你需要一台装有 <a href="https://www.python.org/">Python 3</a> 以及 <a href="https://www.docker.com/">Docker</a> 的电脑。</p>
<blockquote>
<p>注意：为了简洁起见，本演练中的每个代码块可能不包含完整的周边类。完整的代码可以在<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/python_walkthrough.html#full-application">本页底部</a>找到。</p>
</blockquote>
<p>你可以通过点击<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/downloads/walkthrough.zip">这里</a>下载一个包含骨架项目的 zip 文件。</p>
<p>解压包后，你会发现一些文件。这些文件包括 dockerfiles 和数据生成器，用于在本地自包含环境中运行此演练。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ tree statefun-walkthrough
statefun-walkthrough
├── Dockerfile
├── docker-compose.yml
├── generator
│   ├── Dockerfile
│   ├── event-generator.py
│   └── messages_pb2.py
├── greeter
│   ├── Dockerfile
│   ├── greeter.py
│   ├── messages.proto
│   ├── messages_pb2.py
│   └── requirements.txt
└── module.yaml
</code></pre></div><h2 id="从事件开始">从事件开始</h2>
<p>Stateful Functions 是一个事件驱动的系统，所以开发从定义我们的事件开始。问候者应用程序将使用<a href="https://developers.google.com/protocol-buffers">协议缓冲区</a>定义其事件。当一个特定用户的问候请求被摄入时，它将被路由到相应的函数。响应将返回一个适当的问候。第三种类型，SeenCount，是一个实用类，后期将用于帮助管理用户到目前为止被看到的次数。</p>
<pre><code>syntax = &quot;proto3&quot;;

package example;

// External request sent by a user who wants to be greeted
message GreetRequest {
    // The name of the user to greet
    string name = 1;
}
// A customized response sent to the user
message GreetResponse {
    // The name of the user being greeted
    string name = 1;
    // The users customized greeting
    string greeting = 2;
}
// An internal message used to store state
message SeenCount {
    // The number of times a users has been seen so far
    int64 seen = 1;
}
</code></pre><h2 id="我们的第一个函数">我们的第一个函数</h2>
<p>在底层，消息是使用<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/sdk/python.html">有状态的函数</a>来处理的，也就是任何绑定到 <code>StatefulFunction</code> 运行时的两个参数函数。函数用 <code>@function.bind</code> 装饰器绑定到运行时。当绑定一个函数时，它会被注解为一个函数类型。这是在向这个函数发送消息时用来引用它的名称。</p>
<p>当你打开文件 <code>greeter/greeter.py</code> 时，你应该看到以下代码。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">StatefulFunctions</span>

<span class="n">functions</span> <span class="o">=</span> <span class="n">StatefulFunctions</span><span class="p">()</span>

<span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">greet_request</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div><p>一个有状态函数需要两个参数，即上下文和消息。<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/sdk/python.html#context-reference">上下文</a>提供了对有状态函数运行时功能的访问，如状态管理和消息传递。您将在本演练中探索其中的一些功能。</p>
<p>另一个参数是传递给这个函数的输入消息。默认情况下，消息是以 protobuf <a href="https://developers.google.com/protocol-buffers/docs/reference/python-generated#wkt">Any</a> 的形式传递的。如果一个函数只接受一个已知的类型，你可以使用 <a href="https://www.python.org/">Python 3</a> 类型语法覆盖消息类型。这样您就不需要对消息进行拆包或检查类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">messages_pb2</span> <span class="kn">import</span> <span class="n">GreetRequest</span>
<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">StatefulFunctions</span>

<span class="n">functions</span> <span class="o">=</span> <span class="n">StatefulFunctions</span><span class="p">()</span>

<span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">greet_request</span><span class="p">:</span> <span class="n">GreetRequest</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div><h2 id="发送回复">发送回复</h2>
<p>有状态函数接受消息，也可以将消息发送出去。消息可以被发送到其他函数，以及外部系统（或<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/io-module/index.html#egress">出口</a>）。</p>
<p>一个流行的外部系统是 <a href="http://kafka.apache.org/">Apache Kafka</a>。第一步，让我们更新 <code>greeter/greeter.py</code> 中的函数，通过向 Kafka 主题发送问候语来响应每个输入。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">messages_pb2</span> <span class="kn">import</span> <span class="n">GreetRequest</span><span class="p">,</span> <span class="n">GreetResponse</span>
<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">StatefulFunctions</span>

<span class="n">functions</span> <span class="o">=</span> <span class="n">StatefulFunctions</span><span class="p">()</span>

<span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">greet_request</span><span class="p">:</span> <span class="n">GreetRequest</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">GreetResponse</span><span class="p">()</span>
    <span class="n">response</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">greet_request</span><span class="o">.</span><span class="n">name</span>
    <span class="n">response</span><span class="o">.</span><span class="n">greeting</span> <span class="o">=</span> <span class="s2">&#34;Hello {}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    
    <span class="n">egress_message</span> <span class="o">=</span> <span class="n">kafka_egress_record</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="s2">&#34;greetings&#34;</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">pack_and_send_egress</span><span class="p">(</span><span class="s2">&#34;example/greets&#34;</span><span class="p">,</span> <span class="n">egress_message</span><span class="p">)</span>
</code></pre></div><p>对于每条消息，都会构造一个响应，并发送到一个名为 <code>greetings</code> 的 Kafka 主题，该主题按名称分区。<code>egress_message</code> 被发送到一个名为 <code>example/greets</code> 的出口。这个标识符指向一个特定的 Kafka 集群，并在下面的部署中进行配置。</p>
<h2 id="一个有状态的-hello">一个有状态的 Hello</h2>
<p>这是一个很好的开端，但并没有展现出有状态函数的真正威力 - 与状态一起工作。假设你想根据每个用户发送请求的次数，为他们生成个性化的响应。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">compute_greeting</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">seen</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Compute a personalized greeting, based on the number of times this @name had been seen before.
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">templates</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="s2">&#34;Welcome </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="s2">&#34;Nice to see you again </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="s2">&#34;Third time is a charm </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">seen</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">templates</span><span class="p">):</span>
        <span class="n">greeting</span> <span class="o">=</span> <span class="n">templates</span><span class="p">[</span><span class="n">seen</span><span class="p">]</span> <span class="o">%</span> <span class="n">name</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">greeting</span> <span class="o">=</span> <span class="s2">&#34;Nice to see you at the </span><span class="si">%d</span><span class="s2">-nth time </span><span class="si">%s</span><span class="s2">!&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">seen</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">GreetResponse</span><span class="p">()</span>
    <span class="n">response</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">response</span><span class="o">.</span><span class="n">greeting</span> <span class="o">=</span> <span class="n">greeting</span>

    <span class="k">return</span> <span class="n">response</span>
</code></pre></div><p>为了&quot;记住&quot;多条问候信息，你需要将一个持久化的值域（ <code>seen_count</code> ）关联到 <code>Greet</code> 函数。对于每个用户，函数现在可以跟踪他们被看到的次数。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">greet_request</span><span class="p">:</span> <span class="n">GreetRequest</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="s1">&#39;seen_count&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">SeenCount</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">SeenCount</span><span class="p">()</span>
        <span class="n">state</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">state</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">context</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="s1">&#39;seen_count&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">compute_greeting</span><span class="p">(</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">seen</span><span class="p">)</span>

    <span class="n">egress_message</span> <span class="o">=</span> <span class="n">kafka_egress_record</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="s2">&#34;greetings&#34;</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">pack_and_send_egress</span><span class="p">(</span><span class="s2">&#34;example/greets&#34;</span><span class="p">,</span> <span class="n">egress_message</span><span class="p">)</span>
</code></pre></div><p>状态 <code>seen_count</code> 始终是当前名称的范围，因此它可以独立地跟踪每个用户。</p>
<h2 id="连接在一起">连接在一起</h2>
<p>有状态的 Function 应用程序使用 http 与 Apache Flink 运行时进行通信。Python SDK 提供了一个 RequestReplyHandler，它可以基于 RESTful HTTP POSTS 自动分配函数调用。RequestReplyHandler 可以使用任何 HTTP 框架暴露。</p>
<p>一个流行的 Python web 框架是 <a href="https://palletsprojects.com/p/flask/">Flask</a>。它可以用来快速、轻松地将应用程序暴露给 Apache Flink 运行时。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">StatefulFunctions</span>
<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">RequestReplyHandler</span>

<span class="n">functions</span> <span class="o">=</span> <span class="n">StatefulFunctions</span><span class="p">()</span>

<span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greeter</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">message</span><span class="p">:</span> <span class="n">GreetRequest</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="n">handler</span> <span class="o">=</span> <span class="n">RequestReplyHandler</span><span class="p">(</span><span class="n">functions</span><span class="p">)</span>

<span class="c1"># Serve the endpoint</span>

<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">request</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">make_response</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="nd">@app.route</span><span class="p">(</span><span class="s1">&#39;/statefun&#39;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;POST&#39;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">handle</span><span class="p">():</span>
    <span class="n">response_data</span> <span class="o">=</span> <span class="n">handler</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">make_response</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s1">&#39;Content-Type&#39;</span><span class="p">,</span> <span class="s1">&#39;application/octet-stream&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div><h2 id="配置运行时">配置运行时</h2>
<p>有状态函数运行时通过向 Flask 服务器进行 http 调用来向 <code>greeter</code> 函数发出请求。要做到这一点，它需要知道它可以使用什么端点来到达服务器。这也是配置我们连接到输入和输出 Kafka 主题的好时机。配置在一个名为 module.yaml 的文件中。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1.0&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">module</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">remote</span><span class="w">
</span><span class="w">  </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">functions</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">function</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">http</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">example/greeter</span><span class="w">
</span><span class="w">          </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">endpoint</span><span class="p">:</span><span class="w"> </span><span class="l">http://python-worker:8000/statefun</span><span class="w">
</span><span class="w">            </span><span class="nt">states</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="l">seen_count</span><span class="w">
</span><span class="w">            </span><span class="nt">maxNumBatchRequests</span><span class="p">:</span><span class="w"> </span><span class="m">500</span><span class="w">
</span><span class="w">            </span><span class="nt">timeout</span><span class="p">:</span><span class="w"> </span><span class="l">2min</span><span class="w">
</span><span class="w">    </span><span class="nt">ingresses</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">ingress</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">statefun.kafka.io/routable-protobuf-ingress</span><span class="w">
</span><span class="w">            </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l">example/names</span><span class="w">
</span><span class="w">          </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">address</span><span class="p">:</span><span class="w"> </span><span class="l">kafka-broker:9092</span><span class="w">
</span><span class="w">            </span><span class="nt">consumerGroupId</span><span class="p">:</span><span class="w"> </span><span class="l">my-group-id</span><span class="w">
</span><span class="w">            </span><span class="nt">topics</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">topic</span><span class="p">:</span><span class="w"> </span><span class="l">names</span><span class="w">
</span><span class="w">                </span><span class="nt">typeUrl</span><span class="p">:</span><span class="w"> </span><span class="l">com.googleapis/example.GreetRequest</span><span class="w">
</span><span class="w">                </span><span class="nt">targets</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">example/greeter</span><span class="w">
</span><span class="w">    </span><span class="nt">egresses</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">egress</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">statefun.kafka.io/generic-egress</span><span class="w">
</span><span class="w">            </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l">example/greets</span><span class="w">
</span><span class="w">          </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">address</span><span class="p">:</span><span class="w"> </span><span class="l">kafka-broker:9092</span><span class="w">
</span><span class="w">            </span><span class="nt">deliverySemantic</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">exactly-once</span><span class="w">
</span><span class="w">              </span><span class="nt">transactionTimeoutMillis</span><span class="p">:</span><span class="w"> </span><span class="m">100000</span><span class="w">
</span></code></pre></div><p>这个配置做了一些有趣的事情。</p>
<p>首先是声明我们的函数 <code>example/greeter</code>。它包括它可以到达的端点以及函数可以访问的状态。</p>
<p><code>ingress</code> 是将 <code>GreetRequest</code> 消息路由到函数的输入 Kafka 主题。除了 broker 地址和消费者组等基本属性，它还包含一个目标列表。这些是每个消息将被发送到的函数。</p>
<p>出口是输出的 Kafka 集群。它包含 broker 特定的配置，但允许每个消息路由到任何主题。</p>
<h2 id="部署">部署</h2>
<p>现在已经构建了 <code>greeter</code> 应用程序，是时候部署了。部署 Stateful Function 应用程序最简单的方法是使用社区提供的基础映像并加载你的模块。基础镜像提供了 Stateful Function 运行时，它将使用提供的 module.yaml 来为这个特定的工作进行配置。这可以在根目录下的 Docker 文件中找到。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">FROM flink-statefun:2.2.0

RUN mkdir -p /opt/statefun/modules/greeter
ADD module.yaml /opt/statefun/modules/greeter
</code></pre></div><p>现在您可以使用提供的 Docker 设置在本地运行此应用程序。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose up -d
</code></pre></div><p>那么，要想在行动中看到例子，就看看话题问候出来的内容。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f event-generator 
</code></pre></div><h2 id="想更进一步">想更进一步？</h2>
<p>这个 Greeter 永远不会忘记一个用户。试着修改这个函数，使它能够为任何没有与系统交互的用户花超过60秒的时间重置 <code>seen_count</code>。</p>
<p>查看 <a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/sdk/python.html">Python SDK</a> 页面以获得更多关于如何实现这一功能的信息。</p>
<h2 id="完整应用">完整应用</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">messages_pb2</span> <span class="kn">import</span> <span class="n">SeenCount</span><span class="p">,</span> <span class="n">GreetRequest</span><span class="p">,</span> <span class="n">GreetResponse</span>

<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">StatefulFunctions</span>
<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">RequestReplyHandler</span>
<span class="kn">from</span> <span class="nn">statefun</span> <span class="kn">import</span> <span class="n">kafka_egress_record</span>

<span class="n">functions</span> <span class="o">=</span> <span class="n">StatefulFunctions</span><span class="p">()</span>

<span class="nd">@functions.bind</span><span class="p">(</span><span class="s2">&#34;example/greeter&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">greet_request</span><span class="p">:</span> <span class="n">GreetRequest</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="s1">&#39;seen_count&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">SeenCount</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">SeenCount</span><span class="p">()</span>
        <span class="n">state</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">state</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">context</span><span class="o">.</span><span class="n">state</span><span class="p">(</span><span class="s1">&#39;seen_count&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">compute_greeting</span><span class="p">(</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">seen</span><span class="p">)</span>

    <span class="n">egress_message</span> <span class="o">=</span> <span class="n">kafka_egress_record</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="s2">&#34;greetings&#34;</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">greet_request</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">pack_and_send_egress</span><span class="p">(</span><span class="s2">&#34;example/greets&#34;</span><span class="p">,</span> <span class="n">egress_message</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_greeting</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">seen</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Compute a personalized greeting, based on the number of times this @name had been seen before.
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">templates</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="s2">&#34;Welcome </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="s2">&#34;Nice to see you again </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="s2">&#34;Third time is a charm </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">seen</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">templates</span><span class="p">):</span>
        <span class="n">greeting</span> <span class="o">=</span> <span class="n">templates</span><span class="p">[</span><span class="n">seen</span><span class="p">]</span> <span class="o">%</span> <span class="n">name</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">greeting</span> <span class="o">=</span> <span class="s2">&#34;Nice to see you at the </span><span class="si">%d</span><span class="s2">-nth time </span><span class="si">%s</span><span class="s2">!&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">seen</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">GreetResponse</span><span class="p">()</span>
    <span class="n">response</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">response</span><span class="o">.</span><span class="n">greeting</span> <span class="o">=</span> <span class="n">greeting</span>

    <span class="k">return</span> <span class="n">response</span>


<span class="n">handler</span> <span class="o">=</span> <span class="n">RequestReplyHandler</span><span class="p">(</span><span class="n">functions</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Serve the endpoint</span>
<span class="c1">#</span>

<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">request</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">make_response</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@app.route</span><span class="p">(</span><span class="s1">&#39;/statefun&#39;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;POST&#39;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">handle</span><span class="p">():</span>
    <span class="n">response_data</span> <span class="o">=</span> <span class="n">handler</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">make_response</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s1">&#39;Content-Type&#39;</span><span class="p">,</span> <span class="s1">&#39;application/octet-stream&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Sdk]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="分布式架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-02-sdk/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-02T00:00:00+08:00</published>
            <updated>2020-12-02T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Sdk</blockquote><h2 id="sdk">SDK</h2>
<p>有状态函数应用程序由一个或多个模块组成。一个模块是一个由运行时加载的函数捆绑，并提供给消息。来自所有加载模块的函数都是多路复用的，并且可以自由地相互发送消息。</p>
<p>有状态函数支持两种类型的模块。远程模块和嵌入式模块。</p>
<h2 id="远程模块">远程模块</h2>
<p>远程模块作为 Apache Flink® 运行时的外部进程运行；在同一容器中，作为 sidecar，使用无服务器平台或其他外部位置。这种模块类型可以支持任何数量的语言 SDK。远程模块通过 YAML 配置文件在系统中注册。</p>
<h2 id="技术指标">技术指标</h2>
<p>一个远程模块配置由一个元部分和一个规范部分组成。<code>meta</code> 包含了模块的辅助信息；而 <code>spec</code> 则描述了模块中包含的功能并定义了它们的持久值。</p>
<h2 id="定义函数">定义函数</h2>
<p>module.spec.functions 声明了一个由远程模块实现的函数对象列表。一个函数通过一些属性来描述。</p>
<ul>
<li>function.meta.kind
<ul>
<li>用于与远程功能通信的协议。</li>
<li>所支持的值 - http</li>
</ul>
</li>
<li>function.meta.type
<ul>
<li>函数类型那个, 被定义为 <code>&lt;namespace&gt;/&lt;name&gt;</code>。</li>
</ul>
</li>
<li>function.spec.endpoint
<ul>
<li>函数可到达的端点。</li>
<li>所支持的 schemes: http, https.</li>
<li>使用 http+unix 或 https+unix 方案支持通过 UNIX 域套接字进行传输。</li>
<li>当使用 UNIX 域套接字时，端点格式是: <code>http+unix://&lt;socket-file-path&gt;/&lt;serve-url-path&gt;</code>。例如, <code>http+unix:///uds.sock/path/of/url</code>。</li>
</ul>
</li>
<li>function.spec.states
<ul>
<li>在远程函数中声明的持久化值的列表</li>
<li>每个条目由 <code>name</code> 属性和可选的 <code>expireAfter</code> 属性组成。</li>
<li>expireAfter 的默认值为 0，表示状态过期被禁用。</li>
</ul>
</li>
<li>function.spec.maxNumBatchRequests
<ul>
<li>在调用系统背压之前，一个函数可以处理的特定地址的最大记录数。</li>
<li>默认值：1000</li>
</ul>
</li>
<li>function.spec.timeout
<ul>
<li>运行时在失败前等待远程函数返回的最长时间。这涵盖了整个调用过程，包括连接到函数端点、编写请求、函数处理和读取响应。</li>
<li>默认值：1分钟</li>
</ul>
</li>
<li>function.spec.connectTimeout
<ul>
<li>运行时等待连接到远程函数端点的最长时间。</li>
<li>默认值：10秒。</li>
</ul>
</li>
<li>function.spec.readTimeout
<ul>
<li>运行时等待单个读IO操作的最大时间，如读取调用响应。</li>
<li>默认值：10秒。</li>
</ul>
</li>
<li>function.spec.writeTimeout
<ul>
<li>运行时等待单个写IO操作的最大时间，比如写调用请求。</li>
<li>默认值：10秒。</li>
</ul>
</li>
</ul>
<h2 id="完整示例">完整示例</h2>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;2.0&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">module</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">remote</span><span class="w">
</span><span class="w">  </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">functions</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">function</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">meta</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">http</span><span class="w">
</span><span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">example/greeter</span><span class="w">
</span><span class="w">        </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">endpoint</span><span class="p">:</span><span class="w"> </span><span class="l">http://&lt;host-name&gt;/statefun</span><span class="w">
</span><span class="w">          </span><span class="nt">states</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">seen_count</span><span class="w">
</span><span class="w">              </span><span class="nt">expireAfter</span><span class="p">:</span><span class="w"> </span><span class="l">5min</span><span class="w">
</span><span class="w">          </span><span class="nt">maxNumBatchRequests</span><span class="p">:</span><span class="w"> </span><span class="m">500</span><span class="w">
</span><span class="w">          </span><span class="nt">timeout</span><span class="p">:</span><span class="w"> </span><span class="l">2min</span><span class="w">
</span></code></pre></div><h2 id="嵌入式模块">嵌入式模块</h2>
<p>嵌入式模块与 Apache Flink® 运行时共存，并嵌入其中。</p>
<p>这种模块类型只支持基于 JVM 的语言，并通过实现 StatefulFunctionModule 接口来定义。嵌入模块提供了一个单一的配置方法，有状态的函数根据其<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/concepts/logical.html#function-address">函数类型</a>与系统绑定。运行时配置可以通过 globalConfiguration 来实现，它是应用程序 flink-conf.yaml 中前缀 statefun.module.global-config 下的所有配置以及以 <code>--key value</code> 形式传递的任何命令行参数的联合。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">package</span> <span class="nn">org.apache.flink.statefun.docs</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.statefun.sdk.spi.StatefulFunctionModule</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">BasicFunctionModule</span> <span class="kd">implements</span> <span class="n">StatefulFunctionModule</span> <span class="o">{</span>

	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">(</span><span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">globalConfiguration</span><span class="o">,</span> <span class="n">Binder</span> <span class="n">binder</span><span class="o">)</span> <span class="o">{</span>

		<span class="c1">// Declare the user function and bind it to its type
</span><span class="c1"></span>		<span class="n">binder</span><span class="o">.</span><span class="na">bindFunctionProvider</span><span class="o">(</span><span class="n">FnWithDependency</span><span class="o">.</span><span class="na">TYPE</span><span class="o">,</span> <span class="k">new</span> <span class="n">CustomProvider</span><span class="o">());</span>

		<span class="c1">// Stateful functions that do not require any configuration
</span><span class="c1"></span>		<span class="c1">// can declare their provider using java 8 lambda syntax
</span><span class="c1"></span>		<span class="n">binder</span><span class="o">.</span><span class="na">bindFunctionProvider</span><span class="o">(</span><span class="n">Identifiers</span><span class="o">.</span><span class="na">HELLO_TYPE</span><span class="o">,</span> <span class="n">unused</span> <span class="o">-&gt;</span> <span class="k">new</span> <span class="n">FnHelloWorld</span><span class="o">());</span>
	<span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>嵌入式模块利用 <a href="https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html">Java 的服务提供者接口</a>（SPI）进行发现。这意味着每个 JAR 都应该在 <code>META_INF/services</code> 资源目录下包含一个文件 <code>org.apache.flink.statefun.sdk.spi.StatefulFunctionModule</code>，该文件列出了它提供的所有可用模块。</p>
<pre><code>org.apache.flink.statefun.docs.BasicFunctionModule
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[分布式架构]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-application-building-block/?utm_source=atom_feed" rel="related" type="text/html" title="Application Building Blocks" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-logical-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Logical Functions" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-python-walkthrough/?utm_source=atom_feed" rel="related" type="text/html" title="Python 演练" />
                <link href="https://ohmyweekly.github.io/notes/2020-12-02-sdk/?utm_source=atom_feed" rel="related" type="text/html" title="Sdk" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
            
                <id>https://ohmyweekly.github.io/notes/2020-12-02-distributed-architecture/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-12-02T00:00:00+08:00</published>
            <updated>2020-12-02T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Distributed Architecture</blockquote><h2 id="分布式架构">分布式架构</h2>
<p>一个有状态的 Functions 部署是由几个组件交互在一起组成的。在这里，我们将描述这些组件及其相互之间的关系和 Apache Flink 运行时。</p>
<h2 id="高层视图">高层视图</h2>
<p>一个 Stateful Functions 部署由一组 Apache Flink Stateful Functions 进程和可选的执行远程函数的各种部署组成。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/arch_overview.svg" alt="img"></p>
<p>Flink Worker 进程（TaskManagers）从入口系统（Kafka、Kinesis 等）接收事件并将其路由到目标函数。它们调用函数并将产生的消息路由到下一个各自的目标函数。指定用于出口的消息被写入出口系统（同样，Kafka、Kinesis&hellip;）。</p>
<h2 id="组成部分">组成部分</h2>
<p>繁重的工作由 Apache Flink 进程完成，它管理状态，处理消息传递，并调用有状态的函数。Flink 集群通常由一个主进程和多个工作者（TaskManagers）组成。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/arch_components.svg" alt="img"></p>
<p>除了 Apache Flink 进程，完整的部署还需要 <a href="https://zookeeper.apache.org/">ZooKeeper</a>（用于主站<a href="https://ci.apache.org/projects/flink/flink-docs-stable/ops/jobmanager_high_availability.html">故障转移</a>）和批量存储（S3、HDFS、NAS、GCS、Azure Blob Store等）来存储 Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-master/concepts/stateful-stream-processing.html#checkpointing">检查点</a>。而部署时不需要数据库，Flink 进程也不需要持久化卷。</p>
<h2 id="逻辑同位物理分离">逻辑同位，物理分离</h2>
<p>许多流处理器的一个核心原则是，应用逻辑和应用状态必须是共位的。这种方法是它们开箱即用的一致性的基础。Stateful Functions 采用了一种独特的方法，在逻辑上将状态和计算共置，但允许在物理上将它们分开。</p>
<ul>
<li>
<p>逻辑上的共置。消息传递、状态访问/更新和函数调用被紧密地管理在一起，与 Flink 的 DataStream API 的方式相同。状态按键分片，消息按键路由到状态。每个 key 一次有一个写入器，也是对函数调用进行调度。</p>
</li>
<li>
<p>物理分离。函数可以远程执行，消息和状态访问作为调用请求的一部分。这样，函数就可以像无状态进程一样独立管理。</p>
</li>
</ul>
<h2 id="函数的部署风格">函数的部署风格</h2>
<p>有状态的函数本身可以以不同的方式部署，这些方式可以相互交换某些特性：一方面是松散的耦合和独立的扩展，另一方面是性能开销。每个函数模块可以是不同的种类，所以有些函数可以远程运行，而有些函数可以嵌入式运行。</p>
<h3 id="远程函数">远程函数</h3>
<p>远程功能采用上述物理分离的原则，同时保持逻辑上的同位。状态/消息层（即 Flink 进程）和功能层是独立部署、管理和扩展的。</p>
<p>功能调用通过 HTTP/gRPC 协议发生，并通过服务将调用请求路由到任何可用的端点，例如 Kubernetes（负载平衡）服务、Lambda 的 AWS 请求网关等。因为调用是自足的（包含消息、状态、访问计时器等），所以目标函数可以像任何无状态的应用程序一样对待。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/arch_funs_remote.svg" alt="img"></p>
<p>详情请参考 <a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/sdk/python.html">Python SDK</a> 和<a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/sdk/index.html#remote-module">远程模块</a>的文档。</p>
<h3 id="共置函数">共置函数</h3>
<p>部署函数的另一种方式是与 Flink JVM 进程共处。在这样的设置中，每个 Flink TaskManager 将与坐在&quot;旁边&quot;的一个 Function 进程对话。一种常见的方式是使用 Kubernetes 这样的系统，部署由 Flink 容器和 Function 侧车容器组成的 pod；两者通过 pod-local 网络进行通信。</p>
<p>这种模式支持不同的语言，同时避免了要通过 Service/LoadBalancer 来路由调用，但它不能独立扩展状态和计算部分。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/arch_funs_colocated.svg" alt="img"></p>
<p>这种部署方式类似于 Flink 的 Table API 和 API Beam 的可移植层部署和执行非 JVM 函数的方式。</p>
<h3 id="嵌入式函数">嵌入式函数</h3>
<p>嵌入式函数类似于 Stateful Functions 1.0 的执行模式，也类似于 Flink 的 Java/Scala 流处理 API。函数在 JVM 中运行，直接调用消息和状态访问。这是最有性能的方式，不过代价是只支持 JVM 语言。函数的更新意味着更新 Flink 集群。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/fig/concepts/arch_funs_embedded.svg" alt="img"></p>
<p>按照数据库的类比，嵌入式 Functions 有点像存储程序，但方式更有原则。这里的函数是实现标准接口的普通 Java/Scala/Kotlin 函数，可以在任何 IDE 中开发/测试。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Koalas 和 Apache Spark 之间的互操作性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-10-04-interoperability-between-koalas-and-apache-spark/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-10-04-interoperability-between-koalas-and-apache-spark/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-10-04T00:00:00+08:00</published>
            <updated>2020-10-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>How PySpark users effectively work with Koalas</blockquote><p>Koalas 是一个开源项目，它为 pandas 提供了一个 drop-in 的替代品，可以高效地扩展到数百个工人节点，用于日常的数据科学和机器学习。自去年首次推出以来，<a href="https://databricks.com/session/official-announcement-of-koalas-open-source-project">经过一年多的开发</a>，<a href="https://databricks.com/blog/2020/06/24/introducing-koalas-1-0.html">Koalas 1.0 已经发布</a>。</p>
<p>pandas 是数据科学家中常用的 Python 包，但它并不能扩展到大数据。当他们的数据变得庞大时，他们必须从一开始就选择和学习另一个系统，如 Apache Spark，以采用和转换他们现有的工作负载。 Koalas 通过提供 pandas 等效的 API 来填补这个空白，这些 API 可以在 Apache Spark 上工作。其中很多在之前的<a href="https://databricks.com/blog/2020/03/31/10-minutes-from-pandas-to-koalas-on-apache-spark.html">博文</a>中已经介绍过，其中还包括使用 Koalas 时的最佳实践。</p>
<p>Koalas 不仅对 pandas 用户有用，对 PySpark 用户也很有用，因为 Koalas 支持很多 PySpark 难以实现的功能。例如，Spark 用户可以通过 <a href="https://koalas.readthedocs.io/en/latest/reference/frame.html#plotting">Koalas 绘图 API</a> 直接从 PySpark DataFrame 中绘制数据，类似于 pandas。PySpark DataFrame 更符合 SQL 标准，而 Koalas DataFrame 更接近 Python 本身，这为在某些情况下使用 Python 提供了更直观的工作方式。在 <a href="https://koalas.readthedocs.io/en/latest/">Koalas 文档</a>中，有各种 pandas 对应的 API 实现。</p>
<p>在这篇博文中，我们重点介绍 PySpark 用户如何利用自己的知识和 PySpark 与 Koalas 之间的原生交互，更快地编写代码。我们包含了许多自带的例子，如果你<a href="https://koalas.readthedocs.io/en/latest/getting_started/install.html">安装了带 Koalas</a> 的 Spark，或者你正在使用 Databricks Runtime，你可以运行这些例子。从 Databricks Runtime 7.1 开始，Koalas 就被打包在一起，所以您无需手动安装就可以运行。</p>
<h2 id="koalas-和-pyspark-dataframes">Koalas 和 PySpark DataFrames</h2>
<p>在深究之前，我们先来看看 Koalas 和 PySpark DataFrames 的一般区别。</p>
<p>从外观上看，它们是不同的。Koalas DataFrames 无缝地沿用了 pandas DataFrames 的结构，并在底层下实现了一个索引/标识符。而 PySpark DataFrame 则更趋向于符合关系型数据库中的关系/表，并且没有唯一的行标识符。</p>
<p>在内部，Koalas DataFrames 是建立在 PySpark DataFrames 上的。Koalas 将 pandas APIs 翻译成 Spark SQL 的逻辑计划。该计划由复杂而强大的 Spark SQL 引擎优化和执行，Spark 社区不断对其进行改进。Koalas 还沿用 Spark 的懒惰评估语义，以实现性能的最大化。为了实现 pandas DataFrame 结构和 pandas 丰富的 API，需要隐式排序，Koalas DataFrames 的内部元数据表示 pandas 等价的索引和列标签映射到 PySpark DataFrame 中的列。</p>
<p>即使 Koalas 利用 PySpark 作为执行引擎，但与 PySpark 相比，你仍然可能面临轻微的性能下降。正如在 <a href="https://databricks.com/blog/2019/08/22/guest-blog-how-virgin-hyperloop-one-reduced-processing-time-from-hours-to-minutes-with-koalas.html">Virgin Hyperloop One 的迁移经验</a>中所讨论的，主要原因通常是:</p>
<ul>
<li>使用了默认索引。构建默认索引的开销取决于数据大小、集群组成等。因此，总是希望避免使用默认索引。关于这一点将在下面的其他章节中详细讨论。</li>
<li>PySpark 和 pandas 中的一些 API 名称相同，但语义不同。例如，Koalas DataFrame 和 PySpark DataFrame 都有 count API。前者统计每列/行的非 NA/null 条目数，后者统计检索到的行数，包括包含 null 的行。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]})</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">a</span>    <span class="mi">3</span>
<span class="n">b</span>    <span class="mi">3</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
<span class="o">...</span>     <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">schema</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;a&#34;</span><span class="p">,</span> <span class="s2">&#34;b&#34;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">3</span>
</code></pre></div><h2 id="从-pyspark-dataframes-转换到-pyspark-dataframes">从 PySpark DataFrames 转换到 PySpark DataFrames</h2>
<p>对于一个 PySpark 用户来说，很高兴知道你可以很容易地在 Koalas DataFrame 和 PySpark DataFrame 之间来回切换，以及在底层发生了什么，这样你就不需要害怕进入 Koalas 世界，在 Spark 上应用高扩展性的 pandas API。</p>
<ul>
<li>to_koalas()</li>
</ul>
<p>当导入 Koalas 包时，它会自动将 to_koalas()方法附加到 PySpark DataFrames 中。你可以简单地使用这个方法将 PySpark DataFrames 转换为 Koalas DataFrames。</p>
<p>假设你有一个 PySpark DataFrame。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">)],</span><span class="n">schema</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">+---+----+---+</span>
<span class="o">|</span>  <span class="n">x</span><span class="o">|</span>   <span class="n">y</span><span class="o">|</span>  <span class="n">z</span><span class="o">|</span>
<span class="o">+---+----+---+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span><span class="mf">10.0</span><span class="o">|</span>  <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span><span class="mf">20.0</span><span class="o">|</span>  <span class="n">b</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span><span class="mf">30.0</span><span class="o">|</span>  <span class="n">c</span><span class="o">|</span>
<span class="o">+---+----+---+</span> 
</code></pre></div><p>首先，导入 Koalas 包。传统上使用 ks 作为包的别名。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">databricks.koalas</span> <span class="kn">as</span> <span class="nn">ks</span>
</code></pre></div><p>如上所述，用 to_koalas()方法将 Spark DataFrame 转换为 Koalas DataFrame。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span> <span class="o">=</span> <span class="n">sdf</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span>
    <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="mi">0</span>  <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">1</span>  <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">2</span>  <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>   
</code></pre></div><p>kdf 是一个由 PySpark DataFrame 创建的 Koalas DataFrame。当真正需要数据时，计算会被懒惰地执行，例如显示或存储计算的数据，与 PySpark 相同。</p>
<ul>
<li>to_spark()</li>
</ul>
<p>接下来，你还应该知道如何从 Koalas 回到 PySpark DataFrame。你可以在 Koalas DataFrame 上使用 to_spark()方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">sdf_from_kdf</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf_from_kdf</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">+---+----+---+</span>
<span class="o">|</span>  <span class="n">x</span><span class="o">|</span>   <span class="n">y</span><span class="o">|</span>  <span class="n">z</span><span class="o">|</span>
<span class="o">+---+----+---+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span><span class="mf">10.0</span><span class="o">|</span>  <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span><span class="mf">20.0</span><span class="o">|</span>  <span class="n">b</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span><span class="mf">30.0</span><span class="o">|</span>  <span class="n">c</span><span class="o">|</span>
<span class="o">+---+----+---+</span>   
</code></pre></div><p>现在你又有了一个 PySpark DataFrame。请注意，现在已经没有 Koalas DataFrame 中包含的索引列了。下面将讨论处理索引的最佳实践。</p>
<h3 id="索引和-index_col">索引和 index_col</h3>
<p>如上图所示，Koalas 内部管理了几列作为 &ldquo;索引 &ldquo;列，以表示 pandas 的索引。这些 &ldquo;索引 &ldquo;列用于通过 loc/iloc 索引器访问行，或者用于 sort_index()方法中，而不指定排序键列，甚至用于结合两个以上 DataFrame 或 Series 的操作时匹配相应的行，例如 df1+df2，等等。</p>
<p>如果 PySpark DataFrame 中已经有这样的列，可以使用 index_col 参数来指定索引列。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_with_index_col</span> <span class="o">=</span> <span class="n">sdf</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>  <span class="c1"># or index_col=[&#39;x&#39;]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_with_index_col</span>
        <span class="n">y</span>  <span class="n">z</span>
<span class="n">x</span>
<span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>    
</code></pre></div><p>这时，列 x 不被视为常规列之一，而是索引。</p>
<p>如果你有多个列作为索引，你可以传递列名列表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
    <span class="n">z</span>
<span class="n">x</span> <span class="n">y</span>
<span class="mi">1</span> <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">2</span> <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">3</span> <span class="mf">30.0</span>  <span class="n">c</span>
</code></pre></div><p>当回到 PySpark DataFrame 时，你还可以使用 index_col 参数来保存索引列。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_with_index_col</span><span class="o">.</span><span class="n">to_spark</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># or index_col=[&#39;index&#39;]</span>
<span class="o">+-----+----+---+</span>
<span class="o">|</span><span class="n">index</span><span class="o">|</span>   <span class="n">y</span><span class="o">|</span>  <span class="n">z</span><span class="o">|</span>
<span class="o">+-----+----+---+</span>
<span class="o">|</span>    <span class="mi">1</span><span class="o">|</span><span class="mf">10.0</span><span class="o">|</span>  <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">2</span><span class="o">|</span><span class="mf">20.0</span><span class="o">|</span>  <span class="n">b</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">3</span><span class="o">|</span><span class="mf">30.0</span><span class="o">|</span>  <span class="n">c</span><span class="o">|</span>
<span class="o">+-----+----+---+</span>
</code></pre></div><p>否则，就会失去指数，如下图。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_with_index_col</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">+----+---+</span>
<span class="o">|</span>   <span class="n">y</span><span class="o">|</span>  <span class="n">z</span><span class="o">|</span>
<span class="o">+----+---+</span>
<span class="o">|</span><span class="mf">10.0</span><span class="o">|</span>  <span class="n">a</span><span class="o">|</span>
<span class="o">|</span><span class="mf">20.0</span><span class="o">|</span>  <span class="n">b</span><span class="o">|</span>
<span class="o">|</span><span class="mf">30.0</span><span class="o">|</span>  <span class="n">c</span><span class="o">|</span>
<span class="o">+----+---+</span>
</code></pre></div><p>列名的数量应与索引列的数量一致。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_spark</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;index1&#39;</span><span class="p">,</span> <span class="s1">&#39;index2&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
<span class="o">...</span>
<span class="ne">ValueError</span><span class="p">:</span> <span class="n">length</span> <span class="n">of</span> <span class="n">index</span> <span class="n">columns</span> <span class="ow">is</span> <span class="mi">1</span><span class="p">;</span> <span class="n">however</span><span class="p">,</span> <span class="n">the</span> <span class="n">length</span> <span class="n">of</span> <span class="n">the</span> <span class="n">given</span> <span class="s1">&#39;index_col&#39;</span> <span class="ow">is</span> <span class="mf">2.</span>  
</code></pre></div><h3 id="默认索引">默认索引</h3>
<p>正如你所看到的，如果你不指定 index_col 参数，就会创建一个新的列作为索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">()</span>
    <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
 <span class="mi">0</span>  <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
 <span class="mi">1</span>  <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
 <span class="mi">2</span>  <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span> 
</code></pre></div><p>列从哪里来？</p>
<p>答案是 &ldquo;默认索引&rdquo;。如果没有指定 index_col 参数，Koalas 会自动将一列作为索引附加到 DataFrame 中。有三种类型的默认索引。&ldquo;sequence&rdquo;、&ldquo;distributed-sequence &ldquo;和 &ldquo;distributed&rdquo;。每种类型都有其独特的特点和局限性，比如性能惩罚。为了减少性能开销，强烈建议在从 PySpark DataFrame 转换时通过 index_col 指定索引列。</p>
<p>当 Koalas 不知道哪一列是用来做索引时，也会使用默认索引。例如，reset_index()没有任何参数，它试图将所有的索引数据转换为常规列，并重新创建一个索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_with_index_col</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
 <span class="mi">0</span>  <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
 <span class="mi">1</span>  <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
 <span class="mi">2</span>  <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>
</code></pre></div><p>你可以通过设置 Koalas 选项 &ldquo;compute.default_index_type&rdquo; 来改变默认的索引类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">ks</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">)</span>
</code></pre></div><p>或</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">ks</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">compute</span><span class="o">.</span><span class="n">default_index_type</span> <span class="o">=</span> <span class="s1">&#39;sequence&#39;</span>
</code></pre></div><p>顺序型
目前 Koalas 中默认使用 &ldquo;序列 &ldquo;类型，因为它像 pandas 一样保证了索引的连续递增。但是，它内部使用了一个非分区窗口函数，这意味着所有的数据都需要收集到一个节点中。如果节点的内存不足，性能会明显下降，或者出现 OutOfMemoryError。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">()</span>
    <span class="nb">id</span>
<span class="mi">0</span>   <span class="mi">0</span>
<span class="mi">1</span>   <span class="mi">1</span>
<span class="mi">2</span>   <span class="mi">2</span>
<span class="mi">3</span>   <span class="mi">3</span>
<span class="mi">4</span>   <span class="mi">4</span>
</code></pre></div><p>分散式
当使用 &ldquo;分布式-序列 &ldquo;索引时，性能惩罚没有 &ldquo;序列 &ldquo;类型那么显著。它以分布式的方式计算和生成索引，但它需要另一个额外的 Spark Job 来内部生成全局序列。它也不能保证结果的自然顺序。一般来说，它会变成一个不断增加的数字。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed-sequence&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">()</span>
    <span class="nb">id</span>
<span class="mi">3</span>   <span class="mi">3</span>
<span class="mi">1</span>   <span class="mi">1</span>
<span class="mi">2</span>   <span class="mi">2</span>
<span class="mi">4</span>   <span class="mi">4</span>
<span class="mi">0</span>   <span class="mi">0</span>
</code></pre></div><p>分散型
&ldquo;分布式 &ldquo;索引几乎没有性能上的惩罚，而且总是创建单调增加的数字。如果索引只是需要作为每行的唯一数字，或行的顺序，这种索引类型将是最佳选择。但是，这些数字有一个不确定的间隙。这意味着这种索引类型不太可能被用作结合两个以上 DataFrames 或 Series 的操作的索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to_koalas</span><span class="p">()</span>
                <span class="nb">id</span>
<span class="mi">17179869184</span>   <span class="mi">0</span>
<span class="mi">34359738368</span>   <span class="mi">1</span>
<span class="mi">60129542144</span>   <span class="mi">2</span>
<span class="mi">77309411328</span>   <span class="mi">3</span>
<span class="mi">94489280512</span>   <span class="mi">4</span>
</code></pre></div><p>比较
正如你所看到的，每种索引类型都有其独特的特征，如下表所示。考虑到你的工作负载，应该谨慎选择默认的索引类型。</p>
<table>
<thead>
<tr>
<th style="text-align:left">分布式计算</th>
<th style="text-align:left">Map 端操作</th>
<th style="text-align:left">连续递增</th>
<th style="text-align:left">性能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">sequence</td>
<td style="text-align:left">No, 在单个 worker 节点中</td>
<td style="text-align:left">No, 需要 shuffle</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">distributed-sequence</td>
<td style="text-align:left">Yes</td>
<td style="text-align:left">Yes, 但需要另一个 Spark job</td>
<td style="text-align:left">Yes, 在大多数情况下</td>
</tr>
<tr>
<td style="text-align:left">distributed</td>
<td style="text-align:left">Yes</td>
<td style="text-align:left">Yes</td>
<td style="text-align:left">No</td>
</tr>
</tbody>
</table>
<p>参见 <a href="https://koalas.readthedocs.io/en/latest/user_guide/options.html#default-index-type">Koalas 文档中的默认索引类型</a>。</p>
<h2 id="使用-spark-io">使用 Spark I/O</h2>
<p>在 pandas 中，有很多函数可以读写数据，在 Koalas 中也是如此。</p>
<p>下面是 pandas 中的函数列表，Koalas 在下面使用了 Spark I/O。</p>
<ul>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_csv.html">DataFrame.to_csv</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_csv.html">ks.read_csv</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_json.html">DataFrame.to_json</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_json.html">ks.read_json</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_parquet.html">DataFrame.to_parquet</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_parquet.html">ks.read_parquet</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_sql_table.html">ks.read_sql_table</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_sql_query.html">ks.read_sql_query</a></li>
</ul>
<p>API 和它们的参数沿用了 pandas 对应的 API。不过，目前在行为上有细微的差别。例如，pandas 的 read_csv 可以通过 http 协议读取文件，但 Koalas 仍然不支持，因为底层的 Spark 引擎本身并不支持。</p>
<p>这些 Koalas 函数还有 index_col 参数，用来指定哪些列应该被用作索引，或者索引列名应该是什么，类似于上面介绍的 to_koalas()或 to_spark()函数。如果你不指定，就会附加默认的索引，或者索引列丢失。</p>
<p>例如，如果你不指定 index_col 参数，默认索引就会被附加，如下图所示&ndash;为了简单起见，使用了分布式默认索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;/path/to/test.csv&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_csv</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/path/to/test.csv&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_csv</span>
                <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="mi">0</span>            <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">8589934592</span>   <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>
<span class="mi">17179869184</span>  <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
</code></pre></div><p>而如果指定 index_col 参数，指定的列就会变成一个索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;/path/to/test.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_csv_with_index_col</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;/path/to/test.csv&#34;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_csv_with_index_col</span>
        <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="n">index</span>
<span class="mi">2</span>      <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>
<span class="mi">1</span>      <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
</code></pre></div><p>此外，每个函数都需要关键字参数来设置 Spark 中 DataFrameWriter 和 DataFrameReader 的选项。给定的键直接传递给它们的选项并配置行为。当 pandas-origin 参数不足以操作你的数据，但 PySpark 支持缺失的功能时，这很有用。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="c1"># nullValue is the option specific to Spark’s CSV I/O.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/path/to/test.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">nullValue</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">x</span>     <span class="n">y</span>     <span class="n">z</span>
<span class="n">index</span>
<span class="mi">2</span>      <span class="mi">3</span>  <span class="mf">30.0</span>     <span class="n">c</span>
<span class="mi">1</span>      <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="bp">None</span>
<span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">10.0</span>     <span class="n">a</span>
</code></pre></div><h3 id="koalas-特定的-io-功能">Koalas 特定的 I/O 功能</h3>
<p>除了以上来自 pandas 的功能外，Koalas 还有自己的功能。</p>
<ul>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_table.html">DataFrame.to_table</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_table.html">ks.read_table</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_spark_io.html">DataFrame.to_spark_io</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_spark_io.html">ks.read_spark_io</a></li>
<li><a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.to_delta.html">DataFrame.to_delta</a> / <a href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.read_delta.html">ks.read_delta</a></li>
</ul>
<p>首先，DataFrame.to_table 和 ks.read_table 是只需指定表名就可以写入和读取 Spark 表。这分别类似于 Spark 中的 DataFrameWriter.saveAsTable 和 DataFrameReader.table。</p>
<p>其次，DataFrame.to_spark_io 和 ks.read_spark_io 是用于一般的 Spark I/O。为了方便使用，有几个可选的参数，其他都是关键字参数。你可以自由设置 Spark 中 DataFrameWriter.save 和 DataFrameReader.load 使用的选项。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="c1"># &#39;compression&#39; is a Spark specific option.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_spark_io</span><span class="p">(</span><span class="s1">&#39;/path/to/test.orc&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s1">&#39;orc&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s2">&#34;snappy&#34;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_spark_io</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_spark_io</span><span class="p">(</span><span class="s1">&#39;/path/to/test.orc&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s1">&#39;orc&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_spark_io</span>
        <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="n">index</span>
<span class="mi">1</span>      <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">2</span>      <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>
</code></pre></div><p>上例中的 ORC 格式在 pandas 中是不支持的，但 Koalas 可以写和读，因为底层的 Spark I/O 支持它。</p>
<p>最后，如果你<a href="https://docs.delta.io/latest/quick-start.html#set-up-apache-spark-with-delta-lake">安装</a>了 Delta Lake，Koalas 也可以写和读 Delta 表。</p>
<p><a href="https://docs.delta.io/latest/delta-intro.html">Delta Lake</a> 是一个开源的存储层，为数据湖带来了可靠性。Delta Lake 提供了 ACID 事务、可扩展的元数据处理，并统一了流式和批处理数据。</p>
<p>与其他文件源不同的是，read_delta 函数可以让用户指定表的版本来进行时间旅行。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_delta</span><span class="p">(</span><span class="s1">&#39;/path/to/test.delta&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_delta</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_delta</span><span class="p">(</span><span class="s1">&#39;/path/to/test.delta&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf_read_delta</span>
        <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="n">index</span>
<span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">1</span>      <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">2</span>      <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Update the data and overwrite the Delta table</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">to_delta</span><span class="p">(</span><span class="s1">&#39;/path/to/test.delta&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Read the latest data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_delta</span><span class="p">(</span><span class="s1">&#39;/path/to/test.delta&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
        <span class="n">x</span>      <span class="n">y</span>  <span class="n">z</span>
<span class="n">index</span>
<span class="mi">0</span>      <span class="mi">22</span>  <span class="mf">100.0</span>  <span class="n">a</span>
<span class="mi">1</span>      <span class="mi">24</span>  <span class="mf">200.0</span>  <span class="n">b</span>
<span class="mi">2</span>      <span class="mi">26</span>  <span class="mf">300.0</span>  <span class="n">c</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Read the data of version 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ks</span><span class="o">.</span><span class="n">read_delta</span><span class="p">(</span><span class="s1">&#39;/path/to/test.delta&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
        <span class="n">x</span>     <span class="n">y</span>  <span class="n">z</span>
<span class="n">index</span>
<span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">10.0</span>  <span class="n">a</span>
<span class="mi">1</span>      <span class="mi">2</span>  <span class="mf">20.0</span>  <span class="n">b</span>
<span class="mi">2</span>      <span class="mi">3</span>  <span class="mf">30.0</span>  <span class="n">c</span>
</code></pre></div><p>详情请看 <a href="https://delta.io/">Delta Lake</a>。</p>
<h3 id="spark-accessor">Spark accessor</h3>
<p>Koalas 为用户提供了 spark 接入器，让用户更容易地利用现有的 PySpark API。</p>
<h4 id="seriessparktransform-和-seriessparkapply">Series.spark.transform 和 Series.spark.apply</h4>
<p>Series.spark accessor 有变换和应用函数来处理底层的 Spark Column 对象。</p>
<p>例如，假设你有以下 Koalas DataFrame。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span>
    <span class="n">a</span>
<span class="mi">0</span>  <span class="mi">1</span>
<span class="mi">1</span>  <span class="mi">2</span>
<span class="mi">2</span>  <span class="mi">3</span>
<span class="mi">3</span>  <span class="mi">4</span>
</code></pre></div><p>你可以使用 astype 函数来铸造类型，但如果你还不习惯，你可以使用 Series.spark.transform 函数来铸造 Spark 列。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">DoubleType</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;a_astype_double&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;a_cast_double&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">scol</span><span class="p">:</span> <span class="n">scol</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DoubleType</span><span class="p">()))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;a_astype_double&#39;</span><span class="p">,</span> <span class="s1">&#39;a_cast_double&#39;</span><span class="p">]]</span>
    <span class="n">a</span>  <span class="n">a_astype_double</span>  <span class="n">a_cast_double</span>
<span class="mi">0</span>  <span class="mi">1</span>              <span class="mf">1.0</span>            <span class="mf">1.0</span>
<span class="mi">1</span>  <span class="mi">2</span>              <span class="mf">2.0</span>            <span class="mf">2.0</span>
<span class="mi">2</span>  <span class="mi">3</span>              <span class="mf">3.0</span>            <span class="mf">3.0</span>
<span class="mi">3</span>  <span class="mi">4</span>              <span class="mf">4.0</span>            <span class="mf">4.0</span>
</code></pre></div><p>传递给 Series.spark.transform 函数的用户函数取用 Spark 的 Column 对象，可以使用 PySpark 函数对其进行操作。</p>
<p>也可以在 transform/apply 函数中使用 pyspark.sql.function 的函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;a_sqrt&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">scol</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scol</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[</span><span class="s1">&#39;a_log&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">scol</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scol</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;a_sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;a_log&#39;</span><span class="p">]]</span>
    <span class="n">a</span>    <span class="n">a_sqrt</span>     <span class="n">a_log</span>
<span class="mi">0</span>  <span class="mi">1</span>  <span class="mf">1.000000</span>  <span class="mf">0.000000</span>
<span class="mi">1</span>  <span class="mi">2</span>  <span class="mf">1.414214</span>  <span class="mf">0.693147</span>
<span class="mi">2</span>  <span class="mi">3</span>  <span class="mf">1.732051</span>  <span class="mf">1.098612</span>
<span class="mi">3</span>  <span class="mi">4</span>  <span class="mf">2.000000</span>  <span class="mf">1.386294</span>
</code></pre></div><p>Series.spark.transform 的用户函数应该返回与其输入相同长度的 Spark 列，而 Series.spark.apply 的用户函数可以返回不同长度的 Spark 列，比如调用聚合函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">scol</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="n">scol</span><span class="p">))</span>
<span class="mi">0</span>    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</code></pre></div><h4 id="dataframesparkapply">DataFrame.spark.apply</h4>
<p>同样，DataFrame.spark accessor 也有一个 apply 函数。用户函数接受并返回一个 Spark DataFrame，并可以应用任何转换。如果你想在 Spark DataFrame 中保留索引列，你可以设置 index_col 参数。在这种情况下，用户函数必须在返回的 Spark DataFrame 中包含一个同名的列。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">sdf</span><span class="p">:</span> <span class="n">sdf</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&#34;index * 10 as index&#34;</span><span class="p">,</span> <span class="s2">&#34;a + 1 as a&#34;</span><span class="p">),</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&#34;index&#34;</span><span class="p">)</span>
    <span class="n">a</span>
<span class="n">index</span>
<span class="mi">0</span>      <span class="mi">2</span>
<span class="mi">10</span>     <span class="mi">3</span>
<span class="mi">20</span>     <span class="mi">4</span>
<span class="mi">30</span>     <span class="mi">5</span>
</code></pre></div><p>如果你省略 index_col，它将使用默认的索引。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">sdf</span><span class="p">:</span> <span class="n">sdf</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&#34;a + 1 as a&#34;</span><span class="p">))</span>
    <span class="n">a</span>
<span class="mi">17179869184</span>  <span class="mi">2</span>
<span class="mi">42949672960</span>  <span class="mi">3</span>
<span class="mi">68719476736</span>  <span class="mi">4</span>
<span class="mi">94489280512</span>  <span class="mi">5</span>
</code></pre></div><h4 id="spark-schema">Spark schema</h4>
<p>你可以通过 DataFrame.spark.schema 和 DataFrame.spark.print_schema 查看当前的底层 Spark 模式。如果你想知道包括索引列在内的模式，它们都需要 index_col 参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;abc&#39;</span><span class="p">),</span>
<span class="o">...</span>                     <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
<span class="o">...</span>                     <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;i1&#39;</span><span class="p">),</span>
<span class="o">...</span>                     <span class="s1">&#39;d&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">),</span>
<span class="o">...</span>                     <span class="s1">&#39;e&#39;</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">],</span>
<span class="o">...</span>                     <span class="s1">&#39;f&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s1">&#39;20130101&#39;</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="mi">3</span><span class="p">)},</span>
<span class="o">...</span>                    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Print the schema out in Spark’s DDL formatted string</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span><span class="o">.</span><span class="n">simpleString</span><span class="p">()</span>
<span class="s1">&#39;struct&lt;a:string,b:bigint,c:tinyint,d:double,e:boolean,f:timestamp&gt;&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">simpleString</span><span class="p">()</span>
<span class="s1">&#39;struct&lt;index:bigint,a:string,b:bigint,c:tinyint,d:double,e:boolean,f:timestamp&gt;&#39;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Print out the schema as same as Spark’s DataFrame.printSchema()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">print_schema</span><span class="p">()</span>
<span class="n">root</span>
    <span class="o">|--</span> <span class="n">a</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">b</span><span class="p">:</span> <span class="nb">long</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">c</span><span class="p">:</span> <span class="n">byte</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">d</span><span class="p">:</span> <span class="n">double</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">e</span><span class="p">:</span> <span class="n">boolean</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">f</span><span class="p">:</span> <span class="n">timestamp</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">print_schema</span><span class="p">(</span><span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="n">root</span>
    <span class="o">|--</span> <span class="n">index</span><span class="p">:</span> <span class="nb">long</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">a</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">b</span><span class="p">:</span> <span class="nb">long</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">c</span><span class="p">:</span> <span class="n">byte</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">d</span><span class="p">:</span> <span class="n">double</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">e</span><span class="p">:</span> <span class="n">boolean</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
    <span class="o">|--</span> <span class="n">f</span><span class="p">:</span> <span class="n">timestamp</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">false</span><span class="p">)</span>
</code></pre></div><h4 id="解释-spark-计划">解释 Spark 计划</h4>
<p>如果你想知道当前的 Spark 计划，你可以使用 DataFrame.spark.explain()。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Same as Spark’s DataFrame.explain()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="n">Scan</span> <span class="n">ExistingRDD</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="o">==</span> <span class="n">Parsed</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Analyzed</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Optimized</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="n">Scan</span> <span class="n">ExistingRDD</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># New style of mode introduced from Spark 3.0.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;extended&#34;</span><span class="p">)</span>
<span class="o">==</span> <span class="n">Parsed</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Analyzed</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Optimized</span> <span class="n">Logical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>

<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="n">Scan</span> <span class="n">ExistingRDD</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
</code></pre></div><h4 id="缓存">缓存</h4>
<p>spark 访问器还提供了缓存相关的函数，cache、persist、unpersist 和 store_level 属性。你可以使用 cache 函数作为上下文管理器来解除缓存的 persist。让我们看一个例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">StorageLevel</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span> <span class="k">as</span> <span class="n">cached</span><span class="p">:</span>
<span class="o">...</span>   <span class="k">print</span><span class="p">(</span><span class="n">cached</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">storage_level</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">Disk</span> <span class="n">Memory</span> <span class="n">Deserialized</span> <span class="mi">1</span><span class="n">x</span> <span class="n">Replicated</span>

<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">StorageLevel</span><span class="o">.</span><span class="n">MEMORY_ONLY</span><span class="p">)</span> <span class="k">as</span> <span class="n">cached</span><span class="p">:</span>
<span class="o">...</span>   <span class="k">print</span><span class="p">(</span><span class="n">cached</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">storage_level</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">Memory</span> <span class="n">Serialized</span> <span class="mi">1</span><span class="n">x</span> <span class="n">Replicated</span>
</code></pre></div><p>当上下文完成后，缓存会自动清除。如果你想保留它的缓存，你可以按照下面的方法来做。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">cached</span> <span class="o">=</span> <span class="n">kdf</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">cached</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">storage_level</span><span class="p">)</span>
<span class="n">Disk</span> <span class="n">Memory</span> <span class="n">Deserialized</span> <span class="mi">1</span><span class="n">x</span> <span class="n">Replicated</span>
</code></pre></div><p>当不再需要它时，你必须显式调用 DataFrame.spark.unpersist()来从缓存中删除它。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">cached</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</code></pre></div><h4 id="提示">提示</h4>
<p>在 Koalas 中，有一些类似于 join 的操作，比如合并、加入和更新。虽然实际的 join 方法取决于底层的 Spark 计划器，但你仍然可以用 ks.broadcast()函数或 DataFrame.spark.hint()方法指定一个提示。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">kdf1</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;key&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="s1">&#39;baz&#39;</span><span class="p">,</span> <span class="s1">&#39;foo&#39;</span><span class="p">],</span>
<span class="o">...</span>                      <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]},</span>
<span class="o">...</span>                     <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;key&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf2</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;key&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="s1">&#39;baz&#39;</span><span class="p">,</span> <span class="s1">&#39;foo&#39;</span><span class="p">],</span>
<span class="o">...</span>                      <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]},</span>
<span class="o">...</span>                     <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;key&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">kdf2</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;key&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>
<span class="o">...</span> <span class="n">SortMergeJoin</span> <span class="o">...</span>
<span class="o">...</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">ks</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">kdf2</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;key&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>
<span class="o">...</span> <span class="n">BroadcastHashJoin</span> <span class="o">...</span>
<span class="o">...</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">kdf1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">kdf2</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">hint</span><span class="p">(</span><span class="s1">&#39;broadcast&#39;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;key&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
<span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>
<span class="o">...</span>
<span class="o">...</span> <span class="n">BroadcastHashJoin</span> <span class="o">...</span>
<span class="o">...</span>
</code></pre></div><p>特别是，如果底层 Spark 是 3.0 或以上版本，DataFrame.spark.hint()更有用，因为 Spark 3.0 中提供了更多的提示。</p>
<h2 id="结束语">结束语</h2>
<p>Koalas DataFrame 与 PySpark DataFrame 相似，因为 Koalas 内部使用 PySpark DataFrame。在外部，Koalas DataFrame 的工作方式就像 pandas DataFrame 一样。</p>
<p>为了填补这个空白，Koalas 有许多功能，对于熟悉 PySpark 的用户来说，可以轻松地使用 Koalas 和 PySpark DataFrame。虽然在转换过程中需要额外的注意处理索引，但 Koalas 为 PySpark 用户提供了两种 DataFrame 之间的简单转换，为 PySpark 提供了读/写的输入/输出 API，并提供了 spark 访问器以暴露 PySpark 友好的功能，如缓存和内部探索 DataFrame。此外，spark 访问器还提供了一种自然的方式来玩弄 Koalas 系列和 PySpark 列。</p>
<p>PySpark 用户可以从 Koalas 中获益，如上图所示。请在 Databricks Runtime 中试用这些示例并了解更多信息。</p>
<h2 id="阅读更多">阅读更多</h2>
<p>要了解更多关于 Koalas 的信息，请看以下资源。</p>
<ul>
<li>试试附带的<a href="https://databricks.com/notebooks/interoperability-koalas-apache-spark.html">笔记本</a></li>
<li>在 Apache Spark 上阅读之前的博客《<a href="https://databricks.com/blog/2020/03/31/10-minutes-from-pandas-to-koalas-on-apache-spark.html">从 pandas 到 Koalas 的 10 分钟</a>》。</li>
<li>Spark+AI 峰会 2020 演讲 &ldquo;<a href="https://databricks.com/session_na20/koalas-pandas-on-apache-spark">Koalas: Pandas on Apache Spark</a>&rdquo;</li>
<li>Spark+AI 峰会 2020 演讲 &ldquo;<a href="https://databricks.com/session_na20/koalas-making-an-easy-transition-from-pandas-to-apache-spark">Koalas: 从 Pandas 轻松过渡到 Apache Spark</a>&rdquo;</li>
</ul>
<p>原文链接: <a href="https://databricks.com/blog/2020/08/11/interoperability-between-koalas-and-apache-spark.html">https://databricks.com/blog/2020/08/11/interoperability-between-koalas-and-apache-spark.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/pyspark" term="pyspark" label="PySpark" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/pyspark" term="pyspark" label="PySpark" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/koalas" term="koalas" label="Koalas" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[贪婪 Junction 的奇闻异事]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-10-04-the-strange-case-of-the-greedy-junction/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-10-04-reconstructing-raku-junctions/?utm_source=atom_feed" rel="related" type="text/html" title="重构 Raku 的 Junction" />
            
                <id>https://ohmyweekly.github.io/notes/2020-10-04-the-strange-case-of-the-greedy-junction/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-10-04T00:00:00+08:00</published>
            <updated>2020-10-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>The Strange Case of the Greedy Junction</blockquote><h2 id="贪婪-junction-的奇闻异事">贪婪 junction 的奇闻异事</h2>
<p>说明 Raku 的 junction 是如何贪婪的设计，以及一个建议。</p>
<p><a href="https://raku.org/">Raku</a> 有一个整洁的功能，叫做 <a href="https://docs.raku.org/type/Junction">Junction</a>。在这篇短文中，我想强调一下 junction 与函数交互的一个特殊后果：它们是贪婪的，我的意思是它们会无意中把函数的其他参数变成 junction。为了说明这种行为，我将使用一个闭包创建一个 <code>pair</code> 数据结构，它可以接受两个不同类型的值。</p>
<pre><code class="language-raku" data-lang="raku">enum RGB &lt;R G B&gt;;

# Pair Constructor: the arguments of pair() are captured
# in a closure that is returned
sub pair(\x, \y) {
    sub (&amp;p){ p(x, y) } 
}
</code></pre><p>所以 <code>pair</code> 接受两个任意类型的参数，并返回一个以函数为参数的闭包。我们将使用这个函数来访问存储在 <code>pair</code> 中的值。我将把这些访问(accessor)函数称为 <code>fst</code> 和 <code>snd</code>。</p>
<pre><code class="language-raku" data-lang="raku"># Accessors to get the values from the closure
my sub fst (&amp;p) {p( sub (\x,\y){x})}
my sub snd (&amp;p) {p( sub (\x,\y){y})}
</code></pre><p>做实际选择的函数是由 <code>fst</code> 和 <code>snd</code> 返回的匿名子程序，这纯粹是为了让我可以将它们应用于 <code>pair</code>，而不是必须将它们作为参数传递。让我们看一个例子，一个 <code>Int</code> 和一个 <code>RGB</code> 的 pair。</p>
<pre><code class="language-raku" data-lang="raku">my \p1 = pair 42, R;

if ( 42 == fst p1) {
    say snd p1;	#=&gt; says &quot;R&quot;
}
</code></pre><p>所以我们用两个值调用 <code>pair</code> 来创建一个 pair，并使用 <code>fst</code> 和 <code>snd</code> 来访问 pair 中的值。这是一个不可变的数据结构，所以不可能进行更新。</p>
<p>现在让我们使用 junction 作为其中一个参数。</p>
<pre><code class="language-raku" data-lang="raku"># Example instance with a 'one'-type junction
my Junction \p1j = pair (42^43),R;

if ( 42 == fst p1j) {
    say snd p1j; #=&gt; one(R, R)
}
</code></pre><p>这里发生的情况是，原始参数 <code>R</code> 已经不可逆转地变成了与自己的 junction，尽管我们从未明确地在 <code>R</code> 上创建过 junction，但还是发生了这种情况。这是将 junction 类型应用于函数的结果，它不是一个 bug，只是 junction 行为的一个影响。更详细的解释，请看我的文章&quot;<a href="https://gist.github.com/wimvanderbauwhede/19cc1e8d04e9a477f58cfe7288a6172e">重构 Raku 的 Junction</a>&quot;。</p>
<p><a href="https://docs.raku.org/type/Junction">Raku 关于 junction 的文档</a>中说，你不应该真正尝试从 junction 中获取值。</p>
<p>&ldquo;Junction 是用来作为布尔上下文中的匹配器，不支持 junction 的自省。如果你觉得有自省 junction 的冲动，请使用 Set 或相关类型代替。&rdquo;</p>
<p>然而，有一个 FAQ <a href="https://docs.raku.org/language/faq#index-entry-Junction_(FAQ)">勉强地告诉你如何做</a>。FAQ 再次警告不要这样做。</p>
<p>&ldquo;如果你想从 junction 中提取值（特征态），你可能做错了什么，应该用 Set 来代替。&rdquo;</p>
<p>然而，正如我所举的例子所证明的那样，从 junction 中恢复值是有明确的用例的。当然，仅仅因为另一个值恰好是 junction，存储在 pair 中的其中一个值就变得不可访问，这不是我们的本意。</p>
<p>因此，我建议增加一个折叠(<code>collapse</code>)函数，允许将这些无意中出现的 junction 值折叠成它们的原始值。</p>
<pre><code class="language-raku" data-lang="raku">if ( 42 == fst p1j) {
    say collapse(snd p1j); #=&gt; says 'R'
}
</code></pre><p>该函数的实现取自<a href="https://docs.raku.org/language/faq#index-entry-Junction_(FAQ)">上述常见问题</a>，并增加了一个检查，以确保 junction 上的所有值都相同。</p>
<pre><code class="language-raku" data-lang="raku">sub collapse(Junction \j) {    
    my @vvs;
    -&gt; Any \s { push @vvs, s }.(j);    
    my $v =  shift @vvs;        
    my @ts = grep {!($_ ~~ $v)}, @vvs;
    if (@ts.elems==0) {  
        $v
    } else {
        die &quot;Can't collapse this Junction: elements are not identical: {$v,@vvs}&quot;;
    }
}
</code></pre><p>如果能把这个功能作为一个 <code>collapse</code> 方法添加到 <code>Junction</code> 类中就更好了。</p>
<p>原文链接: <a href="https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8">https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/rakulang" term="rakulang" label="rakulang" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/raku" term="raku" label="Raku" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/junction" term="junction" label="Junction" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[重构 Raku 的 Junction]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-10-04-reconstructing-raku-junctions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-10-04-the-strange-case-of-the-greedy-junction/?utm_source=atom_feed" rel="related" type="text/html" title="贪婪 Junction 的奇闻异事" />
            
                <id>https://ohmyweekly.github.io/notes/2020-10-04-reconstructing-raku-junctions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-10-04T00:00:00+08:00</published>
            <updated>2020-10-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Reconstructing Raku&rsquo;s Junctions</blockquote><h2 id="重构-raku-的-junction">重构 Raku 的 Junction</h2>
<p>Raku 中的 junction 很酷，但乍一看它们并没有遵循静态类型化的规则。我对它们的形式化类型语义很好奇，所以我从功能、静态类型的角度对 junction 进行了解构和重构。</p>
<h3 id="raku-中的-junction">Raku 中的 Junction</h3>
<p><a href="https://docs.raku.org/">Raku</a> 有一个整洁的功能叫做 <a href="https://docs.raku.org/type/Junction">Junction</a>。Junction 是一个无序的复合值。当使用 junction 代替值时，会对每个结点(junction)元素进行操作，结果是所有这些操作符的返回值的结点(junction)。当在布尔上下文中使用 junction 时，结点(junction)会折叠成一个值。Junction 的类型可以是 all(<code>&amp;</code>)、any(<code>|</code>)、one(<code>^</code>) 或 <code>none</code> (空结点)。</p>
<p>例如:</p>
<pre><code class="language-raku" data-lang="raku">my $j = 11|22; # short for any(11,22)
if 33 == $j + 11 {
    say 'yes';
}

say so 3 == (1..30).one;         #=&gt; True 
say so (&quot;a&quot; ^ &quot;b&quot; ^ &quot;c&quot;) eq &quot;a&quot;; #=&gt; True
</code></pre><p>函数 <code>so</code> 强制使用布尔上下文。</p>
<p>Junction 有 <code>Junction</code> 类型，我很好奇 Junction 的类型规则，因为乍一看有些奇怪。比方说我们有一个函数 <code>sq</code> 从 <code>Int</code> 到 <code>Int</code>。</p>
<pre><code class="language-raku" data-lang="raku">sub sq(Int $x --&gt; Int) { $x*$x }

my Int $res = sq(11); # OK
say $res; #=&gt; 121
</code></pre><p>现在让我们定义一个类型为任何 <code>Int</code> 值的 Junction。</p>
<pre><code class="language-raku" data-lang="raku">my Junction $j = 11 | 22; 
</code></pre><p>当我们将 <code>sq</code> 应用于 <code>$j</code> 时，我们没有得到一个类型错误，即使函数的类型是 <code>:(Int --&gt; Int)</code>，Junction 的类型是 <code>Junction</code>。相反，我们得到的是一个结果的 Junction。</p>
<pre><code class="language-raku" data-lang="raku">say sq($j); #=&gt; any(121, 484)
</code></pre><p>如果我们像之前一样将其赋值给一个类型为 <code>Int</code> 的变量，我们会得到一个类型错误。</p>
<pre><code class="language-raku" data-lang="raku">my Int $rj = sq($j); #=&gt; Type check failed in assignment to $rj; expected Int but got Junction (any(121, 484))
</code></pre><p>取而代之的是，现在返回值的类型为 <code>Junction</code>。</p>
<pre><code class="language-raku" data-lang="raku">my Junction $rj = sq(11|22); # OK
</code></pre><p>所以，Junction 类型可以代替任何其他类型，但这样一来，操作也变成了 Junction。</p>
<p>另一方面，Junction 是由其组成值隐式类型的，尽管它们看起来是不透明的 <code>Junction</code> 类型。例如，如果我们创建了一个由 <code>Str</code> 值组成的 Junction，并试图将这个 Junction 的值传递到 <code>sq</code> 中，我们会得到一个类型错误。</p>
<pre><code class="language-raku" data-lang="raku">my $sj = '11' | '22';
say $sj.WHAT; #=&gt;(Junction)

my Junction $svj = sq($sj); #=&gt; Type check failed in binding to parameter 'x'; expected Int but got Str (&quot;11&quot;)
</code></pre><h3 id="junction-不遵循静态类型规则">Junction 不遵循静态类型规则</h3>
<p>虽然这样做是有道理的(如果原始函数期望使用 <code>Int</code>，我们不希望它与 <code>Str</code> 一起工作)，但这确实违背了静态类型化的规则，即使是子类型化。如果一个参数的类型是 <code>Int</code>，那么可以使用类型图中低于它的任何类型来代替。但是 <code>Int</code> 和 <code>Junction</code> 的简化类型图如下。</p>
<pre><code>Int -&gt; Cool -&gt; Any -&gt; Mu &lt;- Junction
</code></pre>
<p>所以 Junction 永远不是 <code>Any</code> 以下任何东西的子类型。因此，将 Junction 放在类型为 <code>Any</code> 或其子类型的槽中应该是一个类型错误。</p>
<p>此外，由于 Junction 类型是不透明的（即它不是一个参数化的类型），它不应该持有任何关于 Junction 内部值的类型的信息。然而它却对这些不可见、不可访问的值进行了类型检查。</p>
<p>那么这里到底发生了什么？</p>
<h3 id="一个工作假设">一个工作假设</h3>
<p>一个工作假设是，Junction 类型并不真正取代任何其他类型：它只是一个语法糖，使它看起来如此。</p>
<h3 id="重构-junction-的第一部分类型">重构 Junction 的第一部分：类型</h3>
<p>让我们试着重建这个。我们的目的是想出一个数据类型和一些动作，以复制观察到的 Raku Junction 的行为。首先我们讨论一下类型，为了清晰起见，使用 Haskell 符号。然后我介绍 Raku 中的实现。这个实现将像 Raku 的原生 Junction 一样，但没有神奇的语法糖。通过这种方式，我证明了 Raku 的 Junction 毕竟遵循了正确的类型规则。</p>
<h4 id="junction-类型">Junction 类型</h4>
<p>Junction 是一个由 Junction 类型 <code>JType</code> 和一组值组成的数据结构。为了方便起见，我将这个值集限制为单一类型，同时也是因为混合类型的 Junction 其实没有什么意义。我使用一个列表来模拟这个集合，同样是为了方便。因为 Junction 可以包含任何类型的值，所以它是一个多态的代数数据类型。</p>
<pre><code class="language-raku" data-lang="raku">data JType = JAny | JAll | JOne | JNone

data Junction a = Junction JType [a]
</code></pre><h4 id="应用结点">应用结点</h4>
<p>对一个 Junction 做任何事情都意味着对它应用一个函数。我们可以考虑三种情况，我为每一种情况介绍一个特别定制的操作符。</p>
<ul>
<li>将非 Junction 函数应用于 Junction 表达式</li>
</ul>
<pre><code class="language-raku" data-lang="raku">(•￮) :: (a -&gt; b) -&gt; Junction a -&gt;  Junction b
</code></pre><ul>
<li>将 Junction 函数应用于非 Junction 表达式。</li>
</ul>
<pre><code class="language-raku" data-lang="raku">(￮•) ::  Junction (b -&gt; c) -&gt; b -&gt; Junction c
</code></pre><ul>
<li>将 Junction 函数应用于 Junction 表达式，创建一个嵌套 Junction。</li>
</ul>
<pre><code class="language-raku" data-lang="raku">(￮￮) ::  Junction (b -&gt; c) -&gt; Junction b -&gt; Junction (Junction c)
</code></pre><p>为了方便，我们还可以在 Junction a 和 a 之间创建自定义比较运算符。</p>
<pre><code class="language-raku" data-lang="raku">-- and similar for /-, &gt;, &lt;, &lt;=,&gt;=
(￮==•) :: Junction a -&gt; a -&gt; Bool
</code></pre><h4 id="折叠-junction">折叠 Junction</h4>
<p>那么我们就有了 <code>so</code>，布尔强制函数。它的作用是将一个布尔的 Junction 折叠成一个布尔。</p>
<pre><code class="language-raku" data-lang="raku">so :: Junction Bool -&gt; Bool
</code></pre><p>最后我们有 <code>collapse</code>，它从一个 Junction 返回值，前提是它是一个 Junction，所有存储的值都是一样的。</p>
<pre><code class="language-raku" data-lang="raku">collapse :: (Show a,Eq a) =&gt; Junction a -&gt; a
</code></pre><p>这似乎是一个奇怪的函数，但由于 Junction 的行为，它是必要的。正如我们将看到的，上述语义意味着 Junction 是贪婪的：如果一个函数的一个参数是 Junction，那么所有其他参数也会成为 Junction，但 Junction 中的所有值都是相同的。我已经在&quot;<a href="https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8">贪婪 Junction 的奇怪情况</a>&ldquo;中讨论过这个问题，但我们现在可以将这种行为形式化。</p>
<h4 id="重新审视贪婪-junction-的奇怪情况">重新审视贪婪 Junction 的奇怪情况</h4>
<p>假设我们有一个两个参数的函数 <code>f :: a -&gt; b -&gt; c</code>，我们对第一个参数应用一个结点 <code>j :: Junction</code> a 应用到第一个参数 <code>f •￮ j</code> 上，那么结果是一个部分应用的函数，包裹在一个 Junction 上：<code>fp :: Junction b -&gt; c</code>。如果我们现在想用 <code>fp ￮• v</code> 将这个函数应用于一个非结点的值 <code>v :: b</code>，那么结果就是 <code>Junction c</code> 类型的。</p>
<p>现在，让我们考虑类型 <code>c</code> 是 <code>forall d . (a -&gt; b -&gt; d) -&gt; d</code> 的特殊情况。所以我们有 <code>Junction</code>(<code>forall d . (a-&gt;b-&gt;d) -&gt; d</code>)。这是一个函数，它接受一个函数参数并返回该函数的返回类型的东西。我们使用 <code>forall</code>，所以 <code>d</code> 可以是任何东西，但在实践中我们希望它是 <code>a</code> 或 <code>b</code>。</p>
<p>假设我们将这个函数(称它为 <code>p</code>)应用于 <code>fst :: a-&gt;b-&gt;a</code>，使用 <code>p ￮• fst</code>，那么我们得到 <code>Junction a</code>。但是如果我们将它应用于 <code>snd :: a-&gt;b-&gt;b</code>，使用 <code>p ￮• snd</code>，那么我们得到 <code>Junction b</code>。</p>
<p>这就是形式上基于类型的分析，为什么我们不能从一个 pair 中返回一个非 Junction 的值，在&rdquo;<a href="https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8">贪婪 Junction 的奇怪情况</a>&ldquo;中已经解释过。而这也是我们需要 <code>collapse</code> 函数的原因。</p>
<h4 id="重构-junction-的第2部分raku-的实现">重构 Junction 的第2部分：Raku 的实现。</h4>
<p>我们从创建 Junction 类型开始，为四种 Junction 类型使用一个枚举，为实际的 Junction 数据类型使用一个角色。</p>
<pre><code class="language-raku" data-lang="raku"># The types of Junctions
enum JType &lt;JAny  JAll  JOne  JNone &gt;;

# The actual Junction type
role Junction[\jt, @vs] {
    has JType $.junction-type=jt;
    has @.values=@vs;
}
</code></pre><p>接下来是四种类型的 Junction 的构造函数（下划线，避免与内建函数的名称冲突）。</p>
<pre><code class="language-raku" data-lang="raku">our sub all_(@vs) {
    Junction[ JAll, @vs].new;
}

our sub any_(@vs) {
    Junction[ JAny, @vs].new;
}

our sub one_(@vs) {
    Junction[ JOne, @vs].new;
}

our sub none_(@vs) {
    Junction[ JNone, @vs].new;
}
</code></pre><p>将一个（单参数）函数应用于 junction 参数。</p>
<pre><code class="language-raku" data-lang="raku">sub infix:&lt;●○&gt;( &amp;f, \j ) is export {
    my \jt=j.junction-type; 
    my @vs = j.values;
  
    Junction[ jt, map( {&amp;f($_)}, @vs)].new;
}
</code></pre><p>要将 Junction 内的函数应用于非 Junction 的参数:</p>
<pre><code class="language-raku" data-lang="raku">sub infix:&lt;○●&gt;( \jf, \v ) is export {
    my \jt=jf.junction-type; 
    my @fs = jf.values;

    Junction[ jt, map( {$_( v)}, @fs)].new;
}
</code></pre><p>将一个函数应用于两个 junction 参数，相当于将一个 junction 内的函数应用于一个 junction。这里有一个复杂的问题。Raku 对嵌套施加了一个排序，即所有的嵌套总是外嵌套。因此，我们必须检查 junction 的类型，如果需要的话，我们必须交换映射。</p>
<pre><code class="language-raku" data-lang="raku">sub infix:&lt;○○&gt;( \jf, \jv ) is export {
    my \jft= jf.junction-type; 
    my @fs = jf.values;
    my \jvt = jv.junction-type;
    my @vs = jv.values;
    if (jvt == JAll and jft != JAll) {        
        Junction[ jvt, map( sub (\v){jf ○● v}, @vs)].new;  
    } else {        
        Junction[ jft, map( sub (&amp;f){ &amp;f ●○ jv}, @fs)].new;
    }
}
</code></pre><p>为了完整，这里是 <code>○==●</code> 的定义。<code>○!=●</code>、<code>○&gt;●</code> 等的定义是类似的。</p>
<pre><code class="language-raku" data-lang="raku">sub infix:&lt; ○==● &gt;( \j, \v ) is export {
    sub (\x){x==v} ●○ j
}
</code></pre><p>接下来我们有 <code>so</code>，它把布尔值的 junction 变成了布尔值。</p>
<pre><code class="language-raku" data-lang="raku">our sub so (\jv) { 
    my @vs = jv.values;
    given jv.junction-type {
        when JAny { elems(grep {$_},  @vs) &gt;0}
        when JAll { elems(grep {!$_}, @vs)==0}
        when JOne { elems(grep {$_},  @vs)==1}
        when JOne { elems(grep {$_},  @vs)==0}
    }
}
</code></pre><p>最后我们有 <code>collapse</code>，正如<a href="https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8">贪婪 Junction 的文章</a>中所定义的那样， <code>collapse</code> 返回 Junction 的值，只要它们都是一样的。</p>
<pre><code class="language-raku" data-lang="raku">our sub collapse( \j ) {
    my \jt=j.junction-type; 
    my @vvs = j.values;
    my $v =  shift @vvs;        
    my @ts = grep {!($_ ~~ $v)}, @vvs;
    if (@ts.elems==0) {  
        $v
    } else {
        die &quot;Can't collapse this Junction: elements are not identical: {$v,@vvs}&quot;;
    }
}
</code></pre><h3 id="junction-清理">Junction 清理</h3>
<p>现在我们再来看看我们的工作假说，将 Raku 的 Junction 上的动作解释为上述类型和操作符的语法糖。</p>
<pre><code class="language-raku" data-lang="raku">sub sq(Int $x --&gt; Int) { $x*$x }
my Junction $j = 11 | 22; 
my Junction $rj = sq($j); 
</code></pre><p>去语法塘后这变成了:</p>
<pre><code class="language-raku" data-lang="raku">my Junction $j = any_ [11,22];
my Junction $rj = &amp;sq ●○ $j;
</code></pre><p>类似地,</p>
<pre><code class="language-raku" data-lang="raku">if ($j == 42) {...} 
</code></pre><p>变成了:</p>
<pre><code class="language-raku" data-lang="raku">if (so ($j ○==● 42)) {...}
</code></pre><p>和其他布尔上下文类似。</p>
<p>如果我们仔细看<a href="https://gist.github.com/wimvanderbauwhede/85fb4b88ec53a0b8149e6c05740adcf8">贪婪 Junction 文章</a>中的 pair 例子，那么将 junction 应用到一个有多个参数的函数上:</p>
<pre><code class="language-raku" data-lang="raku">my Junction \p1j = pair R,(42^43);
</code></pre><p>去语法塘后变为:</p>
<pre><code class="language-raku" data-lang="raku">my Junction \p1j = &amp;pair.assuming(R) ●○ one_ [42,43];
</code></pre><p>我们使用 <code>.assuming()</code> 是因为我们需要部分应用。不管我们是先应用非 Junction 参数还是 Junction 参数，都没有关系。</p>
<pre><code class="language-raku" data-lang="raku">my \p1jr = ( sub ($y){ &amp;pair.assuming(*,$y) } ●○ one_ [42,43] ) ○● R;
</code></pre><p>最后，举一个两个参数都是 Junction 的例子。由于 <code>○○</code> 的定义，应用的顺序并不重要。</p>
<pre><code class="language-raku" data-lang="raku">sub m(\x,\y){x*y}

my \p4 = ( sub (\x){ &amp;m.assuming(x) } ●○ any_ [11,22] ) ○○ all_ [33,44];
my \p4r = ( sub (\x){ &amp;m.assuming(*,x) } ●○ all_ [33,44] ) ○○ any_ [11,22];
</code></pre><h3 id="结论">结论</h3>
<p>从 Raku 的 junction 的神奇类型行为实际上是语法糖的假设出发，我使用多态代数数据类型重构了 junction 类型和它的动作，并表明 Raku 的行为作为语法糖的解释对于所提出的实现是成立的。换句话说，Raku 的 Junction 确实遵循静态类型规则。</p>
<p>原文链接: <a href="https://gist.github.com/wimvanderbauwhede/19cc1e8d04e9a477f58cfe7288a6172e">https://gist.github.com/wimvanderbauwhede/19cc1e8d04e9a477f58cfe7288a6172e</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/rakulang" term="rakulang" label="rakulang" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/raku" term="raku" label="Raku" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/junction" term="junction" label="Junction" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SSH Configuration: ssh_config]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-10-01-ssh-configuration/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-10-01-ssh-configuration/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-10-01T00:00:00+08:00</published>
            <updated>2020-10-01T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SSH Configuration</blockquote><p><img src="https://gravitational.com/blog/images/2020/ssh-config-header.png" alt="img"></p>
<p>这篇博文涵盖了我最喜欢的一些设置，用于配置 ssh 客户端的行为（即在 <code>ssh_config</code> 的 man 页面中的内容）。无论你是想添加一些额外的安全约束，减少失败，还是防止腕隧道，<code>ssh_config</code> 都是一个经常未被充分利用的强大工具。</p>
<p>本文将介绍一些修改 <code>ssh_config</code> 文件的有用方法，以达到更高的安全和控制程度。这篇文章并不是关于通过 <code>sshd_config</code> 进行服务器端配置，后者值得单独写一篇文章。</p>
<h2 id="什么是-ssh_config">什么是 ssh_config?</h2>
<p>一些工程师可能会惊讶于 ssh 客户端行为有多少是可以通过配置文件来配置的。如果没有配置文件，为 ssh 指定命令行参数很快就会变得很麻烦。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ssh -i /users/virag/keys/us-west/ed25519 -p <span class="m">1024</span> -l virag <span class="se">\ </span>myserver.aws-west.example.com
</code></pre></div><p>这句话太长了，一次都打不完，更不用说一天打多次了。如果你要管理多台服务器和虚拟机，创建一个自定义的 <code>~/.ssh/ssh_config</code> 是修剪常用 <code>ssh</code> 命令的好方法。</p>
<p>我们可以通过编辑 <code>ssh_config</code>，将上面的例子缩短为 <code>ssh myserver</code>。</p>
<pre><code>Host myserver
	Hostname myserver.aws-west.example.com
	User virag
	Port 1024
	IdentityFile /users/virag/keys/us-west/ed25519
</code></pre><p>优雅而简单。现在我们有了基础知识，让我们看看这里到底发生了什么。我选择的 ed25519 在<a href="https://gravitational.com/blog/comparing-ssh-keys/">比较 SSH 密钥-RSA、DSA、ECDSA 或 EdDSA?</a></p>
<h2 id="ssh_config-如何工作">ssh_config 如何工作</h2>
<p>ssh 客户端从三个地方读取配置，顺序如下:</p>
<ol>
<li>系统范围内的 <code>/etc/ssh/ssh_config</code></li>
<li>在 <code>~/.ssh/ssh_config</code> 中的用户特定配置。</li>
<li>直接提供给 ssh 的命令行标志</li>
</ol>
<p>这意味着命令行标志(#1)可以覆盖用户特定的配置(#2)，可以覆盖全局配置(#3)</p>
<p>当连接参数被重复使用时，通常在 <code>ssh_config</code> 中定义这些参数比较容易，它们会在连接时自动应用。虽然它们通常是在用户第一次运行 ssh 时创建的，但目录和文件可以通过以下方式手动创建。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">touch ~/.ssh/ssh_config
</code></pre></div><p>回到上面的例子，你可能会注意到 <code>ssh_config</code> 是以主机头开始的段落来组织的。</p>
<pre><code>Host [alias]
	Option1 [Value]
	Option2 [Value]
	Option3 [Value]
</code></pre><p>虽然技术上没有必要，但这种缩进的格式很容易被人类阅读。然而，ssh 客户端并不关心这种格式化，相反，它将通过将命令行中输入的 ssh 参数与所有主机头匹配来获取配置参数。通配符也可以作为主机头的一部分。考虑一下:</p>
<pre><code>Host myserver2
	Hostname myserver2.aws-west.example.com
Host myserver*
	Hostname myserver1.aws-west.example.com
	User virag
	Port 1024
</code></pre><p>使用 <code>myserver1</code> 的别名，我们可以从第二节中得到我们所期望的东西。</p>
<pre><code>Hostname myserver1.aws-west.example.com
User virag
Port 1024
</code></pre><p>但 <code>myserver2</code> 也有类似的选项列表。</p>
<pre><code>Hostname myserver2.aws-west.example.com
User virag
Port 1024
</code></pre><p>ssh 客户端通过模式匹配获取这些信息，并在向下顺序读取文件时锁定值。因为 myserver2 同时匹配了 <code>myserver2</code> 和 <code>myserver*</code>，所以它会先从 myserver2 中获取 Hostname 值。然后，当到了第二种模式匹配时，就会使用 User 和 Port 的值，但 Hostname 字段已经被填满。让我再重复一遍，ssh 接受每个选项的第一个值。</p>
<h2 id="常见的-ssh-配置选项">常见的 SSH 配置选项</h2>
<p>在 <code>man 5 ssh_config</code> 中，有近 100 个 ssh_config 选项。我整理了一份我个人使用的清单，其中许多选项将在后面的文章中使用。</p>
<ul>
<li>
<p><code>Port</code> - 远程 ssh 守护进程运行的端口。如果守护进程运行在默认的 22 号端口上，则不需要定义这个选项。在不同的端口上运行 ssh 守护进程被认为是一个很好的做法，因为这样可以减少僵尸探测的数量。</p>
</li>
<li>
<p><code>Hostname</code> - 用于建立连接的真实主机名，如 DNS 或 IP 地址。这对缩短主机名很有用。例如，你可以让一个方便的 <code>ssh mongo</code> 带你到 <code>mongo-12.staging.example.com</code>。</p>
</li>
<li>
<p><code>ProxyJump</code> - 这个选项将通过连接的服务器进行隧道简化为一个标志，<code>-J</code>，用一个别名来命名中间主机（本地客户端和最终目的地之间的主机）。这只适用于较新的客户端（<a href="https://www.openssh.com/txt/release-7.3">OpenSSH 7.3+</a>）。下面我将详细介绍这个。</p>
</li>
<li>
<p><code>ForwardAgent</code> &amp; <code>AddKeysToAgent</code> - 在主机之间跳转（当你在另一个 <code>ssh</code> 会话中再次键入 <code>ssh</code> 时）需要重复验证。要做到这一点，<code>ssh</code> 凭证必须存储在中间服务器上，但这不是一个安全的做法。这两个选项允许另一个通常被称为 <code>ssh-agent</code> 的进程自动将你的本地 <code>ssh</code> 凭证加载到内存中，并通过一个安全转发的 UNIX 套接字将其提供给中间机器的 ssh 客户端。<code>ForwardAgent</code> 可以实现这种转发行为，而 <code>AddKeysToAgent</code> 则可以自动将密钥加载到内存中。我将在下面提供更多细节。</p>
</li>
<li>
<p><code>IdentityFile</code> - 这个选项指定了 ssh 客户端应该尝试验证的密钥的路径。这并不妨碍 ssh 客户端尝试 <code>~/.ssh</code> 或 <code>ssh-agent</code> 中的密钥。常用于由于某种原因，密钥没有存储在默认位置的情况下。</p>
</li>
<li>
<p><code>IdentitiesOnly</code> - 通常和 <code>IdentityFile</code> 一起使用，这个选项会告诉 ssh 客户端到底要提交哪个密钥，并放弃 <code>~/.ssh</code> 或 <code>ssh-agent</code> 中的任何密钥。因为如果尝试了太多无效的密钥，ssh 会抛出一个认证错误，这个选项可以帮助客户端精确地识别要提交的密钥。即使在 <code>ssh_config</code> 中启用了 <code>IdentitiesOnly</code>，任何在命令行输入的身份信息也会被尝试。</p>
</li>
<li>
<p><code>CertificateFile</code> - 考虑到密钥在很大程度上已经过时了，这个选项可以和 <code>IdentityFile</code> 一起使用来指定要提交的证书。这并不总是必要的。当证书颁发机构签署一个密钥来创建证书时，<code>-cert.pub</code> 将自动附加到密钥的文件名中。在加载密钥之前，ssh 客户端将首先尝试使用预期的命名惯例从提供的文件名中加载证书。然而，如果密钥和证书文件名不遵循这种模式，那么必须使用 <code>CertificateFile</code>，否则将无法找到证书。<a href="https://gravitational.com/blog/how-to-ssh-properly/">阅读更多关于为什么你应该使用证书</a>。</p>
</li>
<li>
<p><code>SetEnv</code> &amp; <code>SendEnv</code> - 这些选项允许 ssh 客户端向指定的主机发送本地环境变量。主机服务器必须通过在 <code>/etc/ssh/sshd_config</code> 中将 <code>AcceptEnv</code> 设置为 <code>Yes</code> 来接受这些环境变量。</p>
</li>
<li>
<p><code>ServerAliveInterval</code> &amp; <code>ServerAliveCountMax</code> -如果 ssh 客户端在指定的时间间隔内没有收到任何数据，它将请求主机服务器做出响应。这可以防止负载均衡器和服务器因不活动而放弃连接。</p>
</li>
<li>
<p><code>HostKeyAlias</code> - ssh 客户端会被指示使用 <code>~/.ssh/known_hosts</code> 中的密钥别名，而不是 HostName。这对于具有动态变化的 IP 地址的主机或在一台主机上运行的多个服务器来说非常有用。</p>
</li>
<li>
<p><code>PreferredAuthentication</code> - 这个选项决定了验证方法的尝试顺序。默认值是 <code>gssapi-with-mic</code>, <code>hostbased</code>, <code>publickey</code>, <code>keyboard-interactive</code> 和 <code>password</code>。</p>
</li>
</ul>
<h2 id="组织你的-ssh-配置">组织你的 SSH 配置</h2>
<p>在前面两节所学内容的基础上进行扩展，让我们看看当我们拥有一支规模不大的舰队时，如何组织 <code>ssh_config</code>。以下面的场景为例。</p>
<ul>
<li>Virag 在六个环境下工作： 东岸和西岸 AWS 区域的 Dev、Test 和 Prod。</li>
<li>Virag 有普通用户访问开发和产品环境的权限，但在测试环境中是 root 用户。</li>
<li>Prod 环境有更严格的安全控制</li>
</ul>
<p>我没有记住几个 <code>ssh</code> 命令组合，而是编辑了我的本地配置文件。</p>
<pre><code>Host east-prod
	HostName east-prod.prod.example.com
Host *-prod
	HostName west-prod.prod.example.com
	User virag
	PasswordAuthentication no
	PubKeyAuthentication yes
	IdentityFile /users/virag/keys/production/ed25519
	Host east-test
	HostName east-test.test.example.com
Host *-test
	HostName west-test.test.example.com
	User root
Host east-dev
	HostName east-dev.east.example.com
Host *-dev
	HostName west-dev.west.example.com
	User virag   
Host * !prod
	PreferredAuthentications publickey
Host *
	HostName bastion.example.com
	User Default
	ServerAliveInternal 120
	ServerAliveCountMax 5
</code></pre><p>如果我们运行 <code>ssh east-test</code>，我们的全部选项列表将是：</p>
<pre><code>HostName east-test.test.example.com
User root
PreferredAuthentications publickey
ServerAliveInternal 30
ServerAliveCountMax 5
</code></pre><p>客户端通过与 <code>east-test</code>、<code>*-test</code>、<code>* !prod</code> 和 <code>*</code> 匹配来获取预期的选项值。你可能会注意到 <code>Host *</code> stanza 将适用于任何 ssh 参数。换句话说，<code>Host *</code> 定义了所有用户的全局设置。这对于应用客户端可用的安全控制特别有用。上面，我们只用了两个，但有<a href="https://man.openbsd.org/ssh_config.5">几个关键字</a>会加强安全，如 <code>CheckHostIP</code>，<code>HashKnownHosts</code>，<code>StrictHostKeyChecking</code>，以及更多隐藏的宝石。</p>
<p>需要注意的是。因为 ssh 客户端是按顺序解释选项的, 通用配置应该放在文件的底部。如果放在最上面，在客户端读取下面的特定主机选项之前，选项值就会被固定下来。在上面的案例中，把 <code>Host *</code> 放在文件的开头会导致用户为 <code>Default</code>。</p>
<p>如果出现一次性的情况，一定要记住，在命令行输入的选项会覆盖 <code>ssh_config</code> 中的选项：<code>ssh -o &quot;User=root&quot; dev</code>。</p>
<h2 id="使用-ssh-代理">使用 SSH 代理</h2>
<p>ssh 跳转服务器是站在客户端和其余 ssh 队伍之间的代理。跳跃主机通过强制所有的 ssh 流量通过一个单一的加固的位置，并最大限度地减少个别节点的 ssh 端点到外部世界，从而将威胁降到最低。</p>
<p>配置多跳设置的一种方法是在我们的跳转服务器上存储目标服务器的私钥。不要这样做。跳跃服务器通常是一个多用户环境，这意味着任何拥有高权限的单方都可以破坏任何私钥。解决这种安全威胁的方法是启用代理转发，我们在 <code>AddKeysToAgent</code> 和 <code>ForwardAgent</code> 中简单地提到了这个方法。鉴于这种方法是多么常见，当我建议也不要这样做时，你可能会感到惊讶。为了了解原因，我们来深入了解一下。</p>
<h2 id="代理转发是如何工作的">代理转发是如何工作的？</h2>
<p><code>ssh-agent</code> 是一个独立于 SSH 的密钥管理器。它在内存中保存用于验证的私钥和证书。它不向磁盘写入或导出密钥。相反，代理的转发功能允许我们的本地代理通过现有的 ssh 连接到达，并通过环境变量在远程服务器上进行认证。基本上，当客户端 ssh 接收到密钥挑战时，代理会将这些挑战上游转发到我们本地的机器上，通过本地存储的私钥构造挑战响应，并转发回下游的目的服务器进行认证。我个人在研究的时候觉得这种<a href="http://www.unixwiz.net/techtips/ssh-agent-forwarding.html">直观的解释</a>很有帮助。</p>
<p>在幕后，ssh-agent 绑定到一个 unix-domain 的 socket 上与其他程序通信（<code>$SSH_AUTH_SOCK</code> 环境变量）。问题是，任何在链上任何地方拥有 root 权限的人都可以使用创建的 socket 来劫持我们本地的 <code>ssh-agent</code>。尽管套接字文件受到操作系统很好的保护，但一个 root 用户可以冒充其他用户，将 ssh 客户端指向自己的恶意代理。从本质上来说，使用代理转发就等于在整个链条上与任何一台机器上的 root 用户共享私钥。(深入阅读<a href="http://rabexc.org/posts/pitfalls-of-ssh-agents">使用 ssh-agent 的陷阱</a>)</p>
<p>事实上，关于 <code>ForwardAgent</code> 的 man 页面上写着。</p>
<blockquote>
<p>&ldquo;代理转发应谨慎启用。有能力绕过远程主机（对代理的 Unix-domain 套接字）上的文件权限的用户可以通过转发连接访问本地代理。攻击者无法从代理中获取密钥材料，然而他们可以对密钥进行操作，使他们能够使用加载到代理中的身份进行验证。&rdquo;</p>
</blockquote>
<h2 id="使用-proxyjump-代替">使用 ProxyJump 代替</h2>
<p>为了在跳转服务器中导航，我们其实并不需要代理转发。现代的方法是使用 <code>ProxyJump</code> 或其命令行等价物 <code>-J</code>。</p>
<pre><code>Host myserver
	HostName myserver.example.com
	User virag
	IdentityFile /users/virag/keys/ed25519
	ProxyJump jump
Host jump
	HostName jump.example.com
	User default
</code></pre><p><code>ProxyJump</code> 没有通过代理转发密钥挑战响应，而是将我们本地客户端的 stdin 和 stdout 转发到目的主机。这样一来，我们不需要在 <code>jump.example.com</code> 上运行 ssh。sshd 直接连接到 <code>myserver.example.com</code>，并将该连接的控制权交给我们的本地客户端。作为一个额外的好处，由于跳转服务器在 ssh 隧道内是加密的，所以它不能看到任何通过它的流量。设置跳转服务器而不让 ssh 直接访问它的能力是安全和正确的 ssh 设置的一个重要组成部分。</p>
<h2 id="多跳的代理跳转">多跳的代理跳转</h2>
<p>让我们模拟一个更复杂的场景。我们正试图从家里访问公司网络深处的一个关键资源。我们必须首先通过一个具有动态 IP 的外部堡垒主机、一个内部跳转主机，最后到达资源。每台服务器必须针对我们机器上的唯一本地密钥进行验证。</p>
<p>多重跳转的 ssh 示意图:</p>
<p><img src="https://gravitational.com/blog/images/2020/ssh-config-1.png" alt="img"></p>
<p>再一次，我们的本地配置文件将包含执行 <code>ssh myserver</code> 所需的一切。</p>
<pre><code>Host myserver
	HostName myserver.example.com
	User virag
	IdentityFile /users/virag/keys/myserver-cert.pub
	ProxyJump jump
Host bastion
	#Used because HostName is unreliable as IP address changes frequently
	HostKeyAlias bastion.example
	User external  
Host jump
	HostName jump.example.com
	User internal  
	IdentityFile /users/virag/keys/jump-cert.pub
	ProxyJump bastion
</code></pre><p>现在想象一下，我们必须用内部配置的 OpenSSH 管理全国各地多个云提供商的几百个环境。(你可能会嗤之以鼻，但我们已经听过这些故事了！)仅仅依靠运行时命令，同时宣称要维护可信的安全程度是不可能的。在这种规模下，有效地管理一个舰队需要有意识地架构子网、DNS、代理链、密钥、文件结构等，这些子网、DNS、代理链、密钥、文件结构等遵循可预测的模式，并且可以抄录到 <code>~/.ssh/ssh_config</code> 中。</p>
<h2 id="结束语">结束语</h2>
<p>从本文中得到的更广泛的启示是让生活变得简单。即使是最简单的配置选项，也可以通过巧妙的方式来实现。这些可以让我们保持对强大安全性的承诺，并最大限度地减少人为错误。</p>
<p>如果你想了解更多关于 ssh 访问的最佳实践，你可以考虑以下文章。</p>
<ul>
<li><a href="https://gravitational.com/blog/how-to-ssh-properly/">如何正确使用 SSH</a></li>
<li>Teleport: <a href="https://github.com/gravitational/teleport">OpenSSH 的现代替代品</a></li>
</ul>
<p>原文链接: <a href="https://gravitational.com/blog/ssh-config/">https://gravitational.com/blog/ssh-config/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/git" term="git" label="git" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/git" term="git" label="git" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/config" term="config" label="config" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Custom Serializer]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Custom Serializer</blockquote><h1 id="为你的-flink-程序注册一个自定义的序列器">为你的 Flink 程序注册一个自定义的序列器</h1>
<p>如果你在 Flink 程序中使用的自定义类型不能被 Flink 类型序列化器序列化，Flink 就会回到使用通用的 Kryo 序列化器。你可以用 Kryo 注册你自己的序列化器或像 Google Protobuf 或 Apache Thrift 这样的序列化系统。要做到这一点，只需在 Flink 程序的 ExecutionConfig 中注册类型类和序列化器。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// register the class of the serializer as serializer for a type
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">registerTypeWithKryoSerializer</span><span class="o">(</span><span class="n">MyCustomType</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">MyCustomSerializer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// register an instance as serializer for a type
</span><span class="c1"></span><span class="n">MySerializer</span> <span class="n">mySerializer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MySerializer</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">registerTypeWithKryoSerializer</span><span class="o">(</span><span class="n">MyCustomType</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">mySerializer</span><span class="o">);</span>
</code></pre></div><p>请注意，你的自定义序列化器必须扩展 Kryo 的序列化器类。在 Google Protobuf 或 Apache Thrift 的情况下，这已经为你完成了。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// register the Google Protobuf serializer with Kryo
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">registerTypeWithKryoSerializer</span><span class="o">(</span><span class="n">MyCustomType</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">ProtobufSerializer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// register the serializer included with Apache Thrift as the standard serializer
</span><span class="c1">// TBaseSerializer states it should be initialized as a default Kryo serializer
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">addDefaultKryoSerializer</span><span class="o">(</span><span class="n">MyCustomType</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">TBaseSerializer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</code></pre></div><p>为了使上面的例子有效，你需要在 Maven 项目文件(pom.xml)中加入必要的依赖关系。在依赖关系部分，为 Apache Thrift 添加以下内容。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>com.twitter<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>chill-thrift<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>0.7.6<span class="nt">&lt;/version&gt;</span>
	<span class="c">&lt;!-- exclusions for dependency conversion --&gt;</span>
	<span class="nt">&lt;exclusions&gt;</span>
		<span class="nt">&lt;exclusion&gt;</span>
			<span class="nt">&lt;groupId&gt;</span>com.esotericsoftware.kryo<span class="nt">&lt;/groupId&gt;</span>
			<span class="nt">&lt;artifactId&gt;</span>kryo<span class="nt">&lt;/artifactId&gt;</span>
		<span class="nt">&lt;/exclusion&gt;</span>
	<span class="nt">&lt;/exclusions&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- libthrift is required by chill-thrift --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>org.apache.thrift<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>libthrift<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>0.11.0<span class="nt">&lt;/version&gt;</span>
	<span class="nt">&lt;exclusions&gt;</span>
		<span class="nt">&lt;exclusion&gt;</span>
			<span class="nt">&lt;groupId&gt;</span>javax.servlet<span class="nt">&lt;/groupId&gt;</span>
			<span class="nt">&lt;artifactId&gt;</span>servlet-api<span class="nt">&lt;/artifactId&gt;</span>
		<span class="nt">&lt;/exclusion&gt;</span>
		<span class="nt">&lt;exclusion&gt;</span>
			<span class="nt">&lt;groupId&gt;</span>org.apache.httpcomponents<span class="nt">&lt;/groupId&gt;</span>
			<span class="nt">&lt;artifactId&gt;</span>httpclient<span class="nt">&lt;/artifactId&gt;</span>
		<span class="nt">&lt;/exclusion&gt;</span>
	<span class="nt">&lt;/exclusions&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>对于 Google Protobuf，你需要以下 Maven 依赖。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>com.twitter<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>chill-protobuf<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>0.7.6<span class="nt">&lt;/version&gt;</span>
	<span class="c">&lt;!-- exclusions for dependency conversion --&gt;</span>
	<span class="nt">&lt;exclusions&gt;</span>
		<span class="nt">&lt;exclusion&gt;</span>
			<span class="nt">&lt;groupId&gt;</span>com.esotericsoftware.kryo<span class="nt">&lt;/groupId&gt;</span>
			<span class="nt">&lt;artifactId&gt;</span>kryo<span class="nt">&lt;/artifactId&gt;</span>
		<span class="nt">&lt;/exclusion&gt;</span>
	<span class="nt">&lt;/exclusions&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- We need protobuf for chill-protobuf --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>com.google.protobuf<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>protobuf-java<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>3.7.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>请根据需要调整两个库的版本。</p>
<h2 id="使用-kryo-的-javaserializer-的问题">使用 Kryo 的 JavaSerializer 的问题。</h2>
<p>如果你为你的自定义类型注册了 Kryo 的 JavaSerializer，你可能会遇到 ClassNotFoundExceptions，即使你的自定义类型类包含在提交的用户代码 jar 中。这是由于 Kryo 的 JavaSerializer 的一个已知问题，它可能会错误地使用错误的 classloader。</p>
<p>在这种情况下，你应该使用 org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer 来代替解决这个问题。这是 Flink 中重新实现的 JavaSerializer，它可以确保使用用户代码类加载器。</p>
<p>更多细节请参考 <a href="https://issues.apache.org/jira/browse/FLINK-6025">FLINK-6025</a>。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/custom_serializers.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/custom_serializers.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hive Read and Write]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="related" type="text/html" title="HiveCatalog" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Hive Read and Write</blockquote><h1 id="hive-读写">Hive 读写</h1>
<p>使用 HiveCatalog 和 Flink 与 Hive 的连接器，Flink 可以从 Hive 数据中读取和写入数据，作为 Hive 批处理引擎的替代。请务必按照说明在你的应用中加入正确的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#depedencies">依赖关系</a>。同时请注意，Hive 连接器只适用于 blink planner。</p>
<h2 id="从-hive-读取数据">从 Hive 读取数据</h2>
<p>假设 Hive 在其默认的数据库中包含一个名为 people 的单表，该表包含多条记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">hive&gt; show databases<span class="p">;</span>
OK
default
Time taken: 0.841 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>

hive&gt; show tables<span class="p">;</span>
OK
Time taken: 0.087 seconds

hive&gt; CREATE TABLE mytable<span class="o">(</span>name string, value double<span class="o">)</span><span class="p">;</span>
OK
Time taken: 0.127 seconds

hive&gt; SELECT * FROM mytable<span class="p">;</span>
OK
Tom   4.72
John  8.0
Tom   24.2
Bob   3.14
Bob   4.72
Tom   34.9
Mary  4.79
Tiff  2.72
Bill  4.33
Mary  77.7
Time taken: 0.097 seconds, Fetched: <span class="m">10</span> row<span class="o">(</span>s<span class="o">)</span>
</code></pre></div><p>数据准备好后，你可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#connecting-to-hive">连接到现有的 Hive 安装</a>并开始查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show catalogs<span class="p">;</span>
myhive
default_catalog

<span class="c1"># ------ Set the current catalog to be &#39;myhive&#39; catalog if you haven&#39;t set it in the yaml file ------</span>

Flink SQL&gt; use catalog myhive<span class="p">;</span>

<span class="c1"># ------ See all registered database in catalog &#39;mytable&#39; ------</span>

Flink SQL&gt; show databases<span class="p">;</span>
default

<span class="c1"># ------ See the previously registered table &#39;mytable&#39; ------</span>

Flink SQL&gt; show tables<span class="p">;</span>
mytable

<span class="c1"># ------ The table schema that Flink sees is the same that we created in Hive, two columns - name as string and value as double ------ </span>
Flink SQL&gt; describe mytable<span class="p">;</span>
root
 <span class="p">|</span>-- name: name
 <span class="p">|</span>-- type: STRING
 <span class="p">|</span>-- name: value
 <span class="p">|</span>-- type: DOUBLE

<span class="c1"># ------ Select from hive table or hive view ------ </span>
Flink SQL&gt; SELECT * FROM mytable<span class="p">;</span>

   name      value
__________ __________

    Tom      4.72
    John     8.0
    Tom      24.2
    Bob      3.14
    Bob      4.72
    Tom      34.9
    Mary     4.79
    Tiff     2.72
    Bill     4.33
    Mary     77.7
</code></pre></div><h3 id="查询-hive-视图">查询 Hive 视图</h3>
<p>如果你需要查询 Hive 视图，请注意。</p>
<p>在查询该目录中的视图之前，必须先使用 Hive 目录作为当前目录。可以通过 Table API 中的 <code>tableEnv.useCatalog(...)</code> 或者 SQL Client 中的 USE CATALOG &hellip;来实现。
Hive 和 Flink SQL 有不同的语法，例如，不同的保留关键字和字元。请确保视图的查询与 Flink 语法兼容。</p>
<h2 id="写入-hive">写入 Hive</h2>
<p>同样，也可以使用 INSERT 子句将数据写入 hive 中。</p>
<p>考虑有一个名为 &ldquo;mytable &ldquo;的示例表，表中有两列：name 和 age，类型为 string 和 int。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># ------ INSERT INTO will append to the table or partition, keeping the existing data intact ------ </span>
Flink SQL&gt; INSERT INTO mytable SELECT <span class="s1">&#39;Tom&#39;</span>, 25<span class="p">;</span>

<span class="c1"># ------ INSERT OVERWRITE will overwrite any existing data in the table or partition ------ </span>
Flink SQL&gt; INSERT OVERWRITE mytable SELECT <span class="s1">&#39;Tom&#39;</span>, 25<span class="p">;</span>
</code></pre></div><p>我们也支持分区表，考虑有一个名为 myparttable 的分区表，有四列：name、age、my_type 和 my_date，在 type 中&hellip;<code>my_type</code> 和 <code>my_date</code> 是分区键。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># ------ Insert with static partition ------ </span>
Flink SQL&gt; INSERT OVERWRITE myparttable PARTITION <span class="o">(</span><span class="nv">my_type</span><span class="o">=</span><span class="s1">&#39;type_1&#39;</span>, <span class="nv">my_date</span><span class="o">=</span><span class="s1">&#39;2019-08-08&#39;</span><span class="o">)</span> SELECT <span class="s1">&#39;Tom&#39;</span>, 25<span class="p">;</span>

<span class="c1"># ------ Insert with dynamic partition ------ </span>
Flink SQL&gt; INSERT OVERWRITE myparttable SELECT <span class="s1">&#39;Tom&#39;</span>, 25, <span class="s1">&#39;type_1&#39;</span>, <span class="s1">&#39;2019-08-08&#39;</span><span class="p">;</span>

<span class="c1"># ------ Insert with static(my_type) and dynamic(my_date) partition ------ </span>
Flink SQL&gt; INSERT OVERWRITE myparttable PARTITION <span class="o">(</span><span class="nv">my_type</span><span class="o">=</span><span class="s1">&#39;type_1&#39;</span><span class="o">)</span> SELECT <span class="s1">&#39;Tom&#39;</span>, 25, <span class="s1">&#39;2019-08-08&#39;</span><span class="p">;</span>
</code></pre></div><h2 id="格式">格式</h2>
<p>我们测试了以下表格存储格式：文本、csv、SequenceFile、ORC 和 Parquet。</p>
<h2 id="优化">优化</h2>
<h3 id="分区修剪">分区修剪</h3>
<p>Flink 使用分区修剪作为一种性能优化，以限制 Flink 在查询 Hive 表时读取的文件和分区的数量。当你的数据被分区后，当查询符合某些过滤条件时，Flink 只会读取 Hive 表中的分区子集。</p>
<h3 id="投影下推">投影下推</h3>
<p>Flink 利用投影下推，通过从表扫描中省略不必要的字段，最大限度地减少 Flink 和 Hive 表之间的数据传输。</p>
<p>当一个表包含许多列时，它尤其有利。</p>
<h3 id="限制下推">限制下推</h3>
<p>对于带有 LIMIT 子句的查询，Flink 会尽可能地限制输出记录的数量，以减少跨网络传输的数据量。</p>
<h3 id="读取时的向量优化">读取时的向量优化</h3>
<p>当满足以下条件时，会自动使用优化功能。</p>
<ul>
<li>格式： ORC 或 Parquet。</li>
<li>没有复杂数据类型的列，如 hive 类型: List, Map, Struct, Union。</li>
</ul>
<p>这个功能默认是开启的。如果出现问题，可以使用这个配置选项来关闭 Vectorized Optimization。</p>
<pre><code>table.exec.hive.fallback-mapred-reader=true
</code></pre><h3 id="source-并行性推断">Source 并行性推断</h3>
<p>默认情况下，Flink 根据分割次数来推断 hive 源的并行度，分割次数是根据文件的数量和文件中的块数来推断的。</p>
<p>Flink 允许你灵活配置并行度推断的策略。你可以在 TableConfig 中配置以下参数（注意，这些参数会影响作业的所有源）。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">table.exec.hive.infer-source-parallelism</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">如果为真，则根据分割数来推断源的并行度，如果为假，则根据配置来设置源的并行度。如果为 false，则通过配置来设置源的并行度。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.hive.infer-source-parallelism.max</td>
<td style="text-align:left">1000</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">设置源运算符的最大推断并行度。</td>
</tr>
</tbody>
</table>
<h2 id="路线图">路线图</h2>
<p>我们正在规划并积极开发支持功能，如:</p>
<ul>
<li>ACID 表</li>
<li>分桶表</li>
<li>更多格式</li>
</ul>
<p>更多功能需求请联系社区 <a href="https://flink.apache.org/community.html#mailing-lists">https://flink.apache.org/community.html#mailing-lists</a></p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_read_write.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_read_write.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hive" term="hive" label="Hive" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hive Streaming]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="related" type="text/html" title="HiveCatalog" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Hive Streaming</blockquote><h1 id="hive-流">Hive 流</h1>
<p>一个典型的 hive 作业是周期性地安排执行的，所以会有较大的延迟。</p>
<p>Flink 支持以流式的形式写入、读取和加入 hive 表。</p>
<p>流式数据有三种类型。</p>
<ul>
<li>将流式数据写入 Hive 表。</li>
<li>以流的形式增量读取 Hive 表。</li>
<li>流式表使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">Temporal 表</a>连接 Hive 表。</li>
</ul>
<h2 id="流式写入">流式写入</h2>
<p>Hive 表支持流式写入，基于 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#streaming-sink">Filesystem Streaming Sink</a>。</p>
<p>Hive Streaming Sink 重用 Filesystem Streaming Sink，将 Hadoop OutputFormat/RecordWriter 整合到流式写入。Hadoop RecordWriters 是 Bulk-encoded Formats，Bulk Formats 在每个检查点上滚动文件。</p>
<p>默认情况下，现在只有重命名提交者，这意味着 S3 文件系统不能支持精确的 once，如果你想在 S3 文件系统中使用 Hive 流媒体汇，你可以在 TableConfig 中把以下参数配置为 false，以使用 Flink 原生写入器（只对 parquet 和 orc 有效）（注意这些参数会影响所有作业的汇）。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">table.exec.hive.fallback-mapred-writer</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">如果是假的，用 flink native writer 写 parquet 和 orc 文件；如果是真的，用 hadoop mapred record writer 写 parquet 和 orc 文件。</td>
</tr>
</tbody>
</table>
<p>下面展示了如何使用流接收器写一个流式查询，将数据从 Kafka 写到一个有 partition-commit 的 Hive 表中，并运行一个批处理查询将这些数据读回。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SET</span> <span class="k">table</span><span class="p">.</span><span class="k">sql</span><span class="o">-</span><span class="n">dialect</span><span class="o">=</span><span class="n">hive</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">hive_table</span> <span class="p">(</span>
  <span class="n">user_id</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">order_amount</span> <span class="n">DOUBLE</span>
<span class="p">)</span> <span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">dt</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">hr</span> <span class="n">STRING</span><span class="p">)</span> <span class="n">STORED</span> <span class="k">AS</span> <span class="n">parquet</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
  <span class="s1">&#39;partition.time-extractor.timestamp-pattern&#39;</span><span class="o">=</span><span class="s1">&#39;$dt $hr:00:00&#39;</span><span class="p">,</span>
  <span class="s1">&#39;sink.partition-commit.trigger&#39;</span><span class="o">=</span><span class="s1">&#39;partition-time&#39;</span><span class="p">,</span>
  <span class="s1">&#39;sink.partition-commit.delay&#39;</span><span class="o">=</span><span class="s1">&#39;1 h&#39;</span><span class="p">,</span>
  <span class="s1">&#39;sink.partition-commit.policy.kind&#39;</span><span class="o">=</span><span class="s1">&#39;metastore,success-file&#39;</span>
<span class="p">);</span>

<span class="k">SET</span> <span class="k">table</span><span class="p">.</span><span class="k">sql</span><span class="o">-</span><span class="n">dialect</span><span class="o">=</span><span class="k">default</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_table</span> <span class="p">(</span>
  <span class="n">user_id</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">order_amount</span> <span class="n">DOUBLE</span><span class="p">,</span>
  <span class="n">log_ts</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
  <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">log_ts</span> <span class="k">AS</span> <span class="n">log_ts</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(...);</span>

<span class="c1">-- streaming sql, insert into hive table
</span><span class="c1"></span><span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">hive_table</span> <span class="k">SELECT</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">order_amount</span><span class="p">,</span> <span class="n">DATE_FORMAT</span><span class="p">(</span><span class="n">log_ts</span><span class="p">,</span> <span class="s1">&#39;yyyy-MM-dd&#39;</span><span class="p">),</span> <span class="n">DATE_FORMAT</span><span class="p">(</span><span class="n">log_ts</span><span class="p">,</span> <span class="s1">&#39;HH&#39;</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">kafka_table</span><span class="p">;</span>

<span class="c1">-- batch sql, select with partition pruning
</span><span class="c1"></span><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive_table</span> <span class="k">WHERE</span> <span class="n">dt</span><span class="o">=</span><span class="s1">&#39;2020-05-20&#39;</span> <span class="k">and</span> <span class="n">hr</span><span class="o">=</span><span class="s1">&#39;12&#39;</span><span class="p">;</span>
</code></pre></div><h2 id="流式读取">流式读取</h2>
<p>为了提高 hive 读取的实时性，Flink 支持实时 Hive 表流读取。</p>
<ul>
<li>分区表，监控分区的生成，并逐步读取新分区。</li>
<li>非分区表，监控文件夹中新文件的生成，并增量读取新文件。</li>
</ul>
<p>甚至可以采用 10 分钟级别的分区策略，利用 Flink 的 Hive 流式读取和 Hive 流式写入，大大提高 Hive 数据仓库的实时性能，达到准实时分钟级别。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">streaming-source.enable</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">是否启用流媒体源。注意：请确保每个分区/文件都是以原子方式写入，否则读者可能会得到不完整的数据。请确保每个分区/文件都应该以原子方式写入，否则读者可能会得到不完整的数据。</td>
</tr>
<tr>
<td style="text-align:left">streaming-source.monitor-interval</td>
<td style="text-align:left">1 m</td>
<td style="text-align:left">Duration</td>
<td style="text-align:left">连续监控分区/文件的时间间隔。</td>
</tr>
<tr>
<td style="text-align:left">streaming-source.consume-order</td>
<td style="text-align:left">create-time</td>
<td style="text-align:left">String</td>
<td style="text-align:left">流源的消耗顺序，支持 create-time 和 partition-time。create-time 比较的是分区/文件的创建时间，这不是 Hive metaStore 中的分区创建时间，而是文件系统中的文件夹/文件修改时间；partition-time 比较的是分区名称所代表的时间，如果分区文件夹以某种方式得到更新，比如在文件夹中添加新文件，就会影响数据的消耗方式。对于非分区表，这个值应该一直是 &ldquo;创建时间&rdquo;。</td>
</tr>
<tr>
<td style="text-align:left">streaming-source.consume-start-offset</td>
<td style="text-align:left">1970-00-00</td>
<td style="text-align:left">String</td>
<td style="text-align:left">流式消费的起始偏移量。如何解析和比较偏移量取决于你的顺序。对于创建时间和分区时间，应该是一个时间戳字符串（yyyy-[m]m-[d]d [hh:mm:ss]）。对于分区时间，将使用分区时间提取器从分区中提取时间。</td>
</tr>
</tbody>
</table>
<p>注意:</p>
<ul>
<li>监控策略是现在扫描位置路径中的所有目录/文件。如果分区太多，会出现性能问题。</li>
<li>非分区的流式读取需要将每个文件原子地放入目标目录中。</li>
<li>分区的流式读取要求在 hive metastore 的视图中原子地添加每个分区。这意味着新添加到现有分区的数据不会被消耗掉。</li>
<li>流读取不支持 Flink DDL 中的水印语法。所以它不能用于窗口操作符。</li>
</ul>
<p>下面展示了如何增量读取 Hive 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive_table</span> <span class="cm">/*+ OPTIONS(&#39;streaming-source.enable&#39;=&#39;true&#39;, &#39;streaming-source.consume-start-offset&#39;=&#39;2020-05-20&#39;) */</span><span class="p">;</span>
</code></pre></div><h2 id="hive-表作为临时表">Hive 表作为临时表</h2>
<p>您可以使用 Hive 表作为时态表，并将流式数据加入其中。请按照<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">示例</a>来了解如何连接一个时态表。</p>
<p>在执行 join 时，Hive 表将被缓存在 TM 内存中，并在 Hive 表中查找来自流的每一条记录，以决定是否找到匹配。你不需要任何额外的设置就可以使用 Hive 表作为时态表。但可以选择用以下属性配置 Hive 表缓存的 TTL。缓存过期后，将再次扫描 Hive 表以加载最新的数据。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">lookup.join.cache.ttl</td>
<td style="text-align:left">60 min</td>
<td style="text-align:left">Duration</td>
<td style="text-align:left">在查找连接中构建表的缓存 TTL（例如 10 分钟）。默认情况下，TTL 为 60 分钟。</td>
</tr>
</tbody>
</table>
<p>注意:</p>
<ol>
<li>每个加入子任务都需要保留自己的 Hive 表的缓存。请确保 Hive 表可以放入 TM 任务槽的内存中。</li>
<li>你应该为 lookup.join.cache.ttl 设置一个相对较大的值。如果你的 Hive 表需要太频繁的更新和重载，你可能会有性能问题。</li>
<li>目前，每当缓存需要刷新时，我们只是简单地加载整个 Hive 表。没有办法区分新数据和旧数据。</li>
</ol>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_streaming.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_streaming.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hive" term="hive" label="Hive" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hive 函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="related" type="text/html" title="HiveCatalog" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Hive Functions</blockquote><h1 id="hive-函数">Hive 函数</h1>
<h2 id="通过-hivemodule-使用-hive-内置功能">通过 HiveModule 使用 Hive 内置功能</h2>
<p>HiveModule 将 Hive 内置函数作为 Flink 系统（内置）函数提供给 Flink SQL 和 Table API 用户。</p>
<p>具体信息请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/modules.html#hivemodule">HiveModule</a>。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">name</span>            <span class="k">=</span> <span class="s">&#34;myhive&#34;</span>
<span class="k">val</span> <span class="n">version</span>         <span class="k">=</span> <span class="s">&#34;2.3.4&#34;</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">loadModue</span><span class="o">(</span><span class="n">name</span><span class="o">,</span> <span class="k">new</span> <span class="nc">HiveModule</span><span class="o">(</span><span class="n">version</span><span class="o">));</span>
</code></pre></div><ul>
<li>YAML</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">modules</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">core</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">core</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">myhive</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span></code></pre></div><ul>
<li>注意，旧版本中的一些 Hive 内置功能存在<a href="https://issues.apache.org/jira/browse/HIVE-16183">线程安全问题</a>。我们建议用户给自己的 Hive 打上补丁来修复它们。</li>
</ul>
<h2 id="hive-用户定义的函数">Hive 用户定义的函数</h2>
<p>用户可以在 Flink 中使用他们现有的 Hive 用户定义函数。</p>
<p>支持的 UDF 类型包括:</p>
<ul>
<li>UDF</li>
<li>GenericUDF</li>
<li>GenericUDTF</li>
<li>UDAF</li>
<li>GenericUDAFResolver2</li>
</ul>
<p>在查询规划和执行时，Hive 的 UDF 和 GenericUDF 会自动翻译成 Flink 的 ScalarFunction，Hive 的 GenericUDTF 会自动翻译成 Flink 的 TableFunction，Hive 的 UDAF 和 GenericUDAFResolver2 会翻译成 Flink 的 AggregateFunction。</p>
<p>要使用 Hive 的用户定义函数，用户必须做到:</p>
<ul>
<li>设置一个由 Hive Metastore 支持的 HiveCatalog 作为会话的当前目录，其中包含该函数。</li>
<li>在 Flink 的 classpath 中加入一个包含该函数的 jar。</li>
<li>使用 Blink 计划器。</li>
</ul>
<h2 id="使用-hive-用户定义函数">使用 Hive 用户定义函数</h2>
<p>假设我们在 Hive Metastore 中注册了以下 Hive 函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * Test simple udf. Registered under name &#39;myudf&#39;
</span><span class="cm"> */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">TestHiveSimpleUDF</span> <span class="kd">extends</span> <span class="n">UDF</span> <span class="o">{</span>

	<span class="kd">public</span> <span class="n">IntWritable</span> <span class="nf">evaluate</span><span class="o">(</span><span class="n">IntWritable</span> <span class="n">i</span><span class="o">)</span> <span class="o">{</span>
		<span class="k">return</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="n">i</span><span class="o">.</span><span class="na">get</span><span class="o">());</span>
	<span class="o">}</span>

	<span class="kd">public</span> <span class="n">Text</span> <span class="nf">evaluate</span><span class="o">(</span><span class="n">Text</span> <span class="n">text</span><span class="o">)</span> <span class="o">{</span>
		<span class="k">return</span> <span class="k">new</span> <span class="n">Text</span><span class="o">(</span><span class="n">text</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * Test generic udf. Registered under name &#39;mygenericudf&#39;
</span><span class="cm"> */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">TestHiveGenericUDF</span> <span class="kd">extends</span> <span class="n">GenericUDF</span> <span class="o">{</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="n">ObjectInspector</span> <span class="nf">initialize</span><span class="o">(</span><span class="n">ObjectInspector</span><span class="o">[]</span> <span class="n">arguments</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">UDFArgumentException</span> <span class="o">{</span>
		<span class="n">checkArgument</span><span class="o">(</span><span class="n">arguments</span><span class="o">.</span><span class="na">length</span> <span class="o">==</span> <span class="n">2</span><span class="o">);</span>

		<span class="n">checkArgument</span><span class="o">(</span><span class="n">arguments</span><span class="o">[</span><span class="n">1</span><span class="o">]</span> <span class="k">instanceof</span> <span class="n">ConstantObjectInspector</span><span class="o">);</span>
		<span class="n">Object</span> <span class="n">constant</span> <span class="o">=</span> <span class="o">((</span><span class="n">ConstantObjectInspector</span><span class="o">)</span> <span class="n">arguments</span><span class="o">[</span><span class="n">1</span><span class="o">]).</span><span class="na">getWritableConstantValue</span><span class="o">();</span>
		<span class="n">checkArgument</span><span class="o">(</span><span class="n">constant</span> <span class="k">instanceof</span> <span class="n">IntWritable</span><span class="o">);</span>
		<span class="n">checkArgument</span><span class="o">(((</span><span class="n">IntWritable</span><span class="o">)</span> <span class="n">constant</span><span class="o">).</span><span class="na">get</span><span class="o">()</span> <span class="o">==</span> <span class="n">1</span><span class="o">);</span>

		<span class="k">if</span> <span class="o">(</span><span class="n">arguments</span><span class="o">[</span><span class="n">0</span><span class="o">]</span> <span class="k">instanceof</span> <span class="n">IntObjectInspector</span> <span class="o">||</span>
				<span class="n">arguments</span><span class="o">[</span><span class="n">0</span><span class="o">]</span> <span class="k">instanceof</span> <span class="n">StringObjectInspector</span><span class="o">)</span> <span class="o">{</span>
			<span class="k">return</span> <span class="n">arguments</span><span class="o">[</span><span class="n">0</span><span class="o">];</span>
		<span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
			<span class="k">throw</span> <span class="k">new</span> <span class="n">RuntimeException</span><span class="o">(</span><span class="s">&#34;Not support argument: &#34;</span> <span class="o">+</span> <span class="n">arguments</span><span class="o">[</span><span class="n">0</span><span class="o">]);</span>
		<span class="o">}</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="n">Object</span> <span class="nf">evaluate</span><span class="o">(</span><span class="n">DeferredObject</span><span class="o">[]</span> <span class="n">arguments</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">HiveException</span> <span class="o">{</span>
		<span class="k">return</span> <span class="n">arguments</span><span class="o">[</span><span class="n">0</span><span class="o">].</span><span class="na">get</span><span class="o">();</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="n">String</span> <span class="nf">getDisplayString</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">children</span><span class="o">)</span> <span class="o">{</span>
		<span class="k">return</span> <span class="s">&#34;TestHiveGenericUDF&#34;</span><span class="o">;</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * Test split udtf. Registered under name &#39;mygenericudtf&#39;
</span><span class="cm"> */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">TestHiveUDTF</span> <span class="kd">extends</span> <span class="n">GenericUDTF</span> <span class="o">{</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="n">StructObjectInspector</span> <span class="nf">initialize</span><span class="o">(</span><span class="n">ObjectInspector</span><span class="o">[]</span> <span class="n">argOIs</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">UDFArgumentException</span> <span class="o">{</span>
		<span class="n">checkArgument</span><span class="o">(</span><span class="n">argOIs</span><span class="o">.</span><span class="na">length</span> <span class="o">==</span> <span class="n">2</span><span class="o">);</span>

		<span class="c1">// TEST for constant arguments
</span><span class="c1"></span>		<span class="n">checkArgument</span><span class="o">(</span><span class="n">argOIs</span><span class="o">[</span><span class="n">1</span><span class="o">]</span> <span class="k">instanceof</span> <span class="n">ConstantObjectInspector</span><span class="o">);</span>
		<span class="n">Object</span> <span class="n">constant</span> <span class="o">=</span> <span class="o">((</span><span class="n">ConstantObjectInspector</span><span class="o">)</span> <span class="n">argOIs</span><span class="o">[</span><span class="n">1</span><span class="o">]).</span><span class="na">getWritableConstantValue</span><span class="o">();</span>
		<span class="n">checkArgument</span><span class="o">(</span><span class="n">constant</span> <span class="k">instanceof</span> <span class="n">IntWritable</span><span class="o">);</span>
		<span class="n">checkArgument</span><span class="o">(((</span><span class="n">IntWritable</span><span class="o">)</span> <span class="n">constant</span><span class="o">).</span><span class="na">get</span><span class="o">()</span> <span class="o">==</span> <span class="n">1</span><span class="o">);</span>

		<span class="k">return</span> <span class="n">ObjectInspectorFactory</span><span class="o">.</span><span class="na">getStandardStructObjectInspector</span><span class="o">(</span>
			<span class="n">Collections</span><span class="o">.</span><span class="na">singletonList</span><span class="o">(</span><span class="s">&#34;col1&#34;</span><span class="o">),</span>
			<span class="n">Collections</span><span class="o">.</span><span class="na">singletonList</span><span class="o">(</span><span class="n">PrimitiveObjectInspectorFactory</span><span class="o">.</span><span class="na">javaStringObjectInspector</span><span class="o">));</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">Object</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">HiveException</span> <span class="o">{</span>
		<span class="n">String</span> <span class="n">str</span> <span class="o">=</span> <span class="o">(</span><span class="n">String</span><span class="o">)</span> <span class="n">args</span><span class="o">[</span><span class="n">0</span><span class="o">];</span>
		<span class="k">for</span> <span class="o">(</span><span class="n">String</span> <span class="n">s</span> <span class="o">:</span> <span class="n">str</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&#34;,&#34;</span><span class="o">))</span> <span class="o">{</span>
			<span class="n">forward</span><span class="o">(</span><span class="n">s</span><span class="o">);</span>
			<span class="n">forward</span><span class="o">(</span><span class="n">s</span><span class="o">);</span>
		<span class="o">}</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">close</span><span class="o">()</span> <span class="o">{</span>
	<span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>从 Hive CLI 中，我们可以看到他们已经注册了。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">hive&gt; show functions<span class="p">;</span>
OK
......
mygenericudf
myudf
myudtf
</code></pre></div><p>然后，用户可以在 SQL 中使用它们作为。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; <span class="k">select</span> mygenericudf<span class="o">(</span>myudf<span class="o">(</span>name<span class="o">)</span>, 1<span class="o">)</span> as a, mygenericudf<span class="o">(</span>myudf<span class="o">(</span>age<span class="o">)</span>, 1<span class="o">)</span> as b, s from mysourcetable, lateral table<span class="o">(</span>myudtf<span class="o">(</span>name, 1<span class="o">))</span> as T<span class="o">(</span>s<span class="o">)</span><span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_functions.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_functions.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hive" term="hive" label="Hive" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hive 方言]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="related" type="text/html" title="HiveCatalog" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Hive Dialect</blockquote><h1 id="hive-方言">Hive 方言</h1>
<p>从 1.11.0 开始，当使用 Hive 方言时，Flink 允许用户用 Hive 语法编写 SQL 语句。通过提供与 Hive 语法的兼容性，我们旨在提高与 Hive 的互操作性，减少用户为了执行不同的语句而需要在 Flink 和 Hive 之间切换的情况。</p>
<h2 id="使用-hive-方言">使用 Hive 方言</h2>
<p>Flink 目前支持两种 SQL 方言：默认和 Hive。在使用 Hive 语法编写之前，需要先切换到 Hive 方言。下面介绍如何通过 SQL Client 和 Table API 来设置方言。同时注意，你可以为你执行的每一条语句动态切换方言。不需要重新启动会话来使用不同的方言。</p>
<h3 id="sql-客户端">SQL 客户端</h3>
<p>SQL 方言可以通过 table.sql-dialect 属性来指定，因此你可以在你的 SQL 客户端的 yaml 文件的配置部分设置初始方言。因此，你可以在 SQL 客户端的 yaml 文件的配置部分设置要使用的初始方言。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">execution</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">planner</span><span class="p">:</span><span class="w"> </span><span class="l">blink</span><span class="w">
</span><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">batch</span><span class="w">
</span><span class="w">  </span><span class="nt">result-mode</span><span class="p">:</span><span class="w"> </span><span class="l">table</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">configuration</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">table.sql-dialect</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span></code></pre></div><p>你也可以在 SQL 客户端启动后设置方言。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; <span class="nb">set</span> table.sql-dialect<span class="o">=</span>hive<span class="p">;</span> -- to use hive dialect
<span class="o">[</span>INFO<span class="o">]</span> Session property has been set.

Flink SQL&gt; <span class="nb">set</span> table.sql-dialect<span class="o">=</span>default<span class="p">;</span> -- to use default dialect
<span class="o">[</span>INFO<span class="o">]</span> Session property has been set.
</code></pre></div><h3 id="table-api">Table API</h3>
<p>You can set dialect for your TableEnvironment with Table API.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">settings</span> <span class="o">=</span> <span class="n">EnvironmentSettings</span><span class="o">.</span><span class="n">new_instance</span><span class="p">()</span><span class="o">.</span><span class="n">in_batch_mode</span><span class="p">()</span><span class="o">.</span><span class="n">use_blink_planner</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">environment_settings</span><span class="o">=</span><span class="n">settings</span><span class="p">)</span>

<span class="c1"># to use hive dialect</span>
<span class="n">t_env</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">set_sql_dialect</span><span class="p">(</span><span class="n">SqlDialect</span><span class="o">.</span><span class="n">HIVE</span><span class="p">)</span>
<span class="c1"># to use default dialect</span>
<span class="n">t_env</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">set_sql_dialect</span><span class="p">(</span><span class="n">SqlDialect</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span>
</code></pre></div><h2 id="ddl">DDL</h2>
<p>本节列出了 Hive 方言支持的 DDL。在这里我们将主要关注语法。关于每个 DDL 语句的语义，你可以参考 <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">Hive 文档</a>。</p>
<h3 id="database">DATABASE</h3>
<ul>
<li>Show</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">DATABASES</span><span class="p">;</span>
</code></pre></div><ul>
<li>Create</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">database_name</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">database_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">fs_path</span><span class="p">]</span>
  <span class="p">[</span><span class="k">WITH</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)];</span>
</code></pre></div><ul>
<li>Alter</li>
</ul>
<p>更新属性</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...);</span>
</code></pre></div><p>更新所有者</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="k">OWNER</span> <span class="p">[</span><span class="k">USER</span><span class="o">|</span><span class="k">ROLE</span><span class="p">]</span> <span class="n">user_or_role</span><span class="p">;</span>
</code></pre></div><p>更新位置</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="k">LOCATION</span> <span class="n">fs_path</span><span class="p">;</span>
</code></pre></div><ul>
<li>Drop</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">database_name</span> <span class="p">[</span><span class="k">RESTRICT</span><span class="o">|</span><span class="k">CASCADE</span><span class="p">];</span>
</code></pre></div><ul>
<li>Use</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">USE</span> <span class="n">database_name</span><span class="p">;</span>
</code></pre></div><h3 id="table">TABLE</h3>
<ul>
<li>Show</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">TABLES</span><span class="p">;</span>
</code></pre></div><ul>
<li>Create</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">[</span><span class="k">EXTERNAL</span><span class="p">]</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="k">table_name</span>
  <span class="p">[(</span><span class="n">col_name</span> <span class="n">data_type</span> <span class="p">[</span><span class="n">column_constraint</span><span class="p">]</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...</span> <span class="p">[</span><span class="n">table_constraint</span><span class="p">])]</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">table_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name</span> <span class="n">data_type</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...)]</span>
  <span class="p">[</span>
    <span class="p">[</span><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">row_format</span><span class="p">]</span>
    <span class="p">[</span><span class="n">STORED</span> <span class="k">AS</span> <span class="n">file_format</span><span class="p">]</span>
  <span class="p">]</span>
  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">fs_path</span><span class="p">]</span>
  <span class="p">[</span><span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)]</span>
  
<span class="n">row_format</span><span class="p">:</span>
  <span class="p">:</span> <span class="n">DELIMITED</span> <span class="p">[</span><span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="nb">char</span> <span class="p">[</span><span class="n">ESCAPED</span> <span class="k">BY</span> <span class="nb">char</span><span class="p">]]</span> <span class="p">[</span><span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="nb">char</span><span class="p">]</span>
      <span class="p">[</span><span class="k">MAP</span> <span class="n">KEYS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="nb">char</span><span class="p">]</span> <span class="p">[</span><span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="nb">char</span><span class="p">]</span>
      <span class="p">[</span><span class="k">NULL</span> <span class="k">DEFINED</span> <span class="k">AS</span> <span class="nb">char</span><span class="p">]</span>
  <span class="o">|</span> <span class="n">SERDE</span> <span class="n">serde_name</span> <span class="p">[</span><span class="k">WITH</span> <span class="n">SERDEPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)]</span>
  
<span class="n">file_format</span><span class="p">:</span>
  <span class="p">:</span> <span class="n">SEQUENCEFILE</span>
  <span class="o">|</span> <span class="n">TEXTFILE</span>
  <span class="o">|</span> <span class="n">RCFILE</span>
  <span class="o">|</span> <span class="n">ORC</span>
  <span class="o">|</span> <span class="n">PARQUET</span>
  <span class="o">|</span> <span class="n">AVRO</span>
  <span class="o">|</span> <span class="n">INPUTFORMAT</span> <span class="n">input_format_classname</span> <span class="n">OUTPUTFORMAT</span> <span class="n">output_format_classname</span>
  
<span class="n">column_constraint</span><span class="p">:</span>
  <span class="p">:</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="p">[[</span><span class="n">ENABLE</span><span class="o">|</span><span class="n">DISABLE</span><span class="p">]</span> <span class="p">[</span><span class="n">VALIDATE</span><span class="o">|</span><span class="n">NOVALIDATE</span><span class="p">]</span> <span class="p">[</span><span class="n">RELY</span><span class="o">|</span><span class="n">NORELY</span><span class="p">]]</span>
  
<span class="n">table_constraint</span><span class="p">:</span>
  <span class="p">:</span> <span class="p">[</span><span class="k">CONSTRAINT</span> <span class="k">constraint_name</span><span class="p">]</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span> <span class="p">[[</span><span class="n">ENABLE</span><span class="o">|</span><span class="n">DISABLE</span><span class="p">]</span> <span class="p">[</span><span class="n">VALIDATE</span><span class="o">|</span><span class="n">NOVALIDATE</span><span class="p">]</span> <span class="p">[</span><span class="n">RELY</span><span class="o">|</span><span class="n">NORELY</span><span class="p">]]</span>
</code></pre></div><ul>
<li>Alter</li>
</ul>
<p>重命名</p>
<pre><code class="language-ssql" data-lang="ssql">ALTER TABLE table_name RENAME TO new_table_name;
</code></pre><p>更新属性</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="p">...</span> <span class="p">);</span>
</code></pre></div><p>更新位置</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">]</span> <span class="k">SET</span> <span class="k">LOCATION</span> <span class="n">fs_path</span><span class="p">;</span>
</code></pre></div><p>partition_spec 如果存在，需要是一个完整的规格，即有所有分区列的值。而当它存在时，操作将被应用到相应的分区而不是表。</p>
<p>更新文件格式</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">]</span> <span class="k">SET</span> <span class="n">FILEFORMAT</span> <span class="n">file_format</span><span class="p">;</span>
</code></pre></div><p>partition_spec 如果存在，需要是一个完整的规格，即有所有分区列的值。而当它存在时，操作将被应用到相应的分区而不是表。</p>
<p>更新 SerDe 属性</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">]</span> <span class="k">SET</span> <span class="n">SERDE</span> <span class="n">serde_class_name</span> <span class="p">[</span><span class="k">WITH</span> <span class="n">SERDEPROPERTIES</span> <span class="n">serde_properties</span><span class="p">];</span>
 
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">]</span> <span class="k">SET</span> <span class="n">SERDEPROPERTIES</span> <span class="n">serde_properties</span><span class="p">;</span>
 
<span class="n">serde_properties</span><span class="p">:</span>
  <span class="p">:</span> <span class="p">(</span><span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="p">...</span> <span class="p">)</span>
</code></pre></div><p>partition_spec 如果存在，需要是一个完整的规格，即有所有分区列的值。而当它存在时，操作将被应用到相应的分区而不是表。</p>
<p>添加分区</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="k">ADD</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">(</span><span class="n">PARTITION</span> <span class="n">partition_spec</span> <span class="p">[</span><span class="k">LOCATION</span> <span class="n">fs_path</span><span class="p">])</span><span class="o">+</span><span class="p">;</span>
</code></pre></div><ul>
<li>Drop Partitions</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="k">DROP</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">[,</span> <span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">,</span> <span class="p">...];</span>
</code></pre></div><ul>
<li>新增/替换 列</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span>
  <span class="k">ADD</span><span class="o">|</span><span class="k">REPLACE</span> <span class="n">COLUMNS</span> <span class="p">(</span><span class="n">col_name</span> <span class="n">data_type</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...)</span>
  <span class="p">[</span><span class="k">CASCADE</span><span class="o">|</span><span class="k">RESTRICT</span><span class="p">]</span>
</code></pre></div><ul>
<li>Change Column</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="n">CHANGE</span> <span class="p">[</span><span class="k">COLUMN</span><span class="p">]</span> <span class="n">col_old_name</span> <span class="n">col_new_name</span> <span class="n">column_type</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">]</span> <span class="p">[</span><span class="k">FIRST</span><span class="o">|</span><span class="k">AFTER</span> <span class="k">column_name</span><span class="p">]</span> <span class="p">[</span><span class="k">CASCADE</span><span class="o">|</span><span class="k">RESTRICT</span><span class="p">];</span>
</code></pre></div><ul>
<li>Drop</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="k">table_name</span><span class="p">;</span>
</code></pre></div><h2 id="view">VIEW</h2>
<ul>
<li>Create</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">view_name</span> <span class="p">[(</span><span class="k">column_name</span><span class="p">,</span> <span class="p">...)</span> <span class="p">]</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">view_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="p">...)]</span>
  <span class="k">AS</span> <span class="k">SELECT</span> <span class="p">...;</span>
</code></pre></div><ul>
<li>Alter</li>
</ul>
<p>注意：改变视图只在表 API 中工作，但不支持通过 SQL 客户端。</p>
<p>重命名</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">VIEW</span> <span class="n">view_name</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">new_view_name</span><span class="p">;</span>
</code></pre></div><p>更新属性</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">VIEW</span> <span class="n">view_name</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span> <span class="o">=</span> <span class="n">property_value</span><span class="p">,</span> <span class="p">...</span> <span class="p">);</span>
</code></pre></div><ul>
<li>Update As Select</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">VIEW</span> <span class="n">view_name</span> <span class="k">AS</span> <span class="n">select_statement</span><span class="p">;</span>
</code></pre></div><ul>
<li>Drop</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">VIEW</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">view_name</span><span class="p">;</span>
</code></pre></div><h2 id="function">FUNCTION</h2>
<ul>
<li>Show</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">FUNCTIONS</span><span class="p">;</span>
</code></pre></div><ul>
<li>Create</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">FUNCTION</span> <span class="n">function_name</span> <span class="k">AS</span> <span class="n">class_name</span><span class="p">;</span>
</code></pre></div><p>Drop</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">FUNCTION</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">function_name</span><span class="p">;</span>
</code></pre></div><h2 id="dml">DML</h2>
<h3 id="nsert">NSERT</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="p">(</span><span class="k">INTO</span><span class="o">|</span><span class="n">OVERWRITE</span><span class="p">)</span> <span class="p">[</span><span class="k">TABLE</span><span class="p">]</span> <span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">partition_spec</span><span class="p">]</span> <span class="k">SELECT</span> <span class="p">...;</span>
</code></pre></div><p>partition_spec，如果存在的话，可以是完整规格或部分规格。如果 partition_spec 是部分规格，动态分区列名可以省略。</p>
<h2 id="dql">DQL</h2>
<p>目前，Hive 方言支持的 DQL 语法与 Flink SQL 相同。详情请参考 Flink SQL 查询。而且建议切换到默认方言来执行 DQL。</p>
<h2 id="注意事项">注意事项</h2>
<p>以下是使用 Hive 方言的一些注意事项。</p>
<ul>
<li>Hive 方言只能用于操作 Hive 表，而不是通用表。而且 Hive 方言应该和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html">HiveCatalog</a> 一起使用。</li>
<li>虽然所有的 Hive 版本都支持相同的语法，但是否有特定的功能还是取决于你使用的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#supported-hive-versions">Hive 版本</a>。例如，更新数据库位置只在 Hive-2.4.0 或更高版本中支持。</li>
<li>Hive 和 Calcite 有不同的保留关键字集。例如，在 Calcite 中默认是保留关键字，而在 Hive 中是非保留关键字。即使是 Hive 方言，你也必须用反引号（`）来引用这些关键字，才能将它们作为标识符使用。</li>
<li>由于扩展查询不兼容，在 Flink 中创建的视图不能在 Hive 中查询。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_dialect.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_dialect.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hive" term="hive" label="Hive" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hive 集成 - 概览]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="related" type="text/html" title="HiveCatalog" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Overview</blockquote><h1 id="hive-集成">Hive 集成</h1>
<p>Apache Hive 已经确立了自己作为数据仓库生态系统的焦点。它不仅是大数据分析和 ETL 的 SQL 引擎，也是一个数据管理平台，在这里，数据被发现、定义和发展。</p>
<p>Flink 与 Hive 提供了两方面的整合。</p>
<p>第一是利用 Hive 的 Metastore 作为一个持久性目录，与 Flink 的 HiveCatalog 进行跨会话存储 Flink 特定的元数据。例如，用户可以通过使用 HiveCatalog 将 Kafka 或 ElasticSearch 表存储在 Hive Metastore 中，并在以后的 SQL 查询中重复使用。</p>
<p>二是提供 Flink 作为读写 Hive 表的替代引擎。</p>
<p>HiveCatalog 的设计是 &ldquo;开箱即用&rdquo;，与现有的 Hive 安装兼容。您不需要修改现有的 Hive Metastore，也不需要改变数据位置或表的分区。</p>
<h2 id="支持的-hive-版本">支持的 Hive 版本</h2>
<p>Flink 支持以下 Hive 版本。</p>
<ul>
<li>1.0
<ul>
<li>1.0.0</li>
<li>1.0.1</li>
</ul>
</li>
<li>1.1
<ul>
<li>1.1.0</li>
<li>1.1.1</li>
</ul>
</li>
<li>1.2
<ul>
<li>1.2.0</li>
<li>1.2.1</li>
<li>1.2.2</li>
</ul>
</li>
<li>2.0
<ul>
<li>2.0.0</li>
<li>2.0.1</li>
</ul>
</li>
<li>2.1
<ul>
<li>2.1.0</li>
<li>2.1.1</li>
</ul>
</li>
<li>2.2
<ul>
<li>2.2.0</li>
</ul>
</li>
<li>2.3
<ul>
<li>2.3.0</li>
<li>2.3.1</li>
<li>2.3.2</li>
<li>2.3.3</li>
<li>2.3.4</li>
<li>2.3.5</li>
<li>2.3.6</li>
</ul>
</li>
<li>3.1
<ul>
<li>3.1.0</li>
<li>3.1.1</li>
<li>3.1.2</li>
</ul>
</li>
</ul>
<p>请注意 Hive 本身在不同的版本有不同的功能，这些问题不是 Flink 造成的。</p>
<ul>
<li>1.2.0 及以后版本支持 Hive 内置函数。</li>
<li>3.1.0 及以后版本支持列约束，即 PRIMARY KEY 和 NOT NULL。</li>
<li>在 1.2.0 及以后的版本中，支持修改表的统计数据。</li>
<li>在 1.2.0 及以后的版本中支持 DATE 列统计。</li>
<li>在 2.0.x 中不支持写入 ORC 表。</li>
</ul>
<h3 id="依赖性">依赖性</h3>
<p>为了与 Hive 集成，你需要在 Flink 发行版的 <code>/lib/</code> 目录下添加一些额外的依赖关系，以使集成工作在 Table API 程序或 SQL 客户端中。另外，你也可以将这些依赖项放在一个专门的文件夹中，并分别用 <code>-C</code> 或 <code>-l</code> 选项将它们添加到 <code>classpath</code> 中，用于 Table API 程序或 SQL Client。</p>
<p>Apache Hive 是建立在 Hadoop 上的，所以首先需要 Hadoop 依赖，请参考提供 Hadoop 类。</p>
<p>有两种方法可以添加 Hive 依赖。首先是使用 Flink 的捆绑式 Hive jars。你可以根据你使用的 metastore 的版本来选择捆绑的 Hive jar。第二种是分别添加每个所需的 jar。如果你使用的 Hive 版本没有在这里列出，第二种方式就会很有用。</p>
<h4 id="使用捆绑的-hive-jar">使用捆绑的 Hive jar</h4>
<p>下表列出了所有可用的捆绑的 hive jar，你可以选择一个到 Flink 发行版的 <code>/lib/</code> 目录下。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Metastore version</th>
<th style="text-align:left">Maven dependency</th>
<th style="text-align:left">SQL Client JAR</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1.0.0 - 1.2.2</td>
<td style="text-align:left">flink-sql-connector-hive-1.2.2</td>
<td style="text-align:left"><a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hive-1.2.2_2.11/1.11.0/flink-sql-connector-hive-1.2.2_2.11-1.11.0.jar">Download</a></td>
</tr>
<tr>
<td style="text-align:left">2.0.0 - 2.2.0</td>
<td style="text-align:left">flink-sql-connector-hive-2.2.0</td>
<td style="text-align:left"><a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hive-2.2.0_2.11/1.11.0/flink-sql-connector-hive-2.2.0_2.11-1.11.0.jar">Download</a></td>
</tr>
<tr>
<td style="text-align:left">2.3.0 - 2.3.6</td>
<td style="text-align:left">flink-sql-connector-hive-2.3.6</td>
<td style="text-align:left"><a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hive-2.3.6_2.11/1.11.0/flink-sql-connector-hive-2.3.6_2.11-1.11.0.jar">Download</a></td>
</tr>
<tr>
<td style="text-align:left">3.0.0 - 3.1.2</td>
<td style="text-align:left">flink-sql-connector-hive-3.1.2</td>
<td style="text-align:left"><a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hive-3.1.2_2.11/1.11.0/flink-sql-connector-hive-3.1.2_2.11-1.11.0.jar">Download</a></td>
</tr>
</tbody>
</table>
<h4 id="用户定义的依赖性">用户定义的依赖性</h4>
<p>请在下面找到不同 Hive 主要版本所需的依赖关系。</p>
<ul>
<li>Hive 2.3.4</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector.Contains flink-hadoop-compatibility and flink-orc jars
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-exec-2.3.4.jar
</code></pre><ul>
<li>Hive 1.0.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-metastore-1.0.0.jar
       hive-exec-1.0.0.jar
       libfb303-0.9.0.jar // libfb303 is not packed into hive-exec in some versions, need to add it separately
       
       // Orc dependencies -- required by the ORC vectorized optimizations
       orc-core-1.4.3-nohive.jar
       aircompressor-0.8.jar // transitive dependency of orc-core
</code></pre><ul>
<li>Hive 1.1.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-metastore-1.1.0.jar
       hive-exec-1.1.0.jar
       libfb303-0.9.2.jar // libfb303 is not packed into hive-exec in some versions, need to add it separately

       // Orc dependencies -- required by the ORC vectorized optimizations
       orc-core-1.4.3-nohive.jar
       aircompressor-0.8.jar // transitive dependency of orc-core
</code></pre><ul>
<li>Hive 1.2.1</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-metastore-1.2.1.jar
       hive-exec-1.2.1.jar
       libfb303-0.9.2.jar // libfb303 is not packed into hive-exec in some versions, need to add it separately

       // Orc dependencies -- required by the ORC vectorized optimizations
       orc-core-1.4.3-nohive.jar
       aircompressor-0.8.jar // transitive dependency of orc-core
</code></pre><ul>
<li>Hive 2.0.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-exec-2.0.0.jar
</code></pre><ul>
<li>Hive 2.1.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-exec-2.1.0.jar
</code></pre><ul>
<li>Hive 2.2.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-exec-2.2.0.jar

       // Orc dependencies -- required by the ORC vectorized optimizations
       orc-core-1.4.3.jar
       aircompressor-0.8.jar // transitive dependency of orc-core
</code></pre><ul>
<li>Hive 3.1.0</li>
</ul>
<pre><code>/flink-1.11.0
   /lib

       // Flink's Hive connector
       flink-connector-hive_2.11-1.11.0.jar

       // Hive dependencies
       hive-exec-3.1.0.jar
       libfb303-0.9.3.jar // libfb303 is not packed into hive-exec in some versions, need to add it separately
</code></pre><h3 id="program-maven">Program maven</h3>
<p>如果你正在构建你自己的程序，你需要在你的 mvn 文件中加入以下依赖关系。建议不要在生成的 jar 文件中包含这些依赖关系。你应该在运行时添加上面所说的依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Flink Dependency --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-connector-hive_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>

<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-api-java-bridge_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>

<span class="c">&lt;!-- Hive Dependency --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.apache.hive<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>hive-exec<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${hive.version}<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><h2 id="连接到-hive">连接到 Hive</h2>
<p>通过表环境或 YAML 配置，使用目录接口和 HiveCatalog 连接到现有的 Hive 安装。</p>
<p>如果 <code>hive-conf/hive-site.xml</code> 文件存储在远程存储系统中，用户应先将 hive 配置文件下载到本地环境中。</p>
<p>请注意，虽然 HiveCatalog 不需要特定的规划师，但读/写 Hive 表只适用于 blink 规划师。因此强烈建议您在连接 Hive 仓库时使用 blink planner。</p>
<p>HiveCatalog 能够自动检测使用中的 Hive 版本。建议不要指定 Hive 版本，除非自动检测失败。</p>
<p>以 Hive 2.3.4 版本为例。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">inBatchMode</span><span class="o">().</span><span class="n">build</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="k">val</span> <span class="n">name</span>            <span class="k">=</span> <span class="s">&#34;myhive&#34;</span>
<span class="k">val</span> <span class="n">defaultDatabase</span> <span class="k">=</span> <span class="s">&#34;mydatabase&#34;</span>
<span class="k">val</span> <span class="n">hiveConfDir</span>     <span class="k">=</span> <span class="s">&#34;/opt/hive-conf&#34;</span> <span class="c1">// a local path
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">hive</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveCatalog</span><span class="o">(</span><span class="n">name</span><span class="o">,</span> <span class="n">defaultDatabase</span><span class="o">,</span> <span class="n">hiveConfDir</span><span class="o">)</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="n">hive</span><span class="o">)</span>

<span class="c1">// set the HiveCatalog as the current catalog of the session
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">useCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="ddl">DDL</h2>
<p>建议使用 <a href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect">Hive 方言</a>在 Flink 中执行 DDL 来创建 Hive 表、视图、分区、函数。</p>
<h2 id="dml">DML</h2>
<p>Flink 支持 DML 写入 Hive 表。请参考<a href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write">读写 Hive 表</a>的细节。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hive" term="hive" label="Hive" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[HiveCatalog]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-hivecatalog/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>HiveCatalog</blockquote><h1 id="hivecatalog">HiveCatalog</h1>
<p>Hive Metastore 经过多年的发展，已经成为 Hadoop 生态系统中事实上的元数据中心。很多公司在生产中都有一个 Hive Metastore 服务实例来管理他们所有的元数据，无论是 Hive 元数据还是非 Hive 元数据，都是真理的来源。</p>
<p>对于同时部署了 Hive 和 Flink 的用户，HiveCatalog 可以让他们使用 Hive Metastore 来管理 Flink 的元数据。</p>
<p>对于只有 Flink 部署的用户来说，HiveCatalog 是 Flink 开箱即用的唯一持久化目录。如果没有持久化目录，用户使用 <a href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements">Flink SQL CREATE DDL</a> 必须在每个会话中反复创建元对象，比如 Kafka 表，这就浪费了很多时间。HiveCatalog 填补了这一空白，使用户只需创建一次表和其他元对象，以后就可以跨会话方便地引用和管理它们。</p>
<h2 id="设置-hivecatalog">设置 HiveCatalog</h2>
<h3 id="依赖性">依赖性</h3>
<p>在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#dependencies">依赖关系</a>。</p>
<h3 id="配置">配置</h3>
<p>在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#connecting-to-hive">配置</a>。</p>
<h2 id="如何使用-hivecatalog">如何使用 HiveCatalog</h2>
<p>一旦配置得当，HiveCatalog 应该可以直接使用。用户可以用 DDL 创建 Flink 元对象，并在创建后立即看到它们。</p>
<p>HiveCatalog 可以用来处理两种表。Hive 兼容表和通用表。Hive-compatible 表是指那些以 Hive 兼容的方式存储的表，在存储层的元数据和数据方面都是如此。因此，通过 Flink 创建的 Hive 兼容表可以从 Hive 端进行查询。</p>
<p>而通用表则是针对 Flink 的。当使用 HiveCatalog 创建通用表时，我们只是使用 HMS 来持久化元数据。虽然这些表对 Hive 是可见的，但 Hive 不太可能理解这些元数据。因此在 Hive 中使用这样的表会导致未定义的行为。</p>
<p>Flink 使用属性 &ldquo;is_generic&rdquo; 来判断一个表是与 Hive 兼容还是通用。当用 HiveCatalog 创建一个表时，它默认被认为是通用的。如果你想创建一个 Hive 兼容的表，请确保在你的表属性中把 is_generic 设置为 false。</p>
<p>如上所述，通用表不应该从 Hive 使用。在 Hive CLI 中，你可以调用 describe FORMATTED 对一个表进行检查，通过检查 is_generic 属性来决定它是否是通用的。通用表会有 is_generic=true。</p>
<h3 id="例子">例子</h3>
<p>我们在这里将通过一个简单的例子进行讲解。</p>
<p>第 1 步：设置 Hive Metastore。</p>
<p>有一个 Hive Metastore 在运行。</p>
<p>在这里，我们在本地路径 <code>/opt/hive-conf/hive-site.xml</code> 中设置一个本地 Hive Metastore 和我们的 hive-site.xml 文件。我们有如下的一些配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
   <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true<span class="nt">&lt;/value&gt;</span>
      <span class="nt">&lt;description&gt;</span>metadata is stored in a MySQL server<span class="nt">&lt;/description&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

   <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>com.mysql.jdbc.Driver<span class="nt">&lt;/value&gt;</span>
      <span class="nt">&lt;description&gt;</span>MySQL JDBC driver class<span class="nt">&lt;/description&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

   <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>...<span class="nt">&lt;/value&gt;</span>
      <span class="nt">&lt;description&gt;</span>user name for connecting to mysql server<span class="nt">&lt;/description&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

   <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionPassword<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>...<span class="nt">&lt;/value&gt;</span>
      <span class="nt">&lt;description&gt;</span>password for connecting to mysql server<span class="nt">&lt;/description&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

   <span class="nt">&lt;property&gt;</span>
       <span class="nt">&lt;name&gt;</span>hive.metastore.uris<span class="nt">&lt;/name&gt;</span>
       <span class="nt">&lt;value&gt;</span>thrift://localhost:9083<span class="nt">&lt;/value&gt;</span>
       <span class="nt">&lt;description&gt;</span>IP address (or fully-qualified domain name) and port of the metastore host<span class="nt">&lt;/description&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

   <span class="nt">&lt;property&gt;</span>
       <span class="nt">&lt;name&gt;</span>hive.metastore.schema.verification<span class="nt">&lt;/name&gt;</span>
       <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
   <span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div><p>用 Hive Cli 测试连接到 HMS。运行一些命令，我们可以看到我们有一个名为 default 的数据库，里面没有表。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">hive&gt; show databases<span class="p">;</span>
OK
default
Time taken: 0.032 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>

hive&gt; show tables<span class="p">;</span>
OK
Time taken: 0.028 seconds, Fetched: <span class="m">0</span> row<span class="o">(</span>s<span class="o">)</span>
</code></pre></div><p>步骤 2：配置 Flink 集群和 SQL CLI</p>
<p>将所有 Hive 的依赖关系添加到 Flink 发行版的 <code>/lib</code> 目录下，并修改 SQL CLI 的 yaml 配置文件 sql-cli-defaults.yaml 如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">execution</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">planner</span><span class="p">:</span><span class="w"> </span><span class="l">blink</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">streaming</span><span class="w">
</span><span class="w">    </span><span class="l">...</span><span class="w">
</span><span class="w">    </span><span class="nt">current-catalog</span><span class="p">:</span><span class="w"> </span><span class="l">myhive </span><span class="w"> </span><span class="c"># set the HiveCatalog as the current catalog of the session</span><span class="w">
</span><span class="w">    </span><span class="nt">current-database</span><span class="p">:</span><span class="w"> </span><span class="l">mydatabase</span><span class="w">
</span><span class="w">    
</span><span class="w"></span><span class="nt">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">myhive</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">/opt/hive-conf </span><span class="w"> </span><span class="c"># contains hive-site.xml</span><span class="w">
</span></code></pre></div><p>第三步：建立 Kafka 集群</p>
<p>Bootstrap 一个本地的 Kafka 2.3.0 集群，主题命名为 &ldquo;test&rdquo;，并以 name 和 age 的元组形式向主题产生一些简单的数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">localhost$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="nb">test</span>
&gt;tom,15
&gt;john,21
</code></pre></div><p>这些消息可以通过启动 Kafka 控制台消费者看到。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">localhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="nb">test</span> --from-beginning

tom,15
john,21
</code></pre></div><p>第四步：启动 SQL Client，用 Flink SQL DDL 创建一个 Kafka 表。</p>
<p>启动 Flink SQL Client，通过 DDL 创建一个简单的 Kafka 2.3.0 表，并验证其模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">Flink</span> <span class="k">SQL</span><span class="o">&gt;</span> <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">mykafka</span> <span class="p">(</span><span class="n">name</span> <span class="n">String</span><span class="p">,</span> <span class="n">age</span> <span class="nb">Int</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
   <span class="s1">&#39;connector.type&#39;</span> <span class="o">=</span> <span class="s1">&#39;kafka&#39;</span><span class="p">,</span>
   <span class="s1">&#39;connector.version&#39;</span> <span class="o">=</span> <span class="s1">&#39;universal&#39;</span><span class="p">,</span>
   <span class="s1">&#39;connector.topic&#39;</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span>
   <span class="s1">&#39;connector.properties.bootstrap.servers&#39;</span> <span class="o">=</span> <span class="s1">&#39;localhost:9092&#39;</span><span class="p">,</span>
   <span class="s1">&#39;format.type&#39;</span> <span class="o">=</span> <span class="s1">&#39;csv&#39;</span><span class="p">,</span>
   <span class="s1">&#39;update-mode&#39;</span> <span class="o">=</span> <span class="s1">&#39;append&#39;</span>
<span class="p">);</span>
<span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="k">Table</span> <span class="n">has</span> <span class="n">been</span> <span class="n">created</span><span class="p">.</span>

<span class="n">Flink</span> <span class="k">SQL</span><span class="o">&gt;</span> <span class="k">DESCRIBE</span> <span class="n">mykafka</span><span class="p">;</span>
<span class="n">root</span>
 <span class="o">|</span><span class="c1">-- name: STRING
</span><span class="c1"></span> <span class="o">|</span><span class="c1">-- age: INT
</span></code></pre></div><p>验证该表也是通过 Hive Cli 对 Hive 可见的，注意该表有属性 is_generic=true。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">hive&gt; show tables<span class="p">;</span>
OK
mykafka
Time taken: 0.038 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>

hive&gt; describe formatted mykafka<span class="p">;</span>
OK
<span class="c1"># col_name            	data_type           	comment</span>


<span class="c1"># Detailed Table Information</span>
Database:           	default
Owner:              	null
CreateTime:         	......
LastAccessTime:     	UNKNOWN
Retention:          	<span class="m">0</span>
Location:           	......
Table Type:         	MANAGED_TABLE
Table Parameters:
	flink.connector.properties.bootstrap.servers	localhost:9092
	flink.connector.topic	<span class="nb">test</span>
	flink.connector.type	kafka
	flink.connector.version	universal
	flink.format.type   	csv
	flink.generic.table.schema.0.data-type	VARCHAR<span class="o">(</span>2147483647<span class="o">)</span>
	flink.generic.table.schema.0.name	name
	flink.generic.table.schema.1.data-type	INT
	flink.generic.table.schema.1.name	age
	flink.update-mode   	append
	is_generic          	<span class="nb">true</span>
	transient_lastDdlTime	......

<span class="c1"># Storage Information</span>
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat
OutputFormat:       	org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
Compressed:         	No
Num Buckets:        	-1
Bucket Columns:     	<span class="o">[]</span>
Sort Columns:       	<span class="o">[]</span>
Storage Desc Params:
	serialization.format	<span class="m">1</span>
Time taken: 0.158 seconds, Fetched: <span class="m">36</span> row<span class="o">(</span>s<span class="o">)</span>
</code></pre></div><p>第五步：运行 Flink SQL 查询 Kakfa 表。</p>
<p>在 Flink 集群中，无论是单机还是 yarn-session，从 Flink SQL Client 中运行一个简单的选择查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; <span class="k">select</span> * from mykafka<span class="p">;</span>
</code></pre></div><p>在 Kafka 主题中多产生一些信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">localhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="nb">test</span> --from-beginning

tom,15
john,21
kitty,30
amy,24
kaiky,18
</code></pre></div><p>你现在应该可以在 SQL Client 中看到 Flink 产生的结果，如。</p>
<pre><code>             SQL Query Result (Table)
 Refresh: 1 s    Page: Last of 1     

        name                       age
         tom                        15
        john                        21
       kitty                        30
         amy                        24
       kaiky                        18
</code></pre><h2 id="支持的类型">支持的类型</h2>
<p>HiveCatalog 支持通用表的所有 Flink 类型。</p>
<p>对于 Hive 兼容的表，HiveCatalog 需要将 Flink 数据类型映射到相应的 Hive 类型，如下表所述。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Flink Data Type</th>
<th style="text-align:left">Hive Data Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CHAR(p)</td>
<td style="text-align:left">CHAR(p)</td>
</tr>
<tr>
<td style="text-align:left">VARCHAR(p)</td>
<td style="text-align:left">VARCHAR(p)</td>
</tr>
<tr>
<td style="text-align:left">STRING</td>
<td style="text-align:left">STRING</td>
</tr>
<tr>
<td style="text-align:left">BOOLEAN</td>
<td style="text-align:left">BOOLEAN</td>
</tr>
<tr>
<td style="text-align:left">TINYINT</td>
<td style="text-align:left">TINYINT</td>
</tr>
<tr>
<td style="text-align:left">SMALLINT</td>
<td style="text-align:left">SMALLINT</td>
</tr>
<tr>
<td style="text-align:left">INT</td>
<td style="text-align:left">INT</td>
</tr>
<tr>
<td style="text-align:left">BIGINT</td>
<td style="text-align:left">LONG</td>
</tr>
<tr>
<td style="text-align:left">FLOAT</td>
<td style="text-align:left">FLOAT</td>
</tr>
<tr>
<td style="text-align:left">DOUBLE</td>
<td style="text-align:left">DOUBLE</td>
</tr>
<tr>
<td style="text-align:left">DECIMAL(p, s)</td>
<td style="text-align:left">DECIMAL(p, s)</td>
</tr>
<tr>
<td style="text-align:left">DATE</td>
<td style="text-align:left">DATE</td>
</tr>
<tr>
<td style="text-align:left">TIMESTAMP(9)</td>
<td style="text-align:left">TIMESTAMP</td>
</tr>
<tr>
<td style="text-align:left">BYTES</td>
<td style="text-align:left">BINARY</td>
</tr>
<tr>
<td style="text-align:left">ARRAY<!-- raw HTML omitted --></td>
<td style="text-align:left">LIST<!-- raw HTML omitted --></td>
</tr>
<tr>
<td style="text-align:left">MAP&lt;K, V&gt;</td>
<td style="text-align:left">MAP&lt;K, V&gt;</td>
</tr>
<tr>
<td style="text-align:left">ROW</td>
<td style="text-align:left">STRUCT</td>
</tr>
</tbody>
</table>
<p>关于类型映射需要注意的地方。</p>
<ul>
<li>Hive 的 CHAR(p) 最大长度为 255。</li>
<li>Hive 的 VARCHAR(p) 最大长度为 65535。</li>
<li>Hive 的 MAP 只支持基元键类型，而 Flink 的 MAP 可以是任何数据类型。</li>
<li>不支持 Hive 的 UNION 类型。</li>
<li>Hive 的 TIMESTAMP 的精度总是 9，不支持其他精度。而 Hive 的 UDF 则可以处理精度&lt;=9 的 TIMESTAMP 值。</li>
<li>Hive 不支持 Flink 的 TIMESTAMP_WITH_TIME_ZONE、TIMESTAMP_WITH_LOCAL_TIME_ZONE 和 MULTISET。</li>
<li>Flink 的 INTERVAL 类型还不能映射到 Hive 的 INTERVAL 类型。</li>
</ul>
<h2 id="scala-shell">Scala Shell</h2>
<p>注意：由于目前 Scala Shell 并不支持 blink planner，所以不建议在 Scala Shell 中使用 Hive 连接器。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Streaming Aggregation]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-streaming-aggregation/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-streaming-aggregation/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Streaming Aggregation</blockquote><h1 id="流式聚合">流式聚合</h1>
<p>SQL 是数据分析中使用最广泛的语言。Flink 的 Table API 和 SQL 可以让用户用更少的时间和精力定义高效的流分析应用。此外，Flink Table API 和 SQL 还进行了有效的优化，它集成了大量的查询优化和调整后的运算符实现。但并不是所有的优化都是默认启用的，所以对于一些工作负载，可以通过开启一些选项来提高性能。</p>
<p>在本页面中，我们将介绍一些有用的优化选项和流式聚合的内部结构，在某些情况下会带来很大的改善。</p>
<p>注意: 目前，本页面中提到的优化选项仅在 Blink 计划器中支持。</p>
<p>注意: 目前，流式聚合的优化只支持<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">无边界聚合</a>。未来将支持<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">窗口聚合</a>的优化。</p>
<p>默认情况下，无界聚合运算符对输入记录进行逐一处理，即：（1）从状态中读取累加器，（2）累加/缩减记录到累加器，（3）将累加器写回状态，（4）下一条记录将从（1）开始重新做处理。这种处理模式可能会增加 StateBackend 的开销（尤其是对于 RocksDB StateBackend）。此外，在生产中很常见的数据偏斜也会使问题更加严重，容易出现作业背压的情况。</p>
<h2 id="迷你批处理minibatch聚合">迷你批处理(MiniBatch)聚合</h2>
<p>迷你批处理(mini-batch)聚合的核心思想是将一捆输入缓存在聚合运算器内部的缓冲区中。当触发处理该捆输入时，每个键只需要一个操作来访问状态。这样可以大大降低状态开销，获得更好的吞吐量。但是，这可能会增加一些延迟，因为它缓冲了一些记录，而不是在瞬间处理它们。这就是吞吐量和延迟之间的权衡。</p>
<p>下图解释了迷你批处理聚合如何减少状态操作。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/minibatch_agg.png" alt="img"></p>
<p>MiniBatch 优化默认为禁用。为了启用此优化，您应该设置选项 table.exec.mini-batch.enabled、table.exec.mini-batch.allow-latency 和 table.exec.mini-batch.size。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html#execution-options">配置</a>页面了解更多详情。</p>
<p>下面的示例展示了如何启用这些选项。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate table environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// access flink configuration
</span><span class="c1"></span><span class="k">val</span> <span class="n">configuration</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">().</span><span class="n">getConfiguration</span><span class="o">()</span>
<span class="c1">// set low-level key-value options
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.enabled&#34;</span><span class="o">,</span> <span class="s">&#34;true&#34;</span><span class="o">)</span> <span class="c1">// enable mini-batch optimization
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.allow-latency&#34;</span><span class="o">,</span> <span class="s">&#34;5 s&#34;</span><span class="o">)</span> <span class="c1">// use 5 seconds to buffer input records
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.size&#34;</span><span class="o">,</span> <span class="s">&#34;5000&#34;</span><span class="o">)</span> <span class="c1">// the maximum number of records can be buffered by each aggregate operator task
</span></code></pre></div><h2 id="local-global-聚合">Local-Global 聚合</h2>
<p>Local-Global 是为了解决数据偏斜问题而提出的，将一个分组聚合分为两个阶段，即先在上游做局部聚合，然后在下游做全局聚合，这类似于 MapReduce 中的 Combine+Reduce 模式。例如，考虑以下 SQL。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">color</span><span class="p">,</span> <span class="k">sum</span><span class="p">(</span><span class="n">id</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">T</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">color</span>
</code></pre></div><p>有可能数据流中的记录是倾斜的，因此一些聚合运算符实例要处理的记录比其他实例多得多，从而导致热点。本地聚合可以帮助将一定数量的具有相同键的输入累积到一个累积器中。全局聚合将只接收减少的累加器，而不是大量的原始输入。这可以显著降低网络洗牌和状态访问的成本。本地聚合每次积累的输入数量是基于小批量间隔的。这意味着本地-全局聚合取决于迷你批量优化的启用。</p>
<p>下图显示了本地-全局聚合如何提高性能。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/local_agg.png" alt="img"></p>
<p>下面的例子展示了如何启用本地-全局聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate table environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// access flink configuration
</span><span class="c1"></span><span class="k">val</span> <span class="n">configuration</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">().</span><span class="n">getConfiguration</span><span class="o">()</span>
<span class="c1">// set low-level key-value options
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.enabled&#34;</span><span class="o">,</span> <span class="s">&#34;true&#34;</span><span class="o">)</span> <span class="c1">// local-global aggregation depends on mini-batch is enabled
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.allow-latency&#34;</span><span class="o">,</span> <span class="s">&#34;5 s&#34;</span><span class="o">)</span>
<span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.size&#34;</span><span class="o">,</span> <span class="s">&#34;5000&#34;</span><span class="o">)</span>
<span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.optimizer.agg-phase-strategy&#34;</span><span class="o">,</span> <span class="s">&#34;TWO_PHASE&#34;</span><span class="o">)</span> <span class="c1">// enable two-phase, i.e. local-global aggregation
</span></code></pre></div><h2 id="split-distinct-聚合">Split Distinct 聚合</h2>
<p>Local-Global 优化对于一般的聚合，如 SUM、COUNT、MAX、MIN、AVG，可以有效地消除数据偏斜。但在处理不同的聚合时，其性能并不理想。</p>
<p>例如，如果我们想分析今天有多少独特的用户登录。我们可以有如下查询:</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">day</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">T</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">day</span>
</code></pre></div><p>如果 distinct key（即 user_id）的值很稀疏，<code>count distinct</code> 不好减少记录。即使启用了局部-全局优化，也没有什么帮助。因为累加器仍然包含了几乎所有的原始记录，而全局聚合将是瓶颈（大部分重度累加器是由一个任务处理的，即在同一天）。</p>
<p>这个优化的思路是将不同的聚合（如 COUNT(DISTINCT col)）分成两个层次。第一层聚合由组键和一个额外的桶键进行洗牌。桶键使用 HASH_CODE(distinct_key) % BUCKET_NUM 计算。BUCKET_NUM 默认为 1024，可以通过 <code>table.optimizer.distinct-agg.split.bucket-num</code> 选项进行配置。第二次聚合是按原组键进行洗牌，用 SUM 聚合不同桶的 COUNT DISTINCT 值。因为相同的 distinct key 只会在同一个 bucket 中计算，所以转换是等价的。桶键起到了额外的组键的作用，分担组键中热点的负担。桶键使得工作具有可扩展性，可以解决 distinct aggregations 中的数据偏斜/热点问题。</p>
<p>拆分不同的聚合后，上面的查询会自动改写成下面的查询:</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">day</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">cnt</span><span class="p">)</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="k">day</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">as</span> <span class="n">cnt</span>
    <span class="k">FROM</span> <span class="n">T</span>
    <span class="k">GROUP</span> <span class="k">BY</span> <span class="k">day</span><span class="p">,</span> <span class="k">MOD</span><span class="p">(</span><span class="n">HASH_CODE</span><span class="p">(</span><span class="n">user_id</span><span class="p">),</span> <span class="mi">1024</span><span class="p">)</span>
<span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">day</span>
</code></pre></div><p>下图显示了拆分不同的聚合如何提高性能（假设颜色代表天数，字母代表 user_id）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/distinct_split.png" alt="img"></p>
<p>注：以上是最简单的例子，可以从这个优化中受益。除此之外，Flink 还支持拆分更复杂的聚合查询，例如，多个不同键的不同聚合（如 COUNT(DISTINCT a)，SUM(DISTINCT b)），以及与其他非不同聚合（如 SUM, MAX, MIN, COUNT）一起工作。</p>
<p>注意，目前，分割优化不支持包含用户定义的 AggregateFunction 的聚合。</p>
<p>下面的例子展示了如何启用拆分不同的聚合优化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate table environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">getConfig</span>         <span class="c1">// access high-level configuration
</span><span class="c1"></span>  <span class="o">.</span><span class="n">getConfiguration</span>    <span class="c1">// set low-level key-value options
</span><span class="c1"></span>  <span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.optimizer.distinct-agg.split.enabled&#34;</span><span class="o">,</span> <span class="s">&#34;true&#34;</span><span class="o">)</span>  <span class="c1">// enable distinct agg split
</span></code></pre></div><h2 id="在-distinct-聚合上使用-filter-修饰符">在 Distinct 聚合上使用 FILTER 修饰符</h2>
<p>在某些情况下，用户可能需要从不同的维度来计算 UV(唯一访客)的数量，例如：Android 的 UV、iPhone 的 UV、Web 的 UV 以及总的 UV。很多用户会选择 CASE WHEN 来支持，比如。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
 <span class="k">day</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">total_uv</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">flag</span> <span class="k">IN</span> <span class="p">(</span><span class="s1">&#39;android&#39;</span><span class="p">,</span> <span class="s1">&#39;iphone&#39;</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">user_id</span> <span class="k">ELSE</span> <span class="k">NULL</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">app_uv</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">flag</span> <span class="k">IN</span> <span class="p">(</span><span class="s1">&#39;wap&#39;</span><span class="p">,</span> <span class="s1">&#39;other&#39;</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">user_id</span> <span class="k">ELSE</span> <span class="k">NULL</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">web_uv</span>
<span class="k">FROM</span> <span class="n">T</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">day</span>
</code></pre></div><p>但是，在这种情况下，建议使用 FILTER 语法，而不是 CASE WHEN。因为 FILTER 更符合 SQL 标准，会得到更多的性能提升。FILTER 是用于聚合函数上的修饰符，用于限制聚合中使用的值。用 FILTER 修饰符替换上面的例子，如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
 <span class="k">day</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">total_uv</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="n">FILTER</span> <span class="p">(</span><span class="k">WHERE</span> <span class="n">flag</span> <span class="k">IN</span> <span class="p">(</span><span class="s1">&#39;android&#39;</span><span class="p">,</span> <span class="s1">&#39;iphone&#39;</span><span class="p">))</span> <span class="k">AS</span> <span class="n">app_uv</span><span class="p">,</span>
 <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="n">FILTER</span> <span class="p">(</span><span class="k">WHERE</span> <span class="n">flag</span> <span class="k">IN</span> <span class="p">(</span><span class="s1">&#39;wap&#39;</span><span class="p">,</span> <span class="s1">&#39;other&#39;</span><span class="p">))</span> <span class="k">AS</span> <span class="n">web_uv</span>
<span class="k">FROM</span> <span class="n">T</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">day</span>
</code></pre></div><p>Flink SQL 优化器可以识别同一个独立键上的不同过滤参数。例如，在上面的例子中，三个 COUNT DISTINCT 都在 user_id 列上。那么 Flink 就可以只使用一个共享状态实例而不是三个状态实例来减少状态访问和状态大小。在一些工作负载中，这可以得到显著的性能提升。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tuning/streaming_aggregation_optimization.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tuning/streaming_aggregation_optimization.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[User Defined Sources and Sinks]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-user-defined-sources-and-sinks/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-user-defined-sources-and-sinks/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>User Defined Sources and Sinks</blockquote><h1 id="用户自定义源和接收器">用户自定义源和接收器</h1>
<p>动态表是 Flink 的表与 SQL API 的核心概念，用于统一处理有界和无界数据。</p>
<p>因为动态表只是一个逻辑概念，Flink 并不拥有数据本身。相反，动态表的内容存储在外部系统（如数据库、键值存储、消息队列）或文件中。</p>
<p>动态源和动态汇可以用来从外部系统读取和写入数据。在文档中，源和汇通常被总结为连接器一词。</p>
<p>Flink 为 Kafka、Hive 和不同的文件系统提供了预定义的连接器。有关内置表源和汇的更多信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/">连接器部分</a>。</p>
<p>本页主要介绍如何开发一个自定义的、用户定义的连接器。</p>
<p>注意: Flink 1.11 中引入了新的表源和表汇接口，作为 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-95%3A+New+TableSource+and+TableSink+interfaces">FLIP-95</a> 的一部分。同时工厂接口也被重新设计。FLIP-95 还没有完全实现。许多能力接口还不支持(例如用于过滤器或分区推倒)。如果有必要，还请看一下<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/legacySourceSinks.html">旧 table source 和接收器的页面</a>。为了向后兼容，这些接口仍然被支持。</p>
<h2 id="概述">概述</h2>
<p>在许多情况下，实现者不需要从头开始创建一个新的连接器，而是希望稍微修改现有的连接器或挂入现有的堆栈。在其他情况下，实现者希望创建专门的连接器。</p>
<p>本节将为这两种用例提供帮助。它解释了表连接器的一般架构，从 API 中的纯声明到将在集群上执行的运行时代码。</p>
<p>填充的箭头显示了在翻译过程中，对象如何从一个阶段转换到下一个阶段的其他对象。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table_connectors.svg" alt="img"></p>
<h3 id="元数据">元数据</h3>
<p>表 API 和 SQL 都是声明式 API。这包括表的声明。因此，执行 CREATE TABLE 语句的结果是更新目标目录中的元数据。</p>
<p>对于大多数目录实现来说，外部系统中的物理数据不会因为这样的操作而被修改。特定于连接器的依赖关系还不必存在于 classpath 中。在 WITH 子句中声明的选项既不进行验证，也不进行其他解释。</p>
<p>动态表（通过 DDL 创建或由目录提供）的元数据被表示为 CatalogTable 的实例。表名将在必要时在内部被解析为 CatalogTable。</p>
<h3 id="计划planning">计划(Planning)</h3>
<p>当涉及到表程序的规划和优化时，需要将 CatalogTable 解析为 DynamicTableSource（用于在 SELECT 查询中读取）和 DynamicTableSink（用于在 INSERT INTO 语句中写入）。</p>
<p>DynamicTableSourceFactory 和 DynamicTableSinkFactory 提供了连接器特有的逻辑，用于将 CatalogTable 的元数据翻译成 DynamicTableSource 和 DynamicTableSink 的实例。在大多数情况下，工厂的目的是验证选项（如示例中的 &lsquo;port&rsquo; = &lsquo;5022&rsquo;），配置编码/解码格式（如果需要），并创建表连接器的参数化实例。</p>
<p>默认情况下，DynamicTableSourceFactory 和 DynamicTableSinkFactory 的实例是通过 Java 的<a href="https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html">服务提供商接口</a>（SPI）发现的。连接器选项（如本例中的&rsquo;连接器'=&lsquo;自定义&rsquo;）必须对应一个有效的工厂标识符。</p>
<p>虽然在类的命名中可能并不明显，但 DynamicTableSource 和 DynamicTableSink 也可以被看作是有状态的工厂，最终产生具体的运行时实现来读取/写入实际数据。</p>
<p>规划者使用源和汇实例来执行特定连接器的双向通信，直到找到一个最佳的逻辑计划。根据可选声明的能力接口（如 Supp SupportsProjectionPushDown 或 Supp SupportsOverwrite），规划者可能会对一个实例进行更改，从而对生成的运行时实现进行突变。</p>
<h3 id="运行时">运行时</h3>
<p>逻辑规划完成后，规划师将从表连接器中获取运行时实现。运行时逻辑在 Flink 的核心连接器接口中实现，如 InputFormat 或 SourceFunction。</p>
<p>这些接口被另一层抽象归为 ScanRuntimeProvider、LookupRuntimeProvider 和 SinkRuntimeProvider 的子类。</p>
<p>例如，OutputFormatProvider(提供 <code>org.apache.flink.api.common.io.OutputFormat</code>) 和 SinkFunctionProvider(提供 <code>org.apache.flink.streaming.api.function.sink.SinkFunction</code>) 都是规划者可以处理的 SinkRuntimeProvider 的具体实例。</p>
<h2 id="扩展点">扩展点</h2>
<p>本节解释了用于扩展 Flink 的表连接器的可用接口。</p>
<h3 id="动态表因素">动态表因素</h3>
<p>动态表工厂用于根据目录和会话信息为外部存储系统配置动态表连接器。</p>
<p><code>org.apache.flink.table.fants.DynamicTableSourceFactory</code> 可以实现来构造一个 DynamicTableSource。</p>
<p><code>org.apache.flink.table.fants.DynamicTableSinkFactory</code> 可以被实现来构造一个 DynamicTableSink。</p>
<p>默认情况下，使用连接器选项的值作为工厂标识符和 Java 的服务提供者接口来发现工厂。</p>
<p>在 JAR 文件中，可以在服务文件中添加对新实现的引用。</p>
<p>META-INF/services/org.apache.flink.table.factory.Factory。</p>
<p>框架将检查单个匹配的工厂，该工厂由工厂标识符和请求的基类（如 DynamicTableSourceFactory）唯一识别。</p>
<p>如果有必要，工厂发现过程可以由目录实现绕过。为此，目录需要在 <code>org.apache.flink.table.catalog.Catalog#getFactory</code> 中返回一个实现请求的基类的实例。</p>
<h3 id="动态-table-source">动态 Table Source</h3>
<p>根据定义，动态表可以随时间变化。</p>
<p>当读取一个动态表时，其内容可以被认为是。</p>
<ul>
<li>一个变化日志（有限的或无限的），所有的变化都会被持续消耗，直到变化日志耗尽。这由 ScanTableSource 接口来表示。</li>
<li>一个持续变化的或非常大的外部表，其内容通常不会被完全读取，而是在必要时查询单个值。这由 LookupTableSource 接口来表示。</li>
</ul>
<p>一个类可以同时实现这两个接口。规划师根据指定的查询来决定它们的用途。</p>
<h4 id="扫描-table-source">扫描 Table Source</h4>
<p>ScanTableSource 在运行时扫描来自外部存储系统的所有行，扫描的行不一定只包含插入，也可以包含更新和删除。</p>
<p>扫描的行不一定只包含插入，也可以包含更新和删除。因此，该表源可用于读取（有限或无限）的变更日志。返回的变更日志模式表示计划员在运行时可以预期的变更集。</p>
<p>对于常规的批处理方案，源可以发出只插入行的有界流。</p>
<p>对于常规的流式方案，源可以发出只插入行的无界流。</p>
<p>对于变化数据捕获（CDC）场景，源可以发出有界或无界的流，包含插入、更新和删除行。</p>
<p>Table Source 可以实现更多的能力接口，如 Supp SupportsProjectionPushDown，可能在规划期间突变一个实例。所有的能力都列在 <code>org.apache.flink.table.connector.source.abilities</code> 包和 <code>org.apache.flink.table.connector.source.ScanTableSource</code> 的文档中。</p>
<p>ScanTableSource 的运行时实现必须产生内部数据结构。因此，记录必须以 org.apache.flink.table.data.RowData 的形式发出。框架提供了运行时转换器，这样一个源仍然可以在普通的数据结构上工作，并在最后进行转换。</p>
<h5 id="查询-table-source">查询 Table Source</h5>
<p>LookupTableSource 在运行时通过一个或多个键来查找外部存储系统的行。</p>
<p>与 ScanTableSource 相比，LookupTableSource 不需要读取整个表，可以在必要的时候从外部表（可能是不断变化的）中懒惰地获取单个值。</p>
<p>与 ScanTableSource 相比，LookupTableSource 目前只支持发出只插入的变化。</p>
<p>不支持更多的能力。更多信息请参见 <code>org.apache.flink.table.connector.source.LookupTableSource</code> 的文档。</p>
<p>LookupTableSource 的运行时实现是一个 TableFunction 或 AsyncTableFunction。该函数将在运行时调用给定的查找键的值。</p>
<h3 id="动态-table-sink">动态 Table Sink</h3>
<p>根据定义，动态表可以随时间变化。</p>
<p>在编写动态表时，可以始终将内容视为一个 changelog（有限或无限），对于这个 changelog，所有的变化都会被连续写出来，直到 changelog 用完为止。返回的 changelog 模式表明了 sink 在运行时接受的变化集。</p>
<p>对于常规的批处理方案，sink 可以只接受只插入的行，并写出有界流。</p>
<p>对于常规的流式方案，sink 可以只接受只插入的行，并且可以写出无约束的流。</p>
<p>对于变化数据捕获（CDC）场景，table sink 可以写出有界流或无界流，有插入、更新和删除行。</p>
<p>Table sink 可以实现更多的能力接口，如 SupportsOverwrite，可能在规划期间突变一个实例。所有的能力都列在 <code>org.apache.flink.table.connector.sink.abilities</code> 包和 org.apache.flink.table.connector.sink.DynamicTableSink 的文档中。</p>
<p>DynamicTableSink 的运行时实现必须消耗内部数据结构。因此，记录必须被接受为 org.apache.flink.table.data.RowData。该框架提供了运行时转换器，这样一个 sink 仍然可以在普通的数据结构上工作，并在开始时执行转换。</p>
<h3 id="编码解码格式">编码/解码格式</h3>
<p>一些表连接器接受不同的格式，对键和/或值进行编码和解码。</p>
<p>格式的工作模式类似于 DynamicTableSourceFactory-&gt;DynamicTableSource-&gt;ScanRuntimeProvider，工厂负责翻译选项，源头负责创建运行时逻辑。</p>
<p>因为格式可能位于不同的模块中，所以使用 Java 的服务提供者接口发现它们，类似于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#dynamic-table-factories">表工厂</a>。为了发现格式工厂，动态表工厂会搜索与工厂标识符和连接器特定基类相对应的工厂。</p>
<p>例如，Kafka 表源需要一个 DeserializationSchema 作为解码格式的运行时接口。因此，Kafka 表源工厂使用 value.format 选项的值来发现一个 DeserializationFormatFactory。</p>
<p>目前支持以下格式工厂。</p>
<ul>
<li>org.apache.flink.table.factories.DeserializationFormatFactory</li>
<li>org.apache.flink.table.factories.SerializationFormatFactory</li>
</ul>
<p>格式工厂将选项翻译成 EncodingFormat 或 DecodingFormat。这些接口是另一种工厂，为给定的数据类型产生专门的格式运行时逻辑。</p>
<p>例如，对于 Kafka table source 工厂，DeserializationFormatFactory 将返回一个 <code>EncodingFormat&lt;DeserializationSchema&gt;</code>，它可以传递到 Kafka 表源中。</p>
<h2 id="全栈示例">全栈示例</h2>
<p>本节简要介绍了如何实现一个扫描表源，其解码格式支持 changelog 语义。这个例子说明了所有提到的组件如何一起发挥作用。它可以作为一个参考实现。</p>
<p>特别是，它展示了如何</p>
<ul>
<li>创建解析和验证选项的工厂。</li>
<li>实现表连接器。</li>
<li>实现和发现自定义格式。</li>
<li>并使用提供的实用程序，如数据结构转换器和 FactoryUtil。</li>
</ul>
<p>Table Source 使用一个简单的单线程 SourceFunction 来打开一个监听传入字节的套接字。原始字节由一个可插拔的格式解码成行。该格式期望以 changelog 标志作为第一列。</p>
<p>我们将使用上面提到的大部分接口来实现下面的 DDL。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">UserScores</span> <span class="p">(</span><span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">score</span> <span class="nb">INT</span><span class="p">)</span>
<span class="k">WITH</span> <span class="p">(</span>
  <span class="s1">&#39;connector&#39;</span> <span class="o">=</span> <span class="s1">&#39;socket&#39;</span><span class="p">,</span>
  <span class="s1">&#39;hostname&#39;</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span><span class="p">,</span>
  <span class="s1">&#39;port&#39;</span> <span class="o">=</span> <span class="s1">&#39;9999&#39;</span><span class="p">,</span>
  <span class="s1">&#39;byte-delimiter&#39;</span> <span class="o">=</span> <span class="s1">&#39;10&#39;</span><span class="p">,</span>
  <span class="s1">&#39;format&#39;</span> <span class="o">=</span> <span class="s1">&#39;changelog-csv&#39;</span><span class="p">,</span>
  <span class="s1">&#39;changelog-csv.column-delimiter&#39;</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span>
<span class="p">);</span>
</code></pre></div><p>由于该格式支持 changelog 语义，我们能够在运行时摄取更新，并创建一个能够持续评估变化数据的更新视图。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">name</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">UserScores</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">name</span><span class="p">;</span>
</code></pre></div><p>使用以下命令在终端中摄取数据。</p>
<pre><code>&gt; nc -lk 9999
INSERT|Alice|12
INSERT|Bob|5
DELETE|Alice|12
INSERT|Alice|18
</code></pre><h3 id="工厂">工厂</h3>
<p>本节说明了如何将来自目录的元数据翻译成具体的连接器实例。</p>
<p>这两个工厂都被添加到 META-INF/services 目录中。</p>
<p><strong>SocketDynamicTableFactory</strong></p>
<p>SocketDynamicTableFactory 将目录表翻译成表源。由于表源需要解码格式，为了方便，我们使用提供的 FactoryUtil 发现格式。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ConfigOption</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ConfigOptions</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ReadableConfig</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.format.DecodingFormat</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.DynamicTableSource</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.DeserializationFormatFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.DynamicTableSourceFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.FactoryUtil</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.DataType</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SocketDynamicTableFactory</span> <span class="kd">implements</span> <span class="n">DynamicTableSourceFactory</span> <span class="o">{</span>

  <span class="c1">// define all options statically
</span><span class="c1"></span>  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">ConfigOption</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">HOSTNAME</span> <span class="o">=</span> <span class="n">ConfigOptions</span><span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="s">&#34;hostname&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">stringType</span><span class="o">()</span>
    <span class="o">.</span><span class="na">noDefaultValue</span><span class="o">();</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">ConfigOption</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">PORT</span> <span class="o">=</span> <span class="n">ConfigOptions</span><span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="s">&#34;port&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">intType</span><span class="o">()</span>
    <span class="o">.</span><span class="na">noDefaultValue</span><span class="o">();</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">ConfigOption</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">BYTE_DELIMITER</span> <span class="o">=</span> <span class="n">ConfigOptions</span><span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="s">&#34;byte-delimiter&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">intType</span><span class="o">()</span>
    <span class="o">.</span><span class="na">defaultValue</span><span class="o">(</span><span class="n">10</span><span class="o">);</span> <span class="c1">// corresponds to &#39;\n&#39;
</span><span class="c1"></span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">String</span> <span class="nf">factoryIdentifier</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="s">&#34;socket&#34;</span><span class="o">;</span> <span class="c1">// used for matching to `connector = &#39;...&#39;`
</span><span class="c1"></span>  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">requiredOptions</span><span class="o">()</span> <span class="o">{</span>
    <span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashSet</span><span class="o">&lt;&gt;();</span>
    <span class="n">options</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">HOSTNAME</span><span class="o">);</span>
    <span class="n">options</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">PORT</span><span class="o">);</span>
    <span class="n">options</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">FactoryUtil</span><span class="o">.</span><span class="na">FORMAT</span><span class="o">);</span> <span class="c1">// use pre-defined option for format
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">options</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">optionalOptions</span><span class="o">()</span> <span class="o">{</span>
    <span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashSet</span><span class="o">&lt;&gt;();</span>
    <span class="n">options</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">BYTE_DELIMITER</span><span class="o">);</span>
    <span class="k">return</span> <span class="n">options</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">DynamicTableSource</span> <span class="nf">createDynamicTableSource</span><span class="o">(</span><span class="n">Context</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// either implement your custom validation logic here ...
</span><span class="c1"></span>    <span class="c1">// or use the provided helper utility
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">FactoryUtil</span><span class="o">.</span><span class="na">TableFactoryHelper</span> <span class="n">helper</span> <span class="o">=</span> <span class="n">FactoryUtil</span><span class="o">.</span><span class="na">createTableFactoryHelper</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="n">context</span><span class="o">);</span>

    <span class="c1">// discover a suitable decoding format
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">DecodingFormat</span><span class="o">&lt;</span><span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;&gt;</span> <span class="n">decodingFormat</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="na">discoverDecodingFormat</span><span class="o">(</span>
      <span class="n">DeserializationFormatFactory</span><span class="o">.</span><span class="na">class</span><span class="o">,</span>
      <span class="n">FactoryUtil</span><span class="o">.</span><span class="na">FORMAT</span><span class="o">);</span>

    <span class="c1">// validate all options
</span><span class="c1"></span>    <span class="n">helper</span><span class="o">.</span><span class="na">validate</span><span class="o">();</span>

    <span class="c1">// get the validated options
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">ReadableConfig</span> <span class="n">options</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="na">getOptions</span><span class="o">();</span>
    <span class="kd">final</span> <span class="n">String</span> <span class="n">hostname</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">HOSTNAME</span><span class="o">);</span>
    <span class="kd">final</span> <span class="kt">int</span> <span class="n">port</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">PORT</span><span class="o">);</span>
    <span class="kd">final</span> <span class="kt">byte</span> <span class="n">byteDelimiter</span> <span class="o">=</span> <span class="o">(</span><span class="kt">byte</span><span class="o">)</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="n">options</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">BYTE_DELIMITER</span><span class="o">);</span>

    <span class="c1">// derive the produced data type (excluding computed columns) from the catalog table
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">DataType</span> <span class="n">producedDataType</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getCatalogTable</span><span class="o">().</span><span class="na">getSchema</span><span class="o">().</span><span class="na">toPhysicalRowDataType</span><span class="o">();</span>

    <span class="c1">// create and return dynamic table source
</span><span class="c1"></span>    <span class="k">return</span> <span class="k">new</span> <span class="n">SocketDynamicTableSource</span><span class="o">(</span><span class="n">hostname</span><span class="o">,</span> <span class="n">port</span><span class="o">,</span> <span class="n">byteDelimiter</span><span class="o">,</span> <span class="n">decodingFormat</span><span class="o">,</span> <span class="n">producedDataType</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>ChangelogCsvFormatFactory</strong></p>
<p>ChangelogCsvFormatFactory 将特定格式的选项翻译成一种格式。SocketDynamicTableFactory 中的 FactoryUtil 负责相应地调整选项键，并处理像 changelog-csv.column-delimiter 那样的前缀。</p>
<p>因为这个工厂实现了 DeserializationFormatFactory，所以它也可以用于其他支持反序列化格式的连接器，比如 Kafka 连接器。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ConfigOption</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ConfigOptions</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.ReadableConfig</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.format.DecodingFormat</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.FactoryUtil</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.DeserializationFormatFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.factories.DynamicTableFactory</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">ChangelogCsvFormatFactory</span> <span class="kd">implements</span> <span class="n">DeserializationFormatFactory</span> <span class="o">{</span>

  <span class="c1">// define all options statically
</span><span class="c1"></span>  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">ConfigOption</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">COLUMN_DELIMITER</span> <span class="o">=</span> <span class="n">ConfigOptions</span><span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="s">&#34;column-delimiter&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">stringType</span><span class="o">()</span>
    <span class="o">.</span><span class="na">defaultValue</span><span class="o">(</span><span class="s">&#34;|&#34;</span><span class="o">);</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">String</span> <span class="nf">factoryIdentifier</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="s">&#34;changelog-csv&#34;</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">requiredOptions</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">Collections</span><span class="o">.</span><span class="na">emptySet</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">optionalOptions</span><span class="o">()</span> <span class="o">{</span>
    <span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">ConfigOption</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashSet</span><span class="o">&lt;&gt;();</span>
    <span class="n">options</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">COLUMN_DELIMITER</span><span class="o">);</span>
    <span class="k">return</span> <span class="n">options</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">DecodingFormat</span><span class="o">&lt;</span><span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;&gt;</span> <span class="nf">createDecodingFormat</span><span class="o">(</span>
      <span class="n">DynamicTableFactory</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">,</span>
      <span class="n">ReadableConfig</span> <span class="n">formatOptions</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// either implement your custom validation logic here ...
</span><span class="c1"></span>    <span class="c1">// or use the provided helper method
</span><span class="c1"></span>    <span class="n">FactoryUtil</span><span class="o">.</span><span class="na">validateFactoryOptions</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="n">formatOptions</span><span class="o">);</span>

    <span class="c1">// get the validated options
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">String</span> <span class="n">columnDelimiter</span> <span class="o">=</span> <span class="n">formatOptions</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">COLUMN_DELIMITER</span><span class="o">);</span>

    <span class="c1">// create and return the format
</span><span class="c1"></span>    <span class="k">return</span> <span class="k">new</span> <span class="n">ChangelogCsvFormat</span><span class="o">(</span><span class="n">columnDelimiter</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="table-source-和解码格式">Table Source 和解码格式</h3>
<p>本节说明了如何从规划层的实例转化为运到集群的运行时实例。</p>
<p><strong>SocketDynamicTableSource</strong></p>
<p>在规划过程中会用到 SocketDynamicTableSource。在我们的例子中，我们没有实现任何可用的能力接口。因此，主要的逻辑可以在 <code>getScanRuntimeProvider(...)</code> 中找到，我们在其中实例化了所需的 SourceFunction 和其运行时的 DeserializationSchema。这两个实例都被参数化为返回内部数据结构（即 RowData）。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.functions.source.SourceFunction</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.ChangelogMode</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.format.DecodingFormat</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.DynamicTableSource</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.ScanTableSource</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.SourceFunctionProvider</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.DataType</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SocketDynamicTableSource</span> <span class="kd">implements</span> <span class="n">ScanTableSource</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">hostname</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">port</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">byte</span> <span class="n">byteDelimiter</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">DecodingFormat</span><span class="o">&lt;</span><span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;&gt;</span> <span class="n">decodingFormat</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">DataType</span> <span class="n">producedDataType</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">SocketDynamicTableSource</span><span class="o">(</span>
      <span class="n">String</span> <span class="n">hostname</span><span class="o">,</span>
      <span class="kt">int</span> <span class="n">port</span><span class="o">,</span>
      <span class="kt">byte</span> <span class="n">byteDelimiter</span><span class="o">,</span>
      <span class="n">DecodingFormat</span><span class="o">&lt;</span><span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;&gt;</span> <span class="n">decodingFormat</span><span class="o">,</span>
      <span class="n">DataType</span> <span class="n">producedDataType</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">hostname</span> <span class="o">=</span> <span class="n">hostname</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">port</span> <span class="o">=</span> <span class="n">port</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">byteDelimiter</span> <span class="o">=</span> <span class="n">byteDelimiter</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">decodingFormat</span> <span class="o">=</span> <span class="n">decodingFormat</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">producedDataType</span> <span class="o">=</span> <span class="n">producedDataType</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">ChangelogMode</span> <span class="nf">getChangelogMode</span><span class="o">()</span> <span class="o">{</span>
    <span class="c1">// in our example the format decides about the changelog mode
</span><span class="c1"></span>    <span class="c1">// but it could also be the source itself
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">decodingFormat</span><span class="o">.</span><span class="na">getChangelogMode</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">ScanRuntimeProvider</span> <span class="nf">getScanRuntimeProvider</span><span class="o">(</span><span class="n">ScanContext</span> <span class="n">runtimeProviderContext</span><span class="o">)</span> <span class="o">{</span>

    <span class="c1">// create runtime classes that are shipped to the cluster
</span><span class="c1"></span>
    <span class="kd">final</span> <span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">deserializer</span> <span class="o">=</span> <span class="n">decodingFormat</span><span class="o">.</span><span class="na">createRuntimeDecoder</span><span class="o">(</span>
      <span class="n">runtimeProviderContext</span><span class="o">,</span>
      <span class="n">producedDataType</span><span class="o">);</span>

    <span class="kd">final</span> <span class="n">SourceFunction</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">sourceFunction</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SocketSourceFunction</span><span class="o">(</span>
      <span class="n">hostname</span><span class="o">,</span>
      <span class="n">port</span><span class="o">,</span>
      <span class="n">byteDelimiter</span><span class="o">,</span>
      <span class="n">deserializer</span><span class="o">);</span>

    <span class="k">return</span> <span class="n">SourceFunctionProvider</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">sourceFunction</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">DynamicTableSource</span> <span class="nf">copy</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="n">SocketDynamicTableSource</span><span class="o">(</span><span class="n">hostname</span><span class="o">,</span> <span class="n">port</span><span class="o">,</span> <span class="n">byteDelimiter</span><span class="o">,</span> <span class="n">decodingFormat</span><span class="o">,</span> <span class="n">producedDataType</span><span class="o">);</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">String</span> <span class="nf">asSummaryString</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="s">&#34;Socket Table Source&#34;</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>ChangelogCsvFormat</strong></p>
<p>ChangelogCsvFormat 是一种解码格式，在运行时使用 DeserializationSchema。它支持发出 INSERT 和 DELETE 更改。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.TypeInformation</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.ChangelogMode</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.format.DecodingFormat</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.DynamicTableSource</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.DynamicTableSource.DataStructureConverter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.DataType</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.logical.LogicalType</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.types.RowKind</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">ChangelogCsvFormat</span> <span class="kd">implements</span> <span class="n">DecodingFormat</span><span class="o">&lt;</span><span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">columnDelimiter</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">ChangelogCsvFormat</span><span class="o">(</span><span class="n">String</span> <span class="n">columnDelimiter</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">columnDelimiter</span> <span class="o">=</span> <span class="n">columnDelimiter</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="nd">@SuppressWarnings</span><span class="o">(</span><span class="s">&#34;unchecked&#34;</span><span class="o">)</span>
  <span class="kd">public</span> <span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="nf">createRuntimeDecoder</span><span class="o">(</span>
      <span class="n">DynamicTableSource</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">,</span>
      <span class="n">DataType</span> <span class="n">producedDataType</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// create type information for the DeserializationSchema
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">producedTypeInfo</span> <span class="o">=</span> <span class="o">(</span><span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;)</span> <span class="n">context</span><span class="o">.</span><span class="na">createTypeInformation</span><span class="o">(</span>
      <span class="n">producedDataType</span><span class="o">);</span>

    <span class="c1">// most of the code in DeserializationSchema will not work on internal data structures
</span><span class="c1"></span>    <span class="c1">// create a converter for conversion at the end
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">DataStructureConverter</span> <span class="n">converter</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">createDataStructureConverter</span><span class="o">(</span><span class="n">producedDataType</span><span class="o">);</span>

    <span class="c1">// use logical types during runtime for parsing
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">LogicalType</span><span class="o">&gt;</span> <span class="n">parsingTypes</span> <span class="o">=</span> <span class="n">producedDataType</span><span class="o">.</span><span class="na">getLogicalType</span><span class="o">().</span><span class="na">getChildren</span><span class="o">();</span>

    <span class="c1">// create runtime class
</span><span class="c1"></span>    <span class="k">return</span> <span class="k">new</span> <span class="n">ChangelogCsvDeserializer</span><span class="o">(</span><span class="n">parsingTypes</span><span class="o">,</span> <span class="n">converter</span><span class="o">,</span> <span class="n">producedTypeInfo</span><span class="o">,</span> <span class="n">columnDelimiter</span><span class="o">);</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">ChangelogMode</span> <span class="nf">getChangelogMode</span><span class="o">()</span> <span class="o">{</span>
    <span class="c1">// define that this format can produce INSERT and DELETE rows
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">ChangelogMode</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">()</span>
      <span class="o">.</span><span class="na">addContainedKind</span><span class="o">(</span><span class="n">RowKind</span><span class="o">.</span><span class="na">INSERT</span><span class="o">)</span>
      <span class="o">.</span><span class="na">addContainedKind</span><span class="o">(</span><span class="n">RowKind</span><span class="o">.</span><span class="na">DELETE</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="运行时-1">运行时</h3>
<p>为了完整起见，本节说明了 SourceFunction 和 DeserializationSchema 的运行时逻辑。</p>
<p><strong>ChangelogCsvDeserializer</strong></p>
<p>ChangelogCsvDeserializer 包含了一个简单的解析逻辑，用于将字节转换为带有行种类的整数行和字符串。最后的转换步骤将这些转换为内部数据结构。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.TypeInformation</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.RuntimeConverter.Context</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.connector.source.DynamicTableSource.DataStructureConverter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.logical.LogicalType</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.logical.LogicalTypeRoot</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.types.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.types.RowKind</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">ChangelogCsvDeserializer</span> <span class="kd">implements</span> <span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">LogicalType</span><span class="o">&gt;</span> <span class="n">parsingTypes</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">DataStructureConverter</span> <span class="n">converter</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">producedTypeInfo</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">columnDelimiter</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">ChangelogCsvDeserializer</span><span class="o">(</span>
      <span class="n">List</span><span class="o">&lt;</span><span class="n">LogicalType</span><span class="o">&gt;</span> <span class="n">parsingTypes</span><span class="o">,</span>
      <span class="n">DataStructureConverter</span> <span class="n">converter</span><span class="o">,</span>
      <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">producedTypeInfo</span><span class="o">,</span>
      <span class="n">String</span> <span class="n">columnDelimiter</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">parsingTypes</span> <span class="o">=</span> <span class="n">parsingTypes</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">converter</span> <span class="o">=</span> <span class="n">converter</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">producedTypeInfo</span> <span class="o">=</span> <span class="n">producedTypeInfo</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">columnDelimiter</span> <span class="o">=</span> <span class="n">columnDelimiter</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="nf">getProducedType</span><span class="o">()</span> <span class="o">{</span>
    <span class="c1">// return the type information required by Flink&#39;s core interfaces
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">producedTypeInfo</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">InitializationContext</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// converters must be open
</span><span class="c1"></span>    <span class="n">converter</span><span class="o">.</span><span class="na">open</span><span class="o">(</span><span class="n">Context</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">ChangelogCsvDeserializer</span><span class="o">.</span><span class="na">class</span><span class="o">.</span><span class="na">getClassLoader</span><span class="o">()));</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">RowData</span> <span class="nf">deserialize</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">message</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// parse the columns including a changelog flag
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">String</span><span class="o">[]</span> <span class="n">columns</span> <span class="o">=</span> <span class="k">new</span> <span class="n">String</span><span class="o">(</span><span class="n">message</span><span class="o">).</span><span class="na">split</span><span class="o">(</span><span class="n">Pattern</span><span class="o">.</span><span class="na">quote</span><span class="o">(</span><span class="n">columnDelimiter</span><span class="o">));</span>
    <span class="kd">final</span> <span class="n">RowKind</span> <span class="n">kind</span> <span class="o">=</span> <span class="n">RowKind</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">columns</span><span class="o">[</span><span class="n">0</span><span class="o">]);</span>
    <span class="kd">final</span> <span class="n">Row</span> <span class="n">row</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Row</span><span class="o">(</span><span class="n">kind</span><span class="o">,</span> <span class="n">parsingTypes</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">parsingTypes</span><span class="o">.</span><span class="na">size</span><span class="o">();</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
      <span class="n">row</span><span class="o">.</span><span class="na">setField</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">parse</span><span class="o">(</span><span class="n">parsingTypes</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="na">getTypeRoot</span><span class="o">(),</span> <span class="n">columns</span><span class="o">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">1</span><span class="o">]));</span>
    <span class="o">}</span>
    <span class="c1">// convert to internal data structure
</span><span class="c1"></span>    <span class="k">return</span> <span class="o">(</span><span class="n">RowData</span><span class="o">)</span> <span class="n">converter</span><span class="o">.</span><span class="na">toInternal</span><span class="o">(</span><span class="n">row</span><span class="o">);</span>
  <span class="o">}</span>

  <span class="kd">private</span> <span class="kd">static</span> <span class="n">Object</span> <span class="nf">parse</span><span class="o">(</span><span class="n">LogicalTypeRoot</span> <span class="n">root</span><span class="o">,</span> <span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">switch</span> <span class="o">(</span><span class="n">root</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">case</span> <span class="n">INTEGER</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
      <span class="k">case</span> <span class="n">VARCHAR</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">value</span><span class="o">;</span>
      <span class="k">default</span><span class="o">:</span>
        <span class="k">throw</span> <span class="k">new</span> <span class="n">IllegalArgumentException</span><span class="o">();</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">isEndOfStream</span><span class="o">(</span><span class="n">RowData</span> <span class="n">nextElement</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>SocketSourceFunction</strong></p>
<p>SocketSourceFunction 打开一个套接字并消耗字节。它通过给定的字节定界符（默认为 <code>\n</code>）分割记录，并将解码委托给一个可插拔的 DeserializationSchema。源函数只能以 1 的并行度工作。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.serialization.DeserializationSchema</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.TypeInformation</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.java.typeutils.ResultTypeQueryable</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.configuration.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.functions.source.RichSourceFunction</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.data.RowData</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SocketSourceFunction</span> <span class="kd">extends</span> <span class="n">RichSourceFunction</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="kd">implements</span> <span class="n">ResultTypeQueryable</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">hostname</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">port</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">byte</span> <span class="n">byteDelimiter</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">deserializer</span><span class="o">;</span>

  <span class="kd">private</span> <span class="kd">volatile</span> <span class="kt">boolean</span> <span class="n">isRunning</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
  <span class="kd">private</span> <span class="n">Socket</span> <span class="n">currentSocket</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">SocketSourceFunction</span><span class="o">(</span><span class="n">String</span> <span class="n">hostname</span><span class="o">,</span> <span class="kt">int</span> <span class="n">port</span><span class="o">,</span> <span class="kt">byte</span> <span class="n">byteDelimiter</span><span class="o">,</span> <span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">deserializer</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">hostname</span> <span class="o">=</span> <span class="n">hostname</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">port</span> <span class="o">=</span> <span class="n">port</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">byteDelimiter</span> <span class="o">=</span> <span class="n">byteDelimiter</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">deserializer</span> <span class="o">=</span> <span class="n">deserializer</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="nf">getProducedType</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">deserializer</span><span class="o">.</span><span class="na">getProducedType</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">deserializer</span><span class="o">.</span><span class="na">open</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getMetricGroup</span><span class="o">());</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">(</span><span class="n">SourceContext</span><span class="o">&lt;</span><span class="n">RowData</span><span class="o">&gt;</span> <span class="n">ctx</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">isRunning</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// open and consume from socket
</span><span class="c1"></span>      <span class="k">try</span> <span class="o">(</span><span class="kd">final</span> <span class="n">Socket</span> <span class="n">socket</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Socket</span><span class="o">())</span> <span class="o">{</span>
        <span class="n">currentSocket</span> <span class="o">=</span> <span class="n">socket</span><span class="o">;</span>
        <span class="n">socket</span><span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="k">new</span> <span class="n">InetSocketAddress</span><span class="o">(</span><span class="n">hostname</span><span class="o">,</span> <span class="n">port</span><span class="o">),</span> <span class="n">0</span><span class="o">);</span>
        <span class="k">try</span> <span class="o">(</span><span class="n">InputStream</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">socket</span><span class="o">.</span><span class="na">getInputStream</span><span class="o">())</span> <span class="o">{</span>
          <span class="n">ByteArrayOutputStream</span> <span class="n">buffer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ByteArrayOutputStream</span><span class="o">();</span>
          <span class="kt">int</span> <span class="n">b</span><span class="o">;</span>
          <span class="k">while</span> <span class="o">((</span><span class="n">b</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">read</span><span class="o">())</span> <span class="o">&gt;=</span> <span class="n">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="c1">// buffer until delimiter
</span><span class="c1"></span>            <span class="k">if</span> <span class="o">(</span><span class="n">b</span> <span class="o">!=</span> <span class="n">byteDelimiter</span><span class="o">)</span> <span class="o">{</span>
              <span class="n">buffer</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">b</span><span class="o">);</span>
            <span class="o">}</span>
            <span class="c1">// decode and emit record
</span><span class="c1"></span>            <span class="k">else</span> <span class="o">{</span>
              <span class="n">ctx</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">deserializer</span><span class="o">.</span><span class="na">deserialize</span><span class="o">(</span><span class="n">buffer</span><span class="o">.</span><span class="na">toByteArray</span><span class="o">()));</span>
              <span class="n">buffer</span><span class="o">.</span><span class="na">reset</span><span class="o">();</span>
            <span class="o">}</span>
          <span class="o">}</span>
        <span class="o">}</span>
      <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Throwable</span> <span class="n">t</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">t</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span> <span class="c1">// print and continue
</span><span class="c1"></span>      <span class="o">}</span>
      <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="n">1000</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">cancel</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">isRunning</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="k">try</span> <span class="o">{</span>
      <span class="n">currentSocket</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
    <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Throwable</span> <span class="n">t</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// ignore
</span><span class="c1"></span>    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[数据类型和序列化]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-datatypes-serialization/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-custom-serializer/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Serializer" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-datatypes-serialization/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Datatypes Serialization</blockquote><h1 id="数据类型和序列化">数据类型和序列化</h1>
<p>Apache Flink 以独特的方式处理数据类型和序列化，包含自己的类型描述符、通用类型提取和类型序列化框架。本文档描述了这些概念和它们背后的原理。</p>
<h2 id="支持的数据类型">支持的数据类型</h2>
<p>Flink 对 DataSet 或 DataStream 中的元素类型进行了一些限制。这样做的原因是系统分析类型以确定高效的执行策略。</p>
<p>有七种不同类别的数据类型。</p>
<ol>
<li>Java Tuples 和 Scala Case 类</li>
<li>Java POJOs</li>
<li>Primitive Types</li>
<li>Regular Classes</li>
<li>Values</li>
<li>Hadoop Writables</li>
<li>特殊类型</li>
</ol>
<h3 id="tuples-和-case-类">Tuples 和 Case 类</h3>
<p>Scala case 类（以及 Scala tuples，它是 case 类的一种特殊类型），是包含固定数量的各种类型的字段的复合类型。元组字段由它们的 1-offset 名称寻址，例如第一个字段为 <code>_1</code>。case 类字段用它们的名字来访问。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">WordCount</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&#34;hello&#34;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&#34;world&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set
</span><span class="c1"></span>
<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">)</span><span class="c1">// key by field expression &#34;word&#34;
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="s">&#34;hello&#34;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="s">&#34;world&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Tuple2 Data Set
</span><span class="c1"></span>
<span class="n">input2</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">// key by field positions 0 and 1
</span></code></pre></div><h3 id="pojos">POJOs</h3>
<p>如果 Java 和 Scala 类满足以下要求，Flink 会将其作为一种特殊的 POJO 数据类型。</p>
<ul>
<li>
<p>类必须是公共的。</p>
</li>
<li>
<p>它必须有一个没有参数的公共构造函数（默认构造函数）。</p>
</li>
<li>
<p>所有字段要么是公共的，要么必须通过 getter 和 setter 函数来访问。对于一个名为 foo 的字段，getter 和 setter 方法必须命名为 <code>getFoo()</code> 和 <code> setFoo()</code>。</p>
</li>
<li>
<p>字段的类型必须由注册的序列器支持。</p>
</li>
</ul>
<p>POJOs 通常用 PojoTypeInfo 表示，并用 PojoSerializer 序列化（使用 <a href="https://github.com/EsotericSoftware/kryo">Kryo</a> 作为可配置的回退）。例外的情况是当 POJOs 实际上是 Avro 类型（Avro 特定记录）或作为 &ldquo;Avro 反射类型 &ldquo;产生。在这种情况下，POJO 由 AvroTypeInfo 表示，并通过 AvroSerializer 序列化。如果需要，您也可以注册您自己的自定义序列化器；更多信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/types_serialization.html#serialization-of-pojo-types">序列化</a>。</p>
<p>Flink 分析 POJO 类型的结构，也就是说，它学习 POJO 的字段。因此，POJO 类型比一般类型更容易使用。此外，Flink 可以比一般类型更有效地处理 POJO。</p>
<p>下面的例子显示了一个简单的 POJO，它有两个公共字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="k">var</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span>
      <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&#34;hello&#34;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&#34;world&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set
</span><span class="c1"></span>
<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">)</span><span class="c1">// key by field expression &#34;word&#34;
</span></code></pre></div><h3 id="原始类型">原始类型</h3>
<p>Flink 支持所有的 Java 和 Scala 基元类型，如 Integer, String 和 Double。</p>
<h3 id="通用类类型">通用类类型</h3>
<p>Flink 支持大多数 Java 和 Scala 类（API 和自定义）。限制适用于包含不能序列化的字段的类，如文件指针、I/O 流或其他本地资源。遵循 Java Beans 约定的类一般都能很好地工作。</p>
<p>所有没有被确定为 POJO 类型的类（见上面的 POJO 要求）都被 Flink 作为一般类类型处理。Flink 将这些数据类型视为黑盒，无法访问它们的内容（例如，为了有效的排序）。一般类型使用序列化框架 <a href="https://github.com/EsotericSoftware/kryo">Kryo</a> 进行去/序列化。</p>
<h3 id="值">值</h3>
<p>Value 类型手动描述它们的序列化和反序列化。它们不需要通过一个通用的序列化框架，而是通过实现 org.apache.flinktypes.Value 接口的读写方法，为这些操作提供自定义代码。当通用序列化会非常低效时，使用 Value 类型是合理的。一个例子是一个数据类型，它将一个稀疏的元素向量实现为一个数组。知道数组大部分是零，就可以对非零元素使用特殊的编码，而通用序列化会简单地写入所有数组元素。</p>
<p>org.apache.flinktypes.CopyableValue 接口以类似的方式支持手动内部克隆逻辑。</p>
<p>Flink 自带了预先定义的 Value 类型，对应基本数据类型。ByteValue、ShortValue、IntValue、LongValue、FloatValue、DoubleValue、StringValue、CharValue、BooleanValue）。这些 Value 类型作为基本数据类型的可变体。它们的值可以被改变，允许程序员重用对象并减轻垃圾收集器的压力。</p>
<h3 id="hadoop-可写类型">Hadoop 可写类型</h3>
<p>你可以使用实现 org.apache.hadoop.Writable 接口的类型。在 <code>write()</code> 和 <code>readFields()</code> 方法中定义的序列化逻辑将被用于序列化。</p>
<h3 id="特殊类型">特殊类型</h3>
<p>你可以使用特殊类型，包括 Scala 的 Either、Option 和 Try。Java API 对 Either 有自己的自定义实现。类似于 Scala 的 Either，它代表了两种可能的类型的值，左或右。Either 对于错误处理或需要输出两种不同类型记录的操作符来说非常有用。</p>
<h3 id="类型擦除和类型推断">类型擦除和类型推断。</h3>
<p>注意：本节只与 Java 相关。</p>
<p>Java 编译器在编译后会丢弃很多通用类型信息。这在 Java 中被称为类型清除。这意味着在运行时，一个对象的实例不再知道它的通用类型。例如，<code>DataStream&lt;String&gt;</code> 和 <code>DataStream&lt;Long&gt;</code> 的实例在 JVM 看来是一样的。</p>
<p>Flink 在准备执行程序时（调用程序的主方法时）需要类型信息。Flink Java API 试图重建以各种方式扔掉的类型信息，并将其显式存储在数据集和运算符中。你可以通过 <code>DataStream.getType()</code> 来检索类型。该方法返回一个 TypeInformation 的实例，这是 Flink 内部表示类型的方式。</p>
<p>类型推理有其局限性，在某些情况下需要程序员的 &ldquo;配合&rdquo;。例如从集合中创建数据集的方法，如 <code>ExecutionEnvironment.fromCollection()</code>，你可以传递一个描述类型的参数。但是像 <code>MapFunction&lt;I, O&gt;</code> 这样的通用函数也可能需要额外的类型信息。</p>
<p><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/java/typeutils/ResultTypeQueryable.java">ResultTypeQueryable</a> 接口可以由输入格式和函数实现，以明确地告诉 API 它们的返回类型。函数被调用的输入类型通常可以通过前面操作的结果类型来推断。</p>
<h2 id="flink-中的类型处理">Flink 中的类型处理</h2>
<p>Flink 试图推断出很多关于分布式计算过程中交换和存储的数据类型的信息。把它想象成一个数据库，推断表的模式。在大多数情况下，Flink 自己就能无缝地推断出所有必要的信息。有了类型信息，Flink 就可以做一些很酷的事情。</p>
<ul>
<li>
<p>Flink 对数据类型了解得越多，序列化和数据布局方案就越好。这对于 Flink 中的内存使用范式相当重要（尽可能在堆内/堆外对序列化数据进行工作，并使序列化非常便宜）。</p>
</li>
<li>
<p>最后，在大多数情况下，这也免去了用户对序列化框架的担心，也免去了对类型的注册。</p>
</li>
</ul>
<p>一般来说，关于数据类型的信息是在飞行前阶段需要的&ndash;也就是说，当程序对 DataStream 和 DataSet 进行调用时，以及在对 <code>execute()</code>、<code>print()</code>、<code>count()</code> 或 <code>collect()</code> 进行任何调用之前。</p>
<h2 id="最常见的问题">最常见的问题</h2>
<p>用户最经常需要与 Flink 的数据类型处理进行交互的问题是。</p>
<ul>
<li>
<p>注册子类型。如果函数签名只描述了超类型，但它们在执行过程中实际使用了这些子类型，那么让 Flink 意识到这些子类型可能会提高很多性能。为此，可以在 StreamExecutionEnvironment 或 ExecutionEnvironment 上为每个子类型调用 <code>.registerType(clazz)</code>。</p>
</li>
<li>
<p>注册自定义序列器。Flink 对于那些自己不透明处理的类型又回到了 <a href="https://github.com/EsotericSoftware/kryo">Kryo</a>。并非所有类型都能被 Kryo 无缝处理（因此也能被 Flink 处理）。例如，许多 Google Guava 集合类型在默认情况下不能很好地工作。解决的办法是为导致问题的类型注册额外的序列器。在 StreamExecutionEnvironment 或 ExecutionEnvironment 上调用.getConfig().addDefaultKryoSerializer( clazz, serializer)。许多库中都有额外的 Kryo 序列化器。有关使用自定义序列器的更多细节，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/custom_serializers.html">自定义序列器</a>。</p>
</li>
<li>
<p>添加类型提示。有时，当 Flink 尽管使用了所有技巧也无法推断出通用类型时，用户必须传递一个类型提示。这一般只在 Java API 中才需要。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#type-hints-in-the-java-api">类型提示</a>一节对此进行了更详细的描述。</p>
</li>
<li>
<p>手动创建一个 TypeInformation。对于一些 API 调用来说，这可能是必要的，由于 Java 的通用类型擦除，Flink 不可能推断出数据类型。详情请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#creating-a-typeinformation-or-typeserializer">创建 TypeInformation 或 TypeSerializer</a>。</p>
</li>
</ul>
<h2 id="flink-的-typeinformation-类">Flink 的 TypeInformation 类</h2>
<p><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java">TypeInformation</a> 类是所有类型描述符的基础类。它揭示了类型的一些基本属性，并且可以生成序列器，在特殊化中，可以生成类型的比较器。(注意，Flink 中的比较器的作用远不止定义一个顺序&ndash;它们基本上是处理键的实用程序)</p>
<p>在内部，Flink 对类型做了如下区分。</p>
<ul>
<li>
<p>基本类型。所有的 Java 基元和它们的盒子形式，加上 void，String，Date，BigDecimal 和 BigInteger。</p>
</li>
<li>
<p>基元数组和对象数组：基本类型：所有的 Java 基元和它们的盒子形式，加上 void、String、Date、BigDecimal 和 BigInteger。</p>
</li>
<li>
<p>复合型</p>
<ul>
<li>Flink Java Tuples(Flink Java API 的一部分)：最多 25 个字段，不支持 null 字段。</li>
<li>Scala case 类（包括 Scala tuples）：不支持 null 字段。</li>
<li>Row：具有任意数量字段的元组，支持 null 字段。</li>
<li>POJOs：遵循某种 bean-like 模式的类。</li>
</ul>
</li>
<li>
<p>辅助类型(Option、Either、Lists、Maps&hellip;)</p>
</li>
<li>
<p>通用类型。这些类型不会由 Flink 本身序列化，而是由 Kryo 序列化。</p>
</li>
</ul>
<p>POJOs 特别值得关注，因为它们支持创建复杂类型和在键的定义中使用字段名：<code>dataSet.join(another).where(&quot;name&quot;).equalTo(&quot;personName&quot;)</code>。它们对运行时也是透明的，可以被 Flink 非常有效地处理。</p>
<h3 id="pojo-类型的规则">POJO 类型的规则</h3>
<p>如果满足以下条件，Flink 将数据类型识别为 POJO 类型（并允许 &ldquo;按名称 &ldquo;字段引用）。</p>
<ul>
<li>类是公共的和独立的（没有非静态的内部类）。</li>
<li>该类有一个公共的无参数构造函数。</li>
<li>该类（以及所有超级类）中所有非静态、非瞬态的字段要么是公共的（是非最终的），要么有一个公共的 <code>getter-</code> 和 <code>setter-</code> 方法，遵循 Java beans 中 getter 和 setter 的命名惯例。</li>
</ul>
<p>请注意，当用户定义的数据类型不能被识别为 POJO 类型时，它必须被处理为 GenericType 并通过 Kryo 进行序列化。</p>
<h3 id="创建一个-typeinformation-或-typeserializer">创建一个 TypeInformation 或 TypeSerializer。</h3>
<p>要为一个类型创建 TypeInformation 对象，请使用语言特定的方式。</p>
<p>在 Scala 中，Flink 使用在编译时运行的宏，并捕捉所有通用类型信息，而它仍然可用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// important: this import is needed to access the &#39;createTypeInformation&#39; macro function
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala._</span>

<span class="k">val</span> <span class="n">stringInfo</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">createTypeInformation</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span>

<span class="k">val</span> <span class="n">tupleInfo</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">createTypeInformation</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span>
</code></pre></div><p>你仍然可以使用与 Java 中相同的方法作为后备。</p>
<p>要创建一个 TypeSerializer，只需在 TypeInformation 对象上调用 typeInfo.createSerializer(config)。</p>
<p>config 参数的类型是 ExecutionConfig，并持有程序注册的自定义序列器的信息。在可能的情况下，尽量传递程序的正确的 ExecutionConfig。你通常可以通过调用 <code>getExecutionConfig()</code> 从 DataStream 或 DataSet 中获取它。在函数内部（比如 MapFunction），你可以通过将函数变成 Rich Function，然后调用 <code>getRuntimeContext().getExecutionConfig()</code> 来获取它。</p>
<h2 id="scala-api-中的类型信息">Scala API 中的类型信息</h2>
<p>Scala 通过类型清单和类标签对运行时类型信息有非常详细的概念。一般来说，类型和方法可以访问其通用参数的类型&ndash;因此，Scala 程序不会像 Java 程序那样受到类型擦除的影响。</p>
<p>此外，Scala 允许通过 Scala Macros 在 Scala 编译器中运行自定义代码&ndash;这意味着每当你编译一个针对 Flink 的 Scala API 编写的 Scala 程序时，一些 Flink 代码就会被执行。</p>
<p>我们在编译过程中使用宏来查看所有用户函数的参数类型和返回类型&ndash;这时当然所有的类型信息都是完全可用的。在宏中，我们为函数的返回类型（或参数类型）创建一个 TypeInformation，并将其作为操作的一部分。</p>
<h3 id="没有隐式值的证据参数错误">没有隐式值的证据参数错误</h3>
<p>在 TypeInformation 不能被创建的情况下，程序编译失败，并出现 &ldquo;could not find implicit value for evidence parameter of type TypeInformation&rdquo; 的错误。</p>
<p>一个常见的原因是生成 TypeInformation 的代码没有被导入。请确保导入整个 <code>flink.api.scala</code> 包。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>
</code></pre></div><p>另一个常见的原因是通用方法，它可以在下面的章节中进行修复。</p>
<h3 id="通用方法">通用方法</h3>
<p>请考虑以下案例。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">selectFirst</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">T</span>, <span class="k">_</span><span class="o">)])</span> <span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">input</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">v</span> <span class="k">=&gt;</span> <span class="n">v</span><span class="o">.</span><span class="n">_1</span> <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span> <span class="kt">=</span> <span class="kt">...</span>

<span class="kt">val</span> <span class="kt">result</span> <span class="kt">=</span> <span class="kt">selectFirst</span><span class="o">(</span><span class="kt">data</span><span class="o">)</span>
</code></pre></div><p>对于这样的通用方法，每次调用时，函数参数和返回类型的数据类型可能不一样，在定义方法的站点不知道。上面的代码会导致一个错误，即没有足够的隐含证据。</p>
<p>在这种情况下，必须在调用站点生成类型信息并传递给方法。Scala 为此提供了隐式参数。</p>
<p>下面的代码告诉 Scala 将 T 的类型信息带入函数中。然后，类型信息将在方法被调用的站点生成，而不是在方法被定义的站点生成。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">selectFirst</span><span class="o">[</span><span class="kt">T</span> <span class="kt">:</span> <span class="kt">TypeInformation</span><span class="o">](</span><span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">T</span>, <span class="k">_</span><span class="o">)])</span> <span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">input</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">v</span> <span class="k">=&gt;</span> <span class="n">v</span><span class="o">.</span><span class="n">_1</span> <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h2 id="java-api-中的类型信息">Java API 中的类型信息</h2>
<p>在一般情况下，Java 会擦除通用类型信息，而 Flink 试图通过反射来重建尽可能多的类型信息，使用 Java 保留的少量信息（主要是函数签名和子类信息）。Flink 试图通过反射来重建尽可能多的类型信息，使用 Java 保留的少量信息（主要是函数签名和子类信息）。这个逻辑还包含了一些简单的类型推理，用于函数的返回类型取决于其输入类型的情况。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AppendOne</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="kd">implements</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="n">T</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;(</span><span class="n">value</span><span class="o">,</span> <span class="n">1L</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>在有些情况下，Flink 无法重建所有的通用类型信息。在这种情况下，用户必须通过类型提示来帮忙。</p>
<h3 id="java-api-中的类型提示">Java API 中的类型提示</h3>
<p>在 Flink 无法重建被擦除的通用类型信息的情况下，Java API 提供了所谓的类型提示。类型提示告诉系统一个函数产生的数据流或数据集的类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">SomeType</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">dataSet</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MyGenericNonInferrableFunction</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">SomeType</span><span class="o">&gt;())</span>
        <span class="o">.</span><span class="na">returns</span><span class="o">(</span><span class="n">SomeType</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</code></pre></div><p><code>returns</code> 语句指定产生的类型，在本例中是通过一个类。提示支持类型定义，通过:</p>
<ul>
<li>类，适用于非参数化类型(无属类)</li>
<li>TypeHint 以 <code>returns(new TypeHint&lt;Tuple2&lt;Integer, SomeType&gt;&gt;(){})</code> 的形式存在。TypeHint 类可以捕获通用类型信息，并将其保存到运行时（通过匿名子类）。</li>
</ul>
<h3 id="java-8-lambdas-的类型提取">Java 8 lambdas 的类型提取。</h3>
<p>Java 8 lambdas 的类型提取与非 lambdas 的工作方式不同，因为 lambdas 不与扩展函数接口的实现类相关联。</p>
<p>目前，Flink 试图找出哪个方法实现了 lambda，并使用 Java 的通用签名来确定参数类型和返回类型。然而，并不是所有的编译器都能为 lambdas 生成这些签名（在写这篇文档时，只有 4.5 以后的 Eclipse JDT 编译器能可靠地生成）。</p>
<h3 id="pojo-类型的序列化">POJO 类型的序列化</h3>
<p>PojoTypeInfo 正在为 POJO 内部的所有字段创建序列器。标准类型，如 int、long、String 等，由 Flink 附带的序列器处理。对于所有其他类型，我们回到了 <a href="https://github.com/EsotericSoftware/kryo">Kryo</a>。</p>
<p>如果 Kryo 不能处理类型，你可以要求 PojoTypeInfo 使用 <a href="https://avro.apache.org/">Avro</a> 来序列化 POJO。要做到这一点，你必须调用</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">enableForceAvro</span><span class="o">();</span>
</code></pre></div><p>请注意，Flink 是用 Avro 序列化器自动序列化 Avro 生成的 POJO。</p>
<p>如果您想让整个 POJO 类型被 Kryo 序列化器处理，请设置</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">enableForceKryo</span><span class="o">();</span>
</code></pre></div><p>如果 Kryo 无法序列化你的 POJO，你可以在 Kryo 中添加一个自定义序列化器，使用</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">addDefaultKryoSerializer</span><span class="o">(</span><span class="n">Class</span><span class="o">&lt;?&gt;</span> <span class="n">type</span><span class="o">,</span> <span class="n">Class</span><span class="o">&lt;?</span> <span class="kd">extends</span> <span class="n">Serializer</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">serializerClass</span><span class="o">)</span>
</code></pre></div><p>这些方法有不同的变体。</p>
<h2 id="禁用-kryo-fallback">禁用 Kryo Fallback</h2>
<p>有些情况下，程序可能希望明确避免使用 Kryo 作为通用类型的后备。最常见的情况是希望确保所有类型都能通过 Flink 自己的序列化器或通过用户定义的自定义序列化器进行有效序列化。</p>
<p>下面的设置会在遇到会通过 Kryo 的数据类型时引发异常。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">env</span><span class="o">.</span><span class="n">getConfig</span><span class="o">().</span><span class="n">disableGenericTypes</span><span class="o">();</span>
</code></pre></div><h2 id="使用工厂定义类型信息">使用工厂定义类型信息</h2>
<p>类型信息工厂允许将用户定义的类型信息插入到 Flink 类型系统中。你必须实现 <code>org.apache.flink.api.common.typeinfo.TypeInfoFactory</code> 来返回你的自定义类型信息。如果相应的类型已经被 <code>@org.apache.flink.api.common.typeinfo.TypeInfo</code> 注解，那么在类型提取阶段就会调用这个工厂。</p>
<p>类型信息工厂可以在 Java 和 Scala API 中使用。</p>
<p>在类型的层次结构中，在向上遍历时将选择最接近的工厂，然而，内置工厂具有最高的优先级。工厂也比 Flink 的内置类型有更高的优先级，因此你应该知道你在做什么。</p>
<p>下面的例子展示了如何在 Java 中使用工厂来注释一个自定义类型 MyTuple 并为其提供自定义类型信息。</p>
<p>注解的自定义类型:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="nd">@TypeInfo</span><span class="o">(</span><span class="n">MyTupleTypeInfoFactory</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyTuple</span><span class="o">&lt;</span><span class="n">T0</span><span class="o">,</span> <span class="n">T1</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">T0</span> <span class="n">myfield0</span><span class="o">;</span>
  <span class="kd">public</span> <span class="n">T1</span> <span class="n">myfield1</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>工厂供应自定义类型信息:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyTupleTypeInfoFactory</span> <span class="kd">extends</span> <span class="n">TypeInfoFactory</span><span class="o">&lt;</span><span class="n">MyTuple</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">MyTuple</span><span class="o">&gt;</span> <span class="nf">createTypeInfo</span><span class="o">(</span><span class="n">Type</span> <span class="n">t</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">TypeInformation</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">genericParameters</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="n">MyTupleTypeInfo</span><span class="o">(</span><span class="n">genericParameters</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&#34;T0&#34;</span><span class="o">),</span> <span class="n">genericParameters</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&#34;T1&#34;</span><span class="o">));</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>方法 <code>createTypeInfo(Type, Map&lt;String, TypeInformation&lt;?&gt;)</code> 为工厂的目标类型创建类型信息。参数提供了关于类型本身的附加信息，以及类型的通用类型参数（如果可用）。</p>
<p>如果你的类型包含了可能需要从 Flink 函数的输入类型中导出的通用参数，请确保同时实现 <code>org.apache.flink.api.common.typeinfo.TypeInformation#getGenericParameters</code> 来实现通用参数到类型信息的双向映射。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/serialization" term="serialization" label="Serialization" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[配置]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-25-configuration/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-read-and-write/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Read and Write" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-streaming/?utm_source=atom_feed" rel="related" type="text/html" title="Hive Streaming" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-functions/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-dialect/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 方言" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-25-hive-integration-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Hive 集成 - 概览" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-25-configuration/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-25T00:00:00+08:00</published>
            <updated>2020-08-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Configuration</blockquote><h1 id="配置">配置</h1>
<p>默认情况下，Table &amp; SQL API 是预先配置的，可以在可接受的性能下产生准确的结果。</p>
<p>根据表程序的要求，可能需要调整某些参数进行优化。例如，无约束的流程序可能需要确保所需的状态大小是有上限的（参见流概念）。</p>
<h2 id="概述">概述</h2>
<p>在每个表环境中，TableConfig 都提供了配置当前会话的选项。</p>
<p>对于常见或重要的配置选项，TableConfig 提供了 getter 和 setter 方法，并提供了详细的内联文档。</p>
<p>对于更高级的配置，用户可以直接访问底层的键值映射。下面的章节列出了所有可用的选项，可以用来调整 Flink Table &amp; SQL API 程序。</p>
<p>注意: 由于在执行操作时，选项会在不同的时间点被读取，因此建议在实例化表环境后尽早设置配置选项。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate table environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// access flink configuration
</span><span class="c1"></span><span class="k">val</span> <span class="n">configuration</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">().</span><span class="n">getConfiguration</span><span class="o">()</span>
<span class="c1">// set low-level key-value options
</span><span class="c1"></span><span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.enabled&#34;</span><span class="o">,</span> <span class="s">&#34;true&#34;</span><span class="o">)</span>
<span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.allow-latency&#34;</span><span class="o">,</span> <span class="s">&#34;5 s&#34;</span><span class="o">)</span>
<span class="n">configuration</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;table.exec.mini-batch.size&#34;</span><span class="o">,</span> <span class="s">&#34;5000&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：目前，键值选项只支持 Blink 计划器。目前，键值选项只支持 Blink 计划器。</p>
<h3 id="执行选项">执行选项</h3>
<p>以下选项可以用来调整查询执行的性能。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">table.exec.async-lookup.buffer-capacity(Batch/Streaming)</td>
<td style="text-align:left">100</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">异步查找连接可以触发的最大异步 i/o 操作数。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.async-lookup.timeout(Batch/Streaming)</td>
<td style="text-align:left">&ldquo;3 min&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">异步操作完成的异步超时时间。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.disabled-operators(Batch)</td>
<td style="text-align:left">(none)</td>
<td style="text-align:left">String</td>
<td style="text-align:left">主要用于测试。一个以逗号分隔的操作符名称列表，每个名称代表一种被禁用的操作符。可以禁用的操作符包括 &ldquo;NestedLoopJoin&rdquo;、&ldquo;ShuffleHashJoin&rdquo;、&ldquo;BroadcastHashJoin&rdquo;、&ldquo;SortMergeJoin&rdquo;、&ldquo;HashAgg&rdquo;、&ldquo;SortAgg&rdquo;。默认情况下，没有任何操作符被禁用。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.mini-batch.allow-latency(Streaming)</td>
<td style="text-align:left">&ldquo;-1 ms&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">最大延迟可以用于 MiniBatch 来缓冲输入记录。MiniBatch 是一种优化，用于缓冲输入记录以减少状态访问。MiniBatch 会在允许的延迟间隔和达到最大缓冲记录数时触发。注意：如果 table.exec.mini-batch.enabled 被设置为 true，其值必须大于零。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.mini-batch.enabled(Streaming)</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">指定是否启用 MiniBatch 优化。MiniBatch 是对输入记录进行缓冲以减少状态访问的优化。默认情况下，这个配置是禁用的。要启用这个功能，用户应该将这个配置设置为 true。注意：如果启用了 Mini-batch，必须设置&rsquo;table.exec.mini-batch.allow-latency&rsquo;和&rsquo;table.exec.mini-batch.size'。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.mini-batch.size(Streaming)</td>
<td style="text-align:left">-1</td>
<td style="text-align:left">Long</td>
<td style="text-align:left">MiniBatch 可以缓冲的输入记录的最大数量。MiniBatch 是对输入记录进行缓冲的优化，以减少状态访问。MiniBatch 会在允许的延迟间隔和达到最大缓冲记录数时触发。注意：MiniBatch 目前只适用于非窗口聚合。如果 table.exec.mini-batch.enabled 被设置为 true，其值必须为正。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.resource.default-parallelism(Batch/Streaming)</td>
<td style="text-align:left">-1</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">为所有操作符（如 aggregation、join、filter）设置默认的并行性，以便与并行实例一起运行。这个配置的优先级高于 StreamExecutionEnvironment 的并行性（实际上，这个配置覆盖了 StreamExecutionEnvironment 的并行性）。值为-1 表示没有设置默认的并行性，那么它将回落到使用 StreamExecutionEnvironment 的并行性。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.shuffle-mode(Batch)</td>
<td style="text-align:left">&ldquo;ALL_EDGES_BLOCKING&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">设置执行 shuffle 的模式。接受的值是, ALL_EDGES_BLOCKING: 所有边缘都将使用阻塞洗牌。FORWARD_EDGES_PIPELINED: 正向边缘将使用流水线洗牌，其他边缘将使用阻塞洗牌。POINTWISE_EDGES_PIPELINED: POINTWISE_EDGES_PIPELINED: 点向边缘将使用管道式洗牌，其他边缘将被阻挡。POINTWISE_EDGES_PIPELINED: 点向边缘包括前向和重新缩放边缘。ALL_EDGES_PIPELINED: 所有的边缘都将使用 pipelined shuffle，其他的边缘则使用 blocks。所有边缘都将使用流水线洗牌。batch: 与 ALL_EDGES_BLOCKING 相同。已废弃。pipelined: 与 ALL_EDGES_PIPELINED 相同。已被弃用。注意：Blocking shuffle 意味着数据将在发送到消费者任务之前被完全生成。Pipelined shuffle 意味着数据一旦被生产出来，就会被发送到消费者任务中。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.sink.not-null-enforcer(Batch/Streaming)</td>
<td style="text-align:left">ERROR</td>
<td style="text-align:left">Enum,可能的值: [ERROR, DROP]</td>
<td style="text-align:left">表上的 NOT NULL 列约束强制要求不能将空值插入到表中。Flink 支持 &ldquo;错误&rdquo;（默认）和 &ldquo;放弃 &ldquo;执行行为。默认情况下，当 NOT NULL 列中写入空值时，Flink 会检查值并抛出运行时异常。用户可以将行为改为&rsquo;drop'，在不出现异常的情况下默默地删除这些记录。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.sort.async-merge-enabled(Batch)</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">是否异步合并排序后的 spill 文件。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.sort.default-limit(Batch)</td>
<td style="text-align:left">-1</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">当用户在下单后没有设置限价时，默认限价。-1 表示该配置被忽略。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.sort.max-num-file-handles(Batch)</td>
<td style="text-align:left">128</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">外部合并排序的最大扇入量。它限制了每个操作者的文件句柄数。如果太小，可能会造成中间合并。但如果太大，会造成同时打开的文件太多，消耗内存，导致随机读取。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.source.idle-timeout(Streaming)</td>
<td style="text-align:left">&ldquo;-1 ms&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">当一个源在超时时间内没有收到任何元素时，它将被标记为暂时空闲。这样下游任务就可以提前打水印，而不需要在这个源空闲时等待它的水印。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.spill-compression.block-size(Batch)</td>
<td style="text-align:left">&ldquo;64 kb&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">溢出数据时做压缩时使用的内存大小。内存越大，压缩比越高，但作业会消耗更多的内存资源。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.spill-compression.enabled(Batch)</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">是否压缩溢出数据。目前我们只支持压缩溢出数据的排序和哈希-agg 和哈希-join 操作符。</td>
</tr>
<tr>
<td style="text-align:left">table.exec.window-agg.buffer-size-limit(Batch)</td>
<td style="text-align:left">100000</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">设置组窗口 agg 运算符中使用的窗口元素缓冲区大小限制。</td>
</tr>
</tbody>
</table>
<h2 id="优化选项">优化选项</h2>
<p>以下选项可以用来调整查询优化器的行为，以获得更好的执行计划。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">table.optimizer.agg-phase-strategy(Batch/Streaming)</td>
<td style="text-align:left">&ldquo;AUTO&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">聚合阶段的策略。只能设置 AUTO、TWO_PHASE 或 ONE_PHASE。AUTO：集合阶段无特殊执行器。选择两阶段聚合还是一阶段聚合取决于成本。TWO_PHASE: 强制使用两级聚合，其中包括 localAggregate 和 globalAggregate。请注意，如果聚合调用不支持优化为两阶段，我们仍将使用一个阶段的聚合。ONE_PHASE: 强制使用只有 CompleteGlobalAggregate 的单阶段聚合。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.distinct-agg.split.bucket-num(Streaming)</td>
<td style="text-align:left">1024</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">配置拆分不同聚合时的桶数。这个数字在一级聚合中用于计算一个桶键&rsquo;hash_code(distinct_key) % BUCKET_NUM'，这个桶键在拆分后作为一个额外的组键使用。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.distinct-agg.split.enabled(Streaming)</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">指示优化器是否将 distinct aggregation(例如 COUNT(DISTINCT col)，SUM(DISTINCT col))分成两级。第一层聚合由一个额外的 key 进行洗牌，这个 key 是用 distinct_key 和 buckets 数量的 hashcode 计算出来的。当 distinct aggregation 中存在数据倾斜时，这种优化是非常有用的，并提供了扩展作业的能力。默认为 false。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.join-reorder-enabled(Batch/Streaming)</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">在优化器中启用连接重排序。默认为禁用。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.join.broadcast-threshold(Batch)</td>
<td style="text-align:left">1048576</td>
<td style="text-align:left">Long</td>
<td style="text-align:left">配置在执行连接时将向所有工作节点广播的表的最大字节数。将此值设置为-1，则禁用广播。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.reuse-source-enabled(Batch/Streaming)</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">当它为真时，优化器将尝试找出重复的表源并重用它们。这只有在 table.optimizer.reuse-sub-plan-enabled 为真时才会生效。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.reuse-sub-plan-enabled(Batch/Streaming)</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">当它为真时，优化器将尝试找出重复的子计划并重用它们。</td>
</tr>
<tr>
<td style="text-align:left">table.optimizer.source.predicate-pushdown-enabled(Batch/Streaming)</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">当该值为真时，优化器将向下推送谓词到 FilterableTableSource 中。默认值为 true。</td>
</tr>
</tbody>
</table>
<h2 id="table-选项">Table 选项</h2>
<p>以下选项可用于调整表计划器(planner)的行为:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Key</th>
<th style="text-align:left">Default</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">table.dynamic-table-options.enabled(Batch/Streaming)</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">启用或禁用 OPTIONS 提示，用于动态指定表选项，如果禁用，则如果指定了任何 OPTIONS 提示，就会产生异常。</td>
</tr>
<tr>
<td style="text-align:left">table.sql-dialect(Batch/Streaming)</td>
<td style="text-align:left">&ldquo;default&rdquo;</td>
<td style="text-align:left">String</td>
<td style="text-align:left">SQL 方言定义了如何解析一个 SQL 查询。不同的 SQL 方言可能支持不同的 SQL 语法。目前支持的方言有：默认和 hive。</td>
</tr>
</tbody>
</table>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Alter 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>ALTER Statements</blockquote><h1 id="alter-语句">ALTER 语句</h1>
<p>ALTER 语句用于修改目录中注册的表/视图/函数定义。</p>
<p>Flink SQL 目前支持以下 ALTER 语句。</p>
<ul>
<li>ALTER TABLE</li>
<li>ALTER DATABASE</li>
<li>ALTER FUNCTION</li>
</ul>
<h2 id="运行-alter-语句">运行 ALTER 语句</h2>
<p>ALTER 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法在 ALTER 操作成功时返回 &ldquo;OK&rdquo;，否则将抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 ALTER 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">()...</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">);</span>

<span class="c1">// a string array: [&#34;Orders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">()</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span><span class="c1"></span>
<span class="c1">// rename &#34;Orders&#34; to &#34;NewOrders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;ALTER TABLE Orders RENAME TO NewOrders;&#34;</span><span class="o">)</span>

<span class="c1">// a string array: [&#34;NewOrders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">()</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span></code></pre></div><h2 id="alter-table">ALTER TABLE</h2>
<ul>
<li>Rename Table</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">new_table_name</span>
</code></pre></div><p>将给定的表名重命名为另一个新表名。</p>
<ul>
<li>设置或更改表属性</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span> <span class="k">SET</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)</span>
</code></pre></div><p>设置指定表格中的一个或多个属性。如果某个属性已经在表中被设置，则用新的属性覆盖旧的值。</p>
<h2 id="alter-database">ALTER DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.]</span><span class="n">db_name</span> <span class="k">SET</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)</span>
</code></pre></div><p>在指定的数据库中设置一个或多个属性。如果某个属性已经在数据库中被设置，则用新的属性覆盖旧的值。</p>
<h2 id="alter-function">ALTER FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> 
  <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="n">function_name</span> 
  <span class="k">AS</span> <span class="n">identifier</span> <span class="p">[</span><span class="k">LANGUAGE</span> <span class="n">JAVA</span><span class="o">|</span><span class="n">SCALA</span><span class="o">|</span><span class="n">PYTHON</span><span class="p">]</span>
</code></pre></div><p>用新的标识符和可选的语言标签改变一个目录函数。如果一个函数在目录中不存在，就会抛出一个异常。</p>
<p>如果语言标签是 JAVA/SCALA，标识符是 UDF 的完整 classpath。关于 Java/Scala UDF 的实现，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">User-defined Functions</a> 了解详情。</p>
<p>如果语言标签是 PYTHON，标识符是 UDF 的完全限定名，例如 pyflink.table.test.test_udf.add。关于 Python UDF 的实现，更多细节请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>。</p>
<p><strong>TEMPORARY</strong></p>
<p>改变具有目录和数据库命名空间的临时目录功能，并覆盖目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>更改没有命名空间的临时系统函数，并覆盖内置函数。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果函数不存在，就不会发生任何事情。</p>
<p><strong>LANGUAGE JAVA|SCALA|PYTHON</strong></p>
<p>语言标签，用于指导 flink 运行时如何执行函数。目前只支持 JAVA、SCALA 和 PYTHON，函数的默认语言是 JAVA。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Catalogs]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-catalogs/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Catalogs</blockquote><h1 id="catalogs">Catalogs</h1>
<p>目录提供了元数据，如数据库、表、分区、视图以及访问数据库或其他外部系统中存储的数据所需的功能和信息。</p>
<p>数据处理中最关键的一个方面是管理元数据。它可能是短暂的元数据，如临时表，或针对表环境注册的 UDF。或者是永久性的元数据，比如 Hive Metastore 中的元数据。目录为管理元数据提供了统一的 API，并使其可以从表 API 和 SQL 查询中访问。</p>
<p>Catalog 使用户能够引用数据系统中现有的元数据，并自动将它们映射到 Flink 的相应元数据中。例如，Flink 可以将 JDBC 表自动映射到 Flink 表，用户不必在 Flink 中手动重新编写 DDL。Catalog 大大简化了用户现有系统上手 Flink 所需的步骤，大大提升了用户体验。</p>
<h2 id="catalog-类型">Catalog 类型</h2>
<h3 id="genericinmemorycatalog">GenericInMemoryCatalog</h3>
<p>GenericInMemoryCatalog 是一个目录的内存实现。所有对象只在会话的生命周期内可用。</p>
<h3 id="jdbccatalog">JdbcCatalog</h3>
<p>JdbcCatalog 使用户能够通过 JDBC 协议将 Flink 与关系型数据库连接起来。PostgresCatalog 是目前 JDBC Catalog 的唯一实现。关于设置目录的更多细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/jdbc.html">JdbcCatalog 文档</a>。</p>
<h3 id="hivecatalog">HiveCatalog</h3>
<p>HiveCatalog 有两个目的，一是作为纯 Flink 元数据的持久化存储，二是作为读写现有 Hive 元数据的接口。Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/index.html">Hive 文档</a>提供了设置目录和与现有 Hive 安装接口的完整细节。</p>
<p>警告: Hive Metastore 将所有的元对象名称都存储为小写。这与 GenericInMemoryCatalog 不同，后者是区分大小写的。</p>
<h3 id="用户定义的-catalog">用户定义的 Catalog</h3>
<p>目录是可插拔的，用户可以通过实现 Catalog 接口来开发自定义目录。要在 SQL CLI 中使用自定义目录，用户应该通过实现 CatalogFactory 接口同时开发目录和它对应的目录工厂。</p>
<p>目录工厂定义了一组属性，用于在 SQL CLI 引导时配置目录。该属性集将被传递给发现服务，服务会尝试将属性与 CatalogFactory 匹配，并启动相应的目录实例。</p>
<h2 id="如何创建和注册-flink-table-到目录上">如何创建和注册 Flink Table 到目录上</h2>
<h3 id="使用-sql-ddl">使用 SQL DDL</h3>
<p>用户可以使用 SQL DDL 在 Table API 和 SQL 中创建目录中的表。</p>
<ul>
<li>Flink SQL</li>
</ul>
<pre><code>// the catalog should have been registered via yaml file
Flink SQL&gt; CREATE DATABASE mydb WITH (...);

Flink SQL&gt; CREATE TABLE mytable (name STRING, age INT) WITH (...);

Flink SQL&gt; SHOW TABLES;
mytable
</code></pre><p>详细信息，请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">Flink SQL CREATE DDL</a>。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// Create a HiveCatalog 
</span><span class="c1"></span><span class="k">val</span> <span class="n">catalog</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="s">&#34;&lt;path_of_hive_conf&gt;&#34;</span><span class="o">)</span>

<span class="c1">// Register the catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="n">catalog</span><span class="o">)</span>

<span class="c1">// Create a catalog database
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE DATABASE mydb WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// Create a catalog table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE mytable (name STRING, age INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">()</span> <span class="c1">// should return the tables in current catalog and database.
</span></code></pre></div><p>For detailed information, please check out Flink SQL CREATE DDL.</p>
<h3 id="使用-java-scala-或-python">使用 Java, Scala 或 Python</h3>
<p>用户可以使用 Java、Scala 或 Python 来编程创建目录表。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.catalog._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.catalog.hive.HiveCatalog</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.descriptors.Kafka</span>

<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">.</span><span class="n">build</span><span class="o">)</span>

<span class="c1">// Create a HiveCatalog 
</span><span class="c1"></span><span class="k">val</span> <span class="n">catalog</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="s">&#34;&lt;path_of_hive_conf&gt;&#34;</span><span class="o">)</span>

<span class="c1">// Register the catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="n">catalog</span><span class="o">)</span>

<span class="c1">// Create a catalog database 
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(...))</span>

<span class="c1">// Create a catalog table
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="nc">TableSchema</span><span class="o">.</span><span class="n">builder</span><span class="o">()</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;age&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="n">build</span><span class="o">()</span>

<span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span>
        <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> 
        <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(</span>
            <span class="n">schema</span><span class="o">,</span>
            <span class="k">new</span> <span class="nc">Kafka</span><span class="o">()</span>
                <span class="o">.</span><span class="n">version</span><span class="o">(</span><span class="s">&#34;0.11&#34;</span><span class="o">)</span>
                <span class="o">....</span>
                <span class="o">.</span><span class="n">startFromEarlist</span><span class="o">()</span>
                <span class="o">.</span><span class="n">toProperties</span><span class="o">(),</span>
            <span class="s">&#34;my comment&#34;</span>
        <span class="o">),</span>
        <span class="kc">false</span>
    <span class="o">)</span>
    
<span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span> <span class="c1">// tables should contain &#34;mytable&#34;
</span></code></pre></div><h2 id="catalog-api">Catalog API</h2>
<p>注意：这里只列出了目录程序的 API，用户可以通过 SQL DDL 实现许多相同的功能。用户可以通过 SQL DDL 实现许多相同的功能。详细的 DDL 信息，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">SQL CREATE DDL</a>。</p>
<h3 id="数据库操作">数据库操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// drop database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// alter database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// get database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">);</span>

<span class="c1">// check if a database exist
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">databaseExists</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">);</span>

<span class="c1">// list databases in a catalog
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listDatabases</span><span class="o">();</span>
</code></pre></div><h3 id="table-操作">Table 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// drop table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// alter table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// rename table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">renameTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="s">&#34;my_new_table&#34;</span><span class="o">);</span>

<span class="c1">// get table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getTable</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">);</span>

<span class="c1">// check if a table exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">tableExists</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">);</span>

<span class="c1">// list tables in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">);</span>
</code></pre></div><h3 id="视图操作">视图操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogViewImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// drop view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// alter view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogViewImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// rename view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">renameTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">),</span> <span class="s">&#34;my_new_view&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// get view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getTable</span><span class="o">(</span><span class="s">&#34;myview&#34;</span><span class="o">);</span>

<span class="c1">// check if a view exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">tableExists</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">);</span>

<span class="c1">// list views in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listViews</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">);</span>
</code></pre></div><h3 id="partition-操作">Partition 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createPartition</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...),</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionImpl</span><span class="o">(...),</span>
    <span class="kc">false</span><span class="o">);</span>

<span class="c1">// drop partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// alter partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterPartition</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...),</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionImpl</span><span class="o">(...),</span>
    <span class="kc">false</span><span class="o">);</span>

<span class="c1">// get partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...));</span>

<span class="c1">// check if a partition exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">partitionExists</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...));</span>

<span class="c1">// list partitions of a table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitions</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">));</span>

<span class="c1">// list partitions of a table under a give partition spec
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitions</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(...));</span>

<span class="c1">// list partitions of a table by expression filter
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitionsByFilter</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">),</span> <span class="nc">Arrays</span><span class="o">.</span><span class="n">asList</span><span class="o">(</span><span class="n">epr1</span><span class="o">,</span> <span class="o">...));</span>
</code></pre></div><h3 id="function-操作">Function 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogFunctionImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// drop function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// alter function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">CatalogFunctionImpl</span><span class="o">(...),</span> <span class="kc">false</span><span class="o">);</span>

<span class="c1">// get function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getFunction</span><span class="o">(</span><span class="s">&#34;myfunc&#34;</span><span class="o">);</span>

<span class="c1">// check if a function exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">functionExists</span><span class="o">(</span><span class="s">&#34;myfunc&#34;</span><span class="o">);</span>

<span class="c1">// list functions in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listFunctions</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">);</span>
</code></pre></div><h2 id="目录的-table-api-和-sql">目录的 Table API 和 SQL</h2>
<h3 id="注册目录">注册目录</h3>
<p>用户可以访问一个名为 default_catalog 的默认内存目录，这个目录总是默认创建的。该目录默认有一个名为 default_database 的单一数据库。用户也可以在现有的 Flink 会话中注册额外的目录。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomCatalog</span><span class="o">(</span><span class="s">&#34;myCatalog&#34;</span><span class="o">));</span>
</code></pre></div><ul>
<li>YAML</li>
</ul>
<p>所有使用 YAML 定义的目录必须提供一个 <code>type</code> 属性，指定目录的类型。以下类型是开箱即用的。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Catalog</th>
<th style="text-align:left">Type Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">GenericInMemory</td>
<td style="text-align:left">generic_in_memory</td>
</tr>
<tr>
<td style="text-align:left">Hive</td>
<td style="text-align:left">hive</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">myCatalog</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">custom_catalog</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">...</span><span class="w">
</span></code></pre></div><h3 id="更改当前目录和数据库">更改当前目录和数据库</h3>
<p>Flink 将始终搜索当前目录和数据库中的表、视图和 UDF。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">useCatalog</span><span class="o">(</span><span class="s">&#34;myCatalog&#34;</span><span class="o">);</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">useDatabase</span><span class="o">(</span><span class="s">&#34;myDb&#34;</span><span class="o">);</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; USE CATALOG myCatalog<span class="p">;</span>
Flink SQL&gt; USE myDB<span class="p">;</span>
</code></pre></div><p>通过提供 catalog.database.object 形式的完全限定名称，可以访问非当前目录的元数据。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;not_the_current_catalog.not_the_current_db.my_table&#34;</span><span class="o">);</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; SELECT * FROM not_the_current_catalog.not_the_current_db.my_table<span class="p">;</span>
</code></pre></div><h3 id="列出可用的目录">列出可用的目录</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listCatalogs</span><span class="o">();</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show catalogs<span class="p">;</span>
</code></pre></div><h3 id="列出可用的数据库">列出可用的数据库</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listDatabases</span><span class="o">();</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show databases<span class="p">;</span>
</code></pre></div><h3 id="列出可用的表">列出可用的表</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">();</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show tables<span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/catalogs" term="catalogs" label="Catalogs" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Create 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-create-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Create Statements</blockquote><h1 id="create-语句">CREATE 语句</h1>
<p>CREATE 语句用于在当前或指定的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册一个表/视图/函数。注册的表/视图/函数可以在 SQL 查询中使用。</p>
<p>Flink SQL 目前支持以下 CREATE 语句。</p>
<ul>
<li>CREATE TABLE</li>
<li>CREATE DATABASE</li>
<li>CREATE VIEW</li>
<li>CREATE FUNCTION</li>
</ul>
<h2 id="运行一条-create-语句">运行一条 CREATE 语句</h2>
<p>CREATE 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中执行。executeSql()方法对于一个成功的 CREATE 操作会返回&rsquo;OK'，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 CREATE 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Scala
</span><span class="c1"></span><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">()...</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// SQL query with a registered table
</span><span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">);</span>
<span class="c1">// run a SQL query on the Table and retrieve the result as a new Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">);</span>

<span class="c1">// Execute insert SQL with a registered table
</span><span class="c1">// register a TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE RubberOrders(product STRING, amount INT) WITH (&#39;connector.path&#39;=&#39;/path/to/file&#39; ...)&#34;</span><span class="o">);</span>
<span class="c1">// run an insert SQL on the Table and emit the result to the TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; CREATE TABLE Orders <span class="o">(</span><span class="sb">`</span>user<span class="sb">`</span> BIGINT, product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; CREATE TABLE RubberOrders <span class="o">(</span>product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE <span class="s1">&#39;%Rubber%&#39;</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Submitting SQL update statement to the cluster...
</code></pre></div><h2 id="create-table">CREATE TABLE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span>
  <span class="p">(</span>
    <span class="err">{</span> <span class="o">&lt;</span><span class="n">column_definition</span><span class="o">&gt;</span> <span class="o">|</span> <span class="o">&lt;</span><span class="n">computed_column_definition</span><span class="o">&gt;</span> <span class="err">}</span><span class="p">[</span> <span class="p">,</span> <span class="p">...</span><span class="n">n</span><span class="p">]</span>
    <span class="p">[</span> <span class="o">&lt;</span><span class="n">watermark_definition</span><span class="o">&gt;</span> <span class="p">]</span>
    <span class="p">[</span> <span class="o">&lt;</span><span class="n">table_constraint</span><span class="o">&gt;</span> <span class="p">][</span> <span class="p">,</span> <span class="p">...</span><span class="n">n</span><span class="p">]</span>
  <span class="p">)</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">table_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">partition_column_name1</span><span class="p">,</span> <span class="n">partition_column_name2</span><span class="p">,</span> <span class="p">...)]</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)</span>
  <span class="p">[</span> <span class="k">LIKE</span> <span class="n">source_table</span> <span class="p">[(</span> <span class="o">&lt;</span><span class="n">like_options</span><span class="o">&gt;</span> <span class="p">)]</span> <span class="p">]</span>
   
<span class="o">&lt;</span><span class="n">column_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="k">column_name</span> <span class="n">column_type</span> <span class="p">[</span> <span class="o">&lt;</span><span class="n">column_constraint</span><span class="o">&gt;</span> <span class="p">]</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">column_comment</span><span class="p">]</span>
  
<span class="o">&lt;</span><span class="n">column_constraint</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="p">[</span><span class="k">CONSTRAINT</span> <span class="k">constraint_name</span><span class="p">]</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="k">NOT</span> <span class="n">ENFORCED</span>

<span class="o">&lt;</span><span class="n">table_constraint</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="p">[</span><span class="k">CONSTRAINT</span> <span class="k">constraint_name</span><span class="p">]</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="k">column_name</span><span class="p">,</span> <span class="p">...)</span> <span class="k">NOT</span> <span class="n">ENFORCED</span>

<span class="o">&lt;</span><span class="n">computed_column_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="k">column_name</span> <span class="k">AS</span> <span class="n">computed_column_expression</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">column_comment</span><span class="p">]</span>

<span class="o">&lt;</span><span class="n">watermark_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">rowtime_column_name</span> <span class="k">AS</span> <span class="n">watermark_strategy_expression</span>
  
<span class="o">&lt;</span><span class="n">like_options</span><span class="o">&gt;</span><span class="p">:</span>
<span class="err">{</span>
   <span class="err">{</span> <span class="k">INCLUDING</span> <span class="o">|</span> <span class="k">EXCLUDING</span> <span class="err">}</span> <span class="err">{</span> <span class="k">ALL</span> <span class="o">|</span> <span class="k">CONSTRAINTS</span> <span class="o">|</span> <span class="n">PARTITIONS</span> <span class="err">}</span>
 <span class="o">|</span> <span class="err">{</span> <span class="k">INCLUDING</span> <span class="o">|</span> <span class="k">EXCLUDING</span> <span class="o">|</span> <span class="n">OVERWRITING</span> <span class="err">}</span> <span class="err">{</span> <span class="k">GENERATED</span> <span class="o">|</span> <span class="k">OPTIONS</span> <span class="o">|</span> <span class="n">WATERMARKS</span> <span class="err">}</span> 
<span class="err">}</span><span class="p">[,</span> <span class="p">...]</span>
</code></pre></div><p>用给定的名称创建一个表。如果目录中已经存在同名表，则抛出一个异常。</p>
<p><strong>计算列</strong></p>
<p>计算列是使用 &ldquo;column_name AS computed_column_expression&rdquo; 语法生成的虚拟列。它是由一个非查询表达式生成的，这个表达式使用同一张表中的其他列，而不是实际存储在表中。例如，计算列可以定义为 <code>cost AS price * quantity</code>。表达式可以包含物理列、常量、函数或变量的任意组合。表达式不能包含子查询。</p>
<p>计算列在 Flink 中通常用于在 CREATE TABLE 语句中定义<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。可以通过 <code>proc AS PROCTIME()</code> 使用系统 <code>proctime()</code> 函数轻松定义一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">处理时间属性</a>。另一方面，计算列可以用来派生事件时间列，因为事件时间列可能需要从现有的字段中派生出来，比如原来的字段不是 TIMESTAMP(3)类型，或者嵌套在 JSON 字符串中。</p>
<p>注意：</p>
<ul>
<li>在源表上定义的计算列是在从源表读取后计算出来的，它可以用在下面的 SELECT 查询语句中。</li>
<li>计算列不能作为 INSERT 语句的目标。在 INSERT 语句中，SELECT 子句的模式应该与没有计算列的目标表的模式相匹配。</li>
</ul>
<p><strong>WATERMARK</strong></p>
<p>WATERMARK 定义了表的事件时间属性，其形式为 <code>WATERMARK FOR rowtime_column_name AS watermark_strategy_expression</code>。</p>
<p><code>rowtime_column_name</code> 定义了一个现有的列，该列被标记为表的事件时间属性。这个列的类型必须是 TIMESTAMP(3)，并且是模式中的顶层列。它可以是一个计算列。</p>
<p><code>watermark_strategy_expression</code> 定义了水印生成策略。它允许任意的非查询表达式，包括计算列，来计算水印。表达式的返回类型必须是 TIMESTAMP(3)，它表示自 Epoch 以来的时间戳。只有当返回的水印是非空的，并且它的值大于之前发出的本地水印时，才会发出水印（以保留升水印的契约）。水印生成表达式由框架对每条记录进行评估。框架将定期发射最大的生成水印。如果当前的水印仍然与上一个水印相同，或者是空的，或者返回的水印值小于上一次发射的水印值，那么将不会发射新的水印。水印是在 <code>pipeline.auto-watermark-interval</code> 配置定义的时间间隔内发出的。如果水印间隔为 0ms，如果生成的水印不是空的，并且大于最后一个水印，则每条记录都会发出水印。</p>
<p>当使用事件时间语义时，表必须包含事件时间属性和水印策略。</p>
<p>Flink 提供了几种常用的水印策略。</p>
<ul>
<li>
<p>严格的升序时间戳。WATERMARK FOR rowtime_column AS rowtime_column。</p>
</li>
<li>
<p>发出迄今为止观察到的最大时间戳的水印。时间戳小于最大时间戳的行不会迟到。</p>
</li>
<li>
<p>升序时间戳。WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;0.001&rsquo; SECOND.</p>
</li>
<li>
<p>发出迄今为止观察到的最大时间戳的水印减 1。时间戳等于或小于最大时间戳的行不会迟到。</p>
</li>
<li>
<p>绑定出顺序性的时间戳。WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;string&rsquo; timeUnit.</p>
</li>
</ul>
<p>发出水印，水印是最大观察到的时间戳减去指定的延迟，例如：WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;5&rsquo; SECOND 是 5 秒的延迟水印策略。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span> <span class="p">.</span> <span class="p">.</span> <span class="p">.</span> <span class="p">);</span>
<span class="k">PRIMARY</span> <span class="k">KEY</span>
</code></pre></div><p><strong>PRIMARY KEY</strong></p>
<p>Flink 利用优化的一个提示。它告诉我们一个表或视图的一列或一组列是唯一的，它们不包含空值。主键中的两列都不能为空。因此，主键可以唯一地识别表中的某一行。</p>
<p>主键约束既可以和列定义一起声明（列约束），也可以作为单行（表约束）。对于这两种情况，只能将其声明为一个单子。如果你同时定义了多个主键约束，就会抛出一个异常。</p>
<p><strong>有效性检查</strong></p>
<p>SQL 标准规定，一个约束可以是 ENFORCED 或 NOT ENFORCED。这控制了约束检查是否会在输入/输出数据上执行。Flink 并不拥有数据，因此我们要支持的唯一模式是 NOT ENFORCED 模式。用户要确保查询强制执行密钥的完整性。</p>
<p>Flink 会假设主键的正确性，假设列的空性与主键的列对齐。连接器应该确保这些是对齐的。</p>
<p>注意事项: 在 CREATE TABLE 语句中，创建主键约束会改变列的可空性，也就是说，有主键约束的列是不可空的。</p>
<p><strong>PARTITIONED BY</strong></p>
<p>按指定的列对创建的表进行分区。如果该表被用作文件系统汇，则会为每个分区创建一个目录。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>表属性用于创建表源/接收器。这些属性通常用于查找和创建底层连接器。</p>
<p>表达式 key1=val1 的键和值都应该是字符串文字。关于不同连接器的所有支持的表属性，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统</a>中的详细信息。</p>
<p>注释：表名可以有三种格式。表名可以有三种格式。</p>
<ol>
<li>catalog_name.db_name.table_name</li>
<li>db_name.table_name</li>
<li>table_name。</li>
</ol>
<p>对于 catalog_name.db_name.table_name，表将被注册到元存储中，目录名为 &ldquo;catalog_name&rdquo;，数据库名为 &ldquo;db_name&rdquo;；对于 db_name.table_name，表将被注册到执行表环境的当前目录中，数据库名为 &ldquo;db_name&rdquo;；对于 table_name，表将被注册到执行表环境的当前目录和数据库中。</p>
<p>注意事项: 用 CREATE TABLE 语句注册的表既可以作为表源，也可以作为表汇，在 DMLs 中没有引用之前，我们不能决定它是作为表源还是表汇使用。</p>
<p><strong>LIKE 子句</strong></p>
<p>LIKE 子句是 SQL 特征的变体/组合（特征 T171，&ldquo;表定义中的 LIKE 子句&quot;和特征 T173，&ldquo;表定义中的扩展 LIKE 子句&rdquo;）。该子句可用于根据现有表的定义创建一个表。此外，用户还可以扩展原表或排除其中的某些部分。与 SQL 标准不同的是，该子句必须在 CREATE 语句的顶层定义。这是因为该子句适用于定义的多个部分，而不仅仅是模式部分。</p>
<p>你可以使用该子句来重用（并可能覆盖）某些连接器属性，或者为外部定义的表添加水印。例如，您可以为 Apache Hive 中定义的表添加水印。</p>
<p>请考虑下面的示例语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span> 
    <span class="s1">&#39;connector&#39;</span> <span class="o">=</span> <span class="s1">&#39;kafka&#39;</span><span class="p">,</span>
    <span class="s1">&#39;scan.startup.mode&#39;</span> <span class="o">=</span> <span class="s1">&#39;earliest-offset&#39;</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_with_watermark</span> <span class="p">(</span>
    <span class="c1">-- Add watermark definition
</span><span class="c1"></span>    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="c1">-- Overwrite the startup-mode
</span><span class="c1"></span>    <span class="s1">&#39;scan.startup.mode&#39;</span> <span class="o">=</span> <span class="s1">&#39;latest-offset&#39;</span>
<span class="p">)</span>
<span class="k">LIKE</span> <span class="n">Orders</span><span class="p">;</span>
</code></pre></div><p>由此产生的 Orders_with_watermark 表将等同于用以下语句创建的表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_with_watermark</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="s1">&#39;connector&#39;</span> <span class="o">=</span> <span class="s1">&#39;kafka&#39;</span><span class="p">,</span>
    <span class="s1">&#39;scan.startup.mode&#39;</span> <span class="o">=</span> <span class="s1">&#39;latest-offset&#39;</span>
<span class="p">);</span>
</code></pre></div><p>可以用同类选项控制表功能的合并逻辑。</p>
<p>您可以控制以下的合并行为:</p>
<ul>
<li>CONSTRAINTS - 主键和唯一键等约束条件。</li>
<li>GENERATED-计算列</li>
<li>OPTIONS - 描述连接器和格式属性的连接器选项。</li>
<li>PARTITIONS - 表的分区</li>
<li>WATERMARKS - 水印声明</li>
</ul>
<p>有三种不同的合并策略。</p>
<ul>
<li>INCLUDING - 包括源表的特征，对重复的条目失败，例如，如果两个表中都存在相同键的选项。</li>
<li>EXCLUDING - 不包含源表的给定特征。</li>
<li>OVERWRITING - 包括源表的特征，用新表的属性覆盖源表的重复条目，例如，如果两个表中都存在具有相同键的选项，则将使用当前语句中的选项。</li>
</ul>
<p>此外，可以使用 INCLUDING/EXCLUDING ALL 选项来指定如果没有定义特定的策略应该是什么，即如果使用 EXCLUDING ALL INCLUDING WATERMARKS，则只从源表中包含水印。</p>
<p>例子：</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="c1">-- A source table stored in a filesystem
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_in_file</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time_string</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">AS</span> <span class="n">to_timestamp</span><span class="p">(</span><span class="n">order_time</span><span class="p">)</span>
    
<span class="p">)</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="k">user</span> 
<span class="k">WITH</span> <span class="p">(</span> 
    <span class="s1">&#39;connector&#39;</span> <span class="o">=</span> <span class="s1">&#39;filesystem&#39;</span>
    <span class="s1">&#39;path&#39;</span> <span class="o">=</span> <span class="s1">&#39;...&#39;</span>
<span class="p">);</span>

<span class="c1">-- A corresponding table we want to store in kafka
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_in_kafka</span> <span class="p">(</span>
    <span class="c1">-- Add watermark definition
</span><span class="c1"></span>    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="s1">&#39;connector&#39;</span><span class="p">:</span> <span class="s1">&#39;kafka&#39;</span>
    <span class="p">...</span>
<span class="p">)</span>
<span class="k">LIKE</span> <span class="n">Orders_in_file</span> <span class="p">(</span>
    <span class="c1">-- Exclude everything besides the computed columns which we need to generate the watermark for.
</span><span class="c1"></span>    <span class="c1">-- We do not want to have the partitions or filesystem options as those do not apply to kafka. 
</span><span class="c1"></span>    <span class="k">EXCLUDING</span> <span class="k">ALL</span>
    <span class="k">INCLUDING</span> <span class="k">GENERATED</span>
<span class="p">);</span>
</code></pre></div><p>如果您没有提供同类选项，则默认使用 <code>INCLUDING ALL OVERWRITING OPTIONS</code>。</p>
<p>注意: 您无法控制合并物理字段的行为。这些字段将被合并，就像您应用 <strong>INCLUDING</strong> 策略一样。</p>
<h2 id="create-catalog">CREATE CATALOG</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">CATALOG</span> <span class="k">catalog_name</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)</span>
</code></pre></div><p>用给定的目录属性创建一个目录。如果已经存在同名的目录，则会产生异常。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>目录属性，用于存储与本目录相关的额外信息。表达式 key1=val1 的键和值都应该是字符串文字。</p>
<p>更多详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>。</p>
<h2 id="create-database">CREATE DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.]</span><span class="n">db_name</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">database_comment</span><span class="p">]</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)</span>
</code></pre></div><p>用给定的数据库属性创建一个数据库，如果目录中已经存在同名的数据库，则抛出异常。如果目录中已经存在相同名称的数据库，则会抛出异常。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果数据库已经存在，则不会发生任何事情。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>数据库属性，用于存储与本数据库相关的额外信息。表达式 key1=val1 的键和值都应该是字符串文字。</p>
<h2 id="create-view">CREATE VIEW</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="k">VIEW</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="n">view_name</span>
  <span class="p">[</span><span class="err">{</span><span class="n">columnName</span> <span class="p">[,</span> <span class="n">columnName</span> <span class="p">]</span><span class="o">*</span> <span class="err">}</span><span class="p">]</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">view_comment</span><span class="p">]</span>
  <span class="k">AS</span> <span class="n">query_expression</span>
</code></pre></div><p>用给定的查询表达式创建一个视图，如果目录中已经存在同名的视图，则抛出异常。如果目录中已经存在同名的视图，则会抛出异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>创建具有目录和数据库命名空间并覆盖视图的临时视图。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果视图已经存在，则不会发生任何事情。</p>
<h2 id="create-function">CREATE FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> 
  <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="n">function_name</span> 
  <span class="k">AS</span> <span class="n">identifier</span> <span class="p">[</span><span class="k">LANGUAGE</span> <span class="n">JAVA</span><span class="o">|</span><span class="n">SCALA</span><span class="o">|</span><span class="n">PYTHON</span><span class="p">]</span>
</code></pre></div><p>创建一个目录函数，该函数具有目录和数据库的名称空间，并带有标识符和可选的语言标签。如果目录中已经存在同名函数，则会抛出一个异常。</p>
<p>如果语言标签是 JAVA/SCALA，标识符是 UDF 的完整 classpath。关于 Java/Scala UDF 的实现，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">User-defined Functions</a> 了解详情。</p>
<p>如果语言标签是 PYTHON，标识符是 UDF 的完全限定名，例如 pyflink.table.test.test_udf.add。关于 Python UDF 的实现，更多细节请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>。</p>
<p><strong>TEMPORARY</strong></p>
<p>创建具有目录和数据库命名空间并覆盖目录功能的临时目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>创建没有命名空间并覆盖内置函数的临时系统函数。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果函数已经存在，则不会发生任何事情。</p>
<p><strong>LANGUAGE JAVA|SCALA|PYTHON</strong></p>
<p>语言标签，用于指示 Flink 运行时如何执行函数。目前只支持 JAVA、SCALA 和 PYTHON，函数的默认语言是 JAVA。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Dataset 变换]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="related" type="text/html" title="本地执行" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Dataset Transformations</blockquote><h1 id="dataset-转换">DataSet 转换</h1>
<p>本文档深入介绍了 DataSets 上可用的转换。关于 Flink Java API 的一般介绍，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">编程指南</a>。</p>
<p>对于密集索引的数据集中的压缩元素，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/zip_elements_guide.html">压缩元素指南</a>。</p>
<h2 id="map">Map</h2>
<p>Map 转换将用户定义的映射函数应用于 DataSet 的每个元素。它实现了一对一的映射，也就是说，函数必须准确地返回一个元素。</p>
<p>下面的代码将一个由整数对组成的 DataSet 转化为一个由整数组成的 DataSet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">intPairs</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">intSums</span> <span class="k">=</span> <span class="n">intPairs</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">pair</span> <span class="k">=&gt;</span> <span class="n">pair</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">pair</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
</code></pre></div><h2 id="flatmap">FlatMap</h2>
<p>FlatMap 转换在 DataSet 的每个元素上应用了一个用户定义的 <code>flat-map</code> 函数。这种映射函数的变体可以为每个输入元素返回任意多个结果元素（包括没有）。</p>
<p>下面的代码将一个文本行的 DataSet 转换为一个单词的 DataSet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">textLines</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">words</span> <span class="k">=</span> <span class="n">textLines</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><h2 id="mappartition">MapPartition</h2>
<p>MapPartition 在一次函数调用中转换一个并行分区。map-partition 函数以 Iterable 的形式获取分区，并可以产生任意数量的结果值。每个分区中元素的数量取决于平行度和之前的操作。</p>
<p>下面的代码将文本行的 DataSet 转换为每个分区的计数 DataSet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">textLines</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// Some is required because the return value must be a Collection.
</span><span class="c1">// There is an implicit conversion from Option to a Collection.
</span><span class="c1"></span><span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">texLines</span><span class="o">.</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="n">in</span> <span class="k">=&gt;</span> <span class="nc">Some</span><span class="o">(</span><span class="n">in</span><span class="o">.</span><span class="n">size</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><h2 id="filter">Filter</h2>
<p>过滤器转换将用户定义的过滤器函数应用于 DataSet 的每个元素，并且只保留那些函数返回为真的元素。</p>
<p>以下代码从数据集中删除所有小于零的整数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">intNumbers</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">naturalNumbers</span> <span class="k">=</span> <span class="n">intNumbers</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">}</span>
</code></pre></div><p>重要：系统假设函数不会修改应用谓词的元素。违反这个假设会导致错误的结果。</p>
<h2 id="元组数据集的投影projection">元组数据集的投影(Projection)</h2>
<p><code>Project</code> 转换删除或移动 Tuple DataSet 的 Tuple 字段。<code>project(int...)</code> 方法通过其索引选择应该保留的 Tuple 字段，并定义它们在输出 Tuple 中的顺序。</p>
<p>投影(Projection)不需要定义用户函数。</p>
<p>下面的代码显示了在 DataSet 上应用 <code>Project</code> 转换的不同方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Double</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]
</span><span class="c1">// converts Tuple3&lt;Integer, Double, String&gt; into Tuple2&lt;String, Integer&gt;
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">project</span><span class="o">(</span><span class="n">2</span><span class="o">,</span><span class="n">0</span><span class="o">);</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">#</span> <span class="n">scala</span>
<span class="nc">Not</span> <span class="n">supported</span><span class="o">.</span>
</code></pre></div><h3 id="分组数据集上的变换">分组数据集上的变换</h3>
<p><code>reduce</code> 操作可以对分组的数据集进行操作。指定用于分组的键可以通过多种方式进行。</p>
<ul>
<li>键表达式</li>
<li>键选择器函数</li>
<li>一个或多个字段位置键（仅限元组数据集）。</li>
<li>case 类字段(仅 case 类)</li>
</ul>
<p>请看一下 <code>reduce</code> 的例子，看看如何指定分组键。</p>
<h3 id="换算分组数据集">换算分组数据集</h3>
<p>应用于分组数据集的 <code>Reduce</code> 转换，使用用户定义的 <code>Reduce</code> 函数将每个分组换算为一个元素。对于每一组输入元素，一个 Reduce 函数将成对的元素连续组合成一个元素，直到每组只剩下一个元素。</p>
<p>请注意，对于一个 <code>ReduceFunction</code>，返回对象的键字段应该与输入值相匹配。这是因为 <code>reduce</code> 是隐式可组合的，当传递给 <code>reduce</code> 运算符时，从 <code>combine</code> 运算符发出的对象又是按键分组的。</p>
<h4 id="在按键表达式分组的数据集上进行-reduce-操作">在按键表达式分组的数据集上进行 Reduce 操作</h4>
<p>键表达式指定了 DataSet 中每个元素的一个或多个字段。每个键表达式都是一个公共字段的名称或一个 getter 方法。点号可以用来深入到对象中。键表达式 <code>&quot;*&quot;</code> 可以选择所有字段。下面的代码展示了如何使用键表达式对 POJO 数据集进行分组，并使用 <code>reduce</code> 函数对其进行换算。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO
</span><span class="c1"></span><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">val</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">val</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="c1">// [...]
</span><span class="c1"></span><span class="o">}</span>

<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">).</span><span class="n">reduce</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">w1</span><span class="o">,</span> <span class="n">w2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">WC</span><span class="o">(</span><span class="n">w1</span><span class="o">.</span><span class="n">word</span><span class="o">,</span> <span class="n">w1</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="n">w2</span><span class="o">.</span><span class="n">count</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="对按键选择器分组的数据集进行换算">对按键选择器分组的数据集进行换算</h4>
<p>键选择器函数从数据集的每个元素中提取一个键值。提取的键值用于对 DataSet 进行分组。下面的代码展示了如何使用键选择器函数对 POJO 数据集进行分组，并使用 reduce 函数对其进行换算。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO
</span><span class="c1"></span><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">val</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">val</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="c1">// [...]
</span><span class="c1"></span><span class="o">}</span>

<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">groupBy</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">word</span> <span class="o">}</span> <span class="n">reduce</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">w1</span><span class="o">,</span> <span class="n">w2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">WC</span><span class="o">(</span><span class="n">w1</span><span class="o">.</span><span class="n">word</span><span class="o">,</span> <span class="n">w1</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="n">w2</span><span class="o">.</span><span class="n">count</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="对按字段位置键分组的数据集进行换算仅元组数据集">对按字段位置键分组的数据集进行换算（仅元组数据集）</h4>
<p>字段位置键指定了一个 Tuple DataSet 的一个或多个字段，这些字段被用作分组键。下面的代码显示了如何使用字段位置键和应用 reduce 函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tuples</span> <span class="k">=</span> <span class="nc">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// group on the first and second Tuple field
</span><span class="c1"></span><span class="k">val</span> <span class="n">reducedTuples</span> <span class="k">=</span> <span class="n">tuples</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">).</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h4 id="对按-case-类字段分组的数据集进行换算">对按 case 类字段分组的数据集进行换算</h4>
<p>当使用 Case Classes 时，你也可以使用字段的名称来指定分组键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">MyClass</span><span class="o">(</span><span class="k">val</span> <span class="n">a</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">c</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tuples</span> <span class="k">=</span> <span class="nc">DataSet</span><span class="o">[</span><span class="kt">MyClass</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// group on the first and second field
</span><span class="c1"></span><span class="k">val</span> <span class="n">reducedTuples</span> <span class="k">=</span> <span class="n">tuples</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">).</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h3 id="在分组数据集上进行分组换算">在分组数据集上进行分组换算</h3>
<p>应用在分组 DataSet 上的 GroupReduce 转换，会对每个组调用用户定义的 <code>group-reduce</code> 函数。这与 Reduce 之间的区别在于，用户定义的函数可以一次性获得整个组。该函数是在一个组的所有元素上用一个 <code>Iterable</code> 调用的，并且可以返回任意数量的结果元素。</p>
<h4 id="在按字段位置键分组的数据集上进行分组-reduce只适用于元组数据集">在按字段位置键分组的数据集上进行分组 Reduce(只适用于元组数据集)</h4>
<p>下面的代码显示了如何从一个按 Integer 分组的 DataSet 中删除重复的字符串。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">reduceGroup</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">in</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)])</span> <span class="k">=&gt;</span>
        <span class="n">in</span><span class="o">.</span><span class="n">toSet</span> <span class="n">foreach</span> <span class="o">(</span><span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">)</span>
    <span class="o">}</span>
</code></pre></div><h4 id="对按键表达式键选择器函数或-case-类字段分组的数据集进行分组换算">对按键表达式、键选择器函数或 case 类字段分组的数据集进行分组换算</h4>
<p>类似于 Reduce 变换中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-dataset-grouped-by-key-expression">键表达式</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-dataset-grouped-by-keyselector-function">键选择器函数</a>和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-dataset-grouped-by-case-class-fields">case 类字段</a>的工作。</p>
<h4 id="对排序组进行-groupreduce">对排序组进行 GroupReduce</h4>
<p>一个 <code>group-reduce</code> 函数使用一个 Iterable 访问一个组的元素。可选地，Iterable 可以按照指定的顺序输出一个组的元素。在许多情况下，这有助于降低用户定义的 <code>group-reduce</code> 函数的复杂性，并提高其效率。</p>
<p>下面的代码显示了另一个例子，如何在一个由整数分组并按 String 排序的 DataSet 中删除重复的 String。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">sortGroup</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">reduceGroup</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">in</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)])</span> <span class="k">=&gt;</span>
        <span class="k">var</span> <span class="n">prev</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="kc">null</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">t</span> <span class="k">&lt;-</span> <span class="n">in</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">if</span> <span class="o">(</span><span class="n">prev</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="n">prev</span> <span class="o">!=</span> <span class="n">t</span><span class="o">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">t</span><span class="o">)</span>
            <span class="n">prev</span> <span class="k">=</span> <span class="n">t</span>
        <span class="o">}</span>
    <span class="o">}</span>
</code></pre></div><p>注意：如果在 <code>reduce</code> 操作之前，使用运算符的基于排序的执行策略建立了分组，那么 GroupSort 通常是免费的。</p>
<h4 id="可组合的-groupreducefunctions">可组合的 GroupReduceFunctions</h4>
<p>与 reduce 函数不同，<code>group-reduce</code> 函数是不可隐式组合的。为了使一个分组换算函数可以组合，它必须实现 <code>GroupCombineFunction</code> 接口。</p>
<p>重要：<code>GroupCombineFunction</code> 接口的通用输入和输出类型必须等于 <code>GroupReduceFunction</code> 的通用输入类型，如下例所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Combinable GroupReduceFunction that computes two sums.
</span><span class="c1"></span><span class="k">class</span> <span class="nc">MyCombinableGroupReducer</span>
  <span class="k">extends</span> <span class="nc">GroupReduceFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="kt">String</span><span class="o">]</span>
  <span class="k">with</span> <span class="nc">GroupCombineFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span>
<span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="n">reduce</span><span class="o">(</span>
    <span class="n">in</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)],</span>
    <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
  <span class="o">{</span>
    <span class="k">val</span> <span class="n">r</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span>
      <span class="n">in</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">asScala</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span><span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="o">)</span>
    <span class="c1">// concat key and sum and emit
</span><span class="c1"></span>    <span class="n">out</span><span class="o">.</span><span class="n">collect</span> <span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="s">&#34;-&#34;</span> <span class="o">+</span> <span class="n">r</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">combine</span><span class="o">(</span>
    <span class="n">in</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)],</span>
    <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
  <span class="o">{</span>
    <span class="k">val</span> <span class="n">r</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span>
      <span class="n">in</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">asScala</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span><span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="o">)</span>
    <span class="c1">// emit tuple with key and sum
</span><span class="c1"></span>    <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">r</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="在分组数据集上进行分组合并">在分组数据集上进行分组合并</h3>
<p><code>GroupCombine</code> 变换是可组合的 <code>GroupReduceFunction</code> 中 <code>combine</code> 步骤的泛化形式。与此相反，<code>GroupReduce</code> 函数中的 <code>combine</code> 步骤只允许从输入类型 I 到输出类型 I 的组合。这是因为 <code>GroupReduce</code> 函数中的 <code>reduce</code> 步骤期望输入类型 I。</p>
<p>在某些应用中，希望在执行额外的转换（例如减少数据大小）之前，将一个数据集合并成中间格式。这可以通过一个 <code>CombineGroup</code> 转换来实现，而且成本很低。</p>
<p>注意：对分组数据集的 <code>GroupCombine</code> 是在内存中以贪婪的策略执行的，它可能不会一次处理所有数据，而是分多个步骤进行。它也是在各个分区上执行的，而不像 <code>GroupReduce</code> 变换那样进行数据交换。这可能会导致部分结果。</p>
<p>下面的例子演示了如何使用 <code>CombineGroup</code> 变换来实现另一种 <code>WordCount</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">..</span><span class="o">]</span> <span class="c1">// The words received as input
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">combinedWords</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">combineGroup</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">words</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)])</span> <span class="k">=&gt;</span>
        <span class="k">var</span> <span class="n">key</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="kc">null</span>
        <span class="k">var</span> <span class="n">count</span> <span class="k">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="o">(</span><span class="n">word</span> <span class="k">&lt;-</span> <span class="n">words</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">key</span> <span class="k">=</span> <span class="n">word</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="o">}</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">key</span><span class="o">,</span> <span class="n">count</span><span class="o">))</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">combinedWords</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">reduceGroup</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">words</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)])</span> <span class="k">=&gt;</span>
        <span class="k">var</span> <span class="n">key</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="kc">null</span>
        <span class="k">var</span> <span class="n">sum</span> <span class="k">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="o">((</span><span class="n">word</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">&lt;-</span> <span class="n">words</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">key</span> <span class="k">=</span> <span class="n">word</span>
            <span class="n">sum</span> <span class="o">+=</span> <span class="n">count</span>
        <span class="o">}</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">key</span><span class="o">,</span> <span class="n">sum</span><span class="o">))</span>
<span class="o">}</span>
</code></pre></div><p>上面的另一种 <code>WordCount</code> 实现演示了 <code>GroupCombine</code> 如何在执行 <code>GroupReduce</code> 转换之前组合单词。上面的例子只是一个概念证明。请注意，组合步骤如何改变 DataSet 的类型，通常在执行 <code>GroupReduce</code> 之前需要进行额外的 Map 转换。</p>
<h4 id="在分组元组数据集上进行聚合">在分组元组数据集上进行聚合</h4>
<p>有一些常用的聚合操作是经常使用的。Aggregate 转换提供了以下内置的聚合函数。</p>
<ul>
<li>Sum,</li>
<li>Min,</li>
<li>Max.</li>
</ul>
<p>Aggregate 变换只能应用在 Tuple 数据集上，并且只支持字段位置键进行分组。</p>
<p>下面的代码显示了如何在按字段位置键分组的数据集上应用&quot;聚合&quot;变换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">SUM</span><span class="o">,</span> <span class="mi">0</span><span class="o">).</span><span class="n">and</span><span class="o">(</span><span class="nc">MIN</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
</code></pre></div><p>要在一个 DataSet 上应用多个聚合，必须在第一个聚合之后使用 <code>.and()</code> 函数，也就是说 <code>.aggregary(SUM, 0).and(MIN, 2)</code> 会产生原始 DataSet 的字段 0 和字段 2 的最小值之和。与此相反，<code>.aggregary(SUM，0).aggregary(MIN，2)</code> 将在一个聚合上应用一个聚合。在给定的示例中，它将在计算字段 0 与字段 1 分组后产生字段 2 的最小值。</p>
<p>注意：聚合函数集将在未来得到扩展。</p>
<h4 id="对分组元组数据集的-minby--maxby-函数">对分组元组数据集的 MinBy / MaxBy 函数</h4>
<p><code>MinBy (MaxBy)</code> 转换为每组元组选择一个元组。被选择的元组是一个或多个指定字段的值是最小（最大）的元组。用于比较的字段必须是有效的关键字段，即可比较的字段。如果多个元组具有最小（最大）字段值，则返回这些元组的任意元组。</p>
<p>下面的代码显示了如何从 <code>DataSet&lt;Tuple3&lt;Integer, String, Double&gt;&gt;</code> 中选择具有相同 String 值的每组元组的 Integer 和 Double 字段最小值的元组。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span>
                                   <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>  <span class="c1">// group DataSet on second field
</span><span class="c1"></span>                                   <span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span> <span class="c1">// select tuple with minimum values for first and third field.
</span></code></pre></div><h3 id="换算整个数据集">换算整个数据集</h3>
<p>Reduce 转换将用户定义的 <code>reduce</code> 函数应用于一个数据集的所有元素。随后，<code>reduce</code> 函数将元素对组合成一个元素，直到只剩下一个元素。</p>
<p>下面的代码显示了如何对一个整数数据集的所有元素进行求和。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">intNumbers</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sum</span> <span class="k">=</span> <span class="n">intNumbers</span><span class="o">.</span><span class="n">reduce</span> <span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>
</code></pre></div><p>使用 Reduce 转换换算一个完整的 DataSet 意味着最后的 Reduce 操作不能并行完成。然而，<code>reduce</code> 函数是可以自动组合的，因此 Reduce 转换不会限制大多数用例的可扩展性。</p>
<h3 id="对整个数据集进行分组换算">对整个数据集进行分组换算</h3>
<p><code>GroupReduce</code> 转换将用户定义的 <code>group-reduce</code> 函数应用于 DataSet 的所有元素。<code>group-reduce</code> 可以遍历 DataSet 的所有元素，并返回任意数量的结果元素。</p>
<p>下面的示例展示了如何在一个完整的 DataSet 上应用 <code>GroupReduce</code> 转换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyGroupReducer</span><span class="o">())</span>
</code></pre></div><p>注意：如果 <code>group-reduce</code> 函数不可组合，那么在一个完整的 DataSet 上的 <code>GroupReduce</code> 转换不能并行完成。因此，这可能是一个非常耗费计算的操作。请参阅上面的&quot;可组合的 GroupReduceFunctions&quot; 部分，了解如何实现可组合的 <code>group-reduce</code> 函数。</p>
<h3 id="在完整的数据集上进行分组合并groupcombine">在完整的数据集上进行分组合并(GroupCombine)</h3>
<p>在一个完整的 DataSet 上的 GroupCombine 的工作原理类似于在一个分组的 DataSet 上的 GroupCombine。在所有节点上对数据进行分区，然后以贪婪的方式进行合并（即只有适合内存的数据才会一次性合并）。</p>
<h3 id="在完整的-tuple-数据集上进行聚合">在完整的 Tuple 数据集上进行聚合</h3>
<p>有一些常用的聚合操作是经常使用的。Aggregate 转换提供了以下内置的聚合函数。</p>
<ul>
<li>Sum,</li>
<li>Min, 和</li>
<li>Max.</li>
</ul>
<p>Aggregate 变换只能应用于 Tuple 数据集。</p>
<p>下面的代码显示了如何在一个完整的数据集上应用聚合转换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">SUM</span><span class="o">,</span> <span class="mi">0</span><span class="o">).</span><span class="n">and</span><span class="o">(</span><span class="nc">MIN</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
</code></pre></div><p>注意：扩展支持的聚合函数集是我们的路线图。</p>
<h3 id="在完整的元组数据集上实现-minby--maxby">在完整的元组数据集上实现 MinBy / MaxBy</h3>
<p><code>MinBy (MaxBy)</code> 转换从一个元组数据集中选择一个元组。被选择的元组是一个或多个指定字段的值是最小（最大）的元组。用于比较的字段必须是有效的键字段，即可比较的字段。如果多个元组具有最小（最大）字段值，则返回这些元组的任意元组。</p>
<p>以下代码显示了如何从 <code>DataSet&lt;Tuple3&lt;Integer, String, Double&gt;&gt;</code> 中选择具有 Integer 和 Double 字段最大值的元组。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span>                          
                                   <span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span> <span class="c1">// select tuple with maximum values for first and third field.
</span></code></pre></div><h3 id="distinct">Distinct</h3>
<p>Distinct 转换计算源 DataSet 中不同元素的 DataSet。下面的代码从 DataSet 中删除所有重复的元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">distinct</span><span class="o">()</span>
</code></pre></div><p>也可以使用以下方法改变 DataSet 中元素的区分方式。</p>
<ul>
<li>一个或多个字段位置键（仅元组数据集）。</li>
<li>一个键选择器函数，或</li>
<li>一个键表达式</li>
</ul>
<h4 id="用字段位置键去重distinct">用字段位置键去重(Distinct)</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">2</span><span class="o">)</span>
</code></pre></div><h4 id="用-keyselector-函数去重distinct">用 KeySelector 函数去重(Distinct)</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">distinct</span> <span class="o">{</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nc">Math</span><span class="o">.</span><span class="n">abs</span><span class="o">(</span><span class="n">x</span><span class="o">)}</span>
</code></pre></div><h4 id="用键表达式去重distinct">用键表达式去重(Distinct)</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">CustomType</span><span class="o">(</span><span class="n">aName</span> <span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">aNumber</span> <span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span> <span class="o">}</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">CustomType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="s">&#34;aName&#34;</span><span class="o">,</span> <span class="s">&#34;aNumber&#34;</span><span class="o">)</span>
</code></pre></div><p>也可以用通配符表示使用所有字段:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO
</span><span class="c1"></span><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">CustomType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="s">&#34;_&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="join">Join</h3>
<p>Join 转换将两个 DataSets 连接成一个 DataSet。两个数据集的元素在一个或多个键上进行连接(join)，这些键可以通过使用</p>
<ul>
<li>键选择器函数</li>
<li>一个或多个字段位置键（仅限 Tuple DataSet）。</li>
<li>case 类字段</li>
</ul>
<p>有几种不同的方法来执行 Join 转换，如下所示。</p>
<h4 id="默认的-join-join-into-tuple2">默认的 Join (Join into Tuple2)</h4>
<p>默认的 Join 变换会产生一个新的 Tuple DataSet，它有两个字段。每个元组在第一个元组字段中持有第一个输入 DataSet 的 join 元素，在第二个字段中持有第二个输入 DataSet 的匹配元素。</p>
<p>下面的代码显示了一个使用字段位置键的默认 Join 转换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">input2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Double</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">input2</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><h4 id="用-join-函数连接">用 Join 函数连接</h4>
<p>Join 转换也可以调用用户定义的 <code>join</code> 函数来处理连接(joining)元组。<code>join</code> 函数接收第一个输入 DataSet 的一个元素和第二个输入 DataSet 的一个元素，并准确返回一个元素。</p>
<p>下面的代码使用键选择器函数执行了一个带有自定义 java 对象的 DataSet 和一个 Tuple DataSet 的连接，并展示了如何使用用户定义的连接(join)函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Rating</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">category</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">points</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ratings</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Ratings</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">weights</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">weightedRatings</span> <span class="k">=</span> <span class="n">ratings</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">weights</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;category&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">rating</span><span class="o">,</span> <span class="n">weight</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">rating</span><span class="o">.</span><span class="n">name</span><span class="o">,</span> <span class="n">rating</span><span class="o">.</span><span class="n">points</span> <span class="o">*</span> <span class="n">weight</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="用-flat-join-函数连接">用 Flat-Join 函数连接</h4>
<p>类似于 Map 和 FlatMap，<code>FlatJoin</code> 的行为方式与 Join 相同，但它不是返回一个元素，而是可以返回（收集）、零个、一个或多个元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Rating</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">category</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">points</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ratings</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Ratings</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">weights</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">weightedRatings</span> <span class="k">=</span> <span class="n">ratings</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">weights</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;category&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">rating</span><span class="o">,</span> <span class="n">weight</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)])</span> <span class="k">=&gt;</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">weight</span><span class="o">.</span><span class="n">_2</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="o">)</span> <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">rating</span><span class="o">.</span><span class="n">name</span><span class="o">,</span> <span class="n">rating</span><span class="o">.</span><span class="n">points</span> <span class="o">*</span> <span class="n">weight</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="用-projection-java-only-连接">用 Projection (Java Only) 连接</h4>
<p>Join 变换可以使用投影(projection)构造结果元组，如下所示:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Byte</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">input1</span> <span class="o">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Double</span><span class="o">&gt;&gt;</span> <span class="n">input2</span> <span class="o">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple4</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">Double</span><span class="o">,</span> <span class="n">Byte</span><span class="o">&gt;&gt;</span>
            <span class="n">result</span> <span class="o">=</span>
            <span class="n">input1</span><span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
                  <span class="c1">// key definition on first DataSet using a field position key
</span><span class="c1"></span>                  <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
                  <span class="c1">// key definition of second DataSet using a field position key
</span><span class="c1"></span>                  <span class="o">.</span><span class="na">equalTo</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
                  <span class="c1">// select and reorder fields of matching tuples
</span><span class="c1"></span>                  <span class="o">.</span><span class="na">projectFirst</span><span class="o">(</span><span class="n">0</span><span class="o">,</span><span class="n">2</span><span class="o">).</span><span class="na">projectSecond</span><span class="o">(</span><span class="n">1</span><span class="o">).</span><span class="na">projectFirst</span><span class="o">(</span><span class="n">1</span><span class="o">);</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// scala
</span><span class="c1"></span><span class="nc">Not</span> <span class="n">supported</span><span class="o">.</span>
</code></pre></div><h4 id="用数据集大小提示-join">用数据集大小提示 Join</h4>
<p>为了引导优化器选择正确的执行策略，你可以提示要连接(join)的 DataSet 的大小，如下所示:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">input2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// hint that the second DataSet is very small
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">joinWithTiny</span><span class="o">(</span><span class="n">input2</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="c1">// hint that the second DataSet is very large
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">joinWithHuge</span><span class="o">(</span><span class="n">input2</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</code></pre></div><h4 id="join-算法提示">Join 算法提示</h4>
<p>Flink 运行时可以以各种方式执行连接(join)。每一种可能的方式在不同的情况下都会优于其他方式。系统会尝试自动选择一种合理的方式，但也允许你手动选择一种策略，以防你想强制执行特定的连接(join)方式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">SomeType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">input2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">AnotherType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// hint that the second DataSet is very small
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nc">JoinHint</span><span class="o">.</span><span class="nc">BROADCAST_HASH_FIRST</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
</code></pre></div><p>有以下提示:</p>
<ul>
<li>
<p>OPTIMIZER_CHOOSES: 相当于完全不给提示，让系统来选择。</p>
</li>
<li>
<p>BROADCAST_HASH_FIRST：广播第一个输入，并据此建立一个哈希表，由第二个输入探测。如果第一个输入的数据非常小，这是一个很好的策略。</p>
</li>
<li>
<p>BROADCAST_HASH_SECOND: 广播第二个输入，并从中建立一个哈希表，由第一个输入探测。如果第二个输入非常小，是一个很好的策略。</p>
</li>
<li>
<p>REPARTITION_HASH_FIRST：系统对每个输入进行分区（洗牌）（除非输入已经被分区），并从第一个输入建立一个哈希表。如果第一个输入比第二个输入小，但两个输入都很大，这个策略就很好。注意：如果无法估计大小，也无法重新使用已有的分区和排序，系统就会使用这个默认的后备策略。</p>
</li>
<li>
<p>REPARTITION_HASH_SECOND：系统对每个输入进行分区（洗牌）（除非输入已经被分区），并从第二个输入建立一个哈希表。如果第二个输入比第一个输入小，但两个输入仍然很大，这个策略就很好。</p>
</li>
<li>
<p>REPARTITION_SORT_MERGE：系统对每个输入进行分区（洗牌）（除非输入已经分区），并对每个输入进行排序（除非已经排序）。通过对排序后的输入进行流式合并来连接(join)这些输入。如果一个或两个输入都已经被排序，这个策略就很好。</p>
</li>
</ul>
<h3 id="外连接">外连接</h3>
<p><code>OuterJoin</code> 转换在两个数据集上执行左、右或全外连接。外连接与常规（内连接）类似，创建所有键值相等的元素对。此外，如果在另一侧没有找到匹配的键，&ldquo;外侧&quot;的记录（左、右，或者在完全的情况下两者都有）将被保留。匹配的一对元素（或一个元素和另一个输入的空值）被交给 JoinFunction 将这对元素变成一个元素，或交给 FlatJoinFunction 将这对元素变成任意多个（包括无）元素。</p>
<p>两个 DataSets 的元素都是在一个或多个键上连接的，这些键可以通过使用</p>
<ul>
<li>键选择器函数</li>
<li>一个或多个字段位置键（仅限 Tuple DataSet）。</li>
<li>case 类字段</li>
</ul>
<p>OuterJoins 只支持 Java 和 Scala DataSet API。</p>
<h4 id="用-join-函数进行外连接">用 Join 函数进行外连接</h4>
<p><code>OuterJoin</code> 转换调用一个用户定义的 <code>join</code> 函数来处理连接元组。<code>join</code> 函数接收第一个输入 DataSet 的一个元素和第二个输入 DataSet 的一个元素，并准确地返回一个元素。根据外连接的类型（左、右、全），连接函数的两个输入元素中可以有一个是空的。</p>
<p>下面的代码使用键选择器函数执行 DataSet 与自定义 java 对象和 Tuple DataSet 的左外连接，并展示了如何使用用户定义的连接函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Rating</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">category</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">points</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">val</span> <span class="n">movies</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">ratings</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Ratings</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">moviesWithPoints</span> <span class="k">=</span> <span class="n">movies</span><span class="o">.</span><span class="n">leftOuterJoin</span><span class="o">(</span><span class="n">ratings</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">movie</span><span class="o">,</span> <span class="n">rating</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">movie</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="k">if</span> <span class="o">(</span><span class="n">rating</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">rating</span><span class="o">.</span><span class="n">points</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="使用-flat-join-函数进行外连接">使用 Flat-Join 函数进行外连接</h4>
<p>类似于 Map 和 FlatMap，一个带有 <code>flat-join</code> 函数的 OuterJoin 的行为与带有 <code>join</code> 函数的 OuterJoin 相同，但它不是返回一个元素，而是可以返回（收集）、零个、一个或多个元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Not</span> <span class="n">supported</span><span class="o">.</span>
</code></pre></div><h4 id="join-算法提示-1">Join 算法提示</h4>
<p>Flink 运行时可以以各种方式执行外连接。每一种可能的方式在不同的情况下都会优于其他方式。系统试图自动选择一种合理的方式，但允许你手动选择一种策略，以防你想强制执行特定的外连接方式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">SomeType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">input2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">AnotherType</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// hint that the second DataSet is very small
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">leftOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nc">JoinHint</span><span class="o">.</span><span class="nc">REPARTITION_SORT_MERGE</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nc">JoinHint</span><span class="o">.</span><span class="nc">BROADCAST_HASH_FIRST</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
</code></pre></div><p>有以下提示:</p>
<ul>
<li>
<p>OPTIMIZER_CHOOSES: 相当于完全不给提示，让系统来选择。</p>
</li>
<li>
<p>BROADCAST_HASH_FIRST：广播第一个输入，并据此建立一个哈希表，由第二个输入探测。如果第一个输入的数据非常小，这是一个很好的策略。</p>
</li>
<li>
<p>BROADCAST_HASH_SECOND: 广播第二个输入，并从中建立一个哈希表，由第一个输入探测。如果第二个输入非常小，是一个很好的策略。</p>
</li>
<li>
<p>REPARTITION_HASH_FIRST：系统对每个输入进行分区（洗牌）（除非输入已经被分区），并从第一个输入建立一个哈希表。如果第一个输入比第二个输入小，但两个输入仍然很大，这个策略就很好。</p>
</li>
<li>
<p>REPARTITION_HASH_SECOND：系统对每个输入进行分区（洗牌）（除非输入已经被分区），并从第二个输入建立一个哈希表。如果第二个输入比第一个输入小，但两个输入仍然很大，这个策略就很好。</p>
</li>
<li>
<p>REPARTITION_SORT_MERGE：系统对每个输入进行分区（洗牌）（除非输入已经分区），并对每个输入进行排序（除非已经排序）。通过对排序后的输入进行流式合并来连接(join)这些输入。如果一个或两个输入都已经被排序，这个策略就很好。</p>
</li>
</ul>
<p>注意：目前还不是所有的外连接类型都支持所有的执行策略。</p>
<ul>
<li>
<p>LeftOuterJoin 支持:</p>
<ul>
<li>OPTIMIZER_CHOOSES</li>
<li>BROADCAST_HASH_SECOND</li>
<li>REPARTITION_HASH_SECOND</li>
<li>REPARTITION_SORT_MERGE</li>
</ul>
</li>
<li>
<p>RightOuterJoin 支持:</p>
<ul>
<li>OPTIMIZER_CHOOSES</li>
<li>BROADCAST_HASH_FIRST</li>
<li>REPARTITION_HASH_FIRST</li>
<li>REPARTITION_SORT_MERGE</li>
</ul>
</li>
<li>
<p>FullOuterJoin 支持:</p>
<ul>
<li>OPTIMIZER_CHOOSES</li>
<li>REPARTITION_SORT_MERGE</li>
</ul>
</li>
</ul>
<h3 id="cross">Cross</h3>
<p>Cross 变换将两个 DataSets 组合成一个 DataSet。它建立了两个输入数据集元素的所有 pairwise 组合，即建立了一个笛卡尔积。Cross 变换要么在每对元素上调用用户定义的 <code>cross</code> 函数，要么输出一个 Tuple2。这两种模式如下所示。</p>
<p>注意：Cross 是一个潜在的计算密集型操作，甚至可以挑战大型计算集群。</p>
<h4 id="使用用户定义函数进行交叉运算">使用用户定义函数进行交叉运算</h4>
<p>Cross 变换可以调用一个用户定义的 <code>cross</code> 函数。<code>cross</code> 函数接收第一个输入的一个元素和第二个输入的一个元素，并正好返回一个结果元素。</p>
<p>下面的代码展示了如何使用 <code>cross</code> 函数对两个 DataSets 进行交叉变换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Coord</span><span class="o">(</span><span class="n">id</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">x</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">y</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">val</span> <span class="n">coords1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Coord</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">coords2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Coord</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">distances</span> <span class="k">=</span> <span class="n">coords1</span><span class="o">.</span><span class="n">cross</span><span class="o">(</span><span class="n">coords2</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">c1</span><span class="o">,</span> <span class="n">c2</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">dist</span> <span class="k">=</span> <span class="n">sqrt</span><span class="o">(</span><span class="n">pow</span><span class="o">(</span><span class="n">c1</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">c2</span><span class="o">.</span><span class="n">x</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span> <span class="o">+</span> <span class="n">pow</span><span class="o">(</span><span class="n">c1</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">c2</span><span class="o">.</span><span class="n">y</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
    <span class="o">(</span><span class="n">c1</span><span class="o">.</span><span class="n">id</span><span class="o">,</span> <span class="n">c2</span><span class="o">.</span><span class="n">id</span><span class="o">,</span> <span class="n">dist</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><h4 id="用数据集大小提示交叉">用数据集大小提示交叉</h4>
<p>为了引导优化器选择正确的执行策略，你可以提示要交叉的 DataSet 的大小，如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">input2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// hint that the second DataSet is very small
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">crossWithTiny</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>

<span class="c1">// hint that the second DataSet is very large
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">crossWithHuge</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
</code></pre></div><h3 id="cogroup">CoGroup</h3>
<p>CoGroup 转换联合(jointly)处理两个 DataSets 的组。两个 DataSets 根据定义的键进行分组，共享同一键的两个 DataSets 的组被一起交给用户定义的共组(co-group)函数。如果对于一个特定的键来说，只有一个 DataSet 有一个组，那么 <code>co-group</code> 函数就会和这个组以及一个空组一起被调用。共组(co-group)函数可以分别迭代两个组的元素，并返回任意数量的结果元素。</p>
<p>与 Reduce、GroupReduce 和 Join 类似，可以使用不同的键选择器方法来定义键。</p>
<h4 id="数据集上的-cogroup">数据集上的 CoGroup</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">iVals</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">dVals</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">iVals</span><span class="o">.</span><span class="n">coGroup</span><span class="o">(</span><span class="n">dVals</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">iVals</span><span class="o">,</span> <span class="n">dVals</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Double</span><span class="o">])</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">ints</span> <span class="k">=</span> <span class="n">iVals</span> <span class="n">map</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span> <span class="n">toSet</span>

    <span class="k">for</span> <span class="o">(</span><span class="n">dVal</span> <span class="k">&lt;-</span> <span class="n">dVals</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="n">ints</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">dVal</span><span class="o">.</span><span class="n">_2</span> <span class="o">*</span> <span class="n">i</span><span class="o">)</span>
      <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="union">Union</h3>
<p>产生两个 DataSets 的联合(union)，这两个 DataSets 必须是同一类型。两个以上 DataSets 的联合(union)可以通过多个联合(union)调用来实现，如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">vals1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">vals2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">vals3</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">unioned</span> <span class="k">=</span> <span class="n">vals1</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">vals2</span><span class="o">).</span><span class="n">union</span><span class="o">(</span><span class="n">vals3</span><span class="o">)</span>
</code></pre></div><h3 id="rebalance">Rebalance</h3>
<p>均匀地重新平衡 DataSet 的并行分区，以消除数据倾斜。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// rebalance DataSet and apply a Map transformation.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">rebalance</span><span class="o">().</span><span class="n">map</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h3 id="hash-partition">Hash-Partition</h3>
<p>在给定的键上对 DataSet 进行散列分割。键可以被指定为位置键、表达式键和键选择器函数（关于如何指定键，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-grouped-dataset">Reduce 示例</a>）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// hash-partition DataSet by String value and apply a MapPartition transformation.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">partitionByHash</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h3 id="range-partition">Range-Partition</h3>
<p>在给定的键上 Range-partitions 一个 DataSet。键可以被指定为位置键、表达式键和键选择器函数（关于如何指定键，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-grouped-dataset">Reduce 示例</a>）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// range-partition DataSet by String value and apply a MapPartition transformation.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">partitionByRange</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h3 id="sort-partition">Sort Partition</h3>
<p>按照指定的顺序，在指定的字段上对 DataSet 的所有分区进行本地排序。字段可以被指定为字段表达式或字段位置（关于如何指定键，请参阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-grouped-dataset">Reduce 示例</a>）。通过链式 <code>sortPartition()</code> 调用，可以在多个字段上对分区进行排序。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// Locally sort partitions in ascending order on the second String field and
</span><span class="c1">// in descending order on the first String field.
</span><span class="c1">// Apply a MapPartition transformation on the sorted partitions.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">)</span>
            <span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">DESCENDING</span><span class="o">)</span>
            <span class="o">.</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><h3 id="first-n">First-n</h3>
<p>返回一个 DataSet 的前 n 个（任意）元素。First-n 可以应用于一个常规的 DataSet、一个分组的 DataSet 或一个分组排序的 DataSet。分组键可以被指定为键选择器函数或字段位置键（关于如何指定键，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#reduce-on-grouped-dataset">Reduce 示例</a>）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// Return the first five (arbitrary) elements of the DataSet
</span><span class="c1"></span><span class="k">val</span> <span class="n">out1</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">first</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="c1">// Return the first two (arbitrary) elements of each String group
</span><span class="c1"></span><span class="k">val</span> <span class="n">out2</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">first</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>

<span class="c1">// Return the first three elements of each String group ordered by the Integer field
</span><span class="c1"></span><span class="k">val</span> <span class="n">out3</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">sortGroup</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Drop 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Drop Statements</blockquote><h1 id="drop-语句">DROP 语句</h1>
<p>DROP 语句用于从当前或指定的目录中删除一个注册的表/视图/函数。</p>
<p>Flink SQL 目前支持以下 DROP 语句。</p>
<ul>
<li>DROP TABLE</li>
<li>DROP DATABASE</li>
<li>DROP VIEW</li>
<li>DROP FUNCTION</li>
</ul>
<h2 id="运行一个-drop-语句">运行一个 DROP 语句</h2>
<p>DROP 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法对于一个成功的 DROP 操作会返回&rsquo;OK'，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 DROP 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">()...</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// a string array: [&#34;Orders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">()</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span><span class="c1"></span>
<span class="c1">// drop &#34;Orders&#34; table from catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;DROP TABLE Orders&#34;</span><span class="o">)</span>

<span class="c1">// an empty string array
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">()</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span></code></pre></div><h2 id="drop-table">DROP TABLE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span>
</code></pre></div><p>删除一个给定表名的表。如果要删除的表不存在，则抛出一个异常。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果该表不存在，就不会发生任何事情。</p>
<h2 id="drop-database">DROP DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.]</span><span class="n">db_name</span> <span class="p">[</span> <span class="p">(</span><span class="k">RESTRICT</span> <span class="o">|</span> <span class="k">CASCADE</span><span class="p">)</span> <span class="p">]</span>
</code></pre></div><p>删除一个给定数据库名称的数据库，如果要删除的数据库不存在，会产生异常。如果要删除的数据库不存在，则抛出一个异常。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果数据库不存在，则不会发生任何事情。</p>
<p><strong>RESTRICT</strong></p>
<p>丢弃非空数据库会触发异常。默认为启用。</p>
<p><strong>CASCADE</strong></p>
<p>丢弃一个非空的数据库也会丢弃所有相关的表和函数。</p>
<h2 id="drop-view">DROP VIEW</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="k">VIEW</span>  <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="n">view_name</span>
</code></pre></div><p>丢弃一个有目录和数据库命名空间的视图。如果要删除的视图不存在，则会产生一个异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>删除具有目录和数据库命名空间的临时视图。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果视图不存在，则不会发生任何事情。</p>
<p>维护依赖关系 Flink 没有通过 CASCADE/RESTRICT 关键字来维护视图的依赖关系，当前的方式是当用户试图在诸如视图的底层表被删除的情况下使用视图时，会产生延迟错误消息。</p>
<h2 id="drop-function">DROP FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="n">function_name</span><span class="p">;</span>
</code></pre></div><p>删除一个有目录和数据库命名空间的目录函数。如果要放弃的函数不存在，则会产生一个异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>丢弃具有目录和数据库命名空间的临时目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>删除没有命名空间的临时系统函数。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果函数不存在，就不会发生任何事情。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Explan 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Explan Statements</blockquote><h1 id="explain-语句">EXPLAIN 语句</h1>
<p>EXPLAIN 语句用于解释一个查询或 INSERT 语句的逻辑和优化查询计划。</p>
<h2 id="运行-explain-语句">运行 EXPLAIN 语句</h2>
<p>EXPLAIN 语句可以用 <code>TableEnvironment 的 executeSql()</code> 方法执行，也可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中执行。<code>executeSql()</code> 方法在 EXPLAIN 操作成功后返回解释结果，否则将抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 EXPLAIN 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE MyTable1 (count bigint, work VARCHAR(256) WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE MyTable2 (count bigint, work VARCHAR(256) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// explain SELECT statement through TableEnvironment.explainSql()
</span><span class="c1"></span><span class="k">val</span> <span class="n">explanation</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">explainSql</span><span class="o">(</span>
  <span class="s">&#34;SELECT count, word FROM MyTable1 WHERE word LIKE &#39;F%&#39; &#34;</span> <span class="o">+</span>
  <span class="s">&#34;UNION ALL &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable2&#34;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span>

<span class="c1">// explain SELECT statement through TableEnvironment.executeSql()
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;EXPLAIN PLAN FOR &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable1 WHERE word LIKE &#39;F%&#39; &#34;</span> <span class="o">+</span>
  <span class="s">&#34;UNION ALL &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable2&#34;</span><span class="o">)</span>
<span class="n">tableResult</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>
</code></pre></div><p>EXPLAIN 的结果是：</p>
<pre><code>== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
    FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, MyTable1]], fields=[count, word])
  FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, MyTable2]], fields=[count, word])
  

== Optimized Logical Plan ==
DataStreamUnion(all=[true], union all=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')])
    TableSourceScan(table=[[default_catalog, default_database, MyTable1]], fields=[count, word])
  TableSourceScan(table=[[default_catalog, default_database, MyTable2]], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

Stage 2 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 3 : Operator
		content : from: (count, word)
		ship_strategy : REBALANCE

		Stage 4 : Operator
			content : where: (LIKE(word, _UTF-16LE'F%')), select: (count, word)
			ship_strategy : FORWARD

			Stage 5 : Operator
				content : from: (count, word)
				ship_strategy : REBALANCE
</code></pre><h2 id="语法">语法</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">EXPLAIN</span> <span class="n">PLAN</span> <span class="k">FOR</span> <span class="o">&lt;</span><span class="n">query_statement_or_insert_statement</span><span class="o">&gt;</span>
</code></pre></div><p>关于查询语法，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#supported-syntax">查询</a>页面。关于 INSERT，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">INSERT</a> 页面。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink Dataset API 编程指南]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="related" type="text/html" title="本地执行" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Dataset Api Programming Guide</blockquote><h2 id="flink-dataset-api-编程指南">Flink DataSet API 编程指南</h2>
<p>Flink 中的数据集程序是对数据集实现转换（如过滤、映射、加入、分组）的常规程序。数据集最初是从某些来源创建的（例如，通过读取文件，或从本地集合中创建）。结果通过汇返回，例如可以将数据写入（分布式）文件，或标准输出（例如命令行终端）。Flink 程序可以在各种环境下运行，独立运行，或者嵌入其他程序中。执行可以发生在本地 JVM 中，也可以发生在许多机器的集群中。</p>
<p>请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API 概述</a>，了解 Flink API 的基本概念。该概述是针对 DataStream API 的，但这两个 API 的基本概念是一样的。</p>
<p>为了创建你自己的 Flink DataSet 程序，我们鼓励你从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">Flink 程序的骨架</a>开始，并逐步添加你自己的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#dataset-transformations">转换</a>。其余部分作为附加操作和高级功能的参考。</p>
<h3 id="程序示例">程序示例</h3>
<p>下面的程序是一个完整的、可以使用的 WordCount 的例子，你可以复制和粘贴代码在本地运行。你可以复制和粘贴代码在本地运行它。你只需要在你的项目中加入正确的 Flink 的库（参见与 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration.html">Flink 的链接</a>部分）并指定导入。然后你就可以开始了</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>

<span class="k">object</span> <span class="nc">WordCount</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
    <span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
      <span class="s">&#34;Who&#39;s there?&#34;</span><span class="o">,</span>
      <span class="s">&#34;I think I hear them. Stand, ho! Who&#39;s there?&#34;</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">text</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">toLowerCase</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;\\W+&#34;</span><span class="o">)</span> <span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">nonEmpty</span> <span class="o">}</span> <span class="o">}</span>
      <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span>
      <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
      <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

    <span class="n">counts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="dataset-转换">DataSet 转换</h3>
<p>数据转换将一个或多个 DataSet 转换为一个新的 DataSet。程序可以将多个转换组合成复杂的集合。</p>
<p>本节简要介绍了可用的转换。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html">转换文档</a>中有所有变换的完整描述和示例。</p>
<ul>
<li>Map</li>
</ul>
<p>接受一个元素，产生一个元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
</code></pre></div><ul>
<li>FlatMap</li>
</ul>
<p>接受一个元素并产生零、一个或多个元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="n">str</span> <span class="k">=&gt;</span> <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><ul>
<li>MapPartition</li>
</ul>
<p>在一个函数调用中转换一个并行分区。该函数以&quot;迭代器&quot;的形式获取分区，并可产生任意数量的结果值。每个分区的元素数量取决于平行度和之前的操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="n">in</span> <span class="k">=&gt;</span> <span class="n">in</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Filter</li>
</ul>
<p>对每个元素进行布尔函数评估，并保留那些函数返回真的元素。
重要：系统假设函数不会修改应用谓词的元素。违反这个假设会导致错误的结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span> <span class="o">&gt;</span> <span class="mi">1000</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Reduce</li>
</ul>
<p>通过重复将两个元素合并为一个元素，将一组元素合并为一个元素。换算可以应用于一个完整的数据集，也可以应用于一个分组的数据集。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span>
</code></pre></div><ul>
<li>ReduceGroup</li>
</ul>
<p>将一组元素合并成一个或多个元素。<code>ReduceGroup</code> 可以应用在一个完整的数据集上，也可以应用在一个分组的数据集上。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">reduceGroup</span> <span class="o">{</span> <span class="n">elements</span> <span class="k">=&gt;</span> <span class="n">elements</span><span class="o">.</span><span class="n">sum</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Aggregate</li>
</ul>
<p>将一组值聚合成一个值。<code>Aggregation</code> 函数可以被认为是内置的 <code>reduce</code> 函数。<code>Aggregate</code> 可以应用于一个完整的数据集，也可以应用于一个分组的数据集。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">SUM</span><span class="o">,</span> <span class="mi">0</span><span class="o">).</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">MIN</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
</code></pre></div><p>你也可以使用简写语法来进行 <code>minimum</code>, <code>maximum</code> 和 <code>sum</code> 的聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">output</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">min</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
</code></pre></div><ul>
<li>Distinct</li>
</ul>
<p>返回数据集的不同元素。它从输入的 DataSet 中删除元素的所有字段或字段子集的重复条目。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">distinct</span><span class="o">()</span>
</code></pre></div><ul>
<li>Join</li>
</ul>
<p>通过创建所有键值相等的元素对来连接两个数据集。可以选择使用 <code>JoinFunction</code> 将一对元素变成一个元素，或者使用 <code>FlatJoinFunction</code> 将一对元素变成任意多个（包括无）元素。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#specifying-keys">键</a>部分了解如何定义连接键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// In this case tuple fields are used as keys. &#34;0&#34; is the join field on the first tuple
</span><span class="c1">// &#34;1&#34; is the join field on the second tuple.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">input2</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><p>你可以通过 Join Hints 指定运行时执行连接的方式。这些提示描述了连接是通过分区还是广播进行的，以及它是使用基于排序还是基于散列的算法。请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#join-algorithm-hints">转换指南</a>，了解可能的提示列表和示例。
如果没有指定提示，系统将尝试对输入大小进行估计，并根据这些估计选择最佳策略。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// This executes a join by broadcasting the first data set
</span><span class="c1">// using a hash table for the broadcast data
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">input2</span><span class="o">,</span> <span class="nc">JoinHint</span><span class="o">.</span><span class="nc">BROADCAST_HASH_FIRST</span><span class="o">)</span>
                   <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><p>请注意，连接转换只适用于等价连接。其他的连接类型需要使用 OuterJoin 或 CoGroup 来表达。</p>
<ul>
<li>OuterJoin</li>
</ul>
<p>在两个数据集上执行左联接、右联接或完全外联接。外联接与常规（内联接）类似，创建所有键值相同的元素对。此外，如果在另一侧没有找到匹配的键，&ldquo;外侧&quot;的记录（左、右或全联接时两者都有）将被保留。匹配的元素对（或一个元素和另一个输入的 <code>null</code> 值）被交给 <code>JoinFunction</code> 将这对元素变成单个元素，或交给 <code>FlatJoinFunction</code> 将这对元素变成任意多个（包括无）元素。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#specifying-keys">键</a>部分，了解如何定义连接键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">joined</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">leftOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
   <span class="o">(</span><span class="n">left</span><span class="o">,</span> <span class="n">right</span><span class="o">)</span> <span class="k">=&gt;</span>
     <span class="k">val</span> <span class="n">a</span> <span class="k">=</span> <span class="k">if</span> <span class="o">(</span><span class="n">left</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="s">&#34;none&#34;</span> <span class="k">else</span> <span class="n">left</span><span class="o">.</span><span class="n">_1</span>
     <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">right</span><span class="o">)</span>
  <span class="o">}</span>
</code></pre></div><ul>
<li>CoGroup</li>
</ul>
<p>减少操作的二维变体。在一个或多个字段上对每个输入进行分组，然后将分组合并。每一对组都会调用转换函数。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#specifying-keys">键</a>部分，了解如何定义 <code>coGroup</code> 键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data1</span><span class="o">.</span><span class="n">coGroup</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><ul>
<li>Cross</li>
</ul>
<p>建立两个输入的笛卡尔乘积（交叉乘积），创建所有元素对。可选择使用交叉函数将一对元素变成一个单一元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">data2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">cross</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span>
</code></pre></div><p>注意：<code>Cross</code> 可能是一个非常耗费计算的操作，甚至可以挑战大型计算集群！建议使用 <code>crossWithTiny()</code> 和 <code>crossWithHuge()</code> 来提示系统数据集的大小。</p>
<ul>
<li>
<p>Union</p>
</li>
<li>
<p>产生两个数据集的并集。</p>
</li>
</ul>
<pre><code class="language-raku" data-lang="raku">data.union(data2)
</code></pre><ul>
<li>Rebalance</li>
</ul>
<p>均匀地重新平衡数据集的并行分区，以消除数据倾斜。只有类似于 Map 的变换才可以跟随重新平衡(rebalance)变换。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data1</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">rebalance</span><span class="o">().</span><span class="n">map</span><span class="o">(...)</span>
</code></pre></div><ul>
<li>Hash-Partition</li>
</ul>
<p>在给定的键上对数据集进行散列分区。键可以被指定为位置键、表达式键和键选择函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">partitionByHash</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Range-Partition</li>
</ul>
<p>在给定的键上按照范围分割数据集。键可以被指定为位置键、表达式键和键选择函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">partitionByRange</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><ul>
<li>自定义分区</li>
</ul>
<p>使用自定义的 <code>Partitioner</code> 函数，根据键将记录分配到特定的分区。键可以指定为位置键、表达式键和键选择函数。
注意：此方法仅适用于单个字段键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span>
  <span class="o">.</span><span class="n">partitionCustom</span><span class="o">(</span><span class="n">partitioner</span><span class="o">,</span> <span class="n">key</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Sort Partition</li>
</ul>
<p>按照指定的顺序对数据集的所有分区进行本地排序。字段可以指定为元组位置或字段表达式。对多个字段的排序是通过链式 <code>sortPartition()</code> 调用完成的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">mapPartition</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><ul>
<li>First-n</li>
</ul>
<p>返回一个数据集的前 n 个（任意）元素。First-n 可以应用于一个常规数据集、一个分组数据集或一个分组排序数据集。分组键可以指定为键选择函数、元组位置或 case 类字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// regular data set
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="c1">// grouped data set
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="c1">// grouped-sorted data set
</span><span class="c1"></span><span class="k">val</span> <span class="n">result3</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">sortGroup</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">first</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
</code></pre></div><p>以下转换可用于元组的数据集。</p>
<ul>
<li>MinBy / MaxBy</li>
</ul>
<p>从一组元组中选择一个元组，这些元组的一个或多个字段的值是最小的（最大的）。用于比较的字段必须是有效的键字段，即可比较。如果多个元组具有最小（最大）字段值，则返回这些元组的任意元组。MinBy (MaxBy)可以应用于一个完整的数据集或一个分组数据集。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1">// a data set with a single tuple with minimum values for the Int and String fields.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
<span class="c1">// a data set with one tuple for each group with the minimum value for the Double field.
</span><span class="c1"></span><span class="k">val</span> <span class="n">out2</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
                                             <span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><p>通过匿名模式匹配从 tuple、case 类和集合中提取，比如下面。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">temperature</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><p>不受 API 开箱即用的支持。要使用这个功能，你应该使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/scala_api_extensions.html">Scala API 扩展</a>。</p>
<p>变换的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/parallel.html">并行度</a>可以通过 <code>setParallelism(int)</code> 来定义，而 <code>name(String)</code> 可以给变换指定一个自定义的名称，这对调试很有帮助。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#data-sources">数据源</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#data-sinks">数据接收器</a>也是如此。</p>
<p><code>withParameters(Configuration)</code> 传递 Configuration 对象，这些对象可以从用户函数里面的 <code>open()</code> 方法访问。</p>
<h2 id="指定键">指定键</h2>
<p>一些转换（join、coGroup、groupBy）需要在元素集合上定义一个键。其他转换（Reduce、GroupReduce、Aggregate）允许在应用之前将数据按键分组。</p>
<p>一个 DataSet 被分组为：</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">reduced</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="cm">/*do something*/</span><span class="o">);</span>
</code></pre></div><p>Flink 的数据模型不是基于键值对的。因此，你不需要将数据集类型物理地打包成键和值。键是&quot;虚拟的&rdquo;：它们被定义为实际数据上的函数，以指导分组操作符。</p>
<h3 id="为元组定义键">为元组定义键</h3>
<p>最简单的情况是对 Tuple 的一个或多个字段进行分组。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</code></pre></div><p>元组在第一个字段（整数类型的字段）上进行分组。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">grouped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div><p>在这里，我们将元组放在一个由第一个字段和第二个字段组成的复合键上。</p>
<p>关于嵌套 Tuple 的说明。如果你的 DataSet 有一个嵌套的元组，比如：</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">ds</span><span class="o">;</span>
</code></pre></div><p>指定 <code>groupBy(0)</code> 将使系统使用完整的 Tuple2 作为键（以 Integer 和 Float 为键）。如果要&quot;导航&quot;到嵌套的 Tuple2 中，就必须使用字段表达式键，下面将对其进行说明。</p>
<h3 id="使用字段表达式定义键">使用字段表达式定义键</h3>
<p>你可以使用基于字符串的字段表达式来引用嵌套的字段，并为分组、排序、连接(join)或 coGrouping 定义键。</p>
<p>字段表达式可以非常容易地选择（嵌套的）复合类型中的字段，如 Tuple 和 POJO 类型。</p>
<p>在下面的例子中，我们有一个有两个字段 &ldquo;word&rdquo; 和 &ldquo;count&rdquo; 的 WC POJO。要按字段 <code>word</code> 进行分组，我们只需将其名称传递给 <code>groupBy()</code> 函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary POJO (Plain old Java Object)
</span><span class="c1"></span><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="s">&#34;&#34;</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">)</span>

<span class="c1">// or, as a case class, which is less typing
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="字段表达式语法">字段表达式语法</h3>
<ul>
<li>
<p>通过字段名选择 POJO 字段。例如 &ldquo;user&rdquo; 指的是 POJO 类型的 &ldquo;user&rdquo; 字段。</p>
</li>
<li>
<p>通过 1-offset 字段名或 0-offset 字段索引来选择 Tuple 字段。例如 &ldquo;_1&rdquo; 和 &ldquo;5&rdquo; 分别指 Scala Tuple 类型的第一和第六字段。</p>
</li>
</ul>
<p>你可以在 POJO 和 Tuple 中选择嵌套字段。例如 &ldquo;user.zip&rdquo; 指的是 POJO 的 &ldquo;zip&rdquo; 字段，它存储在 POJO 类型的 &ldquo;user&rdquo; 字段中。支持 POJO 和 Tuple 的任意嵌套和混合，如 &ldquo;_2.user.zip&rdquo; 或 &ldquo;user._4.1.zip&rdquo;。</p>
<p>你可以使用 &ldquo;_&rdquo; 通配符表达式选择完整的类型。这也适用于不是 Tuple 或 POJO 类型的类型。</p>
<p>字段表达式示例:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">complex</span><span class="k">:</span> <span class="kt">ComplexNestedClass</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>

<span class="k">class</span> <span class="nc">ComplexNestedClass</span><span class="o">(</span>
    <span class="k">var</span> <span class="n">someNumber</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
    <span class="n">someFloat</span><span class="k">:</span> <span class="kt">Float</span><span class="o">,</span>
    <span class="n">word</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">),</span>
    <span class="n">hadoopCitizen</span><span class="k">:</span> <span class="kt">IntWritable</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="s">&#34;&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">IntWritable</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span> <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>这些都是上面例子代码的有效字段表达式。</p>
<ul>
<li>
<p>&ldquo;count&rdquo;: WC 类中的计数字段</p>
</li>
<li>
<p>&ldquo;complex&rdquo;: 递归选择 POJO 类型 <code>ComplexNestedClass</code> 的 <code>complex</code> 字段的所有字段。</p>
</li>
<li>
<p>&ldquo;complex.word._3&rdquo;: 选择嵌套的 Tuple3 的最后一个字段。</p>
</li>
<li>
<p>&ldquo;complex.hadoopCitizen&rdquo;: 选择 Hadoop <code>IntWritable</code> 类型。</p>
</li>
</ul>
<h3 id="使用键选择函数定义键">使用键选择函数定义键</h3>
<p>另一种定义键的方法是&quot;键选择器&quot;函数。键选择器函数将一个元素作为输入，并返回该元素的键。键可以是任何类型的，并且可以从确定性计算中得到。</p>
<p>下面的例子显示了一个简单返回对象字段的键选择函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary case class
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">word</span> <span class="o">)</span>
</code></pre></div><h2 id="数据源">数据源</h2>
<p>数据源创建初始数据集，例如从文件或 Java 集合中创建。创建数据集的一般机制是在 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/InputFormat.java">InputFormat</a> 后面抽象出来的。Flink 自带了几种内置的格式来从常见的文件格式创建数据集。其中许多格式在 ExecutionEnvironment 上有快捷方法。</p>
<p>基于文件的:</p>
<ul>
<li>
<p><code>readTextFile(path) / TextInputFormat</code> - 读取文件并以字符串形式返回。</p>
</li>
<li>
<p><code>readTextFileWithValue(path) / TextValueInputFormat</code> - 以行的方式读取文件并以 <code>StringValues</code> 的形式返回。<code>StringValues</code> 是可变字符串。</p>
</li>
<li>
<p><code>readCsvFile(path) / CsvInputFormat</code> - 解析以逗号（或其他字符）分隔的文件。返回一个由 tuple、case 类对象或 POJOs 组成的 DataSet。支持基本的 java 类型及其对应的 Value 类型作为字段类型。</p>
</li>
<li>
<p><code>readFileOfPrimitives(path, delimiter) / PrimitiveInputFormat</code> - 使用给定的定界符，解析新行（或其他字符序列）定界的基元数据类型的文件，如 String 或 Integer。</p>
</li>
<li>
<p><code>readSequenceFile(Key, Value, path) / SequenceFileInputFormat</code> - 创建一个 JobConf 并从指定的路径读取文件，文件类型为 <code>SequenceFileInputFormat</code>，Key 类和 Value 类，并以 <code>Tuple2&lt;Key, Value&gt;</code> 的形式返回。</p>
</li>
</ul>
<p>基于集合的:</p>
<ul>
<li>
<p><code>fromCollection(Iterable)</code> - 从一个 Iterable 创建一个数据集。Iterable 返回的所有元素必须是相同的类型。</p>
</li>
<li>
<p><code>fromCollection(Iterator)</code> - 从一个 Iterator 创建一个数据集。该类指定了迭代器返回的元素的数据类型。</p>
</li>
<li>
<p><code>fromElements(elements: _*)</code> - 从给定的对象序列中创建一个数据集。所有对象必须是相同的类型。</p>
</li>
<li>
<p><code>fromParallelCollection(SplittableIterator)</code> - 从迭代器中并行创建一个数据集。该类指定了迭代器返回的元素的数据类型。</p>
</li>
<li>
<p><code>generateSequence(from, to)</code> - 在给定的区间内并行生成数字序列。</p>
</li>
</ul>
<p>通用的:</p>
<ul>
<li>
<p><code>readFile(inputFormat, path) / FileInputFormat</code> - 接受一个文件输入格式。</p>
</li>
<li>
<p><code>createInput(inputFormat) / InputFormat</code> - 接受一个通用的输入格式。</p>
</li>
</ul>
<p>示例:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span>  <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// read text file from local files system
</span><span class="c1"></span><span class="k">val</span> <span class="n">localLines</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path/to/my/textfile&#34;</span><span class="o">)</span>

<span class="c1">// read text file from an HDFS running at nnHost:nnPort
</span><span class="c1"></span><span class="k">val</span> <span class="n">hdfsLines</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;hdfs://nnHost:nnPort/path/to/my/textfile&#34;</span><span class="o">)</span>

<span class="c1">// read a CSV file with three fields
</span><span class="c1"></span><span class="k">val</span> <span class="n">csvInput</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)](</span><span class="s">&#34;hdfs:///the/CSV/file&#34;</span><span class="o">)</span>

<span class="c1">// read a CSV file with five fields, taking only two of them
</span><span class="c1"></span><span class="k">val</span> <span class="n">csvInput</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)](</span>
  <span class="s">&#34;hdfs:///the/CSV/file&#34;</span><span class="o">,</span>
  <span class="n">includedFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span> <span class="c1">// take the first and the fourth field
</span><span class="c1"></span>
<span class="c1">// CSV input can also be used with Case Classes
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">MyCaseClass</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">dbl</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">val</span> <span class="n">csvInput</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[</span><span class="kt">MyCaseClass</span><span class="o">](</span>
  <span class="s">&#34;hdfs:///the/CSV/file&#34;</span><span class="o">,</span>
  <span class="n">includedFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span> <span class="c1">// take the first and the fourth field
</span><span class="c1"></span>
<span class="c1">// read a CSV file with three fields into a POJO (Person) with corresponding fields
</span><span class="c1"></span><span class="k">val</span> <span class="n">csvInput</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[</span><span class="kt">Person</span><span class="o">](</span>
  <span class="s">&#34;hdfs:///the/CSV/file&#34;</span><span class="o">,</span>
  <span class="n">pojoFields</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">,</span> <span class="s">&#34;age&#34;</span><span class="o">,</span> <span class="s">&#34;zipcode&#34;</span><span class="o">))</span>

<span class="c1">// create a set from some given elements
</span><span class="c1"></span><span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="s">&#34;Foo&#34;</span><span class="o">,</span> <span class="s">&#34;bar&#34;</span><span class="o">,</span> <span class="s">&#34;foobar&#34;</span><span class="o">,</span> <span class="s">&#34;fubar&#34;</span><span class="o">)</span>

<span class="c1">// generate a number sequence
</span><span class="c1"></span><span class="k">val</span> <span class="n">numbers</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">generateSequence</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">10000000</span><span class="o">)</span>

<span class="c1">// read a file from the specified path of type SequenceFileInputFormat
</span><span class="c1"></span><span class="k">val</span> <span class="n">tuples</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">createInput</span><span class="o">(</span><span class="nc">HadoopInputs</span><span class="o">.</span><span class="n">readSequenceFile</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">IntWritable</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Text</span><span class="o">],</span>
 <span class="s">&#34;hdfs://nnHost:nnPort/path/to/file&#34;</span><span class="o">))</span>
</code></pre></div><h3 id="配置-csv-解析">配置 CSV 解析</h3>
<p>Flink 为 CSV 解析提供了许多配置选项。</p>
<ul>
<li>
<p>lineDelimiter: 字符串指定单个记录的定界符。默认的行定界符是新行字符 <code>'/n'</code>。</p>
</li>
<li>
<p>fieldDelimiter: 字符串指定分隔记录字段的定界符。默认的字段定界符是逗号字符 <code>','</code>。</p>
</li>
<li>
<p>includeFields: <code>Array[Int]</code> 定义从输入文件中读取哪些字段（以及忽略哪些字段）。默认情况下，前 n 个字段（由 <code>type()</code> 调用中的类型数定义）会被解析。</p>
</li>
<li>
<p>pojoFields: <code>Array[String]</code> 指定 POJO 的字段，这些字段被映射到 CSV 字段。CSV 字段的解析器会根据 POJO 字段的类型和顺序自动初始化。</p>
</li>
<li>
<p>parseQuotedStrings: 启用引号字符串解析的字符。如果字符串字段的第一个字符是引号字符，那么字符串将被解析为引号字符串（前导或尾部的空白不被修剪）。引号字符串中的字段定界符会被忽略。如果引号字符串字段的最后一个字符不是引号字符，则引号字符串解析失败。如果启用了引号字符串解析，且字段的第一个字符不是引号字符串，则该字符串将被解析为未引号字符串。默认情况下，引号字符串解析被禁用。</p>
</li>
<li>
<p>ignoreComments: 字符串指定一个注解前缀。所有以指定注解前缀开始的行都不会被解析和忽略。默认情况下，没有行被忽略。</p>
</li>
<li>
<p>lenient：布尔值，启用宽松解析。也就是说，不能正确解析的行会被忽略。默认情况下，禁用宽松解析，无效行会引发异常。</p>
</li>
<li>
<p>ignoreFirstLine: Boolean 配置 InputFormat 忽略输入文件的第一行。默认情况下，没有行被忽略。</p>
</li>
</ul>
<h3 id="input-path-的递归遍历">Input Path 的递归遍历</h3>
<p>对于基于文件的输入，当输入路径是一个目录时，默认情况下不会枚举嵌套文件。取而代之的是，只读取基础目录内的文件，而忽略嵌套文件。嵌套文件的递归枚举可以通过 <code>recursive.file.enumeration</code> 配置参数启用，就像下面的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// enable recursive enumeration of nested input files
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span>  <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// create a configuration object
</span><span class="c1"></span><span class="k">val</span> <span class="n">parameters</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span>

<span class="c1">// set the recursive enumeration parameter
</span><span class="c1"></span><span class="n">parameters</span><span class="o">.</span><span class="n">setBoolean</span><span class="o">(</span><span class="s">&#34;recursive.file.enumeration&#34;</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="c1">// pass the configuration to the data source
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path/with.nested/files&#34;</span><span class="o">).</span><span class="n">withParameters</span><span class="o">(</span><span class="n">parameters</span><span class="o">)</span>
</code></pre></div><h3 id="读取压缩文件">读取压缩文件</h3>
<p>Flink 目前支持输入文件的透明解压，如果这些文件被标记为适当的文件扩展名。特别是，这意味着无需进一步配置输入格式，任何 <code>FileInputFormat</code> 都支持压缩，包括自定义输入格式。请注意，压缩文件可能不会被并行读取，从而影响作业的可扩展性。</p>
<p>下表列出了当前支持的压缩方法。</p>
<table>
<thead>
<tr>
<th style="text-align:left">压缩方法</th>
<th style="text-align:left">文件后缀</th>
<th style="text-align:left">并行性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">DEFLATE</td>
<td style="text-align:left">.deflate</td>
<td style="text-align:left">no</td>
</tr>
<tr>
<td style="text-align:left">GZip</td>
<td style="text-align:left">.gz, .gzip</td>
<td style="text-align:left">no</td>
</tr>
<tr>
<td style="text-align:left">Bzip2</td>
<td style="text-align:left">.bz2</td>
<td style="text-align:left">no</td>
</tr>
<tr>
<td style="text-align:left">XZ</td>
<td style="text-align:left">.xz</td>
<td style="text-align:left">no</td>
</tr>
</tbody>
</table>
<h2 id="数据接收器">数据接收器</h2>
<p>数据接收器消费 DataSet 并用于存储或返回它们。数据接收器的操作是用 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/io/OutputFormat.java">OutputFormat</a> 来描述的。Flink 带有各种内置的输出格式，这些格式被封装在对 DataSet 的操作后面。</p>
<ul>
<li><code>writeAsText() / TextOutputFormat</code> &ndash;将元素逐行写成 Strings。通过调用每个元素的 <code>toString()</code> 方法获得字符串。</li>
<li><code>writeAsCsv(...) / CsvOutputFormat</code> - 将元组写成逗号分隔的值文件。行和字段定界符是可配置的。每个字段的值来自对象的 <code>toString()</code> 方法。</li>
<li><code>print() / printToErr()</code> - 在标准输出/标准错误流上打印每个元素的 <code>toString()</code> 值。</li>
<li><code>write() / FileOutputFormat</code> - 用于自定义文件输出的方法和基类。支持自定义对象到字节的转换。</li>
<li><code>output()/ OutputFormat</code> - 最通用的输出方法，用于非基于文件的数据接收器（如将结果存储在数据库中）。</li>
</ul>
<p>一个 DataSet 可以被输入到多个操作中。程序可以写入或打印一个数据集，同时还可以对其进行额外的转换。</p>
<p><strong>示例</strong></p>
<p>标准数据接收器方法:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// text data
</span><span class="c1"></span><span class="k">val</span> <span class="n">textData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// write DataSet to a file on the local file system
</span><span class="c1"></span><span class="n">textData</span><span class="o">.</span><span class="n">writeAsText</span><span class="o">(</span><span class="s">&#34;file:///my/result/on/localFS&#34;</span><span class="o">)</span>

<span class="c1">// write DataSet to a file on an HDFS with a namenode running at nnHost:nnPort
</span><span class="c1"></span><span class="n">textData</span><span class="o">.</span><span class="n">writeAsText</span><span class="o">(</span><span class="s">&#34;hdfs://nnHost:nnPort/my/result/on/localFS&#34;</span><span class="o">)</span>

<span class="c1">// write DataSet to a file and overwrite the file if it exists
</span><span class="c1"></span><span class="n">textData</span><span class="o">.</span><span class="n">writeAsText</span><span class="o">(</span><span class="s">&#34;file:///my/result/on/localFS&#34;</span><span class="o">,</span> <span class="nc">WriteMode</span><span class="o">.</span><span class="nc">OVERWRITE</span><span class="o">)</span>

<span class="c1">// tuples as lines with pipe as the separator &#34;a|b|c&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">values</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">values</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="s">&#34;file:///path/to/the/result/file&#34;</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34;|&#34;</span><span class="o">)</span>

<span class="c1">// this writes tuples in the text formatting &#34;(a, b, c)&#34;, rather than as CSV lines
</span><span class="c1"></span><span class="n">values</span><span class="o">.</span><span class="n">writeAsText</span><span class="o">(</span><span class="s">&#34;file:///path/to/the/result/file&#34;</span><span class="o">)</span>

<span class="c1">// this writes values as strings using a user-defined formatting
</span><span class="c1"></span><span class="n">values</span> <span class="n">map</span> <span class="o">{</span> <span class="n">tuple</span> <span class="k">=&gt;</span> <span class="n">tuple</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="s">&#34; - &#34;</span> <span class="o">+</span> <span class="n">tuple</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  <span class="o">.</span><span class="n">writeAsText</span><span class="o">(</span><span class="s">&#34;file:///path/to/the/result/file&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="本地排序输出">本地排序输出</h3>
<p>数据接收器的输出可以使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#define-keys-for-tuples">元组字段位置</a>或<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#define-keys-using-field-expressions">字段表达式</a>对指定字段按指定顺序进行本地排序。这适用于每一种输出格式。</p>
<p>下面的示例展示了如何使用该功能。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">pData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">BookPojo</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">sData</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="c1">// sort output on String field in ascending order
</span><span class="c1"></span><span class="n">tData</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>

<span class="c1">// sort output on Double field in descending and Int field in ascending order
</span><span class="c1"></span><span class="n">tData</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">DESCENDING</span><span class="o">).</span><span class="n">sortPartition</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>

<span class="c1">// sort output on the &#34;author&#34; field of nested BookPojo in descending order
</span><span class="c1"></span><span class="n">pData</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="s">&#34;_1.author&#34;</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">DESCENDING</span><span class="o">).</span><span class="n">writeAsText</span><span class="o">(...)</span>

<span class="c1">// sort output on the full tuple in ascending order
</span><span class="c1"></span><span class="n">tData</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="s">&#34;_&#34;</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">).</span><span class="n">writeAsCsv</span><span class="o">(...)</span>

<span class="c1">// sort atomic type (String) output in descending order
</span><span class="c1"></span><span class="n">sData</span><span class="o">.</span><span class="n">sortPartition</span><span class="o">(</span><span class="s">&#34;_&#34;</span><span class="o">,</span> <span class="nc">Order</span><span class="o">.</span><span class="nc">DESCENDING</span><span class="o">).</span><span class="n">writeAsText</span><span class="o">(...)</span>
</code></pre></div><p>目前还不支持全局排序输出。</p>
<h2 id="迭代运算符">迭代运算符</h2>
<p>迭代在  Flink 程序中实现了循环。迭代运算符封装了程序的一部分，并反复执行，将一次迭代的结果（部分解）反馈到下一次迭代中。Flink 中的迭代有两种类型。<code>BulkIteration</code> 和 <code>DeltaIteration</code>。</p>
<p>本节提供了如何使用这两种运算符的快速示例。查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">迭代介绍页面</a>可以获得更详细的介绍。</p>
<h3 id="批量迭代">批量迭代</h3>
<p>要创建一个 <code>BulkIteration</code>，调用迭代开始的 DataSet 的 <code>iterate(int)</code> 方法，同时指定一个 <code>step</code> 函数。<code>step</code> 函数获取当前迭代的输入 DataSet，并且必须返回一个新的 DataSet。迭代调用的参数是最大的迭代次数，迭代过后要停止。</p>
<p>还有 <code>iterateWithTermination(int)</code> 函数，接受 <code>step</code> 函数，返回两个 DataSets。迭代步骤的结果和一个终止标准。一旦终止准则 DataSet 为空，就会停止迭代。</p>
<p>下面的例子是迭代估计数字 Pi。目标是计算随机点的数量，这些随机点落入单位圆中。在每一次迭代中，都会挑选一个随机点。如果这个点位于单位圆内，我们就递增计数。然后，Pi 的估计值是所得到的计数除以迭代次数乘以 4。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="c1">// Create initial DataSet
</span><span class="c1"></span><span class="k">val</span> <span class="n">initial</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="n">count</span> <span class="k">=</span> <span class="n">initial</span><span class="o">.</span><span class="n">iterate</span><span class="o">(</span><span class="mi">10000</span><span class="o">)</span> <span class="o">{</span> <span class="n">iterationInput</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=&gt;</span>
  <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">iterationInput</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">i</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">x</span> <span class="k">=</span> <span class="nc">Math</span><span class="o">.</span><span class="n">random</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">y</span> <span class="k">=</span> <span class="nc">Math</span><span class="o">.</span><span class="n">random</span><span class="o">()</span>
    <span class="n">i</span> <span class="o">+</span> <span class="o">(</span><span class="k">if</span> <span class="o">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="n">result</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">count</span> <span class="n">map</span> <span class="o">{</span> <span class="n">c</span> <span class="k">=&gt;</span> <span class="n">c</span> <span class="o">/</span> <span class="mf">10000.0</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">}</span>

<span class="n">result</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&#34;Iterative Pi Example&#34;</span><span class="o">)</span>
</code></pre></div><p>你也可以查看 <a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/clustering/KMeans.scala">K-Means</a> 的例子，它使用 <code>BulkIteration</code> 来聚类一组未标记的点。</p>
<h3 id="增量迭代">增量迭代</h3>
<p>增量迭代利用了某些算法在每次迭代中不改变解的每个数据点的事实。</p>
<p>除了在每次迭代中反馈的部分解（称为 workset），delta 迭代还保持着跨迭代的状态（称为解集），可以通过 delta 更新。迭代计算的结果是最后一次迭代后的状态。关于 delta 迭代的基本原理，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">迭代简介</a>。</p>
<p>定义 <code>DeltaIteration</code> 与定义 <code>BulkIteration</code> 类似。对于 delta 迭代，两个数据集构成了每次迭代的输入（工作集和解集），并且在每次迭代中产生两个数据集作为结果（新工作集，解集 delta）。</p>
<p>要创建一个 DeltaIteration 在初始解集上调用 <code>iterateDelta(initialWorkset，maxIterations，key)</code>。<code>step</code> 函数需要两个参数。(solutionSet, workset), 并且必须返回两个值: (solutionSetDelta, newWorkset).</p>
<p>下面是一个 delta 迭代语法的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// read the initial data sets
</span><span class="c1"></span><span class="k">val</span> <span class="n">initialSolutionSet</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">initialWorkset</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">maxIterations</span> <span class="k">=</span> <span class="mi">100</span>
<span class="k">val</span> <span class="n">keyPosition</span> <span class="k">=</span> <span class="mi">0</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">initialSolutionSet</span><span class="o">.</span><span class="n">iterateDelta</span><span class="o">(</span><span class="n">initialWorkset</span><span class="o">,</span> <span class="n">maxIterations</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="n">keyPosition</span><span class="o">))</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">solution</span><span class="o">,</span> <span class="n">workset</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">candidateUpdates</span> <span class="k">=</span> <span class="n">workset</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="nc">ComputeCandidateChanges</span><span class="o">())</span>
    <span class="k">val</span> <span class="n">deltas</span> <span class="k">=</span> <span class="n">candidateUpdates</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">solution</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)(</span><span class="k">new</span> <span class="nc">CompareChangesToCurrent</span><span class="o">())</span>

    <span class="k">val</span> <span class="n">nextWorkset</span> <span class="k">=</span> <span class="n">deltas</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">FilterByThreshold</span><span class="o">())</span>

    <span class="o">(</span><span class="n">deltas</span><span class="o">,</span> <span class="n">nextWorkset</span><span class="o">)</span>
<span class="o">}</span>

<span class="n">result</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">)</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><h2 id="在函数中对数据对象进行操作">在函数中对数据对象进行操作</h2>
<p>Flink 的运行时以 Java 对象的形式与用户函数交换数据。函数从运行时接收输入对象作为方法参数，并返回输出对象作为结果。因为这些对象是由用户函数和运行时代码访问的，所以理解和遵循用户代码如何访问，即读取和修改这些对象的规则是非常重要的。</p>
<p>用户函数以常规方法参数（如 MapFunction）或通过 Iterable 参数（如 GroupReduceFunction）从 Flink 的运行时接收对象。我们把运行时传递给用户函数的对象称为输入对象。用户函数可以将对象作为方法返回值（像 MapFunction）或通过 Collector（像 FlatMapFunction）发射给 Flink 运行时。我们将用户函数向运行时发射的对象称为输出对象。</p>
<p>Flink 的 DataSet API 具有两种模式，它们在 Flink 的运行时如何创建或重用输入对象方面有所不同。这种行为会影响用户函数如何与输入和输出对象交互的保证和约束。下面的章节定义了这些规则，并给出了编写安全用户函数代码的编码指南。</p>
<h3 id="禁用对象重用default">禁用对象重用(DEFAULT)</h3>
<p>默认情况下，Flink 在禁用对象重用模式下运行。这种模式可以保证函数在函数调用中总是接收新的输入对象。对象重用禁用模式能提供更好的保证，使用起来也更安全。但是，它有一定的处理开销，可能会引起较高的 Java 垃圾收集活动。下表解释了在禁用对象重用模式下，用户函数如何访问输入和输出对象。</p>
<table>
<thead>
<tr>
<th style="text-align:left">操作</th>
<th style="text-align:left">保证和限制</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读取输入对象</td>
<td style="text-align:left">在一个方法调用中，保证输入对象的值不会改变。这包括由 Iterable 服务的对象。例如，在 List 或 Map 中收集由 Iterable 服务的输入对象是安全的。请注意，在方法调用离开后，对象可能会被修改。跨函数调用记忆对象是不安全的。</td>
</tr>
<tr>
<td style="text-align:left">修改输入对象</td>
<td style="text-align:left">你可以修改输入对象。</td>
</tr>
<tr>
<td style="text-align:left">发射输入对象</td>
<td style="text-align:left">你可以发射输入对象。输入对象的值可能在发射后发生变化。读取发射后的输入对象是不安全的。</td>
</tr>
<tr>
<td style="text-align:left">读取输出对象</td>
<td style="text-align:left">给予收集器的对象或作为方法结果返回的对象可能已经改变了其值。读取输出对象是不安全的。</td>
</tr>
<tr>
<td style="text-align:left">修改输出对象</td>
<td style="text-align:left">你可以在对象被发射后对其进行修改，然后再次发射。</td>
</tr>
</tbody>
</table>
<p>对象重用禁用（默认）模式的编码准则。</p>
<ul>
<li>不要跨方法调用记忆和读取输入对象。</li>
<li>不要在发出对象后读取对象。</li>
</ul>
<h3 id="启用对象重用">启用对象重用</h3>
<p>在启用对象重用模式下，Flink 的运行时会尽量减少对象实例化的数量。这可以提高性能，并且可以减少 Java 垃圾收集的压力。通过调用 <code>ExecutionConfig.enableObjectReuse()</code> 激活对象重用启用模式。下表解释了在启用对象重用模式下，用户函数如何访问输入和输出对象。</p>
<table>
<thead>
<tr>
<th style="text-align:left">操作</th>
<th style="text-align:left">保证和限制</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读取作为常规方法参数接收的输入对象</td>
<td style="text-align:left">作为常规方法参数接收的输入对象在一次函数调用中不被修改。对象可能在方法调用结束后被修改。跨函数调用记忆对象是不安全的。</td>
</tr>
<tr>
<td style="text-align:left">读取从 Iterable 参数中接收到的输入对象</td>
<td style="text-align:left">从 Iterable 中接收到的输入对象只在调用 next()方法之前有效。一个 Iterable 或 Iterator 可以多次服务于同一个对象实例。记住从 Iterable 接收的输入对象是不安全的，例如，把它们放在 List 或 Map 中。</td>
</tr>
<tr>
<td style="text-align:left">修改输入对象</td>
<td style="text-align:left">除了 MapFunction、FlatMapFunction、MapPartitionFunction、GroupReduceFunction、GroupCombineFunction、CoGroupFunction 和 InputFormat.next(reuse)的输入对象外，你不得修改输入对象。</td>
</tr>
<tr>
<td style="text-align:left">发射输入对象</td>
<td style="text-align:left">除了 MapFunction、FlatMapFunction、MapPartitionFunction、GroupReduceFunction、GroupCombineFunction、CoGroupFunction 和 InputFormat.next(重用)的输入对象外，你不得发射输入对象。</td>
</tr>
<tr>
<td style="text-align:left">读取输出对象</td>
<td style="text-align:left">一个被交给 Collector 或作为方法结果返回的对象可能已经改变了它的值。读取输出对象是不安全的。</td>
</tr>
<tr>
<td style="text-align:left">修改输出对象</td>
<td style="text-align:left">你可以修改一个输出对象并再次发出它。</td>
</tr>
</tbody>
</table>
<p>启用对象重用的编码准则。</p>
<ul>
<li>不记忆从 Iterable 接收的输入对象。</li>
<li>不记忆和读取跨方法调用的输入对象。</li>
<li>除了 MapFunction、FlatMapFunction、MapPartitionFunction、GroupReduceFunction、GroupCombineFunction、CoGroupFunction 和 InputFormat.next(reuse)的输入对象外，不要修改或发出输入对象。</li>
<li>为了减少对象实例化，你总是可以发出一个专门的输出对象，这个对象被反复修改，但从不读取。</li>
</ul>
<h2 id="调试">调试</h2>
<p>在分布式集群中的大型数据集上运行数据分析程序之前，最好确保所实现的算法能够按照预期的方式运行。因此，实现数据分析程序通常是一个检查结果、调试和改进的渐进过程。</p>
<p>Flink 提供了一些不错的功能，通过支持 IDE 内的本地调试、注入测试数据和收集结果数据，大大简化了数据分析程序的开发过程。本节给大家一些提示，如何简化 Flink 程序的开发。</p>
<h3 id="本地执行环境">本地执行环境</h3>
<p>LocalEnvironment 在它创建的同一个 JVM 进程中启动 Flink 系统。如果你从 IDE 中启动 LocalEnvironment，你可以在代码中设置断点，轻松调试你的程序。</p>
<p>LocalEnvironment 的创建和使用方法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="n">pathToTextFile</span><span class="o">)</span>
<span class="c1">// build your program
</span><span class="c1"></span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><h3 id="收集数据源和接收器">收集数据源和接收器</h3>
<p>为分析程序提供输入并检查其输出，如果通过创建输入文件和读取输出文件来完成，是很麻烦的。Flink 具有特殊的数据源和接收器，这些数据源和接收器由 Java 集合支持，以方便测试。一旦程序经过测试，源和接收器可以很容易地被从 HDFS 等外部数据存储中读取/写入的源和接收器所替代。</p>
<p>集合数据源可以使用以下方式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="c1">// Create a DataSet from a list of elements
</span><span class="c1"></span><span class="k">val</span> <span class="n">myInts</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">)</span>

<span class="c1">// Create a DataSet from any Collection
</span><span class="c1"></span><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">myTuples</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Create a DataSet from an Iterator
</span><span class="c1"></span><span class="k">val</span> <span class="n">longIt</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">myLongs</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">longIt</span><span class="o">)</span>
</code></pre></div><p>注：目前，集合数据源要求数据类型和迭代器实现 Serializable。此外，集合数据源不能并行执行（ parallelism = 1）。</p>
<h2 id="语义注解">语义注解</h2>
<p>语义注解可以用来给 Flink 提供关于函数行为的提示。它们告诉系统，函数读取并评估了函数输入的哪些字段，以及它将哪些字段从输入转发到输出，而没有进行修改。语义注解是加快执行速度的有力手段，因为它们允许系统推理出在多个操作中重复使用排序顺序或分区的问题。使用语义注解最终可能会使程序免于不必要的数据洗牌或不必要的排序，并显著提高程序的性能。</p>
<p>注意：语义注解的使用是可选的。然而，在提供语义注解时，保守地使用语义注解是绝对关键的! 不正确的语义注解将导致 Flink 对你的程序做出不正确的假设，并可能最终导致不正确的结果。如果一个操作符的行为不是明确可预测的，就不应该提供注解。请仔细阅读文档。</p>
<p>目前支持以下语义注解。</p>
<p><strong>转发字段注解</strong></p>
<p>转发字段信息声明了未被修改的输入字段被函数转发到输出中的同一位置或另一位置。该信息被优化器用来推断数据属性（如排序或分区）是否被函数保留。对于对输入元素组进行操作的函数，如 GroupReduce、GroupCombine、CoGroup 和 MapPartition，所有被定义为转发字段的字段必须总是从同一个输入元素联合转发。由组智函数发出的每个元素的转发字段可能来源于函数的输入组的不同元素。</p>
<p>字段转发信息使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#define-keys-using-field-expressions">字段表达式</a>来指定。在输出中转发到同一位置的字段可以通过其位置来指定。指定的位置必须对输入和输出的数据类型有效，并具有相同的类型。例如字符串 &ldquo;f2 &ldquo;声明 Java 输入元组的第三个字段总是等于输出元组中的第三个字段。</p>
<p>将输入中的源字段和输出中的目标字段指定为字段表达式，就可以声明未修改的字段转发到输出中的另一个位置。字符串 <code>&quot;f0-&gt;f2&quot;</code> 表示将 Java 输入元组的第一个字段不变的复制到 Java 输出元组的第三个字段。通配符表达式 <code>*</code> 可以用来指代整个输入或输出类型，即 <code>&quot;f0-&gt;*&quot;</code> 表示一个函数的输出总是等于其 Java 输入元组的第一个字段。</p>
<p>多个转发字段可以在一个字符串中用分号隔开声明为 <code>&quot;f0; f2-&gt;f1; f3-&gt;f2&quot;</code>，也可以在单独的字符串中声明为 &ldquo;f0&rdquo;、&ldquo;f2-&gt;f1&rdquo;、&ldquo;f3-&gt;f2&rdquo;。当指定转发字段时，不要求所有的转发字段都声明，但所有的声明必须正确。</p>
<p>转发字段信息可以通过在函数类定义上附加 Java 注解来声明，或者在调用 DataSet 上的函数后将其作为操作符参数传递，如下图所示。</p>
<p><strong>函数类注解</strong></p>
<ul>
<li><code>@ForwardedFields</code> 用于单输入的函数，如 Map 和 Reduce。</li>
<li><code>@ForwardedFieldsFirst</code> 代表有两个输入的函数的第一个输入，如 Join 和 CoGroup。</li>
<li><code>@ForwardedFieldsSecond</code> 代表有两个输入的函数的第二个输入，如 Join 和 CoGroup。</li>
</ul>
<p><strong>操作符参数</strong></p>
<ul>
<li><code>data.map(myMapFnc).withForwardedFields()</code> 用于单输入的函数，如 Map 和 Reduce。</li>
<li><code>data1.join(data2).where().equalTo().with(myJoinFnc).withForwardFieldsFirst()</code> 用于有两个输入的函数的第一个输入，如 Join 和 CoGroup。</li>
<li><code>data1.join(data2).where().equalTo().with(myJoinFnc).withForwardFieldsSecond()</code> 用于有两个输入的函数的第二个输入，如 Join 和 CoGroup。</li>
</ul>
<p>请注意，不可能覆盖通过操作符参数指定为类注解的字段前向信息。</p>
<p>例子：在函数的第二个输入端，如 Join 和 CoGroup，请注意不能覆盖通过运算符参数指定的类注解的字段前向信息。</p>
<p>下面的例子显示了如何使用函数类注解来声明转发的字段信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nd">@ForwardedFields</span><span class="o">(</span><span class="s">&#34;_1-&gt;_3&#34;</span><span class="o">)</span>
<span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
   <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">(</span><span class="s">&#34;foo&#34;</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span> <span class="o">/</span> <span class="mi">2</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>非转发字段</strong></p>
<p>非转发字段信息声明了所有在函数输出中不保留在同一位置的字段。所有其他字段的值都被认为保留在输出的同一位置。因此，非转发字段信息与转发字段信息是相反的。分组运算符（如 GroupReduce、GroupCombine、CoGroup 和 MapPartition）的非转发字段信息必须满足与转发字段信息相同的要求。</p>
<p>重要：非转发字段信息的规范是可选的。但是如果使用，必须指定 <strong>ALL!</strong> 非转发字段，因为所有其他字段都被认为是原地转发的。将一个转发字段声明为非转发字段是安全的。</p>
<p>非转发字段被指定为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#define-keys-using-field-expressions">字段表达式</a>的列表。这个列表既可以是由分号分隔的字段表达式组成的单个字符串，也可以是多个字符串。例如 &ldquo;f1; f3&rdquo; 和 &ldquo;f1&rdquo;、&ldquo;f3&rdquo; 都声明 Java 元组的第二个和第四个字段不保留在原地，其他所有字段都保留在原地。非前向字段信息只能为输入和输出类型相同的函数指定。</p>
<p>非转发字段信息是作为函数类注解使用以下注解来指定的。</p>
<ul>
<li><code>@NonForwardedFields</code> 用于单个输入函数，如 Map 和 Reduce。</li>
<li><code>@NonForwardedFieldsFirst</code> 用于有两个输入的函数的第一个输入，如 Join 和 CoGroup。</li>
<li><code>@NonForwardedFieldsSecond</code> 用于函数的第二个输入，如 Join 和 CoGroup。</li>
</ul>
<p>例子</p>
<p>下面的例子显示了如何声明非转发字段信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nd">@NonForwardedFields</span><span class="o">(</span><span class="s">&#34;_2&#34;</span><span class="o">)</span> <span class="c1">// second field is not forwarded
</span><span class="c1"></span><span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span> <span class="o">/</span> <span class="mi">2</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>读取字段</strong></p>
<p>读取字段信息声明了所有被函数访问和评估的字段，也就是说，所有被函数用来计算结果的字段。例如，在条件语句中被评估的字段或用于计算的字段必须在指定读取字段信息时被标记为读取。仅仅是未经修改就转发到输出而不评估其值的字段，或者根本没有被访问的字段都不被认为是读。</p>
<p>重要：读取字段信息的指定是可选的。但是如果使用，必须指定 <strong>ALL!</strong> 读取字段。将一个非读字段声明为读字段是安全的。</p>
<p>读取字段被指定为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/#define-keys-using-field-expressions">字段表达式</a>的列表。这个列表可以是一个由分号分隔的字段表达式组成的单个字符串，也可以是多个字符串。例如 &ldquo;f1; f3&rdquo; 和 &ldquo;f1&rdquo;、&ldquo;f3&rdquo; 都声明 Java 元组的第二和第四字段被函数读取和评估。</p>
<p>读取字段信息是以函数类注解的形式指定的，使用以下注解。</p>
<ul>
<li><code>@ReadFields</code> 用于单输入函数，如 Map 和 Reduce。</li>
<li><code>@ReadFieldsFirst</code> 用于有两个输入的函数的第一个输入，如 Join 和 CoGroup。</li>
<li><code>@ReadFieldsSecond</code> 用于有两个输入的函数的第二个输入，如 Join 和 CoGroup。</li>
</ul>
<p>示例：</p>
<p>下面的例子显示了如何声明读取字段信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nd">@ReadFields</span><span class="o">(</span><span class="s">&#34;_1; _4&#34;</span><span class="o">)</span> <span class="c1">// _1 and _4 are read and evaluated by the function.
</span><span class="c1"></span><span class="k">class</span> <span class="nc">MyMap</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span>, <span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)]{</span>
   <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">,</span> <span class="nc">Int</span><span class="o">))</span><span class="k">:</span> <span class="o">(</span><span class="kt">Int</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="n">_1</span> <span class="o">==</span> <span class="mi">42</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">return</span> <span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
      <span class="k">return</span> <span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="n">_4</span> <span class="o">+</span> <span class="mi">10</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h2 id="广播变量">广播变量</h2>
<p>广播变量允许你在操作的常规输入之外，将一个数据集提供给操作的所有并行实例。这对辅助数据集或数据依赖性参数化很有用。然后，该数据集将作为一个集合在操作者处被访问。</p>
<ul>
<li>广播：广播集通过 <code>withBroadcastSet(DataSet，String)</code> 按名称注册，并通过</li>
<li>访问方式：通过目标操作者处的 <code>getRuntimeContext().getBroadcastVariable(String)</code> 访问。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// 1. The DataSet to be broadcast
</span><span class="c1"></span><span class="k">val</span> <span class="n">toBroadcast</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">)</span>

<span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">]()</span> <span class="o">{</span>
    <span class="k">var</span> <span class="n">broadcastSet</span><span class="k">:</span> <span class="kt">Traversable</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="c1">// 3. Access the broadcast DataSet as a Collection
</span><span class="c1"></span>      <span class="n">broadcastSet</span> <span class="k">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="n">getBroadcastVariable</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;broadcastSetName&#34;</span><span class="o">).</span><span class="n">asScala</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="n">withBroadcastSet</span><span class="o">(</span><span class="n">toBroadcast</span><span class="o">,</span> <span class="s">&#34;broadcastSetName&#34;</span><span class="o">)</span> <span class="c1">// 2. Broadcast the DataSet
</span></code></pre></div><p>在注册和访问广播数据集时，确保名称（前面例子中的 <code>broadcastSetName</code>）匹配。关于完整的示例程序，可以看一下 <a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/clustering/KMeans.scala">KMeans 算法</a>。</p>
<p>注意：由于广播变量的内容在每个节点上都保存在内存中，所以它不应该变得太大。对于像标量值这样简单的东西，你可以简单地将参数作为函数闭包的一部分，或者使用 <code>withParameters(...)</code> 方法来传递配置。</p>
<h2 id="分布式缓存">分布式缓存</h2>
<p>Flink 提供了一个类似于 Apache Hadoop 的分布式缓存，以使用户函数的并行实例可以在本地访问文件。该功能可用于共享包含静态外部数据的文件，如字典或机器学习的回归模型。</p>
<p>缓存的工作原理如下。程序在其 <code>ExecutionEnvironment</code> 中以特定的名称将<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/connectors.html#reading-from-file-systems">本地或远程文件系统（如 HDFS 或 S3）</a>的文件或目录注册为缓存文件。当程序执行时，Flink 会自动将该文件或目录复制到所有工作者的本地文件系统中。用户函数可以查找指定名称下的文件或目录，并从工作者的本地文件系统中访问它。</p>
<p>分布式缓存的使用方法如下。</p>
<p>在 <code>ExecutionEnvironment</code> 中注册文件或目录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// register a file from HDFS
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">registerCachedFile</span><span class="o">(</span><span class="s">&#34;hdfs:///path/to/your/file&#34;</span><span class="o">,</span> <span class="s">&#34;hdfsFile&#34;</span><span class="o">)</span>

<span class="c1">// register a local executable file (script, executable, ...)
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">registerCachedFile</span><span class="o">(</span><span class="s">&#34;file:///path/to/exec/file&#34;</span><span class="o">,</span> <span class="s">&#34;localExecFile&#34;</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="c1">// define your program and execute
</span><span class="c1"></span><span class="o">...</span>
<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapper</span><span class="o">())</span>
<span class="o">...</span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><p>在一个用户函数（这里是 MapFunction）中访问缓存文件。该函数必须扩展一个 RichFunction 类，因为它需要访问 RuntimeContext。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// extend a RichFunction to have access to the RuntimeContext
</span><span class="c1"></span><span class="k">class</span> <span class="nc">MyMapper</span> <span class="k">extends</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

    <span class="c1">// access cached file via RuntimeContext and DistributedCache
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">myFile</span><span class="k">:</span> <span class="kt">File</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">.</span><span class="n">getDistributedCache</span><span class="o">.</span><span class="n">getFile</span><span class="o">(</span><span class="s">&#34;hdfsFile&#34;</span><span class="o">)</span>
    <span class="c1">// read the file (or navigate the directory)
</span><span class="c1"></span>    <span class="o">...</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// use content of cached file
</span><span class="c1"></span>    <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h2 id="向函数传递参数">向函数传递参数</h2>
<p>可以使用构造函数或 <code>withParameters(Configuration)</code> 方法将参数传递给函数。参数会被序列化为函数对象的一部分，并传送给所有并行任务实例。</p>
<p><strong>通过构造函数</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">toFilter</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="n">toFilter</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyFilter</span><span class="o">(</span><span class="mi">2</span><span class="o">))</span>

<span class="k">class</span> <span class="nc">MyFilter</span><span class="o">(</span><span class="n">limit</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">FilterFunction</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="n">filter</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">value</span> <span class="o">&gt;</span> <span class="n">limit</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><strong>通过 withParameters(配置)</strong></p>
<p>本方法以一个 Configuration 对象作为参数，它将被传递给<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/user_defined_functions.html#rich-functions">富函数</a>的 <code>open()</code> 方法。配置对象是一个从 String 键到不同值类型的 Map。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">toFilter</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">c</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
<span class="n">c</span><span class="o">.</span><span class="n">setInteger</span><span class="o">(</span><span class="s">&#34;limit&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>

<span class="n">toFilter</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">RichFilterFunction</span><span class="o">[</span><span class="kt">Int</span><span class="o">]()</span> <span class="o">{</span>
    <span class="k">var</span> <span class="n">limit</span> <span class="k">=</span> <span class="mi">0</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="n">limit</span> <span class="k">=</span> <span class="n">config</span><span class="o">.</span><span class="n">getInteger</span><span class="o">(</span><span class="s">&#34;limit&#34;</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="n">filter</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">in</span> <span class="o">&gt;</span> <span class="n">limit</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="n">withParameters</span><span class="o">(</span><span class="n">c</span><span class="o">)</span>
</code></pre></div><p><strong>在全局范围内通过 ExecutionConfig</strong></p>
<p>Flink 还允许将自定义配置值传递到环境的 ExecutionConfig 接口。由于执行配置可以在所有（丰富的）用户函数中访问，因此自定义配置将在所有函数中全局可用。</p>
<p>设置一个自定义的全局配置：</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
<span class="n">conf</span><span class="o">.</span><span class="n">setString</span><span class="o">(</span><span class="s">&#34;mykey&#34;</span><span class="o">,</span> <span class="s">&#34;myvalue&#34;</span><span class="o">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">setGlobalJobParameters</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</code></pre></div><p>请注意，你也可以传递一个扩展 <code>ExecutionConfig.GlobalJobParameters</code> 类的自定义类作为全局作业参数给执行配置。该接口允许实现 <code>Map&lt;String, String&gt; toMap()</code> 方法，该方法将在 web 前端显示来自配置的值。</p>
<p><strong>从全局配置中访问值</strong></p>
<p>全局工作参数中的对象在系统中的很多地方都可以访问。所有实现 RichFunction 接口的用户函数都可以通过运行时上下文访问。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">Tokenizer</span> <span class="kd">extends</span> <span class="n">RichFlatMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="n">String</span> <span class="n">mykey</span><span class="o">;</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
      <span class="kd">super</span><span class="o">.</span><span class="na">open</span><span class="o">(</span><span class="n">parameters</span><span class="o">);</span>
      <span class="n">ExecutionConfig</span><span class="o">.</span><span class="na">GlobalJobParameters</span> <span class="n">globalParams</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getExecutionConfig</span><span class="o">().</span><span class="na">getGlobalJobParameters</span><span class="o">();</span>
      <span class="n">Configuration</span> <span class="n">globConf</span> <span class="o">=</span> <span class="o">(</span><span class="n">Configuration</span><span class="o">)</span> <span class="n">globalParams</span><span class="o">;</span>
      <span class="n">mykey</span> <span class="o">=</span> <span class="n">globConf</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="s">&#34;mykey&#34;</span><span class="o">,</span> <span class="kc">null</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="c1">// ... more here ...
</span></code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/guide" term="guide" label="Guide" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hadoop 的兼容性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="related" type="text/html" title="本地执行" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Hadoop Compatibility Beta</blockquote><h2 id="hadoop-兼容性测试版">Hadoop 兼容性测试版</h2>
<p>Flink 与 Apache Hadoop MapReduce 接口兼容，因此允许重用为 Hadoop MapReduce 实现的代码。</p>
<p>您可以:</p>
<ul>
<li>在 Flink 程序中使用 Hadoop 的可写<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#supported-data-types">数据类型</a>。</li>
<li>使用任何 Hadoop InputFormat 作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#data-sources">数据源</a>。</li>
<li>使用任何 Hadoop 输出格式作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#data-sinks">数据接收器</a>。</li>
<li>将 Hadoop Mapper 用作 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunction</a>。</li>
<li>使用 Hadoop Reducer 作为 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunction</a>。</li>
</ul>
<p>本文档展示了如何将现有的 Hadoop MapReduce 代码与 Flink 一起使用。从 Hadoop 支持的文件系统读取代码，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/filesystems/index.html#hadoop-file-system-hdfs-and-its-other-implementations">连接到其他系统</a>指南。</p>
<h3 id="项目配置">项目配置</h3>
<p>对 Hadoop 输入/输出格式的支持是 flink-java 和 flink-scala Maven 模块的一部分，这些模块在编写 Flink 作业时总是需要的。这些代码位于 <code>org.apache.flink.api.java.hadoop</code> 和 <code>org.apache.flink.api.scala.hadoop</code> 中的 mapred 和 mapreduce API 的附加子包中。</p>
<p>对 Hadoop Mappers 和 Reducers 的支持包含在 <code>flink-hadoop-compatibility</code> Maven 模块中。这段代码位于 <code>org.apache.flink.hadoopcompatibility</code> 包中。</p>
<p>如果您想重用 Mappers 和 Reducers，请在 pom.xml 中添加以下依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>flink-hadoop-compatibility_2.11<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>另请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/hadoop.html#add-hadoop-classpaths">如何配置 hadoop 依赖关系</a>。</p>
<h3 id="使用-hadoop-输入格式">使用 Hadoop 输入格式</h3>
<p>要使用 Flink 的 Hadoop InputFormats，必须先使用 HadoopInputs 实用程序类的 readHadoopFile 或 createHadoopInput 来包装格式。前者用于从 FileInputFormat 派生的输入格式，而后者必须用于通用的输入格式。通过使用 <code>ExecutionEnvironmen#createInput</code>，产生的 InputFormat 可以用来创建数据源。</p>
<p>生成的 DataSet 包含 2 个元组，其中第一个字段是键，第二个字段是从 Hadoop InputFormat 中检索的值。</p>
<p>下面的示例展示了如何使用 Hadoop 的 TextInputFormat。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">LongWritable</span>, <span class="kt">Text</span><span class="o">)]</span> <span class="k">=</span>
  <span class="n">env</span><span class="o">.</span><span class="n">createInput</span><span class="o">(</span><span class="nc">HadoopInputs</span><span class="o">.</span><span class="n">readHadoopFile</span><span class="o">(</span>
                    <span class="k">new</span> <span class="nc">TextInputFormat</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">LongWritable</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Text</span><span class="o">],</span> <span class="n">textPath</span><span class="o">))</span>

<span class="c1">// Do something with the data.
</span><span class="c1"></span><span class="o">[</span><span class="kt">...</span><span class="o">]</span>
</code></pre></div><h3 id="使用-hadoop-输出格式">使用 Hadoop 输出格式</h3>
<p>Flink 为 Hadoop OutputFormat 提供了一个兼容性封装器，它支持任何实现 org.apache.hadoop.mapred.OutputFormat 或扩展 org.apache.hadoop.mapreduce.OutputFormat 的类。OutputFormat 包装器希望它的输入数据是一个包含2个key和value的 DataSet。这些数据将由 Hadoop OutputFormat 处理。</p>
<p>下面的示例展示了如何使用 Hadoop 的 TextOutputFormat。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Obtain your result to emit.
</span><span class="c1"></span><span class="k">val</span> <span class="n">hadoopResult</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">)]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>

<span class="k">val</span> <span class="n">hadoopOF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HadoopOutputFormat</span><span class="o">[</span><span class="kt">Text</span>,<span class="kt">IntWritable</span><span class="o">](</span>
  <span class="k">new</span> <span class="nc">TextOutputFormat</span><span class="o">[</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">],</span>
  <span class="k">new</span> <span class="nc">JobConf</span><span class="o">)</span>

<span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&#34;mapred.textoutputformat.separator&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">)</span>
<span class="nc">FileOutputFormat</span><span class="o">.</span><span class="n">setOutputPath</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">resultPath</span><span class="o">))</span>

<span class="n">hadoopResult</span><span class="o">.</span><span class="n">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">)</span>
</code></pre></div><h3 id="使用-hadoop-mappers-和-reducers">使用 Hadoop Mappers 和 Reducers</h3>
<p>Hadoop Mappers 在语义上等同于 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunctions</a>，Hadoop Reducers 等同于 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunctions</a>。Flink 为 Hadoop MapReduce 的 Mapper 和 Reducer 接口的实现提供了封装器，也就是说，你可以在常规的 Flink 程序中重用你的 Hadoop Mapper 和 Reducer。目前，只支持 Hadoop 的 mapred API（org.apache.hadoop.mapred）的 Mapper 和 Reduce 接口。</p>
<p>包装器将一个 <code>DataSet&lt;Tuple2&lt;KEYIN,VALUEIN&gt;</code> 作为输入，并产生一个 <code>DataSet&lt;Tuple2&lt;KEYOUT,VALUEOUT&gt;</code> 作为输出，其中 KEYIN 和 KEYOUT 是键，VALUEIN 和 VALUEOUT 是 Hadoop 函数处理的 Hadoop 键值对的值。对于 Reducers，Flink 提供了一个包装器，用于带（HadoopReduceCombineFunction）和不带 Combiner（HadoopReduceFunction）的 GroupReduceFunction。包装器接受一个可选的 JobConf 对象来配置 Hadoop Mapper 或 Reducer。</p>
<p>Flink 的函数包装器有:</p>
<ul>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopMapFunction,</li>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopReduceFunction, 和</li>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopReduceCombineFunction.</li>
</ul>
<p>并可作为常规的 Flink <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunctions</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunctions</a> 使用。</p>
<p>下面的例子展示了如何使用 Hadoop Mapper 和 Reducer 函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Obtain data to process somehow.
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// use Hadoop Mapper (Tokenizer) as MapFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
  <span class="c1">// use Hadoop Reducer (Counter) as Reduce- and CombineFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="n">Counter</span><span class="o">()</span>
  <span class="o">));</span>
</code></pre></div><p>请注意：Reducer 包装器工作在 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#transformations-on-grouped-dataset">groupBy()</a> 操作所定义的组上。它不考虑您在 JobConf 中设置的任何自定义分区器、排序或分组比较器。</p>
<h3 id="完整的-hadoop-wordcount-示例">完整的 Hadoop WordCount 示例</h3>
<p>下面的示例展示了使用 Hadoop 数据类型、Input-和 OutputFormats 以及 Mapper 和 Reducer 实现的完整 WordCount 实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// Set up the Hadoop TextInputFormat.
</span><span class="c1"></span><span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span>
<span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="n">hadoopIF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">TextInputFormat</span><span class="o">(),</span> <span class="n">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">TextInputFormat</span><span class="o">.</span><span class="na">addInputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">inputPath</span><span class="o">));</span>

<span class="c1">// Read data using the Hadoop TextInputFormat.
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span><span class="n">hadoopIF</span><span class="o">);</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// use Hadoop Mapper (Tokenizer) as MapFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
  <span class="c1">// use Hadoop Reducer (Counter) as Reduce- and CombineFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="n">Counter</span><span class="o">()</span>
  <span class="o">));</span>

<span class="c1">// Set up the Hadoop TextOutputFormat.
</span><span class="c1"></span><span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;</span> <span class="n">hadoopOF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">TextOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(),</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">hadoopOF</span><span class="o">.</span><span class="na">getConfiguration</span><span class="o">().</span><span class="na">set</span><span class="o">(</span><span class="s">&#34;mapreduce.output.textoutputformat.separator&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">);</span>
<span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">));</span>

<span class="c1">// Emit data using the Hadoop TextOutputFormat.
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">);</span>

<span class="c1">// Execute Program
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&#34;Hadoop WordCount&#34;</span><span class="o">);</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/hadoop_compatibility.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/hadoop_compatibility.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Insert 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Insert Statements</blockquote><h1 id="insert-语句">INSERT 语句</h1>
<p>INSERT 语句用于向表中添加行。</p>
<h2 id="运行-insert-语句">运行 INSERT 语句</h2>
<p>单条 INSERT 语句可以通过 TableEnvironment 的 <code>executeSql()</code> 方法执行，也可以在 SQL CLI 中执行。INSERT 语句的 <code>executeSql()</code> 方法会立即提交一个 Flink 作业，并返回一个与提交的作业相关联的 TableResult 实例。多个 INSERT 语句可以通过 StatementSet 的 <code>addInsertSql()</code> 方法执行，StatementSet 可以由 <code>TableEnvironment.createStatementSet()</code> 方法创建。<code>addInsertSql()</code> 方法是一种懒惰的执行方式，它们只有在调用 <code>StatementSet.execute()</code> 时才会被执行。</p>
<p>下面的例子展示了如何在 TableEnvironment 中运行一条 INSERT 语句，以及在 SQL CLI 中，在 StatementSet 中运行多条 INSERT 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; CREATE TABLE Orders <span class="o">(</span><span class="sb">`</span>user<span class="sb">`</span> BIGINT, product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; CREATE TABLE RubberOrders<span class="o">(</span>product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>

Flink SQL&gt; SHOW TABLES<span class="p">;</span>
Orders
RubberOrders

Flink SQL&gt; INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE <span class="s1">&#39;%Rubber%&#39;</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Submitting SQL update statement to the cluster...
<span class="o">[</span>INFO<span class="o">]</span> Table update statement has been successfully submitted to the cluster:
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">()...</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a source table named &#34;Orders&#34; and a sink table named &#34;RubberOrders&#34;
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE RubberOrders(product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// run a single INSERT query on the registered source table and emit the result to registered sink table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult1</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
<span class="c1">// get job status through TableResult
</span><span class="c1"></span><span class="n">println</span><span class="o">(</span><span class="n">tableResult1</span><span class="o">.</span><span class="n">getJobClient</span><span class="o">().</span><span class="n">get</span><span class="o">().</span><span class="n">getJobStatus</span><span class="o">())</span>

<span class="c1">//----------------------------------------------------------------------------
</span><span class="c1">// register another sink table named &#34;GlassOrders&#34; for multiple INSERT queries
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE GlassOrders(product VARCHAR, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// run multiple INSERT queries on the registered source table and emit the result to registered sink tables
</span><span class="c1"></span><span class="k">val</span> <span class="n">stmtSet</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">createStatementSet</span><span class="o">()</span>
<span class="c1">// only single INSERT query can be accepted by `addInsertSql` method
</span><span class="c1"></span><span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsertSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsertSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO GlassOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Glass%&#39;&#34;</span><span class="o">)</span>
<span class="c1">// execute all statements together
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult2</span> <span class="k">=</span> <span class="n">stmtSet</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
<span class="c1">// get job status through TableResult
</span><span class="c1"></span><span class="n">println</span><span class="o">(</span><span class="n">tableResult2</span><span class="o">.</span><span class="n">getJobClient</span><span class="o">().</span><span class="n">get</span><span class="o">().</span><span class="n">getJobStatus</span><span class="o">())</span>
</code></pre></div><h2 id="insert-from-select-queries">Insert from select queries</h2>
<p>查询结果可以通过使用插入子句插入到表中。</p>
<h3 id="语法">语法</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="err">{</span> <span class="k">INTO</span> <span class="o">|</span> <span class="n">OVERWRITE</span> <span class="err">}</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">part_spec</span><span class="p">]</span> <span class="n">select_statement</span>

<span class="n">part_spec</span><span class="p">:</span>
  <span class="p">(</span><span class="n">part_col_name1</span><span class="o">=</span><span class="n">val1</span> <span class="p">[,</span> <span class="n">part_col_name2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...])</span>
</code></pre></div><p><strong>OVERWRITE</strong></p>
<p>INSERT OVERWRITE 将覆盖表或分区中的任何现有数据。否则，将追加新数据。</p>
<p><strong>PARTITION</strong></p>
<p>PARTITION 子句应包含本次插入的静态分区列。</p>
<h3 id="例子">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="c1">-- Creates a partitioned table
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">country_page_view</span> <span class="p">(</span><span class="k">user</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">cnt</span> <span class="nb">INT</span><span class="p">,</span> <span class="nb">date</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">country</span> <span class="n">STRING</span><span class="p">)</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="nb">date</span><span class="p">,</span> <span class="n">country</span><span class="p">)</span>
<span class="k">WITH</span> <span class="p">(...)</span>

<span class="c1">-- Appends rows into the static partition (date=&#39;2019-8-30&#39;, country=&#39;China&#39;)
</span><span class="c1"></span><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;2019-8-30&#39;</span><span class="p">,</span> <span class="n">country</span><span class="o">=</span><span class="s1">&#39;China&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Appends rows into partition (date, country), where date is static partition with value &#39;2019-8-30&#39;,
</span><span class="c1">-- country is dynamic partition whose value is dynamic determined by each row.
</span><span class="c1"></span><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;2019-8-30&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span><span class="p">,</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Overwrites rows into static partition (date=&#39;2019-8-30&#39;, country=&#39;China&#39;)
</span><span class="c1"></span><span class="k">INSERT</span> <span class="n">OVERWRITE</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;2019-8-30&#39;</span><span class="p">,</span> <span class="n">country</span><span class="o">=</span><span class="s1">&#39;China&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Overwrites rows into partition (date, country), where date is static partition with value &#39;2019-8-30&#39;,
</span><span class="c1">-- country is dynamic partition whose value is dynamic determined by each row.
</span><span class="c1"></span><span class="k">INSERT</span> <span class="n">OVERWRITE</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;2019-8-30&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span><span class="p">,</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>
</code></pre></div><h2 id="insert-values-into-tables">Insert values into tables</h2>
<p>INSERT&hellip;VALUES 语句可以用来直接从 SQL 中向表中插入数据。</p>
<h3 id="语法-1">语法</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="err">{</span> <span class="k">INTO</span> <span class="o">|</span> <span class="n">OVERWRITE</span> <span class="err">}</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span> <span class="k">VALUES</span> <span class="n">values_row</span> <span class="p">[,</span> <span class="n">values_row</span> <span class="p">...]</span>

<span class="n">values_row</span><span class="p">:</span>
    <span class="p">:</span> <span class="p">(</span><span class="n">val1</span> <span class="p">[,</span> <span class="n">val2</span><span class="p">,</span> <span class="p">...])</span>
</code></pre></div><p><strong>OVERWRITE</strong></p>
<p>INSERT OVERWRITE 将覆盖表中的任何现有数据。否则，将追加新数据。</p>
<h3 id="例子-1">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">students</span> <span class="p">(</span><span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">,</span> <span class="n">gpa</span> <span class="nb">DECIMAL</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="k">WITH</span> <span class="p">(...);</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">students</span>
  <span class="k">VALUES</span> <span class="p">(</span><span class="s1">&#39;fred flintstone&#39;</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">1</span><span class="p">.</span><span class="mi">28</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;barney rubble&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">.</span><span class="mi">32</span><span class="p">);</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Java Lambda 表达式]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/?utm_source=atom_feed" rel="related" type="text/html" title="可查询状态" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Java Lambda Expressions</blockquote><h2 id="java-lambda-表达式">Java Lambda 表达式</h2>
<p>Java 8 引入了一些新的语言功能，旨在实现更快、更清晰的编码。其中最重要的功能是所谓的&quot;Lambda 表达式&quot;，它打开了函数式编程的大门。Lambda 表达式允许以一种直接的方式实现和传递函数，而无需声明额外的（匿名）类。</p>
<p>注意 Flink 支持对 Java API 的所有操作符使用 lambda 表达式，但是，每当 lambda 表达式使用 Java 属的时候，你需要明确地声明类型信息。</p>
<p>本文档展示了如何使用 lambda 表达式并描述了当前的限制。关于 Flink API 的一般介绍，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataSteam API 概述</a>。</p>
<h3 id="例子和限制">例子和限制</h3>
<p>下面的例子说明了如何实现一个简单的内联 <code>map()</code> 函数，该函数使用 lambda 表达式对其输入进行平方化。<code>map()</code> 函数的输入 <code>i</code> 和输出参数的类型不需要声明，因为它们是由 Java 编译器推断的。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
<span class="c1">// returns the squared i
</span><span class="c1"></span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="o">)</span>
<span class="o">.</span><span class="na">print</span><span class="o">();</span>
</code></pre></div><p>Flink 可以从方法签名 <code>OUT map(IN value)</code> 的实现中自动提取结果类型信息，因为 OUT 不是通用的，而是 Integer。</p>
<p>遗憾的是，像 <code>flatMap()</code> 这样签名为 <code>void flatMap(IN value, Collector&lt;OUT&gt; out)</code> 的函数被 Java 编译器编译成 <code>void flatMap(IN value, Collector out)</code>。这使得 Flink 无法自动推断输出类型的类型信息。</p>
<p>Flink 很可能会抛出一个类似下面的异常。</p>
<pre><code>org.apache.flink.api.common.functions.InvalidTypesException: The generic type parameters of 'Collector' are missing.
    In many cases lambda methods don't provide enough information for automatic type extraction when Java generics are involved.
    An easy workaround is to use an (anonymous) class instead that implements the 'org.apache.flink.api.common.functions.FlatMapFunction' interface.
    Otherwise the type has to be specified explicitly using type information.
</code></pre><p>在这种情况下，需要明确指定类型信息，否则输出将被视为类型为 Object，导致序列化效率低下。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.Types</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.java.DataSet</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.util.Collector</span><span class="o">;</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">);</span>

<span class="c1">// collector type must be declared
</span><span class="c1"></span><span class="n">input</span><span class="o">.</span><span class="na">flatMap</span><span class="o">((</span><span class="n">Integer</span> <span class="n">number</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
    <span class="n">StringBuilder</span> <span class="n">builder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringBuilder</span><span class="o">();</span>
    <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">number</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
        <span class="n">builder</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">);</span>
        <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">builder</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
    <span class="o">}</span>
<span class="o">})</span>
<span class="c1">// provide type information explicitly
</span><span class="c1"></span><span class="o">.</span><span class="na">returns</span><span class="o">(</span><span class="n">Types</span><span class="o">.</span><span class="na">STRING</span><span class="o">)</span>
<span class="c1">// prints &#34;a&#34;, &#34;a&#34;, &#34;aa&#34;, &#34;a&#34;, &#34;aa&#34;, &#34;aaa&#34;
</span><span class="c1"></span><span class="o">.</span><span class="na">print</span><span class="o">();</span>
</code></pre></div><p>当使用具有通用返回类型的 <code>map()</code> 函数时，也会出现类似的问题。在下面的例子中，一个方法签名 <code>Tuple2&lt;Integer, Integer&gt; map(Integer value)</code> 被擦除为 <code>Tuple2 map(Integer value)</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.functions.MapFunction</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.java.tuple.Tuple2</span><span class="o">;</span>

<span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span><span class="o">))</span>    <span class="c1">// no information about fields of Tuple2
</span><span class="c1"></span>    <span class="o">.</span><span class="na">print</span><span class="o">();</span>
</code></pre></div><p>一般来说，这些问题可以通过多种方式解决。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.Types</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.java.tuple.Tuple2</span><span class="o">;</span>

<span class="c1">// use the explicit &#34;.returns(...)&#34;
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span><span class="o">))</span>
    <span class="o">.</span><span class="na">returns</span><span class="o">(</span><span class="n">Types</span><span class="o">.</span><span class="na">TUPLE</span><span class="o">(</span><span class="n">Types</span><span class="o">.</span><span class="na">INT</span><span class="o">,</span> <span class="n">Types</span><span class="o">.</span><span class="na">INT</span><span class="o">))</span>
    <span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="c1">// use a class instead
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MyTuple2Mapper</span><span class="o">())</span>
    <span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyTuple2Mapper</span> <span class="kd">extends</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="n">Integer</span> <span class="n">i</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// use an anonymous class instead
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>
        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="nf">map</span><span class="o">(</span><span class="n">Integer</span> <span class="n">i</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">})</span>
    <span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="c1">// or in this example use a tuple subclass instead
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">2</span><span class="o">,</span> <span class="n">3</span><span class="o">)</span>
    <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="k">new</span> <span class="n">DoubleTuple</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span><span class="o">))</span>
    <span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">DoubleTuple</span> <span class="kd">extends</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="nf">DoubleTuple</span><span class="o">(</span><span class="kt">int</span> <span class="n">f0</span><span class="o">,</span> <span class="kt">int</span> <span class="n">f1</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">f0</span> <span class="o">=</span> <span class="n">f0</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">f1</span> <span class="o">=</span> <span class="n">f1</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/java_lambdas.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/java_lambdas.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Joining]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-asynchronous-io-for-external-data-access/?utm_source=atom_feed" rel="related" type="text/html" title="用于外部数据访问的异步 I/O" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-windows/?utm_source=atom_feed" rel="related" type="text/html" title="窗口" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-joining/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Joining</blockquote><h1 id="窗口连接join">窗口连接(Join)</h1>
<p>窗口连接(window join)将两个流的元素连接起来，这两个流有一个共同的键，并且位于同一个窗口中。这些窗口可以通过使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-assigners">窗口分配器</a>来定义，并对两个流的元素进行评估。</p>
<p>然后，来自双方的元素被传递到一个用户定义的 JoinFunction 或 FlatJoinFunction 中，用户可以发出符合加入标准的结果。</p>
<p>一般的用法可以归纳为以下几点。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">otherStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(&lt;</span><span class="nc">KeySelector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">equalTo</span><span class="o">(&lt;</span><span class="nc">KeySelector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="nc">WindowAssigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">apply</span><span class="o">(&lt;</span><span class="nc">JoinFunction</span><span class="o">&gt;)</span>
</code></pre></div><p>关于语义的一些说明:</p>
<ul>
<li>两个流中元素的成对组合的创建就像一个内部连接，这意味着一个流中的元素如果没有另一个流中的相应元素与之连接，就不会发出。</li>
<li>那些被加入的元素将以各自窗口中最大的时间戳作为它们的时间戳。例如，一个以 <code>[5, 10)</code> 为边界的窗口将导致加入的元素以9作为它们的时间戳。</li>
</ul>
<p>在下面的章节中，我们将使用一些示例性的场景来概述不同类型的窗口连接是如何进行的。</p>
<h2 id="滚动窗口连接">滚动窗口连接</h2>
<p>当执行滚动窗口连接时，所有具有共同的键和共同的滚动窗口的元素都会以成对组合的方式进行连接，并传递给 <code>JoinFunction</code> 或 <code>FlatJoinFunction</code>。因为这表现得像一个内连接，所以一个流的元素如果在其滚动窗口中没有来自另一个流的元素，就不会被发出去！这就是为什么我们要把一个流的元素加入到滚动窗口中。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tumbling-window-join.svg" alt="img"></p>
<p>如图所示，我们定义了一个大小为2毫秒的滚动窗口，其结果是 <code>[0,1]</code>，<code>[2,3]</code>，&hellip;形式的窗口。图中显示了每个窗口中所有元素的配对组合，这些元素将被传递给 <code>JoinFunction</code>。请注意，在翻滚窗口 <code>[6,7]</code> 中，没有任何元素发出，因为绿色流中没有元素存在，要与橙色元素⑥和⑦连接。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span><span class="o">;</span>

<span class="o">...</span>

<span class="k">val</span> <span class="n">orangeStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">greenStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">orangeStream</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">greenStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">equalTo</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(</span><span class="mi">2</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="o">(</span><span class="n">e1</span><span class="o">,</span> <span class="n">e2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">e1</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span> <span class="n">e2</span> <span class="o">}</span>
</code></pre></div><h2 id="滑动窗连接">滑动窗连接</h2>
<p>在执行滑动窗口连接时，所有具有共同键和共同滑动窗口的元素都会以成对组合的方式连接，并传递给 <code>JoinFunction</code> 或 <code>FlatJoinFunction</code>。一个流的元素如果在当前的滑动窗口中没有来自另一个流的元素，则不会被发出! 请注意，有些元素可能在一个滑动窗口中被加入，但在另一个滑动窗口中却没有!</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/sliding-window-join.svg" alt="img"></p>
<p>在这个例子中，我们使用的是大小为两毫秒的滑动窗口，并将它们滑动一毫秒，结果是滑动窗口 <code>[-1，0]，[0，1]，[1，2]，[2，3]</code>，&hellip;。x轴下面的加入元素就是每个滑动窗口传递给 <code>JoinFunction</code> 的元素。这里你也可以看到，例如橙色的②与绿色的③在窗口 <code>[2,3]</code> 中连接，但与窗口 <code>[1,2]</code> 中的任何元素都没有连接。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span><span class="o">;</span>

<span class="o">...</span>

<span class="k">val</span> <span class="n">orangeStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">greenStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">orangeStream</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">greenStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">equalTo</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">SlidingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="cm">/* size */</span><span class="o">,</span> <span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="cm">/* slide */</span><span class="o">))</span>
    <span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="o">(</span><span class="n">e1</span><span class="o">,</span> <span class="n">e2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">e1</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span> <span class="n">e2</span> <span class="o">}</span>
</code></pre></div><h2 id="会议窗口连接">会议窗口连接</h2>
<p>当执行会话窗口连接时，所有具有相同键的元素，当&quot;组合&quot;满足会话标准时，将以成对组合的方式连接，并传递给 <code>JoinFunction</code> 或 <code>FlatJoinFunction</code>。同样，这也是执行内部连接，所以如果有一个会话窗口只包含来自一个流的元素，就不会有输出。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/session-window-join.svg" alt="img"></p>
<p>在这里，我们定义了一个会话窗口加入，其中每个会话被至少1ms的间隙所分割。有三个会话，在前两个会话中，两个流中的加入元素都会传递给 <code>JoinFunction</code>。在第三个会话中，绿色流中没有元素，所以⑧和⑨没有加入！在第三个会话中，绿色流中没有元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.assigners.EventTimeSessionWindows</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span><span class="o">;</span>
 
<span class="o">...</span>

<span class="k">val</span> <span class="n">orangeStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">greenStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">orangeStream</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">greenStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">equalTo</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">EventTimeSessionWindows</span><span class="o">.</span><span class="n">withGap</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(</span><span class="mi">1</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="o">(</span><span class="n">e1</span><span class="o">,</span> <span class="n">e2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">e1</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span> <span class="n">e2</span> <span class="o">}</span>
</code></pre></div><h2 id="间隔连接">间隔连接</h2>
<p>间隔连接将两个流的元素（我们暂且称它们为A和B）用一个共同的键连接起来，流B中的元素的时间戳与流A中元素的时间戳处于一个相对的时间间隔。</p>
<p>这也可以更正式地表达为 <code>b.timestamp∈[a.timestamp + lowerBound; a.timestamp + upperBound]</code> 或 <code>a.timestamp + lowerBound &lt;= b.timestamp &lt;= a.timestamp + upperBound</code>。</p>
<p>其中a和b是A和B的元素，它们有一个共同的键。下界和上界都可以是负的或正的，只要下界总是小于或等于上界。区间连接目前只执行内连接。</p>
<p>当一对元素传递给 <code>ProcessJoinFunction</code> 时，它们将被分配为两个元素中较大的时间戳（可以通过 <code>ProcessJoinFunction.Context</code> 访问）。</p>
<p>注意：间隔连接目前只支持事件时间。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/interval-join.svg" alt="img"></p>
<p>在上面的例子中，我们将两个流&quot;橙色&quot;和&quot;绿色&quot;连接起来，下界为-2毫秒，上界为+1毫秒。默认情况下，这些边界是包容的，但可以应用 <code>.lowerBoundExclusive()</code> 和 <code>.upperBoundExclusive</code> 来改变行为。</p>
<p>再次使用更正式的符号，这将被翻译为:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">orangeElem</span><span class="o">.</span><span class="n">ts</span> <span class="o">+</span> <span class="n">lowerBound</span> <span class="o">&lt;=</span> <span class="n">greenElem</span><span class="o">.</span><span class="n">ts</span> <span class="o">&lt;=</span> <span class="n">orangeElem</span><span class="o">.</span><span class="n">ts</span> <span class="o">+</span> <span class="n">upperBound</span>
</code></pre></div><p>as indicated by the triangles.</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.functions.co.ProcessJoinFunction</span><span class="o">;</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span><span class="o">;</span>

<span class="o">...</span>

<span class="k">val</span> <span class="n">orangeStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">greenStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">orangeStream</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">)</span>
    <span class="o">.</span><span class="n">intervalJoin</span><span class="o">(</span><span class="n">greenStream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="n">elem</span> <span class="k">=&gt;</span> <span class="cm">/* select key */</span><span class="o">))</span>
    <span class="o">.</span><span class="n">between</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(-</span><span class="mi">2</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProcessJoinFunction</span><span class="o">[</span><span class="kt">Integer</span>, <span class="kt">Integer</span>, <span class="kt">String</span><span class="o">]</span> <span class="o">{</span>
        <span class="k">override</span> <span class="k">def</span> <span class="n">processElement</span><span class="o">(</span><span class="n">left</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">right</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">ctx</span><span class="k">:</span> <span class="kt">ProcessJoinFunction</span><span class="o">[</span><span class="kt">Integer</span>, <span class="kt">Integer</span>, <span class="kt">String</span><span class="o">]</span><span class="k">#</span><span class="nc">Context</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
         <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">left</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span> <span class="n">right</span><span class="o">);</span> 
        <span class="o">}</span>
      <span class="o">});</span>
    <span class="o">});</span>
</code></pre></div><p>原文连接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/joining.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/joining.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/operators" term="operators" label="Operators" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/joining" term="joining" label="Joining" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Operators]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/?utm_source=atom_feed" rel="related" type="text/html" title="可查询状态" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-operators/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Operators</blockquote><h2 id="操作符">操作符</h2>
<p>操作符将一个或多个 DataStream 转换为一个新的 DataStream。程序可以将多个变换组合成复杂的数据流拓扑。</p>
<p>本节给出了基本变换的描述，应用这些变换后的有效物理分区，以及对 Flink 的操作符链的见解。</p>
<h2 id="datastream-转换">DataStream 转换</h2>
<ul>
<li>Map</li>
</ul>
<p>DataStream → DataStream</p>
<p>接受一个元素并产生一个元素。一个将输入流的值翻倍的 <code>map</code> 函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">}</span>
</code></pre></div><ul>
<li>FlatMap</li>
</ul>
<p>DataStream → DataStream</p>
<p>接受一个元素并产生零个、一个或多个元素。一个将句子分割成单词的 <code>flatMap</code> 函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="n">str</span> <span class="k">=&gt;</span> <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Filter</li>
</ul>
<p>DataStream → DataStream</p>
<p>评估每个元素的布尔函数，并保留那些函数返回值为真的元素。一个过滤掉零值的 <code>filter</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span> <span class="o">!=</span> <span class="mi">0</span> <span class="o">}</span>
</code></pre></div><ul>
<li>KeyBy</li>
</ul>
<p>DataStream → KeyedStream</p>
<p>在逻辑上将一个流划分为互斥的分区，每个分区包含相同键的元素。在内部，这是通过哈希分区实现的。关于如何指定键，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#keyed-state">keys</a>。这个转换会返回一个 <code>KeyedStream</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&#34;someKey&#34;</span><span class="o">)</span> <span class="c1">// Key by field &#34;someKey&#34;
</span><span class="c1"></span><span class="n">dataStream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>         <span class="c1">// Key by the first element of a Tuple
</span></code></pre></div><ul>
<li>Reduce</li>
</ul>
<p>KeyedStream → DataStream</p>
<p>在 keyed 数据流上进行&quot;滚动&quot;换算(reduce)。将当前元素与最后一个换算的值合并，并发出新的值。</p>
<p>一个创建部分和(sum)流的 <code>reduce</code> 函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyedStream</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Fold</li>
</ul>
<p>KeyedStream → DataStream</p>
<p>在一个带有初始值的 keyed 数据流上进行&quot;滚动&quot;折叠。将当前元素与最后一个折叠的值结合起来，并发出新的值。</p>
<p>一个折叠函数，当应用于序列(1,2,3,4,5)时，发出序列 &ldquo;start-1&rdquo;、&ldquo;start-1-2&rdquo;、&ldquo;start-1-2-3&rdquo;、&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span>
    <span class="n">keyedStream</span><span class="o">.</span><span class="n">fold</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">)((</span><span class="n">str</span><span class="o">,</span> <span class="n">i</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span> <span class="n">str</span> <span class="o">+</span> <span class="s">&#34;-&#34;</span> <span class="o">+</span> <span class="n">i</span> <span class="o">})</span>
</code></pre></div><ul>
<li>Aggregations</li>
</ul>
<p>KeyedStream → DataStream</p>
<p>在 keyed 数据流上进行滚动聚合。<code>min</code> 和 <code>minBy</code> 的区别在于 <code>min</code> 返回最小值，而 <code>minBy</code> 则返回该字段中具有最小值的元素（<code>max</code> 和 <code>maxBy</code> 也一样）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyedStream</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">keyedStream</span><span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Window</li>
</ul>
<p>KeyedStream → WindowedStream</p>
<p>可以在已经分区的 <code>KeyedStream</code> 上定义 <code>Window</code>。窗口根据一些特征（例如，最近5秒内到达的数据）对每个键中的数据进行分组。关于窗口的描述，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span> <span class="c1">// Last 5 seconds of data
</span></code></pre></div><ul>
<li>WindowAll</li>
</ul>
<p>DataStream → AllWindowedStream</p>
<p>可以在常规的 DataStream 上定义窗口。窗口根据一些特征（例如，在过去5秒内到达的数据）对所有流事件进行分组。关于窗口的完整描述，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>。</p>
<p>警告：在许多情况下，这是一个非并行的转换。所有的记录将被收集在 <code>windowAll</code> 操作符的一个任务(task)中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">windowAll</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span> <span class="c1">// Last 5 seconds of data
</span></code></pre></div><ul>
<li>Window Apply</li>
</ul>
<p>WindowedStream → DataStream</p>
<p>AllWindowedStream → DataStream</p>
<p>将一般函数应用于整个窗口。下面是一个手动求和窗口元素的函数。</p>
<p>注意：如果您使用的是 <code>windowAll</code> 转换，您需要使用 <code>AllWindowFunction</code> 来代替。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">windowedStream</span><span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="nc">WindowFunction</span> <span class="o">}</span>

<span class="c1">// applying an AllWindowFunction on non-keyed window stream
</span><span class="c1"></span><span class="n">allWindowedStream</span><span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="nc">AllWindowFunction</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Window Reduce</li>
</ul>
<p>WindowedStream → DataStream</p>
<p>对窗口应用函数式的 <code>reduce </code> 函数，并返回换算后的值:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">windowedStream</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Window Fold</li>
</ul>
<p>WindowedStream → DataStream</p>
<p>对窗口应用功能 <code>fold</code> 函数并返回折叠后的值。示例函数应用于序列 <code>(1,2,3,4,5)</code> 时，将序列折叠成字符串 &ldquo;start-1-2-3-4-5&rdquo;:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span>
    <span class="n">windowedStream</span><span class="o">.</span><span class="n">fold</span><span class="o">(</span><span class="s">&#34;start&#34;</span><span class="o">,</span> <span class="o">(</span><span class="n">str</span><span class="o">,</span> <span class="n">i</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span> <span class="n">str</span> <span class="o">+</span> <span class="s">&#34;-&#34;</span> <span class="o">+</span> <span class="n">i</span> <span class="o">})</span>
</code></pre></div><ul>
<li>窗口上的聚合</li>
</ul>
<p>WindowedStream → DataStream</p>
<p>聚合一个窗口的内容。<code>min</code> 和 <code>minBy</code> 的区别在于 <code>min</code> 返回最小值，而 <code>minBy</code> 返回在该字段中具有最小值的元素（<code>max</code> 和 <code>maxBy</code> 相同）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">windowedStream</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="n">windowedStream</span><span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Union</li>
</ul>
<p>DataStream* → DataStream</p>
<p>联合两个或多个数据流，创建一个新的流，包含所有流的所有元素。注意：如果你把一个数据流和它自己联合起来，你将在生成的数据流中得到每个元素两次。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">otherStream1</span><span class="o">,</span> <span class="n">otherStream2</span><span class="o">,</span> <span class="o">...)</span>
</code></pre></div><ul>
<li>Window Join</li>
</ul>
<p>DataStream,DataStream → DataStream</p>
<p>在一个给定的键和一个公共窗口上连接(join)两个数据流。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">otherStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;).</span><span class="n">equalTo</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">apply</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
</code></pre></div><ul>
<li>Window CoGroup</li>
</ul>
<p>DataStream,DataStream → DataStream</p>
<p>在一个给定的键和一个共同的窗口上将两个数据流串联(Cogroups)起来。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">coGroup</span><span class="o">(</span><span class="n">otherStream</span><span class="o">)</span>
    <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">apply</span> <span class="o">{}</span>
</code></pre></div><ul>
<li>Connect</li>
</ul>
<p>DataStream,DataStream → ConnectedStreams</p>
<p>&ldquo;连接&rdquo;(connect)两个数据流，保留其类型，允许两个数据流之间共享状态。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">someStream</span> <span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">otherStream</span> <span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">connectedStreams</span> <span class="k">=</span> <span class="n">someStream</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="n">otherStream</span><span class="o">)</span>
</code></pre></div><ul>
<li>CoMap, CoFlatMap</li>
</ul>
<p>ConnectedStreams → DataStream</p>
<p>类似于连接(connected)数据流上的 <code>map</code> 和 <code>flatMap</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">connectedStreams</span><span class="o">.</span><span class="n">map</span><span class="o">(</span>
    <span class="o">(</span><span class="k">_</span> <span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="kc">true</span><span class="o">,</span>
    <span class="o">(</span><span class="k">_</span> <span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="kc">false</span>
<span class="o">)</span>
<span class="n">connectedStreams</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span>
    <span class="o">(</span><span class="k">_</span> <span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="kc">true</span><span class="o">,</span>
    <span class="o">(</span><span class="k">_</span> <span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="kc">false</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>Split</li>
</ul>
<p>DataStream → SplitStream</p>
<p>根据某种标准，将流分成两个或多个流。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">split</span> <span class="k">=</span> <span class="n">someDataStream</span><span class="o">.</span><span class="n">split</span><span class="o">(</span>
  <span class="o">(</span><span class="n">num</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="o">(</span><span class="n">num</span> <span class="o">%</span> <span class="mi">2</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
      <span class="k">case</span> <span class="mi">0</span> <span class="k">=&gt;</span> <span class="nc">List</span><span class="o">(</span><span class="s">&#34;even&#34;</span><span class="o">)</span>
      <span class="k">case</span> <span class="mi">1</span> <span class="k">=&gt;</span> <span class="nc">List</span><span class="o">(</span><span class="s">&#34;odd&#34;</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>Select</li>
</ul>
<p>SplitStream → DataStream</p>
<p>从分割流中选择一个或多个流。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">even</span> <span class="k">=</span> <span class="n">split</span> <span class="n">select</span> <span class="s">&#34;even&#34;</span>
<span class="k">val</span> <span class="n">odd</span> <span class="k">=</span> <span class="n">split</span> <span class="n">select</span> <span class="s">&#34;odd&#34;</span>
<span class="k">val</span> <span class="n">all</span> <span class="k">=</span> <span class="n">split</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&#34;even&#34;</span><span class="o">,</span><span class="s">&#34;odd&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Iterate</li>
</ul>
<p>DataStream → IterativeStream → DataStream</p>
<p>在流(flow)中创建一个&quot;反馈&quot;循环，将一个操作符的输出重定向到之前的某个操作符。这对于定义持续更新模型的算法特别有用。下面的代码从一个流(stream)开始，连续应用迭代体。大于0的元素被送回反馈通道，其余元素被转发到下游。参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#iterations">迭代</a>的完整描述。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">initialStream</span><span class="o">.</span><span class="n">iterate</span> <span class="o">{</span>
  <span class="n">iteration</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iterationBody</span> <span class="k">=</span> <span class="n">iteration</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span><span class="cm">/*do something*/</span><span class="o">}</span>
    <span class="o">(</span><span class="n">iterationBody</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">),</span> <span class="n">iterationBody</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">))</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>通过匿名模式匹配从 tuple、case 类和集合中提取，比如下面:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">temperature</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><p>不受 API 开箱即用的支持。要使用这个功能，你应该使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/scala_api_extensions.html">Scala API 扩展</a>。</p>
<p>以下转换可用于 Tuples 的数据流:</p>
<ul>
<li>Project</li>
</ul>
<p>DataStream → DataStream</p>
<p>从元组中选择一个字段的子集。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Double</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">in</span> <span class="o">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">project</span><span class="o">(</span><span class="n">2</span><span class="o">,</span><span class="n">0</span><span class="o">);</span>
</code></pre></div><h2 id="物理分区">物理分区</h2>
<p>Flink 还可以通过以下函数对转换后的准确流分区进行低级控制（如果需要）。</p>
<ul>
<li>自定义分区</li>
</ul>
<p>DataStream → DataStream</p>
<p>使用用户定义的 Partitioner 为每个元素选择目标任务。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">partitionCustom</span><span class="o">(</span><span class="n">partitioner</span><span class="o">,</span> <span class="s">&#34;someKey&#34;</span><span class="o">)</span>
<span class="n">dataStream</span><span class="o">.</span><span class="n">partitionCustom</span><span class="o">(</span><span class="n">partitioner</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span>
</code></pre></div><ul>
<li>随机分区</li>
</ul>
<p>DataStream → DataStream</p>
<p>将元素按照均匀分布随机分区。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">shuffle</span><span class="o">()</span>
</code></pre></div><ul>
<li>Rebalancing (循环分区)</li>
</ul>
<p>DataStream → DataStream</p>
<p>对元素进行循环分区，使每个分区的负载相等。在数据倾斜的情况下，对性能优化很有用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">rebalance</span><span class="o">()</span>
</code></pre></div><ul>
<li>Rescaling</li>
</ul>
<p>DataStream → DataStream</p>
<p>将元素，轮回分区到下游操作的子集。如果你想拥有管道，例如，从源的每个并行实例向几个映射器(mappers)的子集扇出，以分配负载，但又不想进行 <code>rebalance()</code> 会引起的完全再平衡，那么这就很有用。这将只需要本地数据传输，而不是通过网络传输数据，这取决于其他配置值，如 TaskManagers 的槽数(slots)。</p>
<p>上游操作向其发送元素的下游操作子集取决于上游和下游操作的并行程度。例如，如果上游操作的并行度为2，下游操作的并行度为4，那么一个上游操作将向两个下游操作分发元素，而另一个上游操作将向另外两个下游操作分发。另一方面，如果下游操作具有并行度2，而上游操作具有并行度4，那么两个上游操作将分配给一个下游操作，而其他两个上游操作将分配给其他下游操作。</p>
<p>在不同的并行度不是彼此的倍数的情况下，一个或几个下游操作将从上游操作中获得不同数量的输入。</p>
<p>请看此图，可以直观地看到上例中的连接(connection)模式。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/rescale.svg" alt="img"></p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">rescale</span><span class="o">()</span>
</code></pre></div><ul>
<li>Broadcasting</li>
</ul>
<p>DataStream → DataStream</p>
<p>将元素广播到每个分区。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">dataStream</span><span class="o">.</span><span class="n">broadcast</span><span class="o">()</span>
</code></pre></div><h2 id="任务链和资源组">任务链和资源组</h2>
<p>链式的两个后续变换意味着将它们共同放置在同一个线程中以获得更好的性能。如果可能的话，Flink 默认会将操作符链起来（例如，两个后续的 map 变换）。如果需要的话，API 提供了对链式操作的精细控制。</p>
<p>如果你想在整个作业(job)中禁用链，请使用 <code>StreamExecutionEnvironment.disableOperatorChaining()</code>。对于更细粒度的控制，以下函数是可用的。请注意，这些函数只能在 DataStream 转换之后使用，因为它们引用了之前的转换。例如，你可以使用 <code>someStream.map(...).startNewChain()</code>，但你不能使用 <code>someStream.startNewChain()</code>。</p>
<p>资源组是 Flink 中的一个槽，参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/config.html#configuring-taskmanager-processing-slots">slots</a>。如果需要，你可以在单独的槽中手动隔离操作符。</p>
<ul>
<li>Start new chain</li>
</ul>
<p>开始一个新的链，从这个操作符开始。两个映射器(mappers)将被连锁，<code>filter</code> 将不会被连锁到第一个映射器(mapper)。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">someStream</span><span class="o">.</span><span class="n">filter</span><span class="o">(...).</span><span class="n">map</span><span class="o">(...).</span><span class="n">startNewChain</span><span class="o">().</span><span class="n">map</span><span class="o">(...)</span>
</code></pre></div><ul>
<li>Disable chaining</li>
</ul>
<p>不将 <code>map</code> 运算符连锁化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">someStream</span><span class="o">.</span><span class="n">map</span><span class="o">(...).</span><span class="n">disableChaining</span><span class="o">()</span>
</code></pre></div><ul>
<li>Set slot sharing group</li>
</ul>
<p>设置操作的槽位共享组。Flink 会将具有相同槽位共享组的操作放入同一个槽位，而将没有槽位共享组的操作保留在其他槽位。这可以用来隔离槽位。如果所有的输入操作都在同一个槽共享组中，槽共享组就会从输入操作中继承。缺省槽共享组的名称是 &ldquo;default&rdquo;，操作可以通过调用 <code>slotSharingGroup(&quot;default&quot;)</code> 来明确地放入这个组。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">someStream</span><span class="o">.</span><span class="n">filter</span><span class="o">(...).</span><span class="n">slotSharingGroup</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/operator" term="operator" label="Operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Process Function]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-process-function/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-process-function/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Process Function</blockquote><h2 id="processfunction">ProcessFunction</h2>
<p><code>ProcessFunction</code> 是一种低级的流处理操作，可以访问所有（非循环）流应用的基本构件。</p>
<ul>
<li>事件（流元素）</li>
<li>状态（容错，一致，只在 keyed 流上）。</li>
<li>定时器(事件时间和处理时间，仅在 keyed 流上)</li>
</ul>
<p><code>ProcessFunction</code> 可以被认为是一个 <code>FlatMapFunction</code>，它可以访问 keyed 状态和定时器。它通过对输入流中收到的每个事件进行调用来处理事件。</p>
<p>对于容错状态，<code>ProcessFunction</code> 提供了对 Flink 的 keyed 状态的访问，通过 <code>RuntimeContext</code> 访问，类似于其他有状态函数访问 keyed 状态的方式。</p>
<p>定时器允许应用程序对处理时间和事件时间的变化做出反应。每次调用函数 <code>processElement(...)</code> 都会得到一个 <code>Context</code> 对象，它可以访问元素的事件时间时间戳，以及 <code>TimerService</code>。<code>TimerService</code> 可以用来为未来的事件/处理时间实例注册回调。对于事件时间定时器，当当前水印提前到或超过定时器的时间戳时，就会调用 <code>onTimer(...)</code> 方法；而对于处理时间定时器，当挂钟时间达到指定时间时，就会调用 <code>onTimer(...)</code>。在该调用过程中，所有的状态又会被限定在创建定时器的键上，允许定时器对 keyed 状态进行操作。</p>
<p>注意：如果你想访问 keyed 状态和定时器，你必须在 keyed 流上应用 <code>ProcessFunction</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(...).</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyProcessFunction</span><span class="o">())</span>
</code></pre></div><h2 id="低级连接join">低级连接(join)</h2>
<p>为了实现对两个输入的低级操作，应用程序可以使用 <code>CoProcessFunction</code> 或 <code>KeyedCoProcessFunction</code>。该函数与两个不同的输入绑定，并从两个不同的输入中获取对 <code>processElement1(...)</code> 和 <code>processElement2(...)</code> 记录的单独调用。</p>
<p>实现低级联接(join)通常遵循这种模式。</p>
<ul>
<li>为一个输入（或两个输入）创建一个状态对象。</li>
<li>从其输入中接收到元素时更新状态</li>
<li>在接收到另一个输入的元素后，探测状态并产生加入的结果。</li>
</ul>
<p>例如，您可能会将客户数据加入到金融交易中，同时为客户数据保留状态。如果你关心在面对失序事件时是否有完整的、确定性的加入，你可以使用一个定时器，当客户数据流的水印已经超过该交易的时间时，你可以为该交易评估并发出加入。</p>
<h2 id="例子">例子</h2>
<p>在下面的例子中，<code>KeyedProcessFunction</code> 维护每个键的计数，并且每当一分钟过去（以事件时间为单位），该键没有更新时，就会发出一个键/计数对。</p>
<ul>
<li>计数、键和最后修改时间戳都存储在一个 <code>ValueState</code> 中，这个 <code>ValueState</code> 隐式地被键所限定。</li>
<li>对于每条记录，<code>KeyedProcessFunction</code> 都会递增计数器并设置最后修改时间戳。</li>
<li>该函数还将在未来一分钟内（以事件时间为单位）安排一次回调。</li>
<li>在每次回调时，它都会将回调的事件时间戳与存储的计数的最后修改时间进行核对，如果两者匹配（即在该分钟内没有进一步的更新发生），则发出 <code>key/count</code>。</li>
</ul>
<p>注意: 这个简单的例子可以用会话窗口来实现。我们在这里使用 <code>KeyedProcessFunction</code> 来说明它提供的基本模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.ValueState</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.ValueStateDescriptor</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.tuple.Tuple</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.functions.KeyedProcessFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.util.Collector</span>

<span class="c1">// the source data stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Tuple2</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// apply the process function onto a keyed stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Tuple2</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">]]</span> <span class="k">=</span> <span class="n">stream</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">CountWithTimeoutFunction</span><span class="o">())</span>

<span class="cm">/**
</span><span class="cm">  * The data type stored in the state
</span><span class="cm">  */</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">CountWithTimestamp</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">lastModified</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>

<span class="cm">/**
</span><span class="cm">  * The implementation of the ProcessFunction that maintains the count and timeouts
</span><span class="cm">  */</span>
<span class="k">class</span> <span class="nc">CountWithTimeoutFunction</span> <span class="k">extends</span> <span class="nc">KeyedProcessFunction</span><span class="o">[</span><span class="kt">Tuple</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="o">{</span>

  <span class="cm">/** The state that is maintained by this process function */</span>
  <span class="k">lazy</span> <span class="k">val</span> <span class="n">state</span><span class="k">:</span> <span class="kt">ValueState</span><span class="o">[</span><span class="kt">CountWithTimestamp</span><span class="o">]</span> <span class="k">=</span> <span class="n">getRuntimeContext</span>
    <span class="o">.</span><span class="n">getState</span><span class="o">(</span><span class="k">new</span> <span class="nc">ValueStateDescriptor</span><span class="o">[</span><span class="kt">CountWithTimestamp</span><span class="o">](</span><span class="s">&#34;myState&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">CountWithTimestamp</span><span class="o">]))</span>


  <span class="k">override</span> <span class="k">def</span> <span class="n">processElement</span><span class="o">(</span>
      <span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">String</span><span class="o">),</span> 
      <span class="n">ctx</span><span class="k">:</span> <span class="kt">KeyedProcessFunction</span><span class="o">[</span><span class="kt">Tuple</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span><span class="k">#</span><span class="nc">Context</span><span class="o">,</span> 
      <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

    <span class="c1">// initialize or retrieve/update the state
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">current</span><span class="k">:</span> <span class="kt">CountWithTimestamp</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">value</span> <span class="k">match</span> <span class="o">{</span>
      <span class="k">case</span> <span class="kc">null</span> <span class="k">=&gt;</span>
        <span class="nc">CountWithTimestamp</span><span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="n">ctx</span><span class="o">.</span><span class="n">timestamp</span><span class="o">)</span>
      <span class="k">case</span> <span class="nc">CountWithTimestamp</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">count</span><span class="o">,</span> <span class="n">lastModified</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="nc">CountWithTimestamp</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="o">,</span> <span class="n">ctx</span><span class="o">.</span><span class="n">timestamp</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="c1">// write the state back
</span><span class="c1"></span>    <span class="n">state</span><span class="o">.</span><span class="n">update</span><span class="o">(</span><span class="n">current</span><span class="o">)</span>

    <span class="c1">// schedule the next timer 60 seconds from the current event time
</span><span class="c1"></span>    <span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">registerEventTimeTimer</span><span class="o">(</span><span class="n">current</span><span class="o">.</span><span class="n">lastModified</span> <span class="o">+</span> <span class="mi">60000</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">onTimer</span><span class="o">(</span>
      <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> 
      <span class="n">ctx</span><span class="k">:</span> <span class="kt">KeyedProcessFunction</span><span class="o">[</span><span class="kt">Tuple</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span><span class="k">#</span><span class="nc">OnTimerContext</span><span class="o">,</span> 
      <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

    <span class="n">state</span><span class="o">.</span><span class="n">value</span> <span class="k">match</span> <span class="o">{</span>
      <span class="k">case</span> <span class="nc">CountWithTimestamp</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">count</span><span class="o">,</span> <span class="n">lastModified</span><span class="o">)</span> <span class="k">if</span> <span class="o">(</span><span class="n">timestamp</span> <span class="o">==</span> <span class="n">lastModified</span> <span class="o">+</span> <span class="mi">60000</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">key</span><span class="o">,</span> <span class="n">count</span><span class="o">))</span>
      <span class="k">case</span> <span class="k">_</span> <span class="k">=&gt;</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>注意：在 Flink 1.4.0 之前，当从处理时间计时器调用时，<code>ProcessFunction.onTimer()</code> 方法将当前处理时间设置为事件时间戳。这种行为非常微妙，可能不会被用户发现。嗯，这是有害的，因为处理时间时间戳是不确定的，而且不与水印对齐。此外，用户实现的逻辑依赖于这个错误的时间戳极有可能是无意中的错误。所以我们决定修复它。升级到 1.4.0 后，使用这个错误的事件时间时间戳的 Flink 作业将失败，用户应该将他们的作业调整为正确的逻辑。</p>
<h2 id="keyedprocessfunction">KeyedProcessFunction</h2>
<p><code>KeyedProcessFunction</code> 作为 <code>ProcessFunction</code> 的扩展，在其 <code>onTimer(...)</code> 方法中提供了对定时器键的访问。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">override</span> <span class="k">def</span> <span class="n">onTimer</span><span class="o">(</span><span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">ctx</span><span class="k">:</span> <span class="kt">OnTimerContext</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">OUT</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">key</span> <span class="k">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">getCurrentKey</span>
  <span class="c1">// ...
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><h2 id="定时器">定时器</h2>
<p>两种类型的定时器（处理时间和事件时间）都由 <code>TimerService</code> 内部维护，并排队执行。</p>
<p><code>TimerService</code> 对每个键和时间戳的定时器进行重复复制，即每个键和时间戳最多只有一个定时器。如果同一个时间戳注册了多个定时器，<code>onTimer()</code> 方法将只被调用一次。</p>
<p>注意 Flink 同步调用 <code>onTimer()</code> 和 <code>processElement()</code>。因此，用户不必担心状态的并发修改。</p>
<h2 id="容错性">容错性</h2>
<p>定时器是容错的，并与应用程序的状态一起检查点。在故障恢复或从保存点启动应用程序时，定时器将被恢复。</p>
<p>注意: 在恢复之前应该启动的检查点处理时间定时器将立即启动。这可能发生在应用程序从故障中恢复或从保存点启动时。</p>
<p>注意: 定时器总是异步检查点，除了 RocksDB 后端/与增量快照/与基于堆的定时器的组合（将用FLINK-10026解决）。注意，大量的定时器会增加检查点时间，因为定时器是检查点状态的一部分。请参阅 &ldquo;定时器凝聚 &ldquo;部分，了解如何减少定时器数量的建议。</p>
<h2 id="定时器凝聚">定时器凝聚</h2>
<p>由于 Flink 对每个键和时间戳只维护一个定时器，您可以通过降低定时器分辨率来凝聚定时器的数量。</p>
<p>对于1秒的定时器分辨率（事件或处理时间），您可以将目标时间四舍五入到整秒。定时器最多会提前1秒发射，但不会晚于要求的毫秒精度。因此，每个键和秒最多有一个定时器。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">coalescedTime</span> <span class="k">=</span> <span class="o">((</span><span class="n">ctx</span><span class="o">.</span><span class="n">timestamp</span> <span class="o">+</span> <span class="n">timeout</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="o">)</span> <span class="o">*</span> <span class="mi">1000</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">registerProcessingTimeTimer</span><span class="o">(</span><span class="n">coalescedTime</span><span class="o">)</span>
</code></pre></div><p>由于事件时间定时器只在有水印出现时才会启动，你也可以通过使用当前的水印来安排和凝聚这些定时器与下一个水印。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">coalescedTime</span> <span class="k">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">currentWatermark</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">registerEventTimeTimer</span><span class="o">(</span><span class="n">coalescedTime</span><span class="o">)</span>
</code></pre></div><p>定时器也可以通过以下方式停止或删除。</p>
<p>停止一个处理时间的定时器。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">timestampOfTimerToStop</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">deleteProcessingTimeTimer</span><span class="o">(</span><span class="n">timestampOfTimerToStop</span><span class="o">)</span>
</code></pre></div><p>停止事件时间定时器。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">timestampOfTimerToStop</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">timerService</span><span class="o">.</span><span class="n">deleteEventTimeTimer</span><span class="o">(</span><span class="n">timestampOfTimerToStop</span><span class="o">)</span>
</code></pre></div><p>注意: 如果没有注册给定时间戳的定时器，停止定时器没有效果。</p>
<p>原文连接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Scala API 扩展]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/?utm_source=atom_feed" rel="related" type="text/html" title="可查询状态" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Scala API Extensions</blockquote><h2 id="scala-api-扩展">Scala API 扩展</h2>
<p>为了在 Scala 和 Java API 之间保持相当程度的一致性，一些允许在 Scala 中进行高级表达的功能被从标准 API 中省略了，包括批处理和流式处理。</p>
<p>如果你想享受完整的 Scala 体验，你可以选择加入通过隐式转换来增强 Scala API 的扩展。</p>
<p>要使用所有可用的扩展，您只需为 DataSet API 添加一个简单的导入即可。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.extensions._</span>
</code></pre></div><p>或者 DataStream API:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.extensions._</span>
</code></pre></div><p>另外，你也可以按顺序导入单个扩展，只使用你喜欢的扩展。</p>
<h2 id="接受部分函数">接受部分函数</h2>
<p>通常情况下，DataSet 和 DataStream API 都不接受匿名模式匹配函数来解构 tuple、case 类或集合，比如下面。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">temperature</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="c1">// [...]
</span><span class="c1"></span>  <span class="c1">// The previous line causes the following compilation error:
</span><span class="c1"></span>  <span class="c1">// &#34;The argument types of an anonymous function must be fully known. (SLS 8.5)&#34;
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><p>该扩展在 DataSet 和 DataStream Scala API 中引入了新的方法，这些方法在扩展的 API 中具有一对一的对应关系。这些代理方法确实支持匿名模式匹配函数。</p>
<h3 id="dataset-api">DataSet API</h3>
<ul>
<li>mapWith	方法和原来的 map (DataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">mapWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">value</span><span class="o">.</span><span class="n">toString</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>mapPartitionWith 方法和原来的	mapPartition (DataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">mapPartitionWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="n">head</span> <span class="o">#</span><span class="k">:</span><span class="kt">:</span> <span class="k">_</span> <span class="o">=&gt;</span> <span class="n">head</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>flatMapWith	方法和原来的 flatMap (DataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">flatMapWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">visitTimes</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">visitTimes</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">name</span> <span class="o">-&gt;</span> <span class="k">_</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>filterWith 方法和原来的	filter (DataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">filterWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="nc">Train</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">isOnTime</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">isOnTime</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>reduceWith 方法和原来的	reduce (DataSet, GroupedDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">reduceWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">((</span><span class="k">_</span><span class="o">,</span> <span class="n">amount1</span><span class="o">),</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">amount2</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="n">amount1</span> <span class="o">+</span> <span class="n">amount2</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>reduceGroupWith	方法和原来的 reduceGroup (GroupedDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">reduceGroupWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="n">id</span> <span class="o">#</span><span class="k">:</span><span class="kt">:</span> <span class="kt">value</span> <span class="k">#</span><span class="kt">::</span> <span class="k">_</span> <span class="o">=&gt;</span> <span class="n">id</span> <span class="o">-&gt;</span> <span class="n">value</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>groupingBy 方法和原来的	groupBy (DataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">groupingBy</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">id</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>sortGroupWith	方法和原来的 sortGroup (GroupedDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">grouped</span><span class="o">.</span><span class="n">sortGroupWith</span><span class="o">(</span><span class="nc">Order</span><span class="o">.</span><span class="nc">ASCENDING</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">case</span> <span class="nc">House</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">value</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>combineGroupWith 方法和原来的	combineGroup (GroupedDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">grouped</span><span class="o">.</span><span class="n">combineGroupWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="n">header</span> <span class="o">#</span><span class="k">:</span><span class="kt">:</span> <span class="kt">amounts</span> <span class="o">=&gt;</span> <span class="n">amounts</span><span class="o">.</span><span class="n">sum</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>projecting 方法和原来的	apply (JoinDataSet, CrossDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span>
  <span class="n">whereClause</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="n">pk</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">pk</span><span class="o">).</span>
  <span class="n">isEqualTo</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">fk</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">fk</span><span class="o">).</span>
  <span class="n">projecting</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">((</span><span class="n">pk</span><span class="o">,</span> <span class="n">tx</span><span class="o">),</span> <span class="o">(</span><span class="n">products</span><span class="o">,</span> <span class="n">fk</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="n">tx</span> <span class="o">-&gt;</span> <span class="n">products</span>
  <span class="o">}</span>

<span class="n">data1</span><span class="o">.</span><span class="n">cross</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="n">projecting</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="k">_</span><span class="o">),</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span> <span class="o">-&gt;</span> <span class="n">b</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>projecting 方法和原来的	apply (CoGroupDataSet)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data1</span><span class="o">.</span><span class="n">coGroup</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span>
  <span class="n">whereClause</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="n">pk</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">pk</span><span class="o">).</span>
  <span class="n">isEqualTo</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">fk</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">fk</span><span class="o">).</span>
  <span class="n">projecting</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">head1</span> <span class="o">#</span><span class="k">:</span><span class="kt">:</span> <span class="k">_</span><span class="o">,</span> <span class="n">head2</span> <span class="o">#</span><span class="k">:</span><span class="kt">:</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">head1</span> <span class="o">-&gt;</span> <span class="n">head2</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="datastream-api">DataStream API</h3>
<ul>
<li>mapWith	方法和原来的 map (DataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">mapWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">value</span><span class="o">.</span><span class="n">toString</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>flatMapWith	方法和原来的 flatMap (DataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">flatMapWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">name</span><span class="o">,</span> <span class="n">visits</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">visits</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">name</span> <span class="o">-&gt;</span> <span class="k">_</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>filterWith 方法和原来的	filter (DataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">filterWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="nc">Train</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">isOnTime</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">isOnTime</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>keyingBy 方法和原来的	keyBy (DataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">keyingBy</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">id</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>mapWith 方法和原来的 map (ConnectedDataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">mapWith</span><span class="o">(</span>
  <span class="n">map1</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">value</span><span class="o">.</span><span class="n">toString</span><span class="o">,</span>
  <span class="n">map2</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="n">value</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">value</span> <span class="o">+</span> <span class="mi">1</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>flatMapWith	方法和原来的 flatMap (ConnectedDataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">flatMapWith</span><span class="o">(</span>
  <span class="n">flatMap1</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">json</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">parse</span><span class="o">(</span><span class="n">json</span><span class="o">),</span>
  <span class="n">flatMap2</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="n">json</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">parse</span><span class="o">(</span><span class="n">json</span><span class="o">)</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>keyingBy 方法和原来的	keyBy (ConnectedDataStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">keyingBy</span><span class="o">(</span>
  <span class="n">key1</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">timestamp</span><span class="o">,</span>
  <span class="n">key2</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">id</span>
<span class="o">)</span>
</code></pre></div><ul>
<li>reduceWith 方法和原来的 reduce (KeyedStream, WindowedStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">reduceWith</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">((</span><span class="k">_</span><span class="o">,</span> <span class="n">sum1</span><span class="o">),</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">sum2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">sum1</span> <span class="o">+</span> <span class="n">sum2</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>foldWith 方法和原来的	fold (KeyedStream, WindowedStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">foldWith</span><span class="o">(</span><span class="nc">User</span><span class="o">(</span><span class="n">bought</span> <span class="k">=</span> <span class="mi">0</span><span class="o">))</span> <span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="nc">User</span><span class="o">(</span><span class="n">b</span><span class="o">),</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">items</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="nc">User</span><span class="o">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">items</span><span class="o">.</span><span class="n">size</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><ul>
<li>applyWith	方法和原来的 apply (WindowedStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">applyWith</span><span class="o">(</span><span class="mi">0</span><span class="o">)(</span>
  <span class="n">foldFunction</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="n">sum</span><span class="o">,</span> <span class="n">amount</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">sum</span> <span class="o">+</span> <span class="n">amount</span>
  <span class="n">windowFunction</span> <span class="k">=</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">w</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="o">)</span>
</code></pre></div><ul>
<li>projecting 方法和原来的	apply (JoinedStream)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span>
  <span class="n">whereClause</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="n">pk</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">pk</span><span class="o">).</span>
  <span class="n">isEqualTo</span><span class="o">(</span><span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">fk</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">fk</span><span class="o">).</span>
  <span class="n">projecting</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">((</span><span class="n">pk</span><span class="o">,</span> <span class="n">tx</span><span class="o">),</span> <span class="o">(</span><span class="n">products</span><span class="o">,</span> <span class="n">fk</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="n">tx</span> <span class="o">-&gt;</span> <span class="n">products</span>
  <span class="o">}</span>
</code></pre></div><p>关于每个方法的语义的更多信息，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">DataSet</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API</a> 文档。</p>
<p>要专门使用这个扩展，可以添加以下导入。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.extensions.acceptPartialFunctions</span>
</code></pre></div><p>对于 DataSet 扩展和</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.extensions.acceptPartialFunctions</span>
</code></pre></div><p>下面的代码段展示了一个最小的例子，说明如何一起使用这些扩展方法（与 DataSet API 一起）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">object</span> <span class="nc">Main</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">org.apache.flink.api.scala.extensions._</span>
  <span class="k">case</span> <span class="k">class</span> <span class="nc">Point</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">y</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
    <span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="nc">Point</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="nc">Point</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">),</span> <span class="nc">Point</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">6</span><span class="o">))</span>
    <span class="n">ds</span><span class="o">.</span><span class="n">filterWith</span> <span class="o">{</span>
      <span class="k">case</span> <span class="nc">Point</span><span class="o">(</span><span class="n">x</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="o">}.</span><span class="n">reduceWith</span> <span class="o">{</span>
      <span class="k">case</span> <span class="o">(</span><span class="nc">Point</span><span class="o">(</span><span class="n">x1</span><span class="o">,</span> <span class="n">y1</span><span class="o">),</span> <span class="o">(</span><span class="nc">Point</span><span class="o">(</span><span class="n">x2</span><span class="o">,</span> <span class="n">y2</span><span class="o">)))</span> <span class="k">=&gt;</span> <span class="nc">Point</span><span class="o">(</span><span class="n">x1</span> <span class="o">+</span> <span class="n">y1</span><span class="o">,</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">y2</span><span class="o">)</span>
    <span class="o">}.</span><span class="n">mapWith</span> <span class="o">{</span>
      <span class="k">case</span> <span class="nc">Point</span><span class="o">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="o">)</span>
    <span class="o">}.</span><span class="n">flatMapWith</span> <span class="o">{</span>
      <span class="k">case</span> <span class="o">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&#34;x&#34;</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">,</span> <span class="s">&#34;y&#34;</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">)</span>
    <span class="o">}.</span><span class="n">groupingBy</span> <span class="o">{</span>
      <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">id</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/scala_api_extensions.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/scala_api_extensions.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Show 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-show-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Show Statements</blockquote><h1 id="show-语句">SHOW 语句</h1>
<p>SHOW 语句用于列出所有目录，或列出当前目录中的所有数据库，或列出当前目录和当前数据库中的所有表/视图，或列出当前目录和当前数据库中的所有函数，包括临时系统函数、系统函数、临时目录函数和目录函数。</p>
<p>Flink SQL 目前支持以下 SHOW 语句。</p>
<ul>
<li>SHOW CATALOGS</li>
<li>SHOW DATABASES</li>
<li>SHOW TABLES</li>
<li>SHOW VIEWS</li>
<li>SHOW FUNCTIONS</li>
</ul>
<h2 id="运行-show-语句">运行 SHOW 语句</h2>
<p>SHOW 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法会对成功的 SHOW 操作返回对象，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中运行 SHOW 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; SHOW CATALOGS<span class="p">;</span>
default_catalog

Flink SQL&gt; SHOW DATABASES<span class="p">;</span>
default_database

Flink SQL&gt; CREATE TABLE my_table <span class="o">(</span>...<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; SHOW TABLES<span class="p">;</span>
my_table

Flink SQL&gt; CREATE VIEW my_view AS ...<span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> View has been created.

Flink SQL&gt; SHOW VIEWS<span class="p">;</span>
my_view

Flink SQL&gt; SHOW FUNCTIONS<span class="p">;</span>
mod
sha256
...
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// show catalogs
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW CATALOGS&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +-----------------+
</span><span class="c1">// |    catalog name |
</span><span class="c1">// +-----------------+
</span><span class="c1">// | default_catalog |
</span><span class="c1">// +-----------------+
</span><span class="c1"></span>
<span class="c1">// show databases
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +------------------+
</span><span class="c1">// |    database name |
</span><span class="c1">// +------------------+
</span><span class="c1">// | default_database |
</span><span class="c1">// +------------------+
</span><span class="c1"></span>
<span class="c1">// create a table
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE my_table (...) WITH (...)&#34;</span><span class="o">)</span>
<span class="c1">// show tables
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW TABLES&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +------------+
</span><span class="c1">// | table name |
</span><span class="c1">// +------------+
</span><span class="c1">// |   my_table |
</span><span class="c1">// +------------+
</span><span class="c1"></span>
<span class="c1">// create a view
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE VIEW my_view AS ...&#34;</span><span class="o">)</span>
<span class="c1">// show views
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW VIEWS&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +-----------+
</span><span class="c1">// | view name |
</span><span class="c1">// +-----------+
</span><span class="c1">// |   my_view |
</span><span class="c1">// +-----------+
</span><span class="c1"></span>
<span class="c1">// show functions
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW FUNCTIONS&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +---------------+
</span><span class="c1">// | function name |
</span><span class="c1">// +---------------+
</span><span class="c1">// |           mod |
</span><span class="c1">// |        sha256 |
</span><span class="c1">// |           ... |
</span><span class="c1">// +---------------+
</span></code></pre></div><h2 id="show-catalogs">SHOW CATALOGS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">CATALOGS</span>
</code></pre></div><p>显示所有目录。</p>
<h2 id="show-databases">SHOW DATABASES</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">DATABASES</span>
</code></pre></div><p>显示当前目录中的所有数据库。</p>
<h2 id="show-tables">SHOW TABLES</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">TABLES</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有表。</p>
<h2 id="show-views">SHOW VIEWS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">VIEWS</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有视图。</p>
<h2 id="show-functions">SHOW FUNCTIONS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">FUNCTIONS</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有功能，包括临时系统功能、系统功能、临时目录功能和目录功能。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-overview/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Overview</blockquote><h1 id="sql">SQL</h1>
<p>本页介绍了 Flink 支持的 SQL 语言，包括数据定义语言（DDL）、数据操作语言（DML）和查询语言。Flink 的 SQL 支持是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。</p>
<p>本页列出了目前 Flink SQL 支持的所有语句。</p>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html">SELECT (Queries)</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">CREATE TABLE, DATABASE, VIEW, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html">DROP TABLE, DATABASE, VIEW, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html">ALTER TABLE, DATABASE, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">INSERT</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html">SQL HINTS</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html">DESCRIBE</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/explain.html">EXPLAIN</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html">USE</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html">SHOW</a></li>
</ul>
<h2 id="数据类型">数据类型</h2>
<p>请看关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的专门页面。</p>
<p>通用类型和(嵌套的)复合类型(例如 POJOs、tuple、行、Scala case 类)也可以是行的字段。</p>
<p>具有任意嵌套的复合类型的字段可以用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html#value-access-functions">值访问函数</a>来访问。</p>
<p>通用类型被当作一个黑盒子，可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>进行传递或处理。</p>
<p>对于 DDL，我们支持页面数据类型中定义的完整<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>。</p>
<p>注意事项: 有些数据类型在 SQL 查询中还不支持（即在投递表达式或字元中）。例如：STRING, BYTES, RAW, WITHOUT TIME ZONE 的 TIME(p), WITH LOCAL TIME ZONE 的 TIME(p), WITHOUT TIME ZONE 的 TIMESTAMP(p), WITH LOCAL TIME ZONE 的 TIMESTAMP(p), ARRAY, MULTISET, ROW。</p>
<h2 id="保留关键词">保留关键词</h2>
<p>虽然并不是每一个 SQL 功能都已实现，但有些字符串组合已经被保留为关键字，供将来使用。如果你想使用下面的一个字符串作为字段名，请确保在它们周围加上反引号（例如<code>value</code>，<code>count</code>）。</p>
<pre><code>A, ABS, ABSOLUTE, ACTION, ADA, ADD, ADMIN, AFTER, ALL, ALLOCATE, ALLOW, ALTER, ALWAYS, AND, ANY, ARE, ARRAY, AS, ASC, ASENSITIVE, ASSERTION, ASSIGNMENT, ASYMMETRIC, AT, ATOMIC, ATTRIBUTE, ATTRIBUTES, AUTHORIZATION, AVG, BEFORE, BEGIN, BERNOULLI, BETWEEN, BIGINT, BINARY, BIT, BLOB, BOOLEAN, BOTH, BREADTH, BY, BYTES, C, CALL, CALLED, CARDINALITY, CASCADE, CASCADED, CASE, CAST, CATALOG, CATALOG_NAME, CEIL, CEILING, CENTURY, CHAIN, CHAR, CHARACTER, CHARACTERISTICS, CHARACTERS, CHARACTER_LENGTH, CHARACTER_SET_CATALOG, CHARACTER_SET_NAME, CHARACTER_SET_SCHEMA, CHAR_LENGTH, CHECK, CLASS_ORIGIN, CLOB, CLOSE, COALESCE, COBOL, COLLATE, COLLATION, COLLATION_CATALOG, COLLATION_NAME, COLLATION_SCHEMA, COLLECT, COLUMN, COLUMN_NAME, COMMAND_FUNCTION, COMMAND_FUNCTION_CODE, COMMIT, COMMITTED, CONDITION, CONDITION_NUMBER, CONNECT, CONNECTION, CONNECTION_NAME, CONSTRAINT, CONSTRAINTS, CONSTRAINT_CATALOG, CONSTRAINT_NAME, CONSTRAINT_SCHEMA, CONSTRUCTOR, CONTAINS, CONTINUE, CONVERT, CORR, CORRESPONDING, COUNT, COVAR_POP, COVAR_SAMP, CREATE, CROSS, CUBE, CUME_DIST, CURRENT, CURRENT_CATALOG, CURRENT_DATE, CURRENT_DEFAULT_TRANSFORM_GROUP, CURRENT_PATH, CURRENT_ROLE, CURRENT_SCHEMA, CURRENT_TIME, CURRENT_TIMESTAMP, CURRENT_TRANSFORM_GROUP_FOR_TYPE, CURRENT_USER, CURSOR, CURSOR_NAME, CYCLE, DATA, DATABASE, DATE, DATETIME_INTERVAL_CODE, DATETIME_INTERVAL_PRECISION, DAY, DEALLOCATE, DEC, DECADE, DECIMAL, DECLARE, DEFAULT, DEFAULTS, DEFERRABLE, DEFERRED, DEFINED, DEFINER, DEGREE, DELETE, DENSE_RANK, DEPTH, DEREF, DERIVED, DESC, DESCRIBE, DESCRIPTION, DESCRIPTOR, DETERMINISTIC, DIAGNOSTICS, DISALLOW, DISCONNECT, DISPATCH, DISTINCT, DOMAIN, DOUBLE, DOW, DOY, DROP, DYNAMIC, DYNAMIC_FUNCTION, DYNAMIC_FUNCTION_CODE, EACH, ELEMENT, ELSE, END, END-EXEC, EPOCH, EQUALS, ESCAPE, EVERY, EXCEPT, EXCEPTION, EXCLUDE, EXCLUDING, EXEC, EXECUTE, EXISTS, EXP, EXPLAIN, EXTEND, EXTERNAL, EXTRACT, FALSE, FETCH, FILTER, FINAL, FIRST, FIRST_VALUE, FLOAT, FLOOR, FOLLOWING, FOR, FOREIGN, FORTRAN, FOUND, FRAC_SECOND, FREE, FROM, FULL, FUNCTION, FUSION, G, GENERAL, GENERATED, GET, GLOBAL, GO, GOTO, GRANT, GRANTED, GROUP, GROUPING, HAVING, HIERARCHY, HOLD, HOUR, IDENTITY, IMMEDIATE, IMPLEMENTATION, IMPORT, IN, INCLUDING, INCREMENT, INDICATOR, INITIALLY, INNER, INOUT, INPUT, INSENSITIVE, INSERT, INSTANCE, INSTANTIABLE, INT, INTEGER, INTERSECT, INTERSECTION, INTERVAL, INTO, INVOKER, IS, ISOLATION, JAVA, JOIN, K, KEY, KEY_MEMBER, KEY_TYPE, LABEL, LANGUAGE, LARGE, LAST, LAST_VALUE, LATERAL, LEADING, LEFT, LENGTH, LEVEL, LIBRARY, LIKE, LIMIT, LN, LOCAL, LOCALTIME, LOCALTIMESTAMP, LOCATOR, LOWER, M, MAP, MATCH, MATCHED, MAX, MAXVALUE, MEMBER, MERGE, MESSAGE_LENGTH, MESSAGE_OCTET_LENGTH, MESSAGE_TEXT, METHOD, MICROSECOND, MILLENNIUM, MIN, MINUTE, MINVALUE, MOD, MODIFIES, MODULE, MONTH, MORE, MULTISET, MUMPS, NAME, NAMES, NATIONAL, NATURAL, NCHAR, NCLOB, NESTING, NEW, NEXT, NO, NONE, NORMALIZE, NORMALIZED, NOT, NULL, NULLABLE, NULLIF, NULLS, NUMBER, NUMERIC, OBJECT, OCTETS, OCTET_LENGTH, OF, OFFSET, OLD, ON, ONLY, OPEN, OPTION, OPTIONS, OR, ORDER, ORDERING, ORDINALITY, OTHERS, OUT, OUTER, OUTPUT, OVER, OVERLAPS, OVERLAY, OVERRIDING, PAD, PARAMETER, PARAMETER_MODE, PARAMETER_NAME, PARAMETER_ORDINAL_POSITION, PARAMETER_SPECIFIC_CATALOG, PARAMETER_SPECIFIC_NAME, PARAMETER_SPECIFIC_SCHEMA, PARTIAL, PARTITION, PASCAL, PASSTHROUGH, PATH, PERCENTILE_CONT, PERCENTILE_DISC, PERCENT_RANK, PLACING, PLAN, PLI, POSITION, POWER, PRECEDING, PRECISION, PREPARE, PRESERVE, PRIMARY, PRIOR, PRIVILEGES, PROCEDURE, PUBLIC, QUARTER, RANGE, RANK, RAW, READ, READS, REAL, RECURSIVE, REF, REFERENCES, REFERENCING, REGR_AVGX, REGR_AVGY, REGR_COUNT, REGR_INTERCEPT, REGR_R2, REGR_SLOPE, REGR_SXX, REGR_SXY, REGR_SYY, RELATIVE, RELEASE, REPEATABLE, RESET, RESTART, RESTRICT, RESULT, RETURN, RETURNED_CARDINALITY, RETURNED_LENGTH, RETURNED_OCTET_LENGTH, RETURNED_SQLSTATE, RETURNS, REVOKE, RIGHT, ROLE, ROLLBACK, ROLLUP, ROUTINE, ROUTINE_CATALOG, ROUTINE_NAME, ROUTINE_SCHEMA, ROW, ROWS, ROW_COUNT, ROW_NUMBER, SAVEPOINT, SCALE, SCHEMA, SCHEMA_NAME, SCOPE, SCOPE_CATALOGS, SCOPE_NAME, SCOPE_SCHEMA, SCROLL, SEARCH, SECOND, SECTION, SECURITY, SELECT, SELF, SENSITIVE, SEQUENCE, SERIALIZABLE, SERVER, SERVER_NAME, SESSION, SESSION_USER, SET, SETS, SIMILAR, SIMPLE, SIZE, SMALLINT, SOME, SOURCE, SPACE, SPECIFIC, SPECIFICTYPE, SPECIFIC_NAME, SQL, SQLEXCEPTION, SQLSTATE, SQLWARNING, SQL_TSI_DAY, SQL_TSI_FRAC_SECOND, SQL_TSI_HOUR, SQL_TSI_MICROSECOND, SQL_TSI_MINUTE, SQL_TSI_MONTH, SQL_TSI_QUARTER, SQL_TSI_SECOND, SQL_TSI_WEEK, SQL_TSI_YEAR, SQRT, START, STATE, STATEMENT, STATIC, STDDEV_POP, STDDEV_SAMP, STREAM, STRING, STRUCTURE, STYLE, SUBCLASS_ORIGIN, SUBMULTISET, SUBSTITUTE, SUBSTRING, SUM, SYMMETRIC, SYSTEM, SYSTEM_USER, TABLE, TABLESAMPLE, TABLE_NAME, TEMPORARY, THEN, TIES, TIME, TIMESTAMP, TIMESTAMPADD, TIMESTAMPDIFF, TIMEZONE_HOUR, TIMEZONE_MINUTE, TINYINT, TO, TOP_LEVEL_COUNT, TRAILING, TRANSACTION, TRANSACTIONS_ACTIVE, TRANSACTIONS_COMMITTED, TRANSACTIONS_ROLLED_BACK, TRANSFORM, TRANSFORMS, TRANSLATE, TRANSLATION, TREAT, TRIGGER, TRIGGER_CATALOG, TRIGGER_NAME, TRIGGER_SCHEMA, TRIM, TRUE, TYPE, UESCAPE, UNBOUNDED, UNCOMMITTED, UNDER, UNION, UNIQUE, UNKNOWN, UNNAMED, UNNEST, UPDATE, UPPER, UPSERT, USAGE, USER, USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_CODE, USER_DEFINED_TYPE_NAME, USER_DEFINED_TYPE_SCHEMA, USING, VALUE, VALUES, VARBINARY, VARCHAR, VARYING, VAR_POP, VAR_SAMP, VERSION, VIEW, WEEK, WHEN, WHENEVER, WHERE, WIDTH_BUCKET, WINDOW, WITH, WITHIN, WITHOUT, WORK, WRAPPER, WRITE, XML, YEAR, ZONE
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL 客户端]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-client/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-client/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Client</blockquote><h2 id="sql-client">SQL Client</h2>
<p>Flink 的 Table &amp; SQL API 使得它可以使用 SQL 语言编写的查询，但是这些查询需要嵌入到一个用 Java 或 Scala 编写的表程序中。而且，这些程序在提交给集群之前需要用构建工具打包。这或多或少限制了 Flink 对 Java/Scala 程序员的使用。</p>
<p>SQL Client 旨在提供一种简单的方式来编写、调试和提交表程序到 Flink 集群，而不需要任何一行 Java 或 Scala 代码。SQL Client CLI 允许在命令行上从运行的分布式应用中检索和可视化实时结果。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/sql_client_demo.gif" alt="img"></p>
<h2 id="入门">入门</h2>
<p>本节介绍如何从命令行设置和运行第一个 Flink SQL 程序。</p>
<p>SQL Client 被捆绑在常规的 Flink 发行版中，因此可以开箱即运行。它只需要一个正在运行的 Flink 集群，在那里可以执行表程序。关于设置 Flink 集群的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html">集群和部署</a>部分。如果你只是想试用 SQL Client，也可以使用下面的命令用一个 worker 启动一个本地集群。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/start-cluster.sh
</code></pre></div><h3 id="启动-sql-客户端-cli">启动 SQL 客户端 CLI</h3>
<p>SQL Client 脚本也位于 Flink 的二进制目录中。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#limitations--future">在未来</a>，用户将有两种启动 SQL Client CLI 的可能性，一是通过启动一个嵌入式的独立进程，二是通过连接到一个远程 SQL Client 网关。目前只支持嵌入式模式。你可以通过调用来启动 CLI。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/sql-client.sh embedded
</code></pre></div><p>默认情况下，SQL 客户端将从位于 <code>./conf/sql-client-defaults.yaml</code> 的环境文件中读取其配置。有关环境文件结构的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#environment-files">配置部分</a>。</p>
<h3 id="运行-sql-查询">运行 SQL 查询</h3>
<p>一旦启动 CLI，您可以使用 HELP 命令列出所有可用的 SQL 语句。为了验证你的设置和集群连接，你可以输入第一个 SQL 查询，然后按回车键执行。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="s1">&#39;Hello World&#39;</span><span class="p">;</span>
</code></pre></div><p>这个查询不需要表源(table source)，并产生一个单行结果。CLI 将从集群中检索结果，并将其可视化。您可以按Q键关闭结果视图。</p>
<p>CLI 支持三种模式来维护和可视化结果。</p>
<p>table 模式将结果在内存中具体化，并以常规的、分页的表格表示方式将其可视化。可以通过在 CLI 中执行以下命令启用该模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>table<span class="p">;</span>
</code></pre></div><p><strong>changelog</strong> 模式不将结果具体化，而是将由插入(+)和收回(-)组成的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html#continuous-queries">连续查询</a>所产生的结果流可视化。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>changelog<span class="p">;</span>
</code></pre></div><p><strong>tableau</strong> 模式更像是传统的方式，将结果以 tableau 的形式直接显示在屏幕上。显示内容会受到查询执行类型(execute.type)的影响。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>tableau<span class="p">;</span>
</code></pre></div><p>请注意，当您使用此模式进行流式查询时，结果将在控制台中连续打印。如果这个查询的输入数据是有边界的，那么在Flink处理完所有输入数据后，作业就会终止，打印也会自动停止。否则，如果你想终止一个正在运行的查询，在这种情况下只要输入CTRL-C键，作业和打印就会停止。</p>
<p>你可以使用下面的查询来查看所有的结果模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">name</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="p">(</span><span class="k">VALUES</span> <span class="p">(</span><span class="s1">&#39;Bob&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Alice&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Greg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Bob&#39;</span><span class="p">))</span> <span class="k">AS</span> <span class="n">NameTable</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">name</span><span class="p">;</span>
</code></pre></div><p>这个查询执行一个有界字数的例子。</p>
<p>在 changelog 模式下，可视化的 changelog 应该类似于。</p>
<pre><code>+ Bob, 1
+ Alice, 1
+ Greg, 1
- Bob, 1
+ Bob, 2
</code></pre><p>在 table 模式下，可视化的结果表会持续更新，直到表程序结束。</p>
<pre><code>Bob, 2
Alice, 1
Greg, 1
</code></pre><p>在tableau模式下，如果你在流模式下运行查询，显示的结果将是。</p>
<pre><code>+-----+----------------------+----------------------+
| +/- |                 name |                  cnt |
+-----+----------------------+----------------------+
|   + |                  Bob |                    1 |
|   + |                Alice |                    1 |
|   + |                 Greg |                    1 |
|   - |                  Bob |                    1 |
|   + |                  Bob |                    2 |
+-----+----------------------+----------------------+
Received a total of 5 rows
</code></pre><p>而如果你在批处理模式下运行查询，显示的结果将是。</p>
<pre><code>+-------+-----+
|  name | cnt |
+-------+-----+
| Alice |   1 |
|   Bob |   2 |
|  Greg |   1 |
+-------+-----+
3 rows in set
</code></pre><p>在 SQL 查询的原型设计过程中，所有这些结果模式都是有用的。在所有这些模式中，结果都存储在 SQL 客户端的 Java 堆内存中。为了保持CLI界面的响应性，changelog 模式只显示最新的1000个变化。表模式允许浏览更大的结果，这些结果仅受可用主内存和配置的最大行数（<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#configuration">max-table-result-rows</a>）的限制。</p>
<p>注意：在批处理环境中执行的查询，只能使用table或tableau结果模式进行检索。</p>
<p>在定义了一个查询后，可以将其作为一个长期运行的、分离的 Flink 作业提交给集群。为此，需要使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#detached-sql-queries">INSERT INTO 语句</a>指定存储结果的目标系统。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#configurations">配置部分</a>解释了如何声明 table source 以读取数据，如何声明 table sink 以写入数据，以及如何配置其他表程序属性。</p>
<h2 id="配置">配置</h2>
<p>SQL Client 可以通过以下可选的CLI命令来启动。这些命令将在后面的段落中详细讨论。</p>
<pre><code>./bin/sql-client.sh embedded --help

Mode &quot;embedded&quot; submits Flink jobs from the local machine.

  Syntax: embedded [OPTIONS]
  &quot;embedded&quot; mode options:
     -d,--defaults &lt;environment file&gt;      The environment properties with which
                                           every new session is initialized.
                                           Properties might be overwritten by
                                           session properties.
     -e,--environment &lt;environment file&gt;   The environment properties to be
                                           imported into the session. It might
                                           overwrite default environment
                                           properties.
     -h,--help                             Show the help message with
                                           descriptions of all options.
     -hist,--history &lt;History file path&gt;   The file which you want to save the
                                           command history into. If not
                                           specified, we will auto-generate one
                                           under your user's home directory.
     -j,--jar &lt;JAR file&gt;                   A JAR file to be imported into the
                                           session. The file might contain
                                           user-defined classes needed for the
                                           execution of statements such as
                                           functions, table sources, or sinks.
                                           Can be used multiple times.
     -l,--library &lt;JAR directory&gt;          A JAR file directory with which every
                                           new session is initialized. The files
                                           might contain user-defined classes
                                           needed for the execution of
                                           statements such as functions, table
                                           sources, or sinks. Can be used
                                           multiple times.
     -pyarch,--pyArchives &lt;arg&gt;            Add python archive files for job. The
                                           archive files will be extracted to
                                           the working directory of python UDF
                                           worker. Currently only zip-format is
                                           supported. For each archive file, a
                                           target directory be specified. If the
                                           target directory name is specified,
                                           the archive file will be extracted to
                                           a name can directory with the
                                           specified name. Otherwise, the
                                           archive file will be extracted to a
                                           directory with the same name of the
                                           archive file. The files uploaded via
                                           this option are accessible via
                                           relative path. '#' could be used as
                                           the separator of the archive file
                                           path and the target directory name.
                                           Comma (',') could be used as the
                                           separator to specify multiple archive
                                           files. This option can be used to
                                           upload the virtual environment, the
                                           data files used in Python UDF (e.g.:
                                           --pyArchives
                                           file:///tmp/py37.zip,file:///tmp/data
                                           .zip#data --pyExecutable
                                           py37.zip/py37/bin/python). The data
                                           files could be accessed in Python
                                           UDF, e.g.: f = open('data/data.txt',
                                           'r').
     -pyexec,--pyExecutable &lt;arg&gt;          Specify the path of the python
                                           interpreter used to execute the
                                           python UDF worker (e.g.:
                                           --pyExecutable
                                           /usr/local/bin/python3). The python
                                           UDF worker depends on Python 3.5+,
                                           Apache Beam (version == 2.19.0), Pip
                                           (version &gt;= 7.1.0) and SetupTools
                                           (version &gt;= 37.0.0). Please ensure
                                           that the specified environment meets
                                           the above requirements.
     -pyfs,--pyFiles &lt;pythonFiles&gt;         Attach custom python files for job.
                                           These files will be added to the
                                           PYTHONPATH of both the local client
                                           and the remote python UDF worker. The
                                           standard python resource file
                                           suffixes such as .py/.egg/.zip or
                                           directory are all supported. Comma
                                           (',') could be used as the separator
                                           to specify multiple files (e.g.:
                                           --pyFiles
                                           file:///tmp/myresource.zip,hdfs:///$n
                                           amenode_address/myresource2.zip).
     -pyreq,--pyRequirements &lt;arg&gt;         Specify a requirements.txt file which
                                           defines the third-party dependencies.
                                           These dependencies will be installed
                                           and added to the PYTHONPATH of the
                                           python UDF worker. A directory which
                                           contains the installation packages of
                                           these dependencies could be specified
                                           optionally. Use '#' as the separator
                                           if the optional parameter exists
                                           (e.g.: --pyRequirements
                                           file:///tmp/requirements.txt#file:///
                                           tmp/cached_dir).
     -s,--session &lt;session identifier&gt;     The identifier for a session.
                                           'default' is the default identifier.
     -u,--update &lt;SQL update statement&gt;    Experimental (for testing only!):
                                           Instructs the SQL Client to
                                           immediately execute the given update
                                           statement after starting up. The
                                           process is shut down after the
                                           statement has been submitted to the
                                           cluster and returns an appropriate
                                           return code. Currently, this feature
                                           is only supported for INSERT INTO
                                           statements that declare the target
                                           sink table.

</code></pre><h3 id="环境文件">环境文件</h3>
<p>一个SQL查询需要一个配置环境来执行。所谓的环境文件定义了可用的目录(catalogs)、table source 和 sink、用户定义的函数以及执行和部署所需的其他属性。</p>
<p>每个环境文件都是一个常规的 <a href="http://yaml.org/">YAML 文件</a>。下面是这样一个文件的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># Define tables here such as sources, sinks, views, or temporal tables.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">tables</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyTableSource</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">source-table</span><span class="w">
</span><span class="w">    </span><span class="nt">update-mode</span><span class="p">:</span><span class="w"> </span><span class="l">append</span><span class="w">
</span><span class="w">    </span><span class="nt">connector</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">filesystem</span><span class="w">
</span><span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/path/to/something.csv&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">format</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">csv</span><span class="w">
</span><span class="w">      </span><span class="nt">fields</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyField1</span><span class="w">
</span><span class="w">          </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">INT</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyField2</span><span class="w">
</span><span class="w">          </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">VARCHAR</span><span class="w">
</span><span class="w">      </span><span class="nt">line-delimiter</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;\n&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">comment-prefix</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;#&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">schema</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyField1</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">INT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyField2</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">VARCHAR</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyCustomView</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">view</span><span class="w">
</span><span class="w">    </span><span class="nt">query</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;SELECT MyField2 FROM MyTableSource&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Define user-defined functions here.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">functions</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">myUDF</span><span class="w">
</span><span class="w">    </span><span class="nt">from</span><span class="p">:</span><span class="w"> </span><span class="l">class</span><span class="w">
</span><span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l">foo.bar.AggregateUDF</span><span class="w">
</span><span class="w">    </span><span class="nt">constructor</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="m">7.6</span><span class="w">
</span><span class="w">      </span>- <span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Define available catalogs</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">catalog_1</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span><span class="w">     </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">...</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">catalog_2</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span><span class="w">     </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="nt">default-database</span><span class="p">:</span><span class="w"> </span><span class="l">mydb2</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">...</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Properties that change the fundamental execution behavior of a table program.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">execution</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">planner: blink                    # optional</span><span class="p">:</span><span class="w"> </span><span class="l">either &#39;blink&#39; (default) or &#39;old&#39;</span><span class="w">
</span><span class="w">  </span><span class="nt">type: streaming                   # required</span><span class="p">:</span><span class="w"> </span><span class="l">execution mode either &#39;batch&#39; or &#39;streaming&#39;</span><span class="w">
</span><span class="w">  </span><span class="nt">result-mode: table                # required</span><span class="p">:</span><span class="w"> </span><span class="l">either &#39;table&#39; or &#39;changelog&#39;</span><span class="w">
</span><span class="w">  </span><span class="nt">max-table-result-rows: 1000000    # optional</span><span class="p">:</span><span class="w"> </span><span class="l">maximum number of maintained rows in</span><span class="w">
</span><span class="w">                                    </span><span class="c">#   &#39;table&#39; mode (1000000 by default, smaller 1 means unlimited)</span><span class="w">
</span><span class="w">  </span><span class="nt">time-characteristic: event-time   # optional</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;processing-time&#39;</span><span class="w"> </span><span class="l">or &#39;event-time&#39; (default)</span><span class="w">
</span><span class="w">  </span><span class="nt">parallelism: 1                    # optional</span><span class="p">:</span><span class="w"> </span><span class="l">Flink&#39;s parallelism (1 by default)</span><span class="w">
</span><span class="w">  </span><span class="nt">periodic-watermarks-interval: 200 # optional</span><span class="p">:</span><span class="w"> </span><span class="l">interval for periodic watermarks (200 ms by default)</span><span class="w">
</span><span class="w">  </span><span class="nt">max-parallelism: 16               # optional</span><span class="p">:</span><span class="w"> </span><span class="l">Flink&#39;s maximum parallelism (128 by default)</span><span class="w">
</span><span class="w">  </span><span class="nt">min-idle-state-retention: 0       # optional</span><span class="p">:</span><span class="w"> </span><span class="l">table program&#39;s minimum idle state time</span><span class="w">
</span><span class="w">  </span><span class="nt">max-idle-state-retention: 0       # optional</span><span class="p">:</span><span class="w"> </span><span class="l">table program&#39;s maximum idle state time</span><span class="w">
</span><span class="w">  </span><span class="nt">current-catalog: catalog_1        # optional</span><span class="p">:</span><span class="w"> </span><span class="l">name of the current catalog of the session (&#39;default_catalog&#39; by default)</span><span class="w">
</span><span class="w">  </span><span class="nt">current-database: mydb1           # optional</span><span class="p">:</span><span class="w"> </span><span class="l">name of the current database of the current catalog</span><span class="w">
</span><span class="w">                                    </span><span class="c">#   (default database of the current catalog by default)</span><span class="w">
</span><span class="w">  </span><span class="nt">restart-strategy:                 # optional</span><span class="p">:</span><span class="w"> </span><span class="l">restart strategy</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">fallback                 </span><span class="w"> </span><span class="c">#   &#34;fallback&#34; to global restart strategy by default</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Configuration options for adjusting and tuning table programs.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># A full list of options and their default values can be found</span><span class="w">
</span><span class="w"></span><span class="c"># on the dedicated &#34;Configuration&#34; page.</span><span class="w">
</span><span class="w"></span><span class="nt">configuration</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">table.optimizer.join-reorder-enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">table.exec.spill-compression.enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">table.exec.spill-compression.block-size</span><span class="p">:</span><span class="w"> </span><span class="l">128kb</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Properties that describe the cluster to which table programs are submitted to.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">deployment</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">response-timeout</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></code></pre></div><p>这份配置:</p>
<ul>
<li>定义了一个表源 <code>MyTableSource</code> 的环境，该表源从 CSV 文件中读取。</li>
<li>定义了一个视图 <code>MyCustomView</code>，该视图使用 SQL 查询声明了一个虚拟表。</li>
<li>定义了一个用户定义的函数 <code>myUDF</code>，可以使用类名和两个构造函数参数来实例化。</li>
<li>连接两个 Hive 目录，并使用 catalog_1 作为当前目录，mydb1 作为目录的当前数据库。</li>
<li>在流式模式下使用 blink planner，运行具有事件时间特性和并行度为1的语句。</li>
<li>在 table 结果模式下运行探索性查询。</li>
<li>并通过配置选项围绕连接重排序和溢出进行一些 planner 调整。</li>
</ul>
<p>根据使用情况，一个配置可以被分割成多个文件。因此，可以为一般目的创建环境文件（使用 <code>--defaults</code> 创建默认环境文件），也可以为每个会话创建环境文件（使用 <code>--environment</code> 创建会话环境文件）。每一个 CLI 会话都会用默认属性和会话属性来初始化。例如，<code>defaults</code> 环境文件可以指定在每个会话中应该可以查询的所有 table source，而 <code>session</code> 环境文件只声明特定的状态保留时间和并行度。在启动CLI应用程序时，可以同时传递默认环境文件和会话环境文件。如果没有指定默认环境文件，SQL Client 会在 Flink 的配置目录下搜索 <code>./conf/sql-client-defaults.yaml</code>。</p>
<p>注意：在 CLI 会话中设置的属性（例如使用SET命令）具有最高优先权。</p>
<pre><code>CLI commands &gt; session environment file &gt; defaults environment file
</code></pre><h3 id="重启策略">重启策略</h3>
<p>重启策略控制 Flink 作业在发生故障时如何重启。与 Flink 集群的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/restart_strategies.html">全局重启策略</a>类似，可以在环境文件中声明一个更精细的重启配置。</p>
<p>支持以下策略。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">execution</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># falls back to the global strategy defined in flink-conf.yaml</span><span class="w">
</span><span class="w">  </span><span class="nt">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">fallback</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># job fails directly and no restart is attempted</span><span class="w">
</span><span class="w">  </span><span class="nt">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">none</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># attempts a given number of times to restart the job</span><span class="w">
</span><span class="w">  </span><span class="nt">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">fixed-delay</span><span class="w">
</span><span class="w">    </span><span class="nt">attempts: 3      # retries before job is declared as failed (default</span><span class="p">:</span><span class="w"> </span><span class="l">Integer.MAX_VALUE)</span><span class="w">
</span><span class="w">    </span><span class="nt">delay: 10000     # delay in ms between retries (default</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="l">s)</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># attempts as long as the maximum number of failures per time interval is not exceeded</span><span class="w">
</span><span class="w">  </span><span class="nt">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">failure-rate</span><span class="w">
</span><span class="w">    </span><span class="nt">max-failures-per-interval: 1   # retries in interval until failing (default</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="l">)</span><span class="w">
</span><span class="w">    </span><span class="nt">failure-rate-interval</span><span class="p">:</span><span class="w"> </span><span class="m">60000</span><span class="w">   </span><span class="c"># measuring interval in ms for failure rate</span><span class="w">
</span><span class="w">    </span><span class="nt">delay: 10000                   # delay in ms between retries (default</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="l">s)</span><span class="w">
</span></code></pre></div><h3 id="依赖性">依赖性</h3>
<p>SQL Client 不需要使用 Maven 或 SBT 设置一个 Java 项目。相反，你可以将依赖关系作为常规的 JAR 文件传递给集群。你可以单独指定每个 JAR 文件（使用 <code>--jar</code>）或定义整个库目录（使用 <code>--library</code>）。对于连接到外部系统（如 Apache Kafka）的连接器和相应的数据格式（如JSON），Flink 提供了现成的 JAR bundles。这些 JAR 文件可以从 Maven 中央仓库为每个版本下载。</p>
<p>所提供的 SQL JAR 的完整列表和关于如何使用它们的文档可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统页面</a>上找到。</p>
<p>下面的例子显示了一个环境文件，它定义了一个从 Apache Kafka 读取 JSON 数据的 table source。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">tables</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">TaxiRides</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">source-table</span><span class="w">
</span><span class="w">    </span><span class="nt">update-mode</span><span class="p">:</span><span class="w"> </span><span class="l">append</span><span class="w">
</span><span class="w">    </span><span class="nt">connector</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">kafka</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;0.11&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">topic</span><span class="p">:</span><span class="w"> </span><span class="l">TaxiRides</span><span class="w">
</span><span class="w">      </span><span class="nt">startup-mode</span><span class="p">:</span><span class="w"> </span><span class="l">earliest-offset</span><span class="w">
</span><span class="w">      </span><span class="nt">properties</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">bootstrap.servers</span><span class="p">:</span><span class="w"> </span><span class="l">localhost:9092</span><span class="w">
</span><span class="w">        </span><span class="nt">group.id</span><span class="p">:</span><span class="w"> </span><span class="l">testGroup</span><span class="w">
</span><span class="w">    </span><span class="nt">format</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">json</span><span class="w">
</span><span class="w">      </span><span class="nt">schema</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;ROW&lt;rideId LONG, lon FLOAT, lat FLOAT, rideTime TIMESTAMP&gt;&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">schema</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rideId</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">BIGINT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">lon</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">FLOAT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">lat</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">FLOAT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rowTime</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">TIMESTAMP(3)</span><span class="w">
</span><span class="w">        </span><span class="nt">rowtime</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">timestamps</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;from-field&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">from</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;rideTime&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">watermarks</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;periodic-bounded&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">delay</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;60000&#34;</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">procTime</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">TIMESTAMP(3)</span><span class="w">
</span><span class="w">        </span><span class="nt">proctime</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></code></pre></div><p>由此产生的 <code>TaxiRide</code> 表的模式(schema)包含了 JSON 模式(schema)的大部分字段。此外，它还增加了一个行时间属性 <code>rowTime</code> 和处理时间属性 <code>procTime</code>。</p>
<p><code>connector</code> 和 <code>format</code> 都允许定义一个属性版本（目前是版本1），以便于将来向后兼容。</p>
<h3 id="用户定义的函数">用户定义的函数</h3>
<p>SQL Client 允许用户创建自定义的、用户定义的函数，以便在 SQL 查询中使用。目前，这些函数被限制在 Java/Scala 类或 Python  文件中以编程方式定义。</p>
<p>为了提供一个 Java/Scala 用户定义的函数，你需要首先实现和编译一个扩展 ScalarFunction、AggregateFunction 或 TableFunction 的函数类（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>）。然后可以将一个或多个函数打包到 SQL Client 的依赖 JAR 中。</p>
<p>为了提供一个 Python 用户定义函数，你需要编写一个 Python 函数，并用 <code>pyflink.table.udf.udf</code> 或 <code>pyflink.table.udf.udtf</code> 装饰器来装饰它(见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>)。然后可以将一个或多个函数放入一个 Python 文件中。Python 文件和相关的依赖关系需要通过环境文件中的配置 (参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/python_config.html">Python 配置</a>) 或命令行选项 (参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html#usage">命令行用法</a>) 来指定。</p>
<p>所有函数在被调用之前必须在环境文件中声明。对于函数列表中的每一项，必须指定</p>
<ul>
<li>注册该函数的名称。</li>
<li>函数的源，使用 <code>from</code> (暂时限制为 class (Java/Scala UDF) 或 python (Python UDF))。</li>
</ul>
<p>Java/Scala UDF 必须指定:</p>
<ul>
<li><code>class</code>，表示函数的完全限定类名和一个可选的实例化构造参数列表。</li>
</ul>
<p>Python 的 UDF 必须指定:</p>
<ul>
<li><code>fully-qualified-name</code>: 表示完全限定的名称，即函数的&quot;[模块名].[对象名]&quot;。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">functions</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name: java_udf               # required</span><span class="p">:</span><span class="w"> </span><span class="l">name of the function</span><span class="w">
</span><span class="w">    </span><span class="nt">from: class                  # required</span><span class="p">:</span><span class="w"> </span><span class="l">source of the function</span><span class="w">
</span><span class="w">    </span><span class="nt">class: ...                   # required</span><span class="p">:</span><span class="w"> </span><span class="l">fully qualified class name of the function</span><span class="w">
</span><span class="w">    </span><span class="nt">constructor:                 # optional</span><span class="p">:</span><span class="w"> </span><span class="l">constructor parameters of the function class</span><span class="w">
</span><span class="w">      </span>- <span class="nt">...                      # optional</span><span class="p">:</span><span class="w"> </span><span class="l">a literal parameter with implicit type</span><span class="w">
</span><span class="w">      </span>- <span class="nt">class: ...               # optional</span><span class="p">:</span><span class="w"> </span><span class="l">full class name of the parameter</span><span class="w">
</span><span class="w">        </span><span class="nt">constructor:             # optional</span><span class="p">:</span><span class="w"> </span><span class="l">constructor parameters of the parameter&#39;s class</span><span class="w">
</span><span class="w">          </span>- <span class="nt">type: ...            # optional</span><span class="p">:</span><span class="w"> </span><span class="l">type of the literal parameter</span><span class="w">
</span><span class="w">            </span><span class="nt">value: ...           # optional</span><span class="p">:</span><span class="w"> </span><span class="l">value of the literal parameter</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name: python_udf             # required</span><span class="p">:</span><span class="w"> </span><span class="l">name of the function</span><span class="w">
</span><span class="w">    </span><span class="nt">from: python                 # required</span><span class="p">:</span><span class="w"> </span><span class="l">source of the function </span><span class="w">
</span><span class="w">    </span><span class="nt">fully-qualified-name: ...    # required</span><span class="p">:</span><span class="w"> </span><span class="l">fully qualified class name of the function      </span><span class="w">
</span></code></pre></div><p>对于 Java/Scala UDF，请确保指定参数的顺序和类型严格匹配你的函数类的一个构造函数。</p>
<h3 id="构造函数参数">构造函数参数</h3>
<p>根据用户定义的函数，在 SQL 语句中使用它之前，可能需要对实现进行参数化。</p>
<p>如前面的例子所示，在声明用户定义函数时，可以通过以下三种方式之一使用构造函数参数来配置类。</p>
<p>一个隐含类型的字面值。SQL Client 会根据字面值本身自动推导出类型。目前，这里只支持 BOOLEAN、INT、DOUBLE 和 VARCHAR 的值。如果自动推导没有达到预期的效果（例如，你需要一个 VARCHAR false），请使用显式类型代替。</p>
<pre><code>- true         # -&gt; BOOLEAN (case sensitive)
- 42           # -&gt; INT
- 1234.222     # -&gt; DOUBLE
- foo          # -&gt; VARCHAR
</code></pre><p>一个具有明确类型的字面值。明确声明参数的 <code>type</code> 和 <code>value</code> 属性，以保证类型安全。</p>
<pre><code>- type: DECIMAL
  value: 11111111111111111
</code></pre><p>下表说明了支持的 Java 参数类型和相应的 SQL 类型字符串。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Java type</th>
<th style="text-align:left">SQL type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">java.math.BigDecimal</td>
<td style="text-align:left">DECIMAL</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Boolean</td>
<td style="text-align:left">BOOLEAN</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Byte</td>
<td style="text-align:left">TINYINT</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Double</td>
<td style="text-align:left">DOUBLE</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Float</td>
<td style="text-align:left">REAL, FLOAT</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Integer</td>
<td style="text-align:left">INTEGER, INT</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Long</td>
<td style="text-align:left">BIGINT</td>
</tr>
<tr>
<td style="text-align:left">java.lang.Short</td>
<td style="text-align:left">SMALLINT</td>
</tr>
<tr>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">VARCHAR</td>
</tr>
</tbody>
</table>
<p>目前还不支持更多的类型（如 TIMESTAMP 或 ARRAY）、原语类型和 null。</p>
<p>一个（嵌套的）类实例。除了字面值，你还可以通过指定 <code>class</code> 和 <code>constructor</code> 函数属性，为构造函数参数创建（嵌套）类实例。这个过程可以递归执行，直到所有的构造参数都用字面值表示。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">- <span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l">foo.bar.paramClass</span><span class="w">
</span><span class="w">  </span><span class="nt">constructor</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">StarryName</span><span class="w">
</span><span class="w">    </span>- <span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l">java.lang.Integer</span><span class="w">
</span><span class="w">      </span><span class="nt">constructor</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l">java.lang.String</span><span class="w">
</span><span class="w">          </span><span class="nt">constructor</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">VARCHAR</span><span class="w">
</span><span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div><h3 id="catalogs">Catalogs</h3>
<p>Catalogs 可以定义为一组 YAML 属性，在启动 SQL Client 时自动注册到环境中。</p>
<p>用户可以在 SQL CLI 中指定要使用哪个目录(catalog)作为当前目录(catalog)，以及要使用该目录(catalog)的哪个数据库作为当前数据库。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">catalog_1</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span><span class="w">     </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="nt">default-database</span><span class="p">:</span><span class="w"> </span><span class="l">mydb2</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;path of Hive conf directory&gt;</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">catalog_2</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span><span class="w">     </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="nt">hive-conf-dir</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;path of Hive conf directory&gt;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">execution</span><span class="p">:</span><span class="w">
</span><span class="w">   </span><span class="l">...</span><span class="w">
</span><span class="w">   </span><span class="nt">current-catalog</span><span class="p">:</span><span class="w"> </span><span class="l">catalog_1</span><span class="w">
</span><span class="w">   </span><span class="nt">current-database</span><span class="p">:</span><span class="w"> </span><span class="l">mydb1</span><span class="w">
</span></code></pre></div><p>关于目录的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>。</p>
<h2 id="分离式-sql-查询">分离式 SQL 查询</h2>
<p>为了定义端到端 SQL 管道，SQL 的 INSERT INTO 语句可以用于向 Flink 集群提交长期运行的、分离的查询。这些查询将其结果产生到外部系统中，而不是 SQL Client。这允许处理更高的并行性和更大的数据量。CLI 本身对提交后的分离查询没有任何控制。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">MyTableSink</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">MyTableSource</span>
</code></pre></div><p>表接收器 <code>MyTableSink</code> 必须在环境文件中声明。有关支持的外部系统及其配置的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接页面</a>。下面是一个 Apache Kafka 表接收器的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">tables</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyTableSink</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">sink-table</span><span class="w">
</span><span class="w">    </span><span class="nt">update-mode</span><span class="p">:</span><span class="w"> </span><span class="l">append</span><span class="w">
</span><span class="w">    </span><span class="nt">connector</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">kafka</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;0.11&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">topic</span><span class="p">:</span><span class="w"> </span><span class="l">OutputTopic</span><span class="w">
</span><span class="w">      </span><span class="nt">properties</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">bootstrap.servers</span><span class="p">:</span><span class="w"> </span><span class="l">localhost:9092</span><span class="w">
</span><span class="w">        </span><span class="nt">group.id</span><span class="p">:</span><span class="w"> </span><span class="l">testGroup</span><span class="w">
</span><span class="w">    </span><span class="nt">format</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">json</span><span class="w">
</span><span class="w">      </span><span class="nt">derive-schema</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">schema</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rideId</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">BIGINT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">lon</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">FLOAT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">lat</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">FLOAT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rideTime</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">TIMESTAMP(3)</span><span class="w">
</span></code></pre></div><p>SQL 客户端确保语句成功提交到集群。一旦提交查询，CLI 将显示有关 Flink 作业的信息。</p>
<pre><code>[INFO] Table update statement has been successfully submitted to the cluster:
Cluster ID: StandaloneClusterId
Job ID: 6f922fe5cba87406ff23ae4a7bb79044
Web interface: http://localhost:8081
</code></pre><p>注意: SQL 客户端在提交后不会跟踪正在运行的 Flink 作业的状态。CLI 进程可以在提交后被关闭，而不影响分离查询。Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/restart_strategies.html">重启策略</a>照顾到了容错。可以使用 Flink 的 Web 界面、命令行或 REST API 来取消查询。</p>
<h2 id="sql-视图">SQL 视图</h2>
<p>视图允许从 SQL 查询中定义虚拟表。视图定义会被立即解析和验证。然而，实际的执行发生在提交一般的 INSERT INTO 或 SELECT 语句期间访问视图时。</p>
<p>视图可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#environment-files">环境文件</a>中定义，也可以在 CLI 会话中定义。</p>
<p>下面的例子显示了如何在一个文件中定义多个视图。视图是按照它们在环境文件中定义的顺序注册的。支持诸如视图 A 依赖于视图 B 依赖于视图 C 的引用链。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">tables</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyTableSource</span><span class="w">
</span><span class="w">    </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyRestrictedView</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">view</span><span class="w">
</span><span class="w">    </span><span class="nt">query</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;SELECT MyField2 FROM MyTableSource&#34;</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyComplexView</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">view</span><span class="w">
</span><span class="w">    </span><span class="nt">query</span><span class="p">:</span><span class="w"> </span><span class="p">&gt;</span><span class="sd">
</span><span class="sd">      SELECT MyField2 + 42, CAST(MyField1 AS VARCHAR)
</span><span class="sd">      FROM MyTableSource
</span><span class="sd">      WHERE MyField2 &gt; 200</span><span class="w">      
</span></code></pre></div><p>与 table source 和 sink 类似，会话环境文件中定义的视图具有最高优先级。</p>
<p>视图也可以在 CLI 会话中使用 <code>CREATE VIEW</code> 语句创建。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="n">MyNewView</span> <span class="k">AS</span> <span class="k">SELECT</span> <span class="n">MyField2</span> <span class="k">FROM</span> <span class="n">MyTableSource</span><span class="p">;</span>
</code></pre></div><p>在 CLI 会话中创建的视图也可以使用 <code>DROP VIEW</code> 语句再次删除。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">VIEW</span> <span class="n">MyNewView</span><span class="p">;</span>
</code></pre></div><p>注意: CLI 中视图的定义仅限于上述语法。在未来的版本中，将支持为视图定义模式或在表名中转义空格。</p>
<h2 id="临时表">临时表</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>允许对变化的历史表进行（参数化的）查看，该表在特定的时间点返回一个表的内容。这对于将一个表与另一个表在特定时间戳的内容连接起来特别有用。更多信息可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#join-with-a-temporal-table">临时表连接</a>页面中找到。</p>
<p>下面的示例展示了如何定义一个临时表 <code>SourceTemporalTable</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">tables</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Define the table source (or view) that contains updates to a temporal table</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">HistorySource</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">source-table</span><span class="w">
</span><span class="w">    </span><span class="nt">update-mode</span><span class="p">:</span><span class="w"> </span><span class="l">append</span><span class="w">
</span><span class="w">    </span><span class="nt">connector</span><span class="p">:</span><span class="w"> </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="nt">format</span><span class="p">:</span><span class="w"> </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="nt">schema</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">integerField</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">INT</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">stringField</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">STRING</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rowtimeField</span><span class="w">
</span><span class="w">        </span><span class="nt">data-type</span><span class="p">:</span><span class="w"> </span><span class="l">TIMESTAMP(3)</span><span class="w">
</span><span class="w">        </span><span class="nt">rowtime</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">timestamps</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">from-field</span><span class="w">
</span><span class="w">            </span><span class="nt">from</span><span class="p">:</span><span class="w"> </span><span class="l">rowtimeField</span><span class="w">
</span><span class="w">          </span><span class="nt">watermarks</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">from-source</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Define a temporal table over the changing history table with time attribute and primary key</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">SourceTemporalTable</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">temporal-table</span><span class="w">
</span><span class="w">    </span><span class="nt">history-table</span><span class="p">:</span><span class="w"> </span><span class="l">HistorySource</span><span class="w">
</span><span class="w">    </span><span class="nt">primary-key</span><span class="p">:</span><span class="w"> </span><span class="l">integerField</span><span class="w">
</span><span class="w">    </span><span class="nt">time-attribute</span><span class="p">:</span><span class="w"> </span><span class="l">rowtimeField </span><span class="w"> </span><span class="c"># could also be a proctime field</span><span class="w">
</span></code></pre></div><p>如示例中所示，table source、视图和临时表的定义可以相互混合。它们按照在环境文件中定义的顺序进行注册。例如，一个临时表可以引用一个视图，该视图可以依赖于另一个视图或 table source。</p>
<h2 id="限制和未来">限制和未来</h2>
<p>目前的 SQL Client 只支持嵌入式模式。未来，社区计划通过提供基于 REST 的 SQL Client 网关来扩展其功能，详见 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-24+-+SQL+Client">FLIP-24</a> 和 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-91%3A+Support+SQL+Client+Gateway">FLIP-91</a>。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL 提示]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Hints</blockquote><h1 id="sql-提示">SQL 提示</h1>
<p>SQL 提示可以与 SQL 语句一起使用，以改变执行计划。本章解释了如何使用提示来强制各种方法。</p>
<p>一般来说，一个提示可以用来。</p>
<p>强制执行计划器：没有完美的计划器，所以实现提示让用户更好地控制执行是有意义的。
Append meta data(或统计)：一些统计，比如&quot;扫描的表索引&quot;和 &ldquo;一些 shuffle 键的 skew info&rdquo;，对于查询来说是有些动态的，用提示来配置它们会非常方便，因为我们从 planner 得到的规划元数据往往不是那么准确。
运算符资源约束：对于很多情况，我们会给执行运算符一个默认的资源配置，比如最小并行或管理内存（耗费资源的 UDF）或特殊的资源需求（GPU 或 SSD 磁盘）等等，用提示对每个查询（而不是 Job）的资源进行配置会非常灵活。</p>
<h2 id="动态表选项">动态表选项</h2>
<p>动态表选项允许动态指定或覆盖表选项，与 SQL DDL 或连接 API 定义的静态表选项不同，这些选项可以在每个查询中的每个表范围内灵活指定。</p>
<p>因此，它非常适用于交互式终端的临时查询，例如，在 SQL-CLI 中，只需添加一个动态选项 <code>/*+ OPTIONS('csv.ignore-parse-errors'='true') */</code>，就可以指定忽略 CSV 源的解析错误。</p>
<p>注意：动态表选项默认是禁止使用的，因为它可能会改变查询的语义。您需要将配置选项 table.dynamic-table-options.enabled 显式地设置为 true（默认为 false），有关如何设置配置选项的详细信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html">配置</a>。</p>
<h3 id="语法">语法</h3>
<p>为了不破坏 SQL 的兼容性，我们使用 Oracle 风格的 SQL 提示语法。</p>
<pre><code>table_path /*+ OPTIONS(key=val [, key=val]*) */

key:
    stringLiteral
val:
    stringLiteral
</code></pre><h3 id="例子">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_table1</span> <span class="p">(</span><span class="n">id</span> <span class="nb">BIGINT</span><span class="p">,</span> <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(...);</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_table2</span> <span class="p">(</span><span class="n">id</span> <span class="nb">BIGINT</span><span class="p">,</span> <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(...);</span>

<span class="c1">-- override table options in query source
</span><span class="c1"></span><span class="k">select</span> <span class="n">id</span><span class="p">,</span> <span class="n">name</span> <span class="k">from</span> <span class="n">kafka_table1</span> <span class="cm">/*+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) */</span><span class="p">;</span>

<span class="c1">-- override table options in join
</span><span class="c1"></span><span class="k">select</span> <span class="o">*</span> <span class="k">from</span>
    <span class="n">kafka_table1</span> <span class="cm">/*+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) */</span> <span class="n">t1</span>
    <span class="k">join</span>
    <span class="n">kafka_table2</span> <span class="cm">/*+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) */</span> <span class="n">t2</span>
    <span class="k">on</span> <span class="n">t1</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">t2</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>

<span class="c1">-- override table options for INSERT target table
</span><span class="c1"></span><span class="k">insert</span> <span class="k">into</span> <span class="n">kafka_table1</span> <span class="cm">/*+ OPTIONS(&#39;sink.partitioner&#39;=&#39;round-robin&#39;) */</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">kafka_table2</span><span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Table API</blockquote><h1 id="table-api">Table API</h1>
<p>表 API 是一个统一的关系型 API，用于流处理和批处理。Table API 查询可以在批处理或流处理输入上运行，无需修改。Table API 是 SQL 语言的超级集，是专门为 Apache Flink 工作而设计的。Table API 是 Scala、Java 和 Python 的语言集成 API。Table API 查询不是像 SQL 那样以字符串值的方式指定查询，而是以语言嵌入的方式在 Java、Scala 或 Python 中定义查询，并支持自动完成和语法验证等 IDE。</p>
<p>Table API 与 Flink 的 SQL 集成共享许多概念和部分 API。请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">通用概念</a>和 API，了解如何注册表或创建表对象。<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">流概念</a>页面讨论了流的具体概念，如动态表和<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>。</p>
<p>下面的例子假设一个名为 Orders 的注册表具有属性（a, b, c, rowtime）。rowtime 字段在流式中是一个逻辑<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>，在批处理中是一个常规的时间戳字段。</p>
<h2 id="概述和示例">概述和示例</h2>
<p>Table API 可用于 Scala、Java 和 Python。Scala Table API 利用的是 Scala 表达式，Java Table API 既支持 Expression DSL，也支持解析并转换为等价表达式的字符串，Python Table API 目前只支持解析并转换为等价表达式的字符串。</p>
<p>下面的例子显示了 Scala、Java 和 Python Table API 之间的差异。表程序是在批处理环境中执行的。它扫描 Orders 表，按字段 a 分组，并计算每组的结果行。</p>
<p>通过导入 <code>org.apache.flink.table.api._</code>、<code>org.apache.flink.api.scala._</code> 和 <code>org.apache.flink.table.api.bridge.scala._</code>（用于桥接到/来自 DataStream）来启用 Scala Table API。</p>
<p>下面的例子展示了 Scala Table API 程序是如何构造的。表字段使用 Scala 的字符串插值，使用美元字符（<code>$</code>）引用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala._</span>

<span class="c1">// environment configuration
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register Orders table in table environment
</span><span class="c1">// ...
</span><span class="c1"></span>
<span class="c1">// specify table program
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span> <span class="c1">// schema (a, b, c, rowtime)
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
               <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
               <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">count</span> <span class="n">as</span> <span class="s">&#34;cnt&#34;</span><span class="o">)</span>
               <span class="o">.</span><span class="n">toDataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="c1">// conversion to DataSet
</span><span class="c1"></span>               <span class="o">.</span><span class="n">print</span><span class="o">()</span>
</code></pre></div><p>下一个例子显示了一个更复杂的 Table API 程序。该程序再次扫描 Orders 表，过滤空值，对类型为 String 的字段 a 进行归一化处理，并为每个小时和产品 a 计算平均计费金额 b。它过滤空值，对类型为 String 的字段 a 进行标准化，并为每个小时和产品 a 计算平均账单金额 b。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// environment configuration
</span><span class="c1">// ...
</span><span class="c1"></span>
<span class="c1">// specify table program
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span> <span class="c1">// schema (a, b, c, rowtime)
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
        <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">isNotNull</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">isNotNull</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">.</span><span class="n">isNotNull</span><span class="o">)</span>
        <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">lowerCase</span><span class="o">()</span> <span class="n">as</span> <span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">1.</span><span class="n">hour</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;hourlyWindow&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;hourlyWindow&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;hourlyWindow&#34;</span><span class="o">.</span><span class="n">end</span> <span class="n">as</span> <span class="s">&#34;hour&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span> <span class="n">as</span> <span class="s">&#34;avgBillingAmount&#34;</span><span class="o">)</span>
</code></pre></div><p>由于表 API 是针对批处理和流数据的统一 API，所以这两个示例程序都可以在批处理和流输入上执行，而不需要对表程序本身进行任何修改。在这两种情况下，考虑到流式记录不会迟到，程序会产生相同的结果（详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">流概念</a>）。</p>
<h2 id="操作">操作</h2>
<p>表 API 支持以下操作。请注意，并不是所有的操作都能在批处理和流式处理中使用，它们都有相应的标签。</p>
<h3 id="scan-projection-和-filter">Scan, Projection 和 Filter</h3>
<ul>
<li>From(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 FROM 子句。执行对注册的表的扫描。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Values(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 VALUES 子句。从提供的行中产生一个内联表。</p>
<p>你可以使用 <code>row(...)</code> 表达式来创建复合行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromValues</span><span class="o">(</span>
   <span class="n">row</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;ABC&#34;</span><span class="o">),</span>
   <span class="n">row</span><span class="o">(</span><span class="mi">2L</span><span class="o">,</span> <span class="s">&#34;ABCDE&#34;</span><span class="o">)</span>
<span class="o">)</span>
</code></pre></div><p>将产生一个模式(schema)如下的表。</p>
<pre><code>root
|-- f0: BIGINT NOT NULL     // original types INT and BIGINT are generalized to BIGINT
|-- f1: VARCHAR(5) NOT NULL // original types CHAR(3) and CHAR(5) are generalized
                            // to VARCHAR(5). VARCHAR is used instead of CHAR so that
                            // no padding is applied
</code></pre><p>该方法将从输入的表达式中自动得出类型，如果某个位置的类型不同，该方法将尝试为所有类型找到共同的超级类型。如果某个位置的类型不同，方法将尝试为所有类型找到一个共同的超级类型。如果一个共同的超级类型不存在，将抛出一个异常。</p>
<p>您也可以明确地指定请求的类型。这可能对分配更多的通用类型（如 DECIMAL）或为列命名很有帮助。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromValues</span><span class="o">(</span>
    <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span>
        <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">FIELD</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">DECIMAL</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">2</span><span class="o">)),</span>
        <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">FIELD</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>
    <span class="o">),</span>
    <span class="n">row</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;ABC&#34;</span><span class="o">),</span>
    <span class="n">row</span><span class="o">(</span><span class="mi">2L</span><span class="o">,</span> <span class="s">&#34;ABCDE&#34;</span><span class="o">)</span>
<span class="o">)</span>
</code></pre></div><p>将产生一个模式(schema)如下的表。</p>
<pre><code>root
|-- id: DECIMAL(10, 2)
|-- name: STRING
</code></pre><ul>
<li>Select(Batch/Streaming)</li>
</ul>
<p>类似于 SQL SELECT 语句。执行选择操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
</code></pre></div><p>你可以使用星号（<code>*</code>）作为通配符，选择表中所有的列。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;*&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>As(Batch/Streaming)</li>
</ul>
<p>重新命名字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">,</span> <span class="s">&#34;z&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Where / Filter(Batch/Streaming)</li>
</ul>
<p>类似于 SQL WHERE 子句。过滤掉没有通过过滤谓词的记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">===</span> <span class="mi">0</span><span class="o">)</span>
</code></pre></div><p>或:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span> <span class="o">===</span> <span class="s">&#34;red&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="列操作">列操作</h3>
<ul>
<li>AddColumns(Batch/Streaming)</li>
</ul>
<p>执行字段添加操作。如果添加的字段已经存在，它将抛出一个异常。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">addColumns</span><span class="o">(</span><span class="n">concat</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="s">&#34;Sunny&#34;</span><span class="o">))</span>
</code></pre></div><ul>
<li>AddOrReplaceColumns(Batch/Streaming)</li>
</ul>
<p>执行字段添加操作。如果添加的列名与现有的列名相同，那么现有的字段将被替换。此外，如果添加的字段名与现有字段名重复，则使用最后一个字段名。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">addOrReplaceColumns</span><span class="o">(</span><span class="n">concat</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="s">&#34;Sunny&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;desc&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>DropColumns(Batch/Streaming)</li>
</ul>
<p>执行字段删除操作。字段表达式应该是字段引用表达式，并且只能删除现有的字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">dropColumns</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>RenameColumns(Batch/Streaming)</li>
</ul>
<p>执行字段重命名操作。字段表达式应为别名表达式，且只能对现有字段进行重命名。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">renameColumns</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span> <span class="n">as</span> <span class="s">&#34;b2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span> <span class="n">as</span> <span class="s">&#34;c2&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="聚合aggregations">聚合(Aggregations)</h3>
<ul>
<li>GroupBy 聚合(Batch/Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 GROUP BY 子句。将分组键上的行与下面的运行聚合操作符进行分组，以分组方式聚合行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">().</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;d&#34;</span><span class="o">))</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会无限增长，这取决于聚合的类型和不同分组键的数量。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>GroupBy 窗口聚合(Batch/Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能的一个或多个分组键上对一个表进行分组和聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span> <span class="c1">// access window properties and aggregate
</span></code></pre></div><ul>
<li>Over 窗口聚合(Streaming)</li>
</ul>
<p>类似于 SQL OVER 子句。根据前后记录的窗口(范围)，为每条记录计算 OVER 窗口汇总。更多细节请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#over-windows">over 窗口</a>部分。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
    <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">window</span><span class="o">(</span>
        <span class="nc">Over</span>
          <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span>
          <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span>
          <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span>
          <span class="n">following</span> <span class="nc">CURRENT_RANGE</span>
          <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">max</span><span class="o">().</span><span class="n">over</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">),</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">min</span><span class="o">().</span><span class="n">over</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">))</span> <span class="c1">// sliding aggregate
</span></code></pre></div><p>注意：所有的聚合必须定义在同一个窗口上，即相同的分区、排序和范围。目前，只支持对 CURRENT ROW 范围的 PRECEDING（UNBOUNDED 和 bounded）窗口。还不支持带 FOLLOWING 的范围。ORDER BY 必须在单个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>上指定。</p>
<ul>
<li>Distinct 聚合(Batch Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 DISTINCT AGGREGATION 子句，如 <code>COUNT(DISTINCT a)</code>。Distinct 聚合声明一个聚合函数（内置的或用户定义的）只应用在不同的输入值上，Distinct 可以应用于 GroupBy 聚合，GroupBy 窗口聚合和 Over 窗口聚合。Distinct 可以应用于 GroupBy 聚合、GroupBy 窗口聚合和 Over 窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>
<span class="c1">// Distinct aggregation on group by
</span><span class="c1"></span><span class="k">val</span> <span class="n">groupByDistinctResult</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">distinct</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
<span class="c1">// Distinct aggregation on time window group by
</span><span class="c1"></span><span class="k">val</span> <span class="n">groupByWindowDistinctResult</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">).</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">distinct</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
<span class="c1">// Distinct aggregation on over window
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span>
        <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span>
        <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span>
        <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span>
        <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span><span class="o">.</span><span class="n">distinct</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">max</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">min</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><p>用户自定义的聚合函数也可以与 DISTINCT 修饰符一起使用。如果只计算不同值的聚合结果，只需在聚合函数中添加 distinct 修饰符即可。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">);</span>

<span class="c1">// Use distinct aggregation for user-defined aggregate functions
</span><span class="c1"></span><span class="k">val</span> <span class="n">myUdagg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyUdagg</span><span class="o">();</span>
<span class="n">orders</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;users&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;users&#34;</span><span class="o">,</span> <span class="n">myUdagg</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;points&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;myDistinctResult&#34;</span><span class="o">);</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Distinct(Batch Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 DISTINCT 子句。返回具有不同值组合的记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">distinct</span><span class="o">()</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。如果启用了状态清洗功能，Distinct 必须发出消息，以防止下游操作者过早地驱逐状态，从而使 Distinct 包含结果更新。详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="joins">Joins</h3>
<ul>
<li>Inner Join(Batch/Streaming)</li>
</ul>
<p>类似于 SQL JOIN 子句。连接两个表。两个表必须有不同的字段名，并且必须通过 join 操作符或使用 where 或 filter 操作符定义至少一个平等连接谓词。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">right</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Outer Join(Batch/Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL LEFT/RIGHT/FULL OUTER JOIN 子句。连接两个表。两个表必须有不同的字段名，并且必须定义至少一个平等连接谓词。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataSet</span><span class="o">(</span><span class="n">ds1</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataSet</span><span class="o">(</span><span class="n">ds2</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">leftOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">leftOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">rightOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">fullOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">fullOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Interval Join(Batch/Streaming)</li>
</ul>
<p>注：区间连接是常规连接的一个子集，可以用流式处理。</p>
<p>一个区间连接至少需要一个等价连接谓词和一个连接条件，以限制双方的时间。这样的条件可以由两个合适的范围谓词（&lt;，&lt;=，&gt;=，&gt;）或一个比较两个输入表的相同类型的<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>（即处理时间或事件时间）的单一平等谓词来定义。</p>
<p>例如，以下谓词是有效的区间连接条件。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span>
<span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&gt;=</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&lt;</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">+</span> <span class="mf">10.</span><span class="n">minutes</span>
<span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
  <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&gt;=</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">-</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&lt;</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">+</span> <span class="mf">10.</span><span class="n">minutes</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Inner Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每条记录都与相应的表函数调用所产生的所有记录合并。如果左（外）表的表函数调用返回的结果是空的，则放弃该表的某行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate User-Defined Table Function
</span><span class="c1"></span><span class="k">val</span> <span class="n">split</span><span class="k">:</span> <span class="kt">TableFunction</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySplitUDTF</span><span class="o">()</span>

<span class="c1">// join
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">table</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">split</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="s">&#34;v&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Left Outer Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每一行都与相应的表函数调用所产生的所有行相连接。如果表函数调用返回的结果为空，则保留相应的外侧行，并将结果用空值填充。</p>
<p>注意：目前，表函数左外侧连接的谓词只能是空或字面为真。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate User-Defined Table Function
</span><span class="c1"></span><span class="k">val</span> <span class="n">split</span><span class="k">:</span> <span class="kt">TableFunction</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySplitUDTF</span><span class="o">()</span>

<span class="c1">// join
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">table</span>
    <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">split</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="s">&#34;v&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Join with Temporal Table(Streaming)</li>
</ul>
<p><a href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables">时间表</a>是跟踪其随时间变化的表。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>提供了对时间表在特定时间点的状态的访问。用时态表函数连接表的语法与带表函数的内部连接中的语法相同。</p>
<p>目前只支持与时态表的内联接。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">ratesHistory</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;RatesHistory&#34;</span><span class="o">)</span>

<span class="c1">// register temporal table function with a time attribute and primary key
</span><span class="c1"></span><span class="k">val</span> <span class="n">rates</span> <span class="k">=</span> <span class="n">ratesHistory</span><span class="o">.</span><span class="n">createTemporalTableFunction</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;r_proctime&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span><span class="o">)</span>

<span class="c1">// join with &#34;Orders&#34; based on the time attribute and key
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">rates</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;o_rowtime&#34;</span><span class="o">),</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;o_currency&#34;</span><span class="o">)</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables">时间表概念说明</a>。</p>
<h3 id="集合操作">集合操作</h3>
<ul>
<li>Union(Batch)</li>
</ul>
<p>类似于 SQL UNION 子句。将两个表联合起来，去除重复记录，两个表必须有相同的字段类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>UnionAll(Batch/Streaming)</li>
</ul>
<p>类似于 SQL UNION ALL 子句。联合两个表，两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>Intersect(Batch)</li>
</ul>
<p>类似于 SQL INTERSECT 子句。Intersect 子句返回的是两个表中都存在的记录。如果一条记录在一个表或两个表中存在一次以上，则只返回一次，即结果表没有重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;g&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">intersect</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>IntersectAll(Batch)</li>
</ul>
<p>类似于 SQL 的 INTERSECT ALL 子句。IntersectAll 子句返回两个表中都存在的记录。如果一条记录在两张表中都存在一次以上，那么就会按照它在两张表中存在的次数来返回，也就是说，得到的表可能有重复的记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;g&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">intersectAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>Minus(Batch)</li>
</ul>
<p>类似于 SQL EXCEPT 子句。Minus 返回左表中不存在于右表中的记录。左表中的重复记录只返回一次，即删除重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">minus</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>MinusAll(Batch)</li>
</ul>
<p>类似于 SQL EXCEPT ALL 子句。MinusAll 子句返回右表中不存在的记录。一条记录在左表中出现 n 次，在右表中出现 m 次，则返回(n - m)次，即删除右表中存在的重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">minusAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>In(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 的 IN 子句。如果一个表达式存在于给定的表子查询中，In 子句返回 true。子查询表必须由一列组成。该列必须与表达式具有相同的数据类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">in</span><span class="o">(</span><span class="n">right</span><span class="o">))</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="orderby-offset-和-fetch">OrderBy, Offset 和 Fetch</h3>
<ul>
<li>Order By(Batch)</li>
</ul>
<p>类似于 SQL ORDER BY 子句。返回所有平行分区的全局排序记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">)</span>
</code></pre></div><ul>
<li>Offset 和 Fetch(Batch)</li>
</ul>
<p>类似于 SQL 的 OFFSET 和 FETCH 子句。Offset 和 Fetch 限制了排序结果中返回的记录数量。Offset 和 Fetch 在技术上是 Order By 操作符的一部分，因此必须在它前面。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>

<span class="c1">// returns the first 5 records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">).</span><span class="n">fetch</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="c1">// skips the first 3 records and returns all following records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">).</span><span class="n">offset</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="c1">// skips the first 10 records and returns the next 5 records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result3</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">).</span><span class="n">offset</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="n">fetch</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</code></pre></div><h3 id="insert">Insert</h3>
<ul>
<li>Insert Into(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 <code>INSERT INTO</code> 子句，该方法执行插入到一个注册的输出表中。<code>executeInsert()</code> 方法将立即提交一个执行插入操作的 Flink 作业。</p>
<p>输出表必须在 TableEnvironment 中注册（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#connector-tables">连接器表</a>）。此外，注册表的模式必须与查询的模式相匹配。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="n">orders</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;OutOrders&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="group-窗口">Group 窗口</h3>
<p>分组窗口根据时间或行数间隔将分组行汇总成有限的组，每组评估一次汇总函数。对于批处理表来说，窗口是按时间间隔对记录进行分组的便捷捷径。</p>
<p>窗口是使用 window(w: GroupWindow)子句定义的，并且需要一个别名，这个别名是使用 as 子句指定的。为了通过窗口对表进行分组，必须在 groupBy(&hellip;)子句中像常规分组属性一样引用窗口别名。下面的例子展示了如何在表上定义窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">([</span><span class="kt">w:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>  <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>   <span class="c1">// group the table by window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>  <span class="c1">// aggregate
</span></code></pre></div><p>在流式环境中，只有当窗口聚合除窗口外还对一个或多个属性进行分组时，才能并行计算，即 groupBy(&hellip;)子句引用了一个窗口别名和至少一个附加属性。仅引用窗口别名的 groupBy(&hellip;) 子句（如上面的例子）只能由单个非并行任务来评估。下面的示例显示了如何定义具有附加分组属性的窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">([</span><span class="kt">w:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>  <span class="c1">// group the table by attribute a and window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>  <span class="c1">// aggregate
</span></code></pre></div><p>窗口属性，如时间窗口的开始、结束或行时间戳，可以在选择语句中作为窗口别名的属性，分别添加为 w.start、w.end 和 w.rowtime。窗口开始时间和行时间时间戳是包含的窗口下界和上界。相反，窗口结束时间戳是专属的上层窗口边界。例如一个从下午 2 点开始的 30 分钟的翻滚窗口，其起始时间戳为 14:00:00.000，行时时间戳为 14:29:59.999，结束时间戳为 14:30:00.000。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">([</span><span class="kt">w:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>  <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>  <span class="c1">// group the table by attribute a and window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">count</span><span class="o">)</span> <span class="c1">// aggregate and add window start, end, and rowtime timestamps
</span></code></pre></div><p>窗口参数定义了如何将行映射到窗口。Window 不是一个用户可以实现的接口。相反，Table API 提供了一组具有特定语义的预定义 Window 类，它们被翻译成底层的 DataStream 或 DataSet 操作。下面列出了支持的窗口定义。</p>
<h4 id="滚动窗口">滚动窗口</h4>
<p>滚动窗口将行分配到固定长度的非重叠的连续窗口。例如，5 分钟的滚动窗口以 5 分钟的间隔将行分组。滚动窗口可以在事件时间、处理时间或行数上定义。</p>
<p>滚动窗口可以通过使用 Tumble 类来定义，具体如下。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">over</td>
<td style="text-align:left">定义窗口的长度，可以是时间或行数间隔。</td>
</tr>
<tr>
<td style="text-align:left">on</td>
<td style="text-align:left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td style="text-align:left">as</td>
<td style="text-align:left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Tumbling Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Tumbling Processing-time Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Tumbling Row-count Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="slide-滑动窗口">Slide (滑动窗口)</h4>
<p>滑动窗口有一个固定的尺寸，并按指定的滑动间隔滑动，如果滑动间隔小于窗口尺寸，滑动窗口就会重叠。如果滑动间隔小于窗口大小，滑动窗口就会重叠。因此，行可以分配给多个窗口。例如，一个 15 分钟大小和 5 分钟滑动间隔的滑动窗口将每行分配到 3 个不同的 15 分钟大小的窗口，这些窗口以 5 分钟的间隔进行评估。滑动窗口可以在事件时间、处理时间或行数上定义。</p>
<p>滑动窗口是通过使用 Slide 类来定义的，具体如下。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">over</td>
<td style="text-align:left">定义窗口的长度，可以是时间或行数间隔。</td>
</tr>
<tr>
<td style="text-align:left">every</td>
<td style="text-align:left">定义滑动间隔，可以是时间间隔或行数间隔。缩放间隔的类型必须与尺寸间隔相同。</td>
</tr>
<tr>
<td style="text-align:left">on</td>
<td style="text-align:left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td style="text-align:left">as</td>
<td style="text-align:left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Sliding Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Sliding Processing-time window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Sliding Row-count window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">rows</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="session-会话窗口">Session (会话窗口)</h4>
<p>会话窗口没有固定的大小，但它们的界限是由不活动的时间间隔来定义的，也就是说，如果在定义的间隙期没有事件出现，会话窗口就会被关闭。例如，有 30 分钟间隔的会话窗口在 30 分钟不活动后观察到一行时开始（否则该行将被添加到现有的窗口中），如果在 30 分钟内没有行被添加，则关闭。会话窗口可以在事件时间或处理时间工作。</p>
<p>通过使用 Session 类定义会话窗口，如下所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">withGap</td>
<td style="text-align:left">将两个窗口之间的间隔定义为时间间隔。</td>
</tr>
<tr>
<td style="text-align:left">on</td>
<td style="text-align:left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td style="text-align:left">as</td>
<td style="text-align:left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Session Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Session</span> <span class="n">withGap</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Session Processing-time Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Session</span> <span class="n">withGap</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="over-窗口">Over 窗口</h3>
<p>Over 窗口聚合是从标准 SQL（over 子句）中得知的，并在查询的 SELECT 子句中定义。与组窗口不同的是，组窗口是在 GROUP BY 子句中指定的，over 窗口不折叠行。相反，over 窗口聚合计算的是每条输入行在其相邻行的范围内的聚合。</p>
<p>Over 窗口是使用 window(w: OverWindow*)子句来定义的(在 Python API 中使用 over_window(*OverWindow))，并且在 select()方法中通过别名来引用。下面的例子展示了如何在表上定义一个 <code>over</code> 窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">([</span><span class="kt">w:</span> <span class="kt">OverWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>              <span class="c1">// define over window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">.</span><span class="n">min</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// aggregate over the over window w
</span></code></pre></div><p>OverWindow 定义了计算汇总的行的范围。OverWindow 不是一个用户可以实现的接口。相反，Table API 提供了 Over 类来配置 over 窗口的属性。Over 窗口可以在事件时间或处理时间上定义，也可以在指定为时间间隔或行数的范围上定义。支持的 over 窗口定义是以 Over（和其他类）上的方法暴露出来的，下面列出了这些方法。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法</th>
<th style="text-align:left">Required</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">partitionBy</td>
<td style="text-align:left">Optional</td>
<td style="text-align:left">定义输入的一个或多个属性的分区。每个分区都被单独排序，聚合函数被分别应用到每个分区。注意：在流环境中，只有当窗口包含 partitionBy 子句时，才能并行计算 over window aggregates。如果没有 partitionBy(&hellip;)，流就会被一个单一的、非并行的任务处理。</td>
</tr>
<tr>
<td style="text-align:left">orderBy</td>
<td style="text-align:left">Required</td>
<td style="text-align:left">定义每个分区中行的顺序，从而定义聚合函数应用到行的顺序。注意：对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。目前，只支持单个排序属性。</td>
</tr>
<tr>
<td style="text-align:left">preceding</td>
<td style="text-align:left">Optional</td>
<td style="text-align:left">定义包含在窗口中并在当前行之前的行的间隔。这个间隔可以指定为时间间隔或行数间隔。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#bounded-over-windows">有边界的窗口</a>用间隔的大小来指定，例如，时间间隔为 10.分钟，行数间隔为 10.行。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#unbounded-over-windows">无边界的窗口</a>用一个常数来指定，例如，时间间隔为 UNBOUNDED_RANGE，行数间隔为 UNBOUNDED_ROW。未绑定的窗口从分区的第一行开始。如果省略了前面的子句，UNBOUNDED_RANGE 和 CURRENT_RANGE 被用作窗口的默认前后。</td>
</tr>
<tr>
<td style="text-align:left">following</td>
<td style="text-align:left">Optional</td>
<td style="text-align:left">定义包含在窗口中并跟随当前行的行的窗口间隔。这个间隔必须与前一个间隔的单位（时间或行数）相同。目前，不支持在当前行之后添加行的窗口。您可以指定两个常量中的一个。CURRENT_ROW 将窗口的上界设置为当前行。CURRENT_RANGE 将窗口的上界设置为当前行的排序键，也就是说，所有与当前行具有相同排序键的行都包含在窗口中。如果省略下面的子句，时间间隔窗口的上界定义为 CURRENT_RANGE，行数间隔窗口的上界定义为 CURRENT_ROW。</td>
</tr>
<tr>
<td style="text-align:left">as</td>
<td style="text-align:left">Required</td>
<td style="text-align:left">为 over 窗口指定一个别名。该别名用于在下面的 select()子句中引用 over 窗口。</td>
</tr>
</tbody>
</table>
<p>注意：目前，在同一个 select()调用中，所有的聚合函数都必须在同一个 over 窗口中计算。</p>
<h4 id="unbounded-over-windows">Unbounded Over Windows</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Unbounded Event-time over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Unbounded Processing-time over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Unbounded Event-time Row-count over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_ROW</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
 
<span class="c1">// Unbounded Processing-time Row-count over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_ROW</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="bounded-over-windows">Bounded Over Windows</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Bounded Event-time over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="mf">1.</span><span class="n">minutes</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Bounded Processing-time over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="mf">1.</span><span class="n">minutes</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Bounded Event-time Row-count over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
  
<span class="c1">// Bounded Processing-time Row-count over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="基于行的操作">基于行的操作</h3>
<p>基于行的操作产生多列的输出。</p>
<ul>
<li>Map(Batch/Streaming)</li>
</ul>
<p>使用用户定义的标量函数或内置的标量函数执行 map 操作。如果输出类型是复合类型，则输出将被扁平化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyMapFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="s">&#34;pre-&#34;</span> <span class="o">+</span> <span class="n">a</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="o">(</span><span class="n">signature</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Class</span><span class="o">[</span><span class="k">_</span><span class="o">]])</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span>
    <span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">func</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMapFunction</span><span class="o">()</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">func</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>FlatMap(Batch/Streaming)</li>
</ul>
<p>用表格函数执行 <code>flatMap</code> 操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyFlatMapFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&#34;#&#34;</span><span class="o">))</span> <span class="o">{</span>
      <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;#&#34;</span><span class="o">).</span><span class="n">foreach</span><span class="o">({</span> <span class="n">s</span> <span class="k">=&gt;</span>
        <span class="k">val</span> <span class="n">row</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Row</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
        <span class="n">row</span><span class="o">.</span><span class="n">setField</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">s</span><span class="o">)</span>
        <span class="n">row</span><span class="o">.</span><span class="n">setField</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">length</span><span class="o">)</span>
        <span class="n">collect</span><span class="o">(</span><span class="n">row</span><span class="o">)</span>
      <span class="o">})</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">func</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyFlatMapFunction</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">func</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Aggregate(Batch/Streaming/Result Updating)</li>
</ul>
<p>用一个聚合函数执行一个聚合操作。必须用 select 语句关闭&quot;聚合&quot;，select 语句不支持聚合函数。如果输出类型是复合类型，聚合的输出将被扁平化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">MyMinMaxAcc</span><span class="o">(</span><span class="k">var</span> <span class="n">min</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="k">var</span> <span class="n">max</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">class</span> <span class="nc">MyMinMax</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">Row</span>, <span class="kt">MyMinMaxAcc</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">value</span> <span class="o">&lt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">min</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">min</span> <span class="k">=</span> <span class="n">value</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">value</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">max</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">max</span> <span class="k">=</span> <span class="n">value</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span> <span class="o">=</span> <span class="nc">MyMinMaxAcc</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span>

  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">min</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">max</span> <span class="k">=</span> <span class="mi">0</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">min</span><span class="o">),</span> <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">max</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">RowTypeInfo</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">myAggFunc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMinMax</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="n">myAggFunc</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;y&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Group 窗口聚合(Batch/Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能的一个或多个分组键上对一个表进行分组和聚合。你必须用 select 语句关闭&quot;聚合&quot;。而且选择语句不支持 &ldquo;*&rdquo; 或聚合函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">myAggFunc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMinMax</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="n">myAggFunc</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;y&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">)</span> <span class="c1">// access window properties and aggregate results
</span></code></pre></div><ul>
<li>FlatAggregate(Streaming/Result Updating)</li>
</ul>
<p>类似于 GroupBy 聚合。将分组键上的行与下面的运行表聚合运算符进行分组，将行进行分组。与 AggregateFunction 的不同之处在于，TableAggregateFunction 可以为一个组返回 0 条或多条记录。你必须用 select 语句关闭 &ldquo;flatAggregate&rdquo;。而 select 语句不支持聚合函数。</p>
<p>不使用 emitValue 输出结果，还可以使用 emitUpdateWithRetract 方法。与 emitValue 不同的是，emitUpdateWithRetract 用于输出已经更新的值。这个方法以回缩模式增量输出数据，也就是说，一旦有更新，我们必须在发送新的更新记录之前回缩旧的记录。如果在表聚合函数中定义了 emitUpdateWithRetract 方法，那么 emitUpdateWithRetract 方法将优先于 emitValue 方法使用，因为该方法被视为比 emitValue 更有效，因为它可以增量输出值。详见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html#table-aggregation-functions">表聚合函数</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/**
</span><span class="cm"> * Accumulator for top2.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * The top2 user-defined table aggregate function.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">JIterable</span><span class="o">[</span><span class="kt">Top2Accum</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">its</span><span class="o">.</span><span class="n">iterator</span><span class="o">()</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">first</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">second</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// emit the value and rank
</span><span class="c1"></span>    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2</span>
<span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会无限增长，这取决于聚合的类型和不同分组键的数量。请提供具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请参见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Group Window FlatAggregate(Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能一个或多个分组键上对一个表进行分组和聚合。你必须用 select 语句关闭 &ldquo;flatAggregate&rdquo;。而 select 语句不支持聚合函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2</span>
<span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">w</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span> <span class="c1">// access window properties and aggregate results
</span></code></pre></div><h2 id="数据类型">数据类型</h2>
<p>请看关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的专门页面。</p>
<p>通用类型和(嵌套的)复合类型(例如 POJOs、tuple、行、Scala case 类)也可以是行的字段。</p>
<p>具有任意嵌套的复合类型的字段可以用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html#value-access-functions">值访问函数</a>来访问。</p>
<p>通用类型被视为一个黑盒，可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>进行传递或处理。</p>
<h2 id="表达式语法">表达式语法</h2>
<p>前面几节中的一些操作符都期望有一个或多个表达式。表达式可以使用内嵌的 Scala DSL 或作为字符串来指定。请参考上面的例子来了解如何指定表达式。</p>
<p>这是表达式的 EBNF 语法。</p>
<pre><code>expressionList = expression , { &quot;,&quot; , expression } ;

expression = overConstant | alias ;

alias = logic | ( logic , &quot;as&quot; , fieldReference ) | ( logic , &quot;as&quot; , &quot;(&quot; , fieldReference , { &quot;,&quot; , fieldReference } , &quot;)&quot; ) ;

logic = comparison , [ ( &quot;&amp;&amp;&quot; | &quot;||&quot; ) , comparison ] ;

comparison = term , [ ( &quot;=&quot; | &quot;==&quot; | &quot;===&quot; | &quot;!=&quot; | &quot;!==&quot; | &quot;&gt;&quot; | &quot;&gt;=&quot; | &quot;&lt;&quot; | &quot;&lt;=&quot; ) , term ] ;

term = product , [ ( &quot;+&quot; | &quot;-&quot; ) , product ] ;

product = unary , [ ( &quot;*&quot; | &quot;/&quot; | &quot;%&quot;) , unary ] ;

unary = [ &quot;!&quot; | &quot;-&quot; | &quot;+&quot; ] , composite ;

composite = over | suffixed | nullLiteral | prefixed | atom ;

suffixed = interval | suffixAs | suffixCast | suffixIf | suffixDistinct | suffixFunctionCall | timeIndicator ;

prefixed = prefixAs | prefixCast | prefixIf | prefixDistinct | prefixFunctionCall ;

interval = timeInterval | rowInterval ;

timeInterval = composite , &quot;.&quot; , (&quot;year&quot; | &quot;years&quot; | &quot;quarter&quot; | &quot;quarters&quot; | &quot;month&quot; | &quot;months&quot; | &quot;week&quot; | &quot;weeks&quot; | &quot;day&quot; | &quot;days&quot; | &quot;hour&quot; | &quot;hours&quot; | &quot;minute&quot; | &quot;minutes&quot; | &quot;second&quot; | &quot;seconds&quot; | &quot;milli&quot; | &quot;millis&quot;) ;

rowInterval = composite , &quot;.&quot; , &quot;rows&quot; ;

suffixCast = composite , &quot;.cast(&quot; , dataType , &quot;)&quot; ;

prefixCast = &quot;cast(&quot; , expression , dataType , &quot;)&quot; ;

dataType = &quot;BYTE&quot; | &quot;SHORT&quot; | &quot;INT&quot; | &quot;LONG&quot; | &quot;FLOAT&quot; | &quot;DOUBLE&quot; | &quot;BOOLEAN&quot; | &quot;STRING&quot; | &quot;DECIMAL&quot; | &quot;SQL_DATE&quot; | &quot;SQL_TIME&quot; | &quot;SQL_TIMESTAMP&quot; | &quot;INTERVAL_MONTHS&quot; | &quot;INTERVAL_MILLIS&quot; | ( &quot;MAP&quot; , &quot;(&quot; , dataType , &quot;,&quot; , dataType , &quot;)&quot; ) | ( &quot;PRIMITIVE_ARRAY&quot; , &quot;(&quot; , dataType , &quot;)&quot; ) | ( &quot;OBJECT_ARRAY&quot; , &quot;(&quot; , dataType , &quot;)&quot; ) ;

suffixAs = composite , &quot;.as(&quot; , fieldReference , &quot;)&quot; ;

prefixAs = &quot;as(&quot; , expression, fieldReference , &quot;)&quot; ;

suffixIf = composite , &quot;.?(&quot; , expression , &quot;,&quot; , expression , &quot;)&quot; ;

prefixIf = &quot;?(&quot; , expression , &quot;,&quot; , expression , &quot;,&quot; , expression , &quot;)&quot; ;

suffixDistinct = composite , &quot;distinct.()&quot; ;

prefixDistinct = functionIdentifier , &quot;.distinct&quot; , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

suffixFunctionCall = composite , &quot;.&quot; , functionIdentifier , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

prefixFunctionCall = functionIdentifier , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

atom = ( &quot;(&quot; , expression , &quot;)&quot; ) | literal | fieldReference ;

fieldReference = &quot;*&quot; | identifier ;

nullLiteral = &quot;nullOf(&quot; , dataType , &quot;)&quot; ;

timeIntervalUnit = &quot;YEAR&quot; | &quot;YEAR_TO_MONTH&quot; | &quot;MONTH&quot; | &quot;QUARTER&quot; | &quot;WEEK&quot; | &quot;DAY&quot; | &quot;DAY_TO_HOUR&quot; | &quot;DAY_TO_MINUTE&quot; | &quot;DAY_TO_SECOND&quot; | &quot;HOUR&quot; | &quot;HOUR_TO_MINUTE&quot; | &quot;HOUR_TO_SECOND&quot; | &quot;MINUTE&quot; | &quot;MINUTE_TO_SECOND&quot; | &quot;SECOND&quot; ;

timePointUnit = &quot;YEAR&quot; | &quot;MONTH&quot; | &quot;DAY&quot; | &quot;HOUR&quot; | &quot;MINUTE&quot; | &quot;SECOND&quot; | &quot;QUARTER&quot; | &quot;WEEK&quot; | &quot;MILLISECOND&quot; | &quot;MICROSECOND&quot; ;

over = composite , &quot;over&quot; , fieldReference ;

overConstant = &quot;current_row&quot; | &quot;current_range&quot; | &quot;unbounded_row&quot; | &quot;unbounded_row&quot; ;

timeIndicator = fieldReference , &quot;.&quot; , ( &quot;proctime&quot; | &quot;rowtime&quot; ) ;
</code></pre><p>字符。在这里，literal 是一个有效的 Java 字元。字符串的字元可以使用单引号或双引号来指定。复制引号进行转义（例如 &lsquo;It&rsquo;s me.&rsquo; 或 &ldquo;I &ldquo;&ldquo;like &ldquo;dog.&quot;）。</p>
<p>空符。空符必须有一个类型。使用 nullOf(type)(例如 nullOf(INT))来创建一个空值。</p>
<p>字段引用。fieldReference 指定数据中的一列（如果使用 <code>*</code>，则指定所有列），functionIdentifier 指定一个支持的标量函数。列名和函数名遵循 Java 标识符语法。</p>
<p>函数调用。作为字符串指定的表达式也可以使用前缀符号代替后缀符号来调用运算符和函数。</p>
<p>小数。如果需要处理精确的数值或大的小数，Table API 也支持 Java 的 BigDecimal 类型。在 Scala Table API 中，小数可以通过 BigDecimal(&ldquo;123456&rdquo;)来定义，而在 Java 中，可以通过附加一个 &ldquo;p&rdquo; 来表示精确，例如 123456p。</p>
<p>时间表示法。为了处理时间值，Table API 支持 Java SQL 的 Date, Time 和 Timestamp 类型。在 Scala Table API 中，可以通过使用 java.sql.Date.valueOf(&ldquo;2016-06-27&rdquo;)、java.sql.Time.valueOf(&ldquo;10:10:42&rdquo;) 或 java.sql.Timestamp.valueOf(&ldquo;2016-06-27 10:10:42.123&rdquo;) 来定义字符。Java 和 Scala Table API 还支持调用 &ldquo;2016-06-27&rdquo;.toDate()、&ldquo;10:10:42&rdquo;.toTime() 和  &ldquo;2016-06-27 10:10:42.123&rdquo;.toTimestamp() 来将 Strings 转换为时间类型。注意：由于 Java 的时态 SQL 类型依赖于时区，请确保 Flink 客户端和所有的 TaskManagers 使用相同的时区。</p>
<p>时间间隔。时间间隔可以用月数（Types.INTERVAL_MONTHS）或毫秒数（Types.INTERVAL_MILLIS）表示。同一类型的时间间隔可以加减(例如：1.小时+10.分钟)。可以将毫秒的时间间隔加到时间点上（如 &ldquo;2016-08-10&rdquo;.toDate + 5.days）。</p>
<p>Scala 表达式。Scala 表达式使用隐式转换。因此，确保在你的程序中添加通配符 <code>import org.apache.flink.table.api._</code>。如果一个字词没有被当作表达式，可以使用.toExpr 如 3.toExpr 来强制转换一个字词。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Table API 和 SQL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-and-sql/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api-and-sql/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Table API &amp; SQL</blockquote><h2 id="table-api-和-sql">Table API 和 SQL</h2>
<p>Apache Flink 具有两个关系型 API - Table API 和 SQL - 用于统一的流和批处理。Table API 是 Scala 和 Java 的语言集成查询 API，它允许用非常直观的方式从关系运算符（如选择、过滤和连接）组成查询。Flink 的 SQL 支持是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。无论输入是批处理输入（DataSet）还是流输入（DataStream），在任一接口中指定的查询都具有相同的语义，并指定相同的结果。</p>
<p>表 API 和 SQL 接口与 Flink 的 DataStream 和 DataSet API 紧密集成。你可以很容易地在所有 API 和建立在 API 基础上的库之间切换。例如，您可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/cep.html">CEP 库</a> 从 DataStream 中提取模式，随后使用 Table API 来分析模式，或者您可能会在预处理数据上运行 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/gelly">Gelly 图算法</a>之前，使用 SQL 查询扫描、过滤和聚合一个批处理表。</p>
<p>请注意，Table API 和 SQL 的功能还不完善，正在积极开发中。并非所有的操作都被 [Table API, SQL] 和 [stream, batch] 输入的每个组合所支持。</p>
<h3 id="依赖结构">依赖结构</h3>
<p>从 Flink 1.9 开始，Flink 为评估 Table &amp; SQL API 程序提供了两种不同的规划器实现：Blink planner 和 Flink 1.9 之前的旧 planner。Planner 负责将关系运算符转化为可执行的、优化的 Flink 作业。这两种 planner 都有不同的优化规则和运行时类。它们在支持的功能集上也可能有所不同。</p>
<p>注意: 对于生产用例，我们推荐 blink planner，它从 1.11 开始成为默认 planner。</p>
<p>所有的 Table API 和 SQL 组件都捆绑在 flink-table 或 flink-table-blink Maven 构件中。</p>
<p>以下是与大多数项目相关的依赖关系。</p>
<ul>
<li>flink-table-common: 一个通用模块，用于通过自定义函数、格式等扩展表生态系统。</li>
<li>flink-table-api-java: 使用 Java 编程语言的纯表程序的 Table &amp; SQL API（处于早期开发阶段，不推荐！）。</li>
<li>flink-table-api-scala: Table 和 SQL API，用于使用 Java 编程语言的纯表程序（处于早期开发阶段，不推荐）。</li>
<li>flink-table-api-java-bridge: 使用 Java 编程语言支持 DataStream/DataSet API 的 Table &amp; SQL API。</li>
<li>flink-table-api-scala-bridge: 使用 Scala 编程语言，支持 DataStream/DataSet API 的表和 SQL API。</li>
<li>flink-table-planner: 表程序 planner 和运行时。这是在 1.9 版本之前 Flink 唯一的 planner。从 Flink 1.11 开始，不再推荐使用它。</li>
<li>flink-table-planner-link: 新的 Blink 计划器，从 Flink 1.11 开始成为默认的。</li>
<li>flink-table-runtim-blink: 新的 Blink 运行时。</li>
<li>flink-table-uber: 将上面的 API 模块加上旧的规划器打包成一个适用于大多数 Table &amp; SQL API 使用案例的发行版。uber JAR 文件 <code>flink-table-*.jar</code> 默认位于 Flink 版本的 <code>/lib</code> 目录下。</li>
<li>flink-table-uber-blink: 将上面的 API 模块加上 Blink 的特定模块打包成一个适用于大多数 Table &amp; SQL API 用例的发行版。uber JAR 文件 <code>flink-table-blink-*.jar</code> 默认位于 Flink 版本的 <code>/lib</code> 目录下。</li>
</ul>
<p>关于如何在表程序中切换新旧 Blink planner，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">通用 API</a> 页面。</p>
<h3 id="表程序依赖">表程序依赖</h3>
<p>根据目标编程语言的不同，您需要将 Java 或 Scala API 添加到项目中，以便使用 Table API 和 SQL 来定义管道。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Either... --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-api-java-bridge_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- or... --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-api-scala-bridge_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>此外，如果你想在 IDE 中本地运行 Table API 和 SQL 程序，你必须添加以下一组模块，这取决于你想使用的计划器。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Either... (for the old planner that was available before Flink 1.9) --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-planner_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- or.. (for the new Blink planner) --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-planner-blink_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>在内部，表生态系统的部分内容是在 Scala 中实现的。因此，请确保为批处理和流应用添加以下依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-scala_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><h3 id="扩展依赖性">扩展依赖性</h3>
<p>如果你想实现与 Kafka 交互的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#define-a-tablefactory">自定义格式</a>或一组<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">用户定义的函数</a>，下面的依赖就足够了，可以用于 SQL 客户端的 JAR 文件。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-table-common<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>目前，该模块包括以下扩展点：</p>
<ul>
<li>SerializationSchemaFactory</li>
<li>DeserializationSchemaFactory</li>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h3 id="下一步怎么走">下一步怎么走？</h3>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">概念与通用 API</a>: Table API 和 SQL 的共享概念和 API。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>: 列出了预先定义的数据类型及其属性。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming">流概念</a>: 表 API 或 SQL 的流特定文档，如时间属性的配置和更新结果的处理。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统</a>: 可用的连接器和格式，用于向外部系统读写数据。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a>。支持的操作和表 API 的 API。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL</a>。支持 SQL 的操作和语法。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置函数</a>: 表 API 和 SQL 中支持的函数。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL 客户端</a>: 玩转 Flink SQL，并向集群提交表格程序，无需编程知识。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-use-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-use-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Use Statements</blockquote><h1 id="use-语句">USE 语句</h1>
<p>USE 语句用于设置当前数据库或目录。</p>
<h2 id="运行-use-语句">运行 USE 语句</h2>
<p>USE 语句可以通过 TableEnvironment 的 executeSql() 方法执行，也可以在 SQL CLI 中执行。executeSql() 方法会对一个成功的 USE 操作返回 &lsquo;OK&rsquo;， 否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中运行一条 USE 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// create a catalog
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE CATALOG cat1 WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW CATALOGS&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +-----------------+
</span><span class="c1">// |    catalog name |
</span><span class="c1">// +-----------------+
</span><span class="c1">// | default_catalog |
</span><span class="c1">// | cat1            |
</span><span class="c1">// +-----------------+
</span><span class="c1"></span>
<span class="c1">// change default catalog
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;USE CATALOG cat1&#34;</span><span class="o">)</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// databases are empty
</span><span class="c1">// +---------------+
</span><span class="c1">// | database name |
</span><span class="c1">// +---------------+
</span><span class="c1">// +---------------+
</span><span class="c1"></span>
<span class="c1">// create a database
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE DATABASE db1 WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
<span class="c1">// +---------------+
</span><span class="c1">// | database name |
</span><span class="c1">// +---------------+
</span><span class="c1">// |        db1    |
</span><span class="c1">// +---------------+
</span><span class="c1"></span>
<span class="c1">// change default database
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;USE db1&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="use-catloag">USE CATLOAG</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">USE</span> <span class="k">CATALOG</span> <span class="k">catalog_name</span>
</code></pre></div><p>设置当前目录。所有没有明确指定目录的后续命令将使用这个目录。如果所提供的目录不存在，则会抛出一个异常。默认的当前目录是default_catalog。</p>
<h2 id="use">USE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">USE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.]</span><span class="n">database_name</span>
</code></pre></div><p>设置当前数据库。所有没有明确指定数据库的后续命令将使用这个数据库。如果提供的数据库不存在，则会抛出一个异常。默认的当前数据库是default_database。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[临时表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Temporal Tables</blockquote><h1 id="时间表">时间表</h1>
<p>时间表代表了对变化表的（参数化）视图的概念，该视图返回一个表在特定时间点的内容。</p>
<p>变化表可以是跟踪变化的变化历史表（如数据库变化日志），也可以是将变化具体化的变化维度表（如数据库表）。</p>
<p>对于变化的历史表，Flink 可以跟踪变化，并允许在查询中的某个时间点访问表的内容。在 Flink 中，这种表用 Temporal Table Function 来表示。</p>
<p>对于变化的维度表，Flink 允许在查询内的处理时间点访问表的内容。在 Flink 中，这种表是由一个 Temporal Table 来表示的。</p>
<h2 id="动机">动机</h2>
<h3 id="与不断变化的历史表相关联">与不断变化的历史表相关联</h3>
<p>假设我们有以下表格 RatesHistory。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">RatesHistory</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=======</span> <span class="o">========</span> <span class="o">======</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">15</span>   <span class="n">Euro</span>        <span class="mi">119</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">49</span>   <span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>RatesHistory 代表了一个不断增长的对日元（汇率为 1）的货币汇率附加表。例如，从 09:00 到 10:45，欧元对日元的汇率是 114，从 10:45 到 11:15 是 116。从 10:45 到 11:15 是 116。</p>
<p>考虑到我们希望输出 10:58 时的所有当前汇率，我们将需要以下 SQL 查询来计算结果表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">=</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span>
  <span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r2</span>
  <span class="k">WHERE</span> <span class="n">r2</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span>
  <span class="k">AND</span> <span class="n">r2</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">&lt;=</span> <span class="n">TIME</span> <span class="s1">&#39;10:58&#39;</span><span class="p">);</span>
</code></pre></div><p>相关子查询确定相应货币的最大时间低于或等于期望时间。外层查询列出具有最大时间戳的汇率。</p>
<p>下表显示了这种计算的结果。在我们的例子中，10:45 的欧元更新被考虑在内，然而，11:15 的欧元更新和新输入的英镑在 10:58 的表格中没有被考虑。</p>
<pre><code>rowtime currency   rate
======= ======== ======
09:00   US Dollar   102
09:00   Yen           1
10:45   Euro        116
</code></pre><p>Temporal Tables 的概念旨在简化此类查询，加快其执行速度，并减少 Flink 的状态使用。Temporal Table 是一个关于 append-only 表的参数化视图，它将 append-only 表的行解释为表的 changelog，并提供该表在特定时间点的版本。将 append-only 表解释为变更日志需要指定一个主键属性和一个时间戳属性。主键决定哪些行会被覆盖，时间戳决定行的有效时间。</p>
<p>在上面的例子中，currency 是 RatesHistory 表的主键，rowtime 是时间戳属性。</p>
<p>在 Flink 中，这是由一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-function">Temporal Table Function</a> 来表示的。</p>
<h3 id="与变化的维度表相关联">与变化的维度表相关联</h3>
<p>另一方面，有些用例需要加入一个不断变化的维度表，而这个表是一个外部数据库表。</p>
<p>让我们假设 LatestRates 是一张表（例如存储在），它是以最新的速率来物化的。LatestRates 是物化的历史 RatesHistory。那么 LatestRates 表在时间 10:58 时的内容将是。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">10</span><span class="p">:</span><span class="mi">58</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>
<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Yen</span>           <span class="mi">1</span>
<span class="n">Euro</span>        <span class="mi">116</span>
</code></pre></div><p>12:00 时 LatestRates 表的内容将是：</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">12</span><span class="p">:</span><span class="mi">00</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>
<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Yen</span>           <span class="mi">1</span>
<span class="n">Euro</span>        <span class="mi">119</span>
<span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>在 Flink 中，这用一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>来表示。</p>
<h2 id="时间表函数">时间表函数</h2>
<p>为了访问时态表中的数据，必须传递一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>，该属性决定了将返回的表的版本。Flink 使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html#table-functions">表函数</a>的 SQL 语法来提供一种表达方式。</p>
<p>一旦定义好，一个时态表函数就会接受一个单一的时间参数 timeAttribute，并返回一组行。这个集合包含了所有现有主键相对于给定时间属性的最新版本的行。</p>
<p>假设我们基于 RatesHistory 表定义了一个时态表函数 <code>Rates(timeAttribute)</code>，我们可以用下面的方式查询这样的函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Rates</span><span class="p">(</span><span class="s1">&#39;10:15&#39;</span><span class="p">);</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=======</span> <span class="o">========</span> <span class="o">======</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Rates</span><span class="p">(</span><span class="s1">&#39;11:00&#39;</span><span class="p">);</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=======</span> <span class="o">========</span> <span class="o">======</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>每次查询 <code>Rates(timeAttribute)</code> 都会返回给定时间属性的 Rates 的状态。</p>
<p>注意：目前，Flink 不支持直接查询带有恒定时间属性参数的时态表函数。目前，时态表函数只能用于连接。上面的例子是用来提供对函数 <code>Rates(timeAttribute)</code> 返回内容的直观认识。</p>
<p>关于如何使用时态表进行联接的更多信息，还请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询的连接</a>页面。</p>
<h2 id="定义时态表函数">定义时态表函数</h2>
<p>下面的代码片段说明了如何从一个仅有追加的表创建一个时态表函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Get the stream and table environments.
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Provide a static data set of the rates history table.
</span><span class="c1"></span><span class="k">val</span> <span class="n">ratesHistoryData</span> <span class="k">=</span> <span class="k">new</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">MutableList</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span>
<span class="n">ratesHistoryData</span><span class="o">.+=((</span><span class="s">&#34;US Dollar&#34;</span><span class="o">,</span> <span class="mi">102L</span><span class="o">))</span>
<span class="n">ratesHistoryData</span><span class="o">.+=((</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">114L</span><span class="o">))</span>
<span class="n">ratesHistoryData</span><span class="o">.+=((</span><span class="s">&#34;Yen&#34;</span><span class="o">,</span> <span class="mi">1L</span><span class="o">))</span>
<span class="n">ratesHistoryData</span><span class="o">.+=((</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">116L</span><span class="o">))</span>
<span class="n">ratesHistoryData</span><span class="o">.+=((</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">119L</span><span class="o">))</span>

<span class="c1">// Create and register an example table using above data set.
</span><span class="c1">// In the real setup, you should replace this with your own table.
</span><span class="c1"></span><span class="k">val</span> <span class="n">ratesHistory</span> <span class="k">=</span> <span class="n">env</span>
  <span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">ratesHistoryData</span><span class="o">)</span>
  <span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> &#39;r_currency<span class="o">,</span> &#39;r_rate<span class="o">,</span> &#39;r_proctime<span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;RatesHistory&#34;</span><span class="o">,</span> <span class="n">ratesHistory</span><span class="o">)</span>

<span class="c1">// Create and register TemporalTableFunction.
</span><span class="c1">// Define &#34;r_proctime&#34; as the time attribute and &#34;r_currency&#34; as the primary key.
</span><span class="c1"></span><span class="k">val</span> <span class="n">rates</span> <span class="k">=</span> <span class="n">ratesHistory</span><span class="o">.</span><span class="n">createTemporalTableFunction</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;r_proctime&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span><span class="o">)</span> <span class="c1">// &lt;==== (1)
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerFunction</span><span class="o">(</span><span class="s">&#34;Rates&#34;</span><span class="o">,</span> <span class="n">rates</span><span class="o">)</span>                                          <span class="c1">// &lt;==== (2)
</span></code></pre></div><p>第(1)行创建了一个 Rates <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时态表函数</a>，这使得我们可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 中的函数 Rates。</p>
<p>第(2)行在我们的表环境中以 Rates 的名义注册这个函数，这使得我们可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 中使用 Rates 函数。</p>
<h2 id="时态表">时态表</h2>
<p>注意: 这只在 Blink planner 中支持。</p>
<p>为了访问时间表中的数据，目前必须定义一个 LookupableTableSource 的 TableSource。Flink 使用 SQL:2011 中提出的 SQL 语法 FOR SYSTEM_TIME AS OF 来查询时间表。</p>
<p>假设我们定义了一个名为 LatestRates 的时态表，我们可以用下面的方式查询这样的表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">TIME</span> <span class="s1">&#39;10:15&#39;</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">TIME</span> <span class="s1">&#39;11:00&#39;</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">116</span>
<span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>注意：目前，Flink 不支持直接查询时间恒定的时态表。目前，时态表只能用在 join 中。上面的例子是用来提供一个直观的时间表 LatestRates 返回的内容。</p>
<p>更多关于如何使用时态表进行连接的信息，请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询的连接</a>页面。</p>
<h2 id="定义时态表">定义时态表</h2>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Get the stream and table environments.
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">build</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">,</span> <span class="n">settings</span><span class="o">)</span>
<span class="c1">// or val tEnv = TableEnvironment.create(settings)
</span><span class="c1"></span>
<span class="c1">// Define an HBase table with DDL, then we can use it as a temporal table in sql
</span><span class="c1">// Column &#39;currency&#39; is the rowKey in HBase table
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
    <span class="s">s&#34;&#34;&#34;
</span><span class="s">       |CREATE TABLE LatestRates (
</span><span class="s">       |    currency STRING,
</span><span class="s">       |    fam1 ROW&lt;rate DOUBLE&gt;
</span><span class="s">       |) WITH (
</span><span class="s">       |    &#39;connector&#39; = &#39;hbase-1.4&#39;,
</span><span class="s">       |    &#39;table-name&#39; = &#39;Rates&#39;,
</span><span class="s">       |    &#39;zookeeper.quorum&#39; = &#39;localhost:2181&#39;
</span><span class="s">       |)
</span><span class="s">       |&#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><p>也请参见如何定义 LookupableTableSource 的页面。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[侧输出]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/?utm_source=atom_feed" rel="related" type="text/html" title="可查询状态" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Side Outputs</blockquote><h2 id="side-output">Side Output</h2>
<p>除了 DataStream 操作产生的主流(main stream)外，还可以产生任意数量的附加侧输出结果流。结果流中的数据类型不必与主流中的数据类型相匹配，不同侧输出的类型也可以不同。当您要分割数据流时，这种操作非常有用，通常您必须复制数据流，然后从每个数据流中过滤掉您不想要的数据。</p>
<p>在使用侧输出时，首先需要定义一个 <code>OutputTag</code>，用来识别侧输出流。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">outputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;side-output&#34;</span><span class="o">)</span>
</code></pre></div><p>请注意 <code>OutputTag</code> 是如何根据侧输出流所包含的元素类型进行类型化的。</p>
<p>可以通过以下函数向侧输出发送数据。</p>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">ProcessFunction</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html#the-keyedprocessfunction">KeyedProcessFunction</a></li>
<li>CoProcessFunction</li>
<li>KeyedCoProcessFunction</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#processwindowfunction">ProcessWindowFunction</a></li>
<li>ProcessAllWindowFunction</li>
</ul>
<p>你可以使用 <code>Context</code> 参数（在上面的函数中暴露给用户）向一个由 <code>OutputTag</code> 标识的侧输出发送数据。下面是一个从 <code>ProcessFunction</code> 中发射侧输出数据的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">outputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;side-output&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">mainDataStream</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProcessFunction</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">processElement</span><span class="o">(</span>
        <span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
        <span class="n">ctx</span><span class="k">:</span> <span class="kt">ProcessFunction</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">]</span><span class="k">#</span><span class="nc">Context</span><span class="o">,</span>
        <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="c1">// emit data to regular output
</span><span class="c1"></span>      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">value</span><span class="o">)</span>

      <span class="c1">// emit data to side output
</span><span class="c1"></span>      <span class="n">ctx</span><span class="o">.</span><span class="n">output</span><span class="o">(</span><span class="n">outputTag</span><span class="o">,</span> <span class="s">&#34;sideout-&#34;</span> <span class="o">+</span> <span class="nc">String</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">value</span><span class="o">))</span>
    <span class="o">}</span>
  <span class="o">})</span>
</code></pre></div><p>为了检索侧输出流，你可以在 DataStream 操作的结果上使用 <code>getSideOutput(OutputTag)</code>。这将给你一个 DataStream，它的类型是侧输出流的结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">outputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;side-output&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">mainDataStream</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">sideOutputStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">mainDataStream</span><span class="o">.</span><span class="n">getSideOutput</span><span class="o">(</span><span class="n">outputTag</span><span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/side_output.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/side_output.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/side-outputs" term="side-outputs" label="Side Outputs" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/?utm_source=atom_feed" rel="related" type="text/html" title="用户定义函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Functions</blockquote><h1 id="函数">函数</h1>
<p>Flink Table API &amp; SQL 使用户能够通过函数进行数据转换。</p>
<h2 id="函数的类型">函数的类型</h2>
<p>Flink 中的函数有两个维度来分类。</p>
<p>一个维度是系统（或内置）函数 v.s. 目录函数。系统函数没有命名空间，可以只用名字来引用。目录函数属于目录和数据库，因此它们有目录和数据库的命名空间，它们可以用完全/部分限定名（<code>catalog.db.func</code> 或 <code>db.func</code>）或者只用函数名来引用。</p>
<p>另一个维度是临时函数 v.s. 持久化函数。临时函数是不稳定的，只存在于一个会话的生命周期内，它们总是由用户创建的。而持久性函数则是在会话的生命周期内存在的，它们要么是由系统提供的，要么是在目录中持久存在的。</p>
<p>这两个维度给 Flink 用户提供了4类函数。</p>
<ol>
<li>临时系统函数</li>
<li>系统函数</li>
<li>临时目录函数</li>
<li>目录函数</li>
</ol>
<h2 id="引用函数">引用函数</h2>
<p>在 Flink 中，用户有两种引用函数的方式 - 精确引用函数或模棱两可的引用函数。</p>
<h3 id="精确的函数引用">精确的函数引用</h3>
<p>精确的函数引用使用户能够专门使用目录函数，并且跨目录和跨数据库，例如从 <code>mytable</code> 中选择 <code>mycatalog.mydb.myfunc(x)</code>，从 <code>mytable</code> 中选择 <code>mydb.myfunc(x)</code>。</p>
<p>这只从 Flink 1.10 开始支持。</p>
<h3 id="模棱两可的函数引用">模棱两可的函数引用</h3>
<p>在模棱两可的函数引用中，用户只需在 SQL 查询中指定函数名称即可，例如：<code>select myfunc(x) from mytable</code>。</p>
<h2 id="函数解析顺序">函数解析顺序</h2>
<p>只有当有不同类型但名称相同的函数时，解析顺序才是重要的，比如有三个函数都名为 &ldquo;myfunc&rdquo;，但分别是临时目录、目录和系统函数。如果没有函数名冲突，则函数将被解析为唯一的一个。</p>
<h3 id="精确的函数引用-1">精确的函数引用</h3>
<p>因为系统函数没有命名空间，所以 Flink 中的精确函数引用必须指向临时目录函数或目录函数。</p>
<p>其解析顺序是：</p>
<ol>
<li>临时目录函数</li>
<li>目录函数</li>
</ol>
<h3 id="含糊不清的函数参考">含糊不清的函数参考</h3>
<p>解析顺序是:</p>
<ol>
<li>临时系统函数</li>
<li>系统函数</li>
<li>临时目录函数，在当前目录和当前数据库中的会话。</li>
<li>目录函数，在当前目录和当前数据库中的会话。</li>
</ol>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/function" term="function" label="Function" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[动态表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Dynamic Tables</blockquote><h1 id="动态表">动态表</h1>
<p>SQL 和关系代数在设计时并没有考虑到流数据。因此，关系代数（和 SQL）和流处理之间几乎没有概念上的差距。</p>
<p>本页讨论了这些差异，并解释了 Flink 如何在无界数据上实现与常规数据库引擎在有界数据上相同的语义。</p>
<h2 id="数据流的关系查询">数据流的关系查询</h2>
<p>下表比较了传统的关系代数和流处理在输入数据、执行和输出结果方面的情况。</p>
<table>
<thead>
<tr>
<th style="text-align:left">关系代数/SQL</th>
<th style="text-align:left">流处理</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">关系（或表）是有界（多）元组的集合。</td>
<td style="text-align:left">流是一个无限的元组序列。</td>
</tr>
<tr>
<td style="text-align:left">在批数据上执行的查询（如关系数据库中的表）可以访问完整的输入数据。</td>
<td style="text-align:left">流式查询在启动时不能访问所有的数据，必须&quot;等待&quot;数据流进来。</td>
</tr>
<tr>
<td style="text-align:left">批量查询在产生一个固定大小的结果后就会终止。</td>
<td style="text-align:left">流式查询根据接收到的记录不断地更新其结果，并且永远不会完成。</td>
</tr>
</tbody>
</table>
<p>尽管存在这些差异，但用关系查询和 SQL 处理流并不是不可能的。先进的关系数据库系统提供了一种叫做物化视图的功能。物化视图被定义为一个 SQL 查询，就像一个普通的虚拟视图一样。与虚拟视图不同，物化视图会缓存查询的结果，这样在访问视图时就不需要对查询进行评估。缓存的一个常见挑战是防止缓存提供过时的结果。当其定义查询的基表被修改时，一个物化视图就会过时。急切的视图维护是一种技术，它可以在更新基表时立即更新一个物化视图。</p>
<p>如果我们考虑以下几点，急切的视图维护和流上的 SQL 查询之间的联系就会变得很明显。</p>
<ul>
<li>数据库表是一个 INSERT、UPDATE 和 DELETE DML 语句流的结果，通常称为 changelog 流。</li>
<li>物化视图被定义为一个 SQL 查询。为了更新视图，查询不断处理视图的基础关系的 changelog 流。</li>
<li>物化视图是流式 SQL 查询的结果。</li>
</ul>
<p>考虑到这些要点，我们在下一节介绍以下动态表的概念。</p>
<h2 id="动态表与连续查询">动态表与连续查询</h2>
<p>动态表是 Flink 的表 API 和 SQL 支持流数据的核心概念。与代表批处理数据的静态表相比，动态表是随时间变化的。它们可以像静态批处理表一样被查询。查询动态表会产生一个连续查询。一个连续查询永远不会终止，并产生一个动态表作为结果。查询不断地更新它的（动态）结果表，以反映其（动态）输入表的变化。本质上，对动态表的连续查询与定义物化视图的查询非常相似。</p>
<p>需要注意的是，连续查询的结果在语义上总是等同于在输入表的快照上以批处理模式执行相同查询的结果。</p>
<p>下图直观地展示了流、动态表和连续查询的关系。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/stream-query-stream.png" alt="img"></p>
<ol>
<li>一个流被转换为一个动态表。</li>
<li>对动态表进行连续查询，得到一个新的动态表。</li>
<li>产生的动态表又被转换回流。</li>
</ol>
<p>注意：动态表首先是一个逻辑概念。动态表在查询执行过程中不一定（完全）实体化。</p>
<p>在下文中，我们将解释动态表和连续查询的概念，其点击事件流的模式如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
  <span class="err">user:</span>  <span class="err">VARCHAR</span><span class="p">,</span>   <span class="err">//</span> <span class="err">the</span> <span class="err">name</span> <span class="err">of</span> <span class="err">the</span> <span class="err">user</span>
  <span class="err">cTime:</span> <span class="err">TIMESTAMP</span><span class="p">,</span> <span class="err">//</span> <span class="err">the</span> <span class="err">time</span> <span class="err">when</span> <span class="err">the</span> <span class="err">URL</span> <span class="err">was</span> <span class="err">accessed</span>
  <span class="err">url:</span>   <span class="err">VARCHAR</span>    <span class="err">//</span> <span class="err">the</span> <span class="err">URL</span> <span class="err">that</span> <span class="err">was</span> <span class="err">accessed</span> <span class="err">by</span> <span class="err">the</span> <span class="err">user</span>
<span class="p">]</span>
</code></pre></div><h2 id="在流上定义一个表">在流上定义一个表</h2>
<p>为了用关系查询来处理一个流，必须把它转换成一个表。从概念上讲，流的每一条记录都被解释为对生成的表进行 INSERT 修改。从本质上讲，我们是从一个仅有 INSERT 的 changelog 流建立一个表。</p>
<p>下图直观地展示了点击事件流（左手边）是如何转换为表（右手边）的。随着更多的点击流记录被插入，生成的表在不断增长。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/append-mode.png" alt="img"></p>
<p>注意：一个定义在流上的表在内部是不被实现的。</p>
<h3 id="连续查询">连续查询</h3>
<p>连续查询是在动态表上进行评估，并生成一个新的动态表作为结果。与批处理查询不同，连续查询永远不会终止，并根据输入表的更新更新其结果表。在任何时间点上，连续查询的结果在语义上等同于在输入表的快照上以批处理模式执行相同查询的结果。</p>
<p>在下面我们展示了在点击事件流上定义的点击表上的两个查询示例。</p>
<p>第一个查询是一个简单的 GROUP-BY COUNT 聚合查询。它对用户字段的点击表进行分组，并统计访问的 URL 数量。下图显示了当点击表更新了更多的行时，查询是如何随着时间的推移进行评估的。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/query-groupBy-cnt.png" alt="img"></p>
<p>查询开始时，点击表（左侧）为空。当第一条记录被插入到 clicks 表中时，查询开始计算结果表。插入第一行 <code>[Mary, ./home]</code> 后，结果表（右侧，顶部）由一条行 <code>[Mary, 1]</code> 组成。当第二条记录 <code>[Bob, ./cart]</code> 插入点击表后，查询更新结果表，插入一条新的记录 <code>[Bob, 1]</code>。第三条记录 <code>[Mary, ./prod?id=1]</code> 产生对已经计算好的结果行的更新，这样 <code>[Mary, 1]</code> 就更新为 <code>[Mary, 2]</code>。最后，查询将第三条记录 <code>[Liz，1]</code> 插入到结果表中，这时第四条记录被追加到点击表中。</p>
<p>第二个查询与第一个查询类似，但将点击表除了用户属性也分组在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">一个小时滚动窗口</a>上，然后再统计 URL 的数量（窗口等基于时间的计算是基于特殊的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>，后面会讨论）。同样，图中显示了不同时间点的输入和输出，以直观地显示动态表的变化性质。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/query-groupBy-window-cnt.png" alt="img"></p>
<p>和以前一样，输入表的点击率在左边显示。查询每隔一小时持续计算结果并更新结果表。clicks 表包含四条记录，时间戳（cTime）在 12:00:00 和 12:59:59 之间。查询从这个输入中计算出两条结果行（每个用户一条），并将它们追加到结果表中。对于 13:00:00 和 13:59:59 之间的下一个窗口，点击表包含三条记录，结果是另外两条记录被追加到结果表中。随着时间的推移，更多的行被追加到点击表中，结果表会被更新。</p>
<h3 id="更新和追加查询">更新和追加查询</h3>
<p>虽然这两个例子查询看起来很相似（都是计算一个分组计数合计），但它们在一个重要方面有所不同。</p>
<ul>
<li>第一个查询更新了之前发出的结果，即定义结果表的 changelog 流包含了 INSERT 和 UPDATE 变化。</li>
<li>第二个查询只对结果表进行追加，即结果表的 changelog 流只包含 insert 更改。</li>
</ul>
<p>查询产生的是只追加表还是更新表有一定的影响。</p>
<ul>
<li>产生更新变化的查询通常要维护更多的状态（见下节）。</li>
<li>将仅有附录的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html#table-to-stream-conversion">表转换为流</a>与更新表的转换是不同的（参见表到流的转换部分）。</li>
</ul>
<h3 id="查询限制">查询限制</h3>
<p>许多（但不是全部）语义有效的查询可以作为流上的连续查询来评估。有些查询的计算成本太高，要么是由于它们需要维护的状态大小，要么是由于计算更新太贵。</p>
<ul>
<li>状态大小。连续查询是在无边界的流上进行评估的，通常应该运行数周或数月。因此，一个连续查询处理的数据总量可能非常大。必须更新之前发出的结果的查询需要维护所有发出的行，以便能够更新它们。例如，第一个示例查询需要存储每个用户的 URL 计数，以便能够增加计数，并在输入表收到新行时发出新结果。如果只跟踪注册用户，需要维护的计数数量可能不会太高。但是，如果非注册用户被分配了一个唯一的用户名，那么需要维护的次数会随着时间的推移而增加，最终可能会导致查询失败。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">clicks</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">user</span><span class="p">;</span>
</code></pre></div><ul>
<li>计算更新。有些查询需要重新计算和更新大部分发出的结果行，即使只增加或更新一条输入记录。显然，这种查询并不适合作为连续查询来执行。一个例子是下面的查询，它根据最后一次点击的时间为每个用户计算一个 rank。只要点击表收到一条新的记录，该用户的 lastAction 就会被更新，必须计算新的 rank。但是由于两行不能有相同的 rank，所以所有排名较低的行也需要更新。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">lastLogin</span><span class="p">)</span>
<span class="k">FROM</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">MAX</span><span class="p">(</span><span class="n">cTime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">lastAction</span> <span class="k">FROM</span> <span class="n">clicks</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="k">user</span>
<span class="p">);</span>
</code></pre></div><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>页面讨论了控制连续查询执行的参数。有些参数可用于以维护状态的大小来换取结果的准确性。</p>
<h2 id="表到流的转换">表到流的转换</h2>
<p>动态表可以像普通的数据库表一样，通过 INSERT、UPDATE 和 DELETE 的修改不断地进行修改。它可能是一张只有一行的表，不断地更新，也可能是一张只有插入的表，没有 UPDATE 和 DELETE 的修改，或者是介于两者之间的任何表。</p>
<p>当把动态表转换为流或写入外部系统时，需要对这些变化进行编码。Flink 的表 API 和 SQL 支持三种方式来编码动态表的变化。</p>
<ul>
<li>
<p>只添加流。一个只被 INSERT 修改的动态表，可以通过发出插入的行来转换成流。</p>
</li>
<li>
<p>撤回流。缩回流是指有两种消息的流，即添加消息和缩回消息。通过将 INSERT 变更编码为添加消息，将 DELETE 变更编码为回撤消息，将 UPDATE 变更编码为更新（上一条）行的回撤消息和更新（新一条）行的添加消息，就可以将一张动态表转换为回撤流。下图直观地展示了动态表转换为回撤流的过程。</p>
</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/undo-redo-mode.png" alt="img"></p>
<ul>
<li>Upsert 流。Upsert 流是一个有两种消息类型的流，即 upsert 消息和删除消息。一个动态表被转换为 upsert 流需要一个（可能是复合的）唯一键。通过将 INSERT 和 UPDATE 更改编码为 upsert 消息，将 DELETE 更改编码为 delete 消息，将具有唯一键的动态表转换为流。消耗流的操作者需要知道唯一键属性，以便正确应用消息。与 retract 流的主要区别在于 update 变更用一条消息进行编码，因此效率更高。下图直观地展示了动态表转换为 update 流的过程。</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/redo-mode.png" alt="img"></p>
<p>将动态表转换为 DataStream 的 API 在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#convert-a-table-into-a-datastream">通用概念</a>页面上讨论。请注意，在将动态表转换为 DataStream 时，只支持追加和收回流。在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#define-a-tablesink">TableSources 和 TableSinks</a> 页面上讨论了将动态表发射到外部系统的 TableSink 接口。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[可查询状态]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-queryable-state-beta/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Queryable State Beta</blockquote><p>注意：可查询状态的客户端 API 目前处于不断发展的状态，对所提供接口的稳定性不做保证。在即将到来的 Flink 版本中，客户端的 API 很可能会有突破性的变化。</p>
<p>简而言之，这个功能将 Flink 的 managed keyed (partitioned) state（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">Working with State</a>）暴露给外界，并允许用户从 Flink 外部查询作业的状态。对于某些场景来说，可查询状态消除了与外部系统（如键值存储）进行分布式操作/交易的需求，而这往往是实践中的瓶颈。此外，该功能对于调试目的可能特别有用。</p>
<p>注意事项: 当查询一个状态对象时，该对象是在没有任何同步或复制的情况下从一个并发线程访问的。这是一个设计上的选择，因为上述任何一种情况都会导致作业延迟的增加，这是我们想要避免的。因为任何使用 Java 堆空间的状态后端，如 MemoryStateBackend 或 FsStateBackend，在检索值时都不会使用副本，而是直接引用存储的值，所以读-修改-写模式是不安全的，可能会导致可查询状态服务器因并发修改而失败。RocksDBStateBackend 则可以避免这些问题。</p>
<h2 id="架构">架构</h2>
<p>在展示如何使用可查询状态之前，先简单介绍一下构成它的实体。Queryable State 功能由三个主要实体组成。</p>
<ol>
<li>QueryableStateClient，它（可能）运行在 Flink 集群之外，并提交用户查询。</li>
<li>QueryableStateClientProxy，它运行在每个 TaskManager 上（即 Flink 集群内部），负责接收客户端的查询，代表他从负责的 TaskManager 中获取所请求的状态，并将其返回给客户端，以及</li>
<li>QueryableStateServer，它运行在每个 TaskManager 上，负责为本地存储的状态提供服务。</li>
</ol>
<p>客户端连接到其中一个代理，并发送一个与特定键 <em>k</em> 相关联的状态的请求。正如在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">使用状态</a>中所述，keyed state 被组织在键组(Key Groups)中，每个 TaskManager 都被分配了一些这样的键组(Key Groups)。为了发现哪个 TaskManager 负责持有 <em>k</em> 的键组，代理将询问 JobManager。根据答案，代理将查询运行在该 TaskManager 上的 QueryableStateServer，以获取与 <em>k</em> 相关联的状态，并将响应转发到客户端。</p>
<h2 id="激活可查询状态">激活可查询状态</h2>
<p>要在 Flink 集群上启用可查询状态，你需要做以下工作。</p>
<ol>
<li>将 <code>flink-queryable-state-runtime_2.11-1.11.0.jar</code> 从 <a href="https://flink.apache.org/downloads.html">Flink 发行版</a>的 <code>opt/</code> 文件夹中复制到 <code>lib/</code>  文件夹中。</li>
<li>设置属性 <code>queryable-state.enable</code> 为 <code>true</code>。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/config.html#queryable-state">配置</a>文档了解详情和附加参数。</li>
</ol>
<p>要验证您的群集是否在启用可查询状态后运行，请检查任何 TaskManager 的日志中的行。&ldquo;Started the Queryable State Proxy Server @ &hellip;&quot;。</p>
<h3 id="使状态可查询">使状态可查询</h3>
<p>现在你已经在集群上激活了可查询状态，现在是时候看看如何使用它了。为了使一个状态对外界可见，它需要通过使用以下方式明确地成为可查询状态。</p>
<ul>
<li>QueryableStateStream, 一个方便的对象，它作为一个接收器(sink)，并把它的传入值作为可查询的状态提供，或者是</li>
<li>stateDescriptor.setQueryable(String queryableStateName) 方法，使得状态描述符所代表的 keyed state，可以查询。</li>
</ul>
<p>下面的章节将解释这两种方法的使用。</p>
<h3 id="可查询的状态流">可查询的状态流</h3>
<p>在 KeyedStream 上调用 <code>.asQueryableState(stateName, stateDescriptor)</code> 会返回一个 <code>QueryableStateStream</code>，它将其值作为可查询状态提供。根据状态的类型，<code>asQueryableState()</code> 方法有以下几种变体。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// ValueState
</span><span class="c1"></span><span class="n">QueryableStateStream</span> <span class="nf">asQueryableState</span><span class="o">(</span>
    <span class="n">String</span> <span class="n">queryableStateName</span><span class="o">,</span>
    <span class="n">ValueStateDescriptor</span> <span class="n">stateDescriptor</span><span class="o">)</span>

<span class="c1">// Shortcut for explicit ValueStateDescriptor variant
</span><span class="c1"></span><span class="n">QueryableStateStream</span> <span class="nf">asQueryableState</span><span class="o">(</span><span class="n">String</span> <span class="n">queryableStateName</span><span class="o">)</span>

<span class="c1">// FoldingState
</span><span class="c1"></span><span class="n">QueryableStateStream</span> <span class="nf">asQueryableState</span><span class="o">(</span>
    <span class="n">String</span> <span class="n">queryableStateName</span><span class="o">,</span>
    <span class="n">FoldingStateDescriptor</span> <span class="n">stateDescriptor</span><span class="o">)</span>

<span class="c1">// ReducingState
</span><span class="c1"></span><span class="n">QueryableStateStream</span> <span class="nf">asQueryableState</span><span class="o">(</span>
    <span class="n">String</span> <span class="n">queryableStateName</span><span class="o">,</span>
    <span class="n">ReducingStateDescriptor</span> <span class="n">stateDescriptor</span><span class="o">)</span>
</code></pre></div><p>注意：没有可查询的 <code>ListState</code> 接收器，因为这会导致一个不断增长的列表，可能无法清理，因此最终会消耗过多的内存。</p>
<p>返回的 <code>QueryableStateStream</code> 可以被看作是一个接收器(sink)，不能被进一步转换。在内部，一个 <code>QueryableStateStream</code> 会被翻译成一个操作符，它使用所有传入的记录来更新可查询状态实例。更新逻辑是由 <code>asQueryableState</code> 调用中提供的 <code>StateDescriptor</code> 的类型暗示的。在像下面这样的程序中，keyed stream 的所有记录将通过 <code>ValueState.update(value)</code> 来更新状态实例:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">asQueryableState</span><span class="o">(</span><span class="s">&#34;query-name&#34;</span><span class="o">)</span>
</code></pre></div><p>这就像 Scala API 的 <code>flatMapWithState</code> 一样。</p>
<h3 id="管理的-keyed-state">管理的 Keyed State</h3>
<p>通过 <code>StateDescriptor.setQueryable(String queryableStateName)</code> 使相应的状态描述符成为可查询的状态，可以使操作符的托管键控状态(参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#using-managed-keyed-state">使用 Managed Keyed State)</a>)成为可查询的状态，如下面的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">ValueStateDescriptor</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Long</span><span class="o">&gt;&gt;</span> <span class="n">descriptor</span> <span class="k">=</span>
        <span class="k">new</span> <span class="nc">ValueStateDescriptor</span><span class="o">&lt;&gt;(</span>
                <span class="s">&#34;average&#34;</span><span class="o">,</span> <span class="c1">// the state name
</span><span class="c1"></span>                <span class="nc">TypeInformation</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="k">new</span> <span class="nc">TypeHint</span><span class="o">&lt;</span><span class="nc">Tuple2</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Long</span><span class="o">&gt;&gt;()</span> <span class="o">{}));</span> <span class="c1">// type information
</span><span class="c1"></span>
<span class="n">descriptor</span><span class="o">.</span><span class="n">setQueryable</span><span class="o">(</span><span class="s">&#34;query-name&#34;</span><span class="o">);</span> <span class="c1">// queryable state name
</span></code></pre></div><p>注意：<code>queryableStateName</code> 参数可以任意选择，并且只用于查询。它不一定要与状态本身的名称相同。</p>
<p>这个变体对于哪种类型的状态可以被查询没有限制。这意味着它可以用于任何 ValueState、ReduceState、ListState、MapState、AggregatingState 以及目前已被废弃的 FoldingState。</p>
<h3 id="查询状态">查询状态</h3>
<p>到目前为止，你已经设置了你的集群以可查询的状态运行，并且你已经将你的（部分）状态声明为可查询。现在是时候看看如何查询这个状态了。</p>
<p>为此，你可以使用 <code>QueryableStateClient</code> 辅助类。它可以在 <code>flink-queryable-state-client jar</code> 中找到，它必须和 flink-core 一起被显式地包含在项目的 pom.xml 中作为依赖，如下所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-core<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-queryable-state-client-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>更多的内容，可以查看如何<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration.html">设置 Flink 程序</a>。</p>
<p><code>QueryableStateClient</code> 会将你的查询提交给内部代理，然后代理会处理你的查询并返回最终结果。初始化客户端的唯一要求是提供一个有效的 TaskManager 主机名（记住每个 TaskManager 上都有一个可查询状态代理运行）和代理监听的端口。更多关于如何配置代理和状态服务器端口的信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html#configuration">配置部分</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">QueryableStateClient</span> <span class="n">client</span> <span class="o">=</span> <span class="k">new</span> <span class="n">QueryableStateClient</span><span class="o">(</span><span class="n">tmHostname</span><span class="o">,</span> <span class="n">proxyPort</span><span class="o">)</span>
</code></pre></div><p>客户端准备好后，要查询一个类型为 V 的状态，与类型为 K 的键相关联，可以使用该方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">CompletableFuture</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span> <span class="nf">getKvState</span><span class="o">(</span>
    <span class="n">JobID</span> <span class="n">jobId</span><span class="o">,</span>
    <span class="n">String</span> <span class="n">queryableStateName</span><span class="o">,</span>
    <span class="n">K</span> <span class="n">key</span><span class="o">,</span>
    <span class="n">TypeInformation</span><span class="o">&lt;</span><span class="n">K</span><span class="o">&gt;</span> <span class="n">keyTypeInfo</span><span class="o">,</span>
    <span class="n">StateDescriptor</span><span class="o">&lt;</span><span class="n">S</span><span class="o">,</span> <span class="n">V</span><span class="o">&gt;</span> <span class="n">stateDescriptor</span><span class="o">)</span>
</code></pre></div><p>以上返回一个 CompletableFuture，最终持有 ID 为 jobID 的作业的 <code>queryableStateName</code> 所标识的可查询状态实例的状态值。key 是你对其状态感兴趣的键，keyTypeInfo 将告诉 Flink 如何序列化/解序列化它。最后，<code>stateDescriptor</code> 包含了关于所请求的状态的必要信息，即它的类型（Value、Reduce 等）和如何序列化/解序列化它的必要信息。</p>
<p>细心的读者会注意到，返回的 future 包含一个 S 类型的值，即一个包含实际值的 <code>State</code> 对象。这可以是 Flink 支持的任何一种状态类型。ValueState，ReduceState，ListState，MapState，AggregatingState，以及目前已经废弃的 FoldingState。</p>
<p>注意：这些状态对象不允许对包含的状态进行修改。您可以使用它们来获取状态的实际值，例如使用 <code>valueState.get()</code>，或者迭代包含的 <code>&lt;K，V&gt;</code> 条目，例如使用 <code>mapState.entry()</code>，但您不能修改它们。举个例子，在返回的列表状态上调用 <code>add()</code> 方法会抛出一个 <code>UnsupportedOperationException</code>。</p>
<p>注意：客户端是异步的，可以被多个线程共享。在未使用时需要通过 <code>QueryableStateClient.shutdown()</code> 来关闭它，以释放资源。</p>
<h3 id="例子">例子</h3>
<p>下面的例子扩展了 <code>CountWindowAverage</code> 的例子(请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#using-managed-keyed-state">使用 Managed Keyed State</a>)，使其可查询，并展示了如何查询这个值。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">CountWindowAverage</span> <span class="kd">extends</span> <span class="n">RichFlatMapFunction</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">transient</span> <span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">sum</span><span class="o">;</span> <span class="c1">// a tuple containing the count and the sum
</span><span class="c1"></span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="n">currentSum</span> <span class="o">=</span> <span class="n">sum</span><span class="o">.</span><span class="na">value</span><span class="o">();</span>
        <span class="n">currentSum</span><span class="o">.</span><span class="na">f0</span> <span class="o">+=</span> <span class="n">1</span><span class="o">;</span>
        <span class="n">currentSum</span><span class="o">.</span><span class="na">f1</span> <span class="o">+=</span> <span class="n">input</span><span class="o">.</span><span class="na">f1</span><span class="o">;</span>
        <span class="n">sum</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="n">currentSum</span><span class="o">);</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">currentSum</span><span class="o">.</span><span class="na">f0</span> <span class="o">&gt;=</span> <span class="n">2</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="n">input</span><span class="o">.</span><span class="na">f0</span><span class="o">,</span> <span class="n">currentSum</span><span class="o">.</span><span class="na">f1</span> <span class="o">/</span> <span class="n">currentSum</span><span class="o">.</span><span class="na">f0</span><span class="o">));</span>
            <span class="n">sum</span><span class="o">.</span><span class="na">clear</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">config</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">descriptor</span> <span class="o">=</span>
                <span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;&gt;(</span>
                        <span class="s">&#34;average&#34;</span><span class="o">,</span> <span class="c1">// the state name
</span><span class="c1"></span>                        <span class="n">TypeInformation</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="k">new</span> <span class="n">TypeHint</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;()</span> <span class="o">{}));</span> <span class="c1">// type information
</span><span class="c1"></span>        <span class="n">descriptor</span><span class="o">.</span><span class="na">setQueryable</span><span class="o">(</span><span class="s">&#34;query-name&#34;</span><span class="o">);</span>
        <span class="n">sum</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getState</span><span class="o">(</span><span class="n">descriptor</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="n">Once</span> <span class="n">used</span> <span class="n">in</span> <span class="n">a</span> <span class="n">job</span><span class="o">,</span> <span class="n">you</span> <span class="n">can</span> <span class="n">retrieve</span> <span class="n">the</span> <span class="n">job</span> <span class="n">ID</span> <span class="n">and</span> <span class="n">then</span> <span class="n">query</span> <span class="n">any</span> <span class="n">key</span><span class="err">’</span><span class="n">s</span> <span class="n">current</span> <span class="n">state</span> <span class="n">from</span> <span class="k">this</span> <span class="n">operator</span><span class="o">:</span>

<span class="n">QueryableStateClient</span> <span class="n">client</span> <span class="o">=</span> <span class="k">new</span> <span class="n">QueryableStateClient</span><span class="o">(</span><span class="n">tmHostname</span><span class="o">,</span> <span class="n">proxyPort</span><span class="o">);</span>

<span class="c1">// the state descriptor of the state to be fetched.
</span><span class="c1"></span><span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">descriptor</span> <span class="o">=</span>
        <span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;&gt;(</span>
          <span class="s">&#34;average&#34;</span><span class="o">,</span>
          <span class="n">TypeInformation</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="k">new</span> <span class="n">TypeHint</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;()</span> <span class="o">{}));</span>

<span class="n">CompletableFuture</span><span class="o">&lt;</span><span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;&gt;&gt;</span> <span class="n">resultFuture</span> <span class="o">=</span>
        <span class="n">client</span><span class="o">.</span><span class="na">getKvState</span><span class="o">(</span><span class="n">jobId</span><span class="o">,</span> <span class="s">&#34;query-name&#34;</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="n">BasicTypeInfo</span><span class="o">.</span><span class="na">LONG_TYPE_INFO</span><span class="o">,</span> <span class="n">descriptor</span><span class="o">);</span>

<span class="c1">// now handle the returned value
</span><span class="c1"></span><span class="n">resultFuture</span><span class="o">.</span><span class="na">thenAccept</span><span class="o">(</span><span class="n">response</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="k">try</span> <span class="o">{</span>
            <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="n">res</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
        <span class="o">}</span>
<span class="o">});</span>
</code></pre></div><h2 id="配置">配置</h2>
<p>以下配置参数会影响可查询状态服务器和客户端的行为，它们被定义在 <code>QueryableStateOptions</code> 中。</p>
<h3 id="状态服务器">状态服务器</h3>
<ul>
<li><code>queryable-state.server.ports</code>：可查询状态服务器的服务器端口范围。如果在同一台机器上运行多个 task manager，这对避免端口冲突很有用。指定的范围可以是：一个端口: &ldquo;9123&rdquo;，一个端口范围: &ldquo;50100-50200&rdquo;，或者一个范围和或点的列表: &ldquo;50100-50200,50300-50400,51234&rdquo;。默认端口为 9067。</li>
<li><code>queryable-state.server.network-threads</code>: 接收状态服务器传入请求的网络（事件循环）线程数（0 =&gt; #slots）。</li>
<li><code>queryable-state.server.query-threads</code>: 为状态服务器处理/服务传入请求的线程数（0 =&gt; #slots）。</li>
</ul>
<h3 id="代理">代理</h3>
<ul>
<li><code>queryable-state.proxy.ports</code>：可查询状态代理服务器的端口范围。如果在同一台机器上运行多个 task manager，这对避免端口冲突很有用。指定的范围可以是：一个端口: &ldquo;9123&rdquo;，一个端口范围: &ldquo;50100-50200&rdquo;，或者一个范围和或点的列表: &ldquo;50100-50200,50300-50400,51234&rdquo;。默认端口为 9069。</li>
<li><code>queryable-state.proxy.network-threads</code>：为客户端代理接收传入请求的网络（事件循环）线程数（0 =&gt; #slots）。</li>
<li><code>queryable-state.proxy.query-threads</code>：为客户端代理处理/服务传入请求的线程数（0 =&gt; #slots）。</li>
</ul>
<h3 id="限制条件">限制条件</h3>
<ul>
<li>可查询状态的生命周期与任务的生命周期绑定，例如，任务在启动时注册可查询状态，在处置时取消注册。在未来的版本中，我们希望将其解耦，以便在任务完成后允许查询，并通过状态复制加快恢复速度。</li>
<li>关于可用 KvState 的通知是通过一个简单的告诉发生的。将来应该改进这个功能，使其更加强大，包括询问和确认。</li>
<li>服务器和客户端会跟踪查询的统计数据。目前默认情况下，这些数据是被禁用的，因为它们不会暴露在任何地方。一旦有更好的支持通过 Metrics 系统发布这些数字，我们应该启用统计。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[处理应用程序参数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-handling-application-parameters/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-handling-application-parameters/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Handling Application Parameters</blockquote><h1 id="处理应用程序参数">处理应用程序参数</h1>
<p>几乎所有的 Flink 应用，包括批处理和流式应用，都依赖于外部配置参数，它们用于指定输入和输出源（如路径或地址）、系统参数（并行性、运行时配置）和应用特定参数（通常在用户函数中使用）。它们用于指定输入和输出源（如路径或地址）、系统参数（并行性、运行时配置）和应用程序特定参数（通常在用户函数中使用）。</p>
<p>Flink 提供了一个名为 ParameterTool 的简单工具，为解决这些问题提供一些基本的工具。请注意，你不一定要使用这里描述的 ParameterTool。其他框架如 Commons CLI和argparse4j 也能很好地与 Flink 一起工作。</p>
<p>将你的配置值导入 ParameterTool 之中</p>
<p>ParameterTool 提供了一组预定义的静态方法来读取配置。该工具内部期待的是一个 <code>Map&lt;String，String&gt;</code>，所以很容易将其与自己的配置风格整合在一起。</p>
<p>从 <code>.properties</code> 文件中</p>
<p>下面的方法将读取一个属性文件并提供键/值对。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">String</span> <span class="n">propertiesFilePath</span> <span class="o">=</span> <span class="s">&#34;/home/sam/flink/myjob.properties&#34;</span><span class="o">;</span>
<span class="n">ParameterTool</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromPropertiesFile</span><span class="o">(</span><span class="n">propertiesFilePath</span><span class="o">);</span>

<span class="n">File</span> <span class="n">propertiesFile</span> <span class="o">=</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="n">propertiesFilePath</span><span class="o">);</span>
<span class="n">ParameterTool</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromPropertiesFile</span><span class="o">(</span><span class="n">propertiesFile</span><span class="o">);</span>

<span class="n">InputStream</span> <span class="n">propertiesFileInputStream</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FileInputStream</span><span class="o">(</span><span class="n">file</span><span class="o">);</span>
<span class="n">ParameterTool</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromPropertiesFile</span><span class="o">(</span><span class="n">propertiesFileInputStream</span><span class="o">);</span>
</code></pre></div><p>从命令行参数来看</p>
<p>这就允许从命令行中获取 <code>--input hdfs://mydata --elements 42</code> 这样的参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">ParameterTool</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
    <span class="c1">// .. regular code ..
</span></code></pre></div><p>从系统属性</p>
<p>当启动 JVM 时，你可以将系统属性传递给它。<code>-Dinput=hdfs://mydata</code>。你也可以从这些系统属性中初始化 ParameterTool。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ParameterTool</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromSystemProperties</span><span class="o">();</span>
</code></pre></div><p>在 Flink 程序中使用参数</p>
<p>现在我们已经从某个地方得到了参数（见上文），我们可以以各种方式使用它们。</p>
<p>直接从 ParameterTool 中使用</p>
<p>ParameterTool 本身有访问值的方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ParameterTool</span> <span class="n">parameters</span> <span class="o">=</span> <span class="c1">// ...
</span><span class="c1"></span><span class="n">parameter</span><span class="o">.</span><span class="na">getRequired</span><span class="o">(</span><span class="s">&#34;input&#34;</span><span class="o">);</span>
<span class="n">parameter</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&#34;output&#34;</span><span class="o">,</span> <span class="s">&#34;myDefaultValue&#34;</span><span class="o">);</span>
<span class="n">parameter</span><span class="o">.</span><span class="na">getLong</span><span class="o">(</span><span class="s">&#34;expectedCount&#34;</span><span class="o">,</span> <span class="o">-</span><span class="n">1L</span><span class="o">);</span>
<span class="n">parameter</span><span class="o">.</span><span class="na">getNumberOfParameters</span><span class="o">()</span>
<span class="c1">// .. there are more methods available.
</span></code></pre></div><p>你可以在客户端提交应用程序的 <code>main()</code> 方法中直接使用这些方法的返回值。例如，你可以这样设置一个操作符的并行性。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ParameterTool</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
<span class="kt">int</span> <span class="n">parallelism</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&#34;mapParallelism&#34;</span><span class="o">,</span> <span class="n">2</span><span class="o">);</span>
<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">Tokenizer</span><span class="o">()).</span><span class="na">setParallelism</span><span class="o">(</span><span class="n">parallelism</span><span class="o">);</span>
</code></pre></div><p>由于 ParameterTool 是可序列化的，所以你可以把它传递给函数本身。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ParameterTool</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">Tokenizer</span><span class="o">(</span><span class="n">parameters</span><span class="o">));</span>
</code></pre></div><p>然后在函数内部使用它从命令行获取值。</p>
<p>全局注册参数</p>
<p>在 ExecutionConfig 中注册为全局作业参数的参数可以作为配置值从 JobManager Web 界面和用户定义的所有功能中访问。</p>
<p>全局注册参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ParameterTool</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>

<span class="c1">// set up the execution environment
</span><span class="c1"></span><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">().</span><span class="na">setGlobalJobParameters</span><span class="o">(</span><span class="n">parameters</span><span class="o">);</span>
</code></pre></div><p>在任何丰富的用户功能中访问它们。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">Tokenizer</span> <span class="kd">extends</span> <span class="n">RichFlatMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
	<span class="n">ParameterTool</span> <span class="n">parameters</span> <span class="o">=</span> <span class="o">(</span><span class="n">ParameterTool</span><span class="o">)</span>
	    <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getExecutionConfig</span><span class="o">().</span><span class="na">getGlobalJobParameters</span><span class="o">();</span>
	<span class="n">parameters</span><span class="o">.</span><span class="na">getRequired</span><span class="o">(</span><span class="s">&#34;input&#34;</span><span class="o">);</span>
	<span class="c1">// .. do more ..
</span></code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/application_parameters.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/application_parameters.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/parameters" term="parameters" label="Parameters" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[实验特性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-experimental-features/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-experimental-features/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Experimental Features</blockquote><h2 id="实验特性">实验特性</h2>
<p>本节介绍 DataStream API 中的实验性功能。实验性功能仍在不断发展，可能是不稳定的、不完整的，或者在未来的版本中会有很大的变化。</p>
<h3 id="将预先分割的数据流重新解释为-keyed-流">将预先分割的数据流重新解释为 keyed 流</h3>
<p>我们可以将一个预分区的数据流重新解释为一个 keyed 流，以避免洗牌。</p>
<p>警告：重新解释的数据流必须已经被预分区了，其方式与 Flink 的 keyBy 在洗牌中对数据的分区方式完全相同，即键组分配。</p>
<p>一个用例是两个作业之间的物化洗牌：第一个作业执行 keyBy 洗牌，并将每个输出物化为一个分区。第二个作业有源，对于每个并行实例，从第一个作业创建的相应分区中读取。现在可以将这些源重新解释为 keyed 流，例如应用窗口化。请注意，这个技巧使得第二个作业的并行性很尴尬，这对细粒度的恢复方案很有帮助。</p>
<p>这个重新解释的功能是通过 DataStreamUtils 暴露的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">static</span> <span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">K</span><span class="o">&gt;</span> <span class="nc">KeyedStream</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">K</span><span class="o">&gt;</span> <span class="n">reinterpretAsKeyedStream</span><span class="o">(</span>
    <span class="nc">DataStream</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">stream</span><span class="o">,</span>
    <span class="nc">KeySelector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">,</span> <span class="n">K</span><span class="o">&gt;</span> <span class="n">keySelector</span><span class="o">,</span>
    <span class="nc">TypeInformation</span><span class="o">&lt;</span><span class="n">K</span><span class="o">&gt;</span> <span class="n">typeInfo</span><span class="o">)</span>
</code></pre></div><p>给定一个基流(base stream)、一个键选择器和类型信息，该方法从基流创建一个 keyed 流。</p>
<p>代码示例:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">source</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">new</span> <span class="nc">DataStreamUtils</span><span class="o">(</span><span class="n">source</span><span class="o">).</span><span class="n">reinterpretAsKeyedStream</span><span class="o">((</span><span class="n">in</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">in</span><span class="o">)</span>
  <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
  <span class="o">.</span><span class="n">reduce</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
  <span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="k">new</span> <span class="nc">DiscardingSink</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/experimental.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/experimental.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[广播状态模式]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-the-broadcast-state-pattern/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-the-broadcast-state-pattern/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>The Broadcast State Pattern</blockquote><p>在本节中，您将了解如何在实践中使用广播状态。请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">Stateful Stream Processing</a> 来了解有状态流处理背后的概念。</p>
<h2 id="提供的-api">提供的 API</h2>
<p>为了展示所提供的 API，我们将在介绍它们的全部功能之前先举一个例子。作为我们的运行示例，我们将使用这样的情况：我们有一个不同颜色和形状的对象流，我们希望找到相同颜色的对象对，并遵循特定的模式，例如，一个矩形和一个三角形。我们假设有趣的模式集会随着时间的推移而演变。</p>
<p>在这个例子中，第一个流将包含具有 <code>Color</code> 和 <code>Shape</code> 属性的 <code>Item</code> 类型的元素。另一个流将包含 <code>Rules</code>。</p>
<p>从 <code>Items</code> 流开始，我们只需要按 <code>Color</code> keyBy，因为我们想要相同颜色的对。这将确保相同颜色的元素最终会出现在同一个物理机上。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// key the items by color
</span><span class="c1"></span><span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">,</span> <span class="n">Color</span><span class="o">&gt;</span> <span class="n">colorPartitionedStream</span> <span class="o">=</span> <span class="n">itemStream</span>
                        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="k">new</span> <span class="n">KeySelector</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">,</span> <span class="n">Color</span><span class="o">&gt;(){...});</span>
</code></pre></div><p>继续讨论规则，包含规则的流应该被广播到所有下游任务，这些任务应该将它们存储在本地，以便它们可以根据所有传入的项目评估它们。下面的代码段将i)广播规则流，ii)使用提供的 <code>MapStateDescriptor</code>，它将创建规则将被存储的广播状态。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// a map descriptor to store the name of the rule (string) and the rule itself.
</span><span class="c1"></span><span class="nc">MapStateDescriptor</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Rule</span><span class="o">&gt;</span> <span class="n">ruleStateDescriptor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MapStateDescriptor</span><span class="o">&lt;&gt;(</span>
			<span class="s">&#34;RulesBroadcastState&#34;</span><span class="o">,</span>
			<span class="nc">BasicTypeInfo</span><span class="o">.</span><span class="nc">STRING_TYPE_INFO</span><span class="o">,</span>
			<span class="nc">TypeInformation</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="k">new</span> <span class="nc">TypeHint</span><span class="o">&lt;</span><span class="nc">Rule</span><span class="o">&gt;()</span> <span class="o">{}));</span>
		
<span class="c1">// broadcast the rules and create the broadcast state
</span><span class="c1"></span><span class="nc">BroadcastStream</span><span class="o">&lt;</span><span class="nc">Rule</span><span class="o">&gt;</span> <span class="n">ruleBroadcastStream</span> <span class="k">=</span> <span class="n">ruleStream</span>
                        <span class="o">.</span><span class="n">broadcast</span><span class="o">(</span><span class="n">ruleStateDescriptor</span><span class="o">);</span>
</code></pre></div><p>最后，为了根据从 <code>Item</code> 流传入的元素来评估 <code>Rules</code>，我们需要。</p>
<ul>
<li>连接(connect)两个流，并且</li>
<li>指定我们的匹配检测逻辑。</li>
</ul>
<p>将一个流（keyed or non-keyed）与 <code>BroadcastStream</code> 连接起来，可以通过在非广播流上调用 <code>connect()</code> 来完成，并将 <code>BroadcastStream</code> 作为一个参数。这将返回一个 <code>BroadcastConnectedStream</code>，我们可以在这个 Stream 上调用一个特殊类型的 <code>CoProcessFunction</code> 来处理。该函数将包含我们的匹配逻辑。该函数的具体类型取决于非广播流的类型。</p>
<ul>
<li>如果它是 <strong>keyed</strong>，那么这个函数就是 <code>KeyedBroadcastProcessFunction</code>。</li>
<li>如果是 <strong>non-keyed,</strong>，那么该函数就是一个 <code>BroadcastProcessFunction</code>。</li>
</ul>
<p>鉴于我们的非广播流是 keyed 的，下面的代码段包含了上述调用。</p>
<p>注意： 连接(connect)应该被调用在非广播流上， 以 <code>BroadcastStream</code> 作为参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">colorPartitionedStream</span>
                 <span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="n">ruleBroadcastStream</span><span class="o">)</span>
                 <span class="o">.</span><span class="na">process</span><span class="o">(</span>
                     
                     <span class="c1">// type arguments in our KeyedBroadcastProcessFunction represent: 
</span><span class="c1"></span>                     <span class="c1">//   1. the key of the keyed stream
</span><span class="c1"></span>                     <span class="c1">//   2. the type of elements in the non-broadcast side
</span><span class="c1"></span>                     <span class="c1">//   3. the type of elements in the broadcast side
</span><span class="c1"></span>                     <span class="c1">//   4. the type of the result, here a string
</span><span class="c1"></span>                     
                     <span class="k">new</span> <span class="n">KeyedBroadcastProcessFunction</span><span class="o">&lt;</span><span class="n">Color</span><span class="o">,</span> <span class="n">Item</span><span class="o">,</span> <span class="n">Rule</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>
                         <span class="c1">// my matching logic
</span><span class="c1"></span>                     <span class="o">}</span>
                 <span class="o">);</span>
</code></pre></div><h3 id="broadcastprocessfunction-和-keyedbroadcastprocessfunction">BroadcastProcessFunction 和 KeyedBroadcastProcessFunction</h3>
<p>与 <code>CoProcessFunction</code> 一样，这些函数有两个处理方法要实现；<code>processBroadcastElement()</code> 负责处理广播流中的传入元素，<code>processElement()</code> 用于处理非广播流。这些方法的完整签名如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">BroadcastProcessFunction</span><span class="o">&lt;</span><span class="n">IN1</span><span class="o">,</span> <span class="n">IN2</span><span class="o">,</span> <span class="n">OUT</span><span class="o">&gt;</span> <span class="kd">extends</span> <span class="n">BaseBroadcastProcessFunction</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span><span class="n">IN1</span> <span class="n">value</span><span class="o">,</span> <span class="n">ReadOnlyContext</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">void</span> <span class="nf">processBroadcastElement</span><span class="o">(</span><span class="n">IN2</span> <span class="n">value</span><span class="o">,</span> <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>
<span class="o">}</span>
<span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">KeyedBroadcastProcessFunction</span><span class="o">&lt;</span><span class="n">KS</span><span class="o">,</span> <span class="n">IN1</span><span class="o">,</span> <span class="n">IN2</span><span class="o">,</span> <span class="n">OUT</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span><span class="n">IN1</span> <span class="n">value</span><span class="o">,</span> <span class="n">ReadOnlyContext</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">void</span> <span class="nf">processBroadcastElement</span><span class="o">(</span><span class="n">IN2</span> <span class="n">value</span><span class="o">,</span> <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onTimer</span><span class="o">(</span><span class="kt">long</span> <span class="n">timestamp</span><span class="o">,</span> <span class="n">OnTimerContext</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">OUT</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>首先需要注意的是，这两个函数在处理广播端元素时都需要实现 <code>processBroadcastElement()</code> 方法，在处理非广播端元素时需要实现 <code>processElement()</code> 方法。</p>
<p>这两个方法在提供的上下文中有所不同。非广播侧有一个 <code>ReadOnlyContext</code>，而广播侧有一个 <code>Context</code>。</p>
<p>这两个上下文（以下枚举中的 <code>ctx</code>）:</p>
<ol>
<li>提供对广播状态的访问：<code>ctx.getBroadcastState(MapStateDescriptor&lt;K, V&gt; stateDescriptor)</code>。</li>
<li>允许查询元素的时间戳：<code>ctx.timestamp()</code>。</li>
<li>获取当前水印：<code>ctx.currentWatermark()</code>。</li>
<li>获取当前处理时间：<code>ctx.currentProcessingTime()</code>，以及</li>
<li>将元素发射到侧输出：<code>ctx.output(OutputTag&lt;X&gt; outputTag, X value)</code>。</li>
</ol>
<p><code>getBroadcastState()</code> 中的 <code>stateDescriptor</code> 应该和上面的 <code>.broadcast(ruleStateDescriptor)</code> 中的 <code>stateDescriptor</code> 是一样的。</p>
<p>区别在于各自对广播状态的访问类型。广播端对其有读写访问权，而非广播端则只有读的访问权（因此才有这些名字）。原因是在 Flink 中，不存在跨任务通信。所以，为了保证广播状态中的内容在我们操作符的所有并行实例中都是相同的，我们只给广播侧读写访问权，而广播侧在所有任务中看到的元素都是相同的，并且我们要求该侧每个传入元素的计算在所有任务中都是相同的。忽略这个规则会打破状态的一致性保证，导致结果不一致，而且往往难以调试。</p>
<p>注意 <code>processBroadcastElement()</code> 中实现的逻辑必须在所有并行实例中具有相同的确定性行为!</p>
<p>最后，由于 <code>KeyedBroadcastProcessFunction</code> 是在 keyed stream 上运行的，它暴露了一些 <code>BroadcastProcessFunction</code> 无法实现的功能。那就是</p>
<ol>
<li><code>processElement()</code> 方法中的 <code>ReadOnlyContext</code> 允许访问 Flink 的底层定时器服务，它允许注册事件和/或处理时间定时器。当一个定时器发射时， <code>onTimer()</code> (如上所示)被调用一个 <code>OnTimerContext</code>，它暴露了与 <code>ReadOnlyContext</code> 相同的功能，再加上</li>
</ol>
<ul>
<li>能够询问发射的定时器是事件还是处理时间, 和</li>
<li>来查询与定时器相关联的键。</li>
</ul>
<ol start="2">
<li><code>processBroadcastElement()</code> 方法中的 <code>Context</code> 包含 <code>applyToKeyedState(StateDescriptor&lt;S, VS&gt; stateDescriptor, KeyedStateFunction&lt;KS, S&gt; function)</code> 方法。这允许注册一个 <code>KeyedStateFunction</code>，以应用于与提供的 <code>stateDescriptor</code> 相关联的所有键的所有状态。</li>
</ol>
<p>注意。注册定时器只能在 <code>KeyedBroadcastProcessFunction</code> 的 <code>processElement()</code> 处进行，而且只能在那里进行。在 <code>processBroadcastElement()</code> 方法中是不可能的，因为没有键与广播元素相关联。</p>
<p>回到我们原来的例子，我们的 <code>KeyedBroadcastProcessFunction</code> 可以是如下的样子。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="k">new</span> <span class="n">KeyedBroadcastProcessFunction</span><span class="o">&lt;</span><span class="n">Color</span><span class="o">,</span> <span class="n">Item</span><span class="o">,</span> <span class="n">Rule</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>

    <span class="c1">// store partial matches, i.e. first elements of the pair waiting for their second element
</span><span class="c1"></span>    <span class="c1">// we keep a list as we may have many first elements waiting
</span><span class="c1"></span>    <span class="kd">private</span> <span class="kd">final</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">&gt;&gt;</span> <span class="n">mapStateDesc</span> <span class="o">=</span>
        <span class="k">new</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;&gt;(</span>
            <span class="s">&#34;items&#34;</span><span class="o">,</span>
            <span class="n">BasicTypeInfo</span><span class="o">.</span><span class="na">STRING_TYPE_INFO</span><span class="o">,</span>
            <span class="k">new</span> <span class="n">ListTypeInfo</span><span class="o">&lt;&gt;(</span><span class="n">Item</span><span class="o">.</span><span class="na">class</span><span class="o">));</span>

    <span class="c1">// identical to our ruleStateDescriptor above
</span><span class="c1"></span>    <span class="kd">private</span> <span class="kd">final</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Rule</span><span class="o">&gt;</span> <span class="n">ruleStateDescriptor</span> <span class="o">=</span> 
        <span class="k">new</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;&gt;(</span>
            <span class="s">&#34;RulesBroadcastState&#34;</span><span class="o">,</span>
            <span class="n">BasicTypeInfo</span><span class="o">.</span><span class="na">STRING_TYPE_INFO</span><span class="o">,</span>
            <span class="n">TypeInformation</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="k">new</span> <span class="n">TypeHint</span><span class="o">&lt;</span><span class="n">Rule</span><span class="o">&gt;()</span> <span class="o">{}));</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processBroadcastElement</span><span class="o">(</span><span class="n">Rule</span> <span class="n">value</span><span class="o">,</span>
                                        <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span>
                                        <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">ctx</span><span class="o">.</span><span class="na">getBroadcastState</span><span class="o">(</span><span class="n">ruleStateDescriptor</span><span class="o">).</span><span class="na">put</span><span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="na">name</span><span class="o">,</span> <span class="n">value</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span><span class="n">Item</span> <span class="n">value</span><span class="o">,</span>
                               <span class="n">ReadOnlyContext</span> <span class="n">ctx</span><span class="o">,</span>
                               <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

        <span class="kd">final</span> <span class="n">MapState</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">&gt;&gt;</span> <span class="n">state</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getMapState</span><span class="o">(</span><span class="n">mapStateDesc</span><span class="o">);</span>
        <span class="kd">final</span> <span class="n">Shape</span> <span class="n">shape</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="na">getShape</span><span class="o">();</span>
    
        <span class="k">for</span> <span class="o">(</span><span class="n">Map</span><span class="o">.</span><span class="na">Entry</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Rule</span><span class="o">&gt;</span> <span class="n">entry</span> <span class="o">:</span>
                <span class="n">ctx</span><span class="o">.</span><span class="na">getBroadcastState</span><span class="o">(</span><span class="n">ruleStateDescriptor</span><span class="o">).</span><span class="na">immutableEntries</span><span class="o">())</span> <span class="o">{</span>
            <span class="kd">final</span> <span class="n">String</span> <span class="n">ruleName</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">();</span>
            <span class="kd">final</span> <span class="n">Rule</span> <span class="n">rule</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getValue</span><span class="o">();</span>
    
            <span class="n">List</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">&gt;</span> <span class="n">stored</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">ruleName</span><span class="o">);</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">stored</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">stored</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;&gt;();</span>
            <span class="o">}</span>
    
            <span class="k">if</span> <span class="o">(</span><span class="n">shape</span> <span class="o">==</span> <span class="n">rule</span><span class="o">.</span><span class="na">second</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">stored</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
                <span class="k">for</span> <span class="o">(</span><span class="n">Item</span> <span class="n">i</span> <span class="o">:</span> <span class="n">stored</span><span class="o">)</span> <span class="o">{</span>
                    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="s">&#34;MATCH: &#34;</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">&#34; - &#34;</span> <span class="o">+</span> <span class="n">value</span><span class="o">);</span>
                <span class="o">}</span>
                <span class="n">stored</span><span class="o">.</span><span class="na">clear</span><span class="o">();</span>
            <span class="o">}</span>
    
            <span class="c1">// there is no else{} to cover if rule.first == rule.second
</span><span class="c1"></span>            <span class="k">if</span> <span class="o">(</span><span class="n">shape</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">rule</span><span class="o">.</span><span class="na">first</span><span class="o">))</span> <span class="o">{</span>
                <span class="n">stored</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
            <span class="o">}</span>
    
            <span class="k">if</span> <span class="o">(</span><span class="n">stored</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
                <span class="n">state</span><span class="o">.</span><span class="na">remove</span><span class="o">(</span><span class="n">ruleName</span><span class="o">);</span>
            <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                <span class="n">state</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ruleName</span><span class="o">,</span> <span class="n">stored</span><span class="o">);</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="重要的考虑因素">重要的考虑因素</h3>
<p>在介绍完提供的 API 之后，本节重点介绍使用广播状态时需要注意的重要事项。这些事项是</p>
<ul>
<li>
<p>没有跨任务通信。如前所述，这就是为什么只有 (Keyed)-BroadcastProcessFunction 的广播端可以修改广播状态的内容的原因。此外，用户必须确保所有的任务对每一个传入元素都以同样的方式修改广播状态的内容。否则，不同的任务可能有不同的内容，导致结果不一致。</p>
</li>
<li>
<p>不同任务的广播状态中事件的顺序可能不同。虽然广播流的元素保证了所有元素将（最终）进入所有下游任务，但元素可能会以不同的顺序到达每个任务。因此，每个传入元素的状态更新必须不依赖于传入事件的顺序。</p>
</li>
<li>
<p>所有的任务都会对其广播状态进行 checkpoint。虽然当 checkpoint 发生时，所有任务的广播状态中都有相同的元素（checkpoint 屏障不会超过元素），但所有任务都会 checkpoint 他们的广播状态，而不仅仅是其中一个。这是一个设计决定，以避免在还原过程中让所有任务从同一个文件中读取（从而避免热点），尽管它的代价是将检查点状态的大小增加了p的系数（=并行性）。Flink 保证在恢复/缩放时，不会有重复和丢失的数据。在以相同或更小的并行度进行恢复时，每个任务读取其检查点状态。扩容后，每个任务读取自己的状态，其余任务（p_new-p_old）以循环的方式读取之前任务的检查点。</p>
</li>
<li>
<p>没有 RocksDB 状态后端。广播状态在运行时保存在内存中，内存供应也应相应进行。这对所有的操作符状态都适用。</p>
</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/broadcast_state.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/broadcast_state.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[批处理例子]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="related" type="text/html" title="本地执行" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Batch Examples</blockquote><h2 id="batch-示例">Batch 示例</h2>
<p>下面的示例程序展示了 Flink 的不同应用，从简单的单词计数到图形算法。这些代码样本说明了 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">Flink 的 DataSet API</a> 的使用。</p>
<p>以下和更多例子的完整源代码可以在 Flink 源码库的 <a href="https://github.com/apache/flink/blob/master/flink-examples/flink-examples-batch">flink-examples-batch</a> 模块中找到。</p>
<h3 id="运行一个例子">运行一个例子</h3>
<p>为了运行一个 Flink 实例，我们假设你有一个正在运行的 Flink 实例。导航中的 &ldquo;Quickstart&rdquo; 和 &ldquo;Setup&rdquo; 选项卡描述了启动 Flink 的各种方法。</p>
<p>最简单的方法是运行 <code>./bin/start-cluster.sh</code>，默认情况下，它用一个 JobManager 和一个 TaskManager 启动一个本地集群。</p>
<p>Flink 的每个二进制版本都包含一个例子目录，其中有本页每个例子的 jar 文件。</p>
<p>要运行 WordCount 示例，请发出以下命令。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/flink run ./examples/batch/WordCount.jar
</code></pre></div><p>其他的例子也可以用类似的方式启动。</p>
<p>请注意，许多例子在运行时没有传递任何参数，而是使用内置的数据。要使用真实数据运行 WordCount，你必须传递数据的路径。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/flink run ./examples/batch/WordCount.jar --input /path/to/some/text/data --output /path/to/result
</code></pre></div><p>请注意，非本地文件系统需要一个模式前缀，如 <code>hdfs://</code>。</p>
<h3 id="wordcount">WordCount</h3>
<p>WordCount 是大数据处理系统中的 &ldquo;Hello World&rdquo;。它计算文本集合中的单词频率。该算法分两步工作。首先，文本被分割成单个单词。第二，对单词进行分组和计数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// get input data
</span><span class="c1"></span><span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;/path/to/file&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">text</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">toLowerCase</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;\\W+&#34;</span><span class="o">)</span> <span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">nonEmpty</span> <span class="o">}</span> <span class="o">}</span>
  <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="n">counts</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">)</span>
</code></pre></div><p><a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/wordcount/WordCount.scala">WordCount 的例子</a>实现了上面描述的算法，输入参数：<code>--input &lt;path&gt; --output &lt;path&gt;</code>。作为测试数据，任何文本文件都可以。</p>
<h3 id="页面排名">页面排名</h3>
<p>PageRank 算法计算由链接定义的图中页面的&quot;重要性&quot;，这些链接从一个页面指向另一个页面。它是一种迭代图算法，这意味着它反复应用相同的计算。在每一次迭代中，每个页面将其当前的排名分布在所有的邻居上，并计算其新的排名，作为它从邻居那里得到的排名的累加和。PageRank 算法是由 Google 搜索引擎推广的，它利用网页的重要性来对搜索查询的结果进行排名。</p>
<p>在这个简单的例子中，PageRank 的实现方式是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">批量迭代</a>和固定的迭代次数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// User-defined types
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">Link</span><span class="o">(</span><span class="n">sourceId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">targetId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Page</span><span class="o">(</span><span class="n">pageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">rank</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">AdjacencyList</span><span class="o">(</span><span class="n">sourceId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">targetIds</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Long</span><span class="o">])</span>

<span class="c1">// set up execution environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// read the pages and initial ranks by parsing a CSV file
</span><span class="c1"></span><span class="k">val</span> <span class="n">pages</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[</span><span class="kt">Page</span><span class="o">](</span><span class="n">pagesInputPath</span><span class="o">)</span>

<span class="c1">// the links are encoded as an adjacency list: (page-id, Array(neighbor-ids))
</span><span class="c1"></span><span class="k">val</span> <span class="n">links</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readCsvFile</span><span class="o">[</span><span class="kt">Link</span><span class="o">](</span><span class="n">linksInputPath</span><span class="o">)</span>

<span class="c1">// assign initial ranks to pages
</span><span class="c1"></span><span class="k">val</span> <span class="n">pagesWithRanks</span> <span class="k">=</span> <span class="n">pages</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">p</span> <span class="k">=&gt;</span> <span class="nc">Page</span><span class="o">(</span><span class="n">p</span><span class="o">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">numPages</span><span class="o">))</span>

<span class="c1">// build adjacency list from link input
</span><span class="c1"></span><span class="k">val</span> <span class="n">adjacencyLists</span> <span class="k">=</span> <span class="n">links</span>
  <span class="c1">// initialize lists
</span><span class="c1"></span>  <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">e</span> <span class="k">=&gt;</span> <span class="nc">AdjacencyList</span><span class="o">(</span><span class="n">e</span><span class="o">.</span><span class="n">sourceId</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="n">e</span><span class="o">.</span><span class="n">targetId</span><span class="o">)))</span>
  <span class="c1">// concatenate lists
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;sourceId&#34;</span><span class="o">).</span><span class="n">reduce</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">l1</span><span class="o">,</span> <span class="n">l2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">AdjacencyList</span><span class="o">(</span><span class="n">l1</span><span class="o">.</span><span class="n">sourceId</span><span class="o">,</span> <span class="n">l1</span><span class="o">.</span><span class="n">targetIds</span> <span class="o">++</span> <span class="n">l2</span><span class="o">.</span><span class="n">targetIds</span><span class="o">)</span>
  <span class="o">}</span>

<span class="c1">// start iteration
</span><span class="c1"></span><span class="k">val</span> <span class="n">finalRanks</span> <span class="k">=</span> <span class="n">pagesWithRanks</span><span class="o">.</span><span class="n">iterateWithTermination</span><span class="o">(</span><span class="n">maxIterations</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">currentRanks</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">newRanks</span> <span class="k">=</span> <span class="n">currentRanks</span>
      <span class="c1">// distribute ranks to target pages
</span><span class="c1"></span>      <span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">adjacencyLists</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;pageId&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;sourceId&#34;</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">(</span><span class="n">page</span><span class="o">,</span> <span class="n">adjacent</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Page</span><span class="o">])</span> <span class="k">=&gt;</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">targetId</span> <span class="k">&lt;-</span> <span class="n">adjacent</span><span class="o">.</span><span class="n">targetIds</span><span class="o">)</span> <span class="o">{</span>
          <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">Page</span><span class="o">(</span><span class="n">targetId</span><span class="o">,</span> <span class="n">page</span><span class="o">.</span><span class="n">rank</span> <span class="o">/</span> <span class="n">adjacent</span><span class="o">.</span><span class="n">targetIds</span><span class="o">.</span><span class="n">length</span><span class="o">))</span>
        <span class="o">}</span>
      <span class="o">}</span>
      <span class="c1">// collect ranks and sum them up
</span><span class="c1"></span>      <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&#34;pageId&#34;</span><span class="o">).</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">SUM</span><span class="o">,</span> <span class="s">&#34;rank&#34;</span><span class="o">)</span>
      <span class="c1">// apply dampening factor
</span><span class="c1"></span>      <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">p</span> <span class="k">=&gt;</span>
        <span class="nc">Page</span><span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="n">pageId</span><span class="o">,</span> <span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="n">rank</span> <span class="o">*</span> <span class="nc">DAMPENING_FACTOR</span><span class="o">)</span> <span class="o">+</span> <span class="o">((</span><span class="mi">1</span> <span class="o">-</span> <span class="nc">DAMPENING_FACTOR</span><span class="o">)</span> <span class="o">/</span> <span class="n">numPages</span><span class="o">))</span>
      <span class="o">}</span>

    <span class="c1">// terminate if no rank update was significant
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">termination</span> <span class="k">=</span> <span class="n">currentRanks</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">newRanks</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="s">&#34;pageId&#34;</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="s">&#34;pageId&#34;</span><span class="o">)</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">current</span><span class="o">,</span> <span class="n">next</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span> <span class="k">=&gt;</span>
        <span class="c1">// check for significant update
</span><span class="c1"></span>        <span class="k">if</span> <span class="o">(</span><span class="n">math</span><span class="o">.</span><span class="n">abs</span><span class="o">(</span><span class="n">current</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="n">next</span><span class="o">.</span><span class="n">rank</span><span class="o">)</span> <span class="o">&gt;</span> <span class="nc">EPSILON</span><span class="o">)</span> <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="o">(</span><span class="n">newRanks</span><span class="o">,</span> <span class="n">termination</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">finalRanks</span>

<span class="c1">// emit result
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">)</span>
</code></pre></div><p><a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/graph/PageRankBasic.scala">PageRank 程序</a>实现了上述示例。它需要以下参数才能运行。<code>--pages &lt;path&gt; --links &lt;path&gt; --output &lt;path&gt; --numPages &lt;n&gt; --iterations &lt;n&gt;</code>。</p>
<p>输入文件是纯文本文件，必须按以下格式进行。</p>
<ul>
<li>页数用一个（长）ID 表示，用换行字符分隔。
<ul>
<li>例如 &ldquo;1/n2/n12/n42/n63/n&rdquo; 给出了 5 个 ID 为 1、2、12、42 和 63 的页面。</li>
</ul>
</li>
<li>链接用页面 ID 对表示，用空格分隔。链接用换行符分隔。
<ul>
<li>例如 &ldquo;1 2\n2 12\n1 12\n42 63\n&rdquo; 给出了四个(定向)链接(1)-&gt;(2)，(2)-&gt;(12)，(1)-&gt;(12)和(42)-&gt;(63)。</li>
</ul>
</li>
</ul>
<p>对于这个简单的实现，要求每个页面至少有一个入站链接和一个出站链接（一个页面可以指向自己）。</p>
<h3 id="连接的组件">连接的组件</h3>
<p>Connected Components 算法通过给同一连接部分中的所有顶点分配相同的组件 ID，来识别较大图中相互连接的部分。与 PageRank 类似，Connected Components 是一种迭代算法。在每一步中，每个顶点将其当前的组件 ID 传播给所有的邻居。如果一个顶点接受来自邻居的组件 ID，如果它小于自己的组件 ID。</p>
<p>本实现使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">增量迭代</a>。没有改变组件 ID 的顶点不参与下一步。这产生了更好的性能，因为后面的迭代通常只处理一些离群的顶点。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// set up execution environment
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// read vertex and edge data
</span><span class="c1">// assign the initial components (equal to the vertex id)
</span><span class="c1"></span><span class="k">val</span> <span class="n">vertices</span> <span class="k">=</span> <span class="n">getVerticesDataSet</span><span class="o">(</span><span class="n">env</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="n">id</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">id</span><span class="o">)</span> <span class="o">}</span>

<span class="c1">// undirected edges by emitting for each input edge the input edges itself and an inverted
</span><span class="c1">// version
</span><span class="c1"></span><span class="k">val</span> <span class="n">edges</span> <span class="k">=</span> <span class="n">getEdgesDataSet</span><span class="o">(</span><span class="n">env</span><span class="o">).</span><span class="n">flatMap</span> <span class="o">{</span> <span class="n">edge</span> <span class="k">=&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">edge</span><span class="o">,</span> <span class="o">(</span><span class="n">edge</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">_1</span><span class="o">))</span> <span class="o">}</span>

<span class="c1">// open a delta iteration
</span><span class="c1"></span><span class="k">val</span> <span class="n">verticesWithComponents</span> <span class="k">=</span> <span class="n">vertices</span><span class="o">.</span><span class="n">iterateDelta</span><span class="o">(</span><span class="n">vertices</span><span class="o">,</span> <span class="n">maxIterations</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="n">ws</span><span class="o">)</span> <span class="k">=&gt;</span>

    <span class="c1">// apply the step logic: join with the edges
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">allNeighbors</span> <span class="k">=</span> <span class="n">ws</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">edges</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">{</span> <span class="o">(</span><span class="n">vertex</span><span class="o">,</span> <span class="n">edge</span><span class="o">)</span> <span class="k">=&gt;</span>
      <span class="o">(</span><span class="n">edge</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">vertex</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="c1">// select the minimum neighbor
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">minNeighbors</span> <span class="k">=</span> <span class="n">allNeighbors</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">min</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

    <span class="c1">// update if the component of the candidate is smaller
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">updatedComponents</span> <span class="k">=</span> <span class="n">minNeighbors</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">s</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">equalTo</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">newVertex</span><span class="o">,</span> <span class="n">oldVertex</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)])</span> <span class="k">=&gt;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">newVertex</span><span class="o">.</span><span class="n">_2</span> <span class="o">&lt;</span> <span class="n">oldVertex</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">newVertex</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="c1">// delta and new workset are identical
</span><span class="c1"></span>    <span class="o">(</span><span class="n">updatedComponents</span><span class="o">,</span> <span class="n">updatedComponents</span><span class="o">)</span>
<span class="o">}</span>

<span class="n">verticesWithComponents</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">outputPath</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">)</span>
</code></pre></div><p><a href="https://github.com/apache/flink/blob/master//flink-examples/flink-examples-batch/src/main/scala/org/apache/flink/examples/scala/graph/ConnectedComponents.scala">ConnectedComponents 程序</a>实现了上面的例子。它需要以下参数才能运行: <code>--vertices &lt;path&gt; --edges &lt;path&gt; --output &lt;path&gt; --iterations &lt;n&gt;</code>。</p>
<p>输入文件是纯文本文件，必须按如下格式编写。</p>
<ul>
<li>顶点用 ID 表示，并用换行符隔开。
<ul>
<li>例如 &ldquo;1/n2/n12/n42/n63/n&rdquo; 给出了五个顶点，分别是(1)、(2)、(12)、(42)和(63)。</li>
</ul>
</li>
<li>边缘用一对顶点 ID 表示，这些顶点 ID 用空格字符分隔。边缘用换行符隔开。
<ul>
<li>例如，&ldquo;1 2/n2 12/n1 12/n42 63/n&rdquo; 给出了四个(非直接)联系(1)-(2)、(2)-(12)、(1)-(12)和(42)-(63)。</li>
</ul>
</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/examples.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/examples.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[数据源]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-data-sources/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-data-sources/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Data Sources</blockquote><p>注：这描述了新的数据源 API ，作为 FLIP-27 的一部分在 Flink 1.11 中引入。这个新的 API 目前处于 BETA 状态。
大多数现有的源连接器还没有（截至 Flink 1.11 ）使用这个新的 API 实现，而是使用以前的 API ，基于 SourceFunction 。
本页介绍了 Flink 的数据源 API 及其背后的概念和架构。如果你对 Flink 中的数据源是如何工作的，或者你想实现一个新的数据源，请阅读本页面。</p>
<p>如果您正在寻找预定义的源连接器，请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/">连接器文档</a>。</p>
<h2 id="数据源概念">数据源概念</h2>
<p><strong>核心部件</strong></p>
<p>一个数据源有三个核心组件。<code>Split</code>、<code>SplitEnumerator</code> 和 <code>SourceReader</code>。</p>
<ul>
<li>
<p><code>Split</code> 是数据源所消耗的一部分数据，就像一个文件或一个日志分区。<code>Split</code> 是源分配工作和并行读取数据的粒度。</p>
</li>
<li>
<p><code>SourceReader</code> 请求 <code>Split</code> 并进行处理，例如读取 <code>Split</code> 所代表的文件或日志分区。<code>SourceReader</code> 在 <code>SourceOperators</code> 的 Task Manager 上并行运行，并产生事件/记录的并行流。</p>
</li>
<li>
<p><code>SplitEnumerator</code> 生成 <code>Split</code> 并将它们分配给 <code>SourceReader</code> 。它作为单个实例在任务管理器上运行，负责维护待处理的 <code>Split</code> 的积压，并以平衡的方式将它们分配给读者。</p>
</li>
</ul>
<p><code>Source</code> 类是将上述三个组件联系在一起的 API 入口点。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/source_components.svg" alt="img"></p>
<p><strong>统一的跨流和批处理</strong></p>
<p>数据源 API 以统一的方式支持无界流源和有界批处理源。</p>
<p>这两种情况的区别很小：在有界/批处理的情况下，枚举器生成一组固定的 split ，而且每个 split 必然是有限的。在无界流的情况下，这两种情况中的一种是不正确的（ split 不是有限的，或者枚举器不断产生新的 split ）。</p>
<h3 id="例子">例子</h3>
<p>下面是一些简化的概念性例子，以说明在流式和批处理情况下，数据源组件如何交互。</p>
<p>请注意，这并不能准确地描述 Kafka 和 File 源的实现是如何工作的；部分内容是简化的，用于说明目的。</p>
<p><strong>绑定的文件源</strong></p>
<p>源有一个要读取的目录的 URI/路径，以及一个定义如何解析文件的格式。</p>
<ul>
<li><code>Split</code> 是一个文件，或者一个文件的一个区域（如果数据格式支持分割文件）。</li>
<li><code>SplitEnumerator</code> 列出了给定目录路径下的所有文件。它将 <code>Split</code> 分配给下一个请求 <code>Split</code> 的读者。一旦所有的 <code>Split</code> 都分配完毕，它就会用 <code>NoMoreSplits</code> 来响应请求。</li>
<li>SourceReader 请求一个 <code>Split</code> ，并读取被分配的 <code>Split</code> （文件或文件区域），并使用给定的格式进行解析。如果它没有得到另一个 <code>Split</code> ，而是得到一个 <code>NoMoreSplits</code> 消息，它就结束了。</li>
</ul>
<p><strong>非绑定流文件源</strong></p>
<p>这个源的工作方式和上面描述的一样，除了 <code>SplitEnumerator</code> 从不响应 <code>NoMoreSplits</code> ，而是周期性地列出给定 <code>URI/Path</code> 下的内容以检查新文件。一旦发现新文件，它就会为它们生成新的 <code>Splits</code> ，并可以将它们分配给可用的 <code>SourceReaders</code>。</p>
<p><strong>无界流 Kafka 源</strong></p>
<p>该源有一个 Kafka Topic （或 Topic 列表或 Topic regex ）和一个 Deserializer 来解析记录。</p>
<ul>
<li>一个 Split 就是一个 Kafka Topic 分区。</li>
<li>SplitEnumerator 连接到 brokers ，以列出所有涉及订阅的主题分区。枚举器可以选择重复这个操作来发现新添加的主题/分区。</li>
<li>SourceReader 使用 KafkaConsumer 读取分配的 split （主题分区），并使用提供的 Deserializer 反序列化记录。分割(Topic Partitions) 没有终点，所以读取器永远不会到达数据的终点。</li>
</ul>
<p><strong>绑定的 Kafka 源</strong></p>
<p>和上面一样，只是每个 Split （主题分区）有一个定义的结束偏移量。一旦 SourceReader 达到一个 Split 的结束偏移量，它就会完成该 Split 。一旦所有分配的 Split 结束， SourceReader 就结束了。</p>
<h2 id="数据源-api">数据源 API</h2>
<p>本节介绍了 FLIP-27 中新引入的 Source API 的主要接口，并为开发者提供了 Source 开发的技巧。</p>
<h3 id="source">Source</h3>
<p><a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Source.java">Source</a> API 是一个工厂风格的接口，用于创建以下组件。</p>
<ul>
<li>Split Enumerator</li>
<li>源读取器</li>
<li>分离式序列器</li>
<li>枚举器检查点序列器</li>
</ul>
<p>除此之外， Source 还提供了源的<a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Boundedness.java">边界</a>属性，这样 Flink 可以选择合适的模式来运行 Flink 作业。</p>
<p>Source 的实现应该是可序列化的，因为 Source 实例在运行时被序列化并上传到 Flink 集群。</p>
<h3 id="splitenumerator">SplitEnumerator</h3>
<p><a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/SplitEnumerator.java">SplitEnumerator</a> 有望成为 Source 的&quot;大脑&quot;。SplitEnumerator 的典型实现会做以下工作。</p>
<ul>
<li>SourceReader 注册处理</li>
<li>SourceReader 失败处理
<ul>
<li>当 SourceReader 失败时，将调用 <code>addSplitsBack()</code> 方法。SplitEnumerator 应该收回未被失败的 SourceReader 承认的分割分配。</li>
</ul>
</li>
<li>SourceEvent 处理
<ul>
<li>SourceEvents 是在 SplitEnumerator 和 SourceReader 之间发送的自定义事件。实现可以利用这种机制来进行复杂的协调。</li>
</ul>
</li>
<li>分割发现和分配
<ul>
<li>SplitEnumerator 可以根据各种事件将 split 分配给 SourceReaders ，包括发现新的 split 、新的 SourceReader 注册、 SourceReader 失败等。</li>
</ul>
</li>
</ul>
<p>SplitEnumerator 可以借助 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/SplitEnumeratorContext.java">SplitEnumeratorContext</a> 完成上述工作， SplitEnumeratorContext 是在创建或恢复 SplitEnumerator 时提供给 Source 的。SplitEnumeratorContext 允许 SplitEnumerator 检索读取器的必要信息并执行协调动作。Source 实现应该将 SplitEnumeratorContext 传递给 SplitEnumerator 实例。</p>
<p>虽然 SplitEnumerator 实现可以通过只在它的方法被调用时采取协调动作的被动方式很好地工作，但一些 SplitEnumerator 实现可能希望主动采取行动。例如，一个 SplitEnumerator 可能希望定期运行 split discovery ，并将新的 split 分配给 SourceReaders 。这样的实现可能会发现调用 Async() 方法 SplitEnumeratorContext 很方便。下面的代码片段展示了 SplitEnumerator 实现如何在不维护自己的线程的情况下实现这一点。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MySplitEnumerator</span> <span class="n">implements</span> <span class="nc">SplitEnumerator</span><span class="o">&lt;</span><span class="nc">MySplit</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="k">private</span> <span class="k">final</span> <span class="n">long</span> <span class="nc">DISCOVER_INTERVAL</span> <span class="k">=</span> <span class="mi">60</span><span class="n">_000L</span><span class="o">;</span>

    <span class="cm">/**
</span><span class="cm">     * A method to discover the splits.
</span><span class="cm">     */</span>
    <span class="k">private</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">MySplit</span><span class="o">&gt;</span> <span class="n">discoverSplits</span><span class="o">()</span> <span class="o">{...}</span>
    
    <span class="nd">@Override</span>
    <span class="n">public</span> <span class="n">void</span> <span class="n">start</span><span class="o">()</span> <span class="o">{</span>
        <span class="o">...</span>
        <span class="n">enumContext</span><span class="o">.</span><span class="n">callAsync</span><span class="o">(</span><span class="k">this:</span><span class="kt">:discoverSplits</span><span class="o">,</span> <span class="n">splits</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">MockSourceSplit</span><span class="o">&gt;&gt;</span> <span class="n">assignments</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashMap</span><span class="o">&lt;&gt;();</span>
            <span class="n">int</span> <span class="n">parallelism</span> <span class="k">=</span> <span class="n">enumContext</span><span class="o">.</span><span class="n">currentParallelism</span><span class="o">();</span>
            <span class="k">for</span> <span class="o">(</span><span class="nc">MockSourceSplit</span> <span class="n">split</span> <span class="k">:</span> <span class="kt">splits</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">int</span> <span class="n">owner</span> <span class="k">=</span> <span class="n">split</span><span class="o">.</span><span class="n">splitId</span><span class="o">().</span><span class="n">hashCode</span><span class="o">()</span> <span class="o">%</span> <span class="n">parallelism</span><span class="o">;</span>
                <span class="n">assignments</span><span class="o">.</span><span class="n">computeIfAbsent</span><span class="o">(</span><span class="n">owner</span><span class="o">,</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;()).</span><span class="n">add</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>
            <span class="o">}</span>
            <span class="n">enumContext</span><span class="o">.</span><span class="n">assignSplits</span><span class="o">(</span><span class="k">new</span> <span class="nc">SplitsAssignment</span><span class="o">&lt;&gt;(</span><span class="n">assignments</span><span class="o">));</span>
        <span class="o">},</span> <span class="mi">0L</span><span class="o">,</span> <span class="nc">DISCOVER_INTERVAL</span><span class="o">);</span>
        <span class="o">...</span>
    <span class="o">}</span>
    <span class="o">...</span>
<span class="o">}</span>
</code></pre></div><h2 id="sourcereader">SourceReader</h2>
<p>SourceReader 是一个运行在 Task Manager 中的组件，用于消耗来自 Splits 的记录。</p>
<p>SourceReader 暴露了一个基于拉的消费接口。一个 Flink 任务在循环中不断调用 pollNext(ReaderOutput) 来轮询 SourceReader 的记录。pollNext(ReaderOutput) 方法的返回值表示源阅读器的状态。</p>
<ul>
<li>MORE_AVAILABLE - SourceReader 立即有更多的记录可用。</li>
<li>NOTHING_AVAILABLE - SourceReader 此时没有更多的记录可用，但将来可能会有更多的记录。</li>
<li>END_OF_INPUT - SourceReader 已经用完了所有的记录，达到了数据的终点。这意味着 SourceReader 可以被关闭。</li>
</ul>
<p>为了保证性能，会给 pollNext(ReaderOutput) 方法提供一个 ReaderOutput ，所以如果有必要， SourceReader 可以在一次调用 pollNext() 的过程中发出多条记录。例如，有时外部系统的工作粒度是块。一个块可能包含多条记录，但源码只能在块的边界处进行检查点。在这种情况下， SourceReader 可以一次将一个块中的所有记录排放到 ReaderOutput 。但是，除非必要， SourceReader 的实现应该避免在一次 pollNext(ReaderOutput) 的调用中发射多条记录。这是因为从 SourceReader 中进行轮询的任务线程是在事件循环中工作的，不能阻塞。</p>
<p>SourceReader 的所有状态都应该维护在 SourceSplits 里面，这些状态在 snapshotState() 调用时返回。这样做可以在需要时将 SourceSplits 重新分配给其他 SourceReaders 。</p>
<p>在创建 SourceReader 时，会向 Source 提供一个 SourceReaderContext 。预计 Source 将把上下文传递给 SourceReader 实例。SourceReader 可以通过 SourceReaderContext 向其 SplitEnumerator 发送 SourceEvent 。Source 的一个典型的设计模式是让 SourceReaders 向 SplitEnumerator 报告它们的本地信息， SplitEnumerator 有一个全局视图来做决策。</p>
<p>SourceReader API 是一个低级的 API ，它允许用户手动处理 split ，并有自己的线程模型来获取和交接记录。为了方便 SourceReader 的实现， Flink 提供了一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/SourceReaderBase.java">SourceReaderBase</a> 类，大大减少了编写 SourceReader 的工作量。强烈建议连接器开发人员利用 SourceReaderBase ，而不是从头开始编写 SourceReaders 。更多细节请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html#the-split-reader-api">Split Reader API</a> 部分。</p>
<h3 id="使用-source">使用 Source</h3>
<p>为了从 Source 创建 DataStream ，需要将 Source 传递给 StreamExecutionEnvironment。例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">mySource</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySource</span><span class="o">(...)</span>

<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromSource</span><span class="o">(</span>
      <span class="n">mySource</span><span class="o">,</span>
      <span class="nc">WatermarkStrategy</span><span class="o">.</span><span class="n">noWatermarks</span><span class="o">(),</span>
      <span class="s">&#34;MySourceName&#34;</span><span class="o">)</span>
<span class="o">...</span>
</code></pre></div><h2 id="split-读取器-api">Split 读取器 API</h2>
<p>核心的 SourceReader API 是完全异步的，需要实现者手动管理异步拆分读取。然而，在实践中，大多数 Source 使用执行阻塞操作，比如在客户端（例如 KafkaConsumer ）上阻塞 poll() 调用，或者在分布式文件系统（ HDFS ， S3 ，&hellip;）上阻塞 I/O 操作。为了与异步的 Source API 兼容，这些阻塞（同步）操作需要发生在单独的线程中，线程将数据交给异步部分的阅读器。</p>
<p><a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/splitreader/SplitReader.java">SplitReader</a> 是用于简单的基于同步读取/轮询的源码实现的高级 API ，比如文件读取、 Kafka 等。</p>
<p>核心是 SourceReaderBase 类，它接收一个 SplitReader 并创建运行 SplitReader 的 fetcher 线程，支持不同的消费线程模型。</p>
<h3 id="splitreader">SplitReader</h3>
<p>SplitReader API 只有三个方法。</p>
<ul>
<li>一个阻塞获取方法，返回一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/RecordsWithSplitIds.java">RecordsWithSplitIds</a> 。</li>
<li>一种非阻塞方法，用于处理拆分变化。</li>
<li>一个非阻塞的唤醒方法，用于唤醒阻塞的获取操作。</li>
</ul>
<p>SplitReader 只专注于从外部系统读取记录，因此比 SourceReader 简单得多。详情请查看该类的 Java 文档。</p>
<h3 id="sourcereaderbase">SourceReaderBase</h3>
<p>SourceReader 的实现很常见，它做了以下工作。</p>
<ul>
<li>拥有一个线程池，以阻塞的方式从外部系统的分割处获取数据。</li>
<li>处理内部获取线程和其他方法调用之间的同步，如 pollNext(ReaderOutput) 。</li>
<li>维护每个 split 的水印，以便进行水印对齐。</li>
<li>维护每个分身的状态，以便检查点。</li>
</ul>
<p>为了减少编写一个新的 SourceReader 的工作， Flink 提供了一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/SourceReaderBase.java">SourceReaderBase</a> 类作为 SourceReader 的基础实现。SourceReaderBase 开箱即完成了上述所有工作。如果要编写一个新的 SourceReader ，只需要让 SourceReader 实现继承 SourceReaderBase ，填充一些方法，然后实现一个高级的 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/splitreader/SplitReader.java">SplitReader</a> 就可以了。</p>
<h3 id="splitfetchermanager">SplitFetcherManager</h3>
<p>SourceReaderBase 支持一些开箱即用的线程模型，这取决于与之合作的 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/fetcher/SplitFetcherManager.java">SplitFetcherManager</a> 的行为。SplitFetcherManager 帮助创建和维护一个 SplitFetcher 池，每个 SplitFetcher 用一个 SplitReader 来获取。它还决定了如何将 split 分配给每个 split fetcher 。</p>
<p>举个例子，如下图所示，一个 SplitFetcherManager 可能有固定数量的线程，每个线程从分配给 SourceReader 的一些 split 中获取。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/source_reader.svg" alt="img"></p>
<p>下面的代码片段实现了这个线程模型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * A SplitFetcherManager that has a fixed size of split fetchers and assign splits 
</span><span class="cm"> * to the split fetchers based on the hash code of split IDs.
</span><span class="cm"> */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">FixedSizeSplitFetcherManager</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span> <span class="kd">extends</span> <span class="n">SourceSplit</span><span class="o">&gt;</span> 
        <span class="kd">extends</span> <span class="n">SplitFetcherManager</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">numFetchers</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">FixedSizeSplitFetcherManager</span><span class="o">(</span>
            <span class="kt">int</span> <span class="n">numFetchers</span><span class="o">,</span>
            <span class="n">FutureNotifier</span> <span class="n">futureNotifier</span><span class="o">,</span>
            <span class="n">FutureCompletingBlockingQueue</span><span class="o">&lt;</span><span class="n">RecordsWithSplitIds</span><span class="o">&lt;</span><span class="n">E</span><span class="o">&gt;&gt;</span> <span class="n">elementsQueue</span><span class="o">,</span>
            <span class="n">Supplier</span><span class="o">&lt;</span><span class="n">SplitReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitReaderSupplier</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">futureNotifier</span><span class="o">,</span> <span class="n">elementsQueue</span><span class="o">,</span> <span class="n">splitReaderSupplier</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">numFetchers</span> <span class="o">=</span> <span class="n">numFetchers</span><span class="o">;</span>
        <span class="c1">// Create numFetchers split fetchers.
</span><span class="c1"></span>        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numFetchers</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="n">startFetcher</span><span class="o">(</span><span class="n">createSplitFetcher</span><span class="o">());</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">addSplits</span><span class="o">(</span><span class="n">List</span><span class="o">&lt;</span><span class="n">SplitT</span><span class="o">&gt;</span> <span class="n">splitsToAdd</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Group splits by their owner fetchers.
</span><span class="c1"></span>        <span class="n">Map</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitsByFetcherIndex</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
        <span class="n">splitsToAdd</span><span class="o">.</span><span class="na">forEach</span><span class="o">(</span><span class="n">split</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">ownerFetcherIndex</span> <span class="o">=</span> <span class="n">split</span><span class="o">.</span><span class="na">hashCode</span><span class="o">()</span> <span class="o">%</span> <span class="n">numFetchers</span><span class="o">;</span>
            <span class="n">splitsByFetcherIndex</span>
                    <span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">ownerFetcherIndex</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;&gt;())</span>
                    <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>
        <span class="o">});</span>
        <span class="c1">// Assign the splits to their owner fetcher.
</span><span class="c1"></span>        <span class="n">splitsByFetcherIndex</span><span class="o">.</span><span class="na">forEach</span><span class="o">((</span><span class="n">fetcherIndex</span><span class="o">,</span> <span class="n">splitsForFetcher</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="n">fetchers</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">fetcherIndex</span><span class="o">).</span><span class="na">addSplits</span><span class="o">(</span><span class="n">splitsForFetcher</span><span class="o">);</span>
        <span class="o">});</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>而使用这个线程模型的 SourceReader 可以创建如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">FixedFetcherSizeSourceReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitT</span> <span class="kd">extends</span> <span class="n">SourceSplit</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span>
        <span class="kd">extends</span> <span class="n">SourceReaderBase</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nf">FixedFetcherSizeSourceReader</span><span class="o">(</span>
            <span class="n">FutureNotifier</span> <span class="n">futureNotifier</span><span class="o">,</span>
            <span class="n">FutureCompletingBlockingQueue</span><span class="o">&lt;</span><span class="n">RecordsWithSplitIds</span><span class="o">&lt;</span><span class="n">E</span><span class="o">&gt;&gt;</span> <span class="n">elementsQueue</span><span class="o">,</span>
            <span class="n">Supplier</span><span class="o">&lt;</span><span class="n">SplitReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitFetcherSupplier</span><span class="o">,</span>
            <span class="n">RecordEmitter</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span> <span class="n">recordEmitter</span><span class="o">,</span>
            <span class="n">Configuration</span> <span class="n">config</span><span class="o">,</span>
            <span class="n">SourceReaderContext</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span>
                <span class="n">futureNotifier</span><span class="o">,</span>
                <span class="n">elementsQueue</span><span class="o">,</span>
                <span class="k">new</span> <span class="n">FixedSizeSplitFetcherManager</span><span class="o">&lt;&gt;(</span>
                        <span class="n">config</span><span class="o">.</span><span class="na">getInteger</span><span class="o">(</span><span class="n">SourceConfig</span><span class="o">.</span><span class="na">NUM_FETCHERS</span><span class="o">),</span>
                        <span class="n">futureNotifier</span><span class="o">,</span>
                        <span class="n">elementsQueue</span><span class="o">,</span>
                        <span class="n">splitFetcherSupplier</span><span class="o">),</span>
                <span class="n">recordEmitter</span><span class="o">,</span>
                <span class="n">config</span><span class="o">,</span>
                <span class="n">context</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">onSplitFinished</span><span class="o">(</span><span class="n">Collection</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">finishedSplitIds</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Do something in the callback for the finished splits.
</span><span class="c1"></span>    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">SplitStateT</span> <span class="nf">initializedState</span><span class="o">(</span><span class="n">SplitT</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">SplitT</span> <span class="nf">toSplitType</span><span class="o">(</span><span class="n">String</span> <span class="n">splitId</span><span class="o">,</span> <span class="n">SplitStateT</span> <span class="n">splitState</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>显然， SourceReader 的实现也可以在 SplitFetcherManager 和 SourceReaderBase 之上轻松实现自己的线程模型。</p>
<h2 id="事件时间和水印">事件时间和水印</h2>
<p>事件时间分配和水印生成作为数据源的一部分发生。离开源读取器的事件流具有事件时间戳，并且（在流执行期间）包含水印。有关事件时间和水印的介绍，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html">及时流处理</a>。</p>
<p>重要事项 基于传统 <a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SourceFunction.java">SourceFunction</a> 的应用程序通常会在后面单独的步骤中通过 stream.assignTimestampsAndWatermarks(WatermarkStrategy) 生成时间戳和水印。这个函数不应该被用于新的源，因为时间戳将被分配，并且它将覆盖之前的分割感知水印。</p>
<h3 id="api">API</h3>
<p>在 DataStream API 创建期间， WatermarkStrategy 被传递给 Source，并创建 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/eventtime/TimestampAssigner.java">TimestampAssigner</a> 和 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/eventtime/WatermarkGenerator.java">WatermarkGenerator</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">environment</span><span class="o">.</span><span class="n">fromSource</span><span class="o">(</span>
    <span class="nc">Source</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">,</span> <span class="o">?,</span> <span class="o">?&gt;</span> <span class="n">source</span><span class="o">,</span>
    <span class="nc">WatermarkStrategy</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">&gt;</span> <span class="n">timestampsAndWatermarks</span><span class="o">,</span>
    <span class="nc">String</span> <span class="n">sourceName</span><span class="o">)</span>
</code></pre></div><p>TimestampAssigner 和 WatermarkGenerator 作为 ReaderOutput(或 SourceOutput) 的一部分透明地运行，因此源码实现者不必实现任何时间戳提取和水印生成代码。</p>
<h3 id="事件时间戳">事件时间戳</h3>
<p>事件时间戳的分配有两个步骤。</p>
<ol>
<li>
<p>SourceReader 可以通过调用 SourceOutput.collect(event, timestamp) 将源记录时间戳附加到事件上。这只与基于记录且有时间戳的数据源有关，如 Kafka 、 Kinesis 、 Pulsar 或 Pravega 。不基于记录且有时间戳的数据源（如文件）没有源记录时间戳。这一步是源连接器实现的一部分，而不是由使用源的应用程序参数化。</p>
</li>
<li>
<p>由应用程序配置的 TimestampAssigner 分配最终的时间戳。TimestampAssigner 看到原始源记录时间戳和事件。分配者可以使用源记录时间戳或访问事件的一个字段获得最终的事件时间戳。</p>
</li>
</ol>
<p>这种两步法允许用户同时引用源系统的时间戳和事件数据中的时间戳作为事件时间戳。</p>
<p>注意：当使用没有源记录时间戳的数据源（如文件），并选择源记录时间戳作为最终的事件时间戳时，事件将得到一个默认的时间戳，等于 LONG_MIN （=-9,223,372,036,854,775,808 ）。</p>
<h3 id="水印生成">水印生成</h3>
<p>水印生成器仅在流式执行期间激活。批量执行会停用水印生成器；下面描述的所有相关操作都将成为有效的无操作。</p>
<p>数据源 API 支持每次拆分单独运行水印生成器。这使得 Flink 可以单独观察每个分体的事件时间进度，这对于正确处理事件时间偏斜和防止空闲分区拖累整个应用的事件时间进度非常重要。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/per_split_watermarks.svg" alt="img"></p>
<p>当使用 Split Reader API 实现一个源连接器时，会自动处理这个问题。所有基于 Split Reader API 的实现都具有开箱即用的 split-aware 水印。</p>
<p>对于一个低级别的 SourceReader API 的实现来说，要使用 split-aware 水印的生成，该实现必须将不同的 split 事件输出到不同的输出中： Split-local SourceOutputs 。分割本地输出可以通过 createOutputForSplit(splitId) 和 releaseOutputForSplit(splitId) 方法在主 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/ReaderOutput.java">ReaderOutput</a> 上创建和释放。详情请参考该类和方法的 JavaDocs 。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/data-sources" term="data-sources" label="Data Sources" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[数据集中的 zipping 元素]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="related" type="text/html" title="本地执行" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Zipping Elements in a Dataset</blockquote><h2 id="zipping-数据集中的元素">Zipping 数据集中的元素</h2>
<p>在某些算法中，人们可能需要为数据集元素分配唯一的标识符。本文档介绍了如何将 <a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java/utils/DataSetUtils.java">DataSetUtils</a> 用于该目的。</p>
<h3 id="使用密集索引进行-zip">使用密集索引进行 Zip</h3>
<p><code>zipWithIndex</code> 给元素分配连续的标签，接收一个数据集作为输入，并返回一个新的（唯一id，初始值）2-tuples的数据集。这个过程需要两次传递，先计数再给元素贴标签，而且由于计数的同步性，不能采用流水线方式。备选的 <code>zipWithUniqueId</code> 以流水线的方式工作，当唯一的标签已经足够时，首选 <code>zip</code>。例如，下面的代码。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>

<span class="k">val</span> <span class="n">env</span><span class="k">:</span> <span class="kt">ExecutionEnvironment</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="s">&#34;A&#34;</span><span class="o">,</span> <span class="s">&#34;B&#34;</span><span class="o">,</span> <span class="s">&#34;C&#34;</span><span class="o">,</span> <span class="s">&#34;D&#34;</span><span class="o">,</span> <span class="s">&#34;E&#34;</span><span class="o">,</span> <span class="s">&#34;F&#34;</span><span class="o">,</span> <span class="s">&#34;G&#34;</span><span class="o">,</span> <span class="s">&#34;H&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">zipWithIndex</span>

<span class="n">result</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">resultPath</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34;,&#34;</span><span class="o">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><p>可以得到元组: (0,G), (1,H), (2,A), (3,B), (4,C), (5,D), (6,E), (7,F)</p>
<h3 id="带有唯一标识符的-zip">带有唯一标识符的 Zip</h3>
<p>在许多情况下，人们可能不需要分配连续的标签，<code>zipWithUniqueId</code> 以流水线的方式工作，加快了标签分配过程。该方法接收一个数据集作为输入，并返回一个由（唯一id，初始值）2-tuples组成的新数据集。例如，下面的代码。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>

<span class="k">val</span> <span class="n">env</span><span class="k">:</span> <span class="kt">ExecutionEnvironment</span> <span class="o">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="s">&#34;A&#34;</span><span class="o">,</span> <span class="s">&#34;B&#34;</span><span class="o">,</span> <span class="s">&#34;C&#34;</span><span class="o">,</span> <span class="s">&#34;D&#34;</span><span class="o">,</span> <span class="s">&#34;E&#34;</span><span class="o">,</span> <span class="s">&#34;F&#34;</span><span class="o">,</span> <span class="s">&#34;G&#34;</span><span class="o">,</span> <span class="s">&#34;H&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">zipWithUniqueId</span>

<span class="n">result</span><span class="o">.</span><span class="n">writeAsCsv</span><span class="o">(</span><span class="n">resultPath</span><span class="o">,</span> <span class="s">&#34;\n&#34;</span><span class="o">,</span> <span class="s">&#34;,&#34;</span><span class="o">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><p>可以得到元组: (0,G), (1,A), (2,H), (3,B), (5,C), (7,D), (9,E), (11,F)</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/zip_elements_guide.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/zip_elements_guide.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[时间属性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-time-attributes/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Time Attributes</blockquote><h1 id="时间属性">时间属性</h1>
<p>Flink 能够根据不同的时间概念来处理流数据。</p>
<ul>
<li>处理时间是指正在执行相应操作的机器的系统时间（也称为&quot;挂钟时间&quot;）。</li>
<li>事件时间指的是基于时间戳对流媒体数据的处理，时间戳附加在每一行上。时间戳可以编码事件发生的时间。</li>
<li>摄取时间是事件进入 Flink 的时间；在内部，它的处理方式与事件时间类似。</li>
</ul>
<p>关于 Flink 中时间处理的更多信息，请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间和水印</a>的介绍。</p>
<p>本页解释了如何在 Flink 的表 API 和 SQL 中为基于时间的操作定义时间属性。</p>
<h2 id="时间属性介绍">时间属性介绍</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">Table API</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">SQL</a> 中的窗口等基于时间的操作都需要时间概念及其来源的信息。因此，表可以提供逻辑时间属性，用于指示时间和在表程序中访问相应的时间戳。</p>
<p>时间属性可以成为每个表模式的一部分。它们是在从 CREATE TABLE DDL 或 DataStream 创建表时定义的，或者是在使用 TableSource 时预先定义的。一旦在开始时定义了时间属性，它就可以作为一个字段被引用，并且可以在基于时间的操作中使用。</p>
<p>只要时间属性没有被修改，只是从查询的一个部分转发到另一个部分，它仍然是一个有效的时间属性。时间属性的行为就像常规的时间戳一样，可以被访问进行计算。如果在计算中使用了时间属性，它将被具体化并成为常规时间戳。常规时间戳不与 Flink 的时间和水印系统合作，因此不能再用于基于时间的操作。</p>
<p>表程序要求已经为流环境指定了相应的时间特征。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="n">env</span><span class="o">.</span><span class="n">setStreamTimeCharacteristic</span><span class="o">(</span><span class="nc">TimeCharacteristic</span><span class="o">.</span><span class="nc">ProcessingTime</span><span class="o">)</span> <span class="c1">// default
</span><span class="c1"></span>
<span class="c1">// alternatively:
</span><span class="c1">// env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)
</span><span class="c1">// env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
</span></code></pre></div><h2 id="处理时间">处理时间</h2>
<p>处理时间允许表程序根据本地机器的时间产生结果。它是最简单的时间概念，但不提供确定性。它既不需要提取时间戳，也不需要生成水印。</p>
<p>有三种方法可以定义处理时间属性。</p>
<h3 id="在创建表-ddl-中定义">在创建表 DDL 中定义</h3>
<p>处理时间属性是在创建表 DDL 中使用系统 PROCTIME()函数定义为计算列。关于计算列的更多信息请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html#create-table">CREATE TABLE DDL</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">user_actions</span> <span class="p">(</span>
  <span class="n">user_name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="k">data</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">user_action_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">()</span> <span class="c1">-- declare an additional field as a processing time attribute
</span><span class="c1"></span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
  <span class="p">...</span>
<span class="p">);</span>

<span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;10&#39;</span> <span class="k">MINUTE</span><span class="p">),</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_name</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">user_actions</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;10&#39;</span> <span class="k">MINUTE</span><span class="p">);</span>
</code></pre></div><h3 id="在-datastream-to-table-转换期间">在 DataStream-to-Table 转换期间</h3>
<p>处理时间属性是在模式定义过程中用 <code>.proctime</code> 属性定义的。时间属性只能通过一个额外的逻辑字段来扩展物理模式。因此，它只能在模式定义的最后定义。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// declare an additional logical field as a processing time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;UserActionTimestamp&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="使用-table-source">使用 Table Source</h3>
<p>处理时间属性由实现 <code>DefinedProctimeAttribute</code> 接口的 <code>TableSource</code> 定义。逻辑时间属性附加到由 <code>TableSource</code> 的返回类型定义的物理模式中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// define a table source with a processing attribute
</span><span class="c1"></span><span class="k">class</span> <span class="nc">UserActionSource</span> <span class="k">extends</span> <span class="nc">StreamTableSource</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">with</span> <span class="nc">DefinedProctimeAttribute</span> <span class="o">{</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getReturnType</span> <span class="k">=</span> <span class="o">{</span>
		<span class="k">val</span> <span class="n">names</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;user_name&#34;</span> <span class="o">,</span> <span class="s">&#34;data&#34;</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">types</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]](</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">)</span>
		<span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="n">names</span><span class="o">,</span> <span class="n">types</span><span class="o">)</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getDataStream</span><span class="o">(</span><span class="n">execEnv</span><span class="k">:</span> <span class="kt">StreamExecutionEnvironment</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// create stream
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="o">...</span>
		<span class="n">stream</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getProctimeAttribute</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// field with this name will be appended as a third field
</span><span class="c1"></span>		<span class="s">&#34;user_action_time&#34;</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="c1">// register table source
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">UserActionSource</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">tEnv</span>
	<span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="事件时间">事件时间</h3>
<p>事件时间允许表格程序根据每条记录中包含的时间产生结果。这使得即使在事件失序或事件迟到的情况下，也能得到一致的结果。当从持久存储中读取记录时，它还能保证表程序的结果可重放。</p>
<p>此外，事件时间允许在批处理和流环境中对表程序进行统一的语法。流式环境中的时间属性可以是批处理环境中记录的常规字段。</p>
<p>为了处理失序事件，区分流式环境中事件的准时和迟到，Flink 需要从事件中提取时间戳，并在时间上做出某种进展（所谓的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">水印</a>）。</p>
<p>事件时间属性既可以在创建表 DDL 中定义，也可以在 DataStream 到表的转换过程中定义，或者使用 TableSource 定义。</p>
<h3 id="在创建表-ddl-中定义-1">在创建表 DDL 中定义</h3>
<p>事件时间属性是在 CREATE TABLE DDL 中使用 WATERMARK 语句定义的。水印语句在现有的事件时间字段上定义了一个水印生成表达式，将事件时间字段标记为事件时间属性。关于水印语句和水印策略的更多信息，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html#create-table">CREATE TABLE DDL</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">user_actions</span> <span class="p">(</span>
  <span class="n">user_name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="k">data</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">user_action_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
  <span class="c1">-- declare user_action_time as event time attribute and use 5 seconds delayed watermark strategy
</span><span class="c1"></span>  <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">user_action_time</span> <span class="k">AS</span> <span class="n">user_action_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;5&#39;</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
  <span class="p">...</span>
<span class="p">);</span>

<span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;10&#39;</span> <span class="k">MINUTE</span><span class="p">),</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_name</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">user_actions</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;10&#39;</span> <span class="k">MINUTE</span><span class="p">);</span>
</code></pre></div><h3 id="在-datastream-to-table-转换期间-1">在 DataStream-to-Table 转换期间</h3>
<p>事件时间属性是在模式定义期间用 <code>.rowtime</code> 属性定义的。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">时间戳和水印</a>必须在被转换的 DataStream 中被分配。</p>
<p>在将 DataStream 转换为表时，有两种方法可以定义时间属性。根据指定的.rowtime 字段名是否存在于 DataStream 的模式中，时间戳字段要么是</p>
<ul>
<li>作为一个新的字段添加到模式中，或</li>
<li>替换一个现有的字段。</li>
</ul>
<p>无论哪种情况，事件时间戳字段都将持有 DataStream 事件时间戳的值。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Option 1:
</span><span class="c1"></span>
<span class="c1">// extract timestamp and assign watermarks based on knowledge of the stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(...)</span>

<span class="c1">// declare an additional logical field as an event time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>


<span class="c1">// Option 2:
</span><span class="c1"></span>
<span class="c1">// extract timestamp from first field, and assign watermarks based on knowledge of the stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(...)</span>

<span class="c1">// the first field has been used for timestamp extraction, and is no longer necessary
</span><span class="c1">// replace first field with a logical event time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">)</span>

<span class="c1">// Usage:
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="使用-tablesource">使用 TableSource</h2>
<p>事件时间属性由一个实现 <code>DefinedRowtimeAttributes</code> 接口的 <code>TableSource</code> 定义。<code>getRowtimeAttributeDescriptors()</code> 方法返回一个 <code>RowtimeAttributeDescriptor</code> 列表，用于描述时间属性的最终名称，一个用于导出属性值的时间戳提取器，以及与属性相关的水印策略。</p>
<p>请确保 <code>getDataStream()</code> 方法返回的 DataStream 与定义的时间属性一致。只有当定义了 StreamRecordTimestamp 时间戳提取器时，才会考虑 DataStream 的时间戳（由 TimestampAssigner 分配的时间戳）。只有定义了 PreserveWatermarks 水印策略，DataStream 的水印才会被保留。否则，只有 TableSource 的 rowtime 属性的值是相关的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// define a table source with a rowtime attribute
</span><span class="c1"></span><span class="k">class</span> <span class="nc">UserActionSource</span> <span class="k">extends</span> <span class="nc">StreamTableSource</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">with</span> <span class="nc">DefinedRowtimeAttributes</span> <span class="o">{</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getReturnType</span> <span class="k">=</span> <span class="o">{</span>
		<span class="k">val</span> <span class="n">names</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;user_name&#34;</span> <span class="o">,</span> <span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="s">&#34;user_action_time&#34;</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">types</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]](</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span><span class="o">)</span>
		<span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="n">names</span><span class="o">,</span> <span class="n">types</span><span class="o">)</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getDataStream</span><span class="o">(</span><span class="n">execEnv</span><span class="k">:</span> <span class="kt">StreamExecutionEnvironment</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// create stream
</span><span class="c1"></span>		<span class="c1">// ...
</span><span class="c1"></span>		<span class="c1">// assign watermarks based on the &#34;user_action_time&#34; attribute
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(...)</span>
		<span class="n">stream</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getRowtimeAttributeDescriptors</span><span class="k">:</span> <span class="kt">util.List</span><span class="o">[</span><span class="kt">RowtimeAttributeDescriptor</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// Mark the &#34;user_action_time&#34; attribute as event-time attribute.
</span><span class="c1"></span>		<span class="c1">// We create one attribute descriptor of &#34;user_action_time&#34;.
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">rowtimeAttrDescr</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RowtimeAttributeDescriptor</span><span class="o">(</span>
			<span class="s">&#34;user_action_time&#34;</span><span class="o">,</span>
			<span class="k">new</span> <span class="nc">ExistingField</span><span class="o">(</span><span class="s">&#34;user_action_time&#34;</span><span class="o">),</span>
			<span class="k">new</span> <span class="nc">AscendingTimestamps</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">listRowtimeAttrDescr</span> <span class="k">=</span> <span class="nc">Collections</span><span class="o">.</span><span class="n">singletonList</span><span class="o">(</span><span class="n">rowtimeAttrDescr</span><span class="o">)</span>
		<span class="n">listRowtimeAttrDescr</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="c1">// register the table source
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">UserActionSource</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">tEnv</span>
	<span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[本地执行]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-local-execution/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-local-execution/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Local Execution</blockquote><h2 id="本地执行">本地执行</h2>
<p>Flink 可以在一台机器上运行，甚至在一台 Java 虚拟机中运行。这使得用户可以在本地测试和调试 Flink 程序。本节将对本地执行机制进行概述。</p>
<p>本地环境和执行器允许你在本地 Java 虚拟机中运行 Flink 程序，或者作为现有程序的一部分在任何 JVM 中运行。大多数例子可以通过简单地点击 IDE 的&quot;运行&quot;按钮在本地启动。</p>
<p>Flink 中支持两种不同的本地执行。LocalExecutionEnvironment 是启动完整的 Flink 运行时，包括一个 JobManager 和一个 TaskManager。这些包括内存管理和所有在集群模式下执行的内部算法。</p>
<p>CollectionEnvironment 是在 Java 集合上执行 Flink 程序。这种模式不会启动完整的 Flink 运行时，所以执行的开销非常低，而且是轻量级的。例如，一个 <code>DataSet.map()</code> 转换将通过将 <code>map()</code> 函数应用于 Java 列表中的所有元素来执行。</p>
<h3 id="调试">调试</h3>
<p>如果你在本地运行 Flink 程序，你也可以像其他 Java 程序一样调试你的程序。你可以使用 <code>System.out.println()</code> 来写出一些内部变量，也可以使用调试器。可以在 <code>map()</code>、<code>reduce()</code> 和其他所有方法中设置断点。也请参考 Java API 文档中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#debugging">调试部分</a>，了解 Java API 中的测试和本地调试工具的指南。</p>
<h3 id="maven-依赖">Maven 依赖</h3>
<p>如果你是在 Maven 项目中开发程序，你必须使用这个依赖关系添加 flink-clients 模块。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><h3 id="本地环境">本地环境</h3>
<p>LocalEnvironment 是 Flink 程序本地执行的一个句柄。使用它可以在本地 JVM 中运行程序&ndash;独立或嵌入其他程序中。</p>
<p>本地环境是通过 <code>ExecutionEnvironment.createLocalEnvironment()</code> 方法实例化的。默认情况下，它将使用与你的机器有多少 CPU 核（硬件上下文）一样多的本地线程来执行。您也可以指定所需的并行度。本地环境可以配置为使用 <code>enableLogging()/disableLogging()</code> 将日志记录到控制台。</p>
<p>在大多数情况下，调用 <code>ExecutionEnvironment.getExecutionEnvironment()</code> 是更好的方法。当程序在本地（命令行接口之外）启动时，该方法会返回一个 <code>LocalEnvironment</code>，当程序被命令行接口调用时，该方法会返回一个预配置的集群执行环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">createLocalEnvironment</span><span class="o">();</span>

    <span class="n">DataSet</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path/to/file&#34;</span><span class="o">);</span>

    <span class="n">data</span>
        <span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="n">FilterFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>
            <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="na">startsWith</span><span class="o">(</span><span class="s">&#34;http://&#34;</span><span class="o">);</span>
            <span class="o">}</span>
        <span class="o">})</span>
        <span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">&#34;file:///path/to/result&#34;</span><span class="o">);</span>

    <span class="n">JobExecutionResult</span> <span class="n">res</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>在执行结束后返回的 JobExecutionResult 对象，包含了程序运行时间和累加器结果。</p>
<p>LocalEnvironment 还允许向 Flink 传递自定义配置值。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Configuration</span><span class="o">();</span>
<span class="n">conf</span><span class="o">.</span><span class="na">setFloat</span><span class="o">(</span><span class="n">ConfigConstants</span><span class="o">.</span><span class="na">TASK_MANAGER_MEMORY_FRACTION_KEY</span><span class="o">,</span> <span class="n">0</span><span class="o">.</span><span class="na">5f</span><span class="o">);</span>
<span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">createLocalEnvironment</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</code></pre></div><p>注意：本地执行环境不启动任何 Web 前端来监控执行。</p>
<h3 id="收集环境">收集环境</h3>
<p>使用 CollectionEnvironment 在 Java 集合上执行是一种执行 Flink 程序的低开销方法。这种模式的典型用例是自动测试、调试和代码重用。</p>
<p>用户可以使用为批处理而实现的算法，也可以用于交互性更强的情况。Flink 程序的一个稍微改变的变体可以用于 Java 应用服务器中处理传入的请求。</p>
<p>基于集合执行的骨架:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="c1">// initialize a new Collection-based execution environment
</span><span class="c1"></span>    <span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CollectionEnvironment</span><span class="o">();</span>

    <span class="n">DataSet</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromCollection</span><span class="o">(</span> <span class="cm">/* get elements from a Java Collection */</span><span class="o">);</span>

    <span class="cm">/* Data Set transformations ... */</span>

    <span class="c1">// retrieve the resulting Tuple2 elements into a ArrayList.
</span><span class="c1"></span>    <span class="n">Collection</span><span class="o">&lt;...&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;...&gt;();</span>
    <span class="n">resultDataSet</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="k">new</span> <span class="n">LocalCollectionOutputFormat</span><span class="o">&lt;...&gt;(</span><span class="n">result</span><span class="o">));</span>

    <span class="c1">// kick off execution.
</span><span class="c1"></span>    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>

    <span class="c1">// Do some work with the resulting ArrayList (=Collection).
</span><span class="c1"></span>    <span class="k">for</span><span class="o">(...</span> <span class="n">t</span> <span class="o">:</span> <span class="n">result</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">System</span><span class="o">.</span><span class="na">err</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;Result = &#34;</span><span class="o">+</span><span class="n">t</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>flink-examples-batch 模块包含一个完整的例子，叫做 CollectionExecutionExample。</p>
<p>请注意，基于集合的 Flink 程序的执行只可能在小数据上执行，小数据适合 JVM 堆。在集合上的执行不是多线程的，只使用一个线程。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/local_execution.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/local_execution.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[查询]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-queries/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-queries/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Queries</blockquote><h1 id="查询">查询</h1>
<p>SELECT 语句和 VALUES 语句是用 TableEnvironment 的 sqlQuery()方法指定的。该方法将 SELECT 语句（或 VALUES 语句）的结果作为一个表返回。表可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#mixing-table-api-and-sql">后续的 SQL 和 Table API 查询</a>中使用，可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">转换为 DataSet 或 DataStream</a>，也可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#emit-a-table">写入 TableSink</a>。SQL 和 Table API 查询可以无缝混合，并进行整体优化，转化为一个程序。</p>
<p>为了在 SQL 查询中访问一个表，必须<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-tables-in-the-catalog">在 TableEnvironment 中注册</a>。表可以从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-tablesource">TableSource</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-table">Table</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#create-table">CREATE TABLE 语句</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-datastream-or-dataset-as-table">DataStream 或 DataSet</a> 中注册。另外，用户也可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">在 TableEnvironment 中注册目录</a>来指定数据源的位置。</p>
<p>为了方便起见，Table.toString()会自动在其 TableEnvironment 中以唯一的名称注册表，并返回名称。所以，Table 对象可以直接内联到 SQL 查询中，如下例所示。</p>
<p>注意：包含不支持的 SQL 特性的查询会导致 TableException。批量表和流式表的 SQL 支持的功能在下面的章节中列出。</p>
<h2 id="指定查询">指定查询</h2>
<p>下面的例子显示了如何在注册表和内联表上指定 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">Integer</span><span class="o">)]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(...)</span>

<span class="c1">// SQL query with an inlined (unregistered) table
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">s&#34;SELECT SUM(amount) FROM </span><span class="si">$table</span><span class="s"> WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>

<span class="c1">// SQL query with a registered table
</span><span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">)</span>
<span class="c1">// run a SQL query on the Table and retrieve the result as a new Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>

<span class="c1">// create and register a TableSink
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">())</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/path/to/file&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(...)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;RubberOrders&#34;</span><span class="o">)</span>

<span class="c1">// run an INSERT SQL on the Table and emit the result to the TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="执行查询">执行查询</h2>
<p>可以通过 TableEnvironment.executeSql()方法执行 SELECT 语句或 VALUES 语句，将内容收集到本地。该方法将 SELECT 语句（或 VALUES 语句）的结果作为 TableResult 返回。与 SELECT 语句类似，可以使用 Table.execute()方法执行 Table 对象，将查询的内容收集到本地客户端。TableResult.collect()方法返回一个可关闭的行迭代器。除非收集完所有的结果数据，否则选择作业不会结束。我们应该通过 CloseableIterator#close()方法主动关闭作业，避免资源泄露。我们也可以通过 TableResult.print()方法将选择结果打印到客户端控制台。TableResult 中的结果数据只能被访问一次。因此，collect()和 print()不能相继被调用。</p>
<p>对于流式作业，TableResult.collect()方法或 TableResult.print()方法可以保证端到端的精确一次记录传递。这需要启用检查点机制。默认情况下，检查点机制是被禁用的。要启用检查点，我们可以通过 TableConfig 设置检查点属性（详见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/config.html#checkpointing">检查点配置</a>）。所以一条结果记录只有在其对应的检查点完成后才能被客户端访问。</p>
<p>注意事项 对于流媒体模式，现在只支持只追加查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">,</span> <span class="n">settings</span><span class="o">)</span>
<span class="c1">// enable checkpointing
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">getConfiguration</span><span class="o">.</span><span class="n">set</span><span class="o">(</span>
  <span class="nc">ExecutionCheckpointingOptions</span><span class="o">.</span><span class="nc">CHECKPOINTING_MODE</span><span class="o">,</span> <span class="nc">CheckpointingMode</span><span class="o">.</span><span class="nc">EXACTLY_ONCE</span><span class="o">)</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">getConfiguration</span><span class="o">.</span><span class="n">set</span><span class="o">(</span>
  <span class="nc">ExecutionCheckpointingOptions</span><span class="o">.</span><span class="nc">CHECKPOINTING_INTERVAL</span><span class="o">,</span> <span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// execute SELECT statement
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SELECT * FROM Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">it</span> <span class="k">=</span> <span class="n">tableResult1</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
<span class="k">try</span> <span class="k">while</span> <span class="o">(</span><span class="n">it</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">row</span> <span class="k">=</span> <span class="n">it</span><span class="o">.</span><span class="n">next</span>
  <span class="c1">// handle row
</span><span class="c1"></span><span class="o">}</span>
<span class="k">finally</span> <span class="n">it</span><span class="o">.</span><span class="n">close</span><span class="o">()</span> <span class="c1">// close the iterator to avoid resource leak
</span><span class="c1"></span>
<span class="c1">// execute Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT * FROM Orders&#34;</span><span class="o">).</span><span class="n">execute</span><span class="o">()</span>
<span class="n">tableResult2</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>
</code></pre></div><h2 id="语法">语法</h2>
<p>Flink 使用 <a href="https://calcite.apache.org/docs/reference.html">Apache Calcite</a> 解析 SQL，它支持标准的 ANSI SQL。</p>
<p>下面的 BNF-语法描述了在批处理和流式查询中支持的 SQL 特性的超集。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#operations">操作</a>部分显示了支持的特性的例子，并指出哪些特性只支持批处理或流式查询。</p>
<pre><code>query:
  values
  | {
      select
      | selectWithoutFrom
      | query UNION [ ALL ] query
      | query EXCEPT query
      | query INTERSECT query
    }
    [ ORDER BY orderItem [, orderItem ]* ]
    [ LIMIT { count | ALL } ]
    [ OFFSET start { ROW | ROWS } ]
    [ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY]

orderItem:
  expression [ ASC | DESC ]

select:
  SELECT [ ALL | DISTINCT ]
  { * | projectItem [, projectItem ]* }
  FROM tableExpression
  [ WHERE booleanExpression ]
  [ GROUP BY { groupItem [, groupItem ]* } ]
  [ HAVING booleanExpression ]
  [ WINDOW windowName AS windowSpec [, windowName AS windowSpec ]* ]

selectWithoutFrom:
  SELECT [ ALL | DISTINCT ]
  { * | projectItem [, projectItem ]* }

projectItem:
  expression [ [ AS ] columnAlias ]
  | tableAlias . *

tableExpression:
  tableReference [, tableReference ]*
  | tableExpression [ NATURAL ] [ LEFT | RIGHT | FULL ] JOIN tableExpression [ joinCondition ]

joinCondition:
  ON booleanExpression
  | USING '(' column [, column ]* ')'

tableReference:
  tablePrimary
  [ matchRecognize ]
  [ [ AS ] alias [ '(' columnAlias [, columnAlias ]* ')' ] ]

tablePrimary:
  [ TABLE ] [ [ catalogName . ] schemaName . ] tableName [ dynamicTableOptions ]
  | LATERAL TABLE '(' functionName '(' expression [, expression ]* ')' ')'
  | UNNEST '(' expression ')'

dynamicTableOptions:
  /*+ OPTIONS(key=val [, key=val]*) */

key:
  stringLiteral

val:
  stringLiteral

values:
  VALUES expression [, expression ]*

groupItem:
  expression
  | '(' ')'
  | '(' expression [, expression ]* ')'
  | CUBE '(' expression [, expression ]* ')'
  | ROLLUP '(' expression [, expression ]* ')'
  | GROUPING SETS '(' groupItem [, groupItem ]* ')'

windowRef:
    windowName
  | windowSpec

windowSpec:
    [ windowName ]
    '('
    [ ORDER BY orderItem [, orderItem ]* ]
    [ PARTITION BY expression [, expression ]* ]
    [
        RANGE numericOrIntervalExpression {PRECEDING}
      | ROWS numericExpression {PRECEDING}
    ]
    ')'

matchRecognize:
      MATCH_RECOGNIZE '('
      [ PARTITION BY expression [, expression ]* ]
      [ ORDER BY orderItem [, orderItem ]* ]
      [ MEASURES measureColumn [, measureColumn ]* ]
      [ ONE ROW PER MATCH ]
      [ AFTER MATCH
            ( SKIP TO NEXT ROW
            | SKIP PAST LAST ROW
            | SKIP TO FIRST variable
            | SKIP TO LAST variable
            | SKIP TO variable )
      ]
      PATTERN '(' pattern ')'
      [ WITHIN intervalLiteral ]
      DEFINE variable AS condition [, variable AS condition ]*
      ')'

measureColumn:
      expression AS alias

pattern:
      patternTerm [ '|' patternTerm ]*

patternTerm:
      patternFactor [ patternFactor ]*

patternFactor:
      variable [ patternQuantifier ]

patternQuantifier:
      '*'
  |   '*?'
  |   '+'
  |   '+?'
  |   '?'
  |   '??'
  |   '{' { [ minRepeat ], [ maxRepeat ] } '}' ['?']
  |   '{' repeat '}'
</code></pre><p>Flink SQL 对标识符（表名、属性名、函数名）使用了类似 Java 的词汇策略。</p>
<p>无论标识符是否被引用，它们的大小写都会被保留。
之后，标识符会被大小写敏感地匹配。
与 Java 不同的是，回标允许标识符包含非字母数字字符（例如：&ldquo;SELECT a AS<code>my field</code>FROM t&rdquo;）。
字符串必须用单引号括起来（例如，SELECT &lsquo;Hello World&rsquo;）。重复一个单引号进行转义（例如，SELECT &lsquo;It&rsquo;s me.'）。字符串中支持 Unicode 字符。如果需要明确的 unicode 码点，请使用以下语法。</p>
<p>使用反斜杠（\）作为转义字符（默认）。SELECT U&amp;'\263A&rsquo;
使用自定义转义字符。SELECT U&amp;'#263A' UESCAPE &lsquo;#'。</p>
<h2 id="operations">Operations</h2>
<h3 id="scan-projection-和-filter">Scan, Projection 和 Filter</h3>
<ul>
<li>Scan / Select / As(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span>

<span class="k">SELECT</span> <span class="n">a</span><span class="p">,</span> <span class="k">c</span> <span class="k">AS</span> <span class="n">d</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><ul>
<li>Where / Filter(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div><ul>
<li>用户定义标量函数 (Scalar UDF)(Batch/Streaming)</li>
</ul>
<p>UDF 必须在 TableEnvironment 中注册。关于如何指定和注册标量 UDF 的详细信息，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">PRETTY_PRINT</span><span class="p">(</span><span class="k">user</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><h3 id="聚合">聚合</h3>
<ul>
<li>GroupBy 聚合(Batch/Streaming/Result Updating)</li>
</ul>
<p>注意：流表上的 GroupBy 会产生更新结果。详情请参见<a href="https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables">动态表流</a>概念页面。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">a</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">as</span> <span class="n">d</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">a</span>
</code></pre></div><ul>
<li>GroupBy 窗口聚合(Batch/Streaming)</li>
</ul>
<p>使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">分组窗口</a>来计算每个组的单一结果行。更多细节请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">分组窗口</a>部分。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">rowtime</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1&#39;</span> <span class="k">DAY</span><span class="p">),</span> <span class="k">user</span>
</code></pre></div><ul>
<li>Over 窗口聚合(Streaming)</li>
</ul>
<p>注意：所有的聚合必须定义在同一个窗口上，即相同的分区、排序和范围。目前，只支持对 CURRENT ROW 范围的 PRECEDING（UNBOUNDED 和 bounded）窗口。还不支持带 FOLLOWING 的范围。ORDER BY 必须在单个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>上指定。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="k">user</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="mi">2</span> <span class="n">PRECEDING</span> <span class="k">AND</span> <span class="k">CURRENT</span> <span class="k">ROW</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>

<span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="n">w</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="n">w</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="n">WINDOW</span> <span class="n">w</span> <span class="k">AS</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="k">user</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="mi">2</span> <span class="n">PRECEDING</span> <span class="k">AND</span> <span class="k">CURRENT</span> <span class="k">ROW</span><span class="p">)</span>
</code></pre></div><ul>
<li>Distinct(Batch/Streaming/Result Updating)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="n">users</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Grouping sets, Rollup, Cube(Batch/Streaming/Result Updating)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">GROUPING</span> <span class="k">SETS</span> <span class="p">((</span><span class="k">user</span><span class="p">),</span> <span class="p">(</span><span class="n">product</span><span class="p">))</span>
</code></pre></div><p>注：流式模式分组集、Rollup 和 Cube 仅在 Blink 计划器中支持。</p>
<ul>
<li>Having(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">users</span>
<span class="k">HAVING</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span>
</code></pre></div><ul>
<li>用户定义聚合函数 (UDAGG)(Batch/Streaming)</li>
</ul>
<p>UDAGG 必须在 TableEnvironment 中注册。关于如何指定和注册 UDAGG 的细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">MyAggregate</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">users</span>
</code></pre></div><h3 id="joins">Joins</h3>
<ul>
<li>Inner Equi-join(Batch/Streaming)</li>
</ul>
<p>目前，只支持等价连接，即至少有一个带有平等谓词的共轭条件的连接，不支持任意的交叉连接或θ连接。不支持任意的交叉连接或θ连接。</p>
<p>注意：连接的顺序没有被优化。表的连接顺序是按照 FROM 子句中指定的顺序进行的。确保指定表的顺序不会产生交叉连接（笛卡尔乘积），因为交叉连接不支持，会导致查询失败。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Outer Equi-join(Batch/Streaming/Result Updating)</li>
</ul>
<p>目前，只支持 equi-joins 连接，即至少有一个带有平等谓词的共轭条件的连接，不支持任意的交叉连接或θ连接。不支持任意的交叉连接或θ连接。</p>
<p>注意：连接的顺序没有被优化。表的连接顺序是按照 FROM 子句中指定的顺序进行的。确保指定表的顺序不会产生交叉连接（笛卡尔乘积），因为交叉连接不支持，会导致查询失败。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">LEFT</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>

<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">RIGHT</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>

<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">FULL</span> <span class="k">OUTER</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Interval Join(Batch/Streaming)</li>
</ul>
<p>注：区间连接是常规连接的一个子集，可以用流式处理。</p>
<p>一个区间连接至少需要一个等价连接谓词和一个连接条件，以限制双方的时间。这样的条件可以由两个合适的范围谓词（&lt;，&lt;=，&gt;=，&gt;）、一个 BETWEEN 谓词或一个比较两个输入表的相同类型的<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>（即处理时间或事件时间）的单一平等谓词来定义。</p>
<p>例如，以下谓词是有效的区间连接条件。</p>
<ul>
<li>ltime = rtime</li>
<li>ltime &gt;= rtime AND ltime &lt; rtime + INTERVAL &lsquo;10&rsquo; MINUTE</li>
<li>ltime BETWEEN rtime - INTERVAL &lsquo;10&rsquo; SECOND AND rtime + INTERVAL &lsquo;5&rsquo; SECOND</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="n">o</span><span class="p">,</span> <span class="n">Shipments</span> <span class="n">s</span>
<span class="k">WHERE</span> <span class="n">o</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">orderId</span> <span class="k">AND</span>
      <span class="n">o</span><span class="p">.</span><span class="n">ordertime</span> <span class="k">BETWEEN</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;4&#39;</span> <span class="n">HOUR</span> <span class="k">AND</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span>
</code></pre></div><p>上面的例子中，如果在收到订单 4 小时后才发货，那么就会将所有的订单与其对应的货物加入。</p>
<ul>
<li>将数组扩展为关系(Batch/Streaming)</li>
</ul>
<p>还不支持 Unnesting With ORDINALITY。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">CROSS</span> <span class="k">JOIN</span> <span class="k">UNNEST</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span> <span class="p">(</span><span class="n">tag</span><span class="p">)</span>
</code></pre></div><ul>
<li>Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每一行都与表函数的相应调用所产生的所有行相连接。</p>
<p>用户定义表函数（UDTF）必须在之前注册。关于如何指定和注册 UDTF 的细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<p><strong>Inner Join</strong></p>
<p>左表（外表）的一行，如果它的表函数调用返回一个空的结果，就会被删除。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span><span class="p">,</span> <span class="k">LATERAL</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">unnest_udtf</span><span class="p">(</span><span class="n">tags</span><span class="p">))</span> <span class="n">t</span> <span class="k">AS</span> <span class="n">tag</span>
</code></pre></div><p><strong>Left Outer Join</strong></p>
<p>如果表函数调用返回的结果为空，则保留相应的外行，并将结果用空值填充。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">LEFT</span> <span class="k">JOIN</span> <span class="k">LATERAL</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">unnest_udtf</span><span class="p">(</span><span class="n">tags</span><span class="p">))</span> <span class="n">t</span> <span class="k">AS</span> <span class="n">tag</span> <span class="k">ON</span> <span class="k">TRUE</span>
</code></pre></div><p>注意：目前，只有字面意义上的 &ldquo;TRUE &ldquo;被支持为针对横向表的左外连接的谓词。</p>
<ul>
<li>Join with Temporal Table Function(Streaming)</li>
</ul>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>是跟踪随时间变化的表。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>提供了对时间表在特定时间点的状态的访问。使用时态表函数连接表的语法与使用表函数连接相同。</p>
<p>注意：目前只支持与时态表的内部连接。</p>
<p>假设 Rates 是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>，连接可以用 SQL 表达如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o_amount</span><span class="p">,</span> <span class="n">r_rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o_proctime</span><span class="p">))</span>
<span class="k">WHERE</span>
  <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表概念</a>说明。</p>
<ul>
<li>Join with Temporal Table(Batch/Streaming)</li>
</ul>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>是跟踪随时间变化的表。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>提供了对时间表在特定时间点的版本的访问。</p>
<p>只支持与处理时间的时态表进行内联和左联。</p>
<p>下面的例子假设 LatestRates 是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>，它是以最新的速率来具体化的。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amout</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span><span class="p">,</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o</span><span class="p">.</span><span class="n">proctime</span> <span class="k">AS</span> <span class="n">r</span>
  <span class="k">ON</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>概念描述。</p>
<p>仅支持 Blink 计划器。</p>
<h3 id="集合运算">集合运算</h3>
<ul>
<li>Union(Batch)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">UNION</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>UnionAll(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">UNION</span> <span class="k">ALL</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>Intersect / Except(Batch)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">INTERSECT</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">EXCEPT</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>In(Batch/Streaming)</li>
</ul>
<p>如果给定表的子查询中存在表达式，则返回 true。子查询表必须由一列组成。该列必须与表达式具有相同的数据类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">WHERE</span> <span class="n">product</span> <span class="k">IN</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="n">product</span> <span class="k">FROM</span> <span class="n">NewProducts</span>
<span class="p">)</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Exists(Batch/Streaming)</li>
</ul>
<p>如果子查询至少返回一条记录，则返回 true。只有当操作可以被重写成联接和分组操作时才支持。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">WHERE</span> <span class="n">product</span> <span class="k">EXISTS</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="n">product</span> <span class="k">FROM</span> <span class="n">NewProducts</span>
<span class="p">)</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="orderby-和-limit">OrderBy 和 Limit</h3>
<ul>
<li>Order By</li>
</ul>
<p>批量流注：流查询的结果必须主要按升序时间属性进行排序。支持其他排序属性。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">orderTime</span>
</code></pre></div><ul>
<li>Limit(Batch)</li>
</ul>
<p>注意：LIMIT 子句需要一个 ORDER BY 子句。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">orderTime</span>
<span class="k">LIMIT</span> <span class="mi">3</span>
</code></pre></div><h3 id="top-n">Top-N</h3>
<p>注意 Top-N 只在 Blink planner 中支持。</p>
<p>Top-N 查询要求按列排序的 N 个最小或最大的值。最小值和最大值集都被认为是 Top-N 查询。当需要从批处理/流处理表中只显示 N 条最底层或最上层的记录时，Top-N 查询非常有用。这个结果集可以用于进一步分析。</p>
<p>Flink 使用 OVER 窗口子句和过滤条件的组合来表达 Top-N 查询。借助 OVER window PARTITION BY 子句的强大功能，Flink 还支持每组 Top-N。例如，每个类别中实时销售量最大的前五个产品。对于批处理表和流处理表的 SQL，都支持 Top-N 查询。</p>
<p>下面是 TOP-N 语句的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="p">(</span>
   <span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">],</span>
     <span class="n">ROW_NUMBER</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">([</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">col1</span><span class="p">[,</span> <span class="n">col2</span><span class="p">...]]</span>
       <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">col1</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">][,</span> <span class="n">col2</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">]...])</span> <span class="k">AS</span> <span class="n">rownum</span>
   <span class="k">FROM</span> <span class="k">table_name</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">rownum</span> <span class="o">&lt;=</span> <span class="n">N</span> <span class="p">[</span><span class="k">AND</span> <span class="n">conditions</span><span class="p">]</span>
</code></pre></div><p>参数说明:</p>
<ul>
<li>ROW_NUMBER()。根据分区内行的顺序，给每一行分配一个唯一的、连续的数字，从 1 开始。目前，我们只支持 ROW_NUMBER 作为 over window 函数。在未来，我们将支持 RANK()和 DENSE_RANK()。</li>
<li>PARTITION BY col1[，col2&hellip;]。指定分区列。每个分区将有一个 Top-N 的结果。</li>
<li>ORDER BY col1[asc|desc][，col2[asc|desc]&hellip;]：指定排序列。指定排序列。不同列的排序方向可以不同。</li>
<li>WHERE rownum &lt;= N：为了让 Flink 识别这个查询是 Top-N 查询，需要 rownum &lt;= N。N 代表将保留 N 条最小或最大的记录。</li>
<li>[AND 条件]。在 where 子句中可以自由添加其他条件，但其他条件只能与 rownum &lt;= N 使用 AND 连接组合。</li>
</ul>
<p>流模式下的注意点: TopN 查询是结果更新。Flink SQL 会根据顺序键对输入的数据流进行排序，所以如果前 N 条记录发生了变化，变化后的记录会作为回撤/更新记录发送到下游。建议使用支持更新的存储作为 Top-N 查询的汇。另外，如果 Top N 记录需要存储在外部存储中，结果表应该与 Top-N 查询的唯一键相同。</p>
<p>Top-N 查询的唯一键是分区列和 rownum 列的组合。Top-N 查询也可以得出上游的唯一键。以下面的工作为例，假设 product_id 是 ShopSales 的唯一键，那么 Top-N 查询的唯一键是[category，rownum]和[product_id]。</p>
<p>下面的例子展示了如何在流表上使用 Top-N 指定 SQL 查询。这个例子是为了得到我们上面提到的 &ldquo;每个类别实时销量最大的前五个产品&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(...)</span>
<span class="c1">// register the DataStream under the name &#34;ShopSales&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;ShopSales&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;category&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;sales&#34;</span><span class="o">)</span>


<span class="c1">// select top-5 products per category which have the maximum sales.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT *
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as row_num
</span><span class="s">      |   FROM ShopSales)
</span><span class="s">      |WHERE row_num &lt;= 5
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h4 id="无排名输出优化">无排名输出优化</h4>
<p>如上所述，rownum 字段将作为唯一键的一个字段写入结果表，这可能导致很多记录被写入结果表。例如，当排名 9 的记录（比如产品-1001）更新，其排名升级为 1 时，排名 1~9 的所有记录都会作为更新消息输出到结果表。如果结果表接收的数据过多，就会成为 SQL 作业的瓶颈。</p>
<p>优化的方式是在 Top-N 查询的外侧 SELECT 子句中省略 rownum 字段。这样做是合理的，因为 Top N 记录的数量通常不多，因此消费者可以自己快速排序。如果没有 rownum 字段，在上面的例子中，只需要将改变的记录（product-1001）发送到下游，这样可以减少很多结果表的 IO。</p>
<p>下面的例子展示了如何用这种方式优化上面的 Top-N 例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(...)</span>
<span class="c1">// register the DataStream under the name &#34;ShopSales&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;ShopSales&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;category&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;sales&#34;</span><span class="o">)</span>


<span class="c1">// select top-5 products per category which have the maximum sales.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT product_id, category, product_name, sales  -- omit row_num field in the output
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as row_num
</span><span class="s">      |   FROM ShopSales)
</span><span class="s">      |WHERE row_num &lt;= 5
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><p>流模式下的注意点: 为了将上述查询输出到外部存储中，并得到正确的结果，外部存储必须与 Top-N 查询具有相同的唯一键，在上面的示例查询中，如果 product_id 是查询的唯一键，那么外部表也应该以 product_id 作为唯一键。在上面的示例查询中，如果 product_id 是查询的唯一键，那么外部表也应该以 product_id 作为唯一键。</p>
<h3 id="重复数据删除">重复数据删除</h3>
<p>注意 重复数据删除只在 Blink planner 中支持。</p>
<p>重复数据删除就是删除一组列上重复的行，只保留第一条或最后一条。在某些情况下，上游 ETL 作业并不是端到端完全对接的，这可能会导致在故障切换时，sink 中有重复的记录。但是，重复的记录会影响到下游分析作业（如 SUM、COUNT）的正确性。所以在进一步分析之前需要进行重复数据删除。</p>
<p>Flink 使用 ROW_NUMBER()来删除重复记录，就像 Top-N 查询的方式一样。理论上，重复数据删除是 Top-N 的一个特例，N 为 1，按处理时间或事件时间排序。</p>
<p>下面是重复数据删除语句的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="p">(</span>
   <span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">],</span>
     <span class="n">ROW_NUMBER</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">([</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">col1</span><span class="p">[,</span> <span class="n">col2</span><span class="p">...]]</span>
       <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">time_attr</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">])</span> <span class="k">AS</span> <span class="n">rownum</span>
   <span class="k">FROM</span> <span class="k">table_name</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">rownum</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div><p>参数说明:</p>
<ul>
<li>ROW_NUMBER()。为每一行指定一个唯一的、连续的编号，从 1 开始。</li>
<li>PARTITION BY col1[，col2&hellip;]: 指定分区列，即重复复制键。</li>
<li>ORDER BY time_attr[asc|desc]。指定排序列，必须是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。目前只支持 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">proctime 属性</a>。未来将支持 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#event-time">Rowtime 属性</a>。用 ASC 排序表示保留第一行，用 DESC 排序表示保留最后一行。</li>
<li>WHERE rownum = 1：为了让 Flink 识别这个查询是重复数据删除，需要 rownum = 1。</li>
</ul>
<p>下面的例子展示了如何在流表上指定使用重复数据删除的 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(...)</span>
<span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;order_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;number&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="c1">// remove duplicate rows on order_id and keep the first occurrence row,
</span><span class="c1">// because there shouldn&#39;t be two orders with the same order_id.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT order_id, user, product, number
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY proctime DESC) as row_num
</span><span class="s">      |   FROM Orders)
</span><span class="s">      |WHERE row_num = 1
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="group-windows">Group Windows</h3>
<p>组窗口是在 SQL 查询的 GROUP BY 子句中定义的。就像使用常规的 GROUP BY 子句的查询一样，使用包含组窗口函数的 GROUP BY 子句的查询是为每个组计算一条结果行。在批处理表和流式表上的 SQL 支持以下组窗口函数。</p>
<table>
<thead>
<tr>
<th style="text-align:left">分组窗口函数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">TUMBLE(time_attr, interval)</td>
<td style="text-align:left">定义一个滚动时间窗口。滚动时间窗口将行分配到具有固定持续时间（间隔）的非重叠的连续窗口。例如，一个 5 分钟的时间窗口可以将行以 5 分钟的间隔进行分组。滚动窗口可以在事件时间（流+批次）或处理时间（流）上定义。</td>
</tr>
<tr>
<td style="text-align:left">HOP(time_attr, interval, interval)</td>
<td style="text-align:left">定义一个跳转时间窗口（在表 API 中称为滑动窗口）。跳跃时间窗口有一个固定的持续时间（第二个间隔参数），并按指定的跳跃间隔（第一个间隔参数）进行跳转。如果跳转间隔小于窗口大小，则跳转窗口是重叠的。因此，可以将行分配到多个窗口。例如，15 分钟大小的跳转窗口和 5 分钟的跳转间隔将每行分配给 3 个 15 分钟大小的不同窗口，这些窗口以 5 分钟的间隔进行评估。滚动窗口可以在事件时间（流+批处理）或处理时间（流）上定义。</td>
</tr>
<tr>
<td style="text-align:left">SESSION(time_attr, interval)</td>
<td style="text-align:left">定义一个会话时间窗口。会话时间窗口没有固定的持续时间，但其边界由不活动的时间间隔定义，即如果在定义的间隙期内没有事件出现，则会话窗口关闭。例如，有 30 分钟间隙的会话窗口在 30 分钟不活动后观察到一行时开始（否则该行将被添加到现有的窗口中），如果在 30 分钟内没有行被添加，则关闭。会话窗口可以在事件时间（流+批处理）或处理时间（流）上工作。</td>
</tr>
</tbody>
</table>
<h4 id="时间属性">时间属性</h4>
<p>对于流表的 SQL 查询，组窗口函数的 time_attr 参数必须引用一个有效的时间属性，该属性指定行的处理时间或事件时间。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性的文档</a>，了解如何定义时间属性。</p>
<p>对于批处理表上的 SQL，组窗口函数的 time_attr 参数必须是类型为 TIMESTAMP 的属性。</p>
<h4 id="选择组窗口的开始和结束时间戳">选择组窗口的开始和结束时间戳</h4>
<p>可以通过以下辅助功能选择组窗口的开始和结束时间戳以及时间属性。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Auxiliary 函数</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">TUMBLE_START(time_attr, interval),HOP_START(time_attr, interval, interval),SESSION_START(time_attr, interval)</td>
<td style="text-align:left">返回对应的滚动、跳跃或会话窗口的包容下界的时间戳。</td>
</tr>
<tr>
<td style="text-align:left">TUMBLE_END(time_attr, interval),HOP_END(time_attr, interval, interval),SESSION_END(time_attr, interval)</td>
<td style="text-align:left">返回对应的翻滚、跳跃或会话窗口的专属上界的时间戳。注意：在后续的基于时间的操作中，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或 over 窗口聚合</a>中，不能将专属上界时间戳作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">行时间属性</a>使用。</td>
</tr>
<tr>
<td style="text-align:left">TUMBLE_ROWTIME(time_attr, interval),HOP_ROWTIME(time_attr, interval, interval),SESSION_ROWTIME(time_attr, interval)</td>
<td style="text-align:left">返回对应的翻滚、跳跃或会话窗口的包容上界的时间戳。产生的属性是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">行时间属性</a>，可以用于后续的基于时间的操作，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或窗口聚合</a>。</td>
</tr>
<tr>
<td style="text-align:left">TUMBLE_PROCTIME(time_attr, interval),HOP_PROCTIME(time_attr, interval, interval),SESSION_PROCTIME(time_attr, interval)</td>
<td style="text-align:left">返回一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">proctime 属性</a>，该属性可用于后续基于时间的操作，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或过窗口聚合</a>。</td>
</tr>
</tbody>
</table>
<p>注意：在调用辅助函数时，必须使用与 GROUP BY 子句中的组窗口函数完全相同的参数。</p>
<p>下面的例子展示了如何在流式表上使用组窗口指定 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(...)</span>
<span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per day (in event-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT
</span><span class="s">      |  user,
</span><span class="s">      |  TUMBLE_START(rowtime, INTERVAL &#39;1&#39; DAY) as wStart,
</span><span class="s">      |  SUM(amount)
</span><span class="s">      | FROM Orders
</span><span class="s">      | GROUP BY TUMBLE(rowtime, INTERVAL &#39;1&#39; DAY), user
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per day (in processing-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT user, SUM(amount) FROM Orders GROUP BY TUMBLE(proctime, INTERVAL &#39;1&#39; DAY), user&#34;</span><span class="o">)</span>

<span class="c1">// compute every hour the SUM(amount) of the last 24 hours in event-time
</span><span class="c1"></span><span class="k">val</span> <span class="n">result3</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, SUM(amount) FROM Orders GROUP BY HOP(rowtime, INTERVAL &#39;1&#39; HOUR, INTERVAL &#39;1&#39; DAY), product&#34;</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per session with 12 hour inactivity gap (in event-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result4</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT
</span><span class="s">      |  user,
</span><span class="s">      |  SESSION_START(rowtime, INTERVAL &#39;12&#39; HOUR) AS sStart,
</span><span class="s">      |  SESSION_END(rowtime, INTERVAL &#39;12&#39; HOUR) AS sEnd,
</span><span class="s">      |  SUM(amount)
</span><span class="s">      | FROM Orders
</span><span class="s">      | GROUP BY SESSION(rowtime(), INTERVAL &#39;12&#39; HOUR), user
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="模式识别">模式识别</h3>
<ul>
<li>MATCH_RECOGNIZE(Streaming)</li>
</ul>
<p>根据 MATCH_RECOGNIZE <a href="https://standards.iso.org/ittf/PubliclyAvailableStandards/c065143_ISO_IEC_TR_19075-5_2016.zip">ISO 标准</a>在流表中搜索给定模式。这使得在 SQL 查询中表达复杂事件处理（CEP）逻辑成为可能。</p>
<p>更详细的描述，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html">检测表中模式</a>的专门页面。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">T</span><span class="p">.</span><span class="n">aid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">bid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">cid</span>
<span class="k">FROM</span> <span class="n">MyTable</span>
<span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">userid</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="n">MEASURES</span>
    <span class="n">A</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">aid</span><span class="p">,</span>
    <span class="n">B</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">bid</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">cid</span>
  <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span> <span class="k">C</span><span class="p">)</span>
  <span class="n">DEFINE</span>
    <span class="n">A</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span>
    <span class="n">B</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span>
    <span class="k">C</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span>
<span class="p">)</span> <span class="k">AS</span> <span class="n">T</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[查询配置]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-query-configuration/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Query Configuration</blockquote><h1 id="查询配置">查询配置</h1>
<p>表 API 和 SQL 查询具有相同的语义，无论其输入是有限的行集还是无限制的表变化流。在许多情况下，对流输入的连续查询能够计算出与离线计算结果相同的准确结果。然而，对于一些连续查询，你必须限制它们所维持的状态的大小，以避免在摄取无约束的输入流时耗尽存储。这取决于输入数据的特性和查询本身是否需要限制状态大小，以及它是否和如何影响计算结果的准确性。</p>
<p>Flink 的 Table API 和 SQL 接口提供了参数来调整连续查询的准确性和资源消耗。这些参数是通过 TableConfig 对象指定的，可以从 TableEnvironment 中获得。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// obtain query configuration from TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tConfig</span><span class="k">:</span> <span class="kt">TableConfig</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span>
<span class="c1">// set query parameters
</span><span class="c1"></span><span class="n">tConfig</span><span class="o">.</span><span class="n">setIdleStateRetentionTime</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">12</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">24</span><span class="o">))</span>

<span class="c1">// define query
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">???</span>

<span class="c1">// create TableSink
</span><span class="c1"></span><span class="k">val</span> <span class="n">sink</span><span class="k">:</span> <span class="kt">TableSink</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">???</span>

<span class="c1">// register TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSink</span><span class="o">(</span>
  <span class="s">&#34;outputTable&#34;</span><span class="o">,</span>                  <span class="c1">// table name
</span><span class="c1"></span>  <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">](...),</span>             <span class="c1">// field names
</span><span class="c1"></span>  <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]](...),</span> <span class="c1">// field types
</span><span class="c1"></span>  <span class="n">sink</span><span class="o">)</span>                           <span class="c1">// table sink
</span><span class="c1"></span>
<span class="c1">// emit result Table via a TableSink
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>

<span class="c1">// convert result Table into a DataStream[Row]
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span>
</code></pre></div><p>下面我们介绍 TableConfig 的参数，以及它们如何影响查询的准确性和资源消耗。</p>
<h2 id="闲置状态保留时间">闲置状态保留时间</h2>
<p>许多查询在一个或多个键属性上聚合或连接记录。当这样的查询在一个流上执行时，连续查询需要收集记录或维护每个键的部分结果。如果输入流的键域是不断变化的，即活跃的键值是随着时间的推移而变化的，那么随着观察到越来越多不同的键，连续查询会积累越来越多的状态。然而，往往键在一段时间后就会变得不活跃，其相应的状态也就变得陈旧无用。</p>
<p>例如下面的查询计算每节课的点击次数。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">sessionId</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">clicks</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">sessionId</span><span class="p">;</span>
</code></pre></div><p>sessionId 属性被用作分组键，连续查询会对它观察到的每个 sessionId 进行计数。sessionId 属性是随着时间的推移而不断变化的，sessionId 值只有在会话结束之前才是有效的，即在有限的时间内。然而，连续查询无法知道 sessionId 的这一属性，它期望每个 sessionId 值都能在任何时间点出现。它为每一个观察到的 sessionId 值维持一个计数。因此，随着观察到的 sessionId 值越来越多，查询的总状态大小也在不断增加。</p>
<p>闲置状态保留时间参数定义了一个键的状态在被移除之前不被更新的保留时间。对于前面的示例查询，只要在配置的时间段内没有更新，sessionId 的计数就会被删除。</p>
<p>通过删除一个键的状态，连续查询就会完全忘记它以前见过这个键。如果处理一条带有键的记录，其状态在之前已经被删除，则该记录将被视为带有相应键的第一条记录。对于上面的例子来说，这意味着一个 sessionId 的计数将重新开始为 0。</p>
<p>有两个参数可以配置空闲状态保留时间。</p>
<ul>
<li>最小空闲状态保留时间定义了一个非活动键的状态在被移除之前至少保留多长时间。</li>
<li>最大空闲状态保留时间定义了非活动键的状态在被删除前最多保留多长时间。</li>
</ul>
<p>参数指定如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tConfig</span><span class="k">:</span> <span class="kt">TableConfig</span> <span class="o">=</span> <span class="o">???</span>

<span class="c1">// set idle state retention time: min = 12 hours, max = 24 hours
</span><span class="c1"></span><span class="n">tConfig</span><span class="o">.</span><span class="n">setIdleStateRetentionTime</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">12</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">24</span><span class="o">))</span>
</code></pre></div><p>清理状态需要额外的记账，对于 minTime 和 maxTime 的较大差异，记账成本较低。minTime 和 maxTime 之间的差异必须至少为 5 分钟。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[检查点]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-checkpointing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-checkpointing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Checkpointing</blockquote><p>Flink 中的每一个函数和操作符都可以是有状态的（详情请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">使用状态</a>）。有状态的函数在单个元素/事件的处理过程中存储数据，使得状态成为任何类型的更复杂操作的关键构建模块。</p>
<p>为了使状态具有容错性，Flink 需要对状态进行 <strong>checkpoint</strong>。检查点允许 Flink 恢复流中的状态和位置，使应用程序具有与无故障执行相同的语义。</p>
<p>关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">流式容错的文档</a>详细描述了 Flink 的流式容错机制背后的技术。</p>
<h2 id="前提条件">前提条件</h2>
<p>Flink 的检查点机制与流和状态的持久存储交互。一般来说，它需要:</p>
<ul>
<li>一个能在一定时间内重放记录(replay records)的持久（或耐用）数据源。这种源的例子是持久性消息队列（如 Apache Kafka、RabbitMQ、Amazon Kinesis、Google PubSub）或文件系统（如 HDFS、S3、GFS、NFS、Ceph&hellip;）。</li>
<li>状态的持久性存储，通常是一个分布式文件系统（如 HDFS、S3、GFS、NFS、Ceph&hellip;）。</li>
</ul>
<h2 id="启用和配置检查点">启用和配置检查点</h2>
<p>默认情况下，检查点被禁用。要启用检查点，在 <code>StreamExecutionEnvironment</code> 上调用 <code>enableCheckpointing(n)</code>，其中 <em>n</em> 是检查点间隔，单位为毫秒。</p>
<p>检查点的其他参数包括:</p>
<ul>
<li>
<p>exactly-once vs. at-least-once：你可以选择向 <code>enableCheckpointing(n)</code> 方法传递一个模式，以便在两个保证级别之间进行选择。对于大多数应用来说，exactly-once 是比较好的。At-least-once 可能适用于某些超低延迟（持续几毫秒）的应用。</p>
</li>
<li>
<p>检查点超时。如果一个正在进行中的检查点没有完成，那么它被中止的时间。</p>
</li>
<li>
<p>检查点之间的最小时间。为了确保流应用在检查点之间有一定的进度，可以定义检查点之间需要经过多少时间。例如，如果这个值设置为5000，那么下一个检查点将在上一个检查点完成后不早于5秒开始，无论检查点持续时间和检查点间隔如何。请注意，这意味着检查点间隔永远不会小于这个参数。</p>
</li>
</ul>
<p>通过定义&quot;检查点之间的时间&quot;(time between checkpoints)通常比检查点间隔更容易配置应用程序，因为&quot;检查点之间的时间&quot;不容易受到检查点有时可能比平均时间长的事实的影响（例如，如果目标存储系统暂时缓慢）。</p>
<p>请注意，这个值也意味着并发检查点的数量为1。</p>
<ul>
<li>并发检查点的数量。默认情况下，当一个检查点仍在进行时，系统不会触发另一个检查点。这可以确保拓扑不会在检查点上花费太多时间，而使处理流的工作没有进展。可以允许多个重叠的检查点，这对于那些有一定处理延迟（例如因为函数调用外部服务，需要一些时间来响应），但仍然希望做非常频繁的检查点（100s毫秒），以便在故障时重新处理很少的管道来说是很有意思的。</li>
</ul>
<p>当定义了检查点之间的最小时间时，不能使用这个选项。</p>
<ul>
<li>
<p>外部化检查点。您可以配置周期性检查点，使其在外部持久化。外部化的检查点会将它们的元数据写入持久化存储中，当作业失败时不会自动清理。这样一来，如果你的工作失败了，你身边就会有一个检查点来恢复。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html#externalized-checkpoints">外部化检查点的部署说明</a>中有更多细节。</p>
</li>
<li>
<p>Fail/checkpoint 错误时继续执行任务。这决定了如果在执行任务的检查点过程中出现错误，任务是否会失败。这是默认行为。另外，当禁用该功能时，任务将简单地拒绝向检查点协调器提供检查点并继续运行。</p>
</li>
<li>
<p>更喜欢用于恢复的检查点。这决定了即使有更近的保存点可用时，任务是否会回退到最新的检查点，以减少恢复时间。</p>
</li>
<li>
<p>不对齐的检查点。你可以启用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html#unaligned-checkpoints">不对齐的检查点</a>，以大大减少背压下的检查点时间。仅适用于精确的一次检查点，且并发检查点数量为1。</p>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="c1">// start a checkpoint every 1000 ms
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">enableCheckpointing</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>

<span class="c1">// 高级选项:
</span><span class="c1"></span>
<span class="c1">// 设置模式为 exactly-once (这是默认的)
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">setCheckpointingMode</span><span class="o">(</span><span class="nc">CheckpointingMode</span><span class="o">.</span><span class="nc">EXACTLY_ONCE</span><span class="o">)</span>

<span class="c1">// make sure 500 ms of progress happen between checkpoints
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">setMinPauseBetweenCheckpoints</span><span class="o">(</span><span class="mi">500</span><span class="o">)</span>

<span class="c1">// checkpoints have to complete within one minute, or are discarded
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">setCheckpointTimeout</span><span class="o">(</span><span class="mi">60000</span><span class="o">)</span>

<span class="c1">// prevent the tasks from failing if an error happens in their checkpointing, the checkpoint will just be declined.
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">setFailTasksOnCheckpointingErrors</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// allow only one checkpoint to be in progress at the same time
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">setMaxConcurrentCheckpoints</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="c1">// enables the experimental unaligned checkpoints
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getCheckpointConfig</span><span class="o">.</span><span class="n">enableUnalignedCheckpoints</span><span class="o">()</span>
</code></pre></div><h3 id="相关配置选项">相关配置选项</h3>
<p>更多的参数和/或默认值可以通过 <code>conf/flink-conf.yaml</code> 来设置（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/config.html">配置</a>的完整指南）。</p>
<table>
<thead>
<tr>
<th style="text-align:left">键</th>
<th style="text-align:left">默认值</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">state.backend</td>
<td style="text-align:left">(none)</td>
<td style="text-align:left">String</td>
<td style="text-align:left">用于存储和 checkpoint 状态的状态后端。</td>
</tr>
<tr>
<td style="text-align:left">state.backend.async</td>
<td style="text-align:left">true</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">状态后端是否应该在可能的情况下使用异步快照方法的选项，可配置。有些状态后端可能不支持异步快照，或者只支持异步快照，而忽略这个选项。</td>
</tr>
<tr>
<td style="text-align:left">state.backend.fs.memory-threshold</td>
<td style="text-align:left">20 kb</td>
<td style="text-align:left">MemorySize</td>
<td style="text-align:left">状态数据文件的最小尺寸。小于这个大小的所有状态块都内嵌存储在根检查点元数据文件中。该配置的最大内存阈值为1MB。</td>
</tr>
<tr>
<td style="text-align:left">state.backend.fs.write-buffer-size</td>
<td style="text-align:left">4096</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">写入文件系统的检查点流的默认写缓冲区大小。实际的写缓冲区大小是由这个选项和选项 &lsquo;state.backend.fs.memory-threshold&rsquo; 的最大值决定的。</td>
</tr>
<tr>
<td style="text-align:left">state.backend.incremental</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">如果可能，状态后端是否应该创建增量检查点。对于增量检查点，只存储与前一个检查点的差异，而不是完整的检查点状态。一旦启用，在 Web UI 中显示的状态大小或从 rest API 中获取的状态大小只代表 delta 检查点大小，而不是完整的检查点大小。一些状态后端可能不支持增量检查点而忽略这个选项。</td>
</tr>
<tr>
<td style="text-align:left">state.backend.local-recovery</td>
<td style="text-align:left">false</td>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">这个选项可以配置这个状态后端的本地恢复。默认情况下，本地恢复是被停用的。本地恢复目前只覆盖 keyed state 后端。目前，MemoryStateBackend 不支持本地恢复，忽略此选项。</td>
</tr>
<tr>
<td style="text-align:left">state.checkpoints.dir</td>
<td style="text-align:left">(none)</td>
<td style="text-align:left">String</td>
<td style="text-align:left">在 Flink 支持的文件系统中，用于存储检查点数据文件和元数据的默认目录。该存储路径必须可以从所有参与进程/节点（即所有 TaskManager 和 JobManager）访问。</td>
</tr>
<tr>
<td style="text-align:left">state.checkpoints.num-retained</td>
<td style="text-align:left">1</td>
<td style="text-align:left">Integer</td>
<td style="text-align:left">保留已完成的检查点的最大数量。</td>
</tr>
<tr>
<td style="text-align:left">state.savepoints.dir</td>
<td style="text-align:left">(none)</td>
<td style="text-align:left">String</td>
<td style="text-align:left">保存点的默认目录。由将保存点写入文件系统的状态后端（MemoryStateBackend, FsStateBackend, RocksDBStateBackend）使用。</td>
</tr>
<tr>
<td style="text-align:left">taskmanager.state.local.root-dirs</td>
<td style="text-align:left">(none)</td>
<td style="text-align:left">String</td>
<td style="text-align:left">配置参数，定义本地恢复中存储基于文件的状态的根目录。本地恢复目前只覆盖 keyed state 后端。目前，MemoryStateBackend 不支持本地恢复，忽略这个选项。</td>
</tr>
</tbody>
</table>
<h3 id="选择状态后端">选择状态后端</h3>
<p>Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">检查点机制</a>在定时器和有状态的操作符中存储所有状态的一致快照，包括连接器、窗口和任何<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">用户定义的状态</a>。检查点存储的位置（例如，JobManager内存、文件系统、数据库）取决于配置的状态后端。</p>
<p>默认情况下，状态保存在 TaskManager 的内存中，检查点保存在 JobManager 的内存中。为了正确地持久化大状态，Flink 支持各种方法在其他状态后端存储和检查点状态。状态后端的选择可以通过 <code>StreamExecutionEnvironment.setStateBackend(...)</code> 进行配置。</p>
<p>有关可用的状态后端以及作业范围(job-wide)和集群范围(cluster-wide)配置选项的更多细节，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a>。</p>
<h3 id="迭代作业中的状态检查点">迭代作业中的状态检查点</h3>
<p>Flink 目前只为没有迭代的作业提供处理保证。在迭代作业上启用检查点会导致异常。为了在迭代程序上强制检查点，用户需要在启用检查点时设置一个特殊标志：<code>env.enableCheckpointing(interval, CheckpointingMode.EXACTLY_ONCE, force = true)</code>。</p>
<p>请注意，循环边缘中飞行中的记录（以及与之相关的状态变化）将在失败时丢失。</p>
<h3 id="重新启动策略">重新启动策略</h3>
<p>Flink 支持不同的重启策略，这些策略可以控制作业(job)在发生故障时如何重启。更多信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/task_failure_recovery.html">重启策略</a>。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[检测表中的模式]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-detecting-patterns-in-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-detecting-patterns-in-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Detecting Patterns in Tables</blockquote><p>检测表格中的模式
搜索一组事件模式是一个常见的用例，特别是在数据流的情况下。Flink 自带复杂事件处理（CEP）库，可以在事件流中进行模式检测。此外，Flink 的 SQL API 提供了一种关系型的查询表达方式，有大量的内置函数和基于规则的优化，可以开箱即用。</p>
<p>2016 年 12 月，国际标准化组织（ISO）发布了新版本的 SQL 标准，其中包括 SQL 中的行模式识别（ISO/IEC TR 19075-5:2016）。它允许 Flink 使用 MATCH_RECOGNIZE 子句整合 CEP 和 SQL API，用于 SQL 中的复杂事件处理。</p>
<p>MATCH_RECOGNIZE 子句可以实现以下任务。</p>
<p>对使用 partition by 和 order by 子句的数据进行逻辑分区和排序。
使用 PATTERN 子句定义要寻找的行的模式。这些模式使用类似于正则表达式的语法。
行模式变量的逻辑成分在 DEFINE 子句中指定。
在 MEASURES 子句中定义措施，这些措施是在 SQL 查询的其他部分中可用的表达式。
下面的例子说明了基本模式识别的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">T</span><span class="p">.</span><span class="n">aid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">bid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">cid</span>
<span class="k">FROM</span> <span class="n">MyTable</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
      <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">userid</span>
      <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
      <span class="n">MEASURES</span>
        <span class="n">A</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">aid</span><span class="p">,</span>
        <span class="n">B</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">bid</span><span class="p">,</span>
        <span class="k">C</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">cid</span>
      <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span> <span class="k">C</span><span class="p">)</span>
      <span class="n">DEFINE</span>
        <span class="n">A</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span>
        <span class="n">B</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span>
        <span class="k">C</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span>
    <span class="p">)</span> <span class="k">AS</span> <span class="n">T</span>
</code></pre></div><p>本页将更详细地解释每个关键字，并将说明更复杂的例子。</p>
<p>注意 Flink 对 MATCH_RECOGNIZE 子句的实现是完整标准的一个子集。只有那些在下面的章节中记录的功能得到了支持。根据社区反馈，可能会支持更多的功能，也请看一下已知的限制。</p>
<p>介绍和示例
安装指南
模式识别功能内部使用了 Apache Flink 的 CEP 库。为了能够使用 MATCH_RECOGNIZE 子句，需要将该库作为一个依赖项添加到你的 Maven 项目中。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-cep_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>另外，你也可以将依赖关系添加到集群 classpath 中（更多信息请参见依赖关系部分）。</p>
<p>如果你想在 SQL 客户端中使用 MATCH_RECOGNIZE 子句，你不需要做任何事情，因为所有的依赖关系都是默认的。</p>
<p>SQL 语义
每个 MATCH_RECOGNIZE 查询都由以下子句组成。</p>
<p>PARTITION BY - 定义表的逻辑分区；类似于 GROUP BY 操作。</p>
<p>MEASURES - 定义子句的输出；类似于 SELECT 子句。
ONE ROW PER MATCH - 输出模式，定义每次匹配应该产生多少行。
AFTER MATCH SKIP&ndash;指定下一个匹配应该从哪里开始；这也是控制一个事件可以属于多少个不同匹配的方法。
PATTERN - 允许使用类似于正则表达式的语法来构建搜索的模式。
DEFINE - 这一部分定义了模式变量必须满足的条件。
注意 目前，MATCH_RECOGNIZE 子句只能应用于追加表。此外，它也总是产生一个追加表。</p>
<p>例子
在我们的例子中，我们假设已经注册了一个 Ticker 表。该表包含股票在某一特定时间点的价格。</p>
<p>该表的模式如下：</p>
<pre><code>Ticker
     |-- symbol: String                           # symbol of the stock
     |-- price: Long                              # price of the stock
     |-- tax: Long                                # tax liability of the stock
     |-- rowtime: TimeIndicatorTypeInfo(rowtime)  # point in time when the change to those values happened
</code></pre><p>为了简化，我们只考虑单只股票 ACME 的传入数据。一个行情可以类似于下表，其中行是连续追加的。</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   12      1
'ACME'  '01-Apr-11 10:00:01'   17      2
'ACME'  '01-Apr-11 10:00:02'   19      1
'ACME'  '01-Apr-11 10:00:03'   21      3
'ACME'  '01-Apr-11 10:00:04'   25      2
'ACME'  '01-Apr-11 10:00:05'   18      1
'ACME'  '01-Apr-11 10:00:06'   15      1
'ACME'  '01-Apr-11 10:00:07'   14      2
'ACME'  '01-Apr-11 10:00:08'   24      2
'ACME'  '01-Apr-11 10:00:09'   25      2
'ACME'  '01-Apr-11 10:00:10'   19      1
</code></pre><p>现在的任务是寻找单一行情的价格不断下降的时期。为此，可以写一个类似的查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="n">START_ROW</span><span class="p">.</span><span class="n">rowtime</span> <span class="k">AS</span> <span class="n">start_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">bottom_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_UP</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">end_tstamp</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="k">TO</span> <span class="k">LAST</span> <span class="n">PRICE_UP</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">START_ROW</span> <span class="n">PRICE_DOWN</span><span class="o">+</span> <span class="n">PRICE_UP</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">PRICE_DOWN</span> <span class="k">AS</span>
                <span class="p">(</span><span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">IS</span> <span class="k">NULL</span> <span class="k">AND</span> <span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="n">START_ROW</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">OR</span>
                    <span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">PRICE_UP</span> <span class="k">AS</span>
                <span class="n">PRICE_UP</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span> <span class="n">MR</span><span class="p">;</span>
</code></pre></div><p>该查询按符号列对 Ticker 表进行分区，并按行时间属性进行排序。</p>
<p>PATTERN 子句指定我们感兴趣的模式是以 START_ROW 事件为起点，然后是一个或多个 PRICE_DOWN 事件，最后是 PRICE_UP 事件。如果能找到这样的模式，下一个模式匹配将在最后一个 PRICE_UP 事件中寻找，如 AFTER MATCH SKIP TO LAST 子句所示。</p>
<p>DEFINE 子句指定了 PRICE_DOWN 和 PRICE_UP 事件需要满足的条件。虽然 START_ROW 模式变量并不存在，但它有一个隐含的条件，这个条件总是被评估为 TRUE。</p>
<p>模式变量 PRICE_DOWN 被定义为价格小于满足 PRICE_DOWN 条件的最后一行的价格。对于初始情况或者没有满足 PRICE_DOWN 条件的最后一行，这一行的价格应该小于模式中前一行的价格（由 START_ROW 引用）。</p>
<p>模式变量 PRICE_UP 被定义为价格大于满足 PRICE_DOWN 条件的最后一行的价格的行。</p>
<p>该查询为股票价格连续下跌的每个时期产生一条汇总行。</p>
<p>输出行的具体表示方法在查询的 MEASURES 部分定义。输出行的数量由 ONE ROW PER MATCH 输出模式定义。</p>
<pre><code> symbol       start_tstamp       bottom_tstamp         end_tstamp
=========  ==================  ==================  ==================
ACME       01-APR-11 10:00:04  01-APR-11 10:00:07  01-APR-11 10:00:08
</code></pre><p>结果一行描述了从 01-APR-11 10:00:04 开始的价格下降期，在 01-APR-11 10:00:07 达到最低价，在 01-APR-11 10:00:08 再次上涨。</p>
<p>分割
可以在分区数据中寻找模式，例如，单个股票或特定用户的趋势。这可以使用 partition by 子句来表达。该子句类似于使用 GROUP BY 进行聚合。</p>
<p>注意 强烈建议对输入的数据进行分区，否则 MATCH_RECOGNIZE 子句将被翻译成一个非平行操作符，以确保全局排序。</p>
<p>事件的顺序
Apache Flink 允许根据时间来搜索模式；无论是处理时间还是事件时间。</p>
<p>在事件时间的情况下，事件在被传递到内部模式状态机之前会被排序。因此，产生的输出将是正确的，不管行被附加到表中的顺序如何。相反，模式是按照每行包含的时间所指定的顺序来评估的。</p>
<p>MATCH_RECOGNIZE 子句假设时间属性以升序作为 ORDER BY 子句的第一个参数。</p>
<p>对于 Ticker 表的例子，像 ORDER BY rowtime ASC, price DESC 这样的定义是有效的，但是 ORDER BY price, rowtime 或者 ORDER BY rowtime DESC, price ASC 是无效的。</p>
<p>定义和测量
DEFINE 和 MEASURES 关键字的含义类似于简单 SQL 查询中的 WHERE 和 SELECT 子句。</p>
<p>MEASURES 子句定义了匹配模式的输出中会包含哪些内容。它可以投射列和定义评估的表达式。产生的行数取决于输出模式的设置。</p>
<p>DEFINE 子句指定了行必须满足的条件，以便将其分类到相应的模式变量。如果没有为模式变量定义条件，那么将使用一个默认条件，该条件对每条记录的评价为真。</p>
<p>关于这些子句中可以使用的表达式的更详细解释，请看事件流导航部分。</p>
<p>聚合
聚合可以在 DEFINE 和 MEASURES 子句中使用。同时支持内置和自定义的用户定义函数。</p>
<p>聚合函数被应用于映射到匹配的行的每个子集。为了了解这些子集是如何被评估的，请看一下事件流导航部分。</p>
<p>下面这个例子的任务是找到一个股票平均价格不低于某个阈值的最长时间段。它显示了 MATCH_RECOGNIZE 可以如何通过聚合来表达。这个任务可以用下面的查询来执行。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">start_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">end_tstamp</span><span class="p">,</span>
            <span class="k">AVG</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">avgPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="n">B</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">AVG</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">15</span>
    <span class="p">)</span> <span class="n">MR</span><span class="p">;</span>
</code></pre></div><p>给定这个查询和以下输入值：</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   12      1
'ACME'  '01-Apr-11 10:00:01'   17      2
'ACME'  '01-Apr-11 10:00:02'   13      1
'ACME'  '01-Apr-11 10:00:03'   16      3
'ACME'  '01-Apr-11 10:00:04'   25      2
'ACME'  '01-Apr-11 10:00:05'   2       1
'ACME'  '01-Apr-11 10:00:06'   4       1
'ACME'  '01-Apr-11 10:00:07'   10      2
'ACME'  '01-Apr-11 10:00:08'   15      2
'ACME'  '01-Apr-11 10:00:09'   25      2
'ACME'  '01-Apr-11 10:00:10'   25      1
'ACME'  '01-Apr-11 10:00:11'   30      1
</code></pre><p>只要事件的平均价格不超过 15，查询就会将事件累积为模式变量 A 的一部分。例如，这样的超限事件发生在 01-4-11 10:00:04。接下来的时期在 01-4-11 10:00:11 再次超过 15 的平均价格。因此，所述查询的结果将是：。</p>
<pre><code> symbol       start_tstamp       end_tstamp          avgPrice
=========  ==================  ==================  ============
ACME       01-APR-11 10:00:00  01-APR-11 10:00:03     14.5
ACME       01-APR-11 10:00:05  01-APR-11 10:00:10     13.5
</code></pre><p>注意 聚合可以应用于表达式，但只有当它们引用一个单一的模式变量时才可以。因此 SUM(A.price * A.tax)是有效的，但是 AVG(A.price * B.tax)不是。</p>
<p>注意不支持 DISTINCT 聚合。</p>
<p>定义一个模式
MATCH_RECOGNIZE 子句允许用户在事件流中搜索模式，使用一种强大的、富有表现力的语法，这种语法与广泛使用的正则表达式语法有些相似。</p>
<p>每个模式都是由基本的构件构成的，称为模式变量，可以对其应用运算符（量化符和其他修饰符）。整个模式必须用括号括起来。</p>
<p>一个模式的例子可以是这样的。</p>
<pre><code>PATTERN (A B+ C* D)
</code></pre><p>我们可以使用以下操作符。</p>
<p>并集 &ndash; 像(A B)这样的模式意味着 A 和 B 之间的相邻性是严格的，因此，中间不能有没有映射到 A 或 B 的行。
定量符&ndash;修改可以映射到模式变量的行数。</p>
<pre><code>* — 0 or more rows
+ — 1 or more rows
? — 0 or 1 rows
{ n } — exactly n rows (n &gt; 0)
{ n, } — n or more rows (n ≥ 0)
{ n, m } — between n and m (inclusive) rows (0 ≤ n ≤ m, 0 &lt; m)
{ , m } — between 0 and m (inclusive) rows (m &gt; 0)
</code></pre><p>注意 不支持可能产生空匹配的模式。这类模式的例子有 PATTERN (A*)、PATTERN (A?B*)、PATTERN (A{0,} B{0,} C*)等。</p>
<p>贪婪和不情愿的量化器
每个量化器可以是贪婪的（默认行为）或勉强的。贪婪的量化器试图匹配尽可能多的记录，而不情愿的量化器试图匹配尽可能少的记录。</p>
<p>为了说明两者的区别，我们可以查看下面的示例，在这个示例中，一个贪婪的量化器被应用于 B 变量。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">lastPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span><span class="o">*</span> <span class="k">C</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">,</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="p">,</span>
            <span class="k">C</span> <span class="k">AS</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="mi">12</span>
    <span class="p">)</span>
</code></pre></div><p>鉴于我们有以下输入。</p>
<pre><code> symbol  tax   price          rowtime
======= ===== ======== =====================
 XYZ     1     10       2018-09-17 10:00:02
 XYZ     2     11       2018-09-17 10:00:03
 XYZ     1     12       2018-09-17 10:00:04
 XYZ     2     13       2018-09-17 10:00:05
 XYZ     1     14       2018-09-17 10:00:06
 XYZ     2     16       2018-09-17 10:00:07
</code></pre><p>上述模式将产生以下输出。</p>
<pre><code> symbol   lastPrice
======== ===========
 XYZ      16
</code></pre><p>同样的查询，将 <code>B*</code> 修改为 <code>B*</code> 吗，即 B*应该是不愿意的，会产生。</p>
<pre><code> symbol   lastPrice
======== ===========
 XYZ      13
 XYZ      16
</code></pre><p>模式变量 B 只匹配到价格为 12 的行，而不是吞掉价格为 12、13、14 的行。</p>
<p>注意 对于一个模式的最后一个变量，不可能使用贪婪的量化符。因此，像（A B*）这样的模式是不允许的。这可以通过引入一个人为的状态（如 C）来轻松解决，这个状态具有 B 的否定条件，所以你可以使用这样的查询。</p>
<pre><code>PATTERN (A B* C)
DEFINE
    A AS condA(),
    B AS condB(),
    C AS NOT condB()
</code></pre><p>注意 目前不支持可选的勉强量化符(A??或 A{0,1}?)。</p>
<p>时间限制
特别是对于流式使用案例，通常要求一个模式在给定的时间内完成。这允许限制 Flink 必须在内部维护的整体状态大小，即使在贪婪的量化器的情况下。</p>
<p>因此，Flink SQL 支持额外的（非标准 SQL）WITHIN 子句来定义模式的时间约束。该子句可以定义在 PATTERN 子句之后，并以毫秒为间隔进行解析。</p>
<p>如果一个潜在匹配的第一个事件和最后一个事件之间的时间长于给定的值，这样的匹配将不会被追加到结果表中。</p>
<p>注意 一般鼓励使用 within 子句，因为它有助于 Flink 进行有效的内存管理。一旦达到阈值，底层状态可以被修剪。</p>
<p>注意 然而，WITHIN 子句不是 SQL 标准的一部分。推荐的处理时间限制的方式可能会在未来发生变化。</p>
<p>在下面的查询示例中说明了 WITHIN 子句的使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">C</span><span class="p">.</span><span class="n">rowtime</span> <span class="k">AS</span> <span class="n">dropTime</span><span class="p">,</span>
            <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">dropDiff</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span><span class="o">*</span> <span class="k">C</span><span class="p">)</span> <span class="n">WITHIN</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1&#39;</span> <span class="n">HOUR</span>
        <span class="n">DEFINE</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="mi">10</span>
            <span class="k">C</span> <span class="k">AS</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="mi">10</span>
    <span class="p">)</span>
</code></pre></div><p>查询检测到在 1 小时的时间间隔内发生的价格下跌 10。</p>
<p>假设该查询用于分析以下行情数据。</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   20      1
'ACME'  '01-Apr-11 10:20:00'   17      2
'ACME'  '01-Apr-11 10:40:00'   18      1
'ACME'  '01-Apr-11 11:00:00'   11      3
'ACME'  '01-Apr-11 11:20:00'   14      2
'ACME'  '01-Apr-11 11:40:00'   9       1
'ACME'  '01-Apr-11 12:00:00'   15      1
'ACME'  '01-Apr-11 12:20:00'   14      2
'ACME'  '01-Apr-11 12:40:00'   24      2
'ACME'  '01-Apr-11 13:00:00'   1       2
'ACME'  '01-Apr-11 13:20:00'   19      1
</code></pre><p>查询将产生以下结果。</p>
<pre><code>symbol         dropTime         dropDiff
======  ====================  =============
'ACME'  '01-Apr-11 13:00:00'      14
</code></pre><p>结果行表示价格从 15（在 4 月 1 日 12:00:00）下降到 1（在 4 月 1 日 13:00:00）。dropDiff 列包含了价格差。</p>
<p>请注意，即使价格也以更高的数值下降，例如，下降 11（在 01-Apr-11 10:00:00 和 01-Apr-11 11:40:00 之间），这两个事件之间的时间差大于 1 小时。因此，它们不会产生匹配。</p>
<p>输出模式
输出模式描述了每找到一个匹配的记录应该发出多少行。SQL 标准描述了两种模式。</p>
<pre><code>ALL ROWS PER MATCH
ONE ROW PER MATCH.
</code></pre><p>目前，唯一支持的输出模式是 ONE ROW PER MATCH，对于每一个找到的匹配项，总会产生一个输出汇总行。</p>
<p>输出行的模式将是[分区列]+[措施列]按该特定顺序的连接。</p>
<p>下面的例子显示了一个定义为查询的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">startPrice</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">topPrice</span><span class="p">,</span>
            <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">lastPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="n">B</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">IS</span> <span class="k">NULL</span> <span class="k">OR</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div><p>对于以下输入行：</p>
<pre><code> symbol   tax   price          rowtime
======== ===== ======== =====================
 XYZ      1     10       2018-09-17 10:00:02
 XYZ      2     12       2018-09-17 10:00:03
 XYZ      1     13       2018-09-17 10:00:04
 XYZ      2     11       2018-09-17 10:00:05
</code></pre><p>查询将产生以下输出。</p>
<pre><code> symbol   startPrice   topPrice   lastPrice
======== ============ ========== ===========
 XYZ      10           13         11
</code></pre><p>模式识别是按符号列进行分区的。尽管在 MEASURES 子句中没有明确提到，但在结果的开头会添加分区列。</p>
<p>模式导航
DEFINE 和 MEASURES 子句允许在（可能）匹配模式的行列表中进行导航。</p>
<p>本节将讨论这种用于声明条件或产生输出结果的导航。</p>
<p>模式变量引用
模式变量引用允许引用映射到 DEFINE 或 MEASURES 子句中特定模式变量的一组行。</p>
<p>例如，表达式 A.price 描述了迄今为止映射到 A 的一组行，再加上当前行，如果我们尝试将当前行与 A 进行匹配。如果 DEFINE/MEASURES 子句中的表达式需要单行（例如 A.price 或 A.price&gt;10），则选择属于相应集合的最后一个值。</p>
<p>如果没有指定模式变量（例如 SUM(price)），表达式会引用默认的模式变量*，它引用模式中的所有变量。换句话说，它创建了一个迄今为止映射到任何变量的所有行加上当前行的列表。</p>
<p>例子</p>
<p>要想了解更透彻的例子，可以看看下面的模式和相应的条件。</p>
<pre><code>PATTERN (A B+)
DEFINE
  A AS A.price &gt; 10,
  B AS B.price &gt; A.price AND SUM(price) &lt; 100 AND SUM(B.price) &lt; 80
</code></pre><p>下表描述了如何评估每个传入事件的这些条件。</p>
<p>该表由以下几栏组成：</p>
<pre><code># - the row identifier that uniquely identifies an incoming row in the lists [A.price]/[B.price]/[price].
price - the price of the incoming row.
[A.price]/[B.price]/[price] - describe lists of rows which are used in the DEFINE clause to evaluate conditions.
Classifier - the classifier of the current row which indicates the pattern variable the row is mapped to.
A.price/B.price/SUM(price)/SUM(B.price) - describes the result after those expressions have been evaluated.
#	price	Classifier	[A.price]	[B.price]	[price]	A.price	B.price	SUM(price)	SUM(B.price)
#1	10	-&gt; A	#1	-	-	10	-	-	-
#2	15	-&gt; B	#1	#2	#1, #2	10	15	25	15
#3	20	-&gt; B	#1	#2, #3	#1, #2, #3	10	20	45	35
#4	31	-&gt; B	#1	#2, #3, #4	#1, #2, #3, #4	10	31	76	66
#5	35		#1	#2, #3, #4, #5	#1, #2, #3, #4, #5	10	35	111	101
</code></pre><p>从表中可以看出，第一行被映射到模式变量 A，随后的行被映射到模式变量 B，但是最后一行不满足 B 的条件，因为所有映射行的 SUM(价格)和 B 中所有行的总和超过了指定的阈值。</p>
<p>逻辑偏移
逻辑偏移可以在映射到特定模式变量的事件中进行导航。这可以用两个相应的函数来表示。</p>
<p>偏移函数 描述
LAST(variable.field, n)
返回事件中被映射到变量第 n 个最后元素的字段的值。从映射到的最后一个元素开始计算。</p>
<p>FIRST(variable.field, n)
返回事件中被映射到变量第 n 个元素的字段值。从映射到的第一个元素开始计算。</p>
<p>示例</p>
<p>为了更透彻的举例，可以看看下面的模式和相应的条件。</p>
<pre><code>PATTERN (A B+)
DEFINE
  A AS A.price &gt; 10,
  B AS (LAST(B.price, 1) IS NULL OR B.price &gt; LAST(B.price, 1)) AND
       (LAST(B.price, 2) IS NULL OR B.price &gt; 2 * LAST(B.price, 2))
</code></pre><p>下表描述了如何评估每个传入事件的这些条件。</p>
<p>该表由以下几栏组成：</p>
<pre><code>price - the price of the incoming row.
Classifier - the classifier of the current row which indicates the pattern variable the row is mapped to.
LAST(B.price, 1)/LAST(B.price, 2) - describes the result after those expressions have been evaluated.
price	Classifier	LAST(B.price, 1)	LAST(B.price, 2)	Comment
10	-&gt; A			
15	-&gt; B	null	null	Notice that LAST(A.price, 1) is null because there is still nothing mapped to B.
20	-&gt; B	15	null	
31	-&gt; B	20	15	
35		31	20	Not mapped because 35 &lt; 2 * 20.
</code></pre><p>使用默认的模式变量与逻辑偏移量也可能是有意义的。</p>
<p>在这种情况下，偏移量会考虑到目前为止映射的所有行。</p>
<pre><code>PATTERN (A B? C)
DEFINE
  B AS B.price &lt; 20,
  C AS LAST(price, 1) &lt; C.price
price	Classifier	LAST(price, 1)	Comment
10	-&gt; A		
15	-&gt; B		
20	-&gt; C	15	LAST(price, 1) is evaluated as the price of the row mapped to the B variable.
</code></pre><p>如果第二行没有映射到 B 变量，我们会有以下结果。</p>
<pre><code>price	Classifier	LAST(price, 1)	Comment
10	-&gt; A		
20	-&gt; C	10	LAST(price, 1) is evaluated as the price of the row mapped to the A variable.
</code></pre><p>也可以在 first/last 函数的第一个参数中使用多个模式变量引用。这样，就可以写一个访问多列的表达式。但是，所有这些表达式必须使用同一个模式变量。换句话说，LAST/FIRST 函数的值必须在单行中计算。</p>
<p>因此，可以使用 LAST(A.price * A.tax)，但不允许使用 LAST(A.price * B.tax)这样的表达式。</p>
<p>匹配后策略
AFTER MATCH SKIP 子句指定了在找到完整匹配后，在哪里开始一个新的匹配过程。</p>
<p>有四种不同的策略。</p>
<p>SKIP PAST LAST ROW - 在当前匹配的最后一行之后的下一行恢复模式匹配。
SKIP TO NEXT ROW - 从匹配起始行后的下一行开始继续搜索新的匹配。
SKIP TO LAST 变量&ndash;在映射到指定模式变量的最后一行恢复模式匹配。
SKIP TO FIRST 变量&ndash;在被映射到指定模式变量的第一行恢复模式匹配。
这也是一种指定一个事件可以属于多少个匹配的方式。例如，使用 SKIP PAST LAST ROW 策略，每个事件最多只能属于一个匹配。</p>
<p>例子</p>
<p>为了更好地理解这些策略之间的差异，可以看一下下面的例子。</p>
<p>对于以下输入行。</p>
<pre><code> symbol   tax   price         rowtime
======== ===== ======= =====================
 XYZ      1     7       2018-09-17 10:00:01
 XYZ      2     9       2018-09-17 10:00:02
 XYZ      1     10      2018-09-17 10:00:03
 XYZ      2     5       2018-09-17 10:00:04
 XYZ      2     17      2018-09-17 10:00:05
 XYZ      2     14      2018-09-17 10:00:06
</code></pre><p>我们用不同的策略评估以下查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">SUM</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">sumPrice</span><span class="p">,</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">startTime</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">endTime</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="p">[</span><span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">STRATEGY</span><span class="p">]</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="k">C</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">SUM</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">30</span>
    <span class="p">)</span>
</code></pre></div><p>查询返回映射到 A 的所有行的价格总和，以及整体匹配的第一个和最后一个时间戳。</p>
<p>根据使用的 AFTER MATCH 策略，查询会产生不同的结果。</p>
<p>AFTER MATCH SKIP PAST ROW(跳过最后一行)</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>第一个结果与 1 号，2 号，3 号，4 号行相匹配。</p>
<p>第二个结果与#5, #6 行相匹配。</p>
<p>匹配后跳转到下一行。</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      24         2018-09-17 10:00:02   2018-09-17 10:00:05
 XYZ      15         2018-09-17 10:00:03   2018-09-17 10:00:05
 XYZ      22         2018-09-17 10:00:04   2018-09-17 10:00:06
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>同样，第一个结果对 1 号、2 号、3 号、4 号行进行匹配。</p>
<p>与之前的策略相比，接下来的匹配中又包含了 2 号行的匹配。因此，第二个结果与行#2，#3，#4，#5 相匹配。</p>
<p>第三个结果与 3 号，4 号，5 号行相匹配。</p>
<p>第四个结果与行#4，#5，#6 相匹配。</p>
<p>最后一个结果与行#5，#6 匹配。</p>
<p>匹配后跳转到最后一行。</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      15         2018-09-17 10:00:03   2018-09-17 10:00:05
 XYZ      22         2018-09-17 10:00:04   2018-09-17 10:00:06
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>同样，第一个结果针对 1 号、2 号、3 号、4 号行进行匹配。</p>
<p>与之前的策略相比，接下来的匹配只包括 3 号行（映射到 A 行），再次进行匹配。因此，第二个结果与行#3，#4，#5 相匹配。</p>
<p>第三个结果与#4，#5，#6 行相匹配。</p>
<p>最后一个结果与行#5,#6 匹配，因此第三个结果与行#4,#5,#6 匹配。</p>
<p>匹配后跳转到第一行 A。</p>
<p>这个组合会产生一个运行时异常，因为我们总是试图在上一个比赛开始的地方开始一个新的比赛。这将产生一个无限循环，因此是被禁止的。</p>
<p>我们必须记住，在使用 SKIP TO FIRST/LAST 变量策略的情况下，有可能没有记录映射到该变量上（例如模式 A*）。在这种情况下，将抛出一个运行时异常，因为标准要求有一条有效的记录来继续匹配。</p>
<p>时间属性
为了在 MATCH_RECOGNIZE 之上应用一些后续的查询，可能需要使用时间属性。为了选择这些属性，有两个函数可用。</p>
<p>功能描述
MATCH_ROWTIME()
返回被映射到给定模式的最后一行的时间戳。</p>
<p>所得到的属性是一个 rowtime 属性，它可以被用于后续的基于时间的操作，如区间连接和组窗口或窗口聚合。</p>
<p>MATCH_PROCTIME()
返回一个 proctime 属性，该属性可用于后续基于时间的操作，如区间连接和组窗口或窗口聚合。</p>
<p>控制内存消耗
在编写 MATCH_RECOGNIZE 查询时，内存消耗是一个重要的考虑因素，因为潜在的匹配空间是以类似广度优先的方式建立的。考虑到这一点，必须确保模式能够完成。最好是有合理数量的行映射到匹配中，因为它们必须适应内存。</p>
<p>例如，模式不能有一个没有上限的量化器，接受每一行。这样的模式可以是这样的。</p>
<pre><code>PATTERN (A B+ C)
DEFINE
  A as A.price &gt; 10,
  C as C.price &gt; 20
</code></pre><p>该查询将把每一条进入的记录映射到 B 变量上，因此永远不会结束。这个查询可以通过否定 C 的条件来解决。</p>
<pre><code>PATTERN (A B+ C)
DEFINE
  A as A.price &gt; 10,
  B as B.price &lt;= 20,
  C as C.price &gt; 20
</code></pre><p>或者通过使用勉强的定量器。</p>
<pre><code>PATTERN (A B+? C)
DEFINE
  A as A.price &gt; 10,
  C as C.price &gt; 20
</code></pre><p>注意 请注意，MATCH_RECOGNIZE 子句不使用配置的状态保留时间。人们可能希望使用 WITHIN 子句来达到这个目的。</p>
<p>已知限制
Flink 对 MATCH_RECOGNIZE 子句的实现是一项持续的努力，目前还不支持 SQL 标准的一些功能。</p>
<p>不支持的功能包括</p>
<p>模式表达式。
模式组&ndash;这意味着，例如量化符不能应用于模式的子序列。因此，（A (B C)+）不是有效的模式。
改变&ndash;像 PATTERN((A B | C D) E)这样的模式，这意味着在寻找 E 行之前必须先找到一个子序列 A B 或 C D。
PERMUTE 运算符&ndash;相当于它所应用的所有变量的排列组合，例如 PATTERN(PERMUTE (A, B, C))=PATTERN(A B C | A C B | B A C | B A C | C B A | C B A)。
锚 - ^, $，表示一个分区的开始/结束，这些在流媒体环境中没有意义，将不被支持。
排除 - PATTERN ({- A -} B) 意味着 A 将被查找，但不会参与输出。这只对 ALL ROWS PER MATCH 模式有效。
不情愿的可选量化符&ndash;PATTERN A?? 只支持贪婪的可选量化符。
ALL ROWS PER MATCH 输出模式&ndash;它为每一条参与创建发现匹配的记录产生一条输出行。这也意味着。
MEASURES 子句唯一支持的语义是 FINAL。
CLASSIFIER 函数，该函数返回某行被映射到的模式变量，目前还不支持。
SUBSET - 允许创建模式变量的逻辑组，并在 DEFINE 和 MEASURES 子句中使用这些组。
物理偏移&ndash;PREV/NEXT，它索引所有看到的事件，而不是只索引那些被映射到模式变量的事件（如逻辑偏移情况）。
提取时间属性&ndash;目前没有可能为后续基于时间的操作获取时间属性。
MATCH_RECOGNIZE 只支持 SQL。在 Table API 中没有等价物。
聚合。
不支持不同的聚合。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[概念和通用 API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-concepts-and-common-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-concepts-and-common-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Concepts and Common API</blockquote><h2 id="概念和通用-api">概念和通用 API</h2>
<p>Table API 和 SQL 被集成在一个联合 API 中。这个 API 的核心概念是一个 Table，作为查询的输入和输出。本文档介绍了具有 Table API 和 SQL 查询的程序的常用结构，如何注册 Table，如何查询 Table，如何发出 Table。</p>
<h2 id="两种-planners-的主要区别">两种 Planners 的主要区别</h2>
<ol>
<li>Blink 将批处理作业视为流式作业的一种特殊情况。因此，也不支持 Table 和 DataSet 之间的转换，批处理作业不会被翻译成 DateSet 程序，而是翻译成 DataStream 程序，和流作业一样。</li>
<li>Blink 计划器不支持 BatchTableSource，请使用有界的 StreamTableSource 代替。</li>
<li>旧计划器和 Blink 计划器的 FilterableTableSource 的实现是不兼容的。旧的规划者会将 PlannerExpressions 推送到 FilterableTableSource 中，而 Blink 规划者会将 Expressions 推送下去。</li>
<li>基于字符串的键值<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html">配置</a>选项(详情请看配置文档)只用于 Blink 规划器。</li>
<li>PlannerConfig 在两个规划器中的实现(CalciteConfig)是不同的。</li>
<li>Blink 规划师将在 TableEnvironment 和 StreamTableEnvironment 上把多个汇优化成一个 DAG。旧的规划器总是会将每个汇优化成一个新的 DAG，其中所有的 DAG 是相互独立的。</li>
<li>现在老的计划器不支持目录统计，而 Blink 计划器支持。</li>
</ol>
<h2 id="table-api-和-sql-程序的结构">Table API 和 SQL 程序的结构</h2>
<p>所有用于批处理和流处理的 Table API 和 SQL 程序都遵循相同的模式。下面的代码示例显示了 Table API 和 SQL 程序的共同结构。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create a TableEnvironment for specific planner batch or streaming
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// create a Table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(...).</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;table1&#34;</span><span class="o">)</span>
<span class="c1">// register an output Table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(...).</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>

<span class="c1">// create a Table from a Table API query
</span><span class="c1"></span><span class="k">val</span> <span class="n">tapiResult</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;table1&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(...)</span>
<span class="c1">// create a Table from a SQL query
</span><span class="c1"></span><span class="k">val</span> <span class="n">sqlResult</span>  <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT ... FROM table1 ...&#34;</span><span class="o">)</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult</span> <span class="k">=</span> <span class="n">tapiResult</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>
<span class="n">tableResult</span><span class="o">...</span>
</code></pre></div><p>注意：表 API 和 SQL 查询可以很容易地与 DataStream 或 DataSet 程序集成并嵌入其中。请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">与 DataStream 和 DataSet API 的集成</a>部分，了解如何将 DataStream 和 DataSets 转换为表，反之亦然。</p>
<h2 id="创建一个-tableenvironment">创建一个 TableEnvironment</h2>
<p>TableEnvironment 是 Table API 和 SQL 集成的核心概念。它负责</p>
<ul>
<li>在内部目录(catalog)中注册一个 Table</li>
<li>登记目录(catalog)</li>
<li>加载可插拔模块</li>
<li>执行 SQL 查询</li>
<li>注册一个用户定义的（标量、表或聚合）函数</li>
<li>将 DataStream 或 DataSet 转换为 Table</li>
<li>持有对 ExecutionEnvironment 或 StreamExecutionEnvironment 的引用。</li>
</ul>
<p>一个 Table 总是绑定在一个特定的 TableEnvironment 上。在同一个查询中，不可能将不同 TableEnvironments 的表组合起来，例如，将它们连接或联合起来。</p>
<p>通过调用静态的 <code>BatchTableEnvironment.create()</code> 或 <code>StreamTableEnvironment.create()</code> 方法创建一个 TableEnvironment，其中包含一个 StreamExecutionEnvironment 或 ExecutionEnvironment 和一个可选的 TableConfig。TableConfig 可以用来配置 TableEnvironment 或自定义查询优化和翻译过程（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#query-optimization">Query Optimization</a>）。</p>
<p>确保选择与你的编程语言相匹配的特定规划器 BatchTableEnvironment/StreamTableEnvironment。</p>
<p>如果这两个规划器 jar 都在 classpath 上（默认行为），你应该明确设置在当前程序中使用哪个规划器。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// **********************
</span><span class="c1">// FLINK STREAMING QUERY
</span><span class="c1">// **********************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="n">fsSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">useOldPlanner</span><span class="o">().</span><span class="n">inStreamingMode</span><span class="o">().</span><span class="n">build</span><span class="o">()</span>
<span class="k">val</span> <span class="n">fsEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">fsTableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">fsEnv</span><span class="o">,</span> <span class="n">fsSettings</span><span class="o">)</span>
<span class="c1">// or val fsTableEnv = TableEnvironment.create(fsSettings)
</span><span class="c1"></span>
<span class="c1">// ******************
</span><span class="c1">// FLINK BATCH QUERY
</span><span class="c1">// ******************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.ExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.BatchTableEnvironment</span>

<span class="k">val</span> <span class="n">fbEnv</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">fbTableEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">fbEnv</span><span class="o">)</span>

<span class="c1">// **********************
</span><span class="c1">// BLINK STREAMING QUERY
</span><span class="c1">// **********************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="n">bsEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">bsSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">useBlinkPlanner</span><span class="o">().</span><span class="n">inStreamingMode</span><span class="o">().</span><span class="n">build</span><span class="o">()</span>
<span class="k">val</span> <span class="n">bsTableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">bsEnv</span><span class="o">,</span> <span class="n">bsSettings</span><span class="o">)</span>
<span class="c1">// or val bsTableEnv = TableEnvironment.create(bsSettings)
</span><span class="c1"></span>
<span class="c1">// ******************
</span><span class="c1">// BLINK BATCH QUERY
</span><span class="c1">// ******************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.table.api.</span><span class="o">{</span><span class="nc">EnvironmentSettings</span><span class="o">,</span> <span class="nc">TableEnvironment</span><span class="o">}</span>

<span class="k">val</span> <span class="n">bbSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">useBlinkPlanner</span><span class="o">().</span><span class="n">inBatchMode</span><span class="o">().</span><span class="n">build</span><span class="o">()</span>
<span class="k">val</span> <span class="n">bbTableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">bbSettings</span><span class="o">)</span>
</code></pre></div><p>注意：如果在 <code>/lib</code> 目录下只有一个 planner jar，可以使用 <code>AnyPlanner(python 的 use_any_planner)</code> 来创建特定的环境设置。</p>
<h2 id="在目录catalog中创建表">在目录(Catalog)中创建表</h2>
<p>一个 TableEnvironment 维护着一个表的目录图，这些表是用一个标识符创建的。每个标识符由 3 部分组成：目录名、数据库名和对象名。如果没有指定目录或数据库，将使用当前的默认值（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#table-identifier-expanding">Table 标识符展开</a>部分的例子）。</p>
<p>表可以是虚拟的（VIEWS）或常规的（TABLES）。VIEWS 可以从现有的 Table 对象创建，通常是 Table API 或 SQL 查询的结果。TABLES 描述外部数据，如文件、数据库表或消息队列。</p>
<h3 id="临时表与永久表">临时表与永久表</h3>
<p>表可以是临时的，与单个 Flink 会话的生命周期挂钩，也可以是永久的，在多个 Flink 会话和集群中可见。</p>
<p>永久表需要一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>（如 Hive Metastore）来维护表的元数据。一旦创建了永久表，它对连接到目录的任何 Flink 会话都是可见的，并将继续存在，直到表被显式放弃。</p>
<p>另一方面，临时表总是存储在内存中，并且只在它们创建的 Flink 会话的持续时间内存在。这些表对其他会话不可见。它们不绑定到任何目录或数据库，但可以在一个目录或数据库的命名空间中创建。如果相应的数据库被删除，临时表不会被删除。</p>
<h3 id="shadowing">Shadowing</h3>
<p>可以用与现有永久表相同的标识符登记一个临时表。只要临时表存在，临时表就会对永久表产生遮盖，使永久表无法访问。所有使用该标识符的查询都将针对临时表执行。</p>
<p>这可能对实验很有用。它允许首先对临时表运行完全相同的查询，例如，只有一个数据子集，或者数据被混淆了。一旦验证了查询的正确性，就可以针对真正的生产表运行。</p>
<h2 id="创建一个-table">创建一个 Table</h2>
<h3 id="虚拟表">虚拟表</h3>
<p>表 API 对象对应于 SQL 术语中的 VIEW（虚拟表）。它封装了一个逻辑查询计划。它可以在一个目录中创建，具体如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// table is the result of a simple projection query 
</span><span class="c1"></span><span class="k">val</span> <span class="n">projTable</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;X&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(...)</span>

<span class="c1">// register the Table projTable as table &#34;projectedTable&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;projectedTable&#34;</span><span class="o">,</span> <span class="n">projTable</span><span class="o">)</span>
</code></pre></div><p>注意：Table 对象与关系型数据库系统中的 VIEW 类似，即定义 Table 的查询不进行优化，但当另一个查询引用注册的 Table 时，会被内联。如果多个查询引用同一个注册表，则会对每个引用查询进行内联，并执行多次，即注册表的结果不会被共享。</p>
<h3 id="连接器表">连接器表</h3>
<p>也可以从<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接器</a>声明中创建一个关系型数据库中已知的 TABLE。连接器描述的是存储表数据的外部系统。这里可以声明 Apacha Kafka 或普通文件系统等存储系统。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">DDL</span>
<span class="n">tableEnvironment</span>
  <span class="o">.</span><span class="n">connect</span><span class="o">(...)</span>
  <span class="o">.</span><span class="n">withFormat</span><span class="o">(...)</span>
  <span class="o">.</span><span class="n">withSchema</span><span class="o">(...)</span>
  <span class="o">.</span><span class="n">inAppendMode</span><span class="o">()</span>
  <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="扩展-table-标识符">扩展 Table 标识符</h3>
<p>表总是用目录(catalog)、数据库、表名三部分组成的标识符进行注册。</p>
<p>用户可以将其中的一个目录和一个数据库设置为&quot;当前目录&quot;和&quot;当前数据库&quot;。其中，上述 3 部分标识符中的前两部分可以选择，如果不提供，则引用当前目录和当前数据库。用户可以通过表 API 或 SQL 切换当前目录和当前数据库。</p>
<p>标识符遵循 SQL 的要求，这意味着它们可以用反引号符(`)进行转义。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">...;</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">useCatalog</span><span class="o">(</span><span class="s">&#34;custom_catalog&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">useDatabase</span><span class="o">(</span><span class="s">&#34;custom_database&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...;</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1">// in the database named &#39;custom_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1">// in the database named &#39;other_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;other_database.exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;example.View&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1">// in the database named &#39;custom_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;`example.View`&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;other_catalog&#39;
</span><span class="c1">// in the database named &#39;other_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;other_catalog.other_database.exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>
</code></pre></div><h2 id="查询一个-table">查询一个 Table</h2>
<h3 id="table-api">Table API</h3>
<p>Table API 是 Scala 和 Java 的语言集成查询 API。与 SQL 不同的是，查询不是指定为 Strings，而是在宿主语言中一步步组成。</p>
<p>该 API 基于 Table 类，它表示一个表（流式或批处理），并提供了应用关系操作的方法。这些方法返回一个新的 Table 对象，该对象表示对输入的 Table 应用关系操作的结果。有些关系操作由多个方法调用组成，如 <code>table.groupBy(...).select()</code>，其中 <code>groupBy(...)</code> 指定表的分组，<code>select(...)</code> 是表的分组上的投影。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 文档描述了流式表和批处理表上支持的所有 Table API 操作。</p>
<p>下面的示例显示了一个简单的 Table API 聚合查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register Orders table
</span><span class="c1"></span>
<span class="c1">// scan registered Orders table
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="c1">// compute revenue for all customers from France
</span><span class="c1"></span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cCountry&#34;</span> <span class="o">===</span> <span class="s">&#34;FRANCE&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cID&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;cName&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cID&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;cName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;revenue&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="nc">AS</span> <span class="s">&#34;revSum&#34;</span><span class="o">)</span>

<span class="c1">// emit or convert Table
</span><span class="c1">// execute query
</span></code></pre></div><p>注意：Scala Table API 使用以美元符号（<code>$</code>）开头的 Scala 字符串插值来引用 Table 的属性。Table API 使用 Scala implicits。请确保导入</p>
<ul>
<li><code>org.apache.flink.table.api._</code> - 用于隐式表达式转换</li>
<li><code>org.apache.flink.api.scala._</code> 和 <code>org.apache.flink.table.api.bridge.scala._</code>，如果你想从 DataStream 转换到 DataStream。</li>
</ul>
<h2 id="sql">SQL</h2>
<p>Flink 的 SQL 集成是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。SQL 查询被指定为常规 Strings。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL</a> 文档描述了 Flink 对流和批处理表的 SQL 支持。</p>
<p>下面的例子展示了如何指定一个查询并将结果以表的形式返回。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register Orders table
</span><span class="c1"></span>
<span class="c1">// compute revenue for all customers from France
</span><span class="c1"></span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;&#34;&#34;
</span><span class="s">  |SELECT cID, cName, SUM(revenue) AS revSum
</span><span class="s">  |FROM Orders
</span><span class="s">  |WHERE cCountry = &#39;FRANCE&#39;
</span><span class="s">  |GROUP BY cID, cName
</span><span class="s">  &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="c1">// emit or convert Table
</span><span class="c1">// execute query
</span></code></pre></div><p>下面的示例显示了如何指定一个更新查询，将其结果插入到注册表中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register &#34;Orders&#34; table
</span><span class="c1">// register &#34;RevenueFrance&#34; output table
</span><span class="c1"></span>
<span class="c1">// compute revenue for all customers from France and emit to &#34;RevenueFrance&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;&#34;&#34;
</span><span class="s">  |INSERT INTO RevenueFrance
</span><span class="s">  |SELECT cID, cName, SUM(revenue) AS revSum
</span><span class="s">  |FROM Orders
</span><span class="s">  |WHERE cCountry = &#39;FRANCE&#39;
</span><span class="s">  |GROUP BY cID, cName
</span><span class="s">  &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="混合-table-api-和-sql">混合 Table API 和 SQL</h3>
<p>表 API 和 SQL 查询可以很容易地混合，因为两者都返回 Table 对象。</p>
<ul>
<li>可以在 SQL 查询返回的 Table 对象上定义 Table API 查询。</li>
<li>通过在 TableEnvironment 中<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-table">注册生成的 Table</a>并在 SQL 查询的 FROM 子句中引用它，可以在 Table API 查询的结果上定义一个 SQL 查询。</li>
</ul>
<h3 id="发出一个表">发出一个表</h3>
<p>一个 Table 是通过将其写入 TableSink 而发出的。TableSink 是一个通用接口，它支持多种文件格式（如 CSV、Apache Parquet、Apache Avro）、存储系统（如 JDBC、Apache HBase、Apache Cassandra、Elasticsearch）或消息系统（如 Apache Kafka、RabbitMQ）。</p>
<p>批量表只能写入 BatchTableSink，而流式表则需要 AppendStreamTableSink、RetractStreamTableSink 或 UpsertStreamTableSink。</p>
<p>请参阅有关 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html">Table Sources &amp; Sink</a> 的文档，以了解可用的 Sink 的详细信息以及如何实现自定义 TableSink 的说明。</p>
<p><code>Table.executeInsert(String tableName)</code> 方法将 Table 排放到一个注册的 TableSink 中。该方法通过名称从目录中查找 TableSink，并验证 Table 的模式与 TableSink 的模式是否相同。</p>
<p>下面的示例展示了如何发射 Table。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// create an output Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">LONG</span><span class="o">())</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/path/to/file&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="n">fieldDelimiter</span><span class="o">(</span><span class="sc">&#39;|&#39;</span><span class="o">).</span><span class="n">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;CsvSinkTable&#34;</span><span class="o">)</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// emit the result Table to the registered TableSink
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;CsvSinkTable&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="翻译和执行查询">翻译和执行查询</h3>
<p>两个规划器翻译和执行查询的行为是不同的。</p>
<ul>
<li>Blink 计划器</li>
</ul>
<p>表 API 和 SQL 查询无论其输入是流式还是批处理，都会被翻译成 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream</a> 程序。一个查询在内部表示为一个逻辑查询计划，并分两个阶段进行翻译。</p>
<ol>
<li>逻辑计划的优化。</li>
<li>翻译成 DataStream 程序。</li>
</ol>
<p>Table API 或 SQL 查询被翻译时:</p>
<ul>
<li><code>TableEnvironment.executeSql()</code> 被调用。这个方法用于执行给定的语句，一旦这个方法被调用，sql 查询就会立即被翻译。</li>
<li><code>Table.executeInsert()</code> 被调用。该方法用于将表的内容插入到给定的 sink 路径中，一旦调用该方法，Table API 立即被翻译。</li>
<li>调用 <code>Table.execute()</code>。该方法用于将表内容收集到本地客户端，一旦调用该方法，Table API 立即被翻译。</li>
<li><code>StatementSet.execute()</code> 被调用。一个 Table（通过 <code>StatementSet.addInsert()</code> 向 sink 发出）或一个 INSERT 语句（通过  <code>StatementSet.addInsertSql()</code> 指定）将首先在 StatementSet 中被缓冲。一旦 <code>StatementSet.execute()</code> 被调用，它们就会被翻译。所有接收器将被优化成一个 DAG。</li>
<li>当一个表被转换为 DataStream 时，它就会被翻译（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">与 DataStream 和 DataSet API 的集成</a>）。一旦翻译完毕，它就是一个常规的 DataStream 程序，并在调用 StreamExecutionEnvironment.execut()时被执行。
注意: 从 1.11 版本开始，<code>sqlUpdate()</code> 方法和 <code>insertInto()</code> 方法已被废弃。如果 Table 程序是由这两个方法构建的，我们必须使用 <code>StreamTableEnvironment.execution()</code> 方法代替 <code>StreamExecutionEnvironment.execution()</code> 方法来执行。</li>
</ul>
<h2 id="与-datastream-和-dataset-api-的集成">与 DataStream 和 DataSet API 的集成</h2>
<p>两种流上的计划器都可以与 DataStream API 集成，只有老的计划器可以与 DataSet API 集成，批处理的 Blink 计划器不能与两者结合。只有旧的计划器可以与 DataSet API 集成，批处理的 Blink 计划器不能与两者结合。注：下面讨论的 DataSet API 只适用于批处理的旧版规划器。</p>
<p>Table API 和 SQL 查询可以很容易地与 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch">DataSet</a> 程序集成并嵌入其中。例如，可以查询一个外部表（例如来自 RDBMS），做一些预处理，如过滤、投影、聚合或加入元数据，然后用 DataStream 或 DataSet API（以及建立在这些 API 之上的任何库，如 CEP 或 Gelly）进一步处理数据。反之，也可以在 DataStream 或 DataSet 程序的结果上应用 Table API 或 SQL 查询。</p>
<p>这种交互可以通过将 DataStream 或 DataSet 转换为表来实现，反之亦然。在本节中，我们将描述这些转换是如何完成的。</p>
<h3 id="scala-隐式转换">Scala 隐式转换</h3>
<p>Scala Table API 为 DataSet、DataStream 和 Table 类提供了隐式转换的功能。这些转换是通过导入包 <code>org.apache.flink.table.api.bridge.scala._</code> 来实现的，此外还可以导入 <code>org.apache.flink.api.scala._</code> 来实现 Scala DataStream API。</p>
<h3 id="从-datastream-或-dataset-创建视图">从 DataStream 或 DataSet 创建视图</h3>
<p>DataStream 或 DataSet 可以作为视图在 TableEnvironment 中注册。由此产生的视图的模式取决于注册的 DataStream 或 DataSet 的数据类型。请查看有关<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#mapping-of-data-types-to-table-schema">数据类型到表模式的映射</a>部分以了解详情。</p>
<p>注意：从 DataStream 或 DataSet 创建的视图只能注册为临时视图。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
</span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// register the DataStream as View &#34;myTable&#34; with fields &#34;f0&#34;, &#34;f1&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;myTable&#34;</span><span class="o">,</span> <span class="n">stream</span><span class="o">)</span>

<span class="c1">// register the DataStream as View &#34;myTable2&#34; with fields &#34;myLong&#34;, &#34;myString&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;myTable2&#34;</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> &#39;myLong<span class="o">,</span> &#39;myString<span class="o">)</span>
</code></pre></div><h3 id="将-datastream-或-dataset-转换为-table">将 DataStream 或 DataSet 转换为 Table</h3>
<p>不需要在 TableEnvironment 中注册一个 DataStream 或 DataSet，也可以直接将其转换为 Table。如果你想在 Table API 查询中使用 Table，这很方便。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment
</span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert the DataStream into a Table with default fields &#34;_1&#34;, &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert the DataStream into a Table with fields &#34;myLong&#34;, &#34;myString&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myString&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="将-table-转换为-datastream-或-dataset">将 Table 转换为 DataStream 或 DataSet</h3>
<p>Table 可以被转换为 DataStream 或 DataSet。通过这种方式，可以在表 API 或 SQL 查询的结果上运行自定义 DataStream 或 DataSet 程序。</p>
<p>当将 Table 转换为 DataStream 或 DataSet 时，您需要指定生成的 DataStream 或 DataSet 的数据类型，即表的行要转换为的数据类型。通常，最方便的转换类型是 Row。下面的列表给出了不同选项的功能概述。</p>
<ul>
<li>Row：字段按位置映射，字段数量任意，支持 null 值，无类型安全访问。</li>
<li>POJO：字段按名称映射（POJO 字段必须与表字段一样命名），任意数量的字段，支持 null 值，类型安全访问。</li>
<li>Case Class：字段按位置映射，不支持 null 值，类型安全访问。</li>
<li>Tuple：字段按位置映射，限制为 22 个（Scala）或 25 个（Java）字段，不支持 null 值，类型安全访问。</li>
<li>原子类型：表必须有一个字段，不支持空值，类型安全访问。表必须有一个字段，不支持 null 值，类型安全访问。</li>
</ul>
<h3 id="将-table-转换为-datastream">将 Table 转换为 DataStream</h3>
<p>作为流式查询结果的表将被动态更新，即随着查询输入流中新记录的到达而变化。因此，将这种动态查询转换成的 DataStream 需要对表的更新进行编码。</p>
<p>有两种模式可以将表转换为 DataStream。</p>
<ol>
<li>Append 模式。只有当动态 Table 只被 INSERT 修改时，才可以使用这种模式，即只进行追加，之前发出的结果永远不会更新。</li>
<li>收回模式。这种模式可以一直使用。它将 INSERT 和 DELETE 更改用布尔标志编码。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment. 
</span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into an append DataStream of Row
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2[String, Int]
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="n">dsTuple</span> <span class="k">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a retract DataStream of Row.
</span><span class="c1">//   A retract stream of type X is a DataStream[(Boolean, X)]. 
</span><span class="c1">//   The boolean field indicates the type of the change. 
</span><span class="c1">//   True is INSERT, false is DELETE.
</span><span class="c1"></span><span class="k">val</span> <span class="n">retractStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Boolean</span>, <span class="kt">Row</span><span class="o">)]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toRetractStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>
</code></pre></div><p>注意：关于动态表及其属性的详细讨论在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>文档中给出。</p>
<p>注意: 一旦表转换为 DataStream，请使用 <code>StreamExecutionEnvironment.execute()</code> 方法来执行 DataStream 程序。</p>
<h3 id="将-table-转换为-dataset">将 Table 转换为 DataSet</h3>
<p>Table 转换为 DataStream 的过程如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
</span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into a DataSet of Row
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toDataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a DataSet of Tuple2[String, Int]
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toDataSet</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">)</span>
</code></pre></div><p>注意: 一旦 Table 转换为 DataSet，我们必须使用 <code>ExecutionEnvironment.execute</code> 方法来执行 DataSet 程序。</p>
<h3 id="数据类型到-table-schema-的映射">数据类型到 Table Schema 的映射</h3>
<p>Flink 的 DataStream 和 DataSet API 支持非常多样化的类型。复合类型，如 Tuples（内置的 Scala 和 Flink Java tuples）、POJOs、Scala case 类和 Flink 的 Row 类型，允许嵌套具有多个字段的数据结构，这些字段可以在 Table 表达式中访问。其他类型被视为原子类型。在下文中，我们将描述 Table API 如何将这些类型转换为内部行表示，并展示将 DataStream 转换为 Table 的例子。</p>
<p>数据类型到 Table Schema 的映射可以通过两种方式进行：基于字段位置或基于字段名。</p>
<ul>
<li>基于位置的映射</li>
</ul>
<p>基于位置的映射可以用来给字段一个更有意义的名字，同时保持字段顺序。这种映射可用于具有定义字段顺序的复合数据类型以及原子类型。复合数据类型如元组、行和 case 类都有这样的字段顺序。然而，POJO 的字段必须根据字段名进行映射（见下一节）。字段可以被投影出来，但不能使用别名作为重命名。</p>
<p>当定义基于位置的映射时，指定的名称必须不存在于输入数据类型中，否则 API 将假设映射应该基于字段名发生。如果没有指定字段名，则使用复合类型的默认字段名和字段顺序，对于原子类型则使用 f0。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names &#34;_1&#34; and &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field &#34;myLong&#34; only
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#34;myLong&#34; and &#34;myInt&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myInt&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>基于名称的映射</li>
</ul>
<p>基于名称的映射可以用于任何数据类型，包括 POJO。它是定义表模式映射的最灵活的方式。映射中的所有字段都是通过名称引用的，并可能使用别名重命名为。字段可以重新排序和投影出来。</p>
<p>如果没有指定字段名，则使用复合类型的默认字段名和字段顺序，对于原子类型则使用 f0。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names &#34;_1&#34; and &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field &#34;_2&#34; only
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names &#34;myInt&#34; and &#34;myLong&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span> <span class="n">as</span> <span class="s">&#34;myInt&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span> <span class="n">as</span> <span class="s">&#34;myLong&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="原子类型">原子类型</h3>
<p>Flink 将原语（Integer、Double、String）或通用类型（不能分析和分解的类型）视为原子类型。原子类型的 DataStream 或 DataSet 会被转换为具有单一属性的 Table。属性的类型是从原子类型推断出来的，可以指定属性的名称。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field name &#34;f0&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field name &#34;myLong&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="tuplesscala-和-java和-case-类仅-scala">Tuples（Scala 和 Java）和 Case 类（仅 Scala）。</h3>
<p>Flink 支持 Scala 的内置元组，并为 Java 提供了自己的元组类。DataStreams 和 DataSets 这两种元组都可以转换为表。通过为所有字段提供名称（基于位置的映射），可以重命名字段。如果没有指定字段名，则使用默认的字段名。如果引用了原始的字段名（对于 Flink Tuples 来说是 f0, f1, &hellip;，对于 Scala Tuples 来说是 _1, _2, &hellip;），API 会假定映射是基于名称而不是基于位置的。基于名称的映射允许重新排序字段和用别名（as）进行投影。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with renamed default field names &#39;_1, &#39;_2
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#34;myLong&#34;, &#34;myString&#34; (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myString&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered fields &#34;_2&#34;, &#34;_1&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;_2&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields &#34;myString&#34;, &#34;myLong&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span> <span class="n">as</span> <span class="s">&#34;myString&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span> <span class="n">as</span> <span class="s">&#34;myLong&#34;</span><span class="o">)</span>

<span class="c1">// define case class
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">streamCC</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names &#39;name, &#39;age
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#39;myName, &#39;myAge (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields &#34;myAge&#34;, &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="pojojava-和-scala">POJO（Java 和 Scala）</h3>
<p>Flink 支持 POJO 作为复合类型。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#pojos">这里</a>记录了确定 POJO 的规则。</p>
<p>当将 POJO DataStream 或 DataSet 转换为 Table 而不指定字段名时，会使用原始 POJO 字段的名称。名称映射需要原始名称，不能通过位置来完成。字段可以使用别名（使用 as 关键字）重命名，重新排序，并进行投影。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// Person is a POJO with field names &#34;name&#34; and &#34;age&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names &#34;age&#34;, &#34;name&#34; (fields are ordered by name!)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields &#34;myAge&#34;, &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;name&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="row">Row</h3>
<p>Row 数据类型支持任意数量的字段和具有 null 值的字段。字段名可以通过 RowTypeInfo 来指定，也可以在将 Row DataStream 或 DataSet 转换为 Table 时指定。Row 类型支持通过位置和名称对字段进行映射。可以通过为所有字段提供名称（基于位置的映射）或单独选择字段进行投影/排序/重命名（基于名称的映射）来重命名字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// DataStream of Row with two fields &#34;name&#34; and &#34;age&#34; specified in `RowTypeInfo`
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names &#34;name&#34;, &#34;age&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed field names &#34;myName&#34;, &#34;myAge&#34; (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields &#34;myName&#34;, &#34;myAge&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;name&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="查询优化">查询优化</h2>
<ul>
<li>Blink 计划器</li>
</ul>
<p>Apache Flink 利用并扩展了 Apache Calcite 来执行复杂的查询优化。这包括一系列基于规则和成本的优化，如：</p>
<ul>
<li>基于 Apache Calcite 的子查询装饰相关。</li>
<li>投影修剪</li>
<li>分区修剪</li>
<li>过滤器下推</li>
<li>子计划重复复制，避免重复计算。</li>
<li>特殊子查询重写，包括两部分。
<ul>
<li>将 IN 和 EXISTS 转换为左半连接。</li>
<li>将 NOT IN 和 NOT EXISTS 转换为左反连接。</li>
</ul>
</li>
<li>可选的 join 重新排序
<ul>
<li>通过 <code>table.optimizer.join-reorder-enabled</code> 启用。</li>
</ul>
</li>
</ul>
<p>注：<code>IN/EXISTS/NOT IN/NOT EXISTS</code> 目前只支持子查询重写中的连词条件。</p>
<p>优化器做出智能决策，不仅基于计划，还基于数据源提供的丰富统计数据，以及每个操作符（如 io、cpu、网络和内存）的细粒度成本。</p>
<p>高级用户可以通过 CalciteConfig 对象提供自定义优化，该对象可以通过调用 <code>TableEnvironment#getConfig#setPlannerConfig</code> 提供给 table 环境。</p>
<h2 id="解释表">解释表</h2>
<p>Table API 提供了一种机制来解释计算 Table 的逻辑和优化查询计划。这是通过 <code>Table.explain()</code> 方法或 <code>StatementSet.explain()</code> 方法完成的。<code>Table.explain()</code> 返回一个 Table 的计划。<code>StatementSet.explain()</code> 返回多个接收器的计划。它返回一个描述三个计划的字符串。</p>
<ol>
<li>关系查询的抽象语法树，即未优化的逻辑查询计划。</li>
<li>优化的逻辑查询计划，以及</li>
<li>物理执行计划。</li>
</ol>
<p><code>TableEnvironment.explainSql()</code> 和 <code>TableEnvironment.executeSql()</code> 支持执行 EXPLAIN 语句来获取计划，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/explain.html">EXPLAIN</a> 页面。</p>
<p>下面的代码显示了一个使用 <code>Table.explain()</code> 方法给定 Table 的例子和相应的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;hello&#34;</span><span class="o">)).</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;hello&#34;</span><span class="o">)).</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">.</span><span class="n">like</span><span class="o">(</span><span class="s">&#34;F%&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">table</span><span class="o">.</span><span class="n">explain</span><span class="o">())</span>
</code></pre></div><p>上述例子的结果是:</p>
<pre><code>== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
    FlinkLogicalDataStreamScan(id=[1], fields=[count, word])
  FlinkLogicalDataStreamScan(id=[2], fields=[count, word])

== Optimized Logical Plan ==
DataStreamUnion(all=[true], union all=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')])
    DataStreamScan(id=[1], fields=[count, word])
  DataStreamScan(id=[2], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

Stage 2 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 3 : Operator
		content : from: (count, word)
		ship_strategy : REBALANCE

		Stage 4 : Operator
			content : where: (LIKE(word, _UTF-16LE'F%')), select: (count, word)
			ship_strategy : FORWARD

			Stage 5 : Operator
				content : from: (count, word)
				ship_strategy : REBALANCE
</code></pre><p>下面的代码显示了使用 <code>StatementSet.explain()</code> 方法进行多重接收器计划的一个例子和相应的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">.</span><span class="n">useBlinkPlanner</span><span class="o">.</span><span class="n">inStreamingMode</span><span class="o">.</span><span class="n">build</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">()</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">())</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/source/path1&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="n">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySource1&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/source/path2&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="n">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySource2&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/sink/path1&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="n">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySink1&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/sink/path2&#34;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">().</span><span class="n">deriveSchema</span><span class="o">())</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySink2&#34;</span><span class="o">)</span>
    
<span class="k">val</span> <span class="n">stmtSet</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">createStatementSet</span><span class="o">()</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MySource1&#34;</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">.</span><span class="n">like</span><span class="o">(</span><span class="s">&#34;F%&#34;</span><span class="o">))</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsert</span><span class="o">(</span><span class="s">&#34;MySink1&#34;</span><span class="o">,</span> <span class="n">table1</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">table1</span><span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MySource2&#34;</span><span class="o">))</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsert</span><span class="o">(</span><span class="s">&#34;MySink2&#34;</span><span class="o">,</span> <span class="n">table2</span><span class="o">)</span>

<span class="k">val</span> <span class="n">explanation</span> <span class="k">=</span> <span class="n">stmtSet</span><span class="o">.</span><span class="n">explain</span><span class="o">()</span>
<span class="n">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span>
</code></pre></div><p>多重接收器计划的结果是:</p>
<pre><code>== Abstract Syntax Tree ==
LogicalLegacySink(name=[MySink1], fields=[count, word])
+- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])

LogicalLegacySink(name=[MySink2], fields=[count, word])
+- LogicalUnion(all=[true])
   :- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   :  +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]])

== Optimized Logical Plan ==
Calc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')], reuse_id=[1])
+- TableSourceScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

LegacySink(name=[MySink1], fields=[count, word])
+- Reused(reference_id=[1])

LegacySink(name=[MySink2], fields=[count, word])
+- Union(all=[true], union=[count, word])
   :- Reused(reference_id=[1])
   +- TableSourceScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 2 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 3 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 4 : Operator
				content : Calc(where: (word LIKE _UTF-16LE'F%'), select: (count, word))
				ship_strategy : FORWARD

				Stage 5 : Operator
					content : SinkConversionToRow
					ship_strategy : FORWARD

					Stage 6 : Operator
						content : Map
						ship_strategy : FORWARD

Stage 8 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 9 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 10 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 12 : Operator
				content : SinkConversionToRow
				ship_strategy : FORWARD

				Stage 13 : Operator
					content : Map
					ship_strategy : FORWARD

					Stage 7 : Data Sink
						content : Sink: CsvTableSink(count, word)
						ship_strategy : FORWARD

						Stage 14 : Data Sink
							content : Sink: CsvTableSink(count, word)
							ship_strategy : FORWARD
</code></pre><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[模块]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-modules/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-modules/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Modules</blockquote><h1 id="模块测试版">模块测试版</h1>
<p>模块允许用户扩展 Flink 的内置对象，比如定义一些行为类似 Flink 内置函数的功能。它们是可插拔的，虽然 Flink 提供了一些预建模块，但用户可以编写自己的模块。</p>
<p>例如，用户可以定义自己的地理函数，并将其作为内置函数插入 Flink，以便在 Flink SQL 和 Table API 中使用。又比如，用户可以加载一个现成的 Hive 模块，将 Hive 内置函数作为 Flink 内置函数使用。</p>
<h2 id="模块类型">模块类型</h2>
<h3 id="coremodule">CoreModule</h3>
<p>CoreModule 包含了 Flink 的所有系统（内置）功能，并且默认被加载。</p>
<h3 id="hivemodule">HiveModule</h3>
<p>HiveModule 作为 Flink 的系统函数，向 SQL 和 Table API 用户提供 Hive 内置函数。Flink 的 Hive 文档提供了设置该模块的全部细节。</p>
<h3 id="用户定义模块">用户定义模块</h3>
<p>用户可以通过实现 Module 接口来开发自定义模块。为了在 SQL CLI 中使用自定义模块，用户应该通过实现 ModuleFactory 接口同时开发一个模块和它对应的模块工厂。</p>
<p>模块工厂定义了一组属性，用于在 SQL CLI 引导时配置模块。属性被传递给发现服务，服务会尝试将属性与模块工厂进行匹配，并实例化一个相应的模块实例。</p>
<h2 id="命名空间和解析顺序">命名空间和解析顺序</h2>
<p>模块提供的对象被认为是 Flink 系统（内置）对象的一部分；因此，它们没有任何命名空间。</p>
<p>当有两个同名的对象存在于两个模块中时，Flink 总是将对象引用解析为第一个加载模块中的对象。</p>
<h2 id="模块-api">模块 API</h2>
<h3 id="装载和卸载模块">装载和卸载模块</h3>
<p>用户可以在现有的 Flink 会话中加载和卸载模块。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">loadModule</span><span class="o">(</span><span class="s">&#34;myModule&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CustomModule</span><span class="o">());</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">unloadModule</span><span class="o">(</span><span class="s">&#34;myModule&#34;</span><span class="o">);</span>
</code></pre></div><ul>
<li>YAML</li>
</ul>
<p>所有使用 YAML 定义的模块都必须提供一个 <code>type</code> 属性来指定类型。以下类型是开箱即用的。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Catalog</th>
<th style="text-align:left">Type Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CoreModule</td>
<td style="text-align:left">core</td>
</tr>
<tr>
<td style="text-align:left">HiveModule</td>
<td style="text-align:left">hive</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">modules</span><span class="p">:</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">core</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">core</span><span class="w">
</span><span class="w">   </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">myhive</span><span class="w">
</span><span class="w">     </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">hive</span><span class="w">
</span></code></pre></div><h3 id="列出可用的模块">列出可用的模块</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listModules</span><span class="o">();</span>
</code></pre></div><ul>
<li>SQL</li>
</ul>
<pre><code>Flink SQL&gt; SHOW MODULES;
</code></pre><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/modules.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/modules.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/module" term="module" label="Module" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[流的概念]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Streaming Concepts</blockquote><h2 id="流的概念">流的概念</h2>
<p>Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a>和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL 支持</a>是批处理和流处理的统一 API。这意味着Table API 和 SQL 查询具有相同的语义，无论其输入是有界批处理输入还是无界流输入。由于关系代数和 SQL 最初是为批处理设计的，所以对无界流输入的关系查询不如对有界批输入的关系查询好理解。</p>
<p>下面几页解释了 Flink 的关系 API 在流数据上的概念、实际限制和特定流的配置参数。</p>
<h2 id="下一步该往哪里走">下一步该往哪里走？</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>。描述动态表的概念。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。解释时间属性，以及在表API和SQL中如何处理时间属性。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询中的连接</a>。连续查询中支持的不同类型的连接。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>。描述临时表的概念。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>。列出 Table API 和 SQL 特定配置选项。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[测试]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-testing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-testing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Testing</blockquote><h1 id="测试">测试</h1>
<p>测试是每个软件开发过程中不可缺少的一部分，因此 Apache Flink 提供的工具可以在测试金字塔的多个层次上测试你的应用程序代码。</p>
<h2 id="测试用户自定义函数">测试用户自定义函数</h2>
<p>通常，我们可以假设 Flink 在用户定义的函数之外产生正确的结果。因此，建议尽可能用单元测试来测试那些包含主要业务逻辑的类。</p>
<h3 id="单元测试无状态timeless-udfs">单元测试无状态、Timeless UDFs。</h3>
<p>例如，我们来看看下面的无状态 MapFunction。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">IncrementMapFunction</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">record</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>通过传递合适的参数和验证输出，用你最喜欢的测试框架对这样的函数进行单元测试是非常容易的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">IncrementMapFunctionTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">Matchers</span> <span class="o">{</span>

    <span class="s">&#34;IncrementMapFunction&#34;</span> <span class="n">should</span> <span class="s">&#34;increment values&#34;</span> <span class="n">in</span> <span class="o">{</span>
        <span class="c1">// instantiate your function
</span><span class="c1"></span>        <span class="k">val</span> <span class="n">incrementer</span><span class="k">:</span> <span class="kt">IncrementMapFunction</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">IncrementMapFunction</span><span class="o">()</span>

        <span class="c1">// call the methods that you have implemented
</span><span class="c1"></span>        <span class="n">incremeter</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="n">should</span> <span class="n">be</span> <span class="o">(</span><span class="mi">3</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>同样，使用 org.apache.flink.util.Collector 的用户定义函数（例如 FlatMapFunction 或 ProcessFunction）可以通过提供一个模拟对象而不是真实的 Collector 来轻松测试。一个与 IncrementMapFunction 功能相同的 FlatMapFunction 可以进行如下单元测试。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">IncrementFlatMapFunctionTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">MockFactory</span> <span class="o">{</span>

    <span class="s">&#34;IncrementFlatMapFunction&#34;</span> <span class="n">should</span> <span class="s">&#34;increment values&#34;</span> <span class="n">in</span> <span class="o">{</span>
       <span class="c1">// instantiate your function
</span><span class="c1"></span>      <span class="k">val</span> <span class="n">incrementer</span> <span class="k">:</span> <span class="kt">IncrementFlatMapFunction</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">IncrementFlatMapFunction</span><span class="o">()</span>

      <span class="k">val</span> <span class="n">collector</span> <span class="k">=</span> <span class="n">mock</span><span class="o">[</span><span class="kt">Collector</span><span class="o">[</span><span class="kt">Integer</span><span class="o">]]</span>

      <span class="c1">//verify collector was called with the right output
</span><span class="c1"></span>      <span class="o">(</span><span class="n">collector</span><span class="o">.</span><span class="n">collect</span> <span class="k">_</span><span class="o">).</span><span class="n">expects</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

      <span class="c1">// call the methods that you have implemented
</span><span class="c1"></span>      <span class="n">flattenFunction</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">collector</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="单元测试-有状态或及时的-udf-和自定义操作符">单元测试 有状态或及时的 UDF 和自定义操作符</h3>
<p>测试一个用户定义函数的功能是比较困难的，因为它涉及到测试用户代码和 Flink 运行时之间的交互。为此，Flink 提供了一个所谓的测试线束的集合，它可以用来测试这样的用户定义函数以及自定义操作符。</p>
<ul>
<li>OneInputStreamOperatorTestHarness(用于 DataStreams 上的操作符)</li>
<li>KeyedOneInputStreamOperatorTestHarness(用于 KeyedStreams 上的操作者)</li>
<li>TwoInputStreamOperatorTestHarness (适用于两个 DataStreams 的 ConnectedStreams 操作者)</li>
<li>KeyedTwoInputStreamOperatorTestHarness (用于两个 KeyedStream 的 ConnectedStreams 上的操作员)</li>
</ul>
<p>为了使用测试套件，需要一组额外的依赖关系（测试范围）。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-test-utils_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>test<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-runtime_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>test<span class="nt">&lt;/scope&gt;</span>
  <span class="nt">&lt;classifier&gt;</span>tests<span class="nt">&lt;/classifier&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>test<span class="nt">&lt;/scope&gt;</span>
  <span class="nt">&lt;classifier&gt;</span>tests<span class="nt">&lt;/classifier&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>现在，测试线束可以用来将记录和水印推送到你的用户定义函数或自定义运算符中，控制处理时间，最后对运算符的输出进行断言（包括侧输出）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">StatefulFlatMapFunctionTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">Matchers</span> <span class="k">with</span> <span class="nc">BeforeAndAfter</span> <span class="o">{</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">testHarness</span><span class="k">:</span> <span class="kt">OneInputStreamOperatorTestHarness</span><span class="o">[</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span>
  <span class="k">private</span> <span class="k">var</span> <span class="n">statefulFlatMap</span><span class="k">:</span> <span class="kt">StatefulFlatMapFunction</span> <span class="o">=</span> <span class="kc">null</span>

  <span class="n">before</span> <span class="o">{</span>
    <span class="c1">//instantiate user-defined function
</span><span class="c1"></span>    <span class="n">statefulFlatMap</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StatefulFlatMap</span>

    <span class="c1">// wrap user defined function into a the corresponding operator
</span><span class="c1"></span>    <span class="n">testHarness</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OneInputStreamOperatorTestHarness</span><span class="o">[</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">](</span><span class="k">new</span> <span class="nc">StreamFlatMap</span><span class="o">(</span><span class="n">statefulFlatMap</span><span class="o">))</span>

    <span class="c1">// optionally configured the execution environment
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">getExecutionConfig</span><span class="o">().</span><span class="n">setAutoWatermarkInterval</span><span class="o">(</span><span class="mi">50</span><span class="o">);</span>

    <span class="c1">// open the test harness (will also call open() on RichFunctions)
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">open</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="s">&#34;StatefulFlatMap&#34;</span> <span class="n">should</span> <span class="s">&#34;do some fancy stuff with timers and state&#34;</span> <span class="n">in</span> <span class="o">{</span>


    <span class="c1">//push (timestamped) elements into the operator (and hence user defined function)
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">processElement</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">100</span><span class="o">);</span>

    <span class="c1">//trigger event time timers by advancing the event time of the operator with a watermark
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">processWatermark</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>

    <span class="c1">//trigger proccesign time timers by advancing the processing time of the operator directly
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">setProcessingTime</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>

    <span class="c1">//retrieve list of emitted records for assertions
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">getOutput</span> <span class="n">should</span> <span class="n">contain</span> <span class="o">(</span><span class="mi">3</span><span class="o">)</span>

    <span class="c1">//retrieve list of records emitted to a specific side output for assertions (ProcessFunction only)
</span><span class="c1"></span>    <span class="c1">//testHarness.getSideOutput(new OutputTag[Int](&#34;invalidRecords&#34;)) should have size 0
</span><span class="c1"></span>  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>KeyedOneInputStreamOperatorTestHarness 和 KeyedTwoInputStreamOperatorTestHarness 是通过额外提供一个包括键类的 TypeInformation 的 KeySelector 来实例化的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">StatefulFlatMapTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">Matchers</span> <span class="k">with</span> <span class="nc">BeforeAndAfter</span> <span class="o">{</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">testHarness</span><span class="k">:</span> <span class="kt">OneInputStreamOperatorTestHarness</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Long</span>, <span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span>
  <span class="k">private</span> <span class="k">var</span> <span class="n">statefulFlatMapFunction</span><span class="k">:</span> <span class="kt">FlattenFunction</span> <span class="o">=</span> <span class="kc">null</span>

  <span class="n">before</span> <span class="o">{</span>
    <span class="c1">//instantiate user-defined function
</span><span class="c1"></span>    <span class="n">statefulFlatMapFunction</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StateFulFlatMap</span>

    <span class="c1">// wrap user defined function into a the corresponding operator
</span><span class="c1"></span>    <span class="n">testHarness</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KeyedOneInputStreamOperatorTestHarness</span><span class="o">(</span><span class="k">new</span> <span class="nc">StreamFlatMap</span><span class="o">(</span><span class="n">statefulFlatMapFunction</span><span class="o">),</span><span class="k">new</span> <span class="nc">MyStringKeySelector</span><span class="o">(),</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">())</span>

    <span class="c1">// open the test harness (will also call open() on RichFunctions)
</span><span class="c1"></span>    <span class="n">testHarness</span><span class="o">.</span><span class="n">open</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="c1">//tests
</span><span class="c1"></span>
<span class="o">}</span>
</code></pre></div><p>在 Flink 代码库中还可以找到更多使用这些测试线束的例子，例如。</p>
<ul>
<li>org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest 是一个很好的例子，用于测试依赖于处理或事件时间的操作员和用户定义的函数。</li>
<li>org.apache.flink.streaming.api.function.sink.filesystem.LocalStreamingFileSinkTest 展示了如何使用 AbstractStreamOperatorTestHarness 测试自定义的 sink。具体来说，它使用 AbstractStreamOperatorTestHarness.snapshot 和 AbstractStreamOperatorTestHarness.initializeState 来测试它与 Flink 的检查点机制的交互。</li>
</ul>
<p>注意: AbstractStreamOperatorTestHarness 和它的派生类目前不是公共 API 的一部分，可能会发生变化。</p>
<h3 id="单元测试-processfunction">单元测试 ProcessFunction</h3>
<p>鉴于其重要性，除了之前的测试线束可以直接用于测试 ProcessFunction 外，Flink 还提供了一个名为 ProcessFunctionTestHarnesses 的测试线束工厂，可以更方便地进行测试线束实例化。考虑到这个例子。</p>
<p>注意: 要使用这个测试线束，你还需要引入上一节中提到的依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">PassThroughProcessFunction</span> <span class="k">extends</span> <span class="nc">ProcessFunction</span><span class="o">[</span><span class="kt">Integer</span>, <span class="kt">Integer</span><span class="o">]</span> <span class="o">{</span>

    <span class="nd">@throws</span><span class="o">[</span><span class="kt">Exception</span><span class="o">]</span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">processElement</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">ctx</span><span class="k">:</span> <span class="kt">ProcessFunction</span><span class="o">[</span><span class="kt">Integer</span>, <span class="kt">Integer</span><span class="o">]</span><span class="k">#</span><span class="nc">Context</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">Integer</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">value</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>使用 ProcessFunctionTestHarnesses 对这样的函数进行单元测试是非常容易的，通过传递合适的参数并验证输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">PassThroughProcessFunctionTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">Matchers</span> <span class="o">{</span>

  <span class="s">&#34;PassThroughProcessFunction&#34;</span> <span class="n">should</span> <span class="s">&#34;forward values&#34;</span> <span class="n">in</span> <span class="o">{</span>

    <span class="c1">//instantiate user-defined function
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">processFunction</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PassThroughProcessFunction</span>

    <span class="c1">// wrap user defined function into a the corresponding operator
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">harness</span> <span class="k">=</span> <span class="nc">ProcessFunctionTestHarnesses</span><span class="o">.</span><span class="n">forProcessFunction</span><span class="o">(</span><span class="n">processFunction</span><span class="o">)</span>

    <span class="c1">//push (timestamped) elements into the operator (and hence user defined function)
</span><span class="c1"></span>    <span class="n">harness</span><span class="o">.</span><span class="n">processElement</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">10</span><span class="o">)</span>

    <span class="c1">//retrieve list of emitted records for assertions
</span><span class="c1"></span>    <span class="n">harness</span><span class="o">.</span><span class="n">extractOutputValues</span><span class="o">()</span> <span class="n">should</span> <span class="n">contain</span> <span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>关于如何使用 ProcessFunctionTestHarnesses 来测试 ProcessFunction 的不同风味，如 KeyedProcessFunction、KeyedCoProcessFunction、BroadcastProcessFunction 等的更多例子，鼓励用户查看 ProcessFunctionTestHarnessesTest。</p>
<h2 id="测试-flink-作业">测试 Flink 作业</h2>
<h3 id="junit-规则-miniclusterwithclientresource">JUnit 规则 MiniClusterWithClientResource</h3>
<p>Apache Flink 提供了一个名为 MiniClusterWithClientResource 的 JUnit 规则，用于针对本地的、嵌入式的迷你集群测试完整的作业，名为 MiniClusterWithClientResource。</p>
<p>要使用 MiniClusterWithClientResource，需要一个额外的依赖（测试范围）。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-test-utils_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>让我们以前面几节中同样简单的 MapFunction 为例。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">IncrementMapFunction</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">record</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>现在可以在本地 Flink 集群中测试使用该 MapFunction 的简单管道，具体如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">StreamingJobIntegrationTest</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">Matchers</span> <span class="k">with</span> <span class="nc">BeforeAndAfter</span> <span class="o">{</span>

  <span class="k">val</span> <span class="n">flinkCluster</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MiniClusterWithClientResource</span><span class="o">(</span><span class="k">new</span> <span class="nc">MiniClusterResourceConfiguration</span><span class="o">.</span><span class="nc">Builder</span><span class="o">()</span>
    <span class="o">.</span><span class="n">setNumberSlotsPerTaskManager</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="n">setNumberTaskManagers</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="n">build</span><span class="o">)</span>

  <span class="n">before</span> <span class="o">{</span>
    <span class="n">flinkCluster</span><span class="o">.</span><span class="n">before</span><span class="o">()</span>
  <span class="o">}</span>

  <span class="n">after</span> <span class="o">{</span>
    <span class="n">flinkCluster</span><span class="o">.</span><span class="n">after</span><span class="o">()</span>
  <span class="o">}</span>


  <span class="s">&#34;IncrementFlatMapFunction pipeline&#34;</span> <span class="n">should</span> <span class="s">&#34;incrementValues&#34;</span> <span class="n">in</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

    <span class="c1">// configure your test environment
</span><span class="c1"></span>    <span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>

    <span class="c1">// values are collected in a static variable
</span><span class="c1"></span>    <span class="nc">CollectSink</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>

    <span class="c1">// create a stream of custom elements and apply transformations
</span><span class="c1"></span>    <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">21</span><span class="o">,</span> <span class="mi">22</span><span class="o">)</span>
       <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">IncrementMapFunction</span><span class="o">())</span>
       <span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="k">new</span> <span class="nc">CollectSink</span><span class="o">())</span>

    <span class="c1">// execute
</span><span class="c1"></span>    <span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>

    <span class="c1">// verify your results
</span><span class="c1"></span>    <span class="nc">CollectSink</span><span class="o">.</span><span class="n">values</span> <span class="n">should</span> <span class="n">contain</span> <span class="n">allOf</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">23</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// create a testing sink
</span><span class="c1"></span><span class="k">class</span> <span class="nc">CollectSink</span> <span class="k">extends</span> <span class="nc">SinkFunction</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">invoke</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">synchronized</span> <span class="o">{</span>
      <span class="nc">CollectSink</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">value</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">object</span> <span class="nc">CollectSink</span> <span class="o">{</span>
    <span class="c1">// must be static
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">values</span><span class="k">:</span> <span class="kt">util.List</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="n">util</span><span class="o">.</span><span class="nc">ArrayList</span><span class="o">()</span>
<span class="o">}</span>
</code></pre></div><p>关于 MiniClusterWithClientResource 的集成测试的几点说明。</p>
<ul>
<li>
<p>为了不把你的整个流水线代码从生产中复制到测试中，请在你的生产代码中使源和汇可插拔，并在你的测试中注入特殊的测试源和测试汇。</p>
</li>
<li>
<p>这里使用了 CollectSink 中的静态变量，因为 Flink 在将所有操作符分布在集群中之前，会将它们序列化。通过静态变量与本地 Flink 迷你集群实例化的运算符进行通信是解决这个问题的一种方法。另外，你可以将数据写到与你的测试汇的临时目录中的文件中。</p>
</li>
<li>
<p>如果你的作业使用事件时间计时器，你可以实现一个自定义的并行源函数来发射水印。</p>
</li>
<li>
<p>建议始终以并行度 <code>&gt;1</code> 的方式在本地测试你的流水线，以识别只有并行执行的流水线才会出现的错误。</p>
</li>
<li>
<p>优先选择 <code>@ClassRule</code> 而不是 <code>@Rule</code>，这样多个测试可以共享同一个 Flink 集群。这样做可以节省大量的时间，因为 Flink 集群的启动和关闭通常会支配实际测试的执行时间。</p>
</li>
<li>
<p>如果你的管道包含自定义状态处理，你可以通过启用检查点并在迷你集群内重新启动作业来测试其正确性。为此，你需要通过从你的管道中的（仅测试的）用户定义函数中抛出一个异常来触发失败。</p>
</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/testing" term="testing" label="testing" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[状态后端]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-backends/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-state-backends/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>State Backends</blockquote><h2 id="状态后端">状态后端</h2>
<p>Flink 提供了不同的状态后端，指定状态的存储方式和位置。</p>
<p>状态可以位于 Java 的堆上或离堆(off-heap)。根据你的状态后端，Flink 还可以为应用程序管理状态，这意味着 Flink 处理内存管理（必要时可能会溢出到磁盘），以允许应用程序持有非常大的状态。默认情况下，配置文件 <em>flink-conf.yaml</em> 决定了所有 Flink 作业(job)的状态后端。</p>
<p>然而，默认的状态后端可以在每个作业(per-job)的基础上被重写，如下所示。</p>
<p>有关可用的状态后端、其优势、限制和配置参数的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">部署与操作</a>中的相应章节。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">setStateBackend</span><span class="o">(...)</span>
</code></pre></div><p>状态后端: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state_backends.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state_backends.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[状态模式的演变]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-state-schema-evolution/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-state-schema-evolution/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>State Schema Evolution</blockquote><p>Apache Flink 流媒体应用通常被设计为无限期或长时间运行。与所有长期运行的服务一样，应用程序需要更新以适应不断变化的需求。这对于应用程序所针对的数据模式(data schema)也是一样的，它们会随着应用程序的发展而发展。</p>
<p>本页提供了关于如何演进状态类型的数据模式(data schema)的概述。当前的限制在不同的类型和状态结构（<code>ValueState</code>、<code>ListState</code> 等）中有所不同。</p>
<p>请注意，本页面上的信息仅在您使用由 Flink 自己的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html">类型序列化框架</a>生成的状态序列化器时相关。也就是说，在声明你的状态时，所提供的状态描述符并没有被配置为使用特定的 <code>TypeSerializer</code> 或 <code>TypeInformation</code>，在这种情况下，Flink 会推导出状态类型的信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ListStateDescriptor</span><span class="o">&lt;</span><span class="n">MyPojoType</span><span class="o">&gt;</span> <span class="n">descriptor</span> <span class="o">=</span>
    <span class="k">new</span> <span class="n">ListStateDescriptor</span><span class="o">&lt;&gt;(</span>
        <span class="s">&#34;state-name&#34;</span><span class="o">,</span>
        <span class="n">MyPojoType</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="n">checkpointedState</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getListState</span><span class="o">(</span><span class="n">descriptor</span><span class="o">);</span>
</code></pre></div><p>在底层，状态的模式(schema)是否可以被演化取决于用于读取/写入持久化状态字节的序列化器。简单地说，只有当它的序列化器正确地支持时，一个注册状态的模式才能被演化。这是由 Flink 的类型序列化框架生成的序列化器透明地处理的（当前的支持范围列在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html#supported-data-types-for-schema-evolution">下面</a>）。</p>
<p>如果你打算为你的状态类型实现一个自定义的 <code>TypeSerializer</code>，并想了解如何实现序列化器以支持状态模式演化，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/custom_serialization.html">自定义状态序列化</a>。那里的文档还涵盖了关于状态序列化器和 Flink 的状态后端之间的相互作用的必要内部细节，以支持状态模式(state schema)演化。</p>
<h2 id="状态模式的演化">状态模式的演化</h2>
<p>要演化给定状态类型的模式，您需要采取以下步骤。</p>
<ol>
<li>保存你的 Flink 流作业(job)的保存点。</li>
<li>更新您的应用程序中的状态类型（例如，修改您的 Avro 类型模式）。</li>
<li>从保存点恢复作业(job)。当第一次访问状态时，Flink 将评估是否已经改变了状态的模式(schema)，并在必要时迁移状态模式。</li>
</ol>
<p>迁移状态以适应已更改的模式的过程是自动发生的，并且对每个状态都是独立的。这个过程由 Flink 内部执行，首先检查状态的新序列器是否与之前的序列器有不同的序列化模式，如果有，则用之前的序列器将状态读到对象，再用新的序列器写回字节。</p>
<p>关于迁移过程的进一步细节不在本文档的范围内，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/custom_serialization.html">这里</a>。</p>
<h2 id="支持的模式演化数据类型">支持的模式演化数据类型</h2>
<p>目前，模式演化只支持 POJO 和 Avro 类型。因此，如果你关心状态的模式演化，目前建议始终使用 POJO 或 Avro 作为状态数据类型。</p>
<p>有计划扩展对更多复合类型的支持；更多细节请参考 <a href="https://issues.apache.org/jira/browse/FLINK-10896">FLINK-10896</a>。</p>
<h3 id="pojo-类型">POJO 类型</h3>
<p>Flink 支持 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#rules-for-pojo-types">POJO 类型</a>的演化模式，基于以下一组规则。</p>
<ol>
<li>字段可以被删除。一旦被删除，在未来的检查点和保存点中，被删除字段的之前值将被丢弃。</li>
<li>可以添加新字段。新字段将被初始化为其类型的默认值，正如 <a href="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">Java 所定义的</a>那样。</li>
<li>已声明的字段类型不能改变。</li>
<li>POJO 类型的类名不能改变，包括类的命名空间。</li>
</ol>
<p>请注意，POJO 类型状态的模式只能在 Flink 版本大于 1.8.0 的情况下，从以前的保存点恢复时才能进化。当使用比 1.8.0 更老的 Flink 版本进行还原时，模式不能被改变。</p>
<h3 id="avro-类型">Avro 类型</h3>
<p>Flink 完全支持 Avro 类型状态的演变模式，只要模式变化被 <a href="http://avro.apache.org/docs/current/spec.html#Schema+Resolution">Avro 的模式解析规则</a>认为是兼容的。</p>
<p>一个限制是作为状态类型使用的 Avro 生成的类在恢复作业时不能被重新定位或具有不同的命名空间。</p>
<p>注意: 不支持键的模式演变。</p>
<p>举个例子。RocksDB 状态后端依赖于二进制对象的标识，而不是 hashCode 方法实现。对 keys 对象结构的任何改变都可能导致非确定性行为。</p>
<p>注意: Kryo 不能用于模式演化。</p>
<p>当使用 Kryo 时，框架没有可能验证是否有任何不兼容的变化。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[用于外部数据访问的异步 I/O]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-asynchronous-io-for-external-data-access/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-windows/?utm_source=atom_feed" rel="related" type="text/html" title="窗口" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-asynchronous-io-for-external-data-access/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Asynchronous Io for External Data Access</blockquote><p>本页解释了如何使用 Flink 的 API 与外部数据存储进行异步 I/O。对于不熟悉异步或事件驱动编程的用户来说，一篇关于 Futures 和事件驱动编程的文章可能是有用的准备。</p>
<p>注：关于异步 I/O 实用程序的设计和实现的细节可以在提案和设计文件 <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65870673">FLIP-12：异步I/O设计和实现中找到</a>。</p>
<h2 id="异步io操作的必要性">异步I/O操作的必要性</h2>
<p>在与外部系统交互时（例如用存储在数据库中的数据来丰富流事件时），需要注意与外部系统的通信延迟不会主导流应用的总工作。</p>
<p>奈何访问外部数据库中的数据，例如在 <code>MapFunction</code> 中，通常意味着同步交互。一个请求被发送到数据库，<code>MapFunction</code> 等待直到收到响应。在许多情况下，这种等待占据了函数的绝大部分时间。</p>
<p>与数据库的异步交互意味着一个并行函数实例可以同时处理许多请求，并同时接收响应。这样一来，等待时间就可以与发送其他请求和接收响应叠加起来。最起码，等待时间可以摊在多个请求上。这在大多数情况下会导致更高的流吞吐量。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/async_io.svg" alt="img"></p>
<p>注意：通过仅仅将 <code>MapFunction</code> 扩展到很高的并行度来提高吞吐量，在某些情况下也是可行的，但通常要付出很高的资源代价：拥有更多的并行 <code>MapFunction</code> 实例意味着更多的任务、线程、Flink 内部网络连接、与数据库的网络连接、缓冲区以及一般的内部记账开销。</p>
<h2 id="前提条件">前提条件</h2>
<p>如上节所述，要实现对数据库（或键/值存储）的适当异步 I/O，需要向该数据库提供一个支持异步请求的客户端。许多流行的数据库都提供了这样的客户端。</p>
<p>在没有这样的客户端的情况下，可以尝试通过创建多个客户端，并用线程池处理同步调用，将同步客户端变成有限的并发客户端。然而，这种方法通常比一个合适的异步客户端效率低。</p>
<h2 id="异步-io-api">异步 I/O API</h2>
<p>Flink 的 Async I/O API 允许用户使用异步请求客户端与数据流。该 API 处理与数据流的集成，以及处理顺序、事件时间、容错等。</p>
<p>假设自己有一个目标数据库的异步客户端，需要三个部分来实现对数据库的异步 I/O 的流转换。</p>
<ul>
<li>一个 AsyncFunction 的实现，用来调度请求。</li>
<li>一个回调，获取操作结果并将其交给 <code>ResultFuture</code>。</li>
<li>在 DataStream 上应用异步 I/O 操作作为转换。</li>
</ul>
<p>下面的代码示例说明了基本模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/**
</span><span class="cm"> * An implementation of the &#39;AsyncFunction&#39; that sends requests and sets the callback.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">AsyncDatabaseRequest</span> <span class="k">extends</span> <span class="nc">AsyncFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="o">{</span>

    <span class="cm">/** The database specific client that can issue concurrent requests with callbacks */</span>
    <span class="k">lazy</span> <span class="k">val</span> <span class="n">client</span><span class="k">:</span> <span class="kt">DatabaseClient</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">DatabaseClient</span><span class="o">(</span><span class="n">host</span><span class="o">,</span> <span class="n">post</span><span class="o">,</span> <span class="n">credentials</span><span class="o">)</span>

    <span class="cm">/** The context used for the future callbacks */</span>
    <span class="k">implicit</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">executor</span><span class="k">:</span> <span class="kt">ExecutionContext</span> <span class="o">=</span> <span class="nc">ExecutionContext</span><span class="o">.</span><span class="n">fromExecutor</span><span class="o">(</span><span class="nc">Executors</span><span class="o">.</span><span class="n">directExecutor</span><span class="o">())</span>


    <span class="k">override</span> <span class="k">def</span> <span class="n">asyncInvoke</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">resultFuture</span><span class="k">:</span> <span class="kt">ResultFuture</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

        <span class="c1">// issue the asynchronous request, receive a future for the result
</span><span class="c1"></span>        <span class="k">val</span> <span class="n">resultFutureRequested</span><span class="k">:</span> <span class="kt">Future</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">client</span><span class="o">.</span><span class="n">query</span><span class="o">(</span><span class="n">str</span><span class="o">)</span>

        <span class="c1">// set the callback to be executed once the request by the client is complete
</span><span class="c1"></span>        <span class="c1">// the callback simply forwards the result to the result future
</span><span class="c1"></span>        <span class="n">resultFutureRequested</span><span class="o">.</span><span class="n">onSuccess</span> <span class="o">{</span>
            <span class="k">case</span> <span class="n">result</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span> <span class="n">resultFuture</span><span class="o">.</span><span class="n">complete</span><span class="o">(</span><span class="nc">Iterable</span><span class="o">((</span><span class="n">str</span><span class="o">,</span> <span class="n">result</span><span class="o">)))</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// create the original stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// apply the async I/O transformation
</span><span class="c1"></span><span class="k">val</span> <span class="n">resultStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span>
    <span class="nc">AsyncDataStream</span><span class="o">.</span><span class="n">unorderedWait</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="k">new</span> <span class="nc">AsyncDatabaseRequest</span><span class="o">(),</span> <span class="mi">1000</span><span class="o">,</span> <span class="nc">TimeUnit</span><span class="o">.</span><span class="nc">MILLISECONDS</span><span class="o">,</span> <span class="mi">100</span><span class="o">)</span>
</code></pre></div><p>重要提示：<code>ResultFuture.complete</code> 的第一次调用就完成了。所有后续的完成调用将被忽略。</p>
<p>以下两个参数控制异步操作。</p>
<ul>
<li>
<p>超时: 超时定义了异步请求在被认为失败之前可能需要的时间。这个参数可以防范死机/失败的请求。</p>
</li>
<li>
<p>Capacity（容量）：该参数定义了异步请求在被认为失败之前可能需要的时间。这个参数定义了多少个异步请求可以同时进行。尽管异步I/O方法通常会带来更好的吞吐量，但操作者仍然可以成为流应用的瓶颈。限制并发请求的数量可以确保操作者不会积累越来越多的待处理请求的积压，但一旦容量耗尽，就会触发背压。</p>
</li>
</ul>
<h3 id="超时处理">超时处理</h3>
<p>当一个异步 I/O 请求超时时，默认情况下会抛出一个异常并重新启动作业。如果你想处理超时，你可以重写 <code>AsyncFunction#timeout</code> 方法。</p>
<h3 id="结果的顺序">结果的顺序</h3>
<p><code>AsyncFunction</code> 发出的并发请求经常以某种未定义的顺序完成，基于哪个请求先完成。为了控制结果记录以何种顺序发出，Flink 提供了两种模式。</p>
<ul>
<li>
<p>Unordered: 异步请求一结束，结果记录就会被发出。在异步 I/O 操作符之后，流中记录的顺序与之前不同。这种模式以处理时间为基本时间特性时，延迟最低，开销最小。使用 <code>AsyncDataStream.unorderedWait(...)</code> 来实现这种模式。</p>
</li>
<li>
<p>Ordered: 在这种情况下，流的顺序被保留下来。结果记录的发出顺序与异步请求被触发的顺序相同（运算符输入记录的顺序）。为了达到这个目的，操作符会缓冲一个结果记录，直到它前面的所有记录都被发出来（或定时发出来）。这通常会在检查点中引入一些额外的延迟和一些开销，因为与无序模式相比，记录或结果在检查点状态下维持的时间更长。使用 <code>AsyncDataStream.orderedWait(...)</code> 来处理这种模式。</p>
</li>
</ul>
<h2 id="事件时间">事件时间</h2>
<p>当流媒体应用程序使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间</a>工作时，水印将由异步 I/O 操作符正确处理。具体来说，这意味着两种顺序模式的以下内容。</p>
<ul>
<li>无序的：水印不会超越记录，反之亦然，这意味着水印会建立一个顺序边界。只有在水印之间才会发出无序的记录。发生在某一水印之后的记录，只有在该水印被发射之后才会被发射。而水印则只有在该水印之前的所有输入的结果记录被发出之后才会被发出。</li>
</ul>
<p>这意味着在有水印的情况下，无序模式会引入一些与有序模式相同的延迟和管理开销。该开销的数量取决于水印的频率。</p>
<ul>
<li>有序的: 水印和记录的顺序被保留下来 就像记录之间的顺序被保留一样 与处理时间相比，开销没有明显变化。</li>
</ul>
<p>请记住，摄取时间是事件时间的一种特殊情况，其自动生成的水印是基于源处理时间的。</p>
<h2 id="容错保证">容错保证</h2>
<p>异步 I/O 操作符提供了完全精确的一次容错保证，它将飞行中的异步请求记录存储在检查点中，并在故障恢复时恢复/重新触发请求。它将飞行中的异步请求记录存储在检查点中，并在从故障中恢复时恢复/重新触发请求。</p>
<h2 id="实现技巧">实现技巧</h2>
<p>对于有 Executor（或 Scala 中的 ExecutionContext）用于回调的 Futures 实现，我们建议使用  DirectExecutor，因为回调通常只做最少的工作，而且DirectExecutor 避免了额外的线程间交接开销。回调通常只将结果交给 <code>ResultFuture</code>，后者将其添加到输出缓冲区。从那里开始，包括记录排放和与检查点记账的交互在内的繁重逻辑无论如何都发生在一个专用线程池中。</p>
<p>可以通过 <code>org.apache.flink.runtime.concurrent.Executors.directExecutor()</code> 或 <code>com.google.common.util.concurrent.MoreExecutors.directExecutor()</code> 获得 DirectExecutor。</p>
<h2 id="注意事项">注意事项</h2>
<p>AsyncFunction 不叫多线程。</p>
<p>我们在这里要明确指出的一个常见的困惑是，AsyncFunction 不是以多线程的方式调用的。AsyncFunction 只存在一个实例，并且对于流的各个分区中的每一条记录，它都会被依次调用。除非 <code>asyncInvoke(...)</code> 方法快速返回并依赖于回调（由客户端），否则不会导致正确的异步 I/O。</p>
<p>例如，以下模式会导致阻塞 <code>asyncInvoke(...)</code> 函数，从而使异步行为无效。</p>
<ul>
<li>
<p>使用一个数据库客户端，其查找/查询方法的调用会被阻塞，直到结果被接收回来为止</p>
</li>
<li>
<p>在 <code>asyncInvoke(...)</code> 方法中阻止/等待异步客户端返回的未来型对象。</p>
</li>
</ul>
<p>出于一致性的考虑，AsyncFunction 的操作符（AsyncWaitOperator）目前必须位于操作符链的头部。</p>
<p>由于在 FLINK-13063 问题中给出的原因，我们目前必须打破 AsyncWaitOperator 的操作符链，以防止潜在的一致性问题。这是对以前支持链的行为的改变。需要旧行为并接受潜在的违反一致性保证的用户可以手动实例化并将 AsyncWaitOperator 添加到作业图中，并通过 AsyncWaitOperator#setChainingStrategy(ChainingStrategy.ALWAYS) 将链式策略设置回链式。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/asyncio.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/asyncio.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/operators" term="operators" label="Operators" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/io" term="io" label="IO" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[用户定义函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-functions/?utm_source=atom_feed" rel="related" type="text/html" title="函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>User Defined Functions</blockquote><h1 id="用户自定义函数">用户自定义函数</h1>
<p>用户自定义函数(UDFs)是扩展点，用于调用常用的逻辑或自定义逻辑，这些逻辑无法在查询中以其他方式表达。</p>
<p>用户定义函数可以用 JVM 语言（如 Java 或 Scala）或 Python 实现。实现者可以在 UDF 中使用任意的第三方库。本页将重点介绍基于 JVM 的语言。</p>
<h2 id="概述">概述</h2>
<p>目前，Flink 区分了以下几种函数。</p>
<ul>
<li>标量函数将标量值映射到一个新的标量值。</li>
<li>表函数将标量值映射到新的行(row)。</li>
<li>聚合函数将多行的标量值映射到新的标量值。</li>
<li>表聚合函数将多行的标量值映射到新的行上。</li>
<li>异步表函数是针对 table source 执行查找的特殊函数。</li>
</ul>
<p>注意: 标量函数和表函数已经更新为基于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的新类型系统。聚合函数仍然使用基于 TypeInformation 的旧类型系统。</p>
<p>下面的示例展示了如何创建一个简单的标量函数，以及如何在表 API 和 SQL 中调用该函数。</p>
<p>对于 SQL 查询，一个函数必须始终以一个名字注册。对于 Table API，函数可以被注册，也可以直接内联使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="c1">// define function logic
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SubstringFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">begin</span><span class="o">,</span> <span class="n">end</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(...)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubstringFunction</span><span class="o">],</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">))</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">SubstringFunction</span><span class="o">])</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">))</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT SubstringFunction(myField, 5, 12) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><p>对于交互式会话，也可以在使用或注册函数之前对其进行参数化。在这种情况下，可以使用函数实例代替函数类作为临时函数。</p>
<p>它要求参数是可序列化的，以便将函数实例运送到集群。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="c1">// define parameterizable function logic
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="k">val</span> <span class="n">endInclusive</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">endInclusive</span> <span class="o">?</span> <span class="n">end</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">:</span> <span class="kt">end</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(...)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="k">new</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="kc">true</span><span class="o">),</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">))</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="kc">true</span><span class="o">))</span>
</code></pre></div><h2 id="实现指南">实现指南</h2>
<p>注意：本节目前只适用于标量函数和表函数；在集合函数更新到新的类型系统之前，本节只适用于标量函数。</p>
<p>无论函数的种类如何，所有用户定义的函数都遵循一些基本的实现原则。</p>
<h3 id="函数类">函数类</h3>
<p>一个实现类必须从一个可用的基类(例如 <code>org.apache.flink.table.function.ScalarFunction</code>)中扩展出来。</p>
<p>这个类必须被声明为 <code>public</code>，而不是 <code>abstract</code>，并且应该是全局访问的。因此，不允许使用非静态的内部类或匿名类。</p>
<p>对于在持久化目录中存储用户定义的函数，该类必须有一个默认的构造函数，并且在运行时必须是可实例化的。</p>
<h3 id="评估方法">评估方法</h3>
<p>基类提供了一组可以重写的方法，如 <code>open()</code>、<code>close()</code> 或 <code>isDeterministic()</code>。</p>
<p>然而，除了这些声明的方法外，应用于每个传入记录的主要运行时逻辑必须通过专门的评估方法来实现。</p>
<p>根据函数种类的不同，评价方法如 <code>eval()</code>、<code>accumulate()</code> 或 <code>retract()</code> 会在运行时被代码生成的操作符调用。</p>
<p>这些方法必须声明为 <code>public</code>，并接受一组定义明确的参数。</p>
<p>常规的 JVM 方法调用语义适用。因此，可以</p>
<ul>
<li>实现重载方法，如 <code>eval(Integer)</code> 和 <code>eval(LocalDateTime)</code>。</li>
<li>使用 var-args，如 <code>eval(Integer...)</code>。</li>
<li>使用对象继承，如 <code>eval(Object)</code>，它同时接受 <code>LocalDateTime</code> 和 <code>Integer</code>。</li>
<li>以及上述函数的组合，如 <code>eval(Object...)</code>，它可以接受所有类型的参数。</li>
</ul>
<p>如果你打算在 Scala 中实现函数，请在使用变量参数时添加 scala.annotation.varargs 注解。此外，建议使用盒状基元（如用 java.lang.Integer 代替 Int）来支持 NULL。</p>
<p>下面的代码段显示了一个重载函数的示例。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>
<span class="k">import</span> <span class="nn">java.lang.Integer</span>
<span class="k">import</span> <span class="nn">java.lang.Double</span>
<span class="k">import</span> <span class="nn">scala.annotation.varargs</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SumFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">a</span><span class="o">)</span> <span class="o">+</span> <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">b</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="nd">@varargs</span> <span class="c1">// generate var-args like Java
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">d</span><span class="k">:</span> <span class="kt">Double*</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">d</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">toInt</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="类型推断">类型推断</h3>
<p>表生态系统（类似于 SQL 标准）是一个强类型的 API。因此，函数参数和返回类型都必须映射到<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>。</p>
<p>从逻辑的角度来看，规划师需要关于预期类型、精度和规模的信息。从 JVM 的角度来看，规划师需要了解当调用用户定义的函数时，内部数据结构如何被表示为 JVM 对象。</p>
<p>验证输入参数和推导出函数的参数和结果的数据类型的逻辑被总结在类型推理这个术语下。</p>
<p>Flink 的用户定义函数实现了自动类型推理提取，通过反射从函数的类和它的评估方法中导出数据类型。如果这种隐式反射提取方法不成功，可以通过用 <code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注释受影响的参数、类或方法来支持提取过程。更多关于如何注释函数的例子如下所示。</p>
<p>如果需要更高级的类型推理逻辑，实现者可以在每个用户定义的函数中显式覆盖 <code>getTypeInference()</code> 方法。然而，推荐使用注释方法，因为它将自定义类型推理逻辑保持在受影响的位置附近，并回落到其余实现的默认行为。</p>
<h4 id="自动类型推断">自动类型推断</h4>
<p>自动类型推理检查函数的类和评估方法，从而得出函数的参数和结果的数据类型。<code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注解支持自动提取。</p>
<p>关于可以隐式映射到数据类型的类的完整列表，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html#data-type-extraction">数据类型提取</a>部分。</p>
<h5 id="datatypehint">@DataTypeHint</h5>
<p>在很多情况下，需要支持对函数的参数和返回类型进行在线自动提取。</p>
<p>下面的示例展示了如何使用数据类型提示。更多信息可以在注解类的文档中找到。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.InputGroup</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>
<span class="k">import</span> <span class="nn">scala.annotation.varargs</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1"></span><span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="c1">// no hint required
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
  <span class="o">}</span>

  <span class="c1">// define the precision and scale of a decimal
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;DECIMAL(12, 3)&#34;</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">double</span> <span class="n">a</span><span class="o">,</span> <span class="n">double</span> <span class="n">b</span><span class="o">)</span><span class="k">:</span> <span class="kt">BigDecimal</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="nc">BigDecimal</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="c1">// define a nested data type
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;s STRING, t TIMESTAMP(3) WITH LOCAL TIME ZONE&gt;&#34;</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nc">Int</span> <span class="n">i</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="nc">String</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">i</span><span class="o">),</span> <span class="n">java</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="nc">Instant</span><span class="o">.</span><span class="n">ofEpochSecond</span><span class="o">(</span><span class="n">i</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="c1">// allow wildcard input and customly serialized output
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">value</span> <span class="k">=</span> <span class="s">&#34;RAW&#34;</span><span class="o">,</span> <span class="n">bridgedTo</span> <span class="k">=</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">java.nio.ByteBuffer</span><span class="o">])</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">inputGroup</span> <span class="k">=</span> <span class="nc">InputGroup</span><span class="o">.</span><span class="nc">ANY</span><span class="o">)</span> <span class="nc">Object</span> <span class="n">o</span><span class="o">)</span><span class="k">:</span> <span class="kt">java.nio.ByteBuffer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">MyUtils</span><span class="o">.</span><span class="n">serializeToByteBuffer</span><span class="o">(</span><span class="n">o</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h5 id="functionhint">@FunctionHint</h5>
<p>在某些场景下，一个评估方法同时处理多种不同的数据类型是可取的。此外，在某些场景中，重载的评估方法有一个共同的结果类型，应该只声明一次。</p>
<p><code>@FunctionHint</code> 注解可以提供从参数数据类型到结果数据类型的映射。它可以为输入、累加器和结果数据类型注释整个函数类或评估方法。一个或多个注解可以在一个类的顶部声明，也可以为每个评估方法单独声明，以便重载函数签名。所有的提示参数都是可选的。如果没有定义参数，则使用默认的基于反射的提取方式。在函数类之上定义的提示参数会被所有的评估方法继承。</p>
<p>下面的例子展示了如何使用函数提示。更多信息可以在注解类的文档中找到。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.FunctionHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1">// but globally defined output type
</span><span class="c1"></span><span class="nd">@FunctionHint</span><span class="o">(</span><span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;s STRING, i INT&gt;&#34;</span><span class="o">))</span>
<span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="s">&#34;Sum&#34;</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)))</span>
  <span class="o">}</span>

  <span class="c1">// overloading of arguments is still possible
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="s">&#34;Empty args&#34;</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(-</span><span class="mi">1</span><span class="o">)))</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// decouples the type inference from evaluation methods,
</span><span class="c1">// the type inference is entirely determined by the function hints
</span><span class="c1"></span><span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">)),</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">)),</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(),</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BOOLEAN&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">AnyRef</span><span class="o">]</span> <span class="o">{</span>

  <span class="c1">// an implementer just needs to make sure that a method exists
</span><span class="c1"></span>  <span class="c1">// that can be called by the JVM
</span><span class="c1"></span>  <span class="nd">@varargs</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">o</span><span class="k">:</span> <span class="kt">AnyRef*</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">o</span><span class="o">.</span><span class="n">length</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">collect</span><span class="o">(</span><span class="nc">Boolean</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="kc">false</span><span class="o">))</span>
    <span class="o">}</span>
    <span class="n">collect</span><span class="o">(</span><span class="n">o</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h4 id="自定义类型推断">自定义类型推断</h4>
<p>对于大多数情况下，<code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 应该足以为用户定义的函数建模。然而，通过覆盖 <code>getTypeInference()</code> 中定义的自动类型推理，实现者可以创建任意的函数，这些函数的行为就像内置的系统函数一样。</p>
<p>下面这个用 Java 实现的例子说明了自定义类型推理逻辑的潜力。它使用一个字符串文字参数来确定一个函数的结果类型。该函数需要两个字符串参数：第一个参数代表要解析的字符串，第二个参数代表目标类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.table.api.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.catalog.DataTypeFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.inference.TypeInference</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.types.Row</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">LiteralFunction</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Object</span> <span class="nf">eval</span><span class="o">(</span><span class="n">String</span> <span class="n">s</span><span class="o">,</span> <span class="n">String</span> <span class="n">type</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">switch</span> <span class="o">(</span><span class="n">type</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">case</span> <span class="s">&#34;INT&#34;</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">s</span><span class="o">);</span>
      <span class="k">case</span> <span class="s">&#34;DOUBLE&#34;</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">Double</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">s</span><span class="o">);</span>
      <span class="k">case</span> <span class="s">&#34;STRING&#34;</span><span class="o">:</span>
      <span class="k">default</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">;</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="c1">// the automatic, reflection-based type inference is disabled and
</span><span class="c1"></span>  <span class="c1">// replaced by the following logic
</span><span class="c1"></span>  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">TypeInference</span> <span class="nf">getTypeInference</span><span class="o">(</span><span class="n">DataTypeFactory</span> <span class="n">typeFactory</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">TypeInference</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">()</span>
      <span class="c1">// specify typed arguments
</span><span class="c1"></span>      <span class="c1">// parameters will be casted implicitly to those types if necessary
</span><span class="c1"></span>      <span class="o">.</span><span class="na">typedArguments</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">(),</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">())</span>
      <span class="c1">// specify a strategy for the result data type of the function
</span><span class="c1"></span>      <span class="o">.</span><span class="na">outputTypeStrategy</span><span class="o">(</span><span class="n">callContext</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(!</span><span class="n">callContext</span><span class="o">.</span><span class="na">isArgumentLiteral</span><span class="o">(</span><span class="n">1</span><span class="o">)</span> <span class="o">||</span> <span class="n">callContext</span><span class="o">.</span><span class="na">isArgumentNull</span><span class="o">(</span><span class="n">1</span><span class="o">))</span> <span class="o">{</span>
          <span class="k">throw</span> <span class="n">callContext</span><span class="o">.</span><span class="na">newValidationError</span><span class="o">(</span><span class="s">&#34;Literal expected for second argument.&#34;</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="c1">// return a data type based on a literal
</span><span class="c1"></span>        <span class="kd">final</span> <span class="n">String</span> <span class="n">literal</span> <span class="o">=</span> <span class="n">callContext</span><span class="o">.</span><span class="na">getArgumentValue</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">String</span><span class="o">.</span><span class="na">class</span><span class="o">).</span><span class="na">orElse</span><span class="o">(</span><span class="s">&#34;STRING&#34;</span><span class="o">);</span>
        <span class="k">switch</span> <span class="o">(</span><span class="n">literal</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">case</span> <span class="s">&#34;INT&#34;</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">().</span><span class="na">notNull</span><span class="o">());</span>
          <span class="k">case</span> <span class="s">&#34;DOUBLE&#34;</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">DOUBLE</span><span class="o">().</span><span class="na">notNull</span><span class="o">());</span>
          <span class="k">case</span> <span class="s">&#34;STRING&#34;</span><span class="o">:</span>
          <span class="k">default</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">());</span>
        <span class="o">}</span>
      <span class="o">})</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="运行时集成">运行时集成</h3>
<p>有时可能需要用户自定义函数在实际工作前获取全局运行时信息或做一些设置/清理工作。用户自定义函数提供了 <code>open()</code> 和 <code>close()</code> 方法，这些方法可以被重写，并提供与 DataStream API 的 RichFunction 中的方法类似的功能。</p>
<p><code>open()</code> 方法在评估方法之前被调用一次。<code>close()</code> 方法在最后一次调用评估方法后调用。</p>
<p><code>open()</code> 方法提供了一个 FunctionContext，该 FunctionContext 包含了用户定义函数执行的上下文信息，如度量组、分布式缓存文件或全局作业参数。</p>
<p>通过调用 FunctionContext 的相应方法，可以获得以下信息。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">getMetricGroup()</td>
<td style="text-align:left">该并行子任务的度量组。</td>
</tr>
<tr>
<td style="text-align:left">getCachedFile(name)</td>
<td style="text-align:left">分布式缓存文件的本地临时文件副本。</td>
</tr>
<tr>
<td style="text-align:left">getJobParameter(name, defaultValue)</td>
<td style="text-align:left">与给定键相关联的全局作业参数值。</td>
</tr>
</tbody>
</table>
<p>下面的示例片段展示了如何在标量函数中使用 FunctionContext 来访问全局工作参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.FunctionContext</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="k">class</span> <span class="nc">HashCodeFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">factor</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// access the global &#34;hashcode_factor&#34; parameter
</span><span class="c1"></span>    <span class="c1">// &#34;12&#34; would be the default value if the parameter does not exist
</span><span class="c1"></span>    <span class="n">factor</span> <span class="k">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getJobParameter</span><span class="o">(</span><span class="s">&#34;hashcode_factor&#34;</span><span class="o">,</span> <span class="s">&#34;12&#34;</span><span class="o">).</span><span class="n">toInt</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">hashCode</span> <span class="o">*</span> <span class="n">factor</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(...)</span>

<span class="c1">// add job parameter
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">addJobParameter</span><span class="o">(</span><span class="s">&#34;hashcode_factor&#34;</span><span class="o">,</span> <span class="s">&#34;31&#34;</span><span class="o">)</span>

<span class="c1">// register the function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;hashCode&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">HashCodeFunction</span><span class="o">])</span>

<span class="c1">// use the function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT myField, hashCode(myField) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="标量函数">标量函数</h2>
<p>用户定义的标量函数可以将零、一或多个标量值映射到一个新的标量值。数据类型一节中列出的任何数据类型都可以作为一个评估方法的参数或返回类型。</p>
<p>为了定义一个标量函数，必须扩展 org.apache.flink.table.function 中的基类 ScalarFunction，并实现一个或多个名为 <code>eval(...)</code> 的评估方法。</p>
<p>下面的例子展示了如何定义自己的哈希码函数并在查询中调用它。更多细节请参见实施指南。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.InputGroup</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="k">class</span> <span class="nc">HashFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="c1">// take any data type and return INT
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">inputGroup</span> <span class="k">=</span> <span class="nc">InputGroup</span><span class="o">.</span><span class="nc">ANY</span><span class="o">)</span> <span class="n">o</span><span class="k">:</span> <span class="kt">AnyRef</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">{</span>
    <span class="kt">return</span> <span class="kt">o.hashCode</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(...)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">HashFunction</span><span class="o">],</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">))</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;HashFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">HashFunction</span><span class="o">])</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;HashFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">))</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT HashFunction(myField) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><p>如果你打算用 Python 实现或调用函数，请参考 Python Scalar Functions 文档了解更多细节。</p>
<h2 id="表函数">表函数</h2>
<p>与用户定义的标量函数类似，用户定义的表函数将零、一个或多个标量值作为输入参数。然而，与标量函数不同的是，它可以返回任意数量的行（或结构化类型）作为输出，而不是单个值。返回的记录可能由一个或多个字段组成。如果一条输出记录只由一个字段组成，则可以省略结构化记录，并发出一个标量值。它将被运行时包装成一个隐式行。</p>
<p>为了定义一个表函数，必须扩展 org.apache.flink.table.function 中的基类 TableFunction，并实现一个或多个名为 <code>eval(...)</code> 的评估方法。与其他函数类似，输入和输出数据类型也是使用反射自动提取的。这包括类的通用参数 T，用于确定输出数据类型。与标量函数不同的是，评价方法本身不能有返回类型，相反，表函数提供了一个 <code>collect(T)</code> 方法，可以在每个评价方法内调用，用于发出零、一条或多条记录。</p>
<p>在表 API 中，表函数的使用方法是 <code>.joinLateral(...)</code> 或 <code>.leftOuterJoinLateral(...)</code>。joinLateral 运算符（cross）将外表（运算符左边的表）的每条记录与表值函数产生的所有记录（表值函数在运算符的右边）连接起来。leftOuterJoinLateral 操作符将外表（操作符左边的表）的每一条记录与表值函数产生的所有记录（它在操作符的右边）连接起来，并且保留那些表函数返回空表的外表。</p>
<p>在 SQL 中，使用 <code>LATERAL TABLE(&lt;TableFunction&gt;)</code> 与 JOIN 或 LEFT JOIN 与 ON TRUE 连接条件。</p>
<p>下面的示例展示了如何定义自己的拆分函数并在查询中调用它。更多细节请参见《实现指南》。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.FunctionHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>

<span class="nd">@FunctionHint</span><span class="o">(</span><span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;word STRING, length INT&gt;&#34;</span><span class="o">))</span>
<span class="k">class</span> <span class="nc">SplitFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// use collect(...) to emit a row
</span><span class="c1"></span>    <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">length</span><span class="o">))))</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(...)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">],</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>
<span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">],</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>

<span class="c1">// rename fields of the function in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">],</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;newWord&#34;</span><span class="o">,</span> <span class="s">&#34;newLength&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;newWord&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;newLength&#34;</span><span class="o">)</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">])</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>
<span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, word, length &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable, LATERAL TABLE(SplitFunction(myField))&#34;</span><span class="o">);</span>
<span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, word, length &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable &#34;</span> <span class="o">+</span>
  <span class="s">&#34;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) ON TRUE&#34;</span><span class="o">)</span>

<span class="c1">// rename fields of the function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, newWord, newLength &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable &#34;</span> <span class="o">+</span>
  <span class="s">&#34;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) AS T(newWord, newLength) ON TRUE&#34;</span><span class="o">)</span>
</code></pre></div><p>如果你打算在 Scala 中实现函数，不要将表函数实现为 Scala 对象。Scala 对象是单子，会导致并发问题。</p>
<p>如果你打算用 Python 实现或调用函数，请参考 Python 表函数文档了解更多细节。</p>
<h2 id="聚合函数">聚合函数</h2>
<p>用户自定义聚合函数（UDAGG）将一个表（一个或多个具有一个或多个属性的行）聚合成一个标量值。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/udagg-mechanism.png" alt="img"></p>
<p>上图显示了一个聚合的例子。假设你有一个包含饮料数据的表。该表由 id、名称和价格三列和 5 行组成。想象一下，你需要找到表中所有饮料的最高价格，即执行 <code>max()</code> 聚合。你需要对 5 行中的每一行进行检查，结果将是一个单一的数值。</p>
<p>用户定义的聚合函数是通过扩展 AggregateFunction 类来实现的。AggregateFunction 的工作原理如下。首先，它需要一个累加器，它是存放聚合中间结果的数据结构。通过调用 AggregateFunction 的 <code>createAccumulator()</code> 方法创建一个空的累加器。随后，函数的 <code>accumulate()</code> 方法对每一条输入行进行调用，以更新累加器。一旦所有的行都被处理完毕，函数的 <code>getValue()</code> 方法就会被调用来计算并返回最终结果。</p>
<p>以下方法是每个 AggregateFunction 必须使用的。</p>
<ul>
<li>createAccumulator()</li>
<li>accumulate()</li>
<li>getValue()</li>
</ul>
<p>Flink 的类型提取设施可能无法识别复杂的数据类型，例如，如果它们不是基本类型或简单的 POJOs。所以与 ScalarFunction 和 TableFunction 类似，AggregateFunction 提供了指定结果类型（通过 AggregateFunction#getResultType()）和累加器类型（通过 AggregateFunction#getAccumulatorType()）的方法。</p>
<p>除了上述方法外，还有一些签约方法可以选择实现。这些方法中的一些方法可以让系统更高效地执行查询，而另一些方法则是某些用例所必须的。例如，如果聚合函数应该在会话组窗口的上下文中应用，那么 <code>merge()</code> 方法是强制性的（当观察到有一行 &ldquo;连接 &ldquo;它们时，需要将两个会话窗口的累加器连接起来）。</p>
<p>AggregateFunction 的以下方法是根据用例需要的。</p>
<ul>
<li><code>retract()</code> 对于有界 OVER 窗口上的聚合是需要的。</li>
<li><code>merge()</code> 是许多批次聚合和会话窗口聚合所需要的。</li>
<li><code>resetAccumulator()</code> 是许多批处理聚合所需要的。</li>
</ul>
<p>AggregateFunction 的所有方法都必须声明为 public，而不是 static，并且命名与上述名称完全一致。方法 createAccumulator、getValue、getResultType 和 getAccumulatorType 是在 AggregateFunction 抽象类中定义的，而其他方法则是合同方法。为了定义一个聚合函数，必须扩展基类 org.apache.flink.table.function.AggregateFunction，并实现一个（或多个）accumulate 方法。方法 accumulate 可以用不同的参数类型重载，并支持变量参数。</p>
<p>下面给出了 AggregateFunction 所有方法的详细文档。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/**
</span><span class="cm">  * Base class for user-defined aggregates and table aggregates.
</span><span class="cm">  *
</span><span class="cm">  * @tparam T   the type of the aggregation result.
</span><span class="cm">  * @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  *             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  */</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedFunction</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Creates and init the Accumulator for this (table)aggregate function.
</span><span class="cm">    *
</span><span class="cm">    * @return the accumulator with the initial value
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">ACC</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Returns the TypeInformation of the (table)aggregate function&#39;s result.
</span><span class="cm">    *
</span><span class="cm">    * @return The TypeInformation of the (table)aggregate function&#39;s result or null if the result
</span><span class="cm">    *         type should be automatically inferred.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Returns the TypeInformation of the (table)aggregate function&#39;s accumulator.
</span><span class="cm">    *
</span><span class="cm">    * @return The TypeInformation of the (table)aggregate function&#39;s accumulator or null if the
</span><span class="cm">    *         accumulator type should be automatically inferred.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>

<span class="cm">/**
</span><span class="cm">  * Base class for aggregation functions. 
</span><span class="cm">  *
</span><span class="cm">  * @tparam T   the type of the aggregation result
</span><span class="cm">  * @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  *             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  *             AggregateFunction represents its state using accumulator, thereby the state of the
</span><span class="cm">  *             AggregateFunction must be put into the accumulator.
</span><span class="cm">  */</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Processes the input values and update the provided accumulator instance. The method
</span><span class="cm">    * accumulate can be overloaded with different custom types and arguments. An AggregateFunction
</span><span class="cm">    * requires at least one accumulate() method.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    * @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Retracts the input values from the accumulator instance. The current design assumes the
</span><span class="cm">    * inputs are the values that have been previously accumulated. The method retract can be
</span><span class="cm">    * overloaded with different custom types and arguments. This function must be implemented for
</span><span class="cm">    * datastream bounded over aggregate.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    * @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Merges a group of accumulator instances into one accumulator instance. This function must be
</span><span class="cm">    * implemented for datastream session window grouping aggregate and dataset grouping aggregate.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator  the accumulator which will keep the merged aggregate results. It should
</span><span class="cm">    *                     be noted that the accumulator may contain the previous aggregated
</span><span class="cm">    *                     results. Therefore user should not replace or clean this instance in the
</span><span class="cm">    *                     custom merge method.
</span><span class="cm">    * @param its          an [[java.lang.Iterable]] pointed to a group of accumulators that will be
</span><span class="cm">    *                     merged.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">ACC</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>  
  <span class="cm">/**
</span><span class="cm">    * Called every time when an aggregation result should be materialized.
</span><span class="cm">    * The returned value could be either an early and incomplete result
</span><span class="cm">    * (periodically emitted as data arrive) or the final result of the
</span><span class="cm">    * aggregation.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator the accumulator which contains the current
</span><span class="cm">    *                    aggregated results
</span><span class="cm">    * @return the aggregation result
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Resets the accumulator for this [[AggregateFunction]]. This function must be implemented for
</span><span class="cm">    * dataset grouping aggregate.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator  the accumulator which needs to be reset
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Returns true if this AggregateFunction can only be applied in an OVER window.
</span><span class="cm">    *
</span><span class="cm">    * @return true if the AggregateFunction requires an OVER window, false otherwise.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">requiresOver</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="kc">false</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><p>下面的例子说明了如何进行</p>
<ul>
<li>定义一个 AggregateFunction，用于计算给定列的加权平均值。</li>
<li>在 TableEnvironment 中注册该函数，并且</li>
<li>在查询中使用该函数。</li>
</ul>
<p>为了计算加权平均值，累加器需要存储所有已积累的数据的加权和和计数。在我们的例子中，我们定义了一个类 WeightedAvgAccum 作为累加器。累积器由 Flink 的检查点机制自动备份，并在故障时恢复，以保证精确的唯一性语义。</p>
<p>我们 WeightedAvg AggregateFunction 的 <code>accumulate()</code> 方法有三个输入。第一个是 WeightedAvgAccum 累加器，另外两个是用户自定义的输入：输入值 ivalue 和输入的权重 iweight。虽然 <code>retract()</code>、<code>merge()</code> 和 <code>resetAccumulator()</code> 方法对于大多数聚合类型来说并不是强制性的，但我们在下面提供它们作为例子。请注意，我们在 Scala 示例中使用了 Java 基元类型，并定义了 <code>getResultType()</code> 和  <code>getAccumulatorType()</code> 方法，因为 Flink 类型提取对于 Scala 类型并不十分有效。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Long</span> <span class="k">=&gt;</span> <span class="nc">JLong</span><span class="o">,</span> <span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.tuple.</span><span class="o">{</span><span class="nc">Tuple1</span> <span class="k">=&gt;</span> <span class="nc">JTuple1</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.typeutils.TupleTypeInfo</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.AggregateFunction</span>

<span class="cm">/**
</span><span class="cm"> * Accumulator for WeightedAvg.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">WeightedAvgAccum</span> <span class="k">extends</span> <span class="nc">JTuple1</span><span class="o">[</span><span class="kt">JLong</span>, <span class="kt">JInteger</span><span class="o">]</span> <span class="o">{</span>
  <span class="n">sum</span> <span class="k">=</span> <span class="mi">0L</span>
  <span class="n">count</span> <span class="k">=</span> <span class="mi">0</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * Weighted Average user-defined aggregate function.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">WeightedAvg</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">JLong</span>, <span class="kt">CountAccumulator</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">WeightedAvgAccum</span>
  <span class="o">}</span>
  
  <span class="k">override</span> <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">)</span><span class="k">:</span> <span class="kt">JLong</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
        <span class="kc">null</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="n">acc</span><span class="o">.</span><span class="n">count</span>
    <span class="o">}</span>
  <span class="o">}</span>
  
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">iValue</span><span class="k">:</span> <span class="kt">JLong</span><span class="o">,</span> <span class="n">iWeight</span><span class="k">:</span> <span class="kt">JInteger</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">iValue</span> <span class="o">*</span> <span class="n">iWeight</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">iWeight</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">iValue</span><span class="k">:</span> <span class="kt">JLong</span><span class="o">,</span> <span class="n">iWeight</span><span class="k">:</span> <span class="kt">JInteger</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">-=</span> <span class="n">iValue</span> <span class="o">*</span> <span class="n">iWeight</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">-=</span> <span class="n">iWeight</span>
  <span class="o">}</span>
    
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">it</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">it</span><span class="o">.</span><span class="n">iterator</span><span class="o">()</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">a</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">a</span><span class="o">.</span><span class="n">count</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="k">=</span> <span class="mi">0L</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">TupleTypeInfo</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">],</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">JLong</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span>
<span class="o">}</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">???</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">registerFunction</span><span class="o">(</span><span class="s">&#34;wAvg&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">WeightedAvg</span><span class="o">())</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="表聚合函数">表聚合函数</h2>
<p>用户定义表聚合函数(UDTAGGs)将一个表(具有一个或多个属性的一行或多行)聚合到一个具有多行和多列的结果表。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/udtagg-mechanism.png" alt="img"></p>
<p>上图显示了一个表聚合的例子。假设你有一个包含饮料数据的表。该表由 id、名称和价格三列和 5 行组成。设想你需要找到表中所有饮料中价格最高的前 2 名，即执行 <code>top2()</code> 表聚合。你需要对 5 行中的每一行进行检查，结果将是一个具有前 2 个值的表。</p>
<p>用户定义的表聚合函数是通过扩展 TableAggregateFunction 类来实现的。TableAggregateFunction 的工作原理如下。首先，它需要一个累加器，它是存放聚合中间结果的数据结构。通过调用 TableAggregateFunction 的 <code>createAccumulator()</code> 方法创建一个空的累加器。随后，对每一条输入行调用函数的 <code>accumulate()</code> 方法来更新累加器。一旦所有的行都被处理完毕，函数的 <code>emitValue()</code> 方法就会被调用来计算并返回最终结果。</p>
<p>以下方法是每个 TableAggregateFunction 必须使用的。</p>
<ul>
<li>createAccumulator()</li>
<li>accumulate()</li>
</ul>
<p>Flink 的类型提取设施可能无法识别复杂的数据类型，例如，如果它们不是基本类型或简单的 POJOs。因此，与 ScalarFunction 和 TableFunction 类似，TableAggregateFunction 提供了指定结果类型（通过 <code>TableAggregateFunction#getResultType()</code>）和累积器类型（通过 <code>TableAggregateFunction#getAccumulatorType()</code>）的方法。</p>
<p>除了上述方法外，还有一些签约方法可以选择实现。这些方法中的一些方法可以让系统更高效地执行查询，而另一些方法则是某些用例所必须的。例如，如果聚合函数应该在会话组窗口的上下文中应用，那么 <code>merge()</code> 方法是强制性的（当观察到有一条记录&quot;连接&quot;它们时，需要将两个会话窗口的累加器连接起来）。</p>
<p>TableAggregateFunction 的以下方法是需要的，这取决于用例。</p>
<ul>
<li><code>retract()</code> 对于有界 OVER 窗口上的聚合是需要的。</li>
<li><code>merge()</code> 是许多批次聚合和会话窗口聚合所需要的。</li>
<li><code>resetAccumulator()</code> 是许多批处理聚合所需要的。</li>
<li><code>emitValue()</code> 是批处理和窗口聚合所需要的。</li>
</ul>
<p>TableAggregateFunction 的以下方法用于提高流作业的性能。</p>
<ul>
<li><code>emitUpdateWithRetract()</code> 用于发射在伸缩模式下更新的值。</li>
</ul>
<p>对于 emitValue 方法，则是根据累加器来发射完整的数据。以 TopN 为例，emitValue 每次都会发射所有前 n 个值。这可能会给流式作业带来性能问题。为了提高性能，用户也可以实现 emitUpdateWithRetract 方法来提高性能。该方法以回缩模式增量输出数据，即一旦有更新，我们必须在发送新的更新记录之前回缩旧记录。如果在表聚合函数中都定义了该方法，那么该方法将优先于 emitValue 方法使用，因为 emitUpdateWithRetract 被认为比 emitValue 更有效率，因为它可以增量输出值。</p>
<p>TableAggregateFunction 的所有方法都必须声明为 public，而不是 static，并完全按照上面提到的名字命名。方法 createAccumulator、getResultType 和 getAccumulatorType 是在 TableAggregateFunction 的父抽象类中定义的，而其他方法则是收缩的方法。为了定义一个表聚合函数，必须扩展基类 org.apache.flink.table.function.TableAggregateFunction，并实现一个（或多个）accumulate 方法。积累方法可以用不同的参数类型重载，并支持变量参数。</p>
<p>下面给出了 TableAggregateFunction 所有方法的详细文档。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/**
</span><span class="cm">  * Base class for user-defined aggregates and table aggregates.
</span><span class="cm">  *
</span><span class="cm">  * @tparam T   the type of the aggregation result.
</span><span class="cm">  * @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  *             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  */</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedFunction</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Creates and init the Accumulator for this (table)aggregate function.
</span><span class="cm">    *
</span><span class="cm">    * @return the accumulator with the initial value
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">ACC</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Returns the TypeInformation of the (table)aggregate function&#39;s result.
</span><span class="cm">    *
</span><span class="cm">    * @return The TypeInformation of the (table)aggregate function&#39;s result or null if the result
</span><span class="cm">    *         type should be automatically inferred.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Returns the TypeInformation of the (table)aggregate function&#39;s accumulator.
</span><span class="cm">    *
</span><span class="cm">    * @return The TypeInformation of the (table)aggregate function&#39;s accumulator or null if the
</span><span class="cm">    *         accumulator type should be automatically inferred.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>

<span class="cm">/**
</span><span class="cm">  * Base class for table aggregation functions. 
</span><span class="cm">  *
</span><span class="cm">  * @tparam T   the type of the aggregation result
</span><span class="cm">  * @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  *             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  *             TableAggregateFunction represents its state using accumulator, thereby the state of
</span><span class="cm">  *             the TableAggregateFunction must be put into the accumulator.
</span><span class="cm">  */</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Processes the input values and update the provided accumulator instance. The method
</span><span class="cm">    * accumulate can be overloaded with different custom types and arguments. A TableAggregateFunction
</span><span class="cm">    * requires at least one accumulate() method.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    * @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Retracts the input values from the accumulator instance. The current design assumes the
</span><span class="cm">    * inputs are the values that have been previously accumulated. The method retract can be
</span><span class="cm">    * overloaded with different custom types and arguments. This function must be implemented for
</span><span class="cm">    * datastream bounded over aggregate.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    * @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Merges a group of accumulator instances into one accumulator instance. This function must be
</span><span class="cm">    * implemented for datastream session window grouping aggregate and dataset grouping aggregate.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator  the accumulator which will keep the merged aggregate results. It should
</span><span class="cm">    *                     be noted that the accumulator may contain the previous aggregated
</span><span class="cm">    *                     results. Therefore user should not replace or clean this instance in the
</span><span class="cm">    *                     custom merge method.
</span><span class="cm">    * @param its          an [[java.lang.Iterable]] pointed to a group of accumulators that will be
</span><span class="cm">    *                     merged.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">ACC</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>  
  <span class="cm">/**
</span><span class="cm">    * Called every time when an aggregation result should be materialized. The returned value
</span><span class="cm">    * could be either an early and incomplete result  (periodically emitted as data arrive) or
</span><span class="cm">    * the final result of the  aggregation.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator the accumulator which contains the current
</span><span class="cm">    *                    aggregated results
</span><span class="cm">    * @param out         the collector used to output data
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/**
</span><span class="cm">    * Called every time when an aggregation result should be materialized. The returned value
</span><span class="cm">    * could be either an early and incomplete result (periodically emitted as data arrive) or
</span><span class="cm">    * the final result of the aggregation.
</span><span class="cm">    *
</span><span class="cm">    * Different from emitValue, emitUpdateWithRetract is used to emit values that have been updated.
</span><span class="cm">    * This method outputs data incrementally in retract mode, i.e., once there is an update, we
</span><span class="cm">    * have to retract old records before sending new updated ones. The emitUpdateWithRetract
</span><span class="cm">    * method will be used in preference to the emitValue method if both methods are defined in the
</span><span class="cm">    * table aggregate function, because the method is treated to be more efficient than emitValue
</span><span class="cm">    * as it can outputvalues incrementally.
</span><span class="cm">    *
</span><span class="cm">    * @param accumulator the accumulator which contains the current
</span><span class="cm">    *                    aggregated results
</span><span class="cm">    * @param out         the retractable collector used to output data. Use collect method
</span><span class="cm">    *                    to output(add) records and use retract method to retract(delete)
</span><span class="cm">    *                    records.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">emitUpdateWithRetract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">RetractableCollector</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span> 
  <span class="cm">/**
</span><span class="cm">    * Collects a record and forwards it. The collector can output retract messages with the retract
</span><span class="cm">    * method. Note: only use it in `emitRetractValueIncrementally`.
</span><span class="cm">    */</span>
  <span class="k">trait</span> <span class="nc">RetractableCollector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Collector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="o">{</span>
    
    <span class="cm">/**
</span><span class="cm">      * Retract a record.
</span><span class="cm">      *
</span><span class="cm">      * @param record The record to retract.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>下面的例子说明了如何进行</p>
<ul>
<li>定义一个 TableAggregateFunction，用于计算给定列上的前 2 个值。</li>
<li>在 TableEnvironment 中注册该函数，并且</li>
<li>在 Table API 查询中使用该函数(TableAggregateFunction 仅由 Table API 支持)。</li>
</ul>
<p>为了计算前 2 名的值，累加器需要存储所有已积累的数据中最大的 2 个值。在我们的例子中，我们定义了一个类 Top2Accum 作为累加器。累积器会被 Flink 的检查点机制自动备份，并在故障时恢复，以保证精确的 once 语义。</p>
<p>我们 Top2 TableAggregateFunction 的 <code>accumulate()</code> 方法有两个输入。第一个是 Top2Accum 累加器，另一个是用户定义的输入：输入值 v，虽然 <code>merge()</code> 方法对于大多数表聚合类型来说不是强制性的，但我们在下面提供它作为例子。请注意，我们在 Scala 示例中使用了 Java 基元类型，并定义了 <code>getResultType()</code> 和 <code>getAccumulatorType()</code> 方法，因为 Flink 类型提取对 Scala 类型的效果并不好。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/**
</span><span class="cm"> * Accumulator for top2.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * The top2 user-defined table aggregate function.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">JIterable</span><span class="o">[</span><span class="kt">Top2Accum</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">its</span><span class="o">.</span><span class="n">iterator</span><span class="o">()</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">first</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">second</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// emit the value and rank
</span><span class="c1"></span>    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// init table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tab</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tab</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>&#39;key<span class="o">)</span>
  <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span>&#39;a<span class="o">)</span> <span class="n">as</span> <span class="o">(</span>&#39;v<span class="o">,</span> &#39;rank<span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span>&#39;key<span class="o">,</span> &#39;v<span class="o">,</span> &#39;rank<span class="o">)</span>
</code></pre></div><p>下面的例子展示了如何使用 emitUpdateWithRetract 方法来只发送更新。在我们的例子中，为了只发出更新，累加器同时保留新旧 top2 的值。注意：如果 topN 的 N 很大，那么同时保留新旧值的效率可能很低。解决这种情况的方法之一是在累加方法中把输入的记录存储到累加器中，然后在 emitUpdateWithRetract 中进行计算。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/**
</span><span class="cm"> * Accumulator for top2.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">oldFirst</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">oldSecond</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * The top2 user-defined table aggregate function.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitUpdateWithRetract</span><span class="o">(</span>
    <span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span>
    <span class="n">out</span><span class="k">:</span> <span class="kt">RetractableCollector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]])</span>
  <span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// if there is an update, retract old value then emit new value.
</span><span class="c1"></span>      <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="n">retract</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
      <span class="o">}</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// if there is an update, retract old value then emit new value.
</span><span class="c1"></span>      <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="n">retract</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
      <span class="o">}</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// init table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tab</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tab</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>&#39;key<span class="o">)</span>
  <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span>&#39;a<span class="o">)</span> <span class="n">as</span> <span class="o">(</span>&#39;v<span class="o">,</span> &#39;rank<span class="o">))</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span>&#39;key<span class="o">,</span> &#39;v<span class="o">,</span> &#39;rank<span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/function" term="function" label="Function" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[用户定义函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-user-defined-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-user-defined-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>User Defined Functions</blockquote><h1 id="用户自定义函数">用户自定义函数</h1>
<p>大多数操作符都需要用户定义的函数。本节列出了如何指定这些函数的不同方法。我们还涵盖了累加器，它可以用来深入了解您的 Flink 应用程序。</p>
<h2 id="lambda-函数">Lambda 函数</h2>
<p>在前面的例子中已经看到，所有的操作符都接受 lambda 函数来描述操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&#34;http://&#34;</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">(</span><span class="n">i1</span><span class="o">,</span><span class="n">i2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span> <span class="o">}</span>
<span class="c1">// 或
</span><span class="c1"></span><span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span>
</code></pre></div><h3 id="富函数rich-functions">富函数(Rich functions)</h3>
<p>所有以 lambda 函数作为参数的变换都可以以富函数作为参数。例如，我们可以不使用:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
</code></pre></div><p>你可以编写:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyMapFunction</span> <span class="k">extends</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">};</span>
</code></pre></div><p>并将该函数传递给 map 转换:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapFunction</span><span class="o">())</span>
</code></pre></div><p>丰富的函数也可以定义为匿名类:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">})</span>
</code></pre></div><p>丰富的函数除了提供用户定义的函数（map、reduce等）外，还提供了四个方法：<code>open</code>、<code>close</code>、<code>getRuntimeContext</code> 和 <code>setRuntimeContext</code>。这些方法可以用于为函数设置参数（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#passing-parameters-to-functions">Passing Parameters to Functions</a>）、创建和最终确定局部状态、访问广播变量（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#broadcast-variables">Broadcast Variables</a>）、访问运行时信息，如累加器和计数器（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/user_defined_functions.html#accumulators--counters">Accumulators and Counters</a>）以及迭代信息（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">Iterations</a>）。</p>
<h3 id="累积器和计数器">累积器和计数器</h3>
<p>累积器是一个简单的构造，有一个加法运算和一个最终的累积结果，在作业结束后就可以使用。</p>
<p>最直接的累加器是一个计数器，你可以使用 <code>Accumulator.add(V value)</code> 方法对它进行增量。在作业结束时，Flink 将对所有部分结果进行加总（合并）并将结果发送给客户端。累积器在调试期间或如果你快速想了解更多的数据时是很有用的。</p>
<p>Flink 目前有以下内置的累加器。它们每个都实现了 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a> 接口。</p>
<ul>
<li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/IntCounter.java">IntCounter</a>、<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/LongCounter.java">LongCounter</a> 和 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/DoubleCounter.java">DoubleCounter</a>。请看下面一个使用计数器的例子。</li>
<li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Histogram.java">直方图</a>。一个离散数量的直方块的直方图实现。在内部，它只是一个从 Integer 到 Integer 的映射。你可以用它来计算值的分布，例如字数程序的每行字数分布。</li>
</ul>
<p><strong>如何使用累加器:</strong></p>
<p>首先你必须在用户定义的转换函数中创建一个累加器对象(这里是一个计数器)，在你想使用它的地方。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="n">IntCounter</span> <span class="n">numLines</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntCounter</span><span class="o">();</span>
</code></pre></div><p>其次，你必须注册累加器对象，通常是在富函数的 <code>open()</code> 方法中。在这里你还需要定义名称。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">getRuntimeContext</span><span class="o">().</span><span class="n">addAccumulator</span><span class="o">(</span><span class="s">&#34;num-lines&#34;</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="n">numLines</span><span class="o">);</span>
</code></pre></div><p>现在你可以在运算函数的任何地方使用累加器，包括在 <code>open()</code> 和 <code>close()</code> 方法中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">this</span><span class="o">.</span><span class="n">numLines</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
</code></pre></div><p>整体结果将存储在 <code>JobExecutionResult</code> 对象中，该对象由执行环境的 <code>execute()</code> 方法返回（目前只有在执行等待作业完成的情况下才有效）。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">myJobExecutionResult</span><span class="o">.</span><span class="n">getAccumulatorResult</span><span class="o">(</span><span class="s">&#34;num-lines&#34;</span><span class="o">)</span>
</code></pre></div><p>所有的累加器在每个作业中共享一个命名空间。因此你可以在你的工作的不同操作函数中使用同一个累加器。Flink 会在内部合并所有同名的累加器。</p>
<p>关于累加器和迭代的说明。目前，累加器的结果只有在整个作业结束后才会出现。我们计划在下一次迭代中也能获得上一次迭代的结果。你可以使用 <a href="v">Aggregators</a> 来计算每次迭代的统计数据，并根据这些统计数据来终止迭代。</p>
<p><strong>自定义累加器:</strong></p>
<p>要实现你自己的累加器，你只需要编写你的 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a> 接口的实现。如果你认为你的自定义累加器应该和Flink一起发布，请随时创建一个pull request。</p>
<p>你可以选择实现 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a> 或 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/SimpleAccumulator.java">SimpleAccumulator</a>。</p>
<p><code>Accumulator&lt;V,R&gt;</code> 是最灵活的。它为要添加的值定义了一个类型 V，为最终结果定义了一个结果类型 R。例如，对于一个直方图，V 是一个数字，R 是一个直方图。 <code>SimpleAccumulator</code> 适用于两种类型都相同的情况，例如计数器。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/user_defined_functions.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/user_defined_functions.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[窗口]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-windows/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-asynchronous-io-for-external-data-access/?utm_source=atom_feed" rel="related" type="text/html" title="用于外部数据访问的异步 I/O" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-windows/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Windows</blockquote><h1 id="窗口">窗口</h1>
<p>窗口是处理无限流的核心。窗口将流分割成有限大小的&quot;桶&quot;，我们可以对其应用计算。本文档主要介绍 Flink 中如何进行窗口化，以及程序员如何从其提供的功能中最大限度地受益。</p>
<p>下面介绍了一个窗口化 Flink 程序的一般结构。第一个片段指的是 keyed 流，而第二个片段指的是 non-keyed 流。正如人们所看到的那样，唯一的区别是 keyed 流的 <code>keyBy(...)</code> 调用和 non-keyed 流的 <code>window(...)</code> 变成了 <code>windowAll(...)</code>。这也将作为本页面其他内容的路线图。</p>
<p><strong>Keyed 窗口</strong></p>
<pre><code>stream
       .keyBy(...)               &lt;-  keyed 与 non-keyed 窗口的对比
       .window(...)              &lt;-  必须的: &quot;assigner&quot;
      [.trigger(...)]            &lt;-  可选的: &quot;trigger&quot; (否则使用默认的 trigger)
      [.evictor(...)]            &lt;-  可选的: &quot;evictor&quot; (否则没有 evictor)
      [.allowedLateness(...)]    &lt;-  可选的: &quot;lateness&quot; (否则为零)
      [.sideOutputLateData(...)] &lt;-  可选的: &quot;output tag&quot; (否则迟到数据无侧输出)
       .reduce/aggregate/fold/apply()      &lt;-  必须的: &quot;function&quot;
      [.getSideOutput(...)]      &lt;-  可选的: &quot;output tag&quot;
</code></pre><p><strong>Non-Keyed 窗口</strong></p>
<pre><code>stream
       .windowAll(...)           &lt;-  必须的: &quot;assigner&quot;
      [.trigger(...)]            &lt;-  可选的: &quot;trigger&quot; (否则使用默认的 trigger)
      [.evictor(...)]            &lt;-  可选的: &quot;evictor&quot; (否则没有 evictor)
      [.allowedLateness(...)]    &lt;-  可选的: &quot;lateness&quot; (否则为零)
      [.sideOutputLateData(...)] &lt;-  可选的: &quot;output tag&quot; (否则迟到数据无侧输出)
       .reduce/aggregate/fold/apply()      &lt;-  必须的: &quot;function&quot;
      [.getSideOutput(...)]      &lt;-  可选的: &quot;output tag&quot;
</code></pre><p>在上面，方括号中的命令(<code>[...]</code>)是可选的。这表明 Flink 允许你以多种不同的方式定制你的窗口逻辑，以便它最适合你的需求。</p>
<h2 id="窗口生命周期">窗口生命周期</h2>
<p>简而言之，当第一个应该属于这个窗口的元素到达时，就会创建一个窗口，当时间（事件时间或处理时间）经过(passes)它的结束时间戳加上用户指定的允许延迟时，这个窗口就会被完全移除（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#allowed-lateness">允许延迟</a>）。Flink 只保证对基于时间的窗口进行移除，而不保证对其他类型的窗口，如全局窗口进行移除（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-assigners">窗口分配器</a>）。例如，基于事件-时间的窗口策略每5分钟创建一个非重叠（或翻滚）的窗口，并且允许的延迟为1分钟，当第一个具有时间戳的元素落入这个区间时，Flink 将为 12:00 和 12:05 之间的区间创建一个新的窗口，当水印通过 12:06 的时间戳时，它将删除它。</p>
<p>此外，每个窗口将有一个触发器(见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#triggers">触发器</a>)和一个函数(ProcessWindowFunction、ReduceFunction、AggregateFunction或FoldFunction)(见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-functions">窗口函数</a>)。函数将包含要应用于窗口内容的计算，而触发器则指定了窗口被认为可以应用函数的条件。触发策略可能是&quot;当窗口中的元素数量超过4时&quot;，或者&quot;当水印经过窗口的末端时&quot;。触发器还可以决定在创建和删除窗口之间的任何时间(any time between its creation and removal)清除窗口的内容。在这种情况下，清除只指窗口中的元素，而不是窗口元数据。这意味着新的数据仍然可以被添加到该窗口中。</p>
<p>除上述之外，您还可以指定一个 Evictor(见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#evictors">Evictors</a>)，它将能够在触发器触发后以及在函数应用之前和/或之后从窗口中删除元素。</p>
<p>在下文中，我们将对上述每个组件进行更详细的介绍。我们先从上述代码段中必须的部分开始(参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#keyed-vs-non-keyed-windows">Keyed vs Non-Keyed 窗口</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-assigner">窗口分配器</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-function">窗口函数</a>)，然后再转向可选部分。</p>
<h2 id="keyed-与-non-keyed-窗口的对比">Keyed 与 Non-Keyed 窗口的对比</h2>
<p>首先要指定的是您的流是否应该是 keyed 的。这必须在定义窗口之前完成。使用 <code>keyBy(...)</code> 将把您的无限流分割成逻辑 keyed 流。如果没有调用 <code>keyBy(...)</code>，那么您的流就不是 keyed 流。</p>
<p>在 keyed 流的情况下，传入事件的任何属性都可以被用作键（更多细节在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#keyed-datastream">这里</a>）。拥有一个 keyed 流将允许你的窗口计算由多个任务并行执行，因为每个逻辑 keyed 流可以独立于其他流进行处理。所有指向同一键的元素将被发送到同一个并行任务(task)。</p>
<p>在 non-keyed 流的情况下，您的原始流不会被分割成多个逻辑流，所有的窗口化逻辑将由一个任务(task)来执行，即并行度为1。</p>
<h2 id="窗口分配器">窗口分配器</h2>
<p>在指定流是否是 keyed 流之后，下一步是定义窗口分配器。窗口分配器定义了如何将元素分配给窗口。这是通过在 <code>window(...)</code>（对于 keyed 流）或 <code>windowAll()</code>（对于 non-keyed 流）调用中指定您所选择的 <code>WindowAssigner</code> 来实现的。</p>
<p><code>WindowAssigner</code> 负责将每个传入的元素分配给一个或多个窗口。Flink 为最常见的用例提供了预定义的窗口分配器，即滚动窗口、滑动窗口、会话窗口和全局窗口。您也可以通过扩展 <code>WindowAssigner</code> 类来实现自定义窗口分配器。所有内置的窗口分配器（除了全局窗口）都是基于时间将元素分配给窗口，时间可以是处理时间，也可以是事件时间。请查看我们关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间</a>的部分，了解处理时间和事件时间之间的区别，以及时间戳和水印是如何生成的。</p>
<p>基于时间的窗口有一个开始时间戳（包括）和结束时间戳（不包括），共同描述窗口的大小。在代码中，Flink 在处理基于时间的窗口时使用了 <code>TimeWindow</code>，它有查询开始和结束时间戳的方法，还有一个额外的方法 <code>maxTimestamp()</code>，可以返回给定窗口的最大允许时间戳。</p>
<p>在下文中，我们将展示 Flink 的预定义窗口分配器是如何工作的，以及如何在 DataStream 程序中使用它们。下图直观地展示了每个分配器的工作情况。紫色的圆圈代表流的元素，这些元素被某个键（在本例中是用户1、用户2和用户3）分割。x轴显示的是时间的进度。</p>
<h2 id="滚动窗口">滚动窗口</h2>
<p>滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口。滚动窗口有一个固定的大小，并且不重叠。例如，如果你指定了一个大小为5分钟的滚动窗口，那么当前的窗口将被评估，并且每隔5分钟就会启动一个新的窗口，如下图所示。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tumbling-windows.svg" alt="img"></p>
<p>以下代码片段展示了如何使用滚动窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// tumbling event-time windows
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// tumbling processing-time windows
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingProcessingTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// daily tumbling event-time windows offset by -8 hours.
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">days</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(-</span><span class="mi">8</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>时间间隔可以使用 <code>Time.milliseconds(x)</code>, <code>Time.seconds(x)</code>, <code>Time.minutes(x)</code> 等中的一种来指定。</p>
<p>如最后一个例子所示，滚动窗口分配器还可以采用一个可选的偏移量(<code>offset</code>)参数，用于改变窗口的对齐方式。例如，在没有偏移量的情况下，每小时的滚动窗口与纪元对齐，也就是说，你会得到诸如 <code>1:00:00.000 - 1:59:59.999</code>，<code>2:00:00.000 - 2:59:59.999</code> 等窗口。如果你想改变这一点，你可以给出一个偏移量。例如，如果偏移量为15分钟，您将得到 <code>1:15:00.000 - 2:14:59.999</code>，<code>2:15:00.000 - 3:14:59.999</code> 等。偏移量的一个重要用途是调整窗口到 UTC-0 以外的时区。例如，在中国，你必须指定一个 <code>Time.hours(-8)</code> 的偏移量。</p>
<h2 id="滑动窗口">滑动窗口</h2>
<p>滑动窗口分配器将元素分配给固定长度的窗口。与滚动窗口分配器类似，窗口的大小由窗口大小(window size)参数配置。一个额外的窗口滑动(window slide)参数控制滑动窗口的启动频率。因此，如果滑动窗口的滑块小于窗口大小，滑动窗口可以重叠。在这种情况下，元素被分配到多个窗口。</p>
<p>例如，你可以有10分钟大小的窗口，滑动5分钟。这样，每隔5分钟就会有一个窗口，包含过去10分钟内到达的事件，如下图所示。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/sliding-windows.svg" alt="img"></p>
<p>以下代码片段展示了如何使用滑动窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// sliding event-time windows
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">SlidingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// sliding processing-time windows
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">SlidingProcessingTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// sliding processing-time windows offset by -8 hours
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">SlidingProcessingTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">12</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(-</span><span class="mi">8</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>时间间隔可以通过使用 <code>Time.milliseconds(x)</code>, <code>Time.seconds(x)</code>, <code>Time.minutes(x)</code> 等中的一个来指定。</p>
<p>如上一个例子所示，滑动窗口分配器还可以采取一个可选的偏移量(<code>offset</code>)参数，用于改变窗口的对齐方式。例如，在没有偏移量的情况下，每小时滑动30分钟的窗口与纪元对齐，也就是说，你将得到 <code>1:00:00.000 - 1:59:59.999</code>，<code>1:30:00.000 - 2:29:59.999</code> 等窗口。如果你想改变这一点，你可以给出一个偏移量。例如，如果偏移量为15分钟，您将得到 <code>1:15:00.000 - 2:14:59.999</code>，<code>1:45:00.000 - 2:44:59.999</code> 等。偏移量的一个重要用途是调整窗口到 UTC-0 以外的时区。例如，在中国，你必须指定一个 <code>Time.hours(-8)</code> 的偏移。</p>
<h2 id="会话窗口">会话窗口</h2>
<p>会话窗口分配器按活动的会话对元素进行分组。与滚动窗口和滑动窗口不同，会话窗口不重叠，也没有固定的开始和结束时间。相反，当会话窗口在一定时间内没有接收到元素时，也就是在不活动的间隙发生时，会话窗口就会关闭。会话窗口分配器可以配置一个静态的会话间隙(session gap)，也可以配置一个会话间隙提取函数，该函数定义了多长时间的不活动期。当这个时间段(period)到期(expires)时，当前会话关闭，后续元素被分配到一个新的会话窗口。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/session-windows.svg" alt="img"></p>
<p>以下代码片段展示了如何使用会话窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// event-time session windows with static gap
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">EventTimeSessionWindows</span><span class="o">.</span><span class="n">withGap</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">minutes</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// event-time session windows with dynamic gap
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">EventTimeSessionWindows</span><span class="o">.</span><span class="n">withDynamicGap</span><span class="o">(</span><span class="k">new</span> <span class="nc">SessionWindowTimeGapExtractor</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="o">{</span>
      <span class="k">override</span> <span class="k">def</span> <span class="n">extract</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// determine and return session gap
</span><span class="c1"></span>      <span class="o">}</span>
    <span class="o">}))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="c1">// processing-time session windows with static gap
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">ProcessingTimeSessionWindows</span><span class="o">.</span><span class="n">withGap</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">minutes</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>


<span class="c1">// processing-time session windows with dynamic gap
</span><span class="c1"></span><span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">DynamicProcessingTimeSessionWindows</span><span class="o">.</span><span class="n">withDynamicGap</span><span class="o">(</span><span class="k">new</span> <span class="nc">SessionWindowTimeGapExtractor</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="o">{</span>
      <span class="k">override</span> <span class="k">def</span> <span class="n">extract</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// determine and return session gap
</span><span class="c1"></span>      <span class="o">}</span>
    <span class="o">}))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>静态间隙可以通过使用 <code>Time.milliseconds(x)</code>, <code>Time.seconds(x)</code>, <code>Time.minutes(x)</code> 等之一来指定。</p>
<p>动态间隙可以通过实现 <code>SessionWindowTimeGapExtractor</code> 接口来指定。</p>
<p>注意: 由于会话窗口没有固定的开始和结束，所以它们的评估方式与滚动和滑动窗口不同。在内部，会话窗口操作符为每个到达的记录创建一个新的窗口，如果它们彼此之间的距离比定义的间隙更近，就会将窗口合并在一起。为了能够合并，会话窗口操作符需要一个合并<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#triggers">触发器</a>和一个合并<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-functions">窗口函数</a>，如 ReduceFunction、AggregateFunction 或 ProcessWindowFunction(FoldFunction 不能合并)。</p>
<h2 id="全局窗口">全局窗口</h2>
<p>全局窗口分配器将具有相同键的所有元素分配到同一个全局窗口。只有当你还指定了一个自定义<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#triggers">触发器</a>时，这种窗口方案才有用。否则，任何计算都不会被执行，因为全局窗口没有一个自然的终点，我们可以在那里处理聚集的元素。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/non-windowed.svg" alt="img"></p>
<p>下面的代码片段展示了如何使用全局窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">GlobalWindows</span><span class="o">.</span><span class="n">create</span><span class="o">())</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><h2 id="窗口函数">窗口函数</h2>
<p>在定义了窗口分配器之后，我们需要指定我们要对这些窗口中的每一个窗口进行的计算。这是窗口函数的责任，一旦系统确定一个窗口准备好进行处理，它就会用来处理每个（可能是 keyed 的）窗口的元素（关于 Flink 如何确定窗口准备好，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#triggers">触发器</a>）。</p>
<p>窗口函数可以是 <code>ReduceFunction</code>、<code>AggregateFunction</code>、<code>FoldFunction</code> 或 <code>ProcessWindowFunction</code> 中的一种。前两个可以更有效地执行（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#state%20size">状态大小</a>部分），因为 Flink 可以在每个窗口到达时增量地聚合元素。<code>ProcessWindowFunction</code> 可以为一个窗口中包含的所有元素获取一个 <code>Iterable</code>，以及关于元素所属窗口的附加元信息。</p>
<p>带有 <code>ProcessWindowFunction</code> 的窗口化转换不能像其他情况一样高效执行，因为 Flink 在调用函数之前必须在内部缓冲一个窗口的所有元素。通过将 <code>ProcessWindowFunction</code> 与 <code>ReduceFunction</code>、<code>AggregateFunction</code> 或 <code>FoldFunction</code> 结合起来，既可以得到窗口元素的增量聚合，也可以得到 <code>ProcessWindowFunction</code> 接收到的额外的窗口元数据，从而缓解这种情况。我们将查看这些变体的每个例子。</p>
<h3 id="reducefunction">ReduceFunction</h3>
<p><code>ReduceFunction</code> 指定了如何将输入的两个元素组合起来以产生相同类型的输出元素。Flink 使用 <code>ReduceFunction</code> 来增量聚合一个窗口的元素。</p>
<p><code>ReduceFunction</code> 可以这样定义和使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">(</span><span class="n">v1</span><span class="o">,</span> <span class="n">v2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">v1</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">v1</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">v2</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="o">}</span>
</code></pre></div><p>上面的例子把一个窗口中所有元素的元组的第二个字段相加起来。</p>
<h3 id="aggregatefunction">AggregateFunction</h3>
<p><code>AggregateFunction</code> 是 <code>ReduceFunction</code> 的通用版本，它有三种类型：输入类型（IN）、累加器类型（ACC）和输出类型（OUT）。输入类型是输入流中元素的类型，AggregateFunction 有一个方法用于将一个输入元素添加到累加器中。该接口还有创建一个初始累加器、将两个累加器合并成一个累加器以及从一个累加器中提取一个输出（类型为 OUT）的方法。我们将在下面的例子中看到这些方法是如何工作的。</p>
<p>和 ReduceFunction 一样，Flink 会在窗口的输入元素到达时，对它们进行增量聚合。</p>
<p>AggregateFunction 可以这样定义和使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/**
</span><span class="cm"> * The accumulator is used to keep a running sum and a count. The [getResult] method
</span><span class="cm"> * computes the average.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">AverageAggregate</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="kt">Double</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span> <span class="k">=</span> <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">add</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Long</span><span class="o">),</span> <span class="n">accumulator</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span>
    <span class="o">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="mi">1L</span><span class="o">)</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResult</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_1</span> <span class="o">/</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_2</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">),</span> <span class="n">b</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span>
    <span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="k">new</span> <span class="nc">AverageAggregate</span><span class="o">)</span>
</code></pre></div><p>上面的例子是计算窗口中元素的第二个字段的平均值。</p>
<h3 id="foldfunction">FoldFunction</h3>
<p>FoldFunction 指定了窗口的输入元素如何与输出类型的元素相结合。对于添加到窗口的每个元素和当前的输出值，都会递增地调用 FoldFunction。第一个元素与输出类型的预定义初始值相结合。</p>
<p>可以这样定义和使用 FoldFunction。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">fold</span><span class="o">(</span><span class="s">&#34;&#34;</span><span class="o">)</span> <span class="o">{</span> <span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">v</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">acc</span> <span class="o">+</span> <span class="n">v</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
</code></pre></div><p>上面的例子将所有输入的 Long 值追加到一个初始的空字符串中。</p>
<p>注意 <code>fold()</code> 不能用于会话窗口或其他可合并窗口。</p>
<h3 id="processwindowfunction">ProcessWindowFunction</h3>
<p>ProcessWindowFunction 得到一个包含窗口所有元素的 Iterable，以及一个可以访问时间和状态信息的 Context 对象，这使得它能够提供比其他窗口函数更多的灵活性。这是以性能和资源消耗为代价的，因为元素不能增量聚合，而是需要在内部缓冲，直到窗口被认为可以处理为止。</p>
<p>ProcessWindowFunction 的签名如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">abstract</span> <span class="k">class</span> <span class="nc">ProcessWindowFunction</span><span class="o">[</span><span class="kt">IN</span>, <span class="kt">OUT</span>, <span class="kt">KEY</span>, <span class="kt">W</span> <span class="k">&lt;:</span> <span class="kt">Window</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Function</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Evaluates the window and outputs none or several elements.
</span><span class="cm">    *
</span><span class="cm">    * @param key      The key for which this window is evaluated.
</span><span class="cm">    * @param context  The context in which the window is being evaluated.
</span><span class="cm">    * @param elements The elements in the window being evaluated.
</span><span class="cm">    * @param out      A collector for emitting elements.
</span><span class="cm">    * @throws Exception The function may throw exceptions to fail the program and trigger recovery.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">process</span><span class="o">(</span>
      <span class="n">key</span><span class="k">:</span> <span class="kt">KEY</span><span class="o">,</span>
      <span class="n">context</span><span class="k">:</span> <span class="kt">Context</span><span class="o">,</span>
      <span class="n">elements</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">IN</span><span class="o">],</span>
      <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">OUT</span><span class="o">])</span>

  <span class="cm">/**
</span><span class="cm">    * The context holding window metadata
</span><span class="cm">    */</span>
  <span class="k">abstract</span> <span class="k">class</span> <span class="nc">Context</span> <span class="o">{</span>
    <span class="cm">/**
</span><span class="cm">      * Returns the window that is being evaluated.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">window</span><span class="k">:</span> <span class="kt">W</span>

    <span class="cm">/**
</span><span class="cm">      * Returns the current processing time.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">currentProcessingTime</span><span class="k">:</span> <span class="kt">Long</span>

    <span class="cm">/**
</span><span class="cm">      * Returns the current event-time watermark.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">currentWatermark</span><span class="k">:</span> <span class="kt">Long</span>

    <span class="cm">/**
</span><span class="cm">      * State accessor for per-key and per-window state.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">windowState</span><span class="k">:</span> <span class="kt">KeyedStateStore</span>

    <span class="cm">/**
</span><span class="cm">      * State accessor for per-key global state.
</span><span class="cm">      */</span>
    <span class="k">def</span> <span class="n">globalState</span><span class="k">:</span> <span class="kt">KeyedStateStore</span>
  <span class="o">}</span>

<span class="o">}</span>
</code></pre></div><p>注意 <code>key</code> 参数是通过为 <code>keyBy()</code> 调用指定的 <code>KeySelector</code> 提取的键。如果是元组索引键或字符串字段引用，这个键的类型总是 Tuple，你必须手动将其转换为一个正确大小的元组来提取键字段。</p>
<p><code>ProcessWindowFunction</code> 可以这样定义和使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
  <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">minutes</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
  <span class="o">.</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyProcessWindowFunction</span><span class="o">())</span>

<span class="cm">/* ... */</span>

<span class="k">class</span> <span class="nc">MyProcessWindowFunction</span> <span class="k">extends</span> <span class="nc">ProcessWindowFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">TimeWindow</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">context</span><span class="k">:</span> <span class="kt">Context</span><span class="o">,</span> <span class="n">input</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)],</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">var</span> <span class="n">count</span> <span class="k">=</span> <span class="mi">0L</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">in</span> <span class="k">&lt;-</span> <span class="n">input</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">count</span> <span class="k">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="o">}</span>
    <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="s">s&#34;Window </span><span class="si">${</span><span class="n">context</span><span class="o">.</span><span class="n">window</span><span class="si">}</span><span class="s"> count: </span><span class="si">$count</span><span class="s">&#34;</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>这个例子显示了一个 <code>ProcessWindowFunction</code>，它可以计算一个窗口中的元素。此外，窗口函数还将窗口的信息添加到输出中。</p>
<p>注意，使用 ProcessWindowFunction 进行简单的聚合，如 <code>count</code>，效率相当低。下一节将展示如何将 <code>ReduceFunction</code> 或 <code>AggregateFunction</code> 与 <code>ProcessWindowFunction</code> 结合起来，以获得增量聚合和 <code>ProcessWindowFunction</code> 的附加信息。</p>
<h3 id="具有增量聚合功能的-processwindowfunction">具有增量聚合功能的 ProcessWindowFunction</h3>
<p><code>ProcessWindowFunction</code> 可以与 <code>ReduceFunction</code>、<code>AggregateFunction</code> 或 <code>FoldFunction</code> 相结合，以在元素到达窗口时进行增量聚合。当窗口关闭时，<code>ProcessWindowFunction</code> 将被提供聚合的结果。这使得它可以增量计算窗口，同时可以访问 <code>ProcessWindowFunction</code> 的附加窗口元信息。</p>
<p>注意 您也可以使用 legacy WindowFunction 代替 ProcessWindowFunction 进行增量窗口聚合。</p>
<h4 id="使用-reducefunction-进行增量窗口聚合">使用 ReduceFunction 进行增量窗口聚合</h4>
<p>下面的例子展示了如何将增量 ReduceFunction 与 ProcessWindowFunction 相结合，以返回窗口中最小的事件以及窗口的开始时间。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">SensorReading</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
  <span class="o">.</span><span class="n">timeWindow</span><span class="o">(&lt;</span><span class="n">duration</span><span class="o">&gt;)</span>
  <span class="o">.</span><span class="n">reduce</span><span class="o">(</span>
    <span class="o">(</span><span class="n">r1</span><span class="k">:</span> <span class="kt">SensorReading</span><span class="o">,</span> <span class="n">r2</span><span class="k">:</span> <span class="kt">SensorReading</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span> <span class="k">if</span> <span class="o">(</span><span class="n">r1</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="n">r2</span><span class="o">.</span><span class="n">value</span><span class="o">)</span> <span class="n">r2</span> <span class="k">else</span> <span class="n">r1</span> <span class="o">},</span>
    <span class="o">(</span> <span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
      <span class="n">context</span><span class="k">:</span> <span class="kt">ProcessWindowFunction</span><span class="o">[</span><span class="k">_</span>, <span class="k">_</span>, <span class="k">_</span>, <span class="kt">TimeWindow</span><span class="o">]</span><span class="k">#</span><span class="nc">Context</span><span class="o">,</span>
      <span class="n">minReadings</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">SensorReading</span><span class="o">],</span>
      <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">SensorReading</span><span class="o">)]</span> <span class="o">)</span> <span class="k">=&gt;</span>
      <span class="o">{</span>
        <span class="k">val</span> <span class="n">min</span> <span class="k">=</span> <span class="n">minReadings</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">context</span><span class="o">.</span><span class="n">window</span><span class="o">.</span><span class="n">getStart</span><span class="o">,</span> <span class="n">min</span><span class="o">))</span>
      <span class="o">}</span>
  <span class="o">)</span>
</code></pre></div><h4 id="用-aggregatefunction-进行增量窗口聚合">用 AggregateFunction 进行增量窗口聚合</h4>
<p>下面的例子展示了如何将增量的 AggregateFunction 与 ProcessWindowFunction 结合起来，计算平均值，同时将键和窗口与平均值一起发出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
  <span class="o">.</span><span class="n">timeWindow</span><span class="o">(&lt;</span><span class="n">duration</span><span class="o">&gt;)</span>
  <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="k">new</span> <span class="nc">AverageAggregate</span><span class="o">(),</span> <span class="k">new</span> <span class="nc">MyProcessWindowFunction</span><span class="o">())</span>

<span class="c1">// Function definitions
</span><span class="c1"></span>
<span class="cm">/**
</span><span class="cm"> * The accumulator is used to keep a running sum and a count. The [getResult] method
</span><span class="cm"> * computes the average.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">AverageAggregate</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="kt">Double</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">()</span> <span class="k">=</span> <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">add</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Long</span><span class="o">),</span> <span class="n">accumulator</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span>
    <span class="o">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="mi">1L</span><span class="o">)</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResult</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_1</span> <span class="o">/</span> <span class="n">accumulator</span><span class="o">.</span><span class="n">_2</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">),</span> <span class="n">b</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">))</span> <span class="k">=</span>
    <span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">class</span> <span class="nc">MyProcessWindowFunction</span> <span class="k">extends</span> <span class="nc">ProcessWindowFunction</span><span class="o">[</span><span class="kt">Double</span>, <span class="o">(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)</span>, <span class="kt">String</span>, <span class="kt">TimeWindow</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">context</span><span class="k">:</span> <span class="kt">Context</span><span class="o">,</span> <span class="n">averages</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Double</span><span class="o">)])</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">average</span> <span class="k">=</span> <span class="n">averages</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
    <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">key</span><span class="o">,</span> <span class="n">average</span><span class="o">))</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h4 id="用-foldfunction-进行增量窗口聚合">用 FoldFunction 进行增量窗口聚合</h4>
<p>下面的例子展示了如何将增量式 FoldFunction 与 ProcessWindowFunction 相结合，以提取窗口中的事件数量，并返回窗口的键和结束时间。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">SensorReading</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
 <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
 <span class="o">.</span><span class="n">timeWindow</span><span class="o">(&lt;</span><span class="n">duration</span><span class="o">&gt;)</span>
 <span class="o">.</span><span class="n">fold</span> <span class="o">(</span>
    <span class="o">(</span><span class="s">&#34;&#34;</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
    <span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Long</span><span class="o">,</span> <span class="nc">Int</span><span class="o">),</span> <span class="n">r</span><span class="k">:</span> <span class="kt">SensorReading</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span> <span class="o">(</span><span class="s">&#34;&#34;</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="n">acc</span><span class="o">.</span><span class="n">_3</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">},</span>
    <span class="o">(</span> <span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
      <span class="n">window</span><span class="k">:</span> <span class="kt">TimeWindow</span><span class="o">,</span>
      <span class="n">counts</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)],</span>
      <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="o">)</span> <span class="k">=&gt;</span>
      <span class="o">{</span>
        <span class="k">val</span> <span class="n">count</span> <span class="k">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">next</span><span class="o">()</span>
        <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">key</span><span class="o">,</span> <span class="n">window</span><span class="o">.</span><span class="n">getEnd</span><span class="o">,</span> <span class="n">count</span><span class="o">.</span><span class="n">_3</span><span class="o">))</span>
      <span class="o">}</span>
  <span class="o">)</span>
</code></pre></div><h4 id="在-processwindowfunction-中使用-per-窗口状态">在 ProcessWindowFunction 中使用 per-窗口状态</h4>
<p>除了访问 keyed 状态（任何富函数都可以），ProcessWindowFunction 还可以使用 keyed 状态，该状态的作用域是函数当前正在处理的窗口。在这种情况下，理解每个窗口状态所指的窗口是什么很重要。这里涉及到不同的&quot;窗口&quot;。</p>
<ul>
<li>窗口是在指定窗口操作时定义的。这可能是1小时的滚动窗口或者2小时的滑动窗口，滑动1小时。</li>
<li>一个给定的键的定义窗口的实际实例。这可能是 12: 00 到 13: 00 的时间窗口，用户 ID xyz. 这是基于窗口定义的，会有很多窗口，基于作业当前正在处理的键的数量，基于事件属于什么时间段。</li>
</ul>
<p>每个窗口的状态与这两者中的后一种挂钩。意思是说，如果我们处理了1000个不同键的事件，并且所有键的事件当前都属于 <code>[12:00，13:00)</code> 时间窗口，那么将有1000个窗口实例，每个窗口都有自己的键的per-窗口状态。</p>
<p><code>process()</code> 调用接收到的 Context 对象上有两个方法允许访问这两种类型的状态。</p>
<ul>
<li><code>globalState()</code>，允许访问不在窗口范围内的 keyed 状态。</li>
<li><code>windowState()</code>，它允许访问同样作用于窗口的 keyed 状态。</li>
</ul>
<p>如果你预计同一窗口会有多次发射，那么这个功能是很有帮助的，因为当你对晚到的数据有晚发射的情况，或者当你有一个自定义的触发器，做投机性的早期发射时，可能会发生这种情况。在这种情况下，你会在每个窗口状态下存储之前的发射信息或发射次数。</p>
<p>当使用窗口状态时，重要的是当窗口被清除时也要清理该状态。这应该发生在 <code>clear()</code> 方法中。</p>
<h3 id="windowfunctionlegacy">WindowFunction(Legacy)</h3>
<p>在一些可以使用 <code>ProcessWindowFunction</code> 的地方，你也可以使用 <code>WindowFunction</code>。这是 <code>ProcessWindowFunction</code> 的旧版本，它提供的上下文信息较少，而且没有一些先进的功能，比如每个窗口的 keyed 状态。这个接口在某些时候会被废弃。</p>
<p>WindowFunction 的签名如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">trait</span> <span class="nc">WindowFunction</span><span class="o">[</span><span class="kt">IN</span>, <span class="kt">OUT</span>, <span class="kt">KEY</span>, <span class="kt">W</span> <span class="k">&lt;:</span> <span class="kt">Window</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Function</span> <span class="k">with</span> <span class="nc">Serializable</span> <span class="o">{</span>

  <span class="cm">/**
</span><span class="cm">    * Evaluates the window and outputs none or several elements.
</span><span class="cm">    *
</span><span class="cm">    * @param key    The key for which this window is evaluated.
</span><span class="cm">    * @param window The window that is being evaluated.
</span><span class="cm">    * @param input  The elements in the window being evaluated.
</span><span class="cm">    * @param out    A collector for emitting elements.
</span><span class="cm">    * @throws Exception The function may throw exceptions to fail the program and trigger recovery.
</span><span class="cm">    */</span>
  <span class="k">def</span> <span class="n">apply</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">KEY</span><span class="o">,</span> <span class="n">window</span><span class="k">:</span> <span class="kt">W</span><span class="o">,</span> <span class="n">input</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">IN</span><span class="o">],</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">OUT</span><span class="o">])</span>
<span class="o">}</span>
</code></pre></div><p>可以这样使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">apply</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyWindowFunction</span><span class="o">())</span>
</code></pre></div><h3 id="触发器">触发器</h3>
<p>触发器决定一个窗口（由窗口分配器形成）何时可以被窗口函数处理。每个 <code>WindowAssigner</code> 都有一个默认的触发器。如果默认的触发器不符合你的需求，你可以使用 <code>trigger(...)</code> 指定一个自定义的触发器。</p>
<p>触发器接口有五个方法，允许 Trigger 对不同的事件做出反应。</p>
<ul>
<li><code>onElement()</code> 方法对每个添加到窗口的元素都会被调用。</li>
<li><code>onEventTime()</code> 方法在注册的事件时间定时器启动时被调用。</li>
<li><code>onProcessingTime()</code> 方法在注册的处理时间计时器启动时被调用。</li>
<li><code>onMerge()</code> 方法与有状态的触发器相关，当两个触发器的对应窗口合并时，例如使用会话窗口时，就会合并两个触发器的状态。</li>
<li>最后 <code>clear()</code> 方法在删除相应窗口时执行任何需要的操作。</li>
</ul>
<p>关于以上方法有两点需要注意。</p>
<p>1）前三个方法通过返回一个 <code>TriggerResult</code> 来决定如何对其调用事件采取行动。动作可以是以下之一。</p>
<ul>
<li>CONTINUE：什么也不做。</li>
<li>FIRE：触发计算。</li>
<li>PURGE：清除窗口中的元素，以及</li>
<li>FIRE_AND_PURGE：触发计算，之后清除窗口中的元素。</li>
</ul>
<ol start="2">
<li>这些方法中的任何一种都可以用来注册处理时间或事件时间的定时器，以备将来的操作。</li>
</ol>
<h3 id="fire-和-purge">Fire 和 Purge</h3>
<p>一旦触发器确定一个窗口可以处理，它就会发射，即返回 FIRE 或 FIRE_AND_PURGE。这是窗口操作者发出当前窗口结果的信号。给定一个带有 ProcessWindowFunction 的窗口，所有的元素都会被传递给 ProcessWindowFunction（可能是在将它们传递给 evictor 之后）。带有 ReduceFunction、AggregateFunction 或 FoldFunction 的窗口只是简单地发出它们急切的聚合结果。</p>
<p>当一个触发器发射时，它可以是 FIRE 或 FIRE_AND_PURGE。FIRE 保留窗口的内容，而 FIRE_AND_PURGE 则删除其内容。默认情况下，预先实现的触发器只是 FIRE 而不清除窗口状态。</p>
<p>注意 Purging 将简单地删除窗口的内容，并将完整地保留任何关于窗口和任何触发状态的潜在元信息。</p>
<h3 id="窗口分配器的默认触发器">窗口分配器的默认触发器</h3>
<p>WindowAssigner 的默认触发器适合于许多用例。例如，所有的事件时间窗口分配器都有一个 EventTimeTrigger 作为默认触发器。这个触发器仅仅是在水印通过窗口结束后就会触发。</p>
<p>注意：GlobalWindow 的默认触发器是 NeverTrigger，它永远不会触发。因此，在使用 GlobalWindow 时，您必须定义一个自定义的触发器。</p>
<p>注意：通过使用 trigger() 指定一个触发器，您将覆盖一个 WindowAssigner 的默认触发器。例如，如果你为 TumblingEventTimeWindows 指定了一个 CountTrigger，你将不再获得基于时间进度的窗口启动，而只能通过计数来获得。现在，如果你想同时基于时间和计数做出反应，你必须编写自己的自定义触发器。</p>
<h3 id="内置和自定义触发器">内置和自定义触发器</h3>
<p>Flink 内置了一些触发器。</p>
<ul>
<li>前面已经提到过的, EventTimeTrigger 会根据水印测量的事件时间的进展而触发。</li>
<li>处理时间触发器（ProcessingTimeTrigger）基于处理时间而触发。</li>
<li>CountTrigger 在一个窗口中的元素数量超过给定的限制时触发。</li>
<li>PurgingTrigger 将另一个触发器作为参数，并将其转换为一个清洗触发器。</li>
</ul>
<p>如果你需要实现一个自定义的触发器，你应该查看抽象的 <a href="https://github.com/apache/flink/blob/master//flink-streaming-java/src/main/java/org/apache/flink/streaming/api/windowing/triggers/Trigger.java">Trigger</a> 类。请注意，API 仍在不断发展，可能会在 Flink 的未来版本中改变。</p>
<h3 id="evictors">Evictors</h3>
<p>Flink 的窗口模型允许在 WindowAssigner 和 Trigger 之外指定一个可选的 Evictor。这可以通过 <code>evictor(...)</code> 方法来完成（如本文开头所示）。Evictor 能够在触发器触发后和应用窗口函数之前和/或之后从窗口中移除元素。要做到这一点，Evictor 接口有两个方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * Optionally evicts elements. Called before windowing function.
</span><span class="cm"> *
</span><span class="cm"> * @param elements The elements currently in the pane.
</span><span class="cm"> * @param size The current number of elements in the pane.
</span><span class="cm"> * @param window The {@link Window}
</span><span class="cm"> * @param evictorContext The context for the Evictor
</span><span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">evictBefore</span><span class="o">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">TimestampedValue</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="n">elements</span><span class="o">,</span> <span class="kt">int</span> <span class="n">size</span><span class="o">,</span> <span class="n">W</span> <span class="n">window</span><span class="o">,</span> <span class="n">EvictorContext</span> <span class="n">evictorContext</span><span class="o">);</span>

<span class="cm">/**
</span><span class="cm"> * Optionally evicts elements. Called after windowing function.
</span><span class="cm"> *
</span><span class="cm"> * @param elements The elements currently in the pane.
</span><span class="cm"> * @param size The current number of elements in the pane.
</span><span class="cm"> * @param window The {@link Window}
</span><span class="cm"> * @param evictorContext The context for the Evictor
</span><span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">evictAfter</span><span class="o">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">TimestampedValue</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="n">elements</span><span class="o">,</span> <span class="kt">int</span> <span class="n">size</span><span class="o">,</span> <span class="n">W</span> <span class="n">window</span><span class="o">,</span> <span class="n">EvictorContext</span> <span class="n">evictorContext</span><span class="o">);</span>
</code></pre></div><p><code>evictBefore()</code> 包含在窗口函数之前应用的驱逐逻辑，而 <code>evictAfter()</code> 包含在窗口函数之后应用的逻辑。在应用窗口函数之前被驱逐的元素将不会被它处理。</p>
<p>Flink 自带了三个预先实现的驱逐器。这三个是:</p>
<ul>
<li>CountEvictor：从窗口中保留最多用户指定数量的元素，并从窗口缓冲区开始丢弃剩余的元素。</li>
<li>DeltaEvictor：取 DeltaFunction 和阈值，计算窗口缓冲区中最后一个元素和剩余元素之间的 delta，并删除 delta 大于或等于阈值的元素。</li>
<li>TimeEvictor：以毫秒为单位的时间间隔作为参数，对于一个给定的窗口，它在其元素中找到最大的时间戳 max_ts，并删除所有时间戳小于 max_ts - interval 的元素。</li>
</ul>
<p>默认情况下，所有预先实现的 evictor 都会在 window 函数之前应用其逻辑。</p>
<p>注意: 指定一个 evictor 可以防止任何预聚集，因为一个窗口的所有元素都必须在应用计算之前传递给 evictor。</p>
<p>注意 Flink 不保证窗口内元素的顺序。这意味着，虽然 evictor 可以从窗口的开头移除元素，但这些元素不一定是最先或最后到达的。</p>
<h2 id="允许的延迟">允许的延迟</h2>
<p>当使用事件时间窗口时，可能会发生元素迟到的情况，也就是说，Flink 用来跟踪事件时间进度的水印已经超过了元素所属窗口的结束时间戳。关于 Flink 如何处理事件时间，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间</a>，尤其是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html#late-elements">迟到元素</a>。</p>
<p>默认情况下，当水印超过窗口的结束时间时，晚期元素就会被删除。然而，Flink 允许为窗口操作者指定一个最大允许延迟。允许延迟指定了元素在被丢弃之前可以迟到多少时间，其默认值为0。 在水印通过窗口结束后但在其通过窗口结束前加上允许延迟之前到达的元素，仍然会被添加到窗口中。根据所使用的触发器，一个迟到但未被丢弃的元素可能会导致窗口再次启动。EventTimeTrigger 就属于这种情况。</p>
<p>为了使这个工作，Flink 会保持窗口的状态，直到它们的允许延迟过期。一旦发生这种情况，Flink 就会删除窗口并删除其状态，这一点在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-lifecycle">窗口生命周期</a>部分也有描述。</p>
<p>默认情况下，允许的延迟被设置为0，也就是说，到达水印后面的元素将被丢弃。</p>
<p>您可以像这样指定允许的延迟。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">allowedLateness</span><span class="o">(&lt;</span><span class="n">time</span><span class="o">&gt;)</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>注意 当使用 GlobalWindows 窗口分配器时，由于全局窗口的结束时间戳是 Long.MAX_VALUE，因此没有数据被认为是迟到数据。</p>
<h3 id="作为侧输出获取迟到数据">作为侧输出获取迟到数据</h3>
<p>使用 Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/side_output.html">侧输出</a>功能，你可以得到一个被丢弃的迟到数据流。</p>
<p>首先，你需要在窗口化的数据流上使用 <code>sideOutputLateData(OutputTag)</code> 来指定你要获取迟到的数据。然后，你就可以在窗口化操作的结果上得到侧输出流。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">lateOutputTag</span> <span class="k">=</span> <span class="nc">OutputTag</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="s">&#34;late-data&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">allowedLateness</span><span class="o">(&lt;</span><span class="n">time</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">sideOutputLateData</span><span class="o">(</span><span class="n">lateOutputTag</span><span class="o">)</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>

<span class="k">val</span> <span class="n">lateStream</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">getSideOutput</span><span class="o">(</span><span class="n">lateOutputTag</span><span class="o">)</span>
</code></pre></div><h4 id="迟到元素的考虑">迟到元素的考虑</h4>
<p>当指定允许的延迟大于0时，在水印通过窗口结束后，窗口及其内容将被保留。在这些情况下，当一个迟到但未被丢弃的元素到达时，它可能会触发窗口的另一次发射。这些发射被称为晚期发射，因为它们是由晚期事件触发的，与主发射相反，主发射是窗口的第一次发射。在会话窗口的情况下，迟发可能会进一步导致窗口的合并，因为它们可能会&quot;弥合&quot;两个已经存在的、未合并的窗口之间的差距。</p>
<p>注意：你应该意识到，晚点发射的元素应该被视为之前计算的更新结果，也就是说，你的数据流将包含同一计算的多个结果。根据你的应用，你需要考虑到这些重复的结果，或者对它们进行重复复制。</p>
<h3 id="处理窗口结果">处理窗口结果</h3>
<p>窗口化操作的结果又是一个 DataStream，在结果元素中没有保留任何关于窗口化操作的信息，所以如果你想保留窗口的元信息，你必须在你的 <code>ProcessWindowFunction</code> 的结果元素中手动编码这些信息。在结果元素上设置的唯一相关信息是元素的时间戳。这被设置为处理过的窗口的最大允许时间戳，也就是结束时间戳-1，因为窗口结束时间戳是独占的。注意，这对事件时间窗口和处理时间窗口都是如此，即在窗口化操作后元素总是有一个时间戳，但这个时间戳可以是事件时间时间戳，也可以是处理时间时间戳。对于处理时间窗口来说，这没有特别的影响，但是对于事件时间窗口来说，加上水印与窗口的交互方式，使得<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#consecutive-windowed-operations">连续的窗口化操作</a>具有相同的窗口大小。我们将在看完水印如何与窗口交互后再谈这个问题。</p>
<h4 id="水印和窗口的交互">水印和窗口的交互</h4>
<p>在继续本节之前，你可能想看看我们关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间和水印</a>的章节。</p>
<p>当水印到达窗口操作符时，会触发两件事。</p>
<ul>
<li>水印会触发计算所有窗口的最大时间戳（就是结束时间戳-1）小于新水印的窗口。</li>
<li>水印被转发到下游的操作中</li>
</ul>
<p>直观地说，水印会&quot;冲掉&quot;任何在下游操作中被认为是晚期的窗口，一旦它们收到该水印。</p>
<h4 id="连续的窗口操作">连续的窗口操作</h4>
<p>如前所述，计算窗口化结果的时间戳的方式以及水印与窗口的交互方式允许将连续的窗口化操作串在一起。当你想进行两个连续的窗口化操作时，如果你想使用不同的键，但仍然希望来自同一个上游窗口的元素最终出现在同一个下游窗口中，这就很有用。考虑这个例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">resultsPerKey</span> <span class="k">=</span> <span class="n">input</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="k">new</span> <span class="nc">Summer</span><span class="o">())</span>

<span class="k">val</span> <span class="n">globalResults</span> <span class="k">=</span> <span class="n">resultsPerKey</span>
    <span class="o">.</span><span class="n">windowAll</span><span class="o">(</span><span class="nc">TumblingEventTimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.</span><span class="n">process</span><span class="o">(</span><span class="k">new</span> <span class="nc">TopKWindowFunction</span><span class="o">())</span>
</code></pre></div><p>在这个例子中，第一次操作的时间窗口 <code>[0，5)</code> 的结果也会在随后的窗口操作中最终出现在时间窗口 <code>[0，5)</code>。这样就可以计算每个键的和，然后在第二个操作中计算同一窗口内的 top-k 元素。</p>
<h3 id="有用的状态大小考虑">有用的状态大小考虑</h3>
<p>窗口可以在很长一段时间内（如几天、几周或几个月）被定义，因此会积累非常大的状态。在估算窗口计算的存储需求时，有几个规则需要牢记。</p>
<ol>
<li>
<p>Flink 为每个元素所属的窗口创建一个副本。鉴于此，翻滚窗口为每个元素保留一个副本（一个元素正好属于一个窗口，除非它被后期丢弃）。相比之下，滑动窗口会给每个元素创建若干个，这一点在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#window-assigners">窗口分配器</a>部分有解释。因此，大小为1天，滑动1秒的滑动窗口可能不是一个好主意。</p>
</li>
<li>
<p>ReduceFunction、AggregateFunction 和 FoldFunction 可以显著降低存储要求，因为它们热衷于聚合元素，每个窗口只存储一个值。相比之下，仅仅使用 ProcessWindowFunction 就需要累积所有元素。</p>
</li>
<li>
<p>使用 Evictor 可以防止任何预聚集，因为一个窗口的所有元素都必须在应用计算之前通过 evictor（见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#evictors">Evictor</a>）。</p>
</li>
</ol>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/operators" term="operators" label="Operators" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/windows" term="windows" label="Windows" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[自定义序列化管理状态]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-custom-serialization-for-managed-state/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-custom-serialization-for-managed-state/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Custom Serialization for Managed State</blockquote><p>本页面的目标是为需要使用自定义状态序列化的用户提供指导，涵盖了如何提供自定义状态序列化器，以及实现允许状态模式演化的序列化器的指南和最佳实践。</p>
<p>如果你只是简单地使用 Flink 自带的序列化器，这个页面是不相关的，可以忽略。</p>
<h2 id="使用自定义状态序列化器">使用自定义状态序列化器</h2>
<p>当注册一个 managed operator 或 keyed state时，需要一个 <code>StateDescriptor</code> 来指定状态的名称，以及状态的类型信息。类型信息被 Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html">类型序列化框架</a>用来为状态创建合适的序列化器。</p>
<p>也可以完全绕过这一点，让 Flink 使用自己的自定义序列化器来序列化被管理的状态，只需用自己的 <code>TypeSerializer</code> 实现直接实例化 <code>StateDescriptor</code> 即可。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">CustomTypeSerializer</span> <span class="k">extends</span> <span class="nc">TypeSerializer</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Integer</span><span class="o">)]</span> <span class="o">{...}</span>

<span class="k">val</span> <span class="n">descriptor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ListStateDescriptor</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Integer</span><span class="o">)](</span>
    <span class="s">&#34;state-name&#34;</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">CustomTypeSerializer</span><span class="o">)</span>
<span class="o">)</span>

<span class="n">checkpointedState</span> <span class="k">=</span> <span class="n">getRuntimeContext</span><span class="o">.</span><span class="n">getListState</span><span class="o">(</span><span class="n">descriptor</span><span class="o">)</span>
</code></pre></div><h3 id="状态序列化器和模式演进">状态序列化器和模式演进</h3>
<p>本节解释了与状态序列化和模式演进相关的面向用户的抽象，以及关于 Flink 如何与这些抽象交互的必要内部细节。</p>
<p>当从保存点恢复时，Flink 允许改变用于读取和写入先前注册状态的序列化器，因此用户不会被锁定在任何特定的序列化模式上。当状态被还原时，将为该状态注册一个新的序列化器（即在还原作业中用于访问状态的 <code>StateDescriptor</code> 所附带的序列化器）。这个新的序列化器可能与之前的序列化器的模式不同。因此，在实现状态序列化器时，除了读取/写入数据的基本逻辑外，另一个需要注意的重要问题是未来如何改变序列化模式。</p>
<p>说到 schema，在这里，这个术语可以互换，指的是状态类型的数据模型和状态类型的序列化二进制格式。一般来说，模式，可以为少数情况而改变。</p>
<ol>
<li>状态类型的数据模式发生了变化，即从 POJO 中增加或删除一个作为状态的字段。</li>
<li>一般来说，数据模式发生变化后，需要升级序列器的序列化格式。</li>
<li>序列器的配置发生了变化。</li>
</ol>
<p>为了让新的执行有状态的写入模式的信息，并检测模式是否发生了变化，在对操作符的状态进行保存点时，需要将状态序列器的快照和状态字节一起写入。这就是抽象出来的一个 <code>TypeSerializerSnapshot</code>，在下一小节解释。</p>
<h3 id="typeserializersnapshot-抽象"><code>TypeSerializerSnapshot</code> 抽象</h3>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">TypeSerializerSnapshot</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="nf">getCurrentVersion</span><span class="o">();</span>
    <span class="kt">void</span> <span class="nf">writeSnapshot</span><span class="o">(</span><span class="n">DataOuputView</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">;</span>
    <span class="kt">void</span> <span class="nf">readSnapshot</span><span class="o">(</span><span class="kt">int</span> <span class="n">readVersion</span><span class="o">,</span> <span class="n">DataInputView</span> <span class="n">in</span><span class="o">,</span> <span class="n">ClassLoader</span> <span class="n">userCodeClassLoader</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">;</span>
    <span class="n">TypeSerializerSchemaCompatibility</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nf">resolveSchemaCompatibility</span><span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">newSerializer</span><span class="o">);</span>
    <span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nf">restoreSerializer</span><span class="o">();</span>
<span class="o">}</span>
<span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">TypeSerializer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="o">{</span>    
    
    <span class="c1">// ...
</span><span class="c1"></span>    
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">TypeSerializerSnapshot</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nf">snapshotConfiguration</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>序列器的 TypeSerializerSnapshot 是一个时间点信息，它作为状态序列器的写模式的唯一真理来源，以及还原一个序列器所必须的任何额外信息，这些信息将与给定的时间点相同。关于在还原时应该写入和读取什么作为序列器快照的逻辑是在 <code>writeSnapshot和readSnapshot</code> 方法中定义的。</p>
<p>请注意，快照本身的写模式也可能需要随着时间的推移而改变（例如，当你希望在快照中添加更多关于序列器的信息时）。为了方便，快照是有版本的，在 <code>getCurrentVersion</code> 方法中定义了当前的版本号。在还原时，当从保存点读取序列器快照时，将向 <code>readSnapshot</code> 方法提供写入快照的模式的版本，以便读取实现可以处理不同的版本。</p>
<p>在还原时，检测新的序列器的模式是否改变的逻辑应该在 <code>resolveSchemaCompatibility</code> 方法中实现。当之前的注册状态在还原执行的操作符中再次注册新的序列化器时，新的序列化器会通过这个方法提供给之前序列化器的快照。该方法返回一个代表兼容性解决结果的 <code>TypeSerializerSchemaCompatibility</code>，它可以是以下之一。</p>
<ol>
<li><code>TypeSerializerSchemaCompatibility.compatibleAsIs()</code>：这个结果标志着新的序列化器是兼容的，这意味着新的序列化器与之前的序列化器具有相同的模式。有可能在resolveSchemaCompatibility方法中重新配置了新的序列化器，使其兼容。</li>
<li><code>TypeSerializerSchemaCompatibility.compatibleAfterMigration()</code>：这个结果标志着新的序列化器具有不同的序列化模式，可以从旧的模式迁移，使用之前的序列化器（识别旧的模式）将字节读入状态对象，然后用新的序列化器（识别新的模式）将对象重新写回字节。</li>
<li><code>TypeSerializerSchemaCompatibility.incompatible()</code>：这个结果标志着新的序列化器有不同的序列化模式，但不可能从旧模式迁移。</li>
</ol>
<p>最后一点细节是在需要迁移的情况下，如何获得之前的序列化器。序列化器的 <code>TypeSerializerSnapshot</code> 的另一个重要作用是，它可以作为一个工厂来恢复以前的序列化器。更具体地说，<code>TypeSerializerSnapshot</code> 应该实现 <code>restoreSerializer</code> 方法来实例化一个序列化器实例，该实例能够识别之前序列化器的模式和配置，因此可以安全地读取之前序列化器写入的数据。</p>
<h4 id="flink-如何与-typeserializer-和-typeserializersnapshot-抽象进行交互">Flink 如何与 TypeSerializer 和 TypeSerializerSnapshot 抽象进行交互</h4>
<p>总结一下，本节总结了 Flink，或者更具体地说，状态后端如何与抽象进行交互。根据状态后端的不同，交互略有不同，但这与状态序列化器及其序列化器快照的实现是正交的。</p>
<p><strong>离堆状态后端(如 RocksDBStateBackend)</strong></p>
<ol>
<li>用具有模式A的状态序列器注册新的状态。</li>
</ol>
<ul>
<li>注册的 TypeSerializer 用于在每次状态访问时读取/写入状态。</li>
<li>状态被写入模式A中。</li>
</ul>
<ol start="2">
<li>拍摄一个保存点</li>
</ol>
<ul>
<li>序列器快照是通过 <code>TypeSerializer#snapshotConfiguration</code> 方法提取的。</li>
<li>序列器快照被写入保存点，以及已经序列化的状态字节（模式A）。</li>
</ul>
<ol start="3">
<li>恢复的执行用新的状态序列化器重新访问恢复的状态字节，新的状态序列化器具有模式B。</li>
</ol>
<ul>
<li>前一个状态序列器的快照被还原。</li>
<li>状态字节在还原时不被反序列化，只被加载回状态后端（因此，仍在模式A中）。</li>
<li>接收到新的序列化器后，通过 <code>TypeSerializer#resolveSchemaCompatibility</code> 提供给被还原的前一个序列化器的快照，检查模式是否兼容。</li>
</ul>
<ol start="4">
<li>将后端中的状态字节从模式A迁移到模式B。</li>
</ol>
<ul>
<li>如果兼容性决议反映模式已经改变，并且可以进行迁移，则进行模式迁移。通过 <code>TypeSerializerSnapshot#restoreSerializer()</code>，将从序列化器快照中获取之前识别模式A的状态序列化器，并用于反序列化状态字节到对象，进而用新的序列化器再次重写，识别模式B，完成迁移。在继续处理之前，所有访问状态的条目全部迁移完毕。</li>
<li>如果解析信号为不兼容，则状态访问失败，出现异常。</li>
</ul>
<p><strong>堆状态后端（如 MemoryStateBackend、FsStateBackend）</strong>:</p>
<ol>
<li>用具有模式A的状态序列器注册新的状态。</li>
</ol>
<ul>
<li>注册的 TypeSerializer 由状态后端维护。</li>
</ul>
<ol start="2">
<li>拍摄一个保存点，将所有状态用模式A序列化。</li>
</ol>
<ul>
<li>序列器快照是通过 <code>TypeSerializer#snapshotConfiguration</code> 方法提取的。</li>
<li>序列化器快照被写入保存点。</li>
<li>现在状态对象被序列化到保存点，写入模式A中。</li>
</ul>
<ol start="3">
<li>在还原时，将状态反序列化为堆中的对象。</li>
</ol>
<ul>
<li>前一个状态序列器的快照被恢复。</li>
<li>通过 <code>TypeSerializerSnapshot#restoreSerializer()</code> 从序列化器快照中获取之前的序列化器，该序列化器识别模式A，用于将状态字节反序列化为对象。</li>
<li>从现在开始，所有的状态都已经被反序列化了。</li>
</ul>
<ol start="4">
<li>恢复后的执行用新的状态序列化器重新访问以前的状态，新的状态序列化器具有模式B。</li>
</ol>
<ul>
<li>在接收到新的序列化器后，通过 <code>TypeSerializer#resolveSchemaCompatibility</code> 提供给恢复之前序列化器的快照，以检查模式的兼容性。</li>
<li>如果兼容性检查发出需要迁移的信号，在这种情况下什么都不会发生，因为对于堆后端来说，所有的状态已经被反序列化为对象。</li>
<li>如果解析信号为不兼容，则状态访问失败，出现异常。</li>
</ul>
<ol start="5">
<li>再拍摄一个保存点，将所有状态用模式B序列化。</li>
</ol>
<ul>
<li>与步骤2.相同，但现在状态字节都在模式B中。</li>
</ul>
<h3 id="预先定义方便的-typeserializersnapshot-类">预先定义方便的 TypeSerializerSnapshot 类</h3>
<p>Flink 提供了两个抽象的基础 TypeSerializerSnapshot 类，可以用于典型场景。SimpleTypeSerializerSnapshot 和 CompositeTypeSerializerSnapshot。</p>
<p>提供这些预定义快照作为其序列化器快照的序列化器必须始终有自己独立的子类实现。这与不在不同的序列化器之间共享快照类的最佳实践相对应，这将在下一节中得到更详尽的解释。</p>
<h4 id="实现-simpletypeserializersnapshot">实现 SimpleTypeSerializerSnapshot</h4>
<p>SimpleTypeSerializerSnapshot 是为没有任何状态或配置的序列化器准备的，本质上意味着序列化器的序列化模式完全由序列化器的类来定义。</p>
<p>当使用 SimpleTypeSerializerSnapshot 作为你的序列化器的快照类时，兼容性解决只有2种可能的结果。</p>
<ul>
<li>TypeSerializerSchemaCompatibility.compatibleAsIs()，如果新的序列化器类保持相同，或</li>
<li>TypeSerializerSchemaCompatibility.incompatible()，如果新的序列化器类与之前的序列化器类不同。</li>
</ul>
<p>下面以 Flink 的 <code>IntSerializer</code> 为例，介绍 <code>SimpleTypeSerializerSnapshot</code> 的使用方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">IntSerializerSnapshot</span> <span class="kd">extends</span> <span class="n">SimpleTypeSerializerSnapshot</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="nf">IntSerializerSnapshot</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="n">IntSerializer</span><span class="o">.</span><span class="na">INSTANCE</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>IntSerializer 没有状态或配置。序列化格式完全由序列化器类自己定义，只能由另一个 IntSerializer 读取。因此，它适合 SimpleTypeSerializerSnapshot 的使用情况。</p>
<p>SimpleTypeSerializerSnapshot 的基础超级构造函数期望得到一个相应序列器实例的 Supplier，不管快照当前是在还原还是在快照期间写入。该 Supplier 用于创建还原序列化器，以及类型检查，以验证新序列化器是否属于相同的预期序列化器类。</p>
<h4 id="实现-compositetypeserializersnapshot">实现 CompositeTypeSerializerSnapshot</h4>
<p>CompositeTypeSerializerSnapshot 是为那些依赖于多个嵌套序列化器的序列化器而设计的。</p>
<p>在进一步解释之前，我们将依赖于多个嵌套序列化器的序列化器称为此上下文中的&quot;外部&quot;序列化器。这方面的例子可以是 MapSerializer、ListSerializer、GenericArraySerializer 等。例如，考虑 MapSerializer &ndash;键和值序列化器将是嵌套序列化器，而MapSerializer本身是 &ldquo;外部 &ldquo;序列化器。</p>
<p>在这种情况下，外层序列化器的快照也应该包含嵌套序列化器的快照，这样就可以独立检查嵌套序列化器的兼容性。在解决外层序列化器的兼容性时，需要考虑每个嵌套序列化器的兼容性。</p>
<p>提供 CompositeTypeSerializerSnapshot 是为了协助实现这类复合序列器的快照。它处理嵌套序列化器快照的读写，以及考虑到所有嵌套序列化器的兼容性，解析最终的兼容性结果。</p>
<p>下面以 Flink 的 MapSerializer 为例，介绍如何使用 CompositeTypeSerializerSnapshot。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MapSerializerSnapshot</span><span class="o">&lt;</span><span class="n">K</span><span class="o">,</span> <span class="n">V</span><span class="o">&gt;</span> <span class="kd">extends</span> <span class="n">CompositeTypeSerializerSnapshot</span><span class="o">&lt;</span><span class="n">Map</span><span class="o">&lt;</span><span class="n">K</span><span class="o">,</span> <span class="n">V</span><span class="o">&gt;,</span> <span class="n">MapSerializer</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">CURRENT_VERSION</span> <span class="o">=</span> <span class="n">1</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MapSerializerSnapshot</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">MapSerializer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="nf">MapSerializerSnapshot</span><span class="o">(</span><span class="n">MapSerializer</span><span class="o">&lt;</span><span class="n">K</span><span class="o">,</span> <span class="n">V</span><span class="o">&gt;</span> <span class="n">mapSerializer</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">mapSerializer</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getCurrentOuterSnapshotVersion</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">CURRENT_VERSION</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">MapSerializer</span> <span class="nf">createOuterSerializerWithNestedSerializers</span><span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="n">nestedSerializers</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">K</span><span class="o">&gt;</span> <span class="n">keySerializer</span> <span class="o">=</span> <span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">K</span><span class="o">&gt;)</span> <span class="n">nestedSerializers</span><span class="o">[</span><span class="n">0</span><span class="o">];</span>
        <span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">V</span><span class="o">&gt;</span> <span class="n">valueSerializer</span> <span class="o">=</span> <span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">V</span><span class="o">&gt;)</span> <span class="n">nestedSerializers</span><span class="o">[</span><span class="n">1</span><span class="o">];</span>
        <span class="k">return</span> <span class="k">new</span> <span class="n">MapSerializer</span><span class="o">&lt;&gt;(</span><span class="n">keySerializer</span><span class="o">,</span> <span class="n">valueSerializer</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="n">getNestedSerializers</span><span class="o">(</span><span class="n">MapSerializer</span> <span class="n">outerSerializer</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="o">{</span> <span class="n">outerSerializer</span><span class="o">.</span><span class="na">getKeySerializer</span><span class="o">(),</span> <span class="n">outerSerializer</span><span class="o">.</span><span class="na">getValueSerializer</span><span class="o">()</span> <span class="o">};</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>当实现一个新的序列器快照作为 CompositeTypeSerializerSnapshot 的子类时，必须实现以下三个方法。</p>
<ul>
<li><code>#getCurrentOuterSnapshotVersion()</code>。该方法定义了当前外部序列化器快照的序列化二进制格式的版本。</li>
<li><code>#getNestedSerializers(TypeSerializer)</code>。给定外部序列化器，返回其嵌套的序列化器。</li>
<li><code>#createOuterSerializerWithNestedSerializers(TypeSerializer[])</code>。给定嵌套的序列化器，创建一个外部序列化器的实例。</li>
</ul>
<p>上面的例子是一个 CompositeTypeSerializerSnapshot，除了嵌套的序列化器的快照外，没有额外的信息需要快照。因此，可以预期其外部快照版本永远不需要上报。然而，其他一些序列化器，包含一些额外的静态配置，需要和嵌套的组件序列化器一起持久化。一个例子是 Flink 的 GenericArraySerializer，除了嵌套的元素序列化器之外，它还包含了数组元素类型的类作为配置。</p>
<p>在这些情况下，需要在 CompositeTypeSerializerSnapshot 上实现另外三个方法。</p>
<ul>
<li><code>#writeOuterSnapshot(DataOutputView)</code>：定义如何写入外部快照信息。</li>
<li><code>#readOuterSnapshot(int, DataInputView, ClassLoader)</code>：定义如何读取外部快照信息。</li>
<li><code>#resolveOuterSchemaCompatibility(TypeSerializer)</code>：根据外部快照信息检查兼容性。</li>
</ul>
<p>默认情况下，CompositeTypeSerializerSnapshot 假设没有任何外部快照信息可读/可写，因此上述方法的默认实现为空。如果子类有外部快照信息，那么这三个方法必须全部实现。</p>
<p>下面以 Flink 的 GenericArraySerializer 为例，说明 CompositeTypeSerializerSnapshot 如何用于确实有外部快照信息的复合序列器快照。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">GenericArraySerializerSnapshot</span><span class="o">&lt;</span><span class="n">C</span><span class="o">&gt;</span> <span class="kd">extends</span> <span class="n">CompositeTypeSerializerSnapshot</span><span class="o">&lt;</span><span class="n">C</span><span class="o">[],</span> <span class="n">GenericArraySerializer</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">CURRENT_VERSION</span> <span class="o">=</span> <span class="n">1</span><span class="o">;</span>

    <span class="kd">private</span> <span class="n">Class</span><span class="o">&lt;</span><span class="n">C</span><span class="o">&gt;</span> <span class="n">componentClass</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">GenericArraySerializerSnapshot</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">GenericArraySerializer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="nf">GenericArraySerializerSnapshot</span><span class="o">(</span><span class="n">GenericArraySerializer</span><span class="o">&lt;</span><span class="n">C</span><span class="o">&gt;</span> <span class="n">genericArraySerializer</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">genericArraySerializer</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">componentClass</span> <span class="o">=</span> <span class="n">genericArraySerializer</span><span class="o">.</span><span class="na">getComponentClass</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">int</span> <span class="nf">getCurrentOuterSnapshotVersion</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">CURRENT_VERSION</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">writeOuterSnapshot</span><span class="o">(</span><span class="n">DataOutputView</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="na">writeUTF</span><span class="o">(</span><span class="n">componentClass</span><span class="o">.</span><span class="na">getName</span><span class="o">());</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">readOuterSnapshot</span><span class="o">(</span><span class="kt">int</span> <span class="n">readOuterSnapshotVersion</span><span class="o">,</span> <span class="n">DataInputView</span> <span class="n">in</span><span class="o">,</span> <span class="n">ClassLoader</span> <span class="n">userCodeClassLoader</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">componentClass</span> <span class="o">=</span> <span class="n">InstantiationUtil</span><span class="o">.</span><span class="na">resolveClassByName</span><span class="o">(</span><span class="n">in</span><span class="o">,</span> <span class="n">userCodeClassLoader</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">boolean</span> <span class="nf">resolveOuterSchemaCompatibility</span><span class="o">(</span><span class="n">GenericArraySerializer</span> <span class="n">newSerializer</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">componentClass</span> <span class="o">==</span> <span class="n">newSerializer</span><span class="o">.</span><span class="na">getComponentClass</span><span class="o">())</span>
            <span class="o">?</span> <span class="n">OuterSchemaCompatibility</span><span class="o">.</span><span class="na">COMPATIBLE_AS_IS</span>
            <span class="o">:</span> <span class="n">OuterSchemaCompatibility</span><span class="o">.</span><span class="na">INCOMPATIBLE</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">GenericArraySerializer</span> <span class="nf">createOuterSerializerWithNestedSerializers</span><span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="n">nestedSerializers</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">C</span><span class="o">&gt;</span> <span class="n">componentSerializer</span> <span class="o">=</span> <span class="o">(</span><span class="n">TypeSerializer</span><span class="o">&lt;</span><span class="n">C</span><span class="o">&gt;)</span> <span class="n">nestedSerializers</span><span class="o">[</span><span class="n">0</span><span class="o">];</span>
        <span class="k">return</span> <span class="k">new</span> <span class="n">GenericArraySerializer</span><span class="o">&lt;&gt;(</span><span class="n">componentClass</span><span class="o">,</span> <span class="n">componentSerializer</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="n">getNestedSerializers</span><span class="o">(</span><span class="n">GenericArraySerializer</span> <span class="n">outerSerializer</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="n">TypeSerializer</span><span class="o">&lt;?&gt;[]</span> <span class="o">{</span> <span class="n">outerSerializer</span><span class="o">.</span><span class="na">getComponentSerializer</span><span class="o">()</span> <span class="o">};</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>在上面的代码片段中，有两个重要的事情需要注意。首先，由于这个 <code>CompositeTypeSerializerSnapshot</code> 实现的外快照信息是作为快照的一部分写入的，所以每当外快照信息的序列化格式发生变化时，由 <code>getCurrentOuterSnapshotVersion()</code> 定义的外快照版本必须被上调。</p>
<p>其次，请注意我们在写组件类时避免使用 Java 序列化，只写类名，在读回快照时动态加载。避免使用 Java 序列化来编写序列化器快照的内容，总的来说是一个很好的做法。关于这方面的更多细节将在下一节介绍。</p>
<h3 id="实施说明和最佳实践">实施说明和最佳实践</h3>
<ol>
<li>Flink 通过将序列器快照实例化，恢复序列器快照，其类名为</li>
</ol>
<p>序列器的快照，是注册状态如何被序列化的唯一真实来源，是读取保存点中状态的入口。为了能够恢复和访问以前的状态，必须能够恢复以前状态序列化器的快照。</p>
<p>Flink 通过首先实例化 TypeSerializerSnapshot 与其类名（与快照字节一起写入）来恢复序列器快照。因此，为了避免受到意外的类名更改或实例化失败， TypeSerializerSnapshot 类应该。</p>
<ul>
<li>避免被实现为匿名类或嵌套类。</li>
<li>有一个公共的空值构造函数用于实例化。</li>
</ul>
<ol start="2">
<li>避免在不同的序列化器之间共享同一个 TypeSerializerSnapshot 类。</li>
</ol>
<p>由于模式兼容性检查要通过序列化器快照，让多个序列化器返回同一个 TypeSerializerSnapshot 类作为它们的快照，会使 <code>TypeSerializerSnapshot#resolveSchemaCompatibility</code> 和 <code>TypeSerializerSnapshot#restoreSerializer()</code> 方法的实现变得复杂。</p>
<p>这也将是一个不好的分离关注点，一个单一序列化器的序列化模式、配置以及如何恢复它，应该合并在自己专门的TypeSerializerSnapshot类中。</p>
<ol start="3">
<li>避免使用 Java 序列化来制作序列化器快照内容</li>
</ol>
<p>在编写持久化的序列化器快照的内容时，完全不应该使用 Java 序列化。例如，一个序列化器需要持久化一个目标类型的类作为其快照的一部分。关于类的信息应该通过写入类名来持久化，而不是直接使用 Java 将类序列化。在读取快照时，会读取类名，并通过名称来动态加载类。</p>
<p>这种做法保证了序列化器快照总是可以安全读取。在上面的例子中，如果类型类是使用 Java 序列化来持久化的，一旦类的实现发生了变化，根据 Java 序列化的具体规定，快照可能不再可读，不再二进制兼容。</p>
<h3 id="从-flink-17-之前的废弃序列化快照-api-迁移">从 Flink 1.7 之前的废弃序列化快照 API 迁移</h3>
<p>本节是一个从 Flink 1.7 之前存在的序列化器和序列化器快照的 API 迁移指南。</p>
<p>在 Flink 1.7 之前，序列化器快照是以 TypeSerializerConfigSnapshot 的形式实现的（现在已经被废弃了，将来最终会被移除，完全被新的 TypeSerializerSnapshot 接口取代）。此外，序列化器模式兼容性检查的责任住在 TypeSerializer  内部，在 <code>TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)</code> 方法中实现。</p>
<p>新旧抽象之间的另一个主要区别是，被废弃的 <code>TypeSerializerConfigSnapshot</code> 不具备实例化之前的序列化器的能力。因此，在你的序列化器仍然返回 <code>TypeSerializerConfigSnapshot</code> 的子类作为它的快照的情况下，序列化器实例本身将总是使用 Java 序列化写入 savepoints，以便在还原时可以使用以前的序列化器。这是很不可取的，因为还原作业是否成功，很容易受到前一个序列化器类的可用性的影响，或者说，一般来说，序列化器实例是否可以在还原时使用 Java 序列化读回。这意味着你的状态只能使用同一个序列化器，一旦你想升级序列化器类或进行模式迁移，可能会出现问题。</p>
<p>为了面向未来，并能灵活地迁移你的状态序列器和模式，强烈建议从旧的抽象中迁移。做到这一点的步骤如下。</p>
<ol>
<li>实现 TypeSerializerSnapshot 的新子类。这将是你的序列化器的新快照。</li>
<li>在 <code>TypeSerializer#snapshotConfiguration()</code> 方法中返回新的 <code>TypeSerializerSnapshot</code> 作为你的 serializer 快照。</li>
<li>从 Flink 1.7 之前存在的保存点恢复作业，然后再取一个保存点。注意，在这一步，旧的序列化器的 <code>TypeSerializerConfigSnapshot</code> 必须仍然存在于 classpath 中，并且不能删除 <code>TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)</code> 方法的实现。这个过程的目的是将旧保存点中写的 <code>TypeSerializerConfigSnapshot</code> 替换为序列化器新实现的 <code>TypeSerializerSnapshot</code>。</li>
<li>一旦你有一个用 Flink 1.7 拍摄的保存点，保存点将包含 TypeSerializerSnapshot 作为状态序列化器快照，序列化器实例将不再写入保存点中。在这一点上，现在可以安全地删除旧抽象的所有实现（从序列化器中删除旧的 TypeSerializerConfigSnapshot 实现，因为将作为 TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)）。</li>
</ol>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/custom_serialization.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/custom_serialization.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[运行 Describe 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-run-a-describe-statement/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-run-a-describe-statement/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Run a Describe Statement</blockquote><h1 id="describe-语句">DESCRIBE 语句</h1>
<p>DESCRIBE 语句用于描述表或视图的模式。</p>
<h2 id="运行一个describe语句">运行一个DESCRIBE语句</h2>
<p>DESCRIBE语句可以用TableEnvironment的executeSql()方法执行，也可以在SQL CLI中执行。executeSql()方法对于一个成功的DESCRIBE操作会返回给定表的模式，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在TableEnvironment和SQL CLI中运行DESCRIBE语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">()...</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
        <span class="s">&#34;CREATE TABLE Orders (&#34;</span> <span class="o">+</span>
        <span class="s">&#34; `user` BIGINT NOT NULl,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; product VARCHAR(32),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; amount INT,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; ts TIMESTAMP(3),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; ptime AS PROCTIME(),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; PRIMARY KEY(`user`) NOT ENFORCED,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; WATERMARK FOR ts AS ts - INTERVAL &#39;1&#39; SECONDS&#34;</span> <span class="o">+</span>
        <span class="s">&#34;) with (...)&#34;</span><span class="o">)</span>

<span class="c1">// print the schema
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;DESCRIBE Orders&#34;</span><span class="o">).</span><span class="n">print</span><span class="o">()</span>
</code></pre></div><pre><code>Flink SQL&gt; CREATE TABLE Orders (
&gt;  `user` BIGINT NOT NULl,
&gt;  product VARCHAR(32),
&gt;  amount INT,
&gt;  ts TIMESTAMP(3),
&gt;  ptime AS PROCTIME(),
&gt;  PRIMARY KEY(`user`) NOT ENFORCED,
&gt;  WATERMARK FOR ts AS ts - INTERVAL '1' SECONDS
&gt; ) with (
&gt;  ...
&gt; );
[INFO] Table has been created.

Flink SQL&gt; DESCRIBE Orders;
</code></pre><pre><code>root
 |-- user: BIGINT NOT NULL
 |-- product: VARCHAR(32)
 |-- amount: INT
 |-- ts: TIMESTAMP(3) *ROWTIME*
 |-- ptime: TIMESTAMP(3) NOT NULL *PROCTIME* AS PROCTIME()
 |-- WATERMARK FOR ts AS `ts` - INTERVAL '1' SECOND
 |-- CONSTRAINT PK_3599338 PRIMARY KEY (user)
</code></pre><p>上述例子的结果是：</p>
<pre><code>+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
|    name |                             type |  null |       key | computed column |                  watermark |
+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
|    user |                           BIGINT | false | PRI(user) |                 |                            |
| product |                      VARCHAR(32) |  true |           |                 |                            |
|  amount |                              INT |  true |           |                 |                            |
|      ts |           TIMESTAMP(3) *ROWTIME* |  true |           |                 | `ts` - INTERVAL '1' SECOND |
|   ptime | TIMESTAMP(3) NOT NULL *PROCTIME* | false |           |      PROCTIME() |                            |
+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
5 rows in set
</code></pre><h2 id="语法">语法</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DESCRIBE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.][</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[连续查询中的 Join]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-join-in-continuous-queries/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-join-in-continuous-queries/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Join in Continuous Queries</blockquote><h1 id="连续查询中的-join">连续查询中的 Join</h1>
<p>在批处理数据时，连接是一种常见的、好理解的操作，用来连接两个关系的行。然而，在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>上的连接的语义就不那么明显了，甚至是混乱的。</p>
<p>正因为如此，有几种方法可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 实际执行连接。</p>
<p>关于语法的更多信息，请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 中的连接部分。</p>
<h2 id="常规连接">常规连接</h2>
<p>常规联接是最通用的联接类型，联接输入的任何一条新记录或变化都是可见的，并影响整个联接结果。例如，如果左边有一条新记录，它将与右边所有以前和将来的记录一起连接。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">Product</span>
<span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>这些语义允许任何形式的更新（插入、更新、删除）输入表。</p>
<p>然而，这种操作有一个重要的含义：它需要将 <code>join</code> 输入的双方永远保持在 Flink 的状态中。因此，如果一个或两个输入表持续增长，资源使用量也会无限增长。</p>
<h2 id="区间连接">区间连接</h2>
<p>区间联接是由联接谓词定义的，它检查输入记录的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>是否在一定的时间限制内，即时间窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="n">o</span><span class="p">,</span>
  <span class="n">Shipments</span> <span class="n">s</span>
<span class="k">WHERE</span> <span class="n">o</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">orderId</span> <span class="k">AND</span>
      <span class="n">o</span><span class="p">.</span><span class="n">ordertime</span> <span class="k">BETWEEN</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;4&#39;</span> <span class="n">HOUR</span> <span class="k">AND</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span>
</code></pre></div><p>与普通的 join 操作相比，这种 join 只支持带有时间属性的 append-only 表。由于时间属性是准单调递增的，所以 Flink 可以在不影响结果正确性的情况下，从其状态中删除旧值。</p>
<h2 id="用临时表函数进行联接">用临时表函数进行联接</h2>
<p>使用时态表函数的连接，将一个只附加表（左输入/探针侧）与一个时态表（右输入/建立侧）连接起来，即一个随时间变化的表，并跟踪其变化。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>的更多信息，请查看相应页面。</p>
<p>下面的例子显示了一个只附加表 Orders，它应该与不断变化的货币汇率表 RatesHistory 连接。</p>
<p>Orders 是一个只附加表，表示给定金额和给定货币的付款。例如在 10:15 有一个金额为 2 欧元的订单。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">amount</span> <span class="n">currency</span>
<span class="o">=======</span> <span class="o">======</span> <span class="o">=========</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">15</span>        <span class="mi">2</span> <span class="n">Euro</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">30</span>        <span class="mi">1</span> <span class="n">US</span> <span class="n">Dollar</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">32</span>       <span class="mi">50</span> <span class="n">Yen</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">52</span>        <span class="mi">3</span> <span class="n">Euro</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">04</span>        <span class="mi">5</span> <span class="n">US</span> <span class="n">Dollar</span>
</code></pre></div><p>RatesHistory 代表了一个不断变化的对日元（汇率为 1）的货币汇率附加表。例如，从 09:00 到 10:45，欧元对日元的汇率是 114，从 10:45 到 11:15 是 116。从 10:45 到 11:15 是 116。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">RatesHistory</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=======</span> <span class="o">========</span> <span class="o">======</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">15</span>   <span class="n">Euro</span>        <span class="mi">119</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">49</span>   <span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>我们想计算所有订单的金额，并将其换算成一种通用货币（日元）。</p>
<p>例如，我们想使用给定行时间(114)的适当换算率换算以下订单。</p>
<pre><code>rowtime amount currency
======= ====== =========
10:15        2 Euro
</code></pre><p>如果不使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>的概念，就需要写一个类似的查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span><span class="p">,</span>
  <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
<span class="k">AND</span> <span class="n">r</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">=</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span>
  <span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r2</span>
  <span class="k">WHERE</span> <span class="n">r2</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
  <span class="k">AND</span> <span class="n">r2</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">&lt;=</span> <span class="n">o</span><span class="p">.</span><span class="n">rowtime</span><span class="p">);</span>
</code></pre></div><p>在临时表函数 Rates over RatesHistory 的帮助下，我们可以将这样的查询用 SQL 表达为:</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">rowtime</span><span class="p">))</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>来自探针侧的每条记录将与构建侧表在探针侧记录的相关时间属性时的版本连接。为了支持更新（覆盖）构建侧表的先前值，表必须定义一个主键。</p>
<p>在我们的例子中，来自 Orders 的每条记录将与 Rates 的版本在时间 o.rowtime 连接。货币字段之前已经被定义为 Rates 的主键，在我们的例子中用来连接两个表。如果查询使用的是处理时间的概念，那么在执行操作时，新添加的订单将始终与 Rates 的最新版本连接。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#regular-joins">常规的连接</a>不同，这意味着如果在构建端有新的记录，不会影响之前的连接结果。这又使得 Flink 可以限制必须保留在状态中的元素数量。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#interval-joins">区间联接</a>相比，时间表联接并没有定义一个时间窗口，在这个时间窗口的范围内，记录将被加入。来自探针侧的记录总是在时间属性指定的时间与构建侧的版本进行连接。因此，构建侧的记录可能是任意的旧记录。随着时间的流逝，记录（对于给定的主键）以前的和不再需要的版本将从状态中删除。</p>
<p>这样的行为使得时间表连接成为用关系术语来表达流丰富的一个很好的候选。</p>
<h3 id="使用方法">使用方法</h3>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#defining-temporal-table-function">定义了临时表函数</a>之后，我们就可以开始使用它了。时间表函数的使用方法可以和普通表函数的使用方法一样。</p>
<p>下面的代码片段解决了我们的动机问题，即从订单表中转换货币。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o_amount</span> <span class="o">*</span> <span class="n">r_rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o_proctime</span><span class="p">))</span>
<span class="k">WHERE</span>
  <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// scala
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">rates</span><span class="o">(</span>&#39;o_proctime<span class="o">),</span> &#39;r_currency <span class="o">===</span> &#39;o_currency<span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">((</span>&#39;o_amount <span class="o">*</span> &#39;r_rate<span class="o">).</span><span class="n">sum</span> <span class="n">as</span> &#39;amount<span class="o">)</span>
</code></pre></div><p>注意：在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>中定义的状态保留还没有实现时序连接。这意味着计算查询结果所需的状态可能会根据历史表的不同主键的数量而无限增长。</p>
<h3 id="处理时间的-temporal-连接">处理时间的 Temporal 连接</h3>
<p>有了处理时间时间属性，就不可能将过去的时间属性作为参数传递给时序表函数。根据定义，它总是当前的时间戳。因此，对处理时间时间表函数的调用将始终返回底层表的最新已知版本，底层历史表的任何更新也将立即覆盖当前值。</p>
<p>只有构建侧记录的最新版本（相对于定义的主键）才会保存在状态中。构建侧的更新不会对之前发出的连接结果产生影响。</p>
<p>我们可以把处理时的时空联接看成一个简单的 <code>HashMap&lt;K，V&gt;</code>，它存储了来自构建侧的所有记录。当来自构建侧的新记录与之前的某个记录具有相同的键时，旧的值只是简单地被覆盖。来自探针侧的每条记录总是根据 HashMap 的最近/当前状态进行评估。</p>
<h3 id="事件时间的-temporal-连接">事件时间的 Temporal 连接</h3>
<p>有了事件时间属性（即行时间属性），就可以将过去的时间属性传递给时间表函数。这样就可以在一个共同的时间点上连接两个表。</p>
<p>与处理时间的时空连接相比，时空表不仅保留了状态下构建方记录的最新版本（相对于定义的主键），而且还存储了自上次水印以来的所有版本（通过时间来识别）。</p>
<p>例如，一个事件时间时间戳为 12:30:00 的传入行被追加到探针侧表中，根据<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表的概念</a>，它与构建侧表中时间为 12:30:00 的版本连接。因此，传入的行只与时间戳小于或等于 12:30:00 的行连接，并根据主键应用更新，直到这个时间点。</p>
<p>根据事件时间的定义，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">水印</a>允许联接操作在时间上向前移动，并丢弃不再需要的构建表的版本，因为预计不会有时间戳较低或相等的传入行。</p>
<h3 id="用时间表进行联接">用时间表进行联接</h3>
<p>带时态表的连接将一个任意表（左输入/探针侧）与一个时态表（右输入/建立侧）连接起来，即一个随时间变化的外部维度表。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>的详细信息，请查看相应页面。</p>
<p>注意: 用户不能使用任意表作为时间表，而是需要使用一个由 LookupableTableSource 支持的表。一个 LookupableTableSource 只能作为一个时态表用于时态连接。有关如何定义 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#defining-a-tablesource-with-lookupable">LookupableTableSource</a> 的详细信息，请参见页面。</p>
<p>下面的示例显示了一个 Orders 流，它应该与不断变化的货币汇率表 LatestRates 进行连接。</p>
<p>LatestRates 是一个维度表，它是以最新的汇率来实现的。在时间 10:15、10:30、10:52，LatestRates 的内容如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>

<span class="mi">10</span><span class="p">:</span><span class="mi">30</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>


<span class="mi">10</span><span class="p">:</span><span class="mi">52</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">========</span> <span class="o">======</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">116</span>     <span class="o">&lt;====</span> <span class="n">changed</span> <span class="k">from</span> <span class="mi">114</span> <span class="k">to</span> <span class="mi">116</span>
<span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>时间 10:15 和 10:30 的 LastestRates 内容相等。欧元汇率在 10:52 从 114 变为 116。</p>
<p>订单是一个只附加的表，表示给定金额和给定货币的支付。例如在 10:15 有一个金额为 2 欧元的订单。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span><span class="p">;</span>

<span class="n">amount</span> <span class="n">currency</span>
<span class="o">======</span> <span class="o">=========</span>
     <span class="mi">2</span> <span class="n">Euro</span>             <span class="o">&lt;==</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">15</span>
     <span class="mi">1</span> <span class="n">US</span> <span class="n">Dollar</span>        <span class="o">&lt;==</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">30</span>
     <span class="mi">2</span> <span class="n">Euro</span>             <span class="o">&lt;==</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">52</span>
</code></pre></div><p>我们想计算所有订单的金额，并将其兑换成一种通用货币（日元）。</p>
<p>例如，我们想使用 LatestRates 中的最新汇率来转换以下订单。结果将是：</p>
<pre><code>amount currency     rate   amout*rate
====== ========= ======= ============
     2 Euro          114          228    &lt;== arrived at time 10:15
     1 US Dollar     102          102    &lt;== arrived at time 10:30
     2 Euro          116          232    &lt;== arrived at time 10:52
</code></pre><p>在时间表连接的帮助下，我们可以将这样的查询用 SQL 表达为。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amout</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span><span class="p">,</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o</span><span class="p">.</span><span class="n">proctime</span> <span class="k">AS</span> <span class="n">r</span>
  <span class="k">ON</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>来自探针侧的每一条记录都将与构建侧表的当前版本相连接。在我们的例子中，查询使用的是处理时间的概念，所以在执行操作时，新追加的订单将始终与最新版本的 LatestRates 连接。需要注意的是，结果并不是处理时间的确定性。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#regular-joins">常规联接</a>相比，尽管构建端发生了变化，但时态表联接之前的结果不会受到影响。另外，时态表连接操作符非常轻量级，不保留任何状态。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#interval-joins">区间联接</a>相比，时态表联接不定义记录联接的时间窗口。在处理时，来自探针侧的记录总是与构建侧的最新版本连接。因此，构建侧的记录可能是任意旧的。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#join-with-a-temporal-table-function">时态表函数连接</a>和时态表连接的动机都是一样的，但在 SQL 语法和运行时的实现上却有所不同。</p>
<ul>
<li>时间表函数 join 的 SQL 语法是 join UDTF，而时间表 join 使用 SQL:2011 中引入的标准时间表语法。</li>
<li>时态表函数 join 的实现实际上是将两个流连接起来并保持状态，而时态表 join 只是接收唯一的输入流，并根据记录中的键查找外部数据库。</li>
<li>时态表函数联接通常用于联接变更日志流，而时态表联接通常用于联接外部表（即维表）。</li>
</ul>
<p>这样的行为使得时态表连接成为用关系术语来表达流丰富的一个很好的候选。</p>
<p>在未来，时态表连接将支持时态表函数连接的特性，即支持时态连接 changelog 流。</p>
<h3 id="使用方法-1">使用方法</h3>
<p>时间表连接的语法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="n">table1</span> <span class="p">[</span><span class="k">AS</span> <span class="o">&lt;</span><span class="n">alias1</span><span class="o">&gt;</span><span class="p">]</span>
<span class="p">[</span><span class="k">LEFT</span><span class="p">]</span> <span class="k">JOIN</span> <span class="n">table2</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">table1</span><span class="p">.</span><span class="n">proctime</span> <span class="p">[</span><span class="k">AS</span> <span class="o">&lt;</span><span class="n">alias2</span><span class="o">&gt;</span><span class="p">]</span>
<span class="k">ON</span> <span class="n">table1</span><span class="p">.</span><span class="k">column</span><span class="o">-</span><span class="n">name1</span> <span class="o">=</span> <span class="n">table2</span><span class="p">.</span><span class="k">column</span><span class="o">-</span><span class="n">name1</span>
</code></pre></div><p>目前只支持 INNER JOIN 和 LEFT JOIN。在 temporal 表后应跟上 FOR SYSTEM_TIME AS OF table1.proctime。proctime 是 table1 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">处理时间属性</a>。这意味着它在处理时间对时间表进行快照，当从左表连接每一条记录时，它就会对时间表进行快照。</p>
<p>例如，在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#defining-temporal-table">定义了 temporal 表</a>之后，我们可以按以下方式使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o_amount</span> <span class="o">*</span> <span class="n">r_rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o_proctime</span>
  <span class="k">ON</span> <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><p>注意: 这只在 Blink 计划器中支持。</p>
<p>注意: 目前只在 SQL 中支持，在 Table API 中还不支持。</p>
<p>注意: Flink 目前不支持事件时间的表连接。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[迭代]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-iterations/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Dataset API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/?utm_source=atom_feed" rel="related" type="text/html" title="Hadoop 的兼容性" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-batch-examples/?utm_source=atom_feed" rel="related" type="text/html" title="批处理例子" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-zipping-elements-in-a-dataset/?utm_source=atom_feed" rel="related" type="text/html" title="数据集中的 zipping 元素" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-iterations/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Iterations</blockquote><h2 id="迭代">迭代</h2>
<p>迭代算法出现在数据分析的许多领域，如机器学习或图形分析。为了实现大数据的承诺，从数据中提取有意义的信息，此类算法至关重要。随着人们对在非常大的数据集上运行这类算法的兴趣越来越大，就需要以大规模并行的方式执行迭代。</p>
<p>Flink 程序通过定义一个步骤函数并将其嵌入到一个特殊的迭代运算符中来实现迭代算法。这个运算符有两个变体。Iterate 和 Delta Iterate。这两个运算符都是在当前的迭代状态上反复调用步骤函数，直到达到某个终止条件。</p>
<p>在这里，我们提供了这两个操作符变体的背景，并概述了它们的用法。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">编程指南</a>解释了如何在 Scala 和 Java 中实现这些操作符。我们还通过 Flink 的图处理 API <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/gelly/index.html">Gelly</a> 支持以顶点为中心的迭代和集和应用迭代。</p>
<p>下表提供了这两种运算符的概述:</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">Iterate</th>
<th style="text-align:left">Delta Iterate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Iteration 输入</td>
<td style="text-align:left">Partial Solution</td>
<td style="text-align:left">Workset and Solution Set</td>
</tr>
<tr>
<td style="text-align:left">Step 函数</td>
<td style="text-align:left">Arbitrary Data Flows</td>
<td style="text-align:left">Arbitrary Data Flows</td>
</tr>
<tr>
<td style="text-align:left">State Update</td>
<td style="text-align:left">Next partial solution</td>
<td style="text-align:left">Next workset,Changes to solution set</td>
</tr>
<tr>
<td style="text-align:left">Iteration Result</td>
<td style="text-align:left">Last partial solution</td>
<td style="text-align:left">Solution set state after last iteration</td>
</tr>
<tr>
<td style="text-align:left">Termination</td>
<td style="text-align:left">Maximum number of iterations (default),Custom aggregator convergence</td>
<td style="text-align:left">Maximum number of iterations or empty workset (default),Custom aggregator convergence</td>
</tr>
</tbody>
</table>
<h2 id="iterate-operator">Iterate Operator</h2>
<p>迭代运算符涵盖了简单的迭代形式：在每一次迭代中，step 函数都会消耗整个输入（上一次迭代的结果，或初始数据集），并计算出下一个版本的部分解（如 <code>map</code>, <code>reduce</code>, <code>join</code> 等）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/iterations_iterate_operator.png" alt="img"></p>
<ol>
<li>迭代输入。第一次迭代的初始输入，来自数据源或之前的运算符。</li>
<li>step 函数。步骤函数将在每次迭代中执行。它是一个任意的数据流，由 map、reduce、join 等运算符组成，取决于你手头的具体任务。</li>
<li>下一个部分解决方案。在每次迭代中，步骤函数的输出将被反馈到下一次迭代中。</li>
<li>迭代结果。上一次迭代的输出会被写入数据接收器，或者作为后续运算符的输入。</li>
</ol>
<p>有多个选项可以指定迭代的终止条件。</p>
<ul>
<li>最大迭代次数。没有任何进一步的条件，迭代将被执行这么多次。</li>
<li>自定义聚合器收敛。迭代允许指定自定义聚合器和收敛标准，比如对发出的记录数量进行加总（聚合器），如果这个数字为零就终止（收敛标准）。</li>
</ul>
<p>你也可以用伪代码来思考迭代操作符。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">IterationState</span> <span class="n">state</span> <span class="o">=</span> <span class="n">getInitialState</span><span class="o">();</span>

<span class="k">while</span> <span class="o">(!</span><span class="n">terminationCriterion</span><span class="o">())</span> <span class="o">{</span>
	<span class="n">state</span> <span class="o">=</span> <span class="n">step</span><span class="o">(</span><span class="n">state</span><span class="o">);</span>
<span class="o">}</span>

<span class="n">setFinalState</span><span class="o">(</span><span class="n">state</span><span class="o">);</span>
</code></pre></div><p>详情和代码示例请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">编程指南</a>。</p>
<h2 id="例子-数字递增">例子: 数字递增</h2>
<p>在下面的例子中，我们对一组数字进行迭代递增。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/iterations_iterate_operator_example.png" alt="img"></p>
<ol>
<li>迭代输入。初始输入是从数据源读取的，由5个单字段记录组成（整数1至5）。</li>
<li>step 函数。步进函数是一个单一的 map 运算符，它将整数字段从i递增到i+1。它将被应用于输入的每一条记录。</li>
<li>下一个部分解。step 函数的输出将是 map 运算符的输出，也就是整数递增的记录。</li>
<li>迭代结果。经过十次迭代，初始数字将被递增十倍，结果是整数11到15。</li>
</ol>
<pre><code>// 1st           2nd                       10th
map(1) -&gt; 2      map(2) -&gt; 3      ...      map(10) -&gt; 11
map(2) -&gt; 3      map(3) -&gt; 4      ...      map(11) -&gt; 12
map(3) -&gt; 4      map(4) -&gt; 5      ...      map(12) -&gt; 13
map(4) -&gt; 5      map(5) -&gt; 6      ...      map(13) -&gt; 14
map(5) -&gt; 6      map(6) -&gt; 7      ...      map(14) -&gt; 15
</code></pre><p>请注意，1、2和4可以是任意的数据流。</p>
<h2 id="增量迭代运算符">增量迭代运算符</h2>
<p>delta 迭代算子涵盖了增量迭代的情况。增量迭代有选择地修改其解的元素，并对解进行演化，而不是完全重新计算。</p>
<p>在适用的情况下，这将导致更高效的算法，因为在每次迭代中，并不是解集中的每个元素都会改变。这样就可以把注意力集中在解的热点部分，而对冷点部分不加处理。通常情况下，大部分解的冷却速度比较快，后面的迭代只对一小部分数据进行操作。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/iterations_delta_iterate_operator.png" alt="img"></p>
<ol>
<li>迭代输入。从数据源或以前的运算符中读取初始工作集和解决方案集，作为第一次迭代的输入。</li>
<li>step 函数。在每次迭代中，步骤函数将被执行。它是一个任意的数据流，由 map、reduce、join 等运算符组成，取决于你手头的具体任务。</li>
<li>下一个工作集/更新解决方案集。下一个工作集驱动迭代计算，并将反馈到下一个迭代中。此外，解决方案集将被更新并隐式转发（它不需要被重建）。这两个数据集都可以通过步长函数的不同运算符进行更新。</li>
<li>迭代结果。最后一次迭代后，解集被写入数据接收器，或作为下面运算符的输入。</li>
</ol>
<p>delta 迭代的默认终止条件由空工作集收敛准则和最大迭代次数指定。当产生的下一个工作集为空或达到最大迭代次数时，迭代将终止。也可以指定一个自定义的聚合器和收敛准则。</p>
<p>你也可以用伪代码来思考迭代操作符。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">IterationState</span> <span class="n">workset</span> <span class="o">=</span> <span class="n">getInitialState</span><span class="o">();</span>
<span class="n">IterationState</span> <span class="n">solution</span> <span class="o">=</span> <span class="n">getInitialSolution</span><span class="o">();</span>

<span class="k">while</span> <span class="o">(!</span><span class="n">terminationCriterion</span><span class="o">())</span> <span class="o">{</span>
	<span class="o">(</span><span class="n">delta</span><span class="o">,</span> <span class="n">workset</span><span class="o">)</span> <span class="o">=</span> <span class="n">step</span><span class="o">(</span><span class="n">workset</span><span class="o">,</span> <span class="n">solution</span><span class="o">);</span>

	<span class="n">solution</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="n">delta</span><span class="o">)</span>
<span class="o">}</span>

<span class="n">setFinalState</span><span class="o">(</span><span class="n">solution</span><span class="o">);</span>
</code></pre></div><p>详情和代码示例请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">编程指南</a>。</p>
<h2 id="例子-在图中传播最小值">例子: 在图中传播最小值</h2>
<p>在下面的例子中，每个顶点都有一个ID和一个着色。每个顶点将把它的顶点ID传播给邻近的顶点。目标是给子图中的每个顶点分配最小的ID。如果一个接收到的ID比当前的ID小，它就会改变成接收到ID的顶点的颜色。这在社区分析或连接组件计算中可以找到一个应用。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/iterations_delta_iterate_operator_example.png" alt="img"></p>
<p>初始输入被设定为工作集和解决方案集。在上图中，颜色直观地显示了解决方案集的演变。随着每次迭代，最小ID的颜色在各自的子图中蔓延。同时，每一次迭代，工作量（交换和比较顶点ID）都在减少。这对应于工作集的大小递减，在三次迭代后，工作集从所有七个顶点变为零，此时迭代终止。重要的观察是，下半子图在上半子图之前收敛，而delta迭代能够用工作集抽象捕捉到这一点。</p>
<p>在上子图中，ID 1（橙色）是最小ID。在第一次迭代中，它将被传播到顶点2，随后它的颜色将变为橙色。顶点3和4将收到ID 2（黄色）作为它们当前的最小ID，并改变为黄色。因为顶点1的颜色在第一次迭代中没有改变，所以在下一个工作集中可以跳过它。</p>
<p>在下层子图中，ID 5（青色）是最小ID。下层子图的所有顶点都会在第一次迭代中收到它。同样，我们可以在下一个工作集中跳过没有变化的顶点（顶点5）。</p>
<p>在第2次迭代中，工作集大小已经从7个元素减少到5个元素（顶点2、3、4、6和7）。这些都是迭代的一部分，并进一步传播它们当前的最小ID。在这次迭代之后，下半部分子图已经收敛了（图的冷部分），因为它在工作集中没有元素，而上半部分则需要对剩下的两个工作集元素（顶点3和4）进行进一步的迭代（图的热部分）。</p>
<p>当第3次迭代后工作集为空时，迭代终止。</p>
<h2 id="superstep-同步">Superstep 同步</h2>
<p>我们将迭代操作符的步骤函数的每次执行称为单次迭代。在并行设置中，步骤函数的多个实例在迭代状态的不同分区上并行评估。在许多设置中，在所有并行实例上对步骤函数的一次评估形成一个所谓的超级步骤，这也是同步的粒度。因此，一个迭代的所有并行任务都需要完成 superstep，才会初始化下一个 superstep。终止标准也将在 superstep 障碍处进行评估。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/iterations_supersteps.png" alt="img"></p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dataset-api" term="dataset-api" label="DataSet API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[集群 Execution]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-cluster-execution/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-dataset-transformations/?utm_source=atom_feed" rel="related" type="text/html" title="Dataset 变换" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-cluster-execution/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Cluster Execution</blockquote><p>Flink 程序可以在许多机器组成的集群上分布式运行。有两种方法可以将程序发送到集群上执行。</p>
<h2 id="命令行接口">命令行接口</h2>
<p>命令行界面让您可以将打包的程序（JAR）提交到集群（或单机设置）。</p>
<p>详情请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html">命令行接口</a>文档。</p>
<h2 id="远程环境">远程环境</h2>
<p>远程环境可以让你直接在集群上执行 Flink Java 程序。远程环境指向你要执行程序的集群。</p>
<h3 id="maven-依赖">Maven 依赖</h3>
<p>如果你是以 Maven 项目的形式开发程序，你必须使用这个依赖关系添加 flink-clients 模块。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><h2 id="例子">例子</h2>
<p>以下说明了 RemoteEnvironment 的使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span>
        <span class="o">.</span><span class="na">createRemoteEnvironment</span><span class="o">(</span><span class="s">&#34;flink-jobmanager&#34;</span><span class="o">,</span> <span class="n">8081</span><span class="o">,</span> <span class="s">&#34;/home/user/udfs.jar&#34;</span><span class="o">);</span>

    <span class="n">DataSet</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">&#34;hdfs://path/to/file&#34;</span><span class="o">);</span>

    <span class="n">data</span>
        <span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="n">FilterFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>
            <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="na">startsWith</span><span class="o">(</span><span class="s">&#34;http://&#34;</span><span class="o">);</span>
            <span class="o">}</span>
        <span class="o">})</span>
        <span class="o">.</span><span class="na">writeAsText</span><span class="o">(</span><span class="s">&#34;hdfs://path/to/result&#34;</span><span class="o">);</span>

    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>请注意，该程序包含自定义用户代码，因此需要一个包含代码类的 JAR 文件。远程环境的构造函数使用 JAR 文件的路径。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/cluster_execution.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/cluster_execution.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/cluster-execution" term="cluster-execution" label="Cluster Execution" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[项目配置]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-project-configuration/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-project-configuration/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Project Configuration</blockquote><h2 id="项目配置">项目配置</h2>
<p>每个 Flink 应用都依赖于一组 Flink 库。最起码，应用程序依赖于 Flink APIs。许多应用还依赖于某些连接器库（如 Kafka、Cassandra 等）。当运行 Flink 应用时（无论是在分布式部署中，还是在 IDE 中进行测试），Flink 运行时库也必须是可用的。</p>
<h3 id="flink-核心和应用依赖性">Flink 核心和应用依赖性</h3>
<p>与大多数运行用户定义应用的系统一样，Flink 中的依赖和库有两大类。</p>
<ul>
<li>Flink 核心依赖。Flink 本身由一组运行系统所需的类和依赖关系组成，例如协调、网络、检查点、故障转移、API、操作（如窗口化）、资源管理等。所有这些类和依赖项的集合构成了 Flink 运行时的核心，在 Flink 应用启动时必须存在。</li>
</ul>
<p>这些核心类和依赖项被打包在 flink-dist jar 中。它们是 Flink 的 lib 文件夹的一部分，也是基本的 Flink 容器镜像的一部分。把这些依赖关系想象成类似于 Java 的核心库（rt.jar，charsets.jar 等），其中包含了 String 和 List 等类。</p>
<p>Flink Core Dependencies 不包含任何连接器或库（CEP、SQL、ML 等），以避免默认情况下 classpath 中的依赖关系和类数量过多。事实上，我们尽量让核心依赖关系保持纤细，以保持默认 classpath 小，避免依赖冲突。</p>
<ul>
<li>用户应用依赖是指特定用户应用所需要的所有连接器、格式或库。</li>
</ul>
<p>用户应用程序通常被打包成一个应用程序 jar，其中包含了应用程序代码和所需的连接器和库依赖。</p>
<p>用户应用依赖关系明确不包括 Flink DataStream API 和运行时依赖关系，因为这些已经是 Flink 核心依赖关系的一部分。</p>
<h3 id="设置一个项目-基本依赖性">设置一个项目: 基本依赖性</h3>
<p>每一个 Flink 应用都需要最低限度的 API 依赖关系，来进行开发。</p>
<p>当手动设置项目时，你需要为 Java/Scala API 添加以下依赖关系（这里用 Maven 语法表示，但同样的依赖关系也适用于其他构建工具（Gradle、SBT 等）。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-scala_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>重要：请注意，所有这些依赖关系的范围都被设置为 <em>provided</em>。这意味着它们需要被编译，但它们不应该被打包到项目的应用程序 jar 文件中&ndash;这些依赖是 Flink 核心依赖，在任何设置中都是可用的。</p>
<p>强烈建议将这些依赖关系保持在 <em>provid</em> 的作用域内。如果它们没有被设置为 <em>provided</em>，最好的情况是生成的 JAR 变得过大，因为它也包含了所有 Flink 核心依赖。最坏的情况是，添加到应用程序的 jar 文件中的 Flink 核心依赖与你自己的一些依赖版本发生冲突（通常通过倒类加载来避免）。</p>
<p>关于 IntelliJ 的说明：要使应用程序在 IntelliJ IDEA 中运行，就必须在运行配置中勾选 Include dependencies with &ldquo;Provided&rdquo; scope box。如果这个选项不可用（可能是由于使用了旧的 IntelliJ IDEA 版本），那么一个简单的变通方法是创建一个调用应用程序 <code>main()</code> 方法的测试。</p>
<h3 id="添加连接器和库依赖性">添加连接器和库依赖性</h3>
<p>大多数应用都需要特定的连接器或库来运行，例如与 Kafka、Cassandra 等的连接器。这些连接器不是 Flink 核心依赖的一部分，必须作为依赖关系添加到应用程序中。</p>
<p>下面是一个将 Kafka 的连接器作为依赖项添加的例子（Maven 语法）。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>flink-connector-kafka_2.11<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>我们建议将应用程序代码和所有需要的依赖关系打包成一个带有依赖关系的 jar，我们称之为应用 jar。应用 jar 可以提交给一个已经运行的 Flink 集群，或者添加到 Flink 应用容器镜像中。</p>
<p>从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration.html">Java 项目模板</a>或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration">Scala 项目模板</a>创建的项目被配置为在运行 <code>mvn clean package</code> 时自动将应用依赖关系包含到应用 jar 中。对于没有从这些模板中设置的项目，我们建议添加 Maven Shade Plugin（如下文附录中所列）来构建包含所有所需依赖项的应用 jar。</p>
<p>重要的是。为了让 Maven（和其他构建工具）正确地将依赖关系打包到应用 jar 中，这些应用依赖关系必须在编译范围中指定（与核心依赖关系不同，后者必须在提供的范围中指定）。</p>
<h3 id="scala-版本">Scala 版本</h3>
<p>Scala 版本(2.11, 2.12 等)彼此之间不是二进制兼容的。因此，Flink for Scala 2.11 不能用于使用 Scala 2.12 的应用程序。</p>
<p>所有的 Flink 依赖性都是以 Scala 版本为后缀的，例如 flink-streaming-scala_2.11。</p>
<p>只使用 Java 的开发者可以选择任何 Scala 版本，Scala 开发者需要选择与其应用的 Scala 版本相匹配的 Scala 版本。</p>
<p>请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/flinkDev/building.html#scala-versions">构建指南</a>，了解如何为特定的 Scala 版本构建 Flink。</p>
<h3 id="hadoop-依赖性">Hadoop 依赖性</h3>
<p>一般规则：永远不需要直接将 Hadoop 依赖关系添加到您的应用程序中。唯一的例外是当使用现有的 Hadoop 输入/输出格式和 Flink 的 Hadoop  兼容性包装时。</p>
<p>如果您想将 Flink 与 Hadoop 一起使用，您需要有一个包含 Hadoop 依赖的 Flink 设置，而不是将 Hadoop 添加为应用程序依赖。详情请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/hadoop.html">Hadoop 设置指南</a>。</p>
<p>这种设计主要有两个原因。</p>
<ul>
<li>
<p>一些 Hadoop 交互发生在 Flink 的核心中，可能是在用户应用启动之前，例如为检查点设置 HDFS，通过 Hadoop 的 Kerberos 令牌进行认证，或者在 YARN 上进行部署。</p>
</li>
<li>
<p>Flink 的倒类加载方法将许多过渡性依赖从核心依赖中隐藏起来。这不仅适用于 Flink 自身的核心依赖，也适用于 Hadoop 在设置中存在的依赖。这样一来，应用程序可以使用相同依赖的不同版本，而不会遇到依赖冲突（相信我们，这是一个大问题，因为 Hadoop 的依赖树是巨大的）。</p>
</li>
</ul>
<p>如果你在 IDE 内部的测试或开发过程中需要 Hadoop 依赖关系（例如用于 HDFS 访问），请将这些依赖关系配置成类似于要测试或提供的依赖关系的范围。</p>
<h3 id="maven-快速入门">Maven 快速入门</h3>
<p><strong>所需</strong></p>
<p>唯一的要求是工作中的 Maven 3.0.4（或更高）和 Java 8.x 的安装。</p>
<p><strong>创建项目</strong></p>
<p>使用以下命令之一来创建项目。</p>
<ul>
<li>使用 Maven 原型</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ mvn archetype:generate                           <span class="se">\
</span><span class="se"></span>  -DarchetypeGroupId<span class="o">=</span>org.apache.flink              <span class="se">\
</span><span class="se"></span>  -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-java      <span class="se">\
</span><span class="se"></span>  -DarchetypeVersion<span class="o">=</span>1.11.0
</code></pre></div><p>这可以让你为新创建的项目命名，它将交互式地要求你提供 groupId、artifactId 和包名。</p>
<ul>
<li>运行快速启动脚本</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ curl https://flink.apache.org/q/quickstart.sh <span class="p">|</span> bash -s 1.11.0
</code></pre></div><p>我们建议您将该项目导入到您的 IDE 中进行开发和测试。IntelliJ IDEA 支持开箱即用的 Maven 项目。如果您使用 Eclipse，<a href="http://www.eclipse.org/m2e/">m2e 插件</a>允许<a href="http://books.sonatype.com/m2eclipse-book/reference/creating-sect-importing-projects.html#fig-creating-import">导入 Maven 项目</a>。有些 Eclipse 捆绑包默认包含该插件，有些则需要您手动安装。</p>
<p>请注意：Java 默认的 JVM 堆大小对 Flink 来说可能太小。你必须手动增加它。在 Eclipse 中，选择 Run Configurations -&gt; Arguments，并在 VM Arguments 框中写下 -Xmx800m。在 IntelliJ IDEA 中推荐的改变 JVM 选项的方法是来自 Help | Edit Custom VM Options 菜单。详情请看<a href="https://intellij-support.jetbrains.com/hc/en-us/articles/206544869-Configuring-JVM-options-and-platform-properties">这篇文章</a>。</p>
<h4 id="构建项目">构建项目</h4>
<p>如果你想构建/打包你的项目，进入你的项目目录并运行 &ldquo;mvn clean package&rdquo; 命令。你会发现一个 JAR 文件，其中包含了你的应用程序，加上你可能已经添加的连接器和库作为应用程序的依赖关系：<code>target/&lt;artifact-id&gt;-&lt;version&gt;.jar</code>。</p>
<p>注意：如果您使用与 StreamingJob 不同的类作为应用程序的主类/入口点，我们建议您相应地更改 pom.xml 文件中的 mainClass 设置。这样，Flink 就可以从 JAR 文件中运行应用程序，而不需要额外指定主类。</p>
<h3 id="gradle">Gradle</h3>
<p><strong>需求</strong></p>
<p>唯一的要求是工作的 Gradle 3.x（或更高）和 Java 8.x 安装。</p>
<p><strong>创建项目</strong></p>
<p>使用以下命令之一来创建一个项目。</p>
<ul>
<li>Gradle 例子</li>
</ul>
<p><strong>build.gradle</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="err">buildscript</span> <span class="p">{</span>
    <span class="err">repositories</span> <span class="err">{</span>
        <span class="err">jcenter()</span> <span class="err">//</span> <span class="err">this</span> <span class="err">applies</span> <span class="err">only</span> <span class="err">to</span> <span class="err">the</span> <span class="err">Gradle</span> <span class="err">&#39;Shadow&#39;</span> <span class="err">plugin</span>
    <span class="p">}</span>
    <span class="err">dependencies</span> <span class="p">{</span>
        <span class="err">classpath</span> <span class="err">&#39;com.github.jengelman.gradle.plugins:shadow:2.0.4&#39;</span>
    <span class="p">}</span>
<span class="err">}</span>

<span class="err">plugins</span> <span class="p">{</span>
    <span class="err">id</span> <span class="err">&#39;java&#39;</span>
    <span class="err">id</span> <span class="err">&#39;application&#39;</span>
    <span class="err">//</span> <span class="err">shadow</span> <span class="err">plugin</span> <span class="err">to</span> <span class="err">produce</span> <span class="err">fat</span> <span class="err">JARs</span>
    <span class="err">id</span> <span class="err">&#39;com.github.johnrengelman.shadow&#39;</span> <span class="err">version</span> <span class="err">&#39;2.0.4&#39;</span>
<span class="p">}</span>


<span class="err">//</span> <span class="err">artifact</span> <span class="err">properties</span>
<span class="err">group</span> <span class="err">=</span> <span class="err">&#39;org.myorg.quickstart&#39;</span>
<span class="err">version</span> <span class="err">=</span> <span class="err">&#39;</span><span class="mf">0.1</span><span class="err">-SNAPSHOT&#39;</span>
<span class="err">mainClassName</span> <span class="err">=</span> <span class="err">&#39;org.myorg.quickstart.StreamingJob&#39;</span>
<span class="err">description</span> <span class="err">=</span> <span class="s2">&#34;&#34;&#34;Flink Quickstart Job&#34;&#34;&#34;</span>

<span class="err">ext</span> <span class="p">{</span>
    <span class="err">javaVersion</span> <span class="err">=</span> <span class="err">&#39;1.8&#39;</span>
    <span class="err">flinkVersion</span> <span class="err">=</span> <span class="err">&#39;1.11.0&#39;</span>
    <span class="err">scalaBinaryVersion</span> <span class="err">=</span> <span class="err">&#39;2.11&#39;</span>
    <span class="err">slf4jVersion</span> <span class="err">=</span> <span class="err">&#39;1.7.15&#39;</span>
    <span class="err">log4jVersion</span> <span class="err">=</span> <span class="err">&#39;2.12.1&#39;</span>
<span class="p">}</span>


<span class="err">sourceCompatibility</span> <span class="err">=</span> <span class="err">javaVersion</span>
<span class="err">targetCompatibility</span> <span class="err">=</span> <span class="err">javaVersion</span>
<span class="err">tasks.withType(JavaCompile)</span> <span class="p">{</span>
	<span class="err">options.encoding</span> <span class="err">=</span> <span class="err">&#39;UTF-8&#39;</span>
<span class="p">}</span>

<span class="err">applicationDefaultJvmArgs</span> <span class="err">=</span> <span class="p">[</span><span class="s2">&#34;-Dlog4j.configurationFile=log4j2.properties&#34;</span><span class="p">]</span>

<span class="err">task</span> <span class="err">wrapper(type:</span> <span class="err">Wrapper)</span> <span class="p">{</span>
    <span class="err">gradleVersion</span> <span class="err">=</span> <span class="err">&#39;3.1&#39;</span>
<span class="p">}</span>

<span class="err">//</span> <span class="err">declare</span> <span class="err">where</span> <span class="err">to</span> <span class="err">find</span> <span class="err">the</span> <span class="err">dependencies</span> <span class="err">of</span> <span class="err">your</span> <span class="err">project</span>
<span class="err">repositories</span> <span class="p">{</span>
    <span class="err">mavenCentral()</span>
    <span class="err">maven</span> <span class="err">{</span> <span class="err">url</span> <span class="nt">&#34;https://repository.apache.org/content/repositories/snapshots/&#34;</span> <span class="p">}</span>
<span class="err">}</span>

<span class="err">//</span> <span class="err">NOTE:</span> <span class="err">We</span> <span class="err">cannot</span> <span class="err">use</span> <span class="s2">&#34;compileOnly&#34;</span> <span class="err">or</span> <span class="s2">&#34;shadow&#34;</span> <span class="err">configurations</span> <span class="err">since</span> <span class="err">then</span> <span class="err">we</span> <span class="err">could</span> <span class="err">not</span> <span class="err">run</span> <span class="err">code</span>
<span class="err">//</span> <span class="err">in</span> <span class="err">the</span> <span class="err">IDE</span> <span class="err">or</span> <span class="err">with</span> <span class="s2">&#34;gradle run&#34;</span><span class="err">.</span> <span class="err">We</span> <span class="err">also</span> <span class="err">cannot</span> <span class="err">exclude</span> <span class="err">transitive</span> <span class="err">dependencies</span> <span class="err">from</span> <span class="err">the</span>
<span class="err">//</span> <span class="err">shadowJar</span> <span class="err">yet</span> <span class="err">(see</span> <span class="err">https://github.com/johnrengelman/shadow/issues/</span><span class="mi">159</span><span class="err">).</span>
<span class="err">//</span> <span class="err">-&gt;</span> <span class="err">Explicitly</span> <span class="err">define</span> <span class="err">the</span> <span class="err">//</span> <span class="err">libraries</span> <span class="err">we</span> <span class="err">want</span> <span class="err">to</span> <span class="err">be</span> <span class="err">included</span> <span class="err">in</span> <span class="err">the</span> <span class="s2">&#34;flinkShadowJar&#34;</span> <span class="err">configuration!</span>
<span class="err">configurations</span> <span class="p">{</span>
    <span class="err">flinkShadowJar</span> <span class="err">//</span> <span class="err">dependencies</span> <span class="err">which</span> <span class="err">go</span> <span class="err">into</span> <span class="err">the</span> <span class="err">shadowJar</span>

    <span class="err">//</span> <span class="err">always</span> <span class="err">exclude</span> <span class="err">these</span> <span class="err">(also</span> <span class="err">from</span> <span class="err">transitive</span> <span class="err">dependencies)</span> <span class="err">since</span> <span class="err">they</span> <span class="err">are</span> <span class="err">provided</span> <span class="err">by</span> <span class="err">Flink</span>
    <span class="err">flinkShadowJar.exclude</span> <span class="err">group:</span> <span class="err">&#39;org.apache.flink&#39;,</span> <span class="err">module:</span> <span class="err">&#39;force-shading&#39;</span>
    <span class="err">flinkShadowJar.exclude</span> <span class="err">group:</span> <span class="err">&#39;com.google.code.findbugs&#39;,</span> <span class="err">module:</span> <span class="err">&#39;jsr305&#39;</span>
    <span class="err">flinkShadowJar.exclude</span> <span class="err">group:</span> <span class="err">&#39;org.slf4j&#39;</span>
    <span class="err">flinkShadowJar.exclude</span> <span class="err">group:</span> <span class="err">&#39;org.apache.logging.log4j&#39;</span>
<span class="p">}</span>

<span class="err">//</span> <span class="err">declare</span> <span class="err">the</span> <span class="err">dependencies</span> <span class="err">for</span> <span class="err">your</span> <span class="err">production</span> <span class="err">and</span> <span class="err">test</span> <span class="err">code</span>
<span class="err">dependencies</span> <span class="p">{</span>
    <span class="err">//</span> <span class="err">--------------------------------------------------------------</span>
    <span class="err">//</span> <span class="err">Compile-time</span> <span class="err">dependencies</span> <span class="err">that</span> <span class="err">should</span> <span class="err">NOT</span> <span class="err">be</span> <span class="err">part</span> <span class="err">of</span> <span class="err">the</span>
    <span class="err">//</span> <span class="err">shadow</span> <span class="err">jar</span> <span class="err">and</span> <span class="err">are</span> <span class="err">provided</span> <span class="err">in</span> <span class="err">the</span> <span class="err">lib</span> <span class="err">folder</span> <span class="err">of</span> <span class="err">Flink</span>
    <span class="err">//</span> <span class="err">--------------------------------------------------------------</span>
    <span class="err">compile</span> <span class="nt">&#34;org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}&#34;</span>

    <span class="err">//</span> <span class="err">--------------------------------------------------------------</span>
    <span class="err">//</span> <span class="err">Dependencies</span> <span class="err">that</span> <span class="err">should</span> <span class="err">be</span> <span class="err">part</span> <span class="err">of</span> <span class="err">the</span> <span class="err">shadow</span> <span class="err">jar</span><span class="p">,</span> <span class="err">e.g.</span>
    <span class="err">//</span> <span class="err">connectors.</span> <span class="err">These</span> <span class="err">must</span> <span class="err">be</span> <span class="err">in</span> <span class="err">the</span> <span class="err">flinkShadowJar</span> <span class="err">configuration!</span>
    <span class="err">//</span> <span class="err">--------------------------------------------------------------</span>
    <span class="err">//flinkShadowJar</span> <span class="nt">&#34;org.apache.flink:flink-connector-kafka-0.11_${scalaBinaryVersion}:${flinkVersion}&#34;</span>

    <span class="err">compile</span> <span class="s2">&#34;org.apache.logging.log4j:log4j-api:${log4jVersion}&#34;</span>
    <span class="err">compile</span> <span class="s2">&#34;org.apache.logging.log4j:log4j-core:${log4jVersion}&#34;</span>
    <span class="err">compile</span> <span class="s2">&#34;org.apache.logging.log4j:log4j-slf4j-impl:${log4jVersion}&#34;</span>
    <span class="err">compile</span> <span class="s2">&#34;org.slf4j:slf4j-log4j12:${slf4jVersion}&#34;</span>

    <span class="err">//</span> <span class="err">Add</span> <span class="err">test</span> <span class="err">dependencies</span> <span class="err">here.</span>
    <span class="err">//</span> <span class="err">testCompile</span> <span class="s2">&#34;junit:junit:4.12&#34;</span>
<span class="p">}</span>

<span class="err">//</span> <span class="err">make</span> <span class="err">compileOnly</span> <span class="err">dependencies</span> <span class="err">available</span> <span class="err">for</span> <span class="err">tests:</span>
<span class="err">sourceSets</span> <span class="p">{</span>
    <span class="err">main.compileClasspath</span> <span class="err">+=</span> <span class="err">configurations.flinkShadowJar</span>
    <span class="err">main.runtimeClasspath</span> <span class="err">+=</span> <span class="err">configurations.flinkShadowJar</span>

    <span class="err">test.compileClasspath</span> <span class="err">+=</span> <span class="err">configurations.flinkShadowJar</span>
    <span class="err">test.runtimeClasspath</span> <span class="err">+=</span> <span class="err">configurations.flinkShadowJar</span>

    <span class="err">javadoc.classpath</span> <span class="err">+=</span> <span class="err">configurations.flinkShadowJar</span>
<span class="p">}</span>

<span class="err">run.classpath</span> <span class="err">=</span> <span class="err">sourceSets.main.runtimeClasspath</span>

<span class="err">jar</span> <span class="p">{</span>
    <span class="err">manifest</span> <span class="err">{</span>
        <span class="err">attributes</span> <span class="err">&#39;Built-By&#39;:</span> <span class="err">System.getProperty(&#39;user.name&#39;),</span>
                <span class="err">&#39;Build-Jdk&#39;:</span> <span class="err">System.getProperty(&#39;java.version&#39;)</span>
    <span class="p">}</span>
<span class="err">}</span>

<span class="err">shadowJar</span> <span class="p">{</span>
    <span class="err">configurations</span> <span class="err">=</span> <span class="err">[project.configurations.flinkShadowJar]</span>
<span class="p">}</span>
</code></pre></div><p><strong>setting.gradle</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="err">rootProject.name</span> <span class="err">=</span> <span class="err">&#39;quickstart&#39;</span>
</code></pre></div><p>这允许你为你新创建的项目命名，它将交互式地询问你项目的名称、组织（也用于包名）、项目版本、Scala 和 Flink。它将交互式地要求你提供项目名称、组织（也用于包名）、项目版本、Scala 和 Flink 版本。</p>
<ul>
<li>运行快速启动脚本</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">bash -c <span class="s2">&#34;</span><span class="k">$(</span>curl https://flink.apache.org/q/gradle-quickstart.sh<span class="k">)</span><span class="s2">&#34;</span> -- 1.11.0 2.11
</code></pre></div><p>我们建议你将这个项目导入到你的 IDE 中进行开发和测试。IntelliJ IDEA 在安装 Gradle 插件后，支持 Gradle 项目。Eclipse 通过 <a href="https://projects.eclipse.org/projects/tools.buildship">Eclipse Buildship</a> 插件来实现（确保在导入向导的最后一步指定 Gradle 版本&gt;=3.0，影子插件需要它）。你也可以使用 <a href="https://docs.gradle.org/current/userguide/userguide.html#ide-integration">Gradle 的 IDE 集成</a>来从 Gradle 创建项目文件。</p>
<p>请注意：Java 默认的 JVM 堆大小对 Flink 来说可能太小。你必须手动增加它。在 Eclipse 中，选择 Run Configurations -&gt; Arguments，并在 VM Arguments 框中写下 <code>-Xmx800m</code>。在 IntelliJ IDEA 中推荐的改变 JVM 选项的方法是来自 Help | Edit Custom VM Options 菜单。详情请看<a href="https://intellij-support.jetbrains.com/hc/en-us/articles/206544869-Configuring-JVM-options-and-platform-properties">这篇文章</a>。</p>
<h4 id="构建项目-1">构建项目</h4>
<p>如果你想构建/打包你的项目，去你的项目目录下运行 &ldquo;gradle clean shadowJar&rdquo; 命令，你会发现一个 JAR 文件，其中包含了你的应用程序，以及你可能已经添加到应用程序中作为依赖的连接器和库：<code>build/libs/&lt;project-name&gt;-&lt;version&gt;-all.jar</code>。</p>
<p>注意：如果你使用与 StreamingJob 不同的类作为应用程序的主类/入口点，我们建议你相应地更改 build.gradle 文件中的 mainClassName 设置。这样，Flink 就可以从 JAR 文件中运行应用程序，而无需额外指定主类。</p>
<h3 id="sbt">SBT</h3>
<h4 id="创建项目">创建项目</h4>
<p>您可以通过以下两种方法中的任何一种来构建一个新项目。</p>
<ul>
<li>使用 sbt 模板</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ sbt new tillrohrmann/flink-project.g8
</code></pre></div><ul>
<li>运行快速启动脚本</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ bash &lt;<span class="o">(</span>curl https://flink.apache.org/q/sbt-quickstart.sh<span class="o">)</span>
</code></pre></div><p>这将在指定的项目目录下创建一个 Flink 项目。</p>
<h4 id="构建项目-2">构建项目</h4>
<p>为了建立你的项目，你只需要发出 sbt clean assembly 命令。这将在 <code>target/scala_your-major-scala-version/</code> 目录下创建 fat-jar <code>your-project-name-assembly-0.1-SNAPSHOT.jar</code>。</p>
<p><strong>运行项目</strong></p>
<p>为了运行你的项目，你必须发出 sbt 运行命令。</p>
<p>默认情况下，这将在 sbt 运行的同一个 JVM 中运行你的工作。为了在不同的 JVM 中运行你的工作，请在 build.sbt 中添加以下行。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">fork in run :<span class="o">=</span> <span class="nb">true</span>
</code></pre></div><h4 id="intellij">IntelliJ</h4>
<p>我们推荐您使用 <a href="https://www.jetbrains.com/idea/">IntelliJ</a> 进行 Flink 作业开发。为了开始，您必须将新创建的项目导入到 IntelliJ 中。您可以通过 File -&gt; New -&gt; Project from Existing Sources&hellip;然后选择您的项目目录。IntelliJ 会自动检测 build.sbt 文件，并设置好一切。</p>
<p>为了运行 Flink 作业，建议选择 mainRunner 模块作为运行/调试配置的 classpath。这将确保所有被设置为提供的依赖关系在执行时都是可用的。您可以通过 Run -&gt; Edit Configurations&hellip;配置 Run/Debug 配置，然后从 Use classpath of module dropbox 中选择 mainRunner。</p>
<h4 id="eclipse">Eclipse</h4>
<p>为了将新创建的项目导入到 <a href="https://eclipse.org/">Eclipse</a> 中，首先必须为其创建 Eclipse 项目文件。这些项目文件可以通过  <a href="https://github.com/typesafehub/sbteclipse">sbteclipse</a> 插件来创建。在 PROJECT_DIR/project/plugins.sbt 文件中添加以下一行。</p>
<pre><code>addSbtPlugin(&quot;com.typeafe.sbteclipse&quot; % &quot;sbteclipse-plugin&quot; % &quot;4.0.0&quot;)
</code></pre><p>在 sbt 中使用下面的命令来创建 Eclipse 项目文件</p>
<pre><code>&gt; eclipse
</code></pre><p>现在你可以通过 File-&gt;Import&hellip;-&gt;Existing Projects into Workspace 导入 Eclipse，然后选择项目目录。</p>
<h2 id="附录-用依赖关系构建-jar-的模板">附录: 用依赖关系构建 Jar 的模板</h2>
<p>要构建一个包含声明的连接器和库所需的所有依赖关系的应用程序 JAR，可以使用以下 shade 插件定义。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;build&gt;</span>
    <span class="nt">&lt;plugins&gt;</span>
        <span class="nt">&lt;plugin&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>maven-shade-plugin<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>3.1.1<span class="nt">&lt;/version&gt;</span>
            <span class="nt">&lt;executions&gt;</span>
                <span class="nt">&lt;execution&gt;</span>
                    <span class="nt">&lt;phase&gt;</span>package<span class="nt">&lt;/phase&gt;</span>
                    <span class="nt">&lt;goals&gt;</span>
                        <span class="nt">&lt;goal&gt;</span>shade<span class="nt">&lt;/goal&gt;</span>
                    <span class="nt">&lt;/goals&gt;</span>
                    <span class="nt">&lt;configuration&gt;</span>
                        <span class="nt">&lt;artifactSet&gt;</span>
                            <span class="nt">&lt;excludes&gt;</span>
                                <span class="nt">&lt;exclude&gt;</span>com.google.code.findbugs:jsr305<span class="nt">&lt;/exclude&gt;</span>
                                <span class="nt">&lt;exclude&gt;</span>org.slf4j:*<span class="nt">&lt;/exclude&gt;</span>
                                <span class="nt">&lt;exclude&gt;</span>log4j:*<span class="nt">&lt;/exclude&gt;</span>
                            <span class="nt">&lt;/excludes&gt;</span>
                        <span class="nt">&lt;/artifactSet&gt;</span>
                        <span class="nt">&lt;filters&gt;</span>
                            <span class="nt">&lt;filter&gt;</span>
                                <span class="c">&lt;!-- Do not copy the signatures in the META-INF folder.
</span><span class="c">                                Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;</span>
                                <span class="nt">&lt;artifact&gt;</span>*:*<span class="nt">&lt;/artifact&gt;</span>
                                <span class="nt">&lt;excludes&gt;</span>
                                    <span class="nt">&lt;exclude&gt;</span>META-INF/*.SF<span class="nt">&lt;/exclude&gt;</span>
                                    <span class="nt">&lt;exclude&gt;</span>META-INF/*.DSA<span class="nt">&lt;/exclude&gt;</span>
                                    <span class="nt">&lt;exclude&gt;</span>META-INF/*.RSA<span class="nt">&lt;/exclude&gt;</span>
                                <span class="nt">&lt;/excludes&gt;</span>
                            <span class="nt">&lt;/filter&gt;</span>
                        <span class="nt">&lt;/filters&gt;</span>
                        <span class="nt">&lt;transformers&gt;</span>
                            <span class="nt">&lt;transformer</span> <span class="na">implementation=</span><span class="s">&#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&#34;</span><span class="nt">&gt;</span>
                                <span class="nt">&lt;mainClass&gt;</span>my.programs.main.clazz<span class="nt">&lt;/mainClass&gt;</span>
                            <span class="nt">&lt;/transformer&gt;</span>
                        <span class="nt">&lt;/transformers&gt;</span>
                    <span class="nt">&lt;/configuration&gt;</span>
                <span class="nt">&lt;/execution&gt;</span>
            <span class="nt">&lt;/executions&gt;</span>
        <span class="nt">&lt;/plugin&gt;</span>
    <span class="nt">&lt;/plugins&gt;</span>
<span class="nt">&lt;/build&gt;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/project-configuration.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Event Time]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Datastream API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="related" type="text/html" title="Generating Watermarks" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="related" type="text/html" title="使用状态" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="related" type="text/html" title="内置的水印生成器" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="状态和容错性" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-event-time/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Event Time</blockquote><h2 id="event-timehttpsciapacheorgprojectsflinkflink-docs-release-111devevent_timehtml"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">Event Time</a></h2>
<p>在本节中，您将学习如何编写时间感知(time-aware)的 Flink 程序。请看一下<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html">及时流处理</a>，了解及时流处理背后的概念。</p>
<p>关于如何在 Flink 程序中使用时间的信息请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">windowing</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">ProcessFunction</a>。</p>
<p>使用事件时间处理的先决条件是设置正确的时间特性(<em>time characteristic</em>)。该设置定义了数据流源的行为（例如，它们是否会分配时间戳），以及像 <code>KeyedStream.timeWindow(Time.seconds(30))</code> 这样的窗口操作应该使用什么时间概念。</p>
<p>你可以使用 <code>StreamExecutionEnvironment.setStreamTimeCharacteristic()</code> 设置时间特性:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="n">env</span><span class="o">.</span><span class="n">setStreamTimeCharacteristic</span><span class="o">(</span><span class="nc">TimeCharacteristic</span><span class="o">.</span><span class="nc">EventTime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">](</span><span class="n">topic</span><span class="o">,</span> <span class="n">schema</span><span class="o">,</span> <span class="n">props</span><span class="o">))</span>

<span class="n">stream</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">getUser</span> <span class="o">)</span>
    <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">(</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">b</span><span class="o">)</span> <span class="o">)</span>
    <span class="o">.</span><span class="n">addSink</span><span class="o">(...)</span>
</code></pre></div><p>需要注意的是，为了在事件时间(<em>event time</em>)中运行这个例子，程序需要使用直接为数据定义事件时间并自己发射水印的源，或者程序必须在源之后注入一个时间戳分配器(<em>Timestamp Assigner</em>)与水印生成器(<em>Watermark Generator</em>)。这些函数描述了如何访问事件时间戳，以及事件流表现出何种程度的无序性。</p>
<h2 id="下一步该怎么走">下一步该怎么走？</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html">生成水印</a>。展示了如何编写时间戳分配器和水印生成器，这些都是事件时间(event-time)感知 Flink 应用所需要的。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamp_extractors.html">内置的水印生成器</a>。概述了内置的水印生成器。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/debugging_event_time.html">调试窗口和事件时间</a>：展示如何调试事件时间 Flink 应用程序中围绕水印和时间戳的问题。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink Datastream API 编程指南]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="related" type="text/html" title="Event Time" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="related" type="text/html" title="Generating Watermarks" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="related" type="text/html" title="使用状态" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="related" type="text/html" title="内置的水印生成器" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="状态和容错性" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Datastream API Programming Guide</blockquote><h2 id="flink-datastream-api-编程指南httpsciapacheorgprojectsflinkflink-docs-release-111devdatastream_apihtml"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">Flink DataStream API 编程指南</a></h2>
<p>Flink 中的 DataStream 程序是对数据流实现转换的常规程序（如过滤、更新状态、定义窗口、聚合）。数据流最初是由各种源（如消息队列、套接字流、文件）创建的。结果通过接收器(sink)返回，例如可以将数据写入文件，或标准输出（例如命令行终端）。Flink 程序可以在各种环境下运行，独立运行，或者嵌入到其他程序中。执行可以发生在本地 JVM 中，也可以发生在许多机器的集群中。</p>
<p>为了创建你自己的 Flink DataStream 程序，我们鼓励你从<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">一个 Flink 程序的骨架</a>开始，并逐步添加你自己的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/index.html">流转换</a>。其余部分作为额外操作和高级功能的参考。</p>
<h2 id="什么是-datastream">什么是 DataStream？</h2>
<p>DataStream API 的名字来自于特殊的 <code>DataStream</code> 类，它用于表示 Flink 程序中的数据集合。你可以把它们看作是不可改变的数据集合，可以包含重复的数据。这些数据既可以是有限的，也可以是无边界的，你用来处理它们的 API 是一样的。</p>
<p>DataStream 在用法上与普通的 Java Collection 类似，但在一些关键方面却有很大不同。它们是不可改变的，这意味着一旦它们被创建，你就不能添加或删除元素。你也不能简单地检查里面的元素，而只能使用 DataStream API 操作对它们进行操作，这也被称为转换。</p>
<p>你可以通过在 Flink 程序中添加一个源来创建一个初始的 DataStream。然后你可以从中派生新的流，并通过使用 API 方法，如 <code>map</code>、<code>filter</code> 等来组合它们。</p>
<h2 id="flink-程序的骨架">Flink 程序的骨架</h2>
<p>Flink 程序看起来就像转换 DataStream 的普通程序。每个程序由相同的基本部分组成。</p>
<ol>
<li>获取一个执行环境</li>
<li>加载/创建初始数据。</li>
<li>指定该数据的转换。</li>
<li>指定计算结果的位置。</li>
<li>触发程序执行</li>
</ol>
<p>现在我们将对其中的每一个步骤进行概述，更多细节请参考相关章节。注意，Scala DataStream API 的所有核心类都可以在 <a href="https://github.com/apache/flink/blob/master//flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala">org.apache.flink.stream.api.scala</a> 中找到。</p>
<p><code>StreamExecutionEnvironment</code> 是所有 Flink 程序的基础。你可以使用 <code>StreamExecutionEnvironment</code> 上的这些静态方法获得一个。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="n">createRemoteEnvironment</span><span class="o">(</span><span class="n">host</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">port</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">jarFiles</span><span class="k">:</span> <span class="kt">String*</span><span class="o">)</span>
</code></pre></div><p>通常情况下，你只需要使用 <code>getExecutionEnvironment()</code>，因为这将根据上下文做正确的事情：如果你在 IDE 里面执行你的程序，或者作为一个普通的 Java 程序，它将创建一个本地环境，在你的本地机器上执行你的程序。如果你从你的程序中创建了一个 JAR 文件，并通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html">命令行</a>调用它，Flink 集群管理器将执行你的主方法，并且 <code>getExecutionEnvironment()</code> 将返回一个在集群上执行你的程序的执行环境。</p>
<p>对于指定数据源，执行环境有几种方法可以使用不同的方法从文件中读取数据：你可以只是逐行读取，作为 CSV 文件，或者使用任何其他提供的数据源。如果只是将文本文件作为一个行的序列来读取，你可以使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">text</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path/to/file&#34;</span><span class="o">)</span>
</code></pre></div><p>这将为您提供一个 DataStream，然后您可以在其上应用转换来创建新的派生 DataStream。</p>
<p>你可以通过调用 DataStream 上的方法和转换函数来应用转换。例如，一个 <code>map</code> 转换看起来像这样。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">mapped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
</code></pre></div><p>这将通过将原始集合中的每一个字符串转换为一个 Integer 来创建一个新的 DataStream。</p>
<p>一旦你有了一个包含最终结果的 DataStream，你就可以通过创建一个接收器(sink)将其写入外部系统。这些只是创建接收器的一些示例方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">writeAsText</span><span class="o">(</span><span class="n">path</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>

<span class="n">print</span><span class="o">()</span>
</code></pre></div><p>一旦你指定了完整的程序，你需要通过调用 <code>StreamExecutionEnvironment</code> 上的 <code>execution()</code> 来触发程序的执行。根据 <code>ExecutionEnvironment</code> 的类型，将在你的本地机器上触发执行，或者将你的程序提交到集群上执行。</p>
<p><code>execute()</code> 方法将等待作业完成，然后返回一个 <code>JobExecutionResult</code>，这个包含执行时间和累加器结果。</p>
<p>如果你不想等待作业完成，你可以在 <code>StreamExecutionEnvironment</code> 上调用 <code>executeAysnc()</code> 来触发异步作业执行。它将返回一个 <code>JobClient</code>，你可以用它与刚刚提交的作业进行通信。例如，下面是如何通过使用 <code>executeAsync()</code> 来实现 <code>execute()</code> 的语义。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">JobClient</span> <span class="n">jobClient</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">executeAsync</span><span class="o">();</span>

<span class="kd">final</span> <span class="n">JobExecutionResult</span> <span class="n">jobExecutionResult</span> <span class="o">=</span> <span class="n">jobClient</span><span class="o">.</span><span class="na">getJobExecutionResult</span><span class="o">(</span><span class="n">userClassloader</span><span class="o">).</span><span class="na">get</span><span class="o">();</span>
</code></pre></div><p>最后这部分关于程序执行的内容对于理解 Flink 操作何时以及如何执行至关重要。所有的 Flink 程序都是懒惰地执行的。当程序的主方法被执行时，数据加载和转换不会直接发生。相反，每个操作都被创建并添加到一个数据流图(dataflow graph)中。当执行环境上的 <code>execute()</code> 调用明确触发执行时，这些操作才会被实际执行。程序是在本地执行还是在集群上执行，取决于执行环境的类型</p>
<p>惰性求值可以让您构建复杂的程序，Flink 作为一个整体规划的单元来执行。</p>
<h2 id="示例程序">示例程序</h2>
<p>下面的程序是一个完整的，工作的流媒体窗口单词计数应用程序的例子，它可以在5秒的窗口中计算来自 Web Socket 的单词。你可以复制和粘贴代码在本地运行它。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span>

<span class="k">object</span> <span class="nc">WindowWordCount</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
    <span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">socketTextStream</span><span class="o">(</span><span class="s">&#34;localhost&#34;</span><span class="o">,</span> <span class="mi">9999</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">text</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">toLowerCase</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;\\W+&#34;</span><span class="o">)</span> <span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">nonEmpty</span> <span class="o">}</span> <span class="o">}</span>
      <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span>
      <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
      <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
      <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

    <span class="n">counts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

    <span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&#34;Window Stream WordCount&#34;</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>To run the example program, start the input stream with netcat first from a terminal:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">nc -lk <span class="m">9999</span>
</code></pre></div><p>只需输入一些单词，按回车键输入一个新单词。这些词将被输入到单词计数程序中。如果你想看到大于1的计数，请在5秒内反复输入同一个单词（如果你打字没那么快，请从5秒开始增加窗口大小☺）。</p>
<h2 id="数据源">数据源</h2>
<p>源是你的程序读取其输入的地方。你可以通过使用 <code>StreamExecutionEnvironment.addSource(sourceFunction)</code> 将一个源附加到你的程序中。Flink 提供了许多预先实现的 <code>SourceFunction</code>，但是你可以通过实现非并行源的 <code>SourceFunction</code>，或者实现并行源的 <code>ParallelSourceFunction</code> 接口或扩展 <code>RichParallelSourceFunction</code> 来编写自己的自定义源。</p>
<p>有几种预定义的流源(stream sources)可以从 <code>StreamExecutionEnvironment</code> 中访问。</p>
<p>基于文件的。</p>
<ul>
<li>
<p><code>readTextFile(path)</code> - 逐行读取文本文件，即遵循 <code>TextInputFormat</code> 规范的文件，并将其作为字符串返回。</p>
</li>
<li>
<p><code>readFile(fileInputFormat, path)</code> - 根据指定的文件输入格式读取（一次）文件。</p>
</li>
<li>
<p><code>readFile(fileInputFormat, path, watchType, interval, pathFilter)</code> - 这是前面两个方法内部调用的方法。它根据给定的 <code>fileInputFormat</code> 读取路径中的文件。根据所提供的 <code>watchType</code>，这个源可能会周期性地监视(每隔 interval 毫秒)路径中的新数据(<code>FileProcessingMode.PROCESS_CONTINUOUSLY</code>)，或者处理一次当前路径中的数据并退出(<code>FileProcessingMode.PROCESS_ONCE</code>)。使用 <code>pathFilter</code>，用户可以进一步排除被处理的文件。</p>
</li>
</ul>
<p><em>实现</em>:</p>
<p>在底层下，Flink 将文件读取过程分成两个子任务(sub-tasks)，即目录监控和数据读取。这些子任务中的每一个都是由一个单独的实体实现的。监控由一个单一的、非并行（并行度=1）的任务实现，而读取则由多个任务(task)并行运行。后者的并行度等于作业的并行度(job parallelism)。单个监控任务的作用是扫描目录（根据 <code>watchType</code> 的不同，定期或只扫描一次），找到要处理的文件，将其分割，并将这些分割的文件分配给下游的读取器。读取器是那些将读取实际数据的东西。每个分片只能由一个读取器读取，而一个读取器可以读取多个分片，一个接一个。</p>
<p><em>重要提示</em>:</p>
<ol>
<li>
<p>如果 <code>watchType</code> 被设置为 <code>FileProcessingMode.PROCESS_CONTINUOUSLY</code>，当一个文件被修改时，它的内容会被完全重新处理。这可能会打破&quot;精确地一次&quot;(exactly-once)的语义，因为在文件末尾追加数据会导致其所有内容被重新处理。</p>
</li>
<li>
<p>如果 <code>watchType</code> 被设置为 <code>FileProcessingMode.PROCESS_ONCE</code>，那么源就会对路径扫描一次并退出，而不会等待读取器完成对文件内容的读取。当然，读取器会继续读取，直到读取完所有文件内容。关闭源会导致在这之后不再有检查点。这可能会导致节点故障后的恢复速度变慢，因为作业(job)将从最后一个检查点开始恢复读取。</p>
</li>
</ol>
<p>基于 Socket 的:</p>
<ul>
<li><code>socketTextStream</code> - 从套接字读取。元素可以用定界符分开。</li>
</ul>
<p>基于集合的:</p>
<ul>
<li>
<p><code>fromCollection(Seq)</code> - 从 <code>Java Java.util.Collection</code> 中创建数据流。集合中的所有元素必须是相同的类型。</p>
</li>
<li>
<p><code>fromCollection(Iterator)</code> - 从迭代器中创建一个数据流。该类指定迭代器返回的元素的数据类型。</p>
</li>
<li>
<p><code>fromElements(elements: _*)</code> - 从给定的对象序列中创建一个数据流。所有对象必须是相同的类型。</p>
</li>
<li>
<p><code>fromParallelCollection(SplittableIterator)</code> - 从迭代器中并行创建数据流。该类指定了迭代器返回的元素的数据类型。</p>
</li>
<li>
<p><code>generateSequence(from, to)</code> - 在给定的区间内并行生成数字序列。</p>
</li>
</ul>
<p>自定义的:</p>
<ul>
<li><code>addSource</code> - 附加一个新的源函数。例如，要从 Apache Kafka 读取数据，你可以使用 <code>addSource(new FlinkKafkaConsumer010&lt;&gt;(...))</code>。更多细节请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/">连接器</a>。</li>
</ul>
<h2 id="数据流转换">数据流转换</h2>
<p>请参阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/index.html">operators</a> 以了解可用的流转换的概述。</p>
<h2 id="数据接收器">数据接收器</h2>
<p>数据接收器消耗 DataStream，并将其转发到文件、套接字、外部系统或打印。Flink 带有各种内置的输出格式，这些格式被封装在 DataStream 的操作后面。</p>
<ul>
<li>
<p><code>writeAsText()</code> / <code>TextOutputFormat</code> - 将元素逐行写入字符串。这些字符串是通过调用每个元素的 <code>toString()</code> 方法获得的。</p>
</li>
<li>
<p><code>writeAsCsv(...)</code> / <code>CsvOutputFormat</code> - 将元组写成逗号分隔的值文件。行和字段定界符是可配置的。每个字段的值来自对象的 <code>toString()</code> 方法。</p>
</li>
<li>
<p><code>print()</code> / <code>printToErr()</code> - 将每个元素的 <code>toString()</code> 值打印在标准输出/标准错误流上。可以选择提供一个前缀(msg)，这个前缀被添加到输出中。这可以帮助区分不同的 <code>print</code> 调用。如果并行度大于1，输出也将被预置为产生输出的任务(task)的标识符。</p>
</li>
<li>
<p><code>writeUsingOutputFormat()</code> / <code>FileOutputFormat</code> - 用于自定义文件输出的方法和基类。支持自定义对象到字节的转换。</p>
</li>
<li>
<p><code>writeToSocket</code> - 根据 <code>SerializationSchema</code> 将元素写入 socket。</p>
</li>
<li>
<p>addSink - 调用一个自定义的 sink 函数。Flink 捆绑了连接其他系统（如 Apache Kafka）的连接器，这些连接器被实现为 sink 函数。</p>
</li>
</ul>
<p>请注意，DataStream 上的 <code>write*()</code> 方法主要是为了调试的目的。它们不参与 Flink 的检查点，这意味着这些函数通常具有最多一次(at-least-once)的语义。数据冲洗到目标系统取决于 <code>OutputFormat</code> 的实现。这意味着并非所有发送到 <code>OutputFormat</code> 的元素都会立即在目标系统中显示出来。另外，在失败的情况下，这些记录可能会丢失。</p>
<p>为了可靠地、精确地一次性将流传送到文件系统中，请使用 <code>flink-connector-filesystem</code>。此外，通过 <code>.addSink(...)</code> 方法的自定义实现可以参与 Flink 的检查点，以实现精确的一次语义。</p>
<h2 id="迭代">迭代</h2>
<p>迭代流程序实现了一个步骤函数，并将其嵌入到 <code>IterativeStream</code> 中。由于 DataStream 程序可能永远不会结束，所以没有最大的迭代次数。相反，你需要指定流的哪一部分被馈入到迭代中，哪一部分使用 <code>split</code> 转换或 <code>filter</code> 转发到下游。在这里，我们展示了一个迭代的例子，其中主体（重复计算的部分）是一个简单的 <code>map</code> 转换，而反馈回来的元素是通过使用 <code>filter</code> 转发到下游的元素来区分的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">iteratedStream</span> <span class="k">=</span> <span class="n">someDataStream</span><span class="o">.</span><span class="n">iterate</span><span class="o">(</span>
  <span class="n">iteration</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iterationBody</span> <span class="k">=</span> <span class="n">iteration</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="cm">/* this is executed many times */</span><span class="o">)</span>
    <span class="o">(</span><span class="n">iterationBody</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="cm">/* one part of the stream */</span><span class="o">),</span> <span class="n">iterationBody</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="cm">/* some other part of the stream */</span><span class="o">))</span>
<span class="o">})</span>
</code></pre></div><p>例如，这里的程序是从一系列整数中连续减去1，直到它们达到零。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">someIntegers</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">generateSequence</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1000</span><span class="o">)</span>

<span class="k">val</span> <span class="n">iteratedStream</span> <span class="k">=</span> <span class="n">someIntegers</span><span class="o">.</span><span class="n">iterate</span><span class="o">(</span>
  <span class="n">iteration</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">minusOne</span> <span class="k">=</span> <span class="n">iteration</span><span class="o">.</span><span class="n">map</span><span class="o">(</span> <span class="n">v</span> <span class="k">=&gt;</span> <span class="n">v</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">stillGreaterThanZero</span> <span class="k">=</span> <span class="n">minusOne</span><span class="o">.</span><span class="n">filter</span> <span class="o">(</span><span class="k">_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">lessThanZero</span> <span class="k">=</span> <span class="n">minusOne</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span>
    <span class="o">(</span><span class="n">stillGreaterThanZero</span><span class="o">,</span> <span class="n">lessThanZero</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">)</span>
</code></pre></div><h2 id="执行参数">执行参数</h2>
<p><code>StreamExecutionEnvironment</code> 包含了 <code>ExecutionConfig</code>，它允许为运行时设置作业特定(job specific)的配置值。</p>
<p>请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/execution_configuration.html">执行配置</a>，了解大多数参数的解释。这些参数专门与 DataStream API 有关。</p>
<ul>
<li><code>setAutoWatermarkInterval(long milliseconds)</code>: 设置自动发射水印的时间间隔。你可以通过 <code>long getAutoWatermarkInterval()</code> 来获取当前值。</li>
</ul>
<h3 id="容错">容错</h3>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">状态和检查点</a>介绍了如何启用和配置 Flink 的检查点机制。</p>
<h3 id="控制延迟">控制延迟</h3>
<p>默认情况下，元素不会在网络上逐一传输（会造成不必要的网络流量），而是被缓冲。缓冲区（实际在机器之间传输）的大小可以在 Flink 配置文件中设置。虽然这种方法有利于优化吞吐量，但当传入的数据流速度不够快时，会造成延迟问题。为了控制吞吐量和延迟，你可以在执行环境上（或者在单个 operator 上）使用 <code>env.setBufferTimeout(timeoutMillis)</code> 来设置缓冲区填满的最大等待时间。过了这个时间，即使缓冲区没有满，也会自动发送。该超时的默认值为 100 ms。</p>
<p>使用方法:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span><span class="k">:</span> <span class="kt">LocalStreamEnvironment</span> <span class="o">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">createLocalEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setBufferTimeout</span><span class="o">(</span><span class="n">timeoutMillis</span><span class="o">)</span>

<span class="n">env</span><span class="o">.</span><span class="n">generateSequence</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">10</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">myMap</span><span class="o">).</span><span class="n">setBufferTimeout</span><span class="o">(</span><span class="n">timeoutMillis</span><span class="o">)</span>
</code></pre></div><p>为了最大限度地提高吞吐量，设置 <code>setBufferTimeout(-1)</code>，这将消除超时，缓冲区只有在满时才会被刷新。为了最大限度地减少延迟，将超时设置为接近0的值（例如5或10毫秒）。应该避免缓冲区超时为0，因为它会导致严重的性能下降。</p>
<h2 id="调试">调试</h2>
<p>在分布式集群中运行一个流程序之前，最好先确保实现的算法能够按照预期的方式运行。因此，实现数据分析程序通常是一个检查结果、调试和改进的渐进过程。</p>
<p>Flink 提供了一些功能，通过支持 IDE 内的本地调试、测试数据的注入和结果数据的收集，大大简化了数据分析程序的开发过程。本节给出一些提示，如何简化 Flink 程序的开发。</p>
<h3 id="本地执行环境">本地执行环境</h3>
<p><code>LocalStreamEnvironment</code> 在它创建的同一个 JVM 进程中启动 Flink 系统。如果你从 IDE 中启动 <code>LocalEnvironment</code>，你可以在代码中设置断点，轻松调试你的程序。</p>
<p><code>LocalEnvironment</code> 的创建和使用方法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="cm">/* some source */</span><span class="o">)</span>
<span class="c1">// build your program
</span><span class="c1"></span>
<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span>
</code></pre></div><h3 id="收集数据源">收集数据源</h3>
<p>Flink 提供了特殊的数据源，这些数据源由 Java 集合支持，以方便测试。一旦程序被测试，源和接收器就可以很容易地被从外部系统读取/写入的源和接收器所替代。</p>
<p>集合数据源的使用方法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="c1">// 从元素列表中创建一个 DataStream
</span><span class="c1"></span><span class="k">val</span> <span class="n">myInts</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">)</span>

<span class="c1">// 从任何集合中创建一个 DataStream
</span><span class="c1"></span><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">myTuples</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// 从迭代器中创建一个 DataStream
</span><span class="c1"></span><span class="k">val</span> <span class="n">longIt</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">myLongs</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">longIt</span><span class="o">)</span>
</code></pre></div><p>注：目前，集合数据源要求数据类型和迭代器实现 <code>Serializable</code>。此外，集合数据源不能并行执行( parallelism = 1)。</p>
<h3 id="迭代器数据接收器">迭代器数据接收器</h3>
<p>Flink 还提供了一个收集 DataStream 结果的接收器(sink)，用于测试和调试目的。它的使用方法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.streaming.experimental.DataStreamUtils</span>
<span class="k">import</span> <span class="nn">scala.collection.JavaConverters.asScalaIteratorConverter</span>

<span class="k">val</span> <span class="n">myResult</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">myOutput</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">DataStreamUtils</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">myResult</span><span class="o">.</span><span class="n">javaStream</span><span class="o">).</span><span class="n">asScala</span>
</code></pre></div><p>注意：<code>flink-streaming-contrib</code> 模块从 Flink 1.5.0 中移除。它的类被移到 <code>flink-streaming-java</code> 和 <code>flink-streaming-scala</code> 中。</p>
<h2 id="下一步怎么走">下一步怎么走？</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/index.html">运算符</a>: 规范可用的流式运算符。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间</a>: 介绍 Flink 的时间概念。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/index.html">状态和容错</a>: 解释如何开发有状态的应用。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/index.html">连接器</a>: 描述可用的输入和输出连接器。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Generating Watermarks]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="related" type="text/html" title="Event Time" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Datastream API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="related" type="text/html" title="使用状态" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="related" type="text/html" title="内置的水印生成器" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="状态和容错性" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Generating Watermarks</blockquote><h2 id="生成水印httpsciapacheorgprojectsflinkflink-docs-release-111devevent_timestamps_watermarkshtml"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html">生成水印</a></h2>
<p>在本节中，您将了解 Flink 提供的 API，用于处理事件时间时间戳和水印。关于事件时间、处理时间和摄取时间的介绍，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间的介绍</a>。</p>
<h3 id="水印策略介绍">水印策略介绍</h3>
<p>为了使用事件时间，Flink 需要知道事件的时间戳，这意味着流中的每个元素都需要分配其事件时间戳(event timestamp)。这通常是通过使用 <code>TimestampAssigner</code> 从元素中的某个字段访问/提取时间戳(timestamp)来完成的。</p>
<p>时间戳分配与生成水印是同步进行的，水印告诉系统事件时间的进展。你可以通过指定一个 <code>WatermarkGenerator</code> 来配置。</p>
<p>Flink API 期望一个 <code>WatermarkStrategy</code>，其中包含一个 <code>TimestampAssigner</code> 和 <code>WatermarkGenerator</code>。一些常见的策略作为 <code>WatermarkStrategy</code> 上的静态方法是开箱即用的，但用户也可以在需要时建立自己的策略。</p>
<p>为了完整起见，这里是接口:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="kd">extends</span> <span class="n">TimestampAssignerSupplier</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;,</span> <span class="n">WatermarkGeneratorSupplier</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;{</span>

    <span class="cm">/**
</span><span class="cm">     * Instantiates a {@link TimestampAssigner} for assigning timestamps according to this
</span><span class="cm">     * strategy.
</span><span class="cm">     */</span>
    <span class="nd">@Override</span>
    <span class="n">TimestampAssigner</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nf">createTimestampAssigner</span><span class="o">(</span><span class="n">TimestampAssignerSupplier</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">);</span>

    <span class="cm">/**
</span><span class="cm">     * Instantiates a WatermarkGenerator that generates watermarks according to this strategy.
</span><span class="cm">     */</span>
    <span class="nd">@Override</span>
    <span class="n">WatermarkGenerator</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nf">createWatermarkGenerator</span><span class="o">(</span><span class="n">WatermarkGeneratorSupplier</span><span class="o">.</span><span class="na">Context</span> <span class="n">context</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div><p>如前所述，你通常不会自己实现这个接口，而是使用 <code>WatermarkStrategy</code> 上的静态帮助方法来实现常见的水印策略，或者将自定义的 <code>TimestampAssigner</code> 与 <code>WatermarkGenerator</code> 捆绑在一起。例如，要使用有界无序水印和 lambda 函数作为时间戳分配器，你可以使用这个方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">WatermarkStrategy</span>
  <span class="o">.</span><span class="n">forBoundedOutOfOrderness</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)](</span><span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">20</span><span class="o">))</span>
  <span class="o">.</span><span class="n">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nc">SerializableTimestampAssigner</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">extractTimestamp</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">String</span><span class="o">),</span> <span class="n">recordTimestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="n">_1</span>
  <span class="o">})</span>
</code></pre></div><p>(在这里使用 Scala Lambdas 目前是行不通的，因为 Scala 很笨，很难支持这个。#fus)</p>
<p>指定一个 <code>TimestampAssigner</code> 是可选的，在大多数情况下，你其实并不想指定一个。例如，当使用 Kafka 或 Kinesis 时，你会直接从 Kafka/Kinesis 记录中获取时间戳。</p>
<p>我们将在后面的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html#writing-watermarkgenerators">Writing WatermarkGenerator</a>中查看 <code>WatermarkGenerator</code> 接口。</p>
<p>注意：时间戳和水印都被指定为自 1970-01-01T00:00:00Z 的 Java 纪元以来的毫秒。</p>
<h3 id="使用水印策略">使用水印策略</h3>
<p>在 Flink 应用中，有两个地方可以使用 <code>WatermarkStrategy</code>。1）直接在源上使用，2）在非源操作后使用。</p>
<p>第一个选项是比较好的，因为它允许源在水印逻辑中利用关于碎片/分区/分割的知识。源通常可以更精细地跟踪水印，源产生的整体水印也会更准确。直接在源上指定 <code>WatermarkStrategy</code> 通常意味着你必须使用源的特定接口/请参阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html#watermark-strategies-and-the-kafka-connector">Watermark Strategies 和 Kafka Connector</a>，以了解在 Kafka Connector 上如何工作，以及关于每个分区水印如何工作的更多细节。</p>
<p>第二个选项（在任意操作后设置 <code>WatermarkStrategy</code>）只应在不能直接在源上设置策略时使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setStreamTimeCharacteristic</span><span class="o">(</span><span class="nc">TimeCharacteristic</span><span class="o">.</span><span class="nc">EventTime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readFile</span><span class="o">(</span>
         <span class="n">myFormat</span><span class="o">,</span> <span class="n">myFilePath</span><span class="o">,</span> <span class="nc">FileProcessingMode</span><span class="o">.</span><span class="nc">PROCESS_CONTINUOUSLY</span><span class="o">,</span> <span class="mi">100</span><span class="o">,</span>
         <span class="nc">FilePathFilter</span><span class="o">.</span><span class="n">createDefaultFilter</span><span class="o">())</span>

<span class="k">val</span> <span class="n">withTimestampsAndWatermarks</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="k">=</span> <span class="n">stream</span>
        <span class="o">.</span><span class="n">filter</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">severity</span> <span class="o">==</span> <span class="nc">WARNING</span> <span class="o">)</span>
        <span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(&lt;</span><span class="n">watermark</span> <span class="n">strategy</span><span class="o">&gt;)</span>

<span class="n">withTimestampsAndWatermarks</span>
        <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">getGroup</span> <span class="o">)</span>
        <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
        <span class="o">.</span><span class="n">reduce</span><span class="o">(</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">b</span><span class="o">)</span> <span class="o">)</span>
        <span class="o">.</span><span class="n">addSink</span><span class="o">(...)</span>
</code></pre></div><p>以这种方式使用 <code>WatermarkStrategy</code>，可以获取一个流并生成一个带有时间戳元素和水印的新流。如果原始流已经有时间戳和/或水印了，时间戳分配器就会覆盖它们。</p>
<h3 id="处理闲置源">处理闲置源</h3>
<p>如果其中一个输入分割/分区/碎片在一段时间内没有携带事件，这意味着 <code>WatermarkGenerator</code> 也没有得到任何新的信息来作为水印的基础。我们称之为空闲输入或空闲源。这是一个问题，因为有可能发生你的一些分区仍然携带事件。在这种情况下，水印将被保留下来，因为它是作为所有不同的并行水印的最小值计算的。</p>
<p>为了处理这个问题，你可以使用 <code>WatermarkStrategy</code> 来检测空闲，并将一个输入标记为空闲。<code>WatermarkStrategy</code> 为此提供了一个方便的助手。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">WatermarkStrategy</span>
  <span class="o">.</span><span class="n">forBoundedOutOfOrderness</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)](</span><span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">20</span><span class="o">))</span>
  <span class="o">.</span><span class="n">withIdleness</span><span class="o">(</span><span class="nc">Duration</span><span class="o">.</span><span class="n">ofMinutes</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</code></pre></div><h3 id="编写水印生成器">编写水印生成器</h3>
<p>时间戳分配器(TimestampAssigner)是一个从事件中提取字段的简单函数，因此我们不需要详细研究它们。而 <code>WatermarkGenerator</code> 的编写就比较复杂了，我们将在接下来的两节中看如何做。这就是 <code>WatermarkGenerator</code> 的接口。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * The {@code WatermarkGenerator} generates watermarks either based on events or
</span><span class="cm"> * periodically (in a fixed interval).
</span><span class="cm"> *
</span><span class="cm"> * &lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; This WatermarkGenerator subsumes the previous distinction between the
</span><span class="cm"> * {@code AssignerWithPunctuatedWatermarks} and the {@code AssignerWithPeriodicWatermarks}.
</span><span class="cm"> */</span>
<span class="nd">@Public</span>
<span class="kd">public</span> <span class="kd">interface</span> <span class="nc">WatermarkGenerator</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="cm">/**
</span><span class="cm">     * Called for every event, allows the watermark generator to examine and remember the
</span><span class="cm">     * event timestamps, or to emit a watermark based on the event itself.
</span><span class="cm">     */</span>
    <span class="kt">void</span> <span class="nf">onEvent</span><span class="o">(</span><span class="n">T</span> <span class="n">event</span><span class="o">,</span> <span class="kt">long</span> <span class="n">eventTimestamp</span><span class="o">,</span> <span class="n">WatermarkOutput</span> <span class="n">output</span><span class="o">);</span>

    <span class="cm">/**
</span><span class="cm">     * Called periodically, and might emit a new watermark, or not.
</span><span class="cm">     *
</span><span class="cm">     * &lt;p&gt;The interval in which this method is called and Watermarks are generated
</span><span class="cm">     * depends on {@link ExecutionConfig#getAutoWatermarkInterval()}.
</span><span class="cm">     */</span>
    <span class="kt">void</span> <span class="nf">onPeriodicEmit</span><span class="o">(</span><span class="n">WatermarkOutput</span> <span class="n">output</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div><p>有两种不同风格的水印生成器：周期性和打点式。</p>
<p>周期性生成器通常通过 <code>onEvent()</code> 观察到传入的事件，然后当框架调用 <code>onPeriodicEmit()</code> 时，发射水印。</p>
<p>标点式生成器会观察 <code>onEvent()</code> 中的事件，并等待流中携带水印信息的特殊标记事件或标点。当它看到这些事件之一时，就会立即发出一个水印。通常，标点生成器不会从 <code>onPeriodicEmit()</code> 发出水印。</p>
<p>接下来我们将看看如何实现每种样式的生成器。</p>
<h4 id="编写周期性水印生成器">编写周期性水印生成器</h4>
<p>周期性生成器观察流事件并周期性地生成水印（可能取决于流元素，或者纯粹基于处理时间）。</p>
<p>生成水印的间隔（每n毫秒）通过 <code>ExecutionConfig.setAutoWatermarkInterval(...)</code> 来定义。每次都会调用生成器的 <code>onPeriodicEmit()</code> 方法，如果返回的水印是非空的，并且大于前一个水印，就会发出一个新的水印。</p>
<p>这里我们展示了两个使用周期性水印生成器的简单例子。请注意，Flink 提供了 <code>BoundedOutfOrdernessWatermarks</code>，这是一个 <code>WatermarkGenerator</code>，它的工作原理与下面所示的 <code>BoundedOutfOrdernessGenerator</code> 类似。你可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamp_extractors.html#assigners-allowing-a-fixed-amount-of-lateness">这里</a>阅读关于如何使用它。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/**
</span><span class="cm"> * This generator generates watermarks assuming that elements arrive out of order,
</span><span class="cm"> * but only to a certain degree. The latest elements for a certain timestamp t will arrive
</span><span class="cm"> * at most n milliseconds after the earliest elements for timestamp t.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">BoundedOutOfOrdernessGenerator</span> <span class="k">extends</span> <span class="nc">AssignerWithPeriodicWatermarks</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">maxOutOfOrderness</span> <span class="k">=</span> <span class="mi">3500L</span> <span class="c1">// 3.5 seconds
</span><span class="c1"></span>
    <span class="k">var</span> <span class="n">currentMaxTimestamp</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="k">_</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onEvent</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">MyEvent</span><span class="o">,</span> <span class="n">eventTimestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">currentMaxTimestamp</span> <span class="k">=</span> <span class="n">max</span><span class="o">(</span><span class="n">eventTimestamp</span><span class="o">,</span> <span class="n">currentMaxTimestamp</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onPeriodicEmit</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// emit the watermark as current highest timestamp minus the out-of-orderness bound
</span><span class="c1"></span>        <span class="n">output</span><span class="o">.</span><span class="n">emitWatermark</span><span class="o">(</span><span class="k">new</span> <span class="nc">Watermark</span><span class="o">(</span><span class="n">currentMaxTimestamp</span> <span class="o">-</span> <span class="n">maxOutOfOrderness</span> <span class="o">-</span> <span class="mi">1</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="cm">/**
</span><span class="cm"> * This generator generates watermarks that are lagging behind processing time by a fixed amount.
</span><span class="cm"> * It assumes that elements arrive in Flink after a bounded delay.
</span><span class="cm"> */</span>
<span class="k">class</span> <span class="nc">TimeLagWatermarkGenerator</span> <span class="k">extends</span> <span class="nc">AssignerWithPeriodicWatermarks</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">maxTimeLag</span> <span class="k">=</span> <span class="mi">5000L</span> <span class="c1">// 5 seconds
</span><span class="c1"></span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">onEvent</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">MyEvent</span><span class="o">,</span> <span class="n">eventTimestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// don&#39;t need to do anything because we work on processing time
</span><span class="c1"></span>    <span class="o">}</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onPeriodicEmit</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">output</span><span class="o">.</span><span class="n">emitWatermark</span><span class="o">(</span><span class="k">new</span> <span class="nc">Watermark</span><span class="o">(</span><span class="nc">System</span><span class="o">.</span><span class="n">currentTimeMillis</span><span class="o">()</span> <span class="o">-</span> <span class="n">maxTimeLag</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h4 id="编写一个标点水印生成器">编写一个标点水印生成器</h4>
<p>标点水印生成器将观察事件流，每当它看到一个携带水印信息的特殊元素时，就会发出一个水印。</p>
<p>这就是如何实现一个标点水印生成器，每当一个事件表明它携带某个标记时，它就会发射一个水印。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">PunctuatedAssigner</span> <span class="k">extends</span> <span class="nc">AssignerWithPunctuatedWatermarks</span><span class="o">[</span><span class="kt">MyEvent</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onEvent</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="kt">MyEvent</span><span class="o">,</span> <span class="n">eventTimestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">event</span><span class="o">.</span><span class="n">hasWatermarkMarker</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">output</span><span class="o">.</span><span class="n">emitWatermark</span><span class="o">(</span><span class="k">new</span> <span class="nc">Watermark</span><span class="o">(</span><span class="n">event</span><span class="o">.</span><span class="n">getWatermarkTimestamp</span><span class="o">()))</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onPeriodicEmit</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// don&#39;t need to do anything because we emit in reaction to events above
</span><span class="c1"></span>    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>注：可以对每个事件生成一个水印。然而，由于每个水印都会引起下游的一些计算，因此过多的水印会降低性能。</p>
<h3 id="水印策略和-kafka-连接器">水印策略和 Kafka 连接器</h3>
<p>当使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/kafka.html">Apache Kafka</a> 作为数据源时，每个 Kafka 分区可能有一个简单的事件时间模式（升序时间戳或有界失序）。然而，当消耗来自 Kafka 的流时，多个分区经常会被并行消耗，交织来自分区的事件，并破坏每个分区的模式（这是 Kafka 的消费者客户端的固有工作方式）。</p>
<p>在这种情况下，你可以使用 Flink 的 Kafka-partition-aware 水印生成功能。使用该功能，在 Kafka 消费者内部，按 Kafka 分区生成水印，每个分区水印的合并方式与流洗牌的水印合并方式相同。</p>
<p>例如，如果每个 Kafka 分区的事件时间戳是严格的升序，那么用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamp_extractors.html#assigners-with-ascending-timestamps">升序时间戳水印生成器</a>生成每个分区的水印，会得到完美的整体水印。请注意，我们在示例中并没有提供 TimestampAssigner，而是使用 Kafka 记录本身的时间戳。</p>
<p>下面的插图展示了如何使用 per-Kafka-partition 水印生成器，以及在这种情况下水印如何通过流式数据流传播。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">kafkaSource</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FlinkKafkaConsumer</span><span class="o">[</span><span class="kt">MyType</span><span class="o">](</span><span class="s">&#34;myTopic&#34;</span><span class="o">,</span> <span class="n">schema</span><span class="o">,</span> <span class="n">props</span><span class="o">)</span>
<span class="n">kafkaSource</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span>
  <span class="nc">WatermarkStrategy</span>
    <span class="o">.</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">20</span><span class="o">)))</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">MyType</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="n">kafkaSource</span><span class="o">)</span>
</code></pre></div><p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel_kafka_watermarks.svg" alt="img"></p>
<h3 id="运算符如何处理水印">运算符如何处理水印</h3>
<p>作为一般规则，运算符(operator)在向下游转发一个给定的水印之前，需要对其进行完全处理。例如，<code>WindowOperator</code> 将首先评估所有应该被发射的窗口，只有在产生所有由水印触发的输出之后，水印本身才会被发送到下游。换句话说，所有因发生水印而产生的元素将在水印之前被发射。</p>
<p>同样的规则也适用于 <code>TwoInputStreamOperator</code>。然而，在这种情况下，运算符的当前水印被定义为其两个输入的最小值。</p>
<p>这种行为的细节由 <code>OneInputStreamOperator#processWatermark</code>、<code>TwoInputStreamOperator#processWatermark1</code> 和 <code>TwoInputStreamOperator#processWatermark2</code> 方法的实现来定义。</p>
<h3 id="废弃的-assignerwithperiodicwatermarks-和-assignerwithpunctuatedwatermarks-方法">废弃的 AssignerWithPeriodicWatermarks 和 AssignerWithPunctuatedWatermarks 方法</h3>
<p>在引入当前的 <code>WatermarkStrategy</code>、<code>TimestampAssigner</code> 和 <code>WatermarkGenerator</code> 抽象之前，Flink 使用了 <code>AssignerWithPeriodicWatermarks</code> 和 <code>AssignerWithPeriodicWatermarks</code>。你仍然会在 API 中看到它们，但建议使用新的接口，因为它们提供了更清晰的分离关注点，也统一了水印生成的周期和标点样式。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/event-time" term="event-time" label="Event Time" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Julia 中的 REPL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-repl-in-julia/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-repl-in-julia/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>REPL in Julia</blockquote><h2 id="julia-repl">Julia REPL</h2>
<p>Julia 在 <code>julia</code> 可执行文件中内置了一个功能齐全的交互式命令行 REPL（read-eval-print loop）。除了允许快速、简单地评估 Julia 语句外，它还具有可搜索的历史记录、tab-补全、许多有用的键绑定以及专门的帮助和 <code>shell</code> 模式。REPL 可以通过简单地调用 <code>julia</code> 而不使用参数或双击可执行文件来启动。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ julia

               _
   _       _ _<span class="o">(</span>_<span class="o">)</span>_     <span class="p">|</span>  Documentation: https://docs.julialang.org
  <span class="o">(</span>_<span class="o">)</span>     <span class="p">|</span> <span class="o">(</span>_<span class="o">)</span> <span class="o">(</span>_<span class="o">)</span>    <span class="p">|</span>
   _ _   _<span class="p">|</span> <span class="p">|</span>_  __ _   <span class="p">|</span>  Type <span class="s2">&#34;?&#34;</span> <span class="k">for</span> help, <span class="s2">&#34;]?&#34;</span> <span class="k">for</span> Pkg help.
  <span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="p">|</span>/ _<span class="sb">`</span> <span class="p">|</span>  <span class="p">|</span>
  <span class="p">|</span> <span class="p">|</span> <span class="p">|</span>_<span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="p">|</span> <span class="o">(</span>_<span class="p">|</span> <span class="p">|</span>  <span class="p">|</span>  Version 1.5.0 <span class="o">(</span>2020-08-01<span class="o">)</span>
 _/ <span class="p">|</span><span class="se">\_</span>_<span class="s1">&#39;_|_|_|\__&#39;</span>_<span class="p">|</span>  <span class="p">|</span>  Official https://julialang.org/ release
<span class="p">|</span>__/                   <span class="p">|</span>


julia&gt;
</code></pre></div><p>要退出交互式会话，请键入 <code>^D</code> - 控制键与 <code>d</code> 键一起在空行上键入，或键入 <code>exit()</code> 后跟回车或回车键。REPL 会用一个横幅和 <code>julia&gt;</code> 提示来欢迎您。</p>
<h3 id="不同的提示模式">不同的提示模式</h3>
<h4 id="朱利安模式">朱利安模式</h4>
<p>REPL 有四种主要的操作模式。第一种也是最常见的是 Julian 提示。这是默认的操作模式；每个新行都以 <code>julia&gt;</code> 开始。在这里您可以输入 Julia 表达式。在输入完整的表达式后点击回车或回车将评估该条目并显示最后一个表达式的结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; string<span class="o">(</span><span class="m">1</span> + 2<span class="o">)</span>
<span class="s2">&#34;3&#34;</span>
</code></pre></div><p>在交互式工作中，有许多独特的有用功能。除了显示结果之外，REPL 还将结果绑定到变量 <code>ans</code> 上。行上的分号可以作为一个标志来抑制显示结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; string<span class="o">(</span><span class="m">3</span> * 4<span class="o">)</span><span class="p">;</span>

julia&gt; ans
<span class="s2">&#34;12&#34;</span>
</code></pre></div><p>在 Julia 模式下，REPL 支持称为提示粘贴(<em>prompt pasting</em>)的东西。当把以 <code>julia&gt;</code> 开头的文本粘贴到 REPL 中时，这个功能会被激活。在这种情况下，只有以 <code>julia&gt;</code> 开头的表达式会被解析，其他表达式会被删除。这使得您可以粘贴从 REPL 会话中复制的代码块，而无需清除提示和输出。这个功能默认是启用的，但可以通过 <code>REPL.enable_promptpaste(::Bool)</code> 来禁用或启用。如果启用了，您可以直接将本段上面的代码块粘贴到 REPL 中试试。这个功能在标准的 Windows 命令提示符上不起作用，因为它在检测粘贴发生时的局限性。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">using REPL
REPL.enable_promptpaste<span class="o">(</span><span class="nb">false</span><span class="o">)</span> <span class="c1"># 禁用 prompt pasting</span>
REPL.enable_promptpaste<span class="o">(</span><span class="nb">true</span><span class="o">)</span>  <span class="c1"># 启用 prompt pasting</span>
</code></pre></div><p>对象在 REPL 中使用带有特定 <a href="https://docs.julialang.org/en/v1/base/io-network/#Base.IOContext">IOContext</a> 的 <a href="https://docs.julialang.org/en/v1/base/io-network/#Base.show-Tuple%7BIO,Any%7D">show</a> 函数进行打印。特别是，<code>:limit</code> 属性被设置为 true。其他属性可以在某些 <code>show</code> 方法中接收一个默认值，如果它还没有被设置，比如 <code>:compact</code>。作为实验性功能，可以通过 <code>Base.active_repl.options.iocontext</code> 字典来指定 REPL 使用的属性（将值关联到属性）。例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; rand<span class="o">(</span>2, 2<span class="o">)</span>
2×2 Array<span class="o">{</span>Float64,2<span class="o">}</span>:
 0.8833    0.329197
 0.719708  0.59114

julia&gt; show<span class="o">(</span>IOContext<span class="o">(</span>stdout, :compact <span class="o">=</span>&gt; <span class="nb">false</span><span class="o">)</span>, <span class="s2">&#34;text/plain&#34;</span>, rand<span class="o">(</span>2, 2<span class="o">))</span>
 0.43540323669187075  0.15759787870609387
 0.2540832269192739   0.4597637838786053
julia&gt; Base.active_repl.options.iocontext<span class="o">[</span>:compact<span class="o">]</span> <span class="o">=</span> false<span class="p">;</span>

julia&gt; rand<span class="o">(</span>2, 2<span class="o">)</span>
2×2 Array<span class="o">{</span>Float64,2<span class="o">}</span>:
 0.2083967319174056  0.13330606013126012
 0.6244375177790158  0.9777957560761545
</code></pre></div><p>为了在启动时自动定义这个字典的值，可以使用 <code>~/.julia/config/startup.jl</code> 文件中的 <a href="https://docs.julialang.org/en/v1/stdlib/REPL/#Base.atreplinit"><code>atreplinit</code></a> 函数，例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">atreplinit</span><span class="p">()</span> <span class="k">do</span> <span class="n">repl</span>
    <span class="n">repl</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">iocontext</span><span class="p">[</span><span class="o">:</span><span class="n">compact</span><span class="p">]</span> <span class="o">=</span> <span class="kc">false</span>
<span class="k">end</span>
</code></pre></div><h4 id="帮助模式">帮助模式</h4>
<p>当光标在行首时，可以通过键入 <code>?</code> 来将提示变为帮助模式。Julia 将尝试打印帮助模式下输入的任何内容的帮助或文档。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; ? <span class="c1"># upon typing ?, the prompt changes (in place) to: help?&gt;</span>

help?&gt; string
search: string String Cstring Cwstring RevString randstring bytestring SubString

  string<span class="o">(</span>xs...<span class="o">)</span>

  Create a string from any values using the print <span class="k">function</span>.
</code></pre></div><p>也可以查询宏、类型和变量:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">help?&gt; @time
  @time

  A macro to execute an expression, printing the <span class="nb">time</span> it took to execute, the number of allocations,
  and the total number of bytes its execution caused to be allocated, before returning the value of the
  expression.

  See also @timev, @timed, @elapsed, and @allocated.

help?&gt; Int32
search: Int32 UInt32

  Int32 &lt;: Signed

  32-bit signed integer type.
</code></pre></div><p>按行首的退格键可以退出帮助模式。</p>
<h4 id="shell-模式">Shell 模式</h4>
<p>就像帮助模式对于快速访问文档很有用一样，另一个常见的任务是使用系统 shell 来执行系统命令。就像 <code>?</code> 进入帮助模式时一样, 在行首按下分号(<code>;</code>)会进入 shell 模式。而且可以在行首按退格键退出。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="p">;</span> <span class="c1"># upon typing ;, the prompt changes (in place) to: shell&gt;</span>

shell&gt; <span class="nb">echo</span> hello
hello
</code></pre></div><p>注意:</p>
<p>对于 Windows 用户来说，Julia 的 shell 模式不暴露 windows shell 命令。因此，这将会失败:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="p">;</span> <span class="c1"># upon typing ;, the prompt changes (in place) to: shell&gt;</span>

shell&gt; dir
ERROR: IOError: could not spawn <span class="sb">`</span>dir<span class="sb">`</span>: no such file or directory <span class="o">(</span>ENOENT<span class="o">)</span>
Stacktrace!
.......
</code></pre></div><p>不过，你可以像这样访问 PowerShell:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="p">;</span> <span class="c1"># upon typing ;, the prompt changes (in place) to: shell&gt;</span>

shell&gt; powershell
Windows PowerShell
Copyright <span class="o">(</span>C<span class="o">)</span> Microsoft Corporation. All rights reserved.
PS C:<span class="se">\U</span>sers<span class="se">\e</span>lm&gt;
</code></pre></div><p>&hellip;而且对 <code>cmd.exe</code> 的访问是这样的（见 <code>dir</code> 命令）:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="p">;</span> <span class="c1"># upon typing ;, the prompt changes (in place) to: shell&gt;</span>

shell&gt; cmd
Microsoft Windows <span class="o">[</span>version 10.0.17763.973<span class="o">]</span>
<span class="o">(</span>c<span class="o">)</span> <span class="m">2018</span> Microsoft Corporation. All rights reserved.
C:<span class="se">\U</span>sers<span class="se">\e</span>lm&gt;dir
 Volume in drive C has no label
 Volume Serial Number is 1643-0CD7
  Directory of C:<span class="se">\U</span>sers<span class="se">\e</span>lm

29/01/2020  22:15    &lt;DIR&gt;          .
29/01/2020  22:15    &lt;DIR&gt;          ..
02/02/2020  08:06    &lt;DIR&gt;          .atom
</code></pre></div><h4 id="搜索模式">搜索模式</h4>
<p>在上述所有模式中，执行的行数都会被保存到历史文件中，可以进行搜索。要在以前的历史记录中进行增量搜索，输入 <code>^R</code>&ndash;控制键和 <code>r</code> 键。提示符将变为(<code>reverse-i-search</code>):，当你输入搜索查询时，搜索查询将出现在引号中。当你输入更多的内容时，与查询相匹配的最新结果会动态地更新到冒号的右边。如果要使用相同的查询找到一个较早的结果，只需再次输入 <code>^R</code>。</p>
<p>就像 <code>^R</code> 是反向搜索一样，<code>^S</code> 是正向搜索，并提示(<code>i-search</code>):。两者可以相互结合使用，分别在上一个或下一个匹配结果中移动。</p>
<h3 id="键绑定">键绑定</h3>
<p>Julia REPL 大量使用了键绑定。上面已经介绍了几个控制键绑定（<code>^D</code> 用于退出，<code>^R</code> 和 <code>^S</code> 用于搜索），但还有更多。除了控制键，还有元键绑定。这些因平台不同而变化较大，但大多数终端默认使用 <code>alt-</code> 或 <code>option-</code> 按住键发送元键（也可以配置成这样），或者按 <code>Esc</code> 键，然后按键。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Keybinding</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Program control</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">^D</td>
<td style="text-align:left">退出(当缓存为空时)</td>
</tr>
<tr>
<td style="text-align:left">^C</td>
<td style="text-align:left">中断或取消</td>
</tr>
<tr>
<td style="text-align:left">^L</td>
<td style="text-align:left">清理控制台屏幕</td>
</tr>
<tr>
<td style="text-align:left">Return/Enter, <code>^J</code></td>
<td style="text-align:left">新行，如果完成了就执行</td>
</tr>
<tr>
<td style="text-align:left">meta-Return/Enter</td>
<td style="text-align:left">插入新行而不执行</td>
</tr>
<tr>
<td style="text-align:left"><code>?</code> 或 <code>;</code></td>
<td style="text-align:left">进入帮助或shell模式(当在行的开头时)</td>
</tr>
<tr>
<td style="text-align:left"><code>^R</code>, <code>^S</code></td>
<td style="text-align:left">递增式历史检索，如上所述</td>
</tr>
</tbody>
</table>
<h3 id="自定义键绑定">自定义键绑定</h3>
<p>Julia 的 REPL 键绑定可以通过向 <code>REPL.setup_interface</code> 传递一个字典来完全定制用户的偏好。这个字典的键可以是字符或字符串。键 &lsquo;*&rsquo; 指的是默认操作。控制加字符x的绑定用&quot;^x&quot;表示。Meta 加x可以写成 &ldquo;\M-x&rdquo; 或 &ldquo;\ex&rdquo;，Control 加 x 可以写成 &ldquo;\C-x&rdquo; 或 &ldquo;^x&rdquo;。自定义 keymap 的值必须是 nothing(表示输入应该被忽略)或接受签名的函数(<code>PromptState</code>, <code>AbstractREPL</code>, <code>Char</code>)。<code>REPL.setup_interface</code> 函数必须在 REPL 初始化之前被调用，通过在 atreplinit 注册操作。例如，要绑定上下方向键来移动历史记录而不需要前缀搜索，可以在 <code>~/.julia/config/startup.jl</code> 中放入以下代码。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">import</span> <span class="n">REPL</span>
<span class="k">import</span> <span class="n">REPL</span><span class="o">.</span><span class="n">LineEdit</span>

<span class="kd">const</span> <span class="n">mykeys</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Any</span><span class="p">,</span><span class="kt">Any</span><span class="p">}(</span>
    <span class="c"># Up Arrow</span>
    <span class="s">&#34;\e[A&#34;</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">o</span><span class="o">...</span><span class="p">)</span><span class="o">-&gt;</span><span class="p">(</span><span class="n">LineEdit</span><span class="o">.</span><span class="n">edit_move_up</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">||</span> <span class="n">LineEdit</span><span class="o">.</span><span class="n">history_prev</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">LineEdit</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">)),</span>
    <span class="c"># Down Arrow</span>
    <span class="s">&#34;\e[B&#34;</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">o</span><span class="o">...</span><span class="p">)</span><span class="o">-&gt;</span><span class="p">(</span><span class="n">LineEdit</span><span class="o">.</span><span class="n">edit_move_down</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">||</span> <span class="n">LineEdit</span><span class="o">.</span><span class="n">history_next</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">LineEdit</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">))</span>
<span class="p">)</span>

<span class="k">function</span> <span class="n">customize_keys</span><span class="p">(</span><span class="n">repl</span><span class="p">)</span>
    <span class="n">repl</span><span class="o">.</span><span class="n">interface</span> <span class="o">=</span> <span class="n">REPL</span><span class="o">.</span><span class="n">setup_interface</span><span class="p">(</span><span class="n">repl</span><span class="p">;</span> <span class="n">extra_repl_keymap</span> <span class="o">=</span> <span class="n">mykeys</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">atreplinit</span><span class="p">(</span><span class="n">customize_keys</span><span class="p">)</span>
</code></pre></div><p>用户应该参考 <code>LineEdit.jl</code> 来发现键输入的可用操作。</p>
<h3 id="tab-补全">Tab 补全</h3>
<p>在 REPL 的 Julian 和帮助模式下，可以输入函数或类型的前几个字符，然后按tab键，得到一个所有匹配的列表:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; stri<span class="o">[</span>TAB<span class="o">]</span>
stride     strides     string      strip

julia&gt; Stri<span class="o">[</span>TAB<span class="o">]</span>
StridedArray    StridedMatrix    StridedVecOrMat  StridedVector    String
</code></pre></div><p>tab 键也可以用来用它们的 Unicode 等价物替代 LaTeX 数学符号，并获得 LaTeX 匹配列表。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="se">\p</span>i<span class="o">[</span>TAB<span class="o">]</span>
julia&gt; π
<span class="nv">π</span> <span class="o">=</span> 3.1415926535897...

julia&gt; e<span class="se">\_</span>1<span class="o">[</span>TAB<span class="o">]</span> <span class="o">=</span> <span class="o">[</span>1,0<span class="o">]</span>
julia&gt; e₁ <span class="o">=</span> <span class="o">[</span>1,0<span class="o">]</span>
2-element Array<span class="o">{</span>Int64,1<span class="o">}</span>:
 <span class="m">1</span>
 <span class="m">0</span>

julia&gt; e<span class="se">\^</span>1<span class="o">[</span>TAB<span class="o">]</span> <span class="o">=</span> <span class="o">[</span><span class="m">1</span> 0<span class="o">]</span>
julia&gt; e¹ <span class="o">=</span> <span class="o">[</span><span class="m">1</span> 0<span class="o">]</span>
1×2 Array<span class="o">{</span>Int64,2<span class="o">}</span>:
 <span class="m">1</span>  <span class="m">0</span>

julia&gt; <span class="se">\s</span>qrt<span class="o">[</span>TAB<span class="o">]</span><span class="m">2</span>     <span class="c1"># √ is equivalent to the sqrt function</span>
julia&gt; √2
1.4142135623730951

julia&gt; <span class="se">\h</span>bar<span class="o">[</span>TAB<span class="o">](</span>h<span class="o">)</span> <span class="o">=</span> h / 2<span class="se">\p</span>i<span class="o">[</span>TAB<span class="o">]</span>
julia&gt; ħ<span class="o">(</span>h<span class="o">)</span> <span class="o">=</span> h / 2π
ħ <span class="o">(</span>generic <span class="k">function</span> with <span class="m">1</span> method<span class="o">)</span>

julia&gt; <span class="se">\h</span><span class="o">[</span>TAB<span class="o">]</span>
<span class="se">\h</span>at              <span class="se">\h</span>ermitconjmatrix  <span class="se">\h</span>kswarow          <span class="se">\h</span>rectangle
<span class="se">\h</span>atapprox        <span class="se">\h</span>exagon           <span class="se">\h</span>ookleftarrow     <span class="se">\h</span>rectangleblack
<span class="se">\h</span>bar             <span class="se">\h</span>exagonblack      <span class="se">\h</span>ookrightarrow    <span class="se">\h</span>slash
<span class="se">\h</span>eartsuit        <span class="se">\h</span>ksearow          <span class="se">\h</span>ouse             <span class="se">\h</span>space

julia&gt; <span class="nv">α</span><span class="o">=</span><span class="s2">&#34;\alpha[TAB]&#34;</span>   <span class="c1"># LaTeX completion also works in strings</span>
julia&gt; <span class="nv">α</span><span class="o">=</span><span class="s2">&#34;α&#34;</span>
</code></pre></div><p>完整的tab-补全列表可以在手册的 <a href="https://docs.julialang.org/en/v1/manual/unicode-input/#Unicode-Input-1">Unicode 输入</a>部分找到。</p>
<p>路径补全适用于字符串和 julia 的 shell 模式:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">path</span><span class="o">=</span><span class="s2">&#34;/[TAB]&#34;</span>
.dockerenv  .juliabox/   boot/        etc/         lib/         media/       opt/         root/        sbin/        sys/         usr/
.dockerinit bin/         dev/         home/        lib64/       mnt/         proc/        run/         srv/         tmp/         var/
shell&gt; /<span class="o">[</span>TAB<span class="o">]</span>
.dockerenv  .juliabox/   boot/        etc/         lib/         media/       opt/         root/        sbin/        sys/         usr/
.dockerinit bin/         dev/         home/        lib64/       mnt/         proc/        run/         srv/         tmp/         var/
</code></pre></div><p>Tab 补全可以帮助调查匹配输入参数的可用方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; max<span class="o">([</span>TAB<span class="o">]</span> <span class="c1"># All methods are displayed, not shown here due to size of the list</span>

julia&gt; max<span class="o">([</span>1, 2<span class="o">]</span>, <span class="o">[</span>TAB<span class="o">]</span> <span class="c1"># All methods where `Vector{Int}` matches as first argument</span>
max<span class="o">(</span>x, y<span class="o">)</span> in Base at operators.jl:215
max<span class="o">(</span>a, b, c, xs...<span class="o">)</span> in Base at operators.jl:281

julia&gt; max<span class="o">([</span>1, 2<span class="o">]</span>, max<span class="o">(</span>1, 2<span class="o">)</span>, <span class="o">[</span>TAB<span class="o">]</span> <span class="c1"># All methods matching the arguments.</span>
max<span class="o">(</span>x, y<span class="o">)</span> in Base at operators.jl:215
max<span class="o">(</span>a, b, c, xs...<span class="o">)</span> in Base at operators.jl:281
</code></pre></div><p>关键词也显示在 <code>;</code> 后面的建议方法中，见下面一行，其中 <code>limit</code> 和 <code>keepempty</code> 是关键词参数:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; split<span class="o">(</span><span class="s2">&#34;1 1 1&#34;</span>, <span class="o">[</span>TAB<span class="o">]</span>
split<span class="o">(</span>str::AbstractString<span class="p">;</span> limit, keepempty<span class="o">)</span> in Base at strings/util.jl:302
split<span class="o">(</span>str::T, splitter<span class="p">;</span> limit, keepempty<span class="o">)</span> where T&lt;:AbstractString in Base at strings/util.jl:277
</code></pre></div><p>方法的补全使用类型推断，因此即使参数是函数输出的，也能看到参数是否匹配。函数需要类型稳定，完成才能够删除不匹配的方法。</p>
<p>Tab 补全也可以帮助补全字段:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; import UUIDs

julia&gt; UUIDs.uuid<span class="o">[</span>TAB<span class="o">]</span>
uuid1        uuid4         uuid_version
</code></pre></div><p>也可以补全函数输出的字段:</p>
<pre><code class="language-sshell" data-lang="sshell">julia&gt; split(&quot;&quot;,&quot;&quot;)[1].[TAB]
lastindex  offset  string
</code></pre><p>函数输出的字段完成采用类型推断，只有在函数类型稳定的情况下，它才能建议字段。</p>
<p>字典键也可以用 tab 补全:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">foo</span> <span class="o">=</span> Dict<span class="o">(</span><span class="s2">&#34;qwer1&#34;</span><span class="o">=</span>&gt;1, <span class="s2">&#34;qwer2&#34;</span><span class="o">=</span>&gt;2, <span class="s2">&#34;asdf&#34;</span><span class="o">=</span>&gt;3<span class="o">)</span>
Dict<span class="o">{</span>String,Int64<span class="o">}</span> with <span class="m">3</span> entries:
  <span class="s2">&#34;qwer2&#34;</span> <span class="o">=</span>&gt; <span class="m">2</span>
  <span class="s2">&#34;asdf&#34;</span>  <span class="o">=</span>&gt; <span class="m">3</span>
  <span class="s2">&#34;qwer1&#34;</span> <span class="o">=</span>&gt; <span class="m">1</span>

julia&gt; foo<span class="o">[</span><span class="s2">&#34;q[TAB]
</span><span class="s2">
</span><span class="s2">&#34;</span>qwer1<span class="s2">&#34; &#34;</span>qwer2<span class="s2">&#34;
</span><span class="s2">julia&gt; foo[&#34;</span>qwer
</code></pre></div><h3 id="自定义颜色">自定义颜色</h3>
<p>Julia 和 REPL 所使用的颜色也是可以自定义的。要改变 Julia 提示符的颜色，您可以在您的 <code>~/.julia/config/startup.jl</code> 文件中添加以下内容，该文件应放在您的主目录中。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">customize_colors</span><span class="p">(</span><span class="n">repl</span><span class="p">)</span>
    <span class="n">repl</span><span class="o">.</span><span class="n">prompt_color</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">text_colors</span><span class="p">[</span><span class="o">:</span><span class="n">cyan</span><span class="p">]</span>
<span class="k">end</span>

<span class="n">atreplinit</span><span class="p">(</span><span class="n">customize_colors</span><span class="p">)</span>
</code></pre></div><p>可用的颜色键可以通过在 REPL 的帮助模式下输入 <code>Base.text_colors</code> 来查看。此外，对于支持 256 色的终端来说，整数 0 到 255 可以用作颜色键。</p>
<p>也可以通过在上面的 <code>customize_colors</code> 函数中设置 <code>repl</code> 的相应字段（分别为 <code>help_color</code>、<code>shell_color</code>、<code>input_color</code> 和 <code>answer_color</code>）来改变帮助和 shell 提示符以及输入和回答文字的颜色。对于后两者，要确保 <code>envcolors</code> 字段也设置为 false。</p>
<p>也可以通过使用 <code>Base.text_colors[:bold]</code> 作为颜色来应用粗体格式。例如，要用粗体字打印答案，可以使用下面的 <code>~/.julia/config/startup.jl</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">customize_colors</span><span class="p">(</span><span class="n">repl</span><span class="p">)</span>
    <span class="n">repl</span><span class="o">.</span><span class="n">envcolors</span> <span class="o">=</span> <span class="kc">false</span>
    <span class="n">repl</span><span class="o">.</span><span class="n">answer_color</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">text_colors</span><span class="p">[</span><span class="o">:</span><span class="n">bold</span><span class="p">]</span>
<span class="k">end</span>

<span class="n">atreplinit</span><span class="p">(</span><span class="n">customize_colors</span><span class="p">)</span>
</code></pre></div><p>你也可以通过设置适当的环境变量来定制用于渲染警告和信息消息的颜色。例如，要分别用洋红色、黄色和青色来渲染错误、警告和信息消息，你可以在 <code>~/.julia/config/startup.jl</code> 文件中添加以下内容:</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="nb">ENV</span><span class="p">[</span><span class="s">&#34;JULIA_ERROR_COLOR&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="o">:</span><span class="n">magenta</span>
<span class="nb">ENV</span><span class="p">[</span><span class="s">&#34;JULIA_WARN_COLOR&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="o">:</span><span class="n">yellow</span>
<span class="nb">ENV</span><span class="p">[</span><span class="s">&#34;JULIA_INFO_COLOR&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="o">:</span><span class="n">cyan</span>
</code></pre></div><h3 id="terminalmenus">TerminalMenus</h3>
<p>TerminalMenus 是 Julia REPL 的一个子模块，可以在终端中实现小型、低配的交互式菜单。</p>
<h4 id="例子">例子</h4>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">import</span> <span class="n">REPL</span>
<span class="k">using</span> <span class="n">REPL</span><span class="o">.</span><span class="n">TerminalMenus</span>

<span class="n">options</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#34;apple&#34;</span><span class="p">,</span> <span class="s">&#34;orange&#34;</span><span class="p">,</span> <span class="s">&#34;grape&#34;</span><span class="p">,</span> <span class="s">&#34;strawberry&#34;</span><span class="p">,</span>
            <span class="s">&#34;blueberry&#34;</span><span class="p">,</span> <span class="s">&#34;peach&#34;</span><span class="p">,</span> <span class="s">&#34;lemon&#34;</span><span class="p">,</span> <span class="s">&#34;lime&#34;</span><span class="p">]</span>
</code></pre></div><h4 id="radiomenu">RadioMenu</h4>
<p>RadioMenu 允许用户从列表中选择一个选项。<code>request</code> 函数显示交互式菜单并返回所选选项的索引。如果用户按 &lsquo;q&rsquo; 或 <code>ctrl-c</code>，<code>request</code> 将返回 <code>-1</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="c"># `pagesize` is the number of items to be displayed at a time.</span>
<span class="c">#  The UI will scroll if the number of options is greater</span>
<span class="c">#   than the `pagesize`</span>
<span class="n">menu</span> <span class="o">=</span> <span class="n">RadioMenu</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">pagesize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c"># `request` displays the menu and returns the index after the</span>
<span class="c">#   user has selected a choice</span>
<span class="n">choice</span> <span class="o">=</span> <span class="n">request</span><span class="p">(</span><span class="s">&#34;Choose your favorite fruit:&#34;</span><span class="p">,</span> <span class="n">menu</span><span class="p">)</span>

<span class="k">if</span> <span class="n">choice</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&#34;Your favorite fruit is &#34;</span><span class="p">,</span> <span class="n">options</span><span class="p">[</span><span class="n">choice</span><span class="p">],</span> <span class="s">&#34;!&#34;</span><span class="p">)</span>
<span class="k">else</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&#34;Menu canceled.&#34;</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><p>输出:</p>
<pre><code>Choose your favorite fruit:
^  grape
   strawberry
 &gt; blueberry
v  peach
Your favorite fruit is blueberry!
</code></pre><h4 id="multiselectmenu">MultiSelectMenu</h4>
<p>多重选择菜单（MultiSelectMenu）允许用户从一个列表中选择许多选择。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="c"># here we use the default `pagesize` 10</span>
<span class="n">menu</span> <span class="o">=</span> <span class="n">MultiSelectMenu</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>

<span class="c"># `request` returns a `Set` of selected indices</span>
<span class="c"># if the menu us canceled (ctrl-c or q), return an empty set</span>
<span class="n">choices</span> <span class="o">=</span> <span class="n">request</span><span class="p">(</span><span class="s">&#34;Select the fruits you like:&#34;</span><span class="p">,</span> <span class="n">menu</span><span class="p">)</span>

<span class="k">if</span> <span class="n">length</span><span class="p">(</span><span class="n">choices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&#34;You like the following fruits:&#34;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="n">choices</span>
        <span class="n">println</span><span class="p">(</span><span class="s">&#34;  - &#34;</span><span class="p">,</span> <span class="n">options</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">end</span>
<span class="k">else</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&#34;Menu canceled.&#34;</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><p>输出:</p>
<pre><code>Select the fruits you like:
[press: d=done, a=all, n=none]
   [ ] apple
 &gt; [X] orange
   [X] grape
   [ ] strawberry
   [ ] blueberry
   [X] peach
   [ ] lemon
   [ ] lime
You like the following fruits:
  - orange
  - grape
  - peach
</code></pre><h4 id="customization--configuration">Customization / Configuration</h4>
<p>所有的界面定制都是通过关键字 <code>TerminalMenus.config()</code> 函数完成的。</p>
<h5 id="参数">参数</h5>
<ul>
<li><code>charset::Symbol=:na</code>: 要使用的ui字符(<code>:ascii</code> 或 <code>:unicode</code>); 被其他参数覆盖。</li>
<li><code>cursor::Char='&gt;'|'→'</code>: 光标使用的字符。</li>
<li><code>up_arrow::Char='^'|'↑'</code>: 用于向上箭头的字符。</li>
<li><code>down_arrow::Char='v'|'↓'</code>: 用于向下箭头的字符。</li>
<li><code>checked::String=&quot;[X]&quot;|&quot;✓&quot;</code>：用于检查的字符串。</li>
<li><code>unchecked::String=&quot;[]&quot;|&quot;⬚&quot;)</code>：用于未选中的字符串。</li>
<li><code>scroll::Symbol=:na</code>: 如果 <code>:wrap</code>，则将光标环绕在顶部和底部，如果 <code>:nowrap</code> 则不环绕光标。</li>
<li><code>supress_output::Bool=false</code>。用于测试。如果为真，菜单不会被打印到控制台。</li>
<li><code>ctrl_c_interrupt::Bool=true</code>: 如果为假，在 <code>^C</code> 时返回空，如果为真，在 <code>^C</code> 时抛出 InterruptException()。</li>
</ul>
<h4 id="例子-1">例子</h4>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">menu</span> <span class="o">=</span> MultiSelectMenu<span class="o">(</span>options, <span class="nv">pagesize</span><span class="o">=</span>5<span class="o">)</span><span class="p">;</span>

julia&gt; request<span class="o">(</span>menu<span class="o">)</span> <span class="c1"># ASCII is used by default</span>
<span class="o">[</span>press: <span class="nv">d</span><span class="o">=</span><span class="k">done</span>, <span class="nv">a</span><span class="o">=</span>all, <span class="nv">n</span><span class="o">=</span>none<span class="o">]</span>
   <span class="o">[</span> <span class="o">]</span> apple
   <span class="o">[</span>X<span class="o">]</span> orange
   <span class="o">[</span> <span class="o">]</span> grape
 &gt; <span class="o">[</span>X<span class="o">]</span> strawberry
v  <span class="o">[</span> <span class="o">]</span> blueberry
Set<span class="o">([</span>4, 2<span class="o">])</span>

julia&gt; TerminalMenus.config<span class="o">(</span><span class="nv">charset</span><span class="o">=</span>:unicode<span class="o">)</span>

julia&gt; request<span class="o">(</span>menu<span class="o">)</span>
<span class="o">[</span>press: <span class="nv">d</span><span class="o">=</span><span class="k">done</span>, <span class="nv">a</span><span class="o">=</span>all, <span class="nv">n</span><span class="o">=</span>none<span class="o">]</span>
   ⬚ apple
   ✓ orange
   ⬚ grape
 → ✓ strawberry
↓  ⬚ blueberry
Set<span class="o">([</span>4, 2<span class="o">])</span>

julia&gt; TerminalMenus.config<span class="o">(</span><span class="nv">checked</span><span class="o">=</span><span class="s2">&#34;YEP!&#34;</span>, <span class="nv">unchecked</span><span class="o">=</span><span class="s2">&#34;NOPE&#34;</span>, <span class="nv">cursor</span><span class="o">=</span><span class="s1">&#39;⧐&#39;</span><span class="o">)</span>

julia&gt; request<span class="o">(</span>menu<span class="o">)</span>
<span class="o">[</span>press: <span class="nv">d</span><span class="o">=</span><span class="k">done</span>, <span class="nv">a</span><span class="o">=</span>all, <span class="nv">n</span><span class="o">=</span>none<span class="o">]</span>
   NOPE apple
   YEP! orange
   NOPE grape
 ⧐ YEP! strawberry
↓  NOPE blueberry
Set<span class="o">([</span>4, 2<span class="o">])</span>
</code></pre></div><h3 id="参考">参考</h3>
<p><a href="https://docs.julialang.org/en/v1/stdlib/REPL/#Base.atreplinit">Base.atreplinit</a></p>
<blockquote>
<p>atreplinit(f)</p>
</blockquote>
<p>注册一个单参数函数，在交互式会话中，在 REPL 接口初始化之前被调用；这对自定义接口很有用。f 的参数是 REPL 对象。这个函数应该在 <code>~/.julia/config/startup.jl</code> 初始化文件中调用。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/julia" term="julia" label="Julia" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia" term="julia" label="Julia" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="julia-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Julia 官方文档" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[使用状态]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="related" type="text/html" title="Event Time" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Datastream API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="related" type="text/html" title="Generating Watermarks" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="related" type="text/html" title="内置的水印生成器" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="状态和容错性" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Working With State</blockquote><h2 id="使用状态httpsciapacheorgprojectsflinkflink-docs-release-111devstreamstatestatehtml"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">使用状态</a></h2>
<p>在本节中，您将了解 Flink 为编写有状态程序提供的 API。请看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">Stateful Stream Processing</a> 来了解有状态流处理背后的概念。</p>
<h3 id="keyed-datastream">Keyed DataStream</h3>
<p>如果要使用 keyed state，首先需要在 DataStream 上指定一个键，这个键应该用来分隔(partition)状态（也包括流中的记录本身）。你可以在 DataStream 上使用 <code>keyBy(KeySelector)</code> 指定一个键。这将产生一个 <code>KeyedDataStream</code>，然后允许使用 keyed state 的操作。</p>
<p>键选择函数将一条记录作为输入，并返回该记录的键。键可以是任何类型的，并且必须从确定性计算中导出。</p>
<p>Flink 的数据模型不是基于键值对的。因此，您不需要将数据集类型物理地打包成键和值。键是&quot;虚拟&quot;的：它们被定义为实际数据上的函数，以指导分组操作符。</p>
<p>下面的例子显示了一个键选择函数，它只是返回对象的字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// 普通的 case 类
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]
</span><span class="c1"></span><span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">word</span> <span class="o">)</span>
</code></pre></div><h4 id="元组键和表达式键">元组键和表达式键</h4>
<p>Flink 还有两种定义键的方法：元组键和表达式键。有了它，你可以使用元组字段索引或表达式来指定键，用于选择对象的字段。我们今天不推荐使用这些，但你可以参考 DataStream 的 Javadoc 来了解它们。严格来说，使用 <code>KeySelector</code> 函数更胜一筹：使用 Java lambdas，它们很容易使用，而且它们在运行时的开销可能更少。</p>
<h3 id="使用-keyed-state">使用 Keyed State</h3>
<p>keyed State 接口提供了对不同类型的状态的访问，这些状态的作用域都是当前输入元素的键。这意味着，这种类型的状态只能在 <code>KeyedStream</code> 上使用，它可以通过 <code>stream.keyBy(...)</code> 来创建。</p>
<p>现在，我们将首先看看不同类型的状态有哪些，然后我们会看看如何在程序中使用它们。可用的状态原语有:</p>
<ul>
<li>
<p><code>ValueState&lt;T&gt;</code>：它保留了一个可更新和检索的值（如上所述，作用域为输入元素的键，因此操作符所看到的每个键都可能有一个值）。这个值可以使用 <code>update(T)</code> 来设置，也可以使用 <code>T value()</code> 来检索。</p>
</li>
<li>
<p><code>ListState&lt;T&gt;</code>：这保存了一个元素列表。你可以在所有当前存储的元素上追加元素和检索一个 <code>Iterable</code>。使用 <code>add(T)</code> 或 <code>addAll(List&lt;T&gt;)</code> 添加元素，可以使用 <code>Iterable&lt;T&gt; get()</code> 检索 <code>Iterable</code>。你也可以用 <code>update(List&lt;T&gt;)</code> 覆盖现有的列表。</p>
</li>
<li>
<p><code>ReducingState&lt;T&gt;</code>: 这保留了一个单一的值，代表所有添加到状态的值的集合。该接口类似于 <code>ListState</code>，但使用 <code>add(T)</code> 添加的元素会使用指定的 <code>ReduceFunction</code> 被化简成一个总计。</p>
</li>
<li>
<p><code>AggregatingState&lt;IN，OUT&gt;</code>：这保留了一个单一的值，代表所有添加到状态的值的聚合。与 <code>ReducingState</code> 相反，<code>aggregate</code> 类型可能与添加到状态中的元素类型不同。接口与 <code>ListState</code> 相同，但使用 <code>add(IN)</code> 添加的元素会使用指定的 <code>AggregateFunction</code> 进行聚合。</p>
</li>
<li>
<p><code>MapState&lt;UK, UV&gt;</code>: 它保存了一个映射列表。你可以将键值对放入状态中，并在所有当前存储的映射上检索一个 <code>Iterable</code>。使用 <code>put(UK, UV)</code> 或 <code>putAll(Map&lt;UK, UV&gt;)</code> 可以添加映射。与用户键相关联的值可以使用 <code>get(UK)</code> 来检索。可以分别使用 <code>entries()</code>、<code>keys()</code> 和 <code>values()</code> 检索映射、键和值的可迭代视图。你也可以使用 <code>isEmpty()</code> 来检查这个映射是否包含任何键值映射。</p>
</li>
</ul>
<p>所有类型的状态也都有一个方法 <code>clear()</code>，可以清除当前活动键的状态，也就是输入元素的键。</p>
<p>需要注意的是，这些状态对象只用于带状态的接口。状态不一定存储在里面，而可能驻留在磁盘或其他地方。第二件要记住的事情是，你从状态中得到的值取决于输入元素的键。因此，如果所涉及的键不同，你在用户函数的一次调用中得到的值可能与另一次调用中的值不同。</p>
<p>为了得到一个状态句柄，你必须创建一个 <code>StateDescriptor</code>。这里面包含了状态的名称(我们稍后会看到，你可以创建多个状态，而且它们必须有独特的名称，这样你才能引用它们)，状态所拥有的值的类型，可能还有一个用户指定的函数，比如 <code>ReduceFunction</code>。根据你要检索的状态类型，你可以创建一个 <code>ValueStateDescriptor</code>、一个 <code>ListStateDescriptor</code>、一个 <code>ReducingStateDescriptor</code> 或一个 <code>MapStateDescriptor</code>。</p>
<p>状态是使用 <code>RuntimeContext</code> 访问的，所以只有在富函数(<em>rich functions</em>)中才有可能。请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/user_defined_functions.html#rich-functions">这里</a>了解相关信息，但我们也会很快看到一个例子。<code>RichFunction</code> 中可用的 <code>RuntimeContext</code> 有这些方法来访问状态。</p>
<ul>
<li>ValueState<!-- raw HTML omitted --> getState(ValueStateDescriptor<!-- raw HTML omitted -->)</li>
<li>ReducingState<!-- raw HTML omitted --> getReducingState(ReducingStateDescriptor<!-- raw HTML omitted -->)</li>
<li>ListState<!-- raw HTML omitted --> getListState(ListStateDescriptor<!-- raw HTML omitted -->)</li>
<li>AggregatingState&lt;IN, OUT&gt; getAggregatingState(AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;)</li>
<li>MapState&lt;UK, UV&gt; getMapState(MapStateDescriptor&lt;UK, UV&gt;)</li>
</ul>
<p>这是一个 <code>FlatMapFunction</code> 的例子，它展示了所有的部分是如何结合在一起的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">CountWindowAverage</span> <span class="k">extends</span> <span class="nc">RichFlatMapFunction</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)</span>, <span class="o">(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="o">{</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">sum</span><span class="k">:</span> <span class="kt">ValueState</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="k">_</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">flatMap</span><span class="o">(</span><span class="n">input</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">),</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>

    <span class="c1">// 访问状态值
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">tmpCurrentSum</span> <span class="k">=</span> <span class="n">sum</span><span class="o">.</span><span class="n">value</span>

    <span class="c1">// 如果之前没有使用过，则为 null。
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">currentSum</span> <span class="k">=</span> <span class="k">if</span> <span class="o">(</span><span class="n">tmpCurrentSum</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">tmpCurrentSum</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
      <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="c1">// 更新次数
</span><span class="c1"></span>    <span class="k">val</span> <span class="n">newSum</span> <span class="k">=</span> <span class="o">(</span><span class="n">currentSum</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="mi">1</span><span class="o">,</span> <span class="n">currentSum</span><span class="o">.</span><span class="n">_2</span> <span class="o">+</span> <span class="n">input</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>

    <span class="c1">// 更新状态
</span><span class="c1"></span>    <span class="n">sum</span><span class="o">.</span><span class="n">update</span><span class="o">(</span><span class="n">newSum</span><span class="o">)</span>

    <span class="c1">// 如果计数达到2，则发出平均数，并清除状态。
</span><span class="c1"></span>    <span class="k">if</span> <span class="o">(</span><span class="n">newSum</span><span class="o">.</span><span class="n">_1</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">((</span><span class="n">input</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">newSum</span><span class="o">.</span><span class="n">_2</span> <span class="o">/</span> <span class="n">newSum</span><span class="o">.</span><span class="n">_1</span><span class="o">))</span>
      <span class="n">sum</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">parameters</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">sum</span> <span class="k">=</span> <span class="n">getRuntimeContext</span><span class="o">.</span><span class="n">getState</span><span class="o">(</span>
      <span class="k">new</span> <span class="nc">ValueStateDescriptor</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)](</span><span class="s">&#34;average&#34;</span><span class="o">,</span> <span class="n">createTypeInformation</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)])</span>
    <span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>


<span class="k">object</span> <span class="nc">ExampleCountWindowAverage</span> <span class="k">extends</span> <span class="nc">App</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

  <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span>
    <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">3L</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">5L</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">7L</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">4L</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">)</span>
  <span class="o">)).</span><span class="n">keyBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">CountWindowAverage</span><span class="o">())</span>
    <span class="o">.</span><span class="n">print</span><span class="o">()</span>
  <span class="c1">// the printed output will be (1,4) and (1,5)
</span><span class="c1"></span>
  <span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&#34;ExampleKeyedState&#34;</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div><p>这个例子实现了一个穷人的计数窗口。我们用第一个字段对元组进行 keyed 操作（在本例中，所有元组都有相同的键 <code>1</code>）。该函数将计数和运行的总和存储在一个 <code>ValueState</code>  中。一旦计数达到 2，它就会发出平均数并清除状态，这样我们就可以从 0 开始。注意，如果我们在第一个字段中的元组具有不同的值，那么这将为每个不同的输入键保持不同的状态值。</p>
<h4 id="状态存活时间ttl">状态存活时间(TTL)</h4>
<p>可以为任何类型的 keyed state 分配一个生存时间（TTL）。如果配置了 TTL，并且状态值已经过期，存储的值将在尽力的基础上进行清理，这将在下面详细讨论。</p>
<p>所有状态集合类型都支持每个条目的 TTL。这意味着列表元素和映射条目独立过期。</p>
<p>为了使用状态 TTL，必须首先建立一个 <code>StateTtlConfig</code> 配置对象。然后可以通过传递配置在任何状态描述符中启用 TTL 功能。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.StateTtlConfig</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.ValueStateDescriptor</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.common.time.Time</span>

<span class="k">val</span> <span class="n">ttlConfig</span> <span class="k">=</span> <span class="nc">StateTtlConfig</span>
    <span class="o">.</span><span class="n">newBuilder</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">setUpdateType</span><span class="o">(</span><span class="nc">StateTtlConfig</span><span class="o">.</span><span class="nc">UpdateType</span><span class="o">.</span><span class="nc">OnCreateAndWrite</span><span class="o">)</span>
    <span class="o">.</span><span class="n">setStateVisibility</span><span class="o">(</span><span class="nc">StateTtlConfig</span><span class="o">.</span><span class="nc">StateVisibility</span><span class="o">.</span><span class="nc">NeverReturnExpired</span><span class="o">)</span>
    <span class="o">.</span><span class="n">build</span>
    
<span class="k">val</span> <span class="n">stateDescriptor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ValueStateDescriptor</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;text state&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span>
<span class="n">stateDescriptor</span><span class="o">.</span><span class="n">enableTimeToLive</span><span class="o">(</span><span class="n">ttlConfig</span><span class="o">)</span>
</code></pre></div><p>配置有几个选项需要考虑。</p>
<p><code>newBuilder</code> 方法的第一个参数是强制性的，它是存活的时间值。</p>
<p>更新类型配置状态 TTL 何时被刷新（默认为 <code>OnCreateAndWrite</code>）。</p>
<ul>
<li>StateTtlConfig.UpdateType.OnCreateAndWrite - 仅在创建和写入访问时才会出现</li>
<li>StateTtlConfig.UpdateType.OnReadAndWrite - 也是在读的时候。</li>
</ul>
<p>状态可见性配置如果过期值尚未清理，是否在读取访问时返回（默认为 <code>NeverReturnExpired</code>）。</p>
<ul>
<li>StateTtlConfig.StateVisibility.NeverReturnExpired - 过期值永不返回</li>
<li>StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp - 如果仍然可用则返回。</li>
</ul>
<p>在 <code>NeverReturnExpired</code> 的情况下，过期状态就像不存在一样，即使它仍然必须被删除。这个选项对于数据在 TTL 之后必须严格地成为不可读的访问状态的用例是很有用的，例如处理隐私敏感数据的应用程序。</p>
<p>另一个选项 <code>ReturnExpiredIfNotCleanedUp</code> 允许在清理之前返回过期状态。</p>
<p>注意:</p>
<ul>
<li>
<p>状态后端存储最后一次修改的时间戳和用户值，这意味着启用该功能会增加状态存储的消耗。Heap 状态后端在内存中存储了一个额外的 Java 对象，该对象有一个对用户状态对象的引用和一个原始的长值。RocksDB 状态后端每存储一个值、列表项或映射项增加8个字节。</p>
</li>
<li>
<p>目前只支持参考处理时间的 TTL。</p>
</li>
<li>
<p>试图使用启用 TTL 的描述符来恢复之前没有配置 TTL 的状态，或者反之，将导致兼容性失败和 <code>StateMigrationException</code>。</p>
</li>
<li>
<p>TTL 配置不是检查点或保存点的一部分，而是 Flink 在当前运行的作业中如何处理的一种方式。</p>
</li>
<li>
<p>带 TTL 的映射状态目前只有在用户值序列化器能够处理 null 值的情况下才支持 null 用户值。如果序列化器不支持空值，可以用 <code>NullableSerializer</code> 包装，代价是在序列化形式中多出一个字节。</p>
</li>
</ul>
<h4 id="过期状态的清理">过期状态的清理</h4>
<p>默认情况下，过期的值会在读取时显式删除，如 <code>ValueState#value</code>，如果配置的状态后台支持，则会定期在后台进行垃圾回收。后台清理可以在 <code>StateTtlConfig</code> 中禁用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.StateTtlConfig</span>
<span class="k">val</span> <span class="n">ttlConfig</span> <span class="k">=</span> <span class="nc">StateTtlConfig</span>
    <span class="o">.</span><span class="n">newBuilder</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">disableCleanupInBackground</span>
    <span class="o">.</span><span class="n">build</span>
</code></pre></div><p>如果想对后台的一些特殊清理进行更精细的控制，可以按照下面的描述单独配置。目前，堆状态后台依靠增量清理，RocksDB 后台使用压实过滤器进行后台清理。</p>
<h5 id="全快照中的清理">全快照中的清理</h5>
<p>此外，您可以在拍摄完整状态快照的瞬间激活清理，这将减少其大小。在当前的实现下，本地状态不会被清理，但在从上一个快照恢复的情况下，它将不包括删除的过期状态。可以在 <code>StateTtlConfig</code> 中进行配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.StateTtlConfig</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.common.time.Time</span>

<span class="k">val</span> <span class="n">ttlConfig</span> <span class="k">=</span> <span class="nc">StateTtlConfig</span>
    <span class="o">.</span><span class="n">newBuilder</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">cleanupFullSnapshot</span>
    <span class="o">.</span><span class="n">build</span>
</code></pre></div><p>此选项不适用于 RocksDB 状态后端的增量检查点。</p>
<p><strong>注意:</strong></p>
<ul>
<li>对于现有的作业，这个清理策略可以在 <code>StateTtlConfig</code> 中随时激活或停用，例如从保存点重新启动后。</li>
</ul>
<h5 id="增量清理">增量清理</h5>
<p>另一种选择是逐步触发一些状态条目的清理。触发器可以是每次状态访问或/和每次记录处理的回调。如果这种清理策略对某些状态是激活的，存储后端就会为这个状态的所有条目保留一个惰性的全局迭代器。每次触发增量清理时，迭代器都会被提前。对遍历过的状态条目进行检查，对过期的条目进行清理。</p>
<p>这个功能可以在 <code>StateTtlConfig</code> 中配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.StateTtlConfig</span>
<span class="k">val</span> <span class="n">ttlConfig</span> <span class="k">=</span> <span class="nc">StateTtlConfig</span>
    <span class="o">.</span><span class="n">newBuilder</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">cleanupIncrementally</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="n">build</span>
</code></pre></div><p>这个策略有两个参数。第一个是每次清理触发的检查状态条目数。它总是在每次状态访问时触发。第二个参数定义是否在每次记录处理中额外触发清理。堆后端默认的后台清理每次记录处理检查5个条目而不进行清理。</p>
<p><strong>注意:</strong></p>
<ul>
<li>如果没有发生对状态的访问或者没有处理记录，过期状态将持续存在。</li>
<li>增量清理所花费的时间会增加记录处理的延迟。</li>
<li>目前，增量清理只在堆状态后端实现。对 RocksDB 的设置不会有影响。</li>
<li>如果堆状态后端与同步快照一起使用，全局迭代器在迭代的时候会保留所有键的副本，因为它的具体实现不支持并发修改。那么启用这个功能会增加内存消耗。异步快照则不存在这个问题。</li>
<li>对于现有的作业，这个清理策略可以在 <code>StateTtlConfig</code> 中随时激活或停用，例如从保存点重新启动后。</li>
</ul>
<h5 id="rocksdb-压缩过程中的清理">RocksDB 压缩过程中的清理</h5>
<p>如果使用 RocksDB 状态后端，将调用 Flink 特定的压实过滤器进行后台清理。RocksDB  会定期运行异步压实来合并状态更新，减少存储量。Flink 压实过滤器通过 TTL 检查状态条目的过期时间戳，排除过期值。</p>
<p>这个功能可以在 <code>StateTtlConfig</code> 中配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.common.state.StateTtlConfig</span>

<span class="k">val</span> <span class="n">ttlConfig</span> <span class="k">=</span> <span class="nc">StateTtlConfig</span>
    <span class="o">.</span><span class="n">newBuilder</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="n">cleanupInRocksdbCompactFilter</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
    <span class="o">.</span><span class="n">build</span>
</code></pre></div><p>RocksDB 压实过滤器在处理一定数量的状态条目后，每次都会从 Flink 中查询当前的时间戳，用于检查过期情况，你可以改变它，并传递自定义值给 <code>StateTtlConfig.newBuilder(...).cleanupInRocksdbCompactFilter(long queryTimeAfterNumEntries)</code> 方法。更频繁地更新时间戳可以提高清理速度，但由于它使用了来自本地代码的 JNI 调用，因此降低了压缩性能。RocksDB 后台默认的清理方式是每次处理1000个条目后查询当前时间戳。</p>
<p>你可以通过激活 <code>FlinkCompactionFilter</code> 的调试级别来激活 RocksDB 过滤器原生代码的调试日志。</p>
<pre><code>log4j.logger.org.rocksdb.FlinkCompactionFilter=DEBUG
</code></pre><p><strong>注意:</strong></p>
<ul>
<li>在压实过程中调用 TTL 过滤器会使其速度减慢。TTL 过滤器必须解析最后一次访问的时间戳，并检查每个被压缩的键的存储状态条目的到期时间。如果是集合状态类型(list 或 map)，每个存储元素的检查也会被调用。</li>
<li>如果该功能用于具有非固定字节长度元素的列表状态，则原生 TTL 过滤器必须额外调用每个至少第一个元素已过期的状态条目中元素在 JNI 上的 Flink java 类型序列化器，以确定下一个未过期元素的偏移。</li>
<li>对于现有的作业，这种清理策略可以在 <code>StateTtlConfig</code> 中随时激活或停用，例如从保存点重新启动后。</li>
</ul>
<h3 id="scala-datastream-api-中的状态">Scala DataStream API 中的状态</h3>
<p>除了上面描述的接口外，Scala API 还为 KeyedStream 上具有单个 <code>ValueState</code> 的有状态 <code>map()</code> 或 <code>flatMap()</code> 函数提供了快捷方式。用户函数在 <code>Option</code> 中获取 <code>ValueState</code> 的当前值，并且必须返回一个更新的值，该值将用于更新状态。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">counts</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">stream</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
  <span class="o">.</span><span class="n">mapWithState</span><span class="o">((</span><span class="n">in</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">),</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span> <span class="k">=&gt;</span>
    <span class="n">count</span> <span class="k">match</span> <span class="o">{</span>
      <span class="k">case</span> <span class="nc">Some</span><span class="o">(</span><span class="n">c</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span> <span class="o">(</span><span class="n">in</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">c</span><span class="o">),</span> <span class="nc">Some</span><span class="o">(</span><span class="n">c</span> <span class="o">+</span> <span class="n">in</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="o">)</span>
      <span class="k">case</span> <span class="nc">None</span> <span class="k">=&gt;</span> <span class="o">(</span> <span class="o">(</span><span class="n">in</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span> <span class="nc">Some</span><span class="o">(</span><span class="n">in</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span> <span class="o">)</span>
    <span class="o">})</span>
</code></pre></div><h3 id="operator-state">Operator State</h3>
<p>Operator State（或 non-keyed state）是指绑定到一个并行操作符实例的状态。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/kafka.html">Kafka 连接器</a>是 Flink 中使用 Operator State 的一个很好的激励例子。Kafka 消费者的每个并行实例都维护着一个主题分区和偏移的映射作为其 Operator State。</p>
<p>Operator State 接口支持在并行操作符实例之间重新分配状态，当并行性发生变化时。有不同的方案来进行这种重新分配。</p>
<p>在典型的有状态的 Flink 应用中，你不需要操作符状态。它主要是一种特殊类型的状态，用于源/接收器实现和你没有键的情况下，可以通过它来分隔状态。</p>
<h3 id="广播状态">广播状态</h3>
<p>Broadcast State 是 Operator State 的一种特殊类型。引入它是为了支持这样的用例：一个流的记录(records)需要被广播到所有下游任务，它们被用来在所有子任务中保持相同的状态。然后在处理第二个流的记录时可以访问这个状态。作为一个广播状态可以自然出现的例子，我们可以想象一个低吞吐量的流，其中包含一组规则，我们希望对来自另一个流的所有元素进行评估。考虑到上述类型的用例，广播状态与其余运算符状态的不同之处在于。</p>
<ul>
<li>它有一个 map 格式。</li>
<li>它只适用于有广播流和非广播流作为输入的特定操作符，以及</li>
<li>这样的操作符可以拥有多个不同名称的广播状态。</li>
</ul>
<h3 id="使用-operator-state">使用 Operator State</h3>
<p>要使用运算符状态，有状态函数可以实现 <code>CheckpointedFunction</code> 接口。</p>
<h4 id="checkpointedfunction">CheckpointedFunction</h4>
<p><code>CheckpointedFunction</code> 接口提供了对不同重分配方案的 non-keyed 的访问。它需要实现两个方法。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kt">void</span> <span class="nf">snapshotState</span><span class="o">(</span><span class="n">FunctionSnapshotContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>

<span class="kt">void</span> <span class="nf">initializeState</span><span class="o">(</span><span class="n">FunctionInitializationContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">;</span>
</code></pre></div><p>每当需要执行一个检查点时，就会调用 <code>snapshotState()</code>。与之对应的 <code>initializeState()</code>，在每次用户定义的函数被初始化时都会被调用，不管是在函数首次初始化时，还是在函数实际从早期的检查点恢复时。鉴于此，<code>initializeState()</code> 不仅是初始化不同类型状态的地方，也是包含状态恢复逻辑的地方。</p>
<p>目前，支持列表式操作符状态。状态有望成为一个可序列化对象的 <code>List</code>，彼此独立，因此在重新缩放时有资格重新分配。换句话说，这些对象是 non-keyed state 可以重新分配的最细粒度。根据状态访问方法的不同，定义了以下重分布方案。</p>
<ul>
<li>
<p>均分重分配: 每个操作符都会返回一个状态元素列表。整个状态在逻辑上是所有列表的连接(concatenation)。在还原/再分配时，列表被平均分成有多少个并行操作符就有多少个子列表。每个操作符都会得到一个子列表，这个子列表可以是空的，也可以包含一个或多个元素。举个例子，如果在并行度为1的情况下，一个操作符的检查点状态包含元素1和元素2，当把并行度增加到2时，元素1可能最终进入操作符实例0，而元素2将进入操作符实例1。</p>
</li>
<li>
<p>联盟再分配。每个操作符都会返回一个状态元素列表。整个状态在逻辑上是所有 <code>List</code> 的连接(concatenation)。在还原/再分配时，每个操作符都会得到完整的状态元素列表。如果你的列表可能有很高的基数(cardinality)，请不要使用这个功能。检查点元数据将为每个列表条目存储一个偏移，这可能会导致 RPC 帧大小或内存外错误。</p>
</li>
</ul>
<p>下面是一个有状态的 <code>SinkFunction</code> 的例子，它使用 <code>CheckpointedFunction</code> 来缓冲元素，然后再将它们发送到外界。它演示了基本的均分重分配列表状态。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">BufferingSink</span><span class="o">(</span><span class="n">threshold</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">0</span><span class="o">)</span>
  <span class="k">extends</span> <span class="nc">SinkFunction</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span>
    <span class="k">with</span> <span class="nc">CheckpointedFunction</span> <span class="o">{</span>

  <span class="nd">@transient</span>
  <span class="k">private</span> <span class="k">var</span> <span class="n">checkpointedState</span><span class="k">:</span> <span class="kt">ListState</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="k">_</span>

  <span class="k">private</span> <span class="k">val</span> <span class="n">bufferedElements</span> <span class="k">=</span> <span class="nc">ListBuffer</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]()</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">invoke</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">),</span> <span class="n">context</span><span class="k">:</span> <span class="kt">Context</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">bufferedElements</span> <span class="o">+=</span> <span class="n">value</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">bufferedElements</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">threshold</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">for</span> <span class="o">(</span><span class="n">element</span> <span class="k">&lt;-</span> <span class="n">bufferedElements</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// send it to the sink
</span><span class="c1"></span>      <span class="o">}</span>
      <span class="n">bufferedElements</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">snapshotState</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionSnapshotContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">checkpointedState</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">element</span> <span class="k">&lt;-</span> <span class="n">bufferedElements</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">checkpointedState</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">element</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">initializeState</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionInitializationContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">descriptor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ListStateDescriptor</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span>
      <span class="s">&#34;buffered-elements&#34;</span><span class="o">,</span>
      <span class="nc">TypeInformation</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="k">new</span> <span class="nc">TypeHint</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]()</span> <span class="o">{})</span>
    <span class="o">)</span>

    <span class="n">checkpointedState</span> <span class="k">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getOperatorStateStore</span><span class="o">.</span><span class="n">getListState</span><span class="o">(</span><span class="n">descriptor</span><span class="o">)</span>

    <span class="k">if</span><span class="o">(</span><span class="n">context</span><span class="o">.</span><span class="n">isRestored</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">for</span><span class="o">(</span><span class="n">element</span> <span class="k">&lt;-</span> <span class="n">checkpointedState</span><span class="o">.</span><span class="n">get</span><span class="o">())</span> <span class="o">{</span>
        <span class="n">bufferedElements</span> <span class="o">+=</span> <span class="n">element</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>

<span class="o">}</span>
</code></pre></div><p><code>initializeState</code> 方法的参数是一个 <code>FunctionInitializationContext</code>。它用于初始化 non-keyed &ldquo;容器&rdquo;。这些容器是一个 <code>ListState</code> 类型的容器，在检查点时，non-keyed 对象将被存储在那里。</p>
<p>请注意如何初始化状态，类似于 keyed state，用一个 <code>StateDescriptor</code> 来初始化，这个 <code>StateDescriptor</code> 包含了状态名称和状态所持有的值的类型信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">descriptor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ListStateDescriptor</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)](</span>
    <span class="s">&#34;buffered-elements&#34;</span><span class="o">,</span>
    <span class="nc">TypeInformation</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="k">new</span> <span class="nc">TypeHint</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]()</span> <span class="o">{})</span>
<span class="o">)</span>

<span class="n">checkpointedState</span> <span class="k">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getOperatorStateStore</span><span class="o">.</span><span class="n">getListState</span><span class="o">(</span><span class="n">descriptor</span><span class="o">)</span>
</code></pre></div><p>状态访问方法的命名约定包含其重分配模式，然后是其状态结构。例如，如果要在还原时使用 union 重分配方案的列表状态，则使用 <code>getUnionListState(descriptor)</code> 访问状态。如果方法名中不包含重分配模式，例如 <code>getListState(descriptor)</code>，则仅仅意味着将使用基本的均分重分配方案。</p>
<p>在初始化容器后，我们使用上下文的 <code>isRestored()</code> 方法来检查是否在故障后恢复。如果为真，即我们正在恢复，则应用还原逻辑。</p>
<p>如修改后的 <code>BufferingSink</code> 的代码所示，在状态初始化过程中恢复的这个 <code>ListState</code> 被保存在一个类变量中，以便将来在 <code>snapshotState()</code> 中使用。在那里，<code>ListState</code> 会被清除掉之前检查点所包含的所有对象，然后用我们要检查点的新对象来填充。</p>
<p>顺便说一下， keyed state 也可以在 <code>initializeState()</code> 方法中初始化。这可以使用提供的 <code>FunctionInitializationContext</code> 来完成。</p>
<h3 id="有状态的源函数">有状态的源函数</h3>
<p>与其他操作符相比，有状态的源需要更多的小心。为了使状态和输出集合的更新是原子性的（对于失败/恢复时的精确一次性语义来说是必需的），用户需要从源的上下文中获得一个锁。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">CounterSource</span>
       <span class="k">extends</span> <span class="nc">RichParallelSourceFunction</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span>
       <span class="k">with</span> <span class="nc">CheckpointedFunction</span> <span class="o">{</span>

  <span class="nd">@volatile</span>
  <span class="k">private</span> <span class="k">var</span> <span class="n">isRunning</span> <span class="k">=</span> <span class="kc">true</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">offset</span> <span class="k">=</span> <span class="mi">0L</span>
  <span class="k">private</span> <span class="k">var</span> <span class="n">state</span><span class="k">:</span> <span class="kt">ListState</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="k">_</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">run</span><span class="o">(</span><span class="n">ctx</span><span class="k">:</span> <span class="kt">SourceFunction.SourceContext</span><span class="o">[</span><span class="kt">Long</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">lock</span> <span class="k">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">getCheckpointLock</span>

    <span class="k">while</span> <span class="o">(</span><span class="n">isRunning</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// output and state update are atomic
</span><span class="c1"></span>      <span class="n">lock</span><span class="o">.</span><span class="n">synchronized</span><span class="o">({</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">offset</span><span class="o">)</span>

        <span class="n">offset</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="o">})</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">cancel</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="n">isRunning</span> <span class="k">=</span> <span class="kc">false</span>
  
  <span class="k">override</span> <span class="k">def</span> <span class="n">initializeState</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionInitializationContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">state</span> <span class="k">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getOperatorStateStore</span><span class="o">.</span><span class="n">getListState</span><span class="o">(</span>
      <span class="k">new</span> <span class="nc">ListStateDescriptor</span><span class="o">[</span><span class="kt">Long</span><span class="o">](</span><span class="s">&#34;state&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Long</span><span class="o">]))</span>

    <span class="k">for</span> <span class="o">(</span><span class="n">l</span> <span class="k">&lt;-</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="o">().</span><span class="n">asScala</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">offset</span> <span class="k">=</span> <span class="n">l</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">snapshotState</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionSnapshotContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">state</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>
    <span class="n">state</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">offset</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>一些运算符可能需要检查点被 Flink 完全承认时的信息来与外界沟通。在这种情况下，请参见 <code>org.apache.flink.runtime.state.CheckpointListener</code> 接口。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/state" term="state" label="State" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[内置的水印生成器]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="related" type="text/html" title="Event Time" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Datastream API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="related" type="text/html" title="Generating Watermarks" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="related" type="text/html" title="使用状态" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="状态和容错性" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Builtin Watermark Generators</blockquote><h2 id="内置水印生成器httpsciapacheorgprojectsflinkflink-docs-release-111devevent_timestamp_extractorshtml"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamp_extractors.html">内置水印生成器</a></h2>
<p>正如在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_timestamps_watermarks.html">Generating Watermarks</a> 一文中所描述的，Flink 提供了抽象，允许程序员分配自己的时间戳和发射自己的水印。更具体地说，可以通过实现 WatermarkGenerator 接口来实现。</p>
<p>为了进一步简化此类任务的编程工作，Flink 自带了一些预先实现的时间戳分配器。本节提供了它们的列表。除了它们的开箱即用的功能外，它们的实现可以作为自定义实现的范例。</p>
<h2 id="单调地增加时间戳">单调地增加时间戳</h2>
<p>周期性水印生成的最简单的特殊情况是当给定源任务(task)看到的时间戳以升序出现时。在这种情况下，当前的时间戳总是可以作为水印，因为不会有更早的时间戳到达。</p>
<p>请注意，只需要每个并行数据源任务的时间戳是升序的。例如，如果在一个特定的设置中，一个 Kafka 分区被一个并行数据源实例读取，那么只需要在每个 Kafka 分区中时间戳是升序的。每当并行流被洗牌、联合、连接(connected)或合并时，Flink 的水印合并机制都会生成正确的水印。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">WatermarkStrategy</span><span class="o">.</span><span class="n">forMonotonousTimestamps</span><span class="o">()</span>
</code></pre></div><h2 id="固定的延迟量">固定的延迟量</h2>
<p>周期性水印生成的另一个例子是，当水印滞后于流中看到的最大（事件时间）时间戳的固定时间量时。这种情况涵盖了预先知道流中可能遇到的最大延迟的场景，例如，当创建一个包含时间戳分布在固定时间段内的元素的自定义源进行测试时。对于这些情况，Flink 提供了 BoundedOutOfOrdernessWatermarks 生成器，它以 maxOutOfOrderness 作为参数，即在计算给定窗口的最终结果时，一个元素在被忽略之前允许迟到的最大时间。Lateness 对应于 <em>t - t_w</em> 的结果，其中 <em>t</em> 是一个元素的（事件-时间）时间戳，<em>t_w</em> 是之前的水印。如果 <em>lateness &gt; 0</em>，那么该元素被认为是迟到的，并且默认情况下，在计算其对应窗口的作业结果时被忽略。请参阅关于允许延迟的文档，以获得更多关于处理迟到元素的信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">WatermarkStrategy</span>
  <span class="o">.</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[状态和容错性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-event-time/?utm_source=atom_feed" rel="related" type="text/html" title="Event Time" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-flink-datastream-api-programming-guide/?utm_source=atom_feed" rel="related" type="text/html" title="Flink Datastream API 编程指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-generating-watermarks/?utm_source=atom_feed" rel="related" type="text/html" title="Generating Watermarks" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-working-with-state/?utm_source=atom_feed" rel="related" type="text/html" title="使用状态" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-21-built-in-watermark-generators/?utm_source=atom_feed" rel="related" type="text/html" title="内置的水印生成器" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-21-state-and-fault-tolerance/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-21T00:00:00+08:00</published>
            <updated>2020-08-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>State &amp; Fault Tolerance</blockquote><h2 id="状态和容错性httpsciapacheorgprojectsflinkflink-docs-release-111devstreamstate"><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/">状态和容错性</a></h2>
<p>在本节中，您将了解 Flink 为编写有状态程序提供的 API。请看一下 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">Stateful Stream Processing</a>，了解有状态流处理背后的概念。</p>
<h2 id="下一步怎么走">下一步怎么走？</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html">使用状态</a>。展示如何在 Flink 应用中使用状态，并解释不同类型的状态。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/broadcast_state.html">广播状态模式</a>。解释如何连接一个广播流和一个非广播流，并使用状态在它们之间交换信息。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">检查点</a>。描述了如何启用和配置检查点以实现容错。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">可查询状态</a>。说明如何在运行时从 Flink 外部访问状态。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html">状态模式演化</a>：介绍如何在运行时从外部访问状态。展示了状态类型的模式如何演化。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/custom_serialization.html">管理状态的自定义序列化</a>。讨论如何实现自定义序列化，特别是针对模式演化。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 的架构]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Architecture</blockquote><p>Flink 是一个分布式系统，为了执行流式应用，需要对计算资源进行有效的分配和管理。它集成了所有常见的集群资源管理器，如 <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html">Hadoop YARN</a>、<a href="https://mesos.apache.org/">Apache Mesos</a> 和 <a href="https://kubernetes.io/">Kubernetes</a>，但也可以设置为独立集群甚至作为库运行。</p>
<p>本节包含 Flink 架构的概述，并描述了其主要组件如何交互执行应用程序并从故障中恢复。</p>
<h2 id="flink-集群的解剖">Flink 集群的解剖</h2>
<p>Flink 运行时由两种类型的进程组成：一个 JobManager 和一个或多个 TaskManagers。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/processes.svg" alt="img"></p>
<p>客户端不是运行时和程序执行的一部分，而是用来准备并向 JobManager 发送数据流。之后，客户端可以断开连接（分离模式），或者保持连接以接收进度报告（附加模式）。客户端既可以作为触发执行的 Java/Scala 程序的一部分运行，也可以在命令行进程 <code>./bin/flink run</code> &hellip;中运行。</p>
<p>JobManager 和 TaskManagers 可以以各种方式启动：直接在机器上作为一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html">独立的集群</a>，在容器中，或由 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/yarn_setup.html">YARN</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/mesos.html">Mesos</a> 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作。</p>
<h3 id="jobmanager">JobManager</h3>
<p>JobManager 有一些与协调 Flink 应用的分布式执行有关的职责：它决定何时安排下一个任务（或一组任务），对已完成的任务或执行失败作出反应，协调检查点，并协调失败时的恢复等。这个过程由三个不同的组件组成。</p>
<ul>
<li><strong>资源管理器(ResourceManager)</strong></li>
</ul>
<p>ResourceManager 负责 Flink 集群中的资源去/分配和供应&ndash;它管理任务槽(<strong>task slots</strong>)，任务槽是 Flink 集群中资源调度的单位（见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#taskmanagers">TaskManagers</a>）。Flink 针对不同的环境和资源提供者（如 YARN、Mesos、Kubernetes 和独立部署）实现了多个 ResourceManagers。在独立设置中，ResourceManager 只能分配可用的 TaskManagers 的槽位，不能自行启动新的 TaskManagers。</p>
<ul>
<li><strong>Dispatcher</strong></li>
</ul>
<p>Dispatcher 提供了一个 REST 接口来提交 Flink 应用执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 来提供作业执行的信息。</p>
<ul>
<li><strong>JobMaster</strong></li>
</ul>
<p>一个 JobMaster 负责管理一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">JobGraph</a> 的执行。在一个 Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。</p>
<p>总是至少有一个 JobManager。一个高可用性设置可能有多个 JobManagers，其中一个总是领导者，其他的是备用的（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/jobmanager_high_availability.html">高可用性（HA）</a>）。</p>
<h3 id="taskmanagers">TaskManagers</h3>
<p>任务管理器（TaskManagers）（也叫 worker）执行数据流的任务，并缓冲和交换数据流。</p>
<p>必须始终有至少一个TaskManager。TaskManager中资源调度的最小单位是一个任务槽。一个任务管理器中任务槽的数量表示并发处理任务的数量。请注意，一个任务槽中可以执行多个操作者（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#tasks-and-operator-chains">Tasks 和 Operator 链</a>）。</p>
<h3 id="tasks-和-operator-chains">Tasks 和 Operator Chains</h3>
<p>对于分布式执行，Flink 将操作者的子任务链成任务。每个任务由一个线程执行。将运算符一起链入任务是一种有用的优化：它减少了线程到线程的交接和缓冲的开销，增加了整体的吞吐量，同时降低了延迟。链锁行为可以配置，详情请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#task-chaining-and-resource-groups">chaining 文档</a>。</p>
<p>下图中的示例数据流是以五个子任务，也就是五个并行线程来执行的。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_chains.svg" alt="img"></p>
<h2 id="任务槽和资源task-slots-和-resources">任务槽和资源(Task Slots 和 Resources)</h2>
<p>每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个子任务。为了控制一个任务管理器接受多少任务，它有所谓的任务槽（至少一个）。</p>
<p>每个任务槽代表任务管理器的一个固定的资源子集。例如，一个有三个槽的任务管理器，将把其管理内存的1/3奉献给每个槽。槽位资源意味着一个子任务不会与其他任务的子任务争夺管理内存，而是拥有一定量的预留管理内存。需要注意的是，这里并没有发生 CPU 隔离，目前插槽只是将任务的管理内存分开。</p>
<p>通过调整任务槽的数量，用户可以定义子任务之间的隔离方式。每个任务管理器有一个插槽意味着每个任务组都在一个单独的 JVM 中运行（例如可以在一个单独的容器中启动）。拥有多个插槽意味着更多的子任务共享同一个 JVM。同一 JVM 中的任务共享 TCP 连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每个任务的开销。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_slots.svg" alt="img"></p>
<p>默认情况下，Flink 允许子任务共享槽，即使它们是不同任务的子任务，只要它们来自同一个作业。其结果是，一个槽可以容纳整个作业的流水线。允许这种槽位共享有两个主要好处。</p>
<ul>
<li>
<p>一个 Flink 集群需要的任务槽数量正好与作业中使用的最高并行度相同。不需要计算一个程序总共包含多少个任务（具有不同的并行度）。</p>
</li>
<li>
<p>更容易获得更好的资源利用率。如果没有槽位共享，非密集型的 <code>source/map()</code> 子任务和资源密集型的 window 子任务一样，会阻塞很多资源。有了槽位共享，在我们的例子中，将基础并行度从2个增加到6个，就会产生槽位资源的充分利用，同时确保重度子任务在 TaskManager 中公平分配。</p>
</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/slot_sharing.svg" alt="img"></p>
<h2 id="flink-应用执行">Flink 应用执行</h2>
<p>Flink 应用程序是任何从其 <code>main()</code> 方法中生成一个或多个 Flink 作业的用户程序。这些作业的执行可以发生在本地 JVM（LocalEnvironment）中，也可以发生在多台机器的远程集群设置（RemoteEnvironment）中。对于每个程序，ExecutionEnvironment 提供了控制作业执行的方法（例如设置并行性）和与外界交互的方法（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">Anatomy of a Flink Program</a>）。</p>
<p>Flink 应用的作业可以提交到一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink 会话集群</a>、一个专门的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster">Flink 作业集群</a>或一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink 应用集群</a>。这些选项之间的区别主要与集群的生命周期和资源隔离保证有关。</p>
<h3 id="flink-会话集群">Flink 会话集群</h3>
<ul>
<li>
<p>集群生命周期：在 Flink 会话集群中，客户端连接到一个预先存在的、长期运行的集群，可以接受多个作业提交。即使在所有作业完成后，集群（和 JobManager）将继续运行，直到会话被手动停止。因此，一个 Flink 会话集群的寿命不受任何 Flink 作业寿命的约束。</p>
</li>
<li>
<p>资源隔离。TaskManager 插槽由 ResourceManager 在作业提交时分配，作业完成后释放。因为所有作业都共享同一个集群，所以对集群资源有一定的竞争&ndash;比如提交作业阶段的网络带宽。这种共享设置的一个限制是，如果一个任务管理器崩溃，那么所有在这个任务管理器上有任务运行的作业都会失败；同样，如果在作业管理器上发生一些致命的错误，也会影响集群中运行的所有作业。</p>
</li>
<li>
<p>其他考虑因素：拥有一个预先存在的集群，可以节省大量申请资源和启动 TaskManagers 的时间。这在作业的执行时间非常短，高启动时间会对端到端的用户体验产生负面影响的场景中非常重要&ndash;就像对短查询的交互式分析一样，希望作业能够利用现有资源快速执行计算。</p>
</li>
</ul>
<p>注：以前，Flink 会话集群也被称为会话模式下的 Flink 集群。</p>
<h3 id="flink-作业集群">Flink 作业集群</h3>
<ul>
<li>
<p>集群生命周期：在 Flink Job Cluster 中，可用的集群管理器（如 YARN 或 Kubernetes）为每个提交的作业旋转一个集群，这个集群只对该作业可用。在这里，客户端首先向集群管理器请求资源来启动 JobManager，并将作业提交给运行在这个进程内部的 Dispatcher。然后根据作业的资源需求，懒惰地分配 TaskManager。作业完成后，Flink Job Cluster 就会被拆掉。</p>
</li>
<li>
<p>资源隔离：JobManager 的致命错误只影响该 Flink Job Cluster 中运行的一个作业。</p>
</li>
</ul>
<p>其他考虑因素：由于 ResourceManager 需要申请并等待外部资源管理组件来启动 TaskManager 进程并分配资源，因此 Flink Job Cluster 更适合运行时间长、稳定性要求高、对启动时间较长不敏感的大型作业。</p>
<p>注：以前，Flink Job Cluster 也被称为作业（或每作业）模式下的 Flink Cluster。</p>
<h3 id="flink-应用集群flink-application-cluster">Flink 应用集群(Flink Application Cluster)</h3>
<ul>
<li>
<p>集群生命周期：Flink 应用集群是一个专用的 Flink 集群，它只执行来自一个 Flink 应用的作业，并且 <code>main()</code> 方法运行在集群上而不是客户端上。作业提交是一个一步到位的过程：你不需要先启动一个 Flink 集群，然后向现有的集群会话提交作业，而是将你的应用逻辑和依赖关系打包成一个可执行的作业 JAR，集群入口点(ApplicationClusterEntryPoint)负责调用 <code>main()</code> 方法来提取作业图。这样你就可以像在 Kubernetes 上部署其他应用一样部署 Flink 应用，例如。因此，Flink Application Cluster 的寿命与 Flink Application 的寿命是绑定的。</p>
</li>
<li>
<p>资源隔离：在 Flink Application Cluster 中，ResourceManager 和 Dispatcher 的范围是单一的 Flink Application，这比 Flink Session Cluster 提供了更好的分离关注点。</p>
</li>
</ul>
<p>注：Flink Job Cluster 可以看作是 Flink Application Cluster 的 &ldquo;run-on-client&rdquo; 替代品。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/architecture" term="architecture" label="architecture" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[及时的流处理]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Timely Stream Processing</blockquote><h2 id="介绍">介绍</h2>
<p>及时流处理是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态流处理</a>的一种扩展，其中时间在计算中起着一定的作用。其中，当你做时间序列分析时，当做基于特定时间段（通常称为窗口）的聚合时，或者当你做事件处理时，事件发生的时间很重要时，都是这种情况。</p>
<p>在下面的章节中，我们将着重介绍一些您在使用及时 Flink 应用时应该考虑的主题。</p>
<h2 id="时间的概念事件时间和处理时间">时间的概念：事件时间和处理时间</h2>
<p>当在流程序中提到时间时（例如定义窗口），可以提到不同的时间概念。</p>
<ul>
<li>处理时间。处理时间指的是正在执行相应操作的机器的系统时间。</li>
</ul>
<p>当流程序在处理时间上运行时，所有基于时间的操作(如时间窗口)将使用运行各操作的机器的系统时钟。一个小时的处理时间窗口将包括在系统时钟指示整小时的时间之间到达特定操作者的所有记录。例如，如果一个应用程序在上午9:15开始运行，则第一个小时处理时间窗口将包括上午9:15到10:00之间处理的事件，下一个窗口将包括上午10:00到11:00之间处理的事件，以此类推。</p>
<p>处理时间是最简单的时间概念，不需要流和机器之间的协调。它提供了最好的性能和最低的延迟。然而，在分布式和异步环境中，处理时间并不能提供确定性，因为它很容易受到记录到达系统的速度（例如从消息队列）、记录在系统内部的操作员之间流动的速度以及中断（计划性的或其他）的影响。</p>
<ul>
<li>事件时间。事件时间是指每个事件在其生产设备上发生的时间。这个时间通常在记录进入 Flink 之前就被嵌入到记录中，该事件时间戳可以从每个记录中提取出来。在事件时间中，时间的进展取决于数据，而不是任何挂钟。事件时间程序必须指定如何生成事件时间水印，这是事件时间中信号进度的机制。这个水印机制将在后面的章节中描述，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html#event-time-and-watermarks">下面</a>。</li>
</ul>
<p>在一个完美的世界里，事件时间处理将产生完全一致和确定的结果，不管事件何时到达，或它们的顺序如何。然而，除非已知事件是按顺序到达的（通过时间戳），否则事件时间处理在等待失序事件时就会产生一些延迟。由于只能在有限的时间内等待，这就对事件时间应用的确定性提出了限制。</p>
<p>假设所有的数据都已经到达，事件时间操作将按照预期的方式进行，即使在处理失序或迟到的事件时，或者在重新处理历史数据时，也能产生正确和一致的结果。例如，每小时事件时间窗口将包含所有携带事件时间戳的记录，这些记录属于该小时，无论它们到达的顺序如何，也无论它们何时被处理。更多信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html#late-elements">&ldquo;迟到事件&rdquo;</a>一节）。</p>
<p>需要注意的是，有时事件时间程序在实时处理实时数据时，会使用一些处理时间操作来保证其及时进行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/event_processing_time.svg" alt="img"></p>
<h2 id="事件时间和水印">事件时间和水印</h2>
<p>注：Flink 实现了 Dataflow 模型中的许多技术。对于事件时间和水印的介绍，可以看看下面的文章。</p>
<ul>
<li>Tyler Akidau 的 <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Streaming 101</a>。</li>
<li><a href="https://research.google.com/pubs/archive/43864.pdf">数据流模型论文</a></li>
</ul>
<p>一个支持事件时间的流处理器需要一种方法来测量事件时间的进度。例如，当事件时间已经超过一小时结束时，需要通知建立小时窗口的窗口操作员，以便操作员可以关闭正在进行的窗口。</p>
<p>事件时间的进展可以独立于处理时间(由挂钟测量)。例如，在一个程序中，操作者的当前事件时间可能略微落后于处理时间(考虑到接收事件的延迟)，而两者以相同的速度进行。另一方面，另一个流程序可能通过快进一些已经缓冲在 Kafka 主题（或另一个消息队列）中的历史数据，只用几秒钟的处理时间就可以完成几周的事件时间的进展。</p>
<p>Flink 中衡量事件时间进度的机制是水印。水印作为数据流的一部分流动，并携带一个时间戳 <em>t</em>，一个 Watermark(t) 声明该数据流中的事件时间已经达到了时间 <em>t</em>，也就是说该数据流中不应该再有时间戳 <em>t'&lt;=t</em> 的元素（即事件的时间戳大于或等于水印）。</p>
<p>下图显示了一个带有（逻辑）时间戳的事件流，以及水印的内联流。在这个例子中，事件是按顺序排列的（相对于它们的时间戳），这意味着水印只是流中的周期性标记。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_watermark_in_order.svg" alt="img"></p>
<p>水印对于无序流来说是至关重要的，如下图所示，在这种情况下，事件不是按照时间戳来排序的。一般来说，水印是一种声明，即在流中的那一点上，所有事件在某个时间戳之前都应该已经到达。一旦水印到达操作者，操作者可以将其内部事件时间时钟提前到水印的值。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_watermark_out_of_order.svg" alt="img"></p>
<p>请注意，事件时间是由新创建的流元素（或元素）从产生它们的事件或触发创建这些元素的水印中继承的。</p>
<h3 id="并行流中的水印">并行流中的水印</h3>
<p>水印是在源函数处或直接在源函数后生成的。源函数的每个并行子任务通常都会独立地生成其水印。这些水印定义了该特定并行源的事件时间。</p>
<p>当水印流经流程序时，它们会在它们到达的操作符处提前事件时间。每当一个操作者提前其事件时间时，它就会在下游为其后续操作者生成一个新的水印。</p>
<p>有些运算符会消耗多个输入流；例如，一个联合，或者在 <code>keyBy(...)</code> 或 <code>partition(...)</code> 函数之后的运算符。这种运算符的当前事件时间是其输入流事件时间的最小值。当它的输入流更新它们的事件时间时，该运算符也会更新。</p>
<p>下图显示了事件和水印在并行流中流动的例子，以及运算符跟踪事件时间的例子。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel_streams_watermarks.svg" alt="img"></p>
<h2 id="延时">延时</h2>
<p>某些元素有可能会违反水印条件，也就是说，即使在水印(t)发生后，也会有更多时间戳 <em>t'&lt;=t</em> 的元素发生。事实上，在许多现实世界的设置中，某些元素可以任意延迟，这使得无法指定某个事件时间戳的所有元素在什么时候发生。此外，即使延迟时间可以被限定，但延迟水印的时间过长往往是不可取的，因为它对事件时间窗口的评估造成过多的延迟。</p>
<p>出于这个原因，流媒体程序可能会显式地期望一些迟到的元素。晚期元素是指在系统的事件时间时钟（由水印发出的信号）已经过了晚期元素的时间戳之后到达的元素。有关如何在事件时间窗口中处理迟到元素的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#allowed-lateness">允许的延时</a>。</p>
<h2 id="窗口">窗口</h2>
<p>聚合事件（如计数、求和）在流上的工作方式与批处理中的工作方式不同。例如，不可能对一个流中的所有元素进行计数，因为流一般是无限的（无边界的）。相反，流上的聚合（计数、求和等）是由窗口来限定范围的，比如 &ldquo;过去5分钟的计数&rdquo;，或者&quot;过去100个元素的总和&quot;。</p>
<p>窗口可以是时间驱动的（例如：每30秒），也可以是数据驱动的（例如：每100个元素）。人们通常会区分不同类型的窗口，如翻滚窗口（无重叠）、滑动窗口（有重叠）和会话窗口（以不活动的间隙为点）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/windows.svg" alt="img"></p>
<p>请查看这篇<a href="https://flink.apache.org/news/2015/12/04/Introducing-windows.html">博客文章</a>，了解更多的窗口示例，或查看 DataStream API 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口文档</a>。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/stream" term="stream" label="stream" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[有状态的流处理]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Stateful Stream Processing</blockquote><h2 id="什么是状态">什么是状态？</h2>
<p>虽然数据流中的许多操作一次只看一个单独的事件（例如事件分析器），但有些操作会记住多个事件的信息（例如窗口 operator ）。这些操作被称为有状态操作。</p>
<p>一些有状态操作的例子:</p>
<ul>
<li>当一个应用程序搜索某些事件模式时，状态将存储到目前为止遇到的事件序列。</li>
<li>当按分钟/小时/天聚合事件时，状态会保存待聚合的事件。</li>
<li>当在数据点流上训练机器学习模型时，状态会保存模型参数的当前版本。</li>
<li>当需要管理历史数据时，状态可以有效访问过去发生的事件。</li>
</ul>
<p>Flink 需要了解状态，以便使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">检查点</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>使其具有容错性。</p>
<p>关于状态的知识还允许重新缩放 Flink 应用，这意味着 Flink 负责在并行实例之间重新分配状态。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">可查询状态</a>允许你在运行时从 Flink 外部访问状态。</p>
<p>在处理状态时，阅读一下 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">Flink 的状态后端</a>可能也很有用。Flink 提供了不同的状态后端，指定了状态的存储方式和位置。</p>
<h2 id="keyed-state">Keyed State</h2>
<p>Keyed state 被维护在可以被认为是一个嵌入式键/值存储中。该状态严格地与有状态 operator 读取的流一起被分割和分配。因此，对键/值状态的访问只有在 <em>keyed streams</em> 上，即在 keyed/分区数据交换之后才有可能，并且仅限于与当前事件的键相关联的值。将流和状态的键对齐，可以确保所有的状态更新都是本地操作，保证了一致性，而没有事务开销。这种对齐方式还允许 Flink 透明地重新分配状态和调整流分区。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/state_partitioning.svg" alt="img"></p>
<p>Keyed State 被进一步组织成所谓的 Key Groups。Key Groups 是 Flink 可以重新分配 Keyed State 的原子单位；Key Groups 的数量正好与定义的最大并行度相同。在执行过程中，keyed operator 的每个并行实例都与一个或多个 Key Groups 的键一起工作。</p>
<h2 id="状态持久化">状态持久化</h2>
<p>Flink 使用流重放(<strong>stream replay</strong>)和检查点(<strong>checkpointing</strong>)的组合来实现容错。一个检查点标记了每个输入流中的一个特定点以及每个 operator 的相应状态。通过恢复运算符的状态，从检查点开始重放记录，可以从检查点恢复流数据流，同时保持一致性（精确的一次处理语义）。</p>
<p>检查点间隔是用恢复时间（需要重放的记录数量）来交换执行过程中容错的开销的一种手段。</p>
<p>容错机制不断地绘制分布式流数据流的快照。对于状态较小的流媒体应用，这些快照非常轻量级，可以频繁地绘制，而不会对性能产生太大的影响。流应用的状态存储在一个可配置的地方，通常是在一个分布式文件系统中。</p>
<p>在程序失败的情况下（由于机器、网络或软件故障），Flink会停止分布式流数据流。然后系统会重新启动 operator ，并将其重置到最新的成功检查点。输入流被重置到状态快照的点。作为重新启动的并行数据流的一部分处理的任何记录都保证不影响之前的检查点状态。</p>
<p>注: 默认情况下，检查点被禁用。有关如何启用和配置检查点的详细信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">检查点</a>。</p>
<p>注: 为了实现这种机制的完全保证，数据流源（如消息队列或 broker）需要能够将数据流倒退到一个定义的最近点。<a href="http://kafka.apache.org/">Apache Kafka</a> 具有这种能力，Flink 的 Kafka 连接器利用了这一点。参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/guarantees.html">数据源和接收器的容错保证</a>，了解更多关于 Flink 连接器提供的保证的信息。</p>
<p>注: 因为 Flink 的检查点是通过分布式快照实现的，所以我们互换使用快照和检查点这两个词。通常我们也使用术语快照来表示检查点或保存点。</p>
<h3 id="检查点">检查点</h3>
<p>Flink 容错机制的核心部分是绘制分布式数据流和 operator 状态的一致快照。这些快照作为一致的检查点，系统在发生故障时可以回退。Flink 绘制这些快照的机制在 <a href="http://arxiv.org/abs/1506.08603">&ldquo;Lightweight Asynchronous Snapshots for Distributed Dataflows&rdquo;</a> 中描述。它的灵感来自于分布式快照的标准 <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf">Chandy-Lamport 算法</a>，并专门为 Flink 的执行模型量身定做。</p>
<p>请记住，所有与检查点有关的事情都可以异步完成。检查点屏障不按锁步走，操作可以异步快照其状态。</p>
<p>自 Flink 1.11 以来，检查点可以在有或没有对齐的情况下进行。在本节中，我们先介绍对齐的检查点。</p>
<h4 id="屏障">屏障</h4>
<p>Flink 的分布式快照中的一个核心元素是流屏障。这些屏障被注入到数据流中，并作为数据流的一部分与记录一起流动。屏障永远不会超越记录，它们严格按照线路流动。屏障将数据流中的记录分为进入当前快照的记录集和进入下一个快照的记录。每个屏障都带有其记录被推到前面的快照的ID。屏障不会中断数据流的流动，因此非常轻量级。不同快照的多个屏障可以同时出现在流中，这意味着不同的快照可以同时发生。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_barriers.svg" alt="img"></p>
<p>流屏障是在流源处注入并行数据流。快照n的屏障被注入的点（我们称它为 Sₙ）是源流中快照覆盖数据的位置。例如，在 Apache Kafka 中，这个位置将是分区中最后一条记录的偏移。这个位置 Sₙ 被报告给检查点协调器（Flink 的 JobManager）。</p>
<p>然后，屏障就会流向下游。当一个中间 operator 从它的所有输入流中接收到一个快照n的屏障时，它就会向它的所有输出流中发出一个快照n的屏障。一旦一个汇 operator （流 DAG 的末端）从它的所有输入流中接收到屏障n，它就会向检查点协调器确认该快照n。在所有的接收器(sink)确认了一个快照之后，它就被认为完成了。</p>
<p>一旦快照n完成后，作业再也不会向源头询问 Sₙ 之前的记录，因为此时这些记录（以及它们的子孙记录）将通过整个数据流拓扑。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_aligning.svg" alt="img"></p>
<p>接收多个输入流的 operator 需要将输入流对准快照屏障。上图就说明了这一点。</p>
<ul>
<li>一旦 operator 从一个输入流中接收到快照屏障n，它就不能再处理该流的任何记录，直到它也从其他输入中接收到屏障n。否则，它就会把属于快照n的记录和属于快照n+1的记录混在一起。</li>
<li>一旦最后一个流收到了屏障n， operator 就会发出所有的待发记录，然后自己发出快照n的屏障。</li>
<li>它快照状态并恢复处理所有输入流的记录，在处理流的记录之前，先处理输入缓冲区的记录。</li>
<li>最后， operator 将状态异步写入状态后端。</li>
</ul>
<p>需要注意的是，所有具有多个输入的 operator 和洗牌后的 operator 在消耗多个上游子任务的输出流时，都需要进行对齐。</p>
<h4 id="快照-operator-state">快照 Operator State</h4>
<p>当 operator 包含任何形式的状态时，这个状态也必须是快照的一部分。</p>
<p>Operator 在从输入流接收到所有快照屏障后，在向输出流发出屏障之前，在这个时间点快照其状态。这时，所有来自屏障之前的记录对状态的更新都已经进行了，而没有依赖于屏障之后的记录的更新。由于快照的状态可能很大，所以它被存储在一个可配置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a>。默认情况下，这是 JobManager 的内存，但对于生产使用，应该配置一个分布式的可靠存储（如 HDFS）。状态存储完毕后， operator 确认检查点，向输出流发出快照屏障，然后继续进行。</p>
<p>现在产生的快照包含。</p>
<ul>
<li>对于每个并行流数据源，当快照开始时，流中的偏移量/位置。</li>
<li>对于每个 operator，一个指向作为快照的一部分存储的状态的指针。</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/checkpointing.svg" alt="img"></p>
<h4 id="恢复">恢复</h4>
<p>这种机制下的恢复是直接的。系统会重新部署整个分布式数据流，并给每个 operator 提供快照的状态，作为检查点 <em>k</em> 的一部分。 来源被设置为从位置 Sₖ 开始读取数据流。例如在 Apache Kafka 中，这意味着告诉消费者从偏移量 Sₖ 开始获取。</p>
<p>如果状态是增量快照的，则运算符从最新的完整快照的状态开始，然后对该状态应用一系列增量快照更新。</p>
<p>更多信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/task_failure_recovery.html#restart-strategies">重启策略</a>。</p>
<h3 id="不对齐检查点">不对齐检查点</h3>
<p>从 Flink 1.11 开始，检查点也可以在不对齐的情况下进行。基本思路是，只要飞行中的数据成为 operator 状态的一部分，检查点就可以覆盖所有飞行中的数据。</p>
<p>请注意，这种方法实际上更接近 <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf">Chandy-Lamport 算法</a> ，但 Flink 仍然在源中插入屏障，以避免超载检查点协调器。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_unaligning.svg" alt="img"></p>
<p>该图描述了一个 operator 如何处理不对齐的检查点屏障。</p>
<ul>
<li>operator 对输入缓冲区中存储的第一个屏障作出反应。</li>
<li>它立即将屏障转发给下游 operator ，将其添加到输出缓冲区的末尾。</li>
<li>operator 将所有被超越的记录标记为异步存储，并创建自己状态的快照。</li>
</ul>
<p>因此， operator 只短暂地停止对输入的处理以标记缓冲区，转发屏障，并创建其他状态的快照。</p>
<p>不对齐的检查点确保屏障以最快的速度到达汇流排。它特别适合于至少有一条缓慢移动的数据路径的应用，在这种应用中，对齐时间可能达到数小时。然而，由于它增加了额外的I/O压力，所以当状态后端的I/O是瓶颈时，它并没有帮助。关于其他的局限性，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html#unaligned-checkpoints">运维</a>中更深入的讨论。</p>
<p>请注意，保存点将始终是对齐的。</p>
<h4 id="未对齐的恢复">未对齐的恢复</h4>
<p>operator 首先恢复飞行中的数据，然后才开始处理来自上游 operator 在不结盟检查点的任何数据。除此之外，它执行的步骤与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html#recovery">恢复对齐检查点</a>时相同。</p>
<h3 id="状态后端">状态后端</h3>
<p>键/值索引的具体数据结构取决于所选择的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a>。一种状态后端将数据存储在内存中的哈希图中，另一种状态后端使用 <a href="http://rocksdb.org/">RocksDB</a> 作为键/值存储。除了定义持有状态的数据结构外，状态后端还实现了对键/值状态进行时间点快照的逻辑，并将该快照作为检查点的一部分进行存储。状态后端可以在不改变应用逻辑的情况下进行配置。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/checkpoints.svg" alt="img"></p>
<h3 id="保存点">保存点</h3>
<p>所有使用检查点的程序都可以从保存点(<strong>savepoint</strong>)恢复执行。保存点允许在不丢失任何状态的情况下同时更新你的程序和 Flink 集群。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>是<strong>手动触发的检查点</strong>，它采取程序的快照并将其写入状态后端。它们依靠常规的检查点机制来实现。</p>
<p>保存点与检查点类似，只是它们是<strong>由用户触发的</strong>，当新的检查点完成后，它们<strong>不会自动失效</strong>。</p>
<h3 id="完全一次与至少一次">完全一次与至少一次</h3>
<p>对齐步骤可能会给流媒体程序增加延迟。通常，这种额外的延迟是在几毫秒的数量级，但我们已经看到一些异常值的延迟明显增加的情况。对于要求所有记录持续超低延迟（几毫秒）的应用，Flink 有一个开关，可以在检查点期间跳过流对齐。只要 operator 从每个输入中看到检查点屏障，检查点快照仍然会被绘制。</p>
<p>当跳过对齐时， operator 会继续处理所有的输入，甚至在一些检查点 <em>n</em> 的检查点屏障到达后， operator 也会继续处理。这样一来， operator 也会在检查点 <em>n</em> 的状态快照被采集之前处理属于检查点 <em>n+1</em> 的元素。在还原时，这些记录将作为重复发生，因为它们都包含在检查点 <em>n</em> 的状态快照中，并将在检查点 <em>n</em> 之后作为数据的一部分重放。</p>
<p>注意对齐只发生在有多个前辈的 operator （连接）以及有多个发送者的 operator （流重新分区/洗牌后）。正因为如此，即使在至少一次的模式下，只有令人尴尬的并行流操作(<code>map()</code>, <code>flatMap()</code>, <code>filter()</code>, &hellip;)的数据流实际上也会给出精确的一次保证。</p>
<h2 id="批量程序中的状态和容错能力">批量程序中的状态和容错能力</h2>
<p>Flink 执行<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">批处理程序</a>是流程序的一种特殊情况，其中流是有界的（元素数量有限）。一个 DataSet 在内部被当作一个数据流。因此，上述概念适用于批处理程序的方式与适用于流程序的方式相同，但有一些小的例外。</p>
<ul>
<li>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/fault_tolerance.html">批处理程序的容错</a>不使用检查点。恢复是通过完全重放流发生的。这是可能的，因为输入是有界的。这将成本更多地推向恢复，但使常规处理更便宜，因为它避免了检查点。</p>
</li>
<li>
<p>DataSet API 中的有状态操作使用简化的内存内/核心外数据结构，而不是键/值索引。</p>
</li>
<li>
<p>DataSet API 引入了特殊的同步（基于superstep的）迭代，只有在有界流上才能实现。详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">迭代文档</a>。</p>
</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/stateful" term="stateful" label="stateful" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[术语表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-glossary/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Glossary</blockquote><p><strong>Flink Application Cluster</strong></p>
<p>Flink 应用集群是一个专用的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>，它只执行一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用</a>的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a>。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>的寿命与 Flink 应用的寿命绑定。</p>
<p><strong>Flink Job Cluster</strong></p>
<p>Flink Job Cluster 是一个专用的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a>，它只执行一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a>。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a> 的寿命与 Flink Job 的寿命绑定。</p>
<p><strong>Flink Cluster</strong></p>
<p>一个分布式系统由（通常）一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 和一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager">Flink TaskManager</a> 进程组成。</p>
<p><strong>Event</strong></p>
<p>事件是关于应用程序所模拟的域的状态变化的声明。事件可以是流或批处理应用程序的输入和/或输出。事件是特殊类型的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record">记录</a>。</p>
<p><strong>ExecutionGraph</strong></p>
<p>参见物理图(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph">Physical Graph</a>)</p>
<p><strong>Function</strong></p>
<p>函数由用户实现，封装了 Flink 程序的应用逻辑。大多数 Functions 都由相应的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 封装。</p>
<p><strong>Instance</strong></p>
<p>术语 instance 用于描述运行时特定类型（通常是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a>）的具体实例。由于 Apache Flink 大部分是用 Java 编写的，所以对应于 Java 中的 Instance 或 Object 的定义。在 Apache Flink 的上下文中，并行实例这个术语也经常被用来强调同一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a> 类型的多个实例在并行运行。</p>
<p><strong>Flink Application</strong></p>
<p>Flink 应用程序是一个 Java 应用程序，它从 <code>main()</code> 方法(或通过其他方式)提交一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a>。提交作业通常是通过调用执行环境上的 <code>execute()</code> 来完成的。</p>
<p>应用程序的作业可以提交到一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink 会话集群</a>，也可以提交到一个专门的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink 应用集群</a>，或者提交到一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster">Flink 作业集群</a>。</p>
<p><strong>Flink Job</strong></p>
<p>Flink Job 是指在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用</a>中通过调用 <code>execute()</code> 来创建和提交的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>（也常称为数据流图）的运行时表示。</p>
<p><strong>JobGraph</strong></p>
<p>参见逻辑图(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">Logical Graph</a>)</p>
<p><strong>Flink JobManager</strong></p>
<p>JobManager 是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>的协调器。它包含了三个不同的组件：Flink 资源管理器、Flink 调度器和每个运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a> 一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmaster">Flink JobMaster</a>。</p>
<p><strong>Flink JobMaster</strong></p>
<p>JobMasters 是运行在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 中的组件之一。一个 JobMaster 负责监督单个作业的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a> 的执行情况。</p>
<p><strong>Logical Graph</strong></p>
<p>逻辑图是一个有向图，其中节点是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operators</a>，边缘定义了 operator 的输入/输出关系，并对应数据流或数据集。逻辑图是通过从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用程序</a>提交作业来创建的。</p>
<p>逻辑图也常被称为数据流图。</p>
<p><strong>Managed State</strong></p>
<p>Managed State 描述的是已经在框架中注册的应用状态。对于托管状态，Apache Flink 将负责处理持久性和重新缩放等问题。</p>
<p><strong>Operator</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>的节点。Operator 执行某种操作，通常由 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a> 执行。源和接收器是数据摄入和数据输出的特殊 Operator。</p>
<p><strong>Operator Chain</strong></p>
<p>一个 Operator 链由两个或多个连续的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 组成，中间没有任何重新分区。同一 Operator 链内的 operattor 直接相互转发记录，而不需要经过序列化或 Flink 的网络栈。</p>
<p><strong>Partition</strong></p>
<p>分区是整个数据流或数据集的一个独立子集。通过将每条<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record">记录</a>分配到一个或多个分区，将数据流或数据集划分为多个分区。数据流或数据集的分区在运行时由<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a>消耗。改变数据流或数据集分区方式的转换通常称为重新分区。</p>
<p><strong>Physical Graph</strong></p>
<p>物理图是翻译<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>的结果，以便在分布式运行时执行。节点是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a>，边缘表示输入/输出关系或数据流或数据集的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition">分区</a>。</p>
<p><strong>Record</strong></p>
<p>记录是数据集或数据流的组成元素。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Function">Functions</a> 接收记录作为输入，并发出记录作为输出。</p>
<p><strong>Flink Session Cluster</strong></p>
<p>一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a>，它接受多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a> 的执行。该  Flink Cluster 的寿命不受任何 Flink Job 寿命的约束。以前，Flink Session Cluster 也被称为会话模式下的 Flink Cluster。与 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink Application Cluster</a> 比较。</p>
<p><strong>State Backend</strong></p>
<p>对于流处理程序来说，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a> 的状态后端决定了它的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#managed-state">状态</a>如何存储在每个 TaskManager 上（TaskManager 的 Java 堆或（嵌入式）RocksDB），以及它在检查点时的写入位置（<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 的 Java 堆或 Filesystem）。</p>
<p><strong>Sub-Task</strong></p>
<p>子任务( Sub-Task)是指负责处理数据流的一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition">分区</a>的任务(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Task</a>)。术语&quot;子任务&quot;强调同一 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain">Operator 链</a>有多个并行的 Task。</p>
<p><strong>Task</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph">物理图</a>的节点。Task 是工作的基本单位，由 Flink 的运行时执行。任务正好封装了一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain">Operator 链</a> 的一个并行实例。</p>
<p><strong>Flink TaskManager</strong></p>
<p>TaskManager 是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a> 的工作进程。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a> 被安排给 TaskManagers 执行。它们相互通信，在后续的 Task 之间交换数据。</p>
<p><strong>Transformation</strong></p>
<p>变换应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。变换可能会在每条记录的基础上改变数据流或数据集，但也可能只改变其分区或执行聚合。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Functions</a>是 Flink 的 API 的 &ldquo;物理&quot;部分，而变换只是一个 API 概念。具体来说，大多数变换是由某些 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 实现的。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/architecture" term="architecture" label="architecture" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[概念]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Concepts</blockquote><h2 id="概念">概念</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/">实践培训</a>解释了作为 Flink 的 API 基础的有状态和及时流处理的基本概念，并提供了这些机制如何在应用中使用的例子。有状态的流处理是在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/etl.html#stateful-transformations">数据管道</a>和ETL的背景下介绍的，并在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">容错</a>部分进一步发展。在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html">&ldquo;流分析&rdquo;</a>一节中介绍了及时的流处理。</p>
<p>本概念深度部分提供了对 Flink 的架构和运行时如何实现这些概念的更深入的理解。</p>
<h2 id="flink-的-api">Flink 的 API</h2>
<p>Flink 为开发流式/批量应用提供了不同层次的抽象。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/levels_of_abstraction.svg" alt="img"></p>
<ul>
<li>
<p>最底层的抽象只是提供<strong>有状态和及时的流处理</strong>。它通过 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">Process Function</a> 嵌入到 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API</a> 中。它允许用户自由处理来自一个或多个流的事件，并提供一致的、容错的状态。此外，用户还可以注册事件时间和处理时间的回调，使程序可以实现复杂的计算。</p>
</li>
<li>
<p>在实际应用中，很多应用程序并不需要上述的低级抽象，而是可以针对 <strong>Core APIs</strong> 进行编程：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API</a>（有界/无界流）和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/">DataSet API</a>（有界数据集）。这些流畅的 API 为数据处理提供了常见的构件，比如各种形式的用户指定的转换、连接、聚合、窗口、状态等。在这些 API 中处理的数据类型在各自的编程语言中被表示为类。</p>
</li>
</ul>
<p>低级 Process Function 与 DataStream API 相集成，因此可以根据需要使用低级抽象。DataSet API 提供了关于有界数据集的附加原语，如循环/迭代。</p>
<ul>
<li><strong>Table API</strong> 是以表为中心的声明式 DSL，它可能是动态变化的表（当表示流时）。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">Table API</a> 遵循（扩展的）关系模型。表有一个附加的模式（类似于关系数据库中的表），API 提供了可比较的操作，如select、project、join、group-by、aggregation 等。Table API 程序声明式地定义了应该做什么逻辑操作，而不是具体规定操作的代码是怎样的。虽然 Table API 可以通过各种类型的用户定义函数进行扩展，但它的表现力不如 Core API，使用起来更简洁（写的代码更少）。此外，Table API 程序在执行前还要经过一个优化器，应用优化规则。</li>
</ul>
<p>人们可以在表和 DataStream/DataSet 之间无缝转换，允许程序将 Table API 与 DataStream 和 DataSet API 混合使用。</p>
<ul>
<li>Flink 提供的最高级抽象是 <strong>SQL</strong>。这个抽象在语义和表现形式上都与 Table API 相似，但将程序表示为 SQL 查询表达式。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/#sql">SQL</a> 抽象与 Table API 紧密交互，SQL 查询可以在 Table API 中定义的表上执行。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/%E6%A6%82%E5%BF%B5" term="%E6%A6%82%E5%BF%B5" label="概念" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[DataStream API 介绍]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Intro to the DataStream API</blockquote><p>本次培训的重点是广泛地介绍 DataStream API，使你能够开始编写流式应用程序。</p>
<h2 id="什么可以被流式化">什么可以被流式化？</h2>
<p>Flink 的 DataStream API(Java 和 Scala)可以让你流化任何可以序列化的东西。Flink 自己的序列化器用于:</p>
<ul>
<li>基本类型，即 String, Long, Integer, Boolean, Array</li>
<li>复合类型。Tuples, POJOs 和 Scala case classes</li>
</ul>
<p>而 Flink 又回到了 Kryo 的其他类型。也可以在 Flink 中使用其他序列化器。特别是 Avro，得到了很好的支持。</p>
<h3 id="java-元组-和-pojo">Java 元组 和 POJO</h3>
<p>Flink 的本地序列化器可以有效地操作元组和 POJO。</p>
<p><strong>元组</strong></p>
<p>对于 Java，Flink 定义了自己的 Tuple0 到 Tuple25 类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">person</span> <span class="o">=</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">);</span>

<span class="c1">// zero based index!  
</span><span class="c1"></span><span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="n">person</span><span class="o">.</span><span class="na">f0</span><span class="o">;</span>
<span class="n">Integer</span> <span class="n">age</span> <span class="o">=</span> <span class="n">person</span><span class="o">.</span><span class="na">f1</span><span class="o">;</span>
</code></pre></div><p><strong>POJO</strong></p>
<p>如果满足以下条件，Flink 将数据类型识别为 POJO 类型（并允许&quot;按名称&quot;字段引用）。</p>
<ul>
<li>类是公共的和独立的（没有非静态的内部类）。</li>
<li>该类有一个公共的无参数构造函数。</li>
<li>类（以及所有超级类）中的所有非静态、非瞬态字段要么是公共的（而且是非最终的），要么有公共的 getter- 和 setter- 方法，这些方法遵循 Java beans 中 getter 和 setter 的命名约定。</li>
</ul>
<p>例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Person</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span>  
    <span class="kd">public</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">;</span>  
    <span class="kd">public</span> <span class="nf">Person</span><span class="o">()</span> <span class="o">{};</span>  
    <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">)</span> <span class="o">{</span>  
        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">};</span>  
<span class="o">}</span>  

<span class="n">Person</span> <span class="n">person</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Fred Flintstone&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">);</span>
</code></pre></div><p>Flink 的序列化器<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html#pojo-types">支持 POJO 类型的模式进化</a>。</p>
<h3 id="scala-元组和-case-class">Scala 元组和 case class</h3>
<p>这些工作就像你期望的那样。</p>
<h2 id="一个完整的例子">一个完整的例子</h2>
<p>这个例子将一个关于人的记录流作为输入，并将其过滤为只包括成年人。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.datastream.DataStream</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.common.functions.FilterFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Example</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span>
                <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="n">flintstones</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">),</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Wilma&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">),</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Pebbles&#34;</span><span class="o">,</span> <span class="n">2</span><span class="o">));</span>

        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="n">adults</span> <span class="o">=</span> <span class="n">flintstones</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="n">FilterFunction</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;()</span> <span class="o">{</span>
            <span class="nd">@Override</span>
            <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="n">Person</span> <span class="n">person</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">person</span><span class="o">.</span><span class="na">age</span> <span class="o">&gt;=</span> <span class="n">18</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">});</span>

        <span class="n">adults</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>

        <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Person</span> <span class="o">{</span>
        <span class="kd">public</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span>
        <span class="kd">public</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">;</span>
        <span class="kd">public</span> <span class="nf">Person</span><span class="o">()</span> <span class="o">{};</span>

        <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
            <span class="k">this</span><span class="o">.</span><span class="na">age</span> <span class="o">=</span> <span class="n">age</span><span class="o">;</span>
        <span class="o">};</span>

        <span class="kd">public</span> <span class="n">String</span> <span class="nf">toString</span><span class="o">()</span> <span class="o">{</span>
            <span class="k">return</span> <span class="k">this</span><span class="o">.</span><span class="na">name</span><span class="o">.</span><span class="na">toString</span><span class="o">()</span> <span class="o">+</span> <span class="s">&#34;: age &#34;</span> <span class="o">+</span> <span class="k">this</span><span class="o">.</span><span class="na">age</span><span class="o">.</span><span class="na">toString</span><span class="o">();</span>
        <span class="o">};</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h2 id="流执行环境">流执行环境</h2>
<p>每个 Flink 应用都需要一个执行环境，本例中的 env。流式应用需要使用一个 StreamExecutionEnvironment。</p>
<p>在你的应用程序中进行的 DataStream API 调用建立了一个作业图(job graph)，这个作业图被附加到 StreamExecutionEnvironment 上。当调用 env.execute() 时，这个图会被打包并发送给 JobManager，JobManager 将作业并行化，并将它的片断分配给 Task Manager 执行。你的作业的每个并行片断将在一个任务槽(task slot)中执行。</p>
<p>注意，如果你不调用 execute()，你的应用程序将不会被运行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/distributed-runtime.svg" alt="img"></p>
<p>这种分布式运行时取决于你的应用程序是可序列化的。它还要求所有的依赖关系都能在集群中的每个节点上使用。</p>
<h3 id="基本的流源">基本的流源</h3>
<p>上面的例子使用 <code>env.fromElements(...)</code> 构造了一个 <code>DataStream[Person]</code>。这是一种方便的方法，可以将一个简单的流组合起来，用于原型或测试。StreamExecutionEnvironment 上还有一个 fromCollection(Collection) 方法。所以，你可以用这个方法来代替。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">people</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;();</span>

<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="mi">35</span><span class="o">));</span>
<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Wilma&#34;</span><span class="o">,</span> <span class="mi">35</span><span class="o">));</span>
<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Pebbles&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">));</span>

<span class="k">val</span> <span class="n">flintstones</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">people</span><span class="o">);</span>
</code></pre></div><p>另一种方便的方法是在原型开发时将一些数据导入流中，使用 socket:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">lines</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">socketTextStream</span><span class="o">(</span><span class="s">&#34;localhost&#34;</span><span class="o">,</span> <span class="mi">9999</span><span class="o">)</span>
</code></pre></div><p>或从文件中读取:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">lines</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path&#34;</span><span class="o">);</span>
</code></pre></div><p>在实际应用中，最常用的数据源是那些支持低延迟、高吞吐量并行读取并结合倒带和重放的数据源&ndash;这是高性能和容错的先决条件&ndash;如 Apache Kafka、Kinesis 和各种文件系统。REST API 和数据库也经常被用于流的丰富。</p>
<h3 id="基本的流式接收器">基本的流式接收器</h3>
<p>上面的例子使用 <code>adults.print()</code> 将其结果打印到 task manager 的日志中（当在 IDE 中运行时，它将出现在你的 IDE 的控制台中）。这将在流的每个元素上调用 <code>toString()</code>。</p>
<p>输出结果看起来像这样：</p>
<pre><code>1&gt; Fred: age 35
2&gt; Wilma: age 35
</code></pre><p>其中 <code>1&gt;</code> 和 <code>2&gt;</code> 表示哪个子任务（即线程）产生的输出。</p>
<p>在生产中，常用的接收器括 StreamingFileSink、各种数据库和一些 pub-sub 系统。</p>
<h2 id="调试">调试</h2>
<p>在生产中，你的应用程序将在远程集群或一组容器中运行。而如果它失败了，它将会远程失败。JobManager 和 TaskManager 日志对调试此类故障非常有帮助，但在 IDE 内部进行本地调试要容易得多，Flink 支持这一点。你可以设置断点，检查本地变量，并逐步检查你的代码。你也可以步入 Flink 的代码，如果你好奇 Flink 是如何工作的，这可以是一个很好的方式来了解它的内部结构。</p>
<h2 id="实践">实践</h2>
<p>在这一点上，你知道了足够的知识，可以开始编码和运行一个简单的 DataStream 应用程序。克隆 <a href="https://github.com/apache/flink-training/tree/release-1.11">flink-training</a> repo，按照 README 中的说明操作后，进行第一个练习。<a href="https://github.com/apache/flink-training/tree/release-1.11/ride-cleansing">过滤一个流（Ride Cleansing）</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://flink.apache.org/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink序列化调优第一卷：选择你的序列化器&ndash;如果你可以的话</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">Flink 程序的解剖</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#data-sources">数据源</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#data-sinks">数据接收器</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/">DataStream 连接器</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[事件驱动型应用程序]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Event-driven Applications</blockquote><h2 id="process-functions">Process Functions</h2>
<h3 id="介绍">介绍</h3>
<p>ProcessFunction 将事件处理与定时器和状态结合起来，使其成为流处理应用的强大构件。这是用 Flink 创建事件驱动应用的基础。它与 RichFlatMapFunction 非常相似，但增加了定时器。</p>
<h3 id="实例">实例</h3>
<p>如果你做过<a href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics">流分析</a>培训中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html#hands-on">实战练习</a>，你会记得它使用 TumblingEventTimeWindow 来计算每个司机在每个小时内的小费之和，就像这样:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">((</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)))</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">AddTips</span><span class="o">());</span>
</code></pre></div><p>用 KeyedProcessFunction 做同样的事情是相当直接的，也是很有教育意义的。让我们先把上面的代码替换成这样:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">((</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">PseudoWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)));</span>
</code></pre></div><p>在这段代码中，一个名为 PseudoWindow 的 KeyedProcessFunction 被应用于一个 keyed 流，其结果是一个 <code>DataStream&lt;Tuple3&lt;Long，Long，Float&gt;&gt;</code>（就是使用 Flink 内置时间窗口的实现所产生的那种流）。</p>
<p>PseudoWindow 的整体轮廓是这样的形状:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Compute the sum of the tips for each driver in hour-long windows.
</span><span class="c1">// The keys are driverIds.
</span><span class="c1"></span><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">PseudoWindow</span> <span class="kd">extends</span> 
        <span class="n">KeyedProcessFunction</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">TaxiFare</span><span class="o">,</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">durationMsec</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">PseudoWindow</span><span class="o">(</span><span class="n">Time</span> <span class="n">duration</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">durationMsec</span> <span class="o">=</span> <span class="n">duration</span><span class="o">.</span><span class="na">toMilliseconds</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called once during initialization.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called as each fare arrives to be processed.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span>
            <span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called when the current watermark indicates that a window is now complete.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onTimer</span><span class="o">(</span><span class="kt">long</span> <span class="n">timestamp</span><span class="o">,</span> 
            <span class="n">OnTimerContext</span> <span class="n">context</span><span class="o">,</span> 
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>需要注意的事情。</p>
<ul>
<li>
<p>ProcessFunctions 有好几种类型&ndash;这是一个 KeyedProcessFunctions，但还有 CoProcessFunctions、BroadcastProcessFunctions 等。</p>
</li>
<li>
<p>KeyedProcessFunction 是 RichFunction的一种。作为一个 RichFunction，它可以访问在管理 keyed state 下工作所需的 <code>open</code> 和 <code>getRuntimeContext</code> 方法。</p>
</li>
<li>
<p>有两个回调要实现：<code>processElement</code> 和 <code>onTimer</code>。<code>processElement</code> 在每次传入事件时被调用；<code>onTimer</code> 在定时器发射时被调用。这些定时器可以是事件时间，也可以是处理时间定时器。<code>processElement</code> 和 <code>onTimer</code> 都提供了一个上下文对象，该对象可以用来与 <code>TimerService</code> 交互（除其他外）。两个回调都还传递了一个可以用来发出结果的 Collector。</p>
</li>
</ul>
<h4 id="open-方法">open() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Keyed, managed state, with an entry for each window, keyed by the window&#39;s end time.
</span><span class="c1">// There is a separate MapState object for each driver.
</span><span class="c1"></span><span class="kd">private</span> <span class="kd">transient</span> <span class="n">MapState</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">sumOfTips</span><span class="o">;</span>

<span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>

    <span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">sumDesc</span> <span class="o">=</span>
            <span class="k">new</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;&gt;(</span><span class="s">&#34;sumOfTips&#34;</span><span class="o">,</span> <span class="n">Long</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Float</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">sumOfTips</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getMapState</span><span class="o">(</span><span class="n">sumDesc</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div><p>由于票价事件可能会不按顺序到达，所以有时需要处理一个小时的事件，然后再完成前一个小时的结果计算。事实上，如果水印延迟比窗口长度长得多，那么可能会同时打开许多窗口，而不是只有两个。本实现通过使用 <code>MapState</code> 来支持这一点，<code>MapState</code> 将每个窗口结束的时间戳映射到该窗口的提示之和。</p>
<h4 id="processelement-方法">processElement() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span>
        <span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">,</span>
        <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span>
        <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

    <span class="kt">long</span> <span class="n">eventTime</span> <span class="o">=</span> <span class="n">fare</span><span class="o">.</span><span class="na">getEventTime</span><span class="o">();</span>
    <span class="n">TimerService</span> <span class="n">timerService</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="na">timerService</span><span class="o">();</span>

    <span class="k">if</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">&lt;=</span> <span class="n">timerService</span><span class="o">.</span><span class="na">currentWatermark</span><span class="o">())</span> <span class="o">{</span>
        <span class="c1">// This event is late; its window has already been triggered.
</span><span class="c1"></span>    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="c1">// Round up eventTime to the end of the window containing this event.
</span><span class="c1"></span>        <span class="kt">long</span> <span class="n">endOfWindow</span> <span class="o">=</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">-</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">%</span> <span class="n">durationMsec</span><span class="o">)</span> <span class="o">+</span> <span class="n">durationMsec</span> <span class="o">-</span> <span class="n">1</span><span class="o">);</span>

        <span class="c1">// Schedule a callback for when the window has been completed.
</span><span class="c1"></span>        <span class="n">timerService</span><span class="o">.</span><span class="na">registerEventTimeTimer</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">);</span>

        <span class="c1">// Add this fare&#39;s tip to the running total for that window.
</span><span class="c1"></span>        <span class="n">Float</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">sumOfTips</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">);</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">sum</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">sum</span> <span class="o">=</span> <span class="n">0</span><span class="o">.</span><span class="na">0F</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="n">sum</span> <span class="o">+=</span> <span class="n">fare</span><span class="o">.</span><span class="na">tip</span><span class="o">;</span>
        <span class="n">sumOfTips</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">,</span> <span class="n">sum</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>要考虑的事情:</p>
<ul>
<li>
<p>迟到的事件会怎样？在水印后面的事件（即迟到）会被丢弃。如果你想做一些比这更好的事情，可以考虑使用侧输出，这将在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#side-outputs">下一节</a>解释。</p>
</li>
<li>
<p>这个例子使用了一个 MapState，其中键是时间戳，并为同一个时间戳设置一个 Timer。这是一种常见的模式；它使得在定时器发射时查找相关信息变得简单而高效。</p>
</li>
</ul>
<h4 id="ontimer-方法">onTimer() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kt">void</span> <span class="nf">onTimer</span><span class="o">(</span>
        <span class="kt">long</span> <span class="n">timestamp</span><span class="o">,</span> 
        <span class="n">OnTimerContext</span> <span class="n">context</span><span class="o">,</span> 
        <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

    <span class="kt">long</span> <span class="n">driverId</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getCurrentKey</span><span class="o">();</span>
    <span class="c1">// Look up the result for the hour that just ended.
</span><span class="c1"></span>    <span class="n">Float</span> <span class="n">sumOfTips</span> <span class="o">=</span> <span class="k">this</span><span class="o">.</span><span class="na">sumOfTips</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">timestamp</span><span class="o">);</span>

    <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">driverId</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">,</span> <span class="n">sumOfTips</span><span class="o">);</span>
    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">result</span><span class="o">);</span>
    <span class="k">this</span><span class="o">.</span><span class="na">sumOfTips</span><span class="o">.</span><span class="na">remove</span><span class="o">(</span><span class="n">timestamp</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div><p>观察:</p>
<ul>
<li>
<p>传递给 onTimer 的 OnTimerContext 上下文可以用来确定当前的键。</p>
</li>
<li>
<p>我们的伪窗口是在当前水印到达每个小时结束时被触发的，此时调用 onTimer。这个 onTimer 方法从 sumOfTips 中删除了相关的条目，这样做的效果是无法容纳迟到的事件。这相当于在使用 Flink 的时间窗口时，将 allowLateness 设置为零。</p>
</li>
</ul>
<h3 id="性能方面的考虑">性能方面的考虑</h3>
<p>Flink 提供了针对 RocksDB 优化的 MapState 和 ListState 类型。在可能的情况下，应该使用这些类型来代替持有某种集合的 ValueState 对象。RocksDB 状态后端可以追加到 ListState，而不需要经过(去)序列化，对于 MapState，每个键/值对都是一个单独的 RocksDB 对象，因此 MapState 可以有效地被访问和更新。</p>
<h2 id="侧输出">侧输出</h2>
<h3 id="介绍-1">介绍</h3>
<p>有几个很好的理由可以让 Flink operator 有一个以上的输出流，比如报告:</p>
<ul>
<li>异常</li>
<li>畸形事件</li>
<li>迟到事件</li>
<li>操作警报，如与外部服务的连接超时。</li>
</ul>
<p>侧输出是一种方便的方式。除了错误报告，侧输出也是实现流的多路分割的好方法。</p>
<h3 id="例子">例子</h3>
<p>现在，您可以对上一节中被忽略的迟到事件做些什么了。</p>
<p>一个侧输出通道与一个 <code>OutputTag&lt;T&gt;</code> 相关联。这些标签具有与侧输出的 DataStream 的类型相对应的通用类型，它们有名称。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">TaxiFare</span><span class="o">&gt;</span> <span class="n">lateFares</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">TaxiFare</span><span class="o">&gt;(</span><span class="s">&#34;lateFares&#34;</span><span class="o">)</span> <span class="o">{};</span>
</code></pre></div><p>上面展示的是一个静态的 <code>OutputTag&lt;TaxiFare&gt;</code>，它既可以在 PseudoWindow 的 processElement 方法中发出迟到事件时被引用。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="k">if</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">&lt;=</span> <span class="n">timerService</span><span class="o">.</span><span class="na">currentWatermark</span><span class="o">())</span> <span class="o">{</span>
    <span class="c1">// This event is late; its window has already been triggered.
</span><span class="c1"></span>    <span class="n">ctx</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">lateFares</span><span class="o">,</span> <span class="n">fare</span><span class="o">);</span>
<span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
    <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
<span class="o">}</span>
</code></pre></div><p>并在访问这一侧输出的流时，在作业的 <code>main</code> 方法中输出:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">SingleOutputStreamOperator</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">((</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">PseudoWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)));</span>

<span class="n">hourlyTips</span><span class="o">.</span><span class="na">getSideOutput</span><span class="o">(</span><span class="n">lateFares</span><span class="o">).</span><span class="na">print</span><span class="o">();</span>
</code></pre></div><p>或者，您可以使用两个具有相同名称的 OutputTags 来引用同一侧面输出，但如果您这样做，它们必须具有相同的类型。</p>
<h2 id="结束语">结束语</h2>
<p>在这个例子中，你已经看到了如何使用 ProcessFunction 来重新实现一个直接的时间窗口。当然，如果 Flink 内置的窗口 API 满足你的需求，无论如何，请继续使用它。但如果你发现自己在考虑用 Flink 的窗口做一些变形，不要害怕推出自己的窗口。</p>
<p>此外，ProcessFunction 对于计算分析之外的许多其他用例也很有用。下面的实践练习提供了一个完全不同的例子。</p>
<p>ProcessFunction 的另一个常见用例是用于过期的陈旧状态。如果你回想一下 <a href="https://github.com/apache/flink-training/tree/release-1.11/rides-and-fares">Rides 和 Fares 练习</a>，其中使用 RichCoFlatMapFunction 来计算一个简单的连接，示例解决方案假设 TaxiRides 和 TaxiFares 是完美匹配的，每个 rideId 是一对一的。如果一个事件丢失了，同一乘车 ID 的其他事件将永远保持在状态。这可以替换为一个 KeyedCoProcessFunction 来实现，并且可以使用一个定时器来检测和清除任何陈旧的状态。</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实战练习是 <a href="https://github.com/apache/flink-training/tree/release-1.11/long-ride-alerts">Long Ride Alerts 练习</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">ProcessFunction</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/side_output.html">侧输出</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[学习 Flink: 实践培训]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Learn Flink: Hands-on Training</blockquote><h2 id="本次培训的目标和范围">本次培训的目标和范围</h2>
<p>本培训介绍了 Apache Flink，包括足够的内容让你开始编写可扩展的流式 ETL，分析和事件驱动的应用程序，同时省略了很多（最终重要的）细节。本书的重点是为 Flink 管理状态和时间的 API 提供直接的介绍，希望在掌握了这些基础知识后，你能更好地从更详细的参考文档中获取其余需要了解的内容。每一节末尾的链接将引导你到可以学习更多知识的地方。</p>
<p>具体来说，您将学习:</p>
<ul>
<li>如何实现流数据处理管道</li>
<li>Flink 如何以及为何管理状态</li>
<li>如何使用事件时间来持续计算准确的分析结果？</li>
<li>如何在连续流上构建事件驱动的应用程序？</li>
<li>Flink 是如何提供具有精确只读语义的容错、有状态的流处理的？</li>
</ul>
<p>本培训主要介绍四个关键概念：流数据的连续处理、事件时间、有状态的流处理和状态快照。本页介绍了这些概念。</p>
<p>注: 伴随本培训的是一套实践练习，它将指导您学习如何使用所介绍的概念。每一节的最后都提供了相关练习的链接。</p>
<h2 id="流处理">流处理</h2>
<p>流是数据的天然栖息地。无论是来自网络服务器的事件，还是来自股票交易所的交易，或者是来自工厂车间机器的传感器读数，数据都是作为流的一部分被创建的。但当你分析数据时，你可以围绕有界流或无界流组织处理，而你选择哪种范式会产生深远的影响。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/bounded-unbounded.png" alt="img"></p>
<p>当你处理一个有边界的数据流时，<strong>批处理</strong>是工作的范式。在这种操作模式下，你可以选择在产生任何结果之前摄取整个数据集，这意味着，例如，可以对数据进行排序，计算全局统计，或产生一个汇总所有输入的最终报告。</p>
<p>另一方面，<strong>流处理</strong>涉及无边界的数据流。至少在概念上，输入可能永远不会结束，因此你不得不在数据到达时持续处理数据。</p>
<p>在 Flink 中，应用程序由<strong>流式数据流</strong>组成，这些数据流可以通过用户定义的<strong>运算符</strong>进行转换。这些数据流形成有向图，从一个或多个源开始，到一个或多个 sink 结束。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/program_dataflow.svg" alt="img"></p>
<p>通常，程序中的变换(transformation)和数据流(dataflow)中的运算符(operator)之间存在一对一的对应关系。但有时，一个变换可能由多个运算符(operator)组成。</p>
<p>一个应用程序可能会消耗来自流式源的实时数据，如消息队列或分布式日志，如 Apache Kafka 或 Kinesis。但 Flink 也可以消耗来自各种数据源的有界历史数据。同样，Flink 应用正在产生的结果流也可以被发送到各种各样的系统，这些系统可以作为 sink 连接。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/flink-application-sources-sinks.png" alt="img"></p>
<h3 id="并行数据流">并行数据流</h3>
<p>Flink 中的程序本质上是并行和分布式的。在执行过程中，一个流有一个或多个流分区(<strong>stream partitions</strong>)，每个运算符(operator)有一个或多个运算符子任务(<strong>operator subtasks</strong>)。运算符子任务(<strong>operator subtasks</strong>)相互独立，在不同的线程中执行，也可能在不同的机器或容器上执行。</p>
<p>运算符符子任务(<strong>operator subtasks</strong>)的数量就是该特定运算符(operator)的并行度(<strong>parallelism</strong>)。同一程序的不同运算符可能具有不同的并行度水平。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel_dataflow.svg" alt="img"></p>
<p>流可以在两个运算符之间以一对一（或转发）的模式或以重分发的模式传输数据。</p>
<ul>
<li>
<p>一对一的流（例如上图中 Source 和 map() 运算符之间）保留了元素的分区和排序。这意味着 map() 运算符的 subtask[1] 将看到与 Source 运算符的 subtask[1] 所产生的元素顺序相同的元素。</p>
</li>
<li>
<p>重新分发流（如上面 map() 和 keyBy/window 之间，以及 keyBy/window 和 Sink 之间）会改变流的分区。每个运算符子任务(operator subtask)都会根据所选的转换将数据发送到不同的目标子任务。例如 keyBy()（通过散列键来重新分区）、broadcast() 或 rebalance()（随机重新分区）。在重分发交换中，元素之间的排序只在每一对发送和接收子任务中被保留（例如，map() 的 subtask[1] 和 keyBy/window 的 subtask[2]）。因此，例如，上面显示的 keyBy/window 和 Sink 运算符之间的重新分发，引入了关于不同键的聚合结果到达 Sink 的顺序的非确定性。</p>
</li>
</ul>
<h2 id="及时的流处理">及时的流处理</h2>
<p>对于大多数流式应用来说，能够用处理实时数据的相同代码重新处理历史数据是非常有价值的&ndash;无论如何，都能产生确定性的、一致的结果。</p>
<p>此外，关注事件发生的顺序，而不是事件交付处理的顺序，并且能够推理出一组事件何时（或应该）完成也是至关重要的。例如，考虑电子商务交易，或金融贸易中涉及的一系列事件。</p>
<p>通过使用记录在数据流中的事件时间戳，而不是使用处理数据的机器的时钟，可以满足这些及时流处理的要求。</p>
<h2 id="有状态的流处理">有状态的流处理</h2>
<p>Flink 的操作可以是有状态的。这意味着一个事件的处理方式可以取决于之前所有事件的累积效果。状态可以用于一些简单的事情，例如计算每分钟的事件以显示在仪表板上，或者用于一些更复杂的事情，例如计算欺诈检测模型的功能。</p>
<p>一个 Flink 应用是在分布式集群上并行运行的。一个给定的运算符的各种并行实例将以不同的线程独立执行，一般来说，它们将在不同的机器上运行。</p>
<p>一个有状态运算符的并行实例集实际上是一个分片的键值存储。每一个并行实例负责处理一组特定键的事件，这些键的状态被保存在本地。</p>
<p>下图显示了一个作业(Job)，在作业图(job graph)中的前三个运算符上运行的并行度为2，终止于一个并行度为 1 的 sink。第三个运算符是有状态的，你可以看到在第二个和第三个运算符之间发生了一个完全连接的网络洗牌。这是在通过一些键来对流进行分区，这样所有需要一起处理的事件，都会被一起处理。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel-job.png" alt="img"></p>
<p>状态总是在本地访问，这有助于 Flink 应用实现高吞吐量和低延迟。你可以选择将状态保存在 JVM 堆上，如果状态太大，也可以将其保存在有效组织的磁盘数据结构中。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/local-state.png" alt="img"></p>
<h2 id="通过状态快照进行容错">通过状态快照进行容错</h2>
<p>Flink 能够通过状态快照和流重放的组合，提供容错、精确的一次性语义。这些快照捕获了分布式管道的整个状态，记录了进入输入队列的偏移以及整个作业图(job graph)中因摄取了该点数据而产生的状态。当发生故障时，源会被重放，状态被恢复，并恢复处理。如上所述，这些状态快照是异步捕获的，不会妨碍正在进行的处理。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[数据管道和 ETL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Data Pipelines &amp; ETL</blockquote><p>对于 Apache Flink 来说，一个非常常见的用例是实现 ETL（提取、转换、加载）管道，从一个或多个源中获取数据，进行一些转换和/或丰富，然后将结果存储在某个地方。在这一节中，我们将看看如何使用 Flink 的 DataStream API 来实现这种应用。</p>
<p>请注意，Flink的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">Table 和 SQL API</a>很适合许多 ETL 用例。但无论你最终是否直接使用 DataStream API，对这里介绍的基础知识有一个扎实的理解都是有价值的。</p>
<h2 id="无状态转换">无状态转换</h2>
<p>本节介绍了 map() 和 flatmap()，它们是用来实现无状态转换的基本操作。本节中的例子假设你熟悉 <a href="https://github.com/apache/flink-training/tree/release-1.11">flink-training</a> 仓库中的实战练习中使用的出租车乘车数据。</p>
<h3 id="map">map()</h3>
<p>在第一个练习中，你过滤了一个打车事件的流，在同一个代码库中，有一个 GeoUtils 类，它提供了一个静态方法 GeoUtils.mapToGridCell(float lon, float lat)，该方法将一个 location (longitude, latitude) 映射到一个网格单元，该单元指的是一个大约100x100米大小的区域。</p>
<p>现在让我们通过为每个事件添加 startCell 和 endCell 字段来丰富我们的打车对象流。你可以创建一个 EnrichedRide 对象，扩展 TaxiRide，添加这些字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">EnrichedRide</span> <span class="kd">extends</span> <span class="n">TaxiRide</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">startCell</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">endCell</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">EnrichedRide</span><span class="o">()</span> <span class="o">{}</span>

    <span class="kd">public</span> <span class="nf">EnrichedRide</span><span class="o">(</span><span class="n">TaxiRide</span> <span class="n">ride</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">rideId</span> <span class="o">=</span> <span class="n">ride</span><span class="o">.</span><span class="na">rideId</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">isStart</span> <span class="o">=</span> <span class="n">ride</span><span class="o">.</span><span class="na">isStart</span><span class="o">;</span>
        <span class="o">...</span>
        <span class="k">this</span><span class="o">.</span><span class="na">startCell</span> <span class="o">=</span> <span class="n">GeoUtils</span><span class="o">.</span><span class="na">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="na">startLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="na">startLat</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">endCell</span> <span class="o">=</span> <span class="n">GeoUtils</span><span class="o">.</span><span class="na">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="na">endLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="na">endLat</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">toString</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="kd">super</span><span class="o">.</span><span class="na">toString</span><span class="o">()</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span>
            <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">startCell</span><span class="o">)</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span>
            <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">endCell</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后，您可以创建一个应用程序，将流转化为:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">TaxiRideSource</span><span class="o">(...));</span>

<span class="k">val</span> <span class="n">enrichedNYCRides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">]</span>  <span class="k">=</span> <span class="n">rides</span>
    <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">RideCleansingSolution</span><span class="o">.</span><span class="nc">NYCFilter</span><span class="o">())</span>
    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">Enrichment</span><span class="o">());</span>

<span class="n">enrichedNYCRides</span><span class="o">.</span><span class="n">print</span><span class="o">();</span>
</code></pre></div><p>使用这个 MapFunction:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">Enrichment</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[</span><span class="kt">TaxiRide</span>, <span class="kt">EnrichedRide</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">taxiRide</span><span class="k">:</span> <span class="kt">TaxiRide</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="nc">EnrichedRide</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="flatmap">flatmap()</h3>
<p><code>MapFunction</code> 只适用于执行一对一的转换：对于每一个进入的流元素，<code>map()</code> 将发出一个转换后的元素。否则，你将需要使用 <code>flatmap()</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">TaxiRideSource</span><span class="o">(...));</span>

<span class="k">val</span> <span class="n">enrichedNYCRides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">());</span>

<span class="n">enrichedNYCRides</span><span class="o">.</span><span class="n">print</span><span class="o">();</span>
</code></pre></div><p>加上一个 <code>FlatMapFunction</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">NYCEnrichment</span> <span class="k">extends</span> <span class="nc">FlatMapFunction</span><span class="o">[</span><span class="kt">TaxiRide</span>, <span class="kt">EnrichedRide</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">flatMap</span><span class="o">(</span><span class="n">taxiRide</span><span class="k">:</span> <span class="kt">TaxiRide</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">])</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">valid</span><span class="k">:</span> <span class="kt">FilterFunction</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RideCleansing</span><span class="o">.</span><span class="nc">NYCFilter</span><span class="o">();</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">valid</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">))</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="k">new</span> <span class="nc">EnrichedRide</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">));</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>通过这个接口提供的 Collector，<code>flatmap()</code> 方法可以随心所欲地发射许多流元素，包括完全不发射元素。</p>
<h2 id="keyed-streams">Keyed Streams</h2>
<h3 id="keyby">keyBy()</h3>
<p>通常，能够围绕一个属性对一个流进行分区是非常有用的，这样所有具有相同属性值的事件就会被归为一组。例如，假设你想找到从每个网格单元开始的最长的出租车乘车时间。从 SQL 查询的角度考虑，这意味着要对 startCell 进行某种 GROUP BY，而在 Flink 中，这是用 <code>keyBy(KeySelector)</code> 来完成的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">())</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&#34;startCell&#34;</span><span class="o">)</span>
</code></pre></div><p>每一个 <code>keyBy</code> 都会引起一次网络洗牌，对流进行重新分区。一般来说，这是很昂贵的，因为它涉及到网络通信以及序列化和反序列化。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/keyBy.png" alt="img"></p>
<p>在上面的例子中，键是由一个字段名 &ldquo;startCell&rdquo; 指定的。这种键选择的风格有一个缺点，那就是编译器无法推断用于键选择的字段的类型，因此 Flink 会将键值作为元组传递，这可能会很笨拙。最好是使用一个正确类型的 <code>KeySelector</code>，例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">rides</span>
    <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">NYCEnrichment</span><span class="o">())</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span>
        <span class="k">new</span> <span class="n">KeySelector</span><span class="o">&lt;</span><span class="n">EnrichedRide</span><span class="o">,</span> <span class="kt">int</span><span class="o">&gt;()</span> <span class="o">{</span>

            <span class="nd">@Override</span>
            <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getKey</span><span class="o">(</span><span class="n">EnrichedRide</span> <span class="n">enrichedRide</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="na">startCell</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">})</span>
</code></pre></div><p>可以用 lambda 更简洁地表达出来。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">())</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="n">enrichedRide</span> <span class="o">-&gt;</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="n">startCell</span><span class="o">)</span>
</code></pre></div><h3 id="keys-are-computed">Keys are computed</h3>
<p>KeySelectors 并不局限于从你的事件中提取一个键，相反，它们可以用任何你想要的方式来计算键，只要产生的键是确定性的，并且有有效的 <code>hashCode()</code> 和 <code>equals()</code> 的实现。这个限制排除了生成随机数，或者返回数组或枚举的 KeySelectors，但是你可以使用元组或 POJOs 来生成复合键，例如，只要它们的元素遵循这些相同的规则。</p>
<p>键必须以确定性的方式产生，因为每当需要它们时，它们就会被重新计算，而不是附加到流记录上。</p>
<p>例如，我们不是创建一个新的 <code>EnrichedRide</code> 类，该类有一个 <code>startCell</code> 字段，然后我们将其用作键:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyBy</span><span class="o">(</span><span class="n">enrichedRide</span> <span class="o">-&gt;</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="n">startCell</span><span class="o">)</span>
</code></pre></div><p>相反, 我们可以这样做:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyBy</span><span class="o">(</span><span class="n">ride</span> <span class="o">-&gt;</span> <span class="nc">GeoUtils</span><span class="o">.</span><span class="n">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="n">startLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="n">startLat</span><span class="o">))</span>
</code></pre></div><h3 id="keyed-流的聚合">Keyed 流的聚合</h3>
<p>这段代码为每个 end-of-ride 事件创建一个新的元组流，其中包含 <code>startCell</code> 和持续时间（分钟）。</p>
<pre><code>import org.joda.time.Interval;

DataStream&lt;Tuple2&lt;Integer, Minutes&gt;&gt; minutesByStartCell = enrichedNYCRides
    .flatMap(new FlatMapFunction&lt;EnrichedRide, Tuple2&lt;Integer, Minutes&gt;&gt;() {

        @Override
        public void flatMap(EnrichedRide ride,
                            Collector&lt;Tuple2&lt;Integer, Minutes&gt;&gt; out) throws Exception {
            if (!ride.isStart) {
                Interval rideInterval = new Interval(ride.startTime, ride.endTime);
                Minutes duration = rideInterval.toDuration().toStandardMinutes();
                out.collect(new Tuple2&lt;&gt;(ride.startCell, duration));
            }
        }
    });
</code></pre><p>现在可以产生一个流，其中只包含那些对每个 <code>startCell</code> 来说是有史以来（至此）最长的乘车记录。</p>
<p>有多种方式可以表达作为键的字段。之前你看到了一个 EnrichedRide POJO 的例子，在这个例子中，要用作键的字段是用它的名字指定的。这个例子涉及到 Tuple2 对象，元组中的索引（从0开始）被用来指定键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">minutesByStartCell</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="c1">// startCell
</span><span class="c1"></span>  <span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="c1">// duration
</span><span class="c1"></span>  <span class="o">.</span><span class="n">print</span><span class="o">();</span>
</code></pre></div><p>现在，每当持续时间达到一个新的最大值时，输出流就会包含一个针对每个键的记录&ndash;如这里的50797单元格所示。</p>
<pre><code>...
4&gt; (64549,5M)
4&gt; (46298,18M)
1&gt; (51549,14M)
1&gt; (53043,13M)
1&gt; (56031,22M)
1&gt; (50797,6M)
...
1&gt; (50797,8M)
...
1&gt; (50797,11M)
...
1&gt; (50797,12M)
</code></pre><h3 id="implicit-state">(Implicit) State</h3>
<p>这是本次训练中第一个涉及有状态流的例子。虽然状态被透明地处理，但 Flink 必须跟踪每个不同键的最大持续时间。</p>
<p>每当状态涉及到你的应用时，你应该考虑状态可能会变得多大。每当键空间是无限制的，那么 Flink 需要的状态量也是无限制的。</p>
<p>当处理流时，一般来说，在有限的窗口上考虑聚合比在整个流上考虑更有意义。</p>
<h3 id="reduce-和其他聚合器">reduce() 和其他聚合器</h3>
<p>上文中使用的 <code>maxBy()</code> 只是 Flink 的 KeyedStreams 上众多聚合函数中的一个例子。还有一个更通用的 <code>reduce()</code> 函数，你可以用它来实现自己的自定义聚合。</p>
<h2 id="状态转换">状态转换</h2>
<h3 id="为什么-flink-要参与管理状态">为什么 Flink 要参与管理状态？</h3>
<p>你的应用程序当然能够在没有让 Flink 参与管理状态的情况下使用状态&ndash;但 Flink 为它所管理的状态提供了一些引人注目的功能。</p>
<ul>
<li>本地化。Flink 状态被保存在处理它的机器的本地，并且可以以内存速度被访问。</li>
<li>耐用。Flink 状态是容错的，即每隔一段时间就会自动检查一次，一旦失败就会恢复。</li>
<li>纵向可扩展。Flink 状态可以保存在嵌入式 RocksDB 实例中，通过增加更多的本地磁盘来扩展。</li>
<li>横向可扩展。随着集群的增长和收缩，Flink 状态会被重新分配。</li>
<li>可查询。Flink 状态可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">可查询状态 API</a> 进行外部查询。</li>
</ul>
<p>在本节中，您将学习如何使用 Flink 的 API 管理 keyed 状态。</p>
<h3 id="rich-函数">Rich 函数</h3>
<p>此时你已经看到了 Flink 的几个函数接口，包括 <code>FilterFunction</code>、<code>MapFunction</code> 和 <code>FlatMapFunction</code>。这些都是单一抽象方法模式的例子。</p>
<p>对于每一个接口，Flink 还提供了一个所谓的&quot;富&quot;变体，例如，<code>RichFlatMapFunction</code>，它有一些额外的方法，包括:</p>
<ul>
<li>open(Configuration c)</li>
<li>close()</li>
<li>getRuntimeContext()</li>
</ul>
<p><code>open()</code> 在操作符初始化期间被调用一次。这是一个加载一些静态数据的机会，或者, 例如打开一个外部服务的连接。</p>
<p><code>getRuntimeContext()</code> 提供了对一整套潜在的有趣的东西的访问，但最值得注意的是它是如何创建和访问由 Flink 管理的状态。</p>
<h3 id="一个带有-keyed-state-的例子">一个带有 Keyed State 的例子</h3>
<p>在这个例子中，想象一下，你有一个事件流，你想去掉重复，所以你只保留每个键的第一个事件。这里有一个应用程序可以做到这一点，使用一个名为 <code>Deduplicator</code> 的 <code>RichFlatMapFunction</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Event</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">key</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">timestamp</span><span class="o">;</span>
    <span class="o">...</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
  
    <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">EventSource</span><span class="o">())</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">e</span> <span class="o">-&gt;</span> <span class="n">e</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
        <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">Deduplicator</span><span class="o">())</span>
        <span class="o">.</span><span class="na">print</span><span class="o">();</span>
  
    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>为了达到这个目的，Deduplicator 将需要以某种方式记住，对于每个键来说，是否已经有了该键的事件。它将使用 Flink 的 <em>keyed state</em> 接口来做到这一点。</p>
<p>当你在使用像这样的 <em>keyed</em> 流时，Flink 将为每个被管理的状态项目维护一个键/值存储。</p>
<p>Flink 支持几种不同类型的 <em>keyed state</em>，本例使用的是最简单的一种，即 <code>ValueState</code>。这意味着对于每个键，Flink 将存储一个单一的对象&ndash;在本例中，一个类型为 Boolean 的对象。</p>
<p>我们的 Deduplicator 类有两个方法：<code>open()</code> 和 <code>flatMap()</code>。<code>open</code> 方法通过定义一个 ValueStateDescriptor<!-- raw HTML omitted -->` 来建立对托管状态的使用。构造函数的参数为这个 <em>keyed state</em> 项指定了一个名称（&ldquo;keyHasBeenSeen&rdquo;），并提供了可用于序列化这些对象的信息（在本例中，Types.BOOLEAN）。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Deduplicator</span> <span class="kd">extends</span> <span class="n">RichFlatMapFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">Event</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">keyHasBeenSeen</span><span class="o">;</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">desc</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;&gt;(</span><span class="s">&#34;keyHasBeenSeen&#34;</span><span class="o">,</span> <span class="n">Types</span><span class="o">.</span><span class="na">BOOLEAN</span><span class="o">);</span>
        <span class="n">keyHasBeenSeen</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getState</span><span class="o">(</span><span class="n">desc</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="na">value</span><span class="o">()</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">event</span><span class="o">);</span>
            <span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>当 <code>flatMap</code> 方法调用 <code>keyHasBeenSeen.value()</code> 时，Flink 的运行时会在上下文中查找 key 的这块状态值，只有当它为 null 时，它才会去收集事件到输出。在这种情况下，它还会将 <code>keyHasBeenSeen</code> 更新为 true。</p>
<p>这种访问和更新 key-partitioned 状态的机制可能看起来相当神奇，因为在我们的 Deduplicator 的实现中，key 并不是显式可见的。当 Flink 的运行时调用我们的 <code>RichFlatMapFunction</code> 的 <code>open</code> 方法时，没有任何事件，因此那一刻上下文中没有 key。但是当它调用 <code>flatMap</code> 方法时，被处理的事件的 key 对运行时来说是可用的，并在幕后用于确定 Flink 的状态后端中的哪个条目被操作。</p>
<p>当部署到分布式集群时，会有很多这个 Deduplicator 的实例，每个实例将负责整个键空间的一个不相干子集。因此，当你看到一个 ValueState 的单项，如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">keyHasBeenSeen</span><span class="o">;</span>
</code></pre></div><p>理解这不仅仅是一个单一的布尔值，而是一个分布式的、分片式的、键/值存储。</p>
<h3 id="清除状态">清除状态</h3>
<p>上面的例子有一个潜在的问题。如果键的空间是无限制的，会发生什么？Flink 是在某个地方为每一个被使用的不同键存储一个布尔的实例。如果有一个有界的键集，那么这将是很好的，但是在键集以无界的方式增长的应用中，有必要为不再需要的键清除状态。这是通过调用状态对象上的 <code>clear()</code> 来实现的，如:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="n">clear</span><span class="o">()</span>
</code></pre></div><p>例如，你可能想在给定键的一段时间不活动后这样做。当你在事件驱动的应用程序一节中学习 <code>ProcessFunction</code> 时，你将看到如何使用 <code>Timer</code> 来实现这一点。</p>
<p>此外，还有一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#state-time-to-live-ttl">状态存活时间(TTL)</a>选项，你可以用状态描述符来配置，指定什么时候自动清除陈旧键的状态。</p>
<h3 id="non-keyed-state">Non-keyed State</h3>
<p>也可以在 non-keyed 的上下文中使用托管状态。这有时被称为 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#operator-state">operator state</a>。所涉及的接口有些不同，由于用户定义的函数需要 non-keyed state 是不常见的，所以这里不做介绍。这个功能最常用于源和接收器(sink)的实现。</p>
<h2 id="connected-streams">Connected Streams</h2>
<p>有时不是应用这样的预定义变换:</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/transformation.svg" alt="img"></p>
<p>你希望能够动态地改变变换的某些方面&ndash;通过流的阈值，或规则，或其他参数。Flink 中支持这种模式的是一种叫做连接流(connected streams)的东西，其中一个 operator 有两个输入流，就像这样:</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/connected-streams.svg" alt="img"></p>
<p>连接流也可以用来实现流式连接(streaming joins.)。</p>
<h3 id="例子">例子</h3>
<p>在这个例子中，控制流被用来指定必须从  streamOfWords 中过滤掉的单词。一个名为 ControlFunction 的 RichCoFlatMapFunction 被应用到连接的流中来完成这个任务。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

    <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">control</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">&#34;DROP&#34;</span><span class="o">,</span> <span class="s">&#34;IGNORE&#34;</span><span class="o">).</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">);</span>
    <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">streamOfWords</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">&#34;Apache&#34;</span><span class="o">,</span> <span class="s">&#34;DROP&#34;</span><span class="o">,</span> <span class="s">&#34;Flink&#34;</span><span class="o">,</span> <span class="s">&#34;IGNORE&#34;</span><span class="o">).</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">);</span>
  
    <span class="n">control</span>
        <span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="n">datastreamOfWords</span><span class="o">)</span>
        <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">ControlFunction</span><span class="o">())</span>
        <span class="o">.</span><span class="na">print</span><span class="o">();</span>

    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>注意，被连接的两个流必须以兼容的方式进行 keyed。keyBy 的作用是对流的数据进行分区，当 keyed 流连接时，必须以同样的方式进行分区。这样就可以保证两个流中具有相同 key 的事件都会被发送到同一个实例中。那么，这就使得将该键上的两个流连接起来成为可能，例如。</p>
<p>在这种情况下，两个流的类型都是 <code>DataStream[String]</code>，并且两个流都以字符串为键。如下所示，这个 <code>RichCoFlatMapFunction</code> 在  keyed state 下存储了一个布尔值，而这个布尔值是由两个流共享的。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ControlFunction</span> <span class="kd">extends</span> <span class="n">RichCoFlatMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">blocked</span><span class="o">;</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">config</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">blocked</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getState</span><span class="o">(</span><span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;&gt;(</span><span class="s">&#34;blocked&#34;</span><span class="o">,</span> <span class="n">Boolean</span><span class="o">.</span><span class="na">class</span><span class="o">));</span>
    <span class="o">}</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap1</span><span class="o">(</span><span class="n">String</span> <span class="n">control_value</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">blocked</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="n">Boolean</span><span class="o">.</span><span class="na">TRUE</span><span class="o">);</span>
    <span class="o">}</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap2</span><span class="o">(</span><span class="n">String</span> <span class="n">data_value</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">blocked</span><span class="o">.</span><span class="na">value</span><span class="o">()</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">data_value</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>RichCoFlatMapFunction 是 FlatMapFunction 的一种，它可以应用于一对连接的流，并且它可以访问富函数接口。这意味着它可以被做成有状态的。</p>
<p>屏蔽的(blocked)布尔正在被用来记住控制流上提到的键（在这里是单词），这些词被过滤出 streamOfWords 流。这就是 <em>keyed state</em>，它在两个流之间是共享的，这就是为什么两个流要共享同一个键空间。</p>
<p><code>flatMap1</code> 和 <code>flatMap2</code> 被 Flink 运行时调用，分别来自两个连接流的元素&ndash;在我们的例子中，来自控制流的元素被传入 <code>flatMap1</code>，来自 <code>streamOfWords</code> 的元素被传入 <code>flatMap2</code>。这是由使用 <code>control.connect(datastreamOfWords)</code> 连接两个流的顺序决定的。</p>
<p>重要的是要认识到，你无法控制调用 <code>flatMap1</code> 和 <code>flatMap2</code> 回调的顺序。这两个输入流在相互竞争，Flink 运行时将对来自一个流或另一个流的事件的消耗做它想做的事。在时间和/或顺序很重要的情况下，你可能会发现有必要在托管的 Flink 状态下缓冲事件，直到你的应用程序准备好处理它们。(注意：如果你真的很绝望，可以通过使用实现 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/streaming/api/operators/InputSelectable.html">InputSelectable</a> 接口的自定义 Operator 来对双输入 operator 消耗输入的顺序进行一些有限的控制。)</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实践练习是<a href="https://github.com/apache/flink-training/tree/release-1.11/rides-and-fares">&ldquo;乘车与票价练习&rdquo;</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#datastream-transformations">数据流转换</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态的流处理</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[流分析]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Streaming Analytics</blockquote><h2 id="event-time-和-watermarks">Event Time 和 Watermarks</h2>
<h3 id="介绍">介绍</h3>
<p>Flink 明确支持三种不同的时间概念。</p>
<p>事件时间：事件发生的时间，由产生（或存储）该事件的设备记录的时间</p>
<p>摄取时间：Flink 在摄取事件时记录的时间戳。</p>
<p>处理时间：您的管道中的特定 operator 处理事件的时间。</p>
<p>为了获得可重复的结果，例如，在计算某一天股票在交易的第一个小时内达到的最高价格时，您应该使用事件时间(event time)。这样一来，结果就不会依赖于计算的时间。这种实时应用有时会使用处理时间(processing time)，但这样一来，结果就会由该小时内恰好处理的事件决定，而不是由当时发生的事件决定。基于处理时间的计算分析会导致不一致，并使重新分析历史数据或测试新的实现变得困难。</p>
<h3 id="使用事件时间">使用事件时间</h3>
<p>默认情况下，Flink 将使用处理时间(processing time)。要改变这一点，您可以设置时间特性(Time Characteristic)。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span>
    <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setStreamTimeCharacteristic</span><span class="o">(</span><span class="n">TimeCharacteristic</span><span class="o">.</span><span class="na">EventTime</span><span class="o">);</span>
</code></pre></div><p>如果你想使用事件时间，你还需要提供一个时间戳提取器和水印生成器，Flink 将使用它们来跟踪事件时间的进展。这将在下面的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html#working-with-watermarks">&ldquo;使用水印&rdquo;</a>一节中介绍，但首先我们应该解释一下什么是水印。</p>
<h3 id="水印">水印</h3>
<p>让我们通过一个简单的例子来说明为什么需要水印，以及它们是如何工作的。</p>
<p>在这个例子中，你有一个带时间戳的事件流，这些事件的到达顺序有些混乱，如下所示。显示的数字是时间戳，表示这些事件实际发生的时间。第一个到达的事件发生在时间 4，随后是更早发生的事件，在时间 2，以此类推。</p>
<pre><code>··· 23 19 22 24 21 14 17 13 12 15 9 11 7 2 4 →
</code></pre><p>现在想象一下，你正在尝试创建一个流排序器(stream sorter)。这个应用程序的目的是处理流中的每个事件，并发出一个新的流，其中包含相同的事件，但按时间戳排序。</p>
<p>一些观察:</p>
<p>(1)你的流排序器看到的第一个元素是 4， 但你不能马上把它作为排序流的第一个元素释放出来。它可能已经不按顺序到达，而更早的事件可能还没有到达。事实上，你对这个流的未来有一些神一样的知识，你可以看到，你的流排序器至少应该等到 2 到达后再产生任何结果。</p>
<p>一些缓冲，和一些延迟，是必要的。</p>
<p>(2)如果你做错了，你可能最终会永远等待。首先，排序器看到了一个来自时间 4 的事件，然后是一个来自时间 2 的事件。一个时间戳小于 2 的事件会不会永远到达？也许会，也许不会。也许不会。你可以永远等待，永远看不到 1。</p>
<p>最终你必须鼓起勇气，发出 2 作为排序流的开始。</p>
<p>(3)那么你需要的是某种策略，它定义了对于任何给定的时间戳事件，何时停止等待早期事件的到来。</p>
<p>这正是水印的作用&ndash;它们定义了何时停止等待早期(earlier)事件。</p>
<p>Flink 中的事件时间处理依赖于水印生成器，这些水印生成器将特殊的时间戳元素插入到流中，称为水印。时间 t 的水印是一种断言，即到时间 t 为止，流现在（可能）是完整的。</p>
<p>这个流排序器应该在什么时候停止等待，并推出2开始排序流？当一个时间戳为 2，或更大的水印到达时。</p>
<p>(4)你可以想象不同的策略来决定如何生成水印。</p>
<p>每一个事件都是在一些延迟之后到达的，而这些延迟是不同的，所以一些事件的延迟比其他事件更多。一个简单的方法是假设这些延迟被某个最大延迟所约束。Flink 将这种策略称为有界无序水印。很容易想象更复杂的水印方法，但对于大多数应用来说，固定的延迟已经足够好了。</p>
<h3 id="延迟与完整性">延迟与完整性</h3>
<p>关于水印的另一种思考方式是，水印让你这个流式应用的开发者能够控制延迟和完整性之间的权衡。与批处理不同的是，在批处理中，人们可以在产生任何结果之前完全了解输入，而在流式处理中，你最终必须停止等待看到更多的输入，并产生某种结果。</p>
<p>你可以积极地配置你的水印，用一个很短的延迟，从而承担在对输入不完全了解的情况下产生结果的风险&ndash;也就是说，一个可能是错误的结果，很快就产生了。或者你可以等待更长时间，并利用对输入流更完整的知识产生结果。</p>
<p>也可以实现混合解决方案，快速生成初始结果，然后在处理额外（后期）数据时对这些结果进行更新。对于某些应用来说，这是一种很好的方法。</p>
<h3 id="延迟">延迟</h3>
<p>迟到的定义是相对于水印而言的。水印(t)声明流在时间t之前是完整的；在这个水印之后的任何事件，如果时间戳 ≤t，则为延迟。</p>
<h3 id="使用水印">使用水印</h3>
<p>为了执行基于事件时间的事件处理，Flink 需要知道与每个事件相关联的时间，还需要流包含水印。</p>
<p>实践练习中使用的 Taxi 数据源为你处理了这些细节。但在你自己的应用程序中，你必须自己处理这些事情，通常是通过实现一个类来实现，该类从事件中提取时间戳，并按需生成水印。最简单的方法是使用 WatermarkStrategy:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">strategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
        <span class="o">.&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="n">20</span><span class="o">))</span>
        <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">((</span><span class="n">event</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">timestamp</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">withTimestampsAndWatermarks</span> <span class="o">=</span>
    <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">strategy</span><span class="o">);</span>
</code></pre></div><h2 id="窗口">窗口</h2>
<p>Flink 具有非常有表现力的窗口语义。</p>
<p>在本节中，你将学习</p>
<ul>
<li>如何使用窗口来计算无边界流的聚合。</li>
<li>Flink 支持哪些类型的窗口，以及</li>
<li>如何实现一个窗口化聚合的 DataStream 程序？</li>
</ul>
<h3 id="介绍-1">介绍</h3>
<p>在做流处理的时候，自然而然地想要计算流的有界子集的聚合分析，以回答这样的问题。</p>
<ul>
<li>每分钟的页面浏览量</li>
<li>每个用户每周会话数</li>
<li>每个传感器每分钟的最高温度</li>
</ul>
<p>用 Flink 计算窗口化分析依赖于两个主要的抽象。窗口分配器（Window Assigners）将事件分配给窗口（必要时创建新的窗口对象），窗口函数（Window Functions）应用于分配给窗口的事件。</p>
<p>Flink 的窗口 API 还有 Triggers 的概念，它决定什么时候调用窗口函数，还有 Evictors，它可以删除窗口中收集的元素。</p>
<p>在它的基本形式中，你将窗口化应用到像这样的 keyed stream 中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">|</span><span class="n">aggregate</span><span class="o">|</span><span class="n">process</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>您也可以对 non-keyed stream 使用窗口化，但请记住，在这种情况下，处理将不会并行进行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="n">windowAll</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">|</span><span class="n">aggregate</span><span class="o">|</span><span class="n">process</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><h3 id="窗口分配器">窗口分配器</h3>
<p>Flink 有几种内置的窗口分配器类型，下面进行说明。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/window-assigners.svg" alt="img"></p>
<p>一些例子说明这些窗口分配器的用途，以及如何指定它们:</p>
<ul>
<li>
<p>滚动时间窗口</p>
</li>
<li>
<p>每分钟浏览量</p>
</li>
<li>
<p>TumblingEventTimeWindows.of(Time.minutes(1))</p>
</li>
<li>
<p>滑动时间窗口</p>
</li>
<li>
<p>每10秒计算的每分钟页面浏览量</p>
</li>
<li>
<p>SlidingEventTimeWindows.of(Time.min(1), Time.seconds(10))</p>
</li>
<li>
<p>会话窗口</p>
</li>
<li>
<p>每节课的页面浏览量，其中每节课之间至少有30分钟的间隔。</p>
</li>
<li>
<p>EventTimeSessionWindows.withGap(Time.minutes(30))</p>
</li>
</ul>
<p>可以使用 Time.milliseconds(n), Time.seconds(n), Time.minutes(n), Time.hours(n), 和 Time.days(n) 中的一种指定持续时间。</p>
<p>基于时间的窗口分配器（包括会话窗口）有事件时间(event time)和处理时间(processing time)两种风味。这两种类型的时间窗口之间有显著的权衡。对于处理时间窗口，你必须接受这些限制:</p>
<ul>
<li>不能正确处理历史数据。</li>
<li>不能正确处理失序数据。</li>
<li>结果将是非确定性的。</li>
</ul>
<p>但具有较低延迟的优势。</p>
<p>当使用基于计数的窗口时，请记住，这些窗口将不会启动，直到一个批次完成。没有超时和处理部分窗口的选项，尽管你可以用自定义的触发器自己实现这种行为。</p>
<p>全局窗口分配器将每个事件（用相同的键）分配到同一个全局窗口。只有当你打算使用自定义触发器来做你自己的自定义窗口时，这才是有用的。在许多看似有用的情况下，您最好使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#process-functions">另一节</a>中描述的 ProcessFunction。</p>
<h3 id="窗口函数">窗口函数</h3>
<p>对于如何处理窗口的内容，您有三个基本选项。</p>
<ol>
<li>作为一个批次，使用一个 ProcessWindowFunction，它将被传递一个包含窗口内容的 Iterable。</li>
<li>以增量方式，使用 ReduceFunction 或 AggregateFunction，当每个事件被分配到窗口时被调用。</li>
<li>或两者结合，当窗口被触发时，ReduceFunction 或 AggregateFunction 的预聚集结果被提供给 ProcessWindowFunction。</li>
</ol>
<p>这里是方法1和3的例子。每个实现都在1分钟的事件时间窗口中从每个传感器中找到峰值值，并产生一个包含(key, end-of-window-timestamp, max_value) 的 Tuples 流。</p>
<h4 id="processwindowfunction-示例">ProcessWindowFunction 示例</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="n">1</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">MyWastefulMax</span><span class="o">());</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyWastefulMax</span> <span class="kd">extends</span> <span class="n">ProcessWindowFunction</span><span class="o">&lt;</span>
        <span class="n">SensorReading</span><span class="o">,</span>                  <span class="c1">// input type
</span><span class="c1"></span>        <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;,</span>  <span class="c1">// output type
</span><span class="c1"></span>        <span class="n">String</span><span class="o">,</span>                         <span class="c1">// key type
</span><span class="c1"></span>        <span class="n">TimeWindow</span><span class="o">&gt;</span> <span class="o">{</span>                   <span class="c1">// window type
</span><span class="c1"></span>    
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span>
            <span class="n">String</span> <span class="n">key</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">context</span><span class="o">,</span> 
            <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">events</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>

        <span class="kt">int</span> <span class="n">max</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">SensorReading</span> <span class="n">event</span> <span class="o">:</span> <span class="n">events</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">max</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">event</span><span class="o">.</span><span class="na">value</span><span class="o">,</span> <span class="n">max</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">context</span><span class="o">.</span><span class="na">window</span><span class="o">().</span><span class="na">getEnd</span><span class="o">(),</span> <span class="n">max</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>在这个实现中，有几件事需要注意。</p>
<ul>
<li>所有分配给窗口的事件都必须在 keyed Flink state 下被缓冲，直到窗口被触发。这可能是相当昂贵的。</li>
<li>我们的 ProcessWindowFunction 被传递了一个 Context 对象，其中包含了窗口的信息。它的接口是这样的:</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">Context</span> <span class="kd">implements</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">Serializable</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">W</span> <span class="nf">window</span><span class="o">();</span>
    
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">long</span> <span class="nf">currentProcessingTime</span><span class="o">();</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">long</span> <span class="nf">currentWatermark</span><span class="o">();</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">KeyedStateStore</span> <span class="nf">windowState</span><span class="o">();</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">KeyedStateStore</span> <span class="nf">globalState</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div><p>windowState 和 globalState 是您可以存储该键的所有窗口的 per-key, per-window, 或全局 per-key 信息的地方。例如，如果您想记录一些关于当前窗口的信息，并在处理后续窗口时使用这些信息，这可能会很有用。</p>
<h4 id="递增聚合示例">递增聚合示例</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">input</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="n">1</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(</span><span class="k">new</span> <span class="n">MyReducingMax</span><span class="o">(),</span> <span class="k">new</span> <span class="n">MyWindowFunction</span><span class="o">());</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyReducingMax</span> <span class="kd">implements</span> <span class="n">ReduceFunction</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="n">SensorReading</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">SensorReading</span> <span class="n">r1</span><span class="o">,</span> <span class="n">SensorReading</span> <span class="n">r2</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">r1</span><span class="o">.</span><span class="na">value</span><span class="o">()</span> <span class="o">&gt;</span> <span class="n">r2</span><span class="o">.</span><span class="na">value</span><span class="o">()</span> <span class="o">?</span> <span class="n">r1</span> <span class="o">:</span> <span class="n">r2</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyWindowFunction</span> <span class="kd">extends</span> <span class="n">ProcessWindowFunction</span><span class="o">&lt;</span>
    <span class="n">SensorReading</span><span class="o">,</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">SensorReading</span><span class="o">&gt;,</span> <span class="n">String</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span>
            <span class="n">String</span> <span class="n">key</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">context</span><span class="o">,</span>
            <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">maxReading</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">SensorReading</span><span class="o">&gt;&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>

        <span class="n">SensorReading</span> <span class="n">max</span> <span class="o">=</span> <span class="n">maxReading</span><span class="o">.</span><span class="na">iterator</span><span class="o">().</span><span class="na">next</span><span class="o">();</span>
        <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">context</span><span class="o">.</span><span class="na">window</span><span class="o">().</span><span class="na">getEnd</span><span class="o">(),</span> <span class="n">max</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>请注意，<code>Iterable&lt;SensorReading&gt;</code> 将只包含一个读数&ndash;由 MyReducingMax 计算的 pre-aggregated 最大值。</p>
<h3 id="迟来的事件">迟来的事件</h3>
<p>默认情况下，当使用事件时间窗口时，迟到的事件会被丢弃。窗口 API 有两个可选部分可以让您对此有更多的控制。</p>
<p>您可以使用名为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#side-outputs">&ldquo;侧输出&rdquo;</a>的机制，安排将被丢弃的事件收集到一个备用的输出流中。下面是一个例子，说明这可能是什么样子的:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">lateTag</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;(</span><span class="s">&#34;late&#34;</span><span class="o">){};</span>

<span class="n">SingleOutputStreamOperator</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(...)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(...)</span>
    <span class="o">.</span><span class="na">sideOutputLateData</span><span class="o">(</span><span class="n">lateTag</span><span class="o">)</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(...);</span>
  
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">lateStream</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">getSideOutput</span><span class="o">(</span><span class="n">lateTag</span><span class="o">);</span>
</code></pre></div><p>您还可以指定允许的延迟时间间隔，在此期间，延迟事件将继续分配给相应的窗口（其状态将被保留）。默认情况下，每个延迟事件都会导致窗口函数再次被调用（有时称为延迟发射）。</p>
<p>换句话说，水印后面的元素会被丢弃（或发送到侧输出）。</p>
<p>比如说:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(...)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(...)</span>
    <span class="o">.</span><span class="na">allowedLateness</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="n">10</span><span class="o">))</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(...);</span>
</code></pre></div><p>当允许的延迟大于零时，只有那些晚到会被丢弃的事件才会被发送到侧输出（如果已经配置了）。</p>
<h3 id="惊喜">惊喜</h3>
<p>Flink 的 windowing API 的某些方面可能并不像你所期望的那样。基于 <a href="https://flink.apache.org/community.html#mailing-lists">flink 用户邮件列表</a>和其他地方的常见问题，这里有一些关于窗口的事实可能会让你感到惊讶。</p>
<h4 id="滑动窗口会进行复制">滑动窗口会进行复制</h4>
<p>滑动窗口分配器可以创建很多窗口对象，并会将每个事件复制到每个相关窗口中。例如，如果你每15分钟有一个长度为24小时的滑动窗口，每个事件将被复制到 4*24=96 个窗口中。</p>
<h4 id="时间窗口与纪元对齐">时间窗口与纪元对齐</h4>
<p>仅仅因为你使用了一个小时的处理时间窗口，并且在 12:05 开始运行你的应用程序，并不意味着第一个窗口会在 1:05 关闭。第一个窗口将长达 55 分钟，并在 1:00 关闭。</p>
<p>但是请注意，滚动窗口和滑动窗口分配器采用一个可选的偏移参数，可以用来改变窗口的对齐方式。详情请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#tumbling-windows">滚动窗口</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#sliding-windows">滑动窗口</a>。</p>
<h4 id="窗口可以跟随窗口">窗口可以跟随窗口</h4>
<p>例如，这样做是可行的:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">stream</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">t</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">timeWindow</span><span class="o">(&lt;</span><span class="n">time</span> <span class="n">specification</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(&lt;</span><span class="n">reduce</span> <span class="n">function</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="na">timeWindowAll</span><span class="o">(&lt;</span><span class="n">same</span> <span class="n">time</span> <span class="n">specification</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(&lt;</span><span class="n">same</span> <span class="n">reduce</span> <span class="n">function</span><span class="o">&gt;)</span>
</code></pre></div><p>你可能会期望 Flink 的运行时足够聪明，能够为你做这种并行的预聚合（前提是你使用的是 ReduceFunction 或 AggregateFunction），但事实并非如此。</p>
<p>之所以这样做的原因是，一个时间窗口产生的事件会根据窗口结束的时间分配时间戳。所以，例如，一个小时长的窗口产生的所有事件都会有标记一个小时结束的时间戳。任何消耗这些事件的后续窗口的持续时间应该与前一个窗口的持续时间相同，或者是其倍数。</p>
<h4 id="空的时间窗口没有结果">空的时间窗口没有结果</h4>
<p>只有当事件被分配到窗口时，才会创建窗口。因此，如果在给定的时间帧内没有事件，就不会报告结果。</p>
<h4 id="迟来的事件会导致迟来的合并">迟来的事件会导致迟来的合并</h4>
<p>会话窗口是基于可以合并的窗口的抽象。每个元素最初都被分配到一个新的窗口，之后只要窗口之间的间隙足够小，就会合并。这样一来，一个迟到的事件可以弥合分开两个之前独立的会话的差距，产生迟到的合并。</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实战练习是 <a href="https://github.com/apache/flink-training/tree/release-1.11/hourly-tips">Hourly Tips Exercise</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html">及时的流处理</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a></li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[通过状态快照进行容错]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Fault Tolerance via State Snapshots</blockquote><h2 id="状态后端">状态后端</h2>
<p>Flink 管理的 keyed state 是一种碎片化的、键/值存储，每项 keyed state 的工作副本都被保存在负责该键的 taskmanager 的本地某处。Operator 的状态也被保存在需要它的机器的本地。Flink 会定期对所有状态进行持久化快照，并将这些快照复制到某个更持久的地方，比如分布式文件系统。</p>
<p>在发生故障的情况下，Flink 可以恢复你的应用程序的完整状态，并恢复处理，就像什么都没有发生过一样。</p>
<p>Flink 管理的这种状态被存储在状态后端中。状态后端有两种实现&ndash;一种是基于 RocksDB 的，它是一个嵌入式的键/值存储，将其工作状态保存在磁盘上；另一种是基于堆的状态后端，将其工作状态保存在内存中，在 Java 堆上。这种基于堆的状态后端有两种风味：将其状态快照持久化到分布式文件系统的 FsStateBackend 和使用 JobManager 的堆的 MemoryStateBackend。</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">工作状态</th>
<th style="text-align:left">状态备份</th>
<th style="text-align:left">快照</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">RocksDBStateBackend</td>
<td style="text-align:left">本地磁盘(tmp dir)</td>
<td style="text-align:left">分布式文件系统</td>
<td style="text-align:left">完全/增量</td>
</tr>
<tr>
<td style="text-align:left">支持大于可用内存的状态; 经验法则：比基于堆的后端慢10倍。</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">FsStateBackend</td>
<td style="text-align:left">JVM Heap</td>
<td style="text-align:left">分布式文件系统</td>
<td style="text-align:left">Full</td>
</tr>
<tr>
<td style="text-align:left">速度快，需要大量堆积; 受制于 GC</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">MemoryStateBackend</td>
<td style="text-align:left">JVM Heap</td>
<td style="text-align:left">JobManager JVM Heap</td>
<td style="text-align:left">Full</td>
</tr>
<tr>
<td style="text-align:left">有利于小状态（地方）的测试和实验。</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<p>当处理保存在基于堆的状态后端的状态时，访问和更新涉及到在堆上读写对象。但是对于保存在 RocksDBStateBackend 中的对象，访问和更新涉及到序列化和反序列化，因此成本更高。但是使用 RocksDB 可以拥有的状态数量只受限于本地磁盘的大小。还要注意的是，只有 RocksDBStateBackend 能够进行增量快照，这对于有大量缓慢变化的状态的应用来说是一个很大的好处。</p>
<p>所有这些状态后端都能够进行异步快照，这意味着它们可以在不妨碍正在进行的流处理的情况下进行快照。</p>
<h2 id="状态快照">状态快照</h2>
<h3 id="定义">定义</h3>
<ul>
<li>快照&ndash;一个通用术语，指的是一个 Flink 作业状态的全局、一致的图像。快照包括进入每个数据源的指针（例如，进入文件或 Kafka 分区的偏移），以及来自每个作业的有状态操作符的状态副本，这些操作符是在处理了所有事件后产生的，直到源中的这些位置。</li>
<li>检查点&ndash;Flink 为了能够从故障中恢复而自动拍摄的快照。检查点可以是增量的，并为快速恢复进行了优化。</li>
<li>外部化检查点&ndash;通常检查点不打算被用户操纵。Flink 只在作业运行时保留n个最近的检查点（n是可配置的），并在作业取消时删除它们。但你也可以配置它们被保留，在这种情况下，你可以手动从它们恢复。</li>
<li>保存点&ndash;由用户（或API调用）手动触发的快照，用于某些操作目的，例如有状态的重新部署/升级/重新缩放操作。保存点始终是完整的，并为操作的灵活性进行了优化。</li>
</ul>
<h3 id="状态快照是如何工作的">状态快照是如何工作的？</h3>
<p>Flink 使用 <a href="https://en.wikipedia.org/wiki/Chandy-Lamport_algorithm">Chandy-Lamport</a> 算法的一个变体，称为异步屏障快照。</p>
<p>当任务管理器被检查点协调器（作业管理器的一部分）指示开始检查点时，它让所有的源记录它们的偏移量，并在它们的流中插入编号的检查点障碍。这些屏障在作业图(job graph)中流动，指示每个检查点前后的流的部分。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_barriers.svg" alt="img"></p>
<p>检查点n将包含每个 operator 的状态，这些状态是由于消耗了检查点障碍n之前的每个事件，而没有消耗它之后的任何事件。</p>
<p>当作业图中的每个 operator 接收到这些障碍之一时，它就会记录其状态。具有两个输入流（如 CoProcessFunction）的 operator 执行屏障对齐，这样快照将反映消耗两个输入流的事件所产生的状态，直到（但不超过）两个屏障。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_aligning.svg" alt="img"></p>
<p>Flink 的状态后端使用复制-写机制，允许在异步快照状态的旧版本时，流处理不受阻碍地继续。只有当快照被持久化后，这些旧版本的状态才会被垃圾回收。</p>
<h3 id="一次性保证">一次性保证</h3>
<p>当流处理应用中出现问题时，有可能出现丢失，或者重复的结果。在 Flink 中，根据你对应用的选择和你运行它的集群，这些结果中的任何一种都是可能的。</p>
<ul>
<li>Flink 不努力从故障中恢复（最多一次）。</li>
<li>没有任何损失，但您可能会遇到重复的结果（至少一次）。</li>
<li>没有任何东西丢失或重复（精确地一次）。</li>
</ul>
<p>鉴于 Flink 通过倒带和重放源数据流从故障中恢复，当理想情况被描述为精确一次时，这并不意味着每个事件都将被精确处理一次。相反，它意味着每一个事件都会对 Flink 所管理的状态产生一次确切的影响。</p>
<p>Barrier 对齐只需要用于提供精确的一次保证。如果你不需要这个，你可以通过配置 Flink 使用 CheckpointingMode.AT_LEAST_ONCE 来获得一些性能，它的效果是禁用屏障对齐。</p>
<h3 id="精确一次-端到端">精确一次, 端到端</h3>
<p>为了实现端到端精确的一次，让源的每个事件精确地影响汇，以下几点必须是真的。</p>
<ol>
<li>你的源必须是可重播的，并且</li>
<li>你的接收器必须是事务性的(或幂等的)</li>
</ol>
<h2 id="实践">实践</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html">Flink Operations Playground</a> 包括<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#observing-failure--recovery">观察故障和恢复</a>的部分。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态的流处理</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/guarantees.html">数据源和接收器的容错保证</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">启用和配置检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html">检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/large_state_tuning.html">调整检查点和大状态</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/checkpoint_monitoring.html">监测检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/task_failure_recovery.html">任务故障恢复</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 操作游乐场]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="related" type="text/html" title="Python API 指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Operations Playground</blockquote><h2 id="flink-操作游乐场">Flink 操作游乐场</h2>
<p>在各种环境中部署和操作 Apache Flink 的方法有很多。无论这种多样性如何，Flink 集群的基本构件保持不变，类似的操作原则也适用。</p>
<p>在这个游乐场上，你将学习如何管理和运行 Flink Jobs。你将看到如何部署和监控应用程序，体验 Flink 如何从 Job 故障中恢复，并执行日常操作任务，如升级和重新缩放。</p>
<h3 id="这个游乐场的解剖">这个游乐场的解剖</h3>
<p>这个游乐场由一个持久的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink Session Cluster</a> 和一个 Kafka Cluster 组成。</p>
<p>一个 Flink Cluster 总是由一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 和一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager">Flink TaskManager</a> 组成。JobManager 负责处理 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Job</a> 提交，监督 Job 以及资源管理。Flink TaskManager 是 worker 进程，负责执行构成 Flink Job 的实际<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">任务</a>。在这个游戏场中，你将从单个 TaskManager 开始，但以后会扩展到更多的 TaskManager。此外，这个游乐场还带有一个专门的客户端容器，我们使用它来提交 Flink Job，并在以后执行各种操作任务。客户端容器不是 Flink Cluster 本身需要的，只是为了方便使用才包含在里面。</p>
<p>Kafka 集群由一个 Zookeeper 服务器和一个 Kafka Broker 组成。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/flink-docker-playground.svg" alt="img"></p>
<p>当游乐场启动时，一个名为 Flink Event Count 的 Flink Job 将被提交给 JobManager。此外，还会创建两个 Kafka 主题 <em>input</em> 和 <em>output</em>。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/click-event-count-example.svg" alt="img"></p>
<p>该作业从 <em>input</em> 主题中消耗点击事件(<strong>ClickEvent</strong>)，每个点击事件(<strong>ClickEvent</strong>)都有一个时间戳(<strong>timestamp</strong>)和一个页面(<strong>page</strong>)。然后按页面对事件进行分组(<strong>keyed by</strong>)，并在 15 秒的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>中进行计数。结果被写入 <em>output</em> 主题。</p>
<p>有6个不同的页面，我们在每个页面和15秒内产生1000个点击事件。因此，Flink 作业的输出应该显示每个页面和窗口有1000个浏览量。</p>
<h3 id="启动游乐场">启动游乐场</h3>
<p>游戏场环境的设置只需几步。我们将引导你完成必要的命令，并展示如何验证一切都在正确运行。</p>
<p>我们假设你的机器上安装了 <a href="https://docs.docker.com/">Docker</a>（1.12+）和 <a href="https://docs.docker.com/compose/">docker-compose</a>（2.1+）。</p>
<p>所需的配置文件可以在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 仓库中找到。检查一下，然后对齐环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">git clone --branch release-1.11 https://github.com/apache/flink-playgrounds.git
<span class="nb">cd</span> flink-playgrounds/operations-playground
docker-compose build
docker-compose up -d
</code></pre></div><p>之后，你可以用以下命令检查正在运行的 Docker 容器。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose ps

                    Name                                  Command               State                   Ports                
-----------------------------------------------------------------------------------------------------------------------------
operations-playground_clickevent-generator_1   /docker-entrypoint.sh java ...   Up       6123/tcp, 8081/tcp                  
operations-playground_client_1                 /docker-entrypoint.sh flin ...   Exit <span class="m">0</span>                                       
operations-playground_jobmanager_1             /docker-entrypoint.sh jobm ...   Up       6123/tcp, 0.0.0.0:8081-&gt;8081/tcp    
operations-playground_kafka_1                  start-kafka.sh                   Up       0.0.0.0:9094-&gt;9094/tcp              
operations-playground_taskmanager_1            /docker-entrypoint.sh task ...   Up       6123/tcp, 8081/tcp                  
operations-playground_zookeeper_1              /bin/sh -c /usr/sbin/sshd  ...   Up       2181/tcp, 22/tcp, 2888/tcp, 3888/tcp
</code></pre></div><p>这表明客户端容器已经成功提交了 Flink Job（Exit 0），所有集群组件以及数据生成器都在运行（Up）。</p>
<p>你可以通过调用来停止游乐场环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose down -v
</code></pre></div><h3 id="进入游乐场">进入游乐场</h3>
<p>在这个游乐场中，有很多东西你可以尝试和检查。在下面的两节中，我们将向你展示如何与 Flink 集群进行交互，并展示 Flink 的一些关键功能。</p>
<h4 id="flink-webui">Flink WebUI</h4>
<p>观察你的 Flink 集群最自然的出发点是在 <a href="http://localhost:8081/">http://localhost:8081</a> 下暴露的 WebUI。如果一切顺利，你会看到集群最初由一个 TaskManager 组成，并执行一个名为 Click Event Count 的 Job。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui.png" alt="img"></p>
<p>Flink WebUI 包含了很多关于 Flink 集群和它的工作的有用和有趣的信息（JobGraph, Metrics, Checkpointing Statistics, TaskManager Status, &hellip;）。</p>
<h4 id="日志">日志</h4>
<h5 id="jobmanager">JobManager</h5>
<p>可以通过 <code>docker-compose</code> 对 JobManager 日志进行跟踪。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f jobmanager
</code></pre></div><p>在初始启动后，你应该主要看到每一个检查点完成的日志信息。</p>
<h5 id="taskmanager">TaskManager</h5>
<p>TaskManager 的日志也可以用同样的方式进行 tail。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f taskmanager
</code></pre></div><p>在初始启动后，你应该主要看到每个检查点完成的日志信息。</p>
<h4 id="flink-cli">Flink CLI</h4>
<p>Flink CLI 可以在客户端容器中使用。例如，要打印 Flink CLI 的帮助信息，你可以运行以下命令</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink --help
</code></pre></div><h4 id="flink-rest-api">Flink REST API</h4>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">Flink REST API</a> 通过主机上的 localhost:8081 或客户端容器中的 jobmanager:8081 暴露出来，例如，要列出所有当前正在运行的作业，你可以运行:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">curl localhost:8081/jobs
</code></pre></div><h4 id="kafka-topics">Kafka Topics</h4>
<p>你可以通过运行以下命令来查看写入 Kafka 主题的记录</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">//input topic <span class="o">(</span><span class="m">1000</span> records/s<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic input

//output topic <span class="o">(</span><span class="m">24</span> records/min<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><h4 id="time-to-play">Time to Play!</h4>
<p>现在你已经学会了如何与 Flink 和 Docker 容器进行交互，让我们来看看一些常见的操作任务，你可以在我们的游乐场上尝试一下。所有这些任务都是相互独立的，即你可以以任何顺序执行它们。大多数任务可以通过 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-cli">CLI</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-rest-api">REST API</a> 来执行。</p>
<h5 id="列出正在运行的-job">列出正在运行的 Job</h5>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink list
</code></pre></div><p><strong>期望的输出</strong></p>
<pre><code>Waiting for response...
------------------ Running/Restarting Jobs -------------------
16.07.2019 16:37:55 : &lt;job-id&gt; : Click Event Count (RUNNING)
--------------------------------------------------------------
No scheduled jobs.
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<pre><code>curl localhost:8081/jobs
</code></pre><p><strong>期待的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobs&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div><p>JobID 在提交时被分配给作业(Job)，并且需要通过 CLI 或 REST API 对作业(Job)执行操作。</p>
<h5 id="观察故障和恢复">观察故障和恢复</h5>
<p>Flink 在(部分)失败下提供了精确的一次处理保证。在这个游乐场中，你可以观察并在一定程度上验证这种行为。</p>
<p><strong>步骤1：观察输出</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#anatomy-of-this-playground">如上所述</a>，在这个游乐场中的事件是这样生成的，每个窗口正好包含一千条记录。因此，为了验证 Flink 是否成功地从 TaskManager 故障中恢复，而没有数据丢失或重复，你可以跟踪 <em>output</em> 主题，并检查恢复后所有的窗口都存在，而且计数是正确的。</p>
<p>为此，从 <em>output</em> 主题开始读取，并让这个命令运行到恢复后（步骤3）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第二步：引入故障</strong></p>
<p>为了模拟部分故障，你可以杀死一个 TaskManager，在生产设置中，这可能对应于 TaskManager 进程、TaskManager 机器的丢失，或者仅仅是框架或用户代码抛出的瞬时异常（例如由于暂时不可用）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">kill</span> taskmanager
</code></pre></div><p>几秒钟后，JobManager 会注意到 TaskManager 的丢失，取消受影响的 Job，并立即重新提交它进行恢复。当 Job 被重新启动后，其任务仍处于 <strong>SCHEDULED</strong> 状态，由紫色的方块表示（见下面的截图）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui-failure.png" alt="img"></p>
<p>注意：即使作业(Job)的任务(Task)处于 <strong>SCHEDULED</strong> 状态而不是 <strong>RUNNING</strong> 状态，作业(Job)的整体状态也会显示为 <strong>RUNNING</strong>。</p>
<p>此时，Job 的任务(Task)不能从 <strong>SCHEDULED</strong> 状态转为 <strong>RUNNING</strong> 状态，因为没有资源(<strong>TaskManager</strong> 提供的 <strong>TaskSlots</strong>）来运行这些任务。在新的 TaskManager 可用之前，Job 将经历一个取消和重新提交的循环。</p>
<p>同时，数据生成器会不断地将 ClickEvents 推送到 <em>input</em> 主题中。这类似于真正的生产设置，在生产数据的同时，要处理数据的 Job 却宕机了。</p>
<p><strong>步骤3：恢复</strong></p>
<p>一旦你重新启动 TaskManager，它就会重新连接到 JobManager。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose up -d taskmanager
</code></pre></div><p>当 JobManager 被通知到新的 TaskManager 时，它将恢复中的 Job 的任务(tasks)调度到新的可用 TaskSlots。重新启动后，任务会从故障前最后一次成功的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">检查点</a>恢复其状态，并切换到 RUNNING 状态。</p>
<p>Job 将快速处理来自 Kafka 的全部积压输入事件(在故障期间积累的)，并以更高的速度(&gt;24条记录/分钟)产生输出，直到到达流的头部。在输出中，你会看到所有的键(页面)都存在于所有的时间窗口中，而且每个计数都是精确的 1000。由于我们是在&quot;至少一次&quot;模式下使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/kafka.html#kafka-producers-and-fault-tolerance">FlinkKafkaProducer</a>，所以你有可能会看到一些重复的输出记录。</p>
<p>注意：大多数生产设置依赖于资源管理器(Kubernetes、Yarn、Mesos)来自动重启失败的进程。</p>
<h5 id="升级和重新缩放作业">升级和重新缩放作业</h5>
<p>升级 Flink 作业总是涉及两个步骤。首先，用一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>优雅地停止 Flink Job。保存点是在一个明确定义的、全局一致的时间点(类似于检查点)上的完整应用状态的一致快照。其次，升级后的 Flink Job 从 Savepoint 开始。在这种情况下，&ldquo;升级&quot;可以意味着不同的事情，包括以下内容:</p>
<ul>
<li>配置的升级（包括作业的并行性）。</li>
<li>对 Job 的拓扑结构进行升级（增加/删除 Operator）。</li>
<li>对 Job 的用户定义的函数进行升级。</li>
</ul>
<p>在开始升级之前，你可能要开始 tailing <em>output</em> 主题，以观察在升级过程中没有数据丢失或损坏。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第一步：停止工作</strong></p>
<p>要优雅地停止作业，你需要使用 CLI 或 REST API 的 &ldquo;stop&rdquo; 命令。为此，你需要该作业的 JobID，你可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#listing-running-jobs">列出所有正在运行的 Job</a> 或从 WebUI 中获得。有了 JobID，你就可以继续停止该作业:</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink stop &lt;job-id&gt;
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Suspending job &quot;&lt;job-id&gt;&quot; with a savepoint.
Suspended job &quot;&lt;job-id&gt;&quot; with a savepoint.
</code></pre><p>Savepoint 已经被存储到 flink-conf.yaml 中配置的 state.savepoint.dir 中，它被安装在本地机器的 /tmp/flink-savepoints-directory/ 下。在下一步中，你将需要这个 Savepoint 的路径。在 REST API 的情况下，这个路径已经是响应的一部分，你将需要直接查看文件系统。</p>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ls -lia /tmp/flink-savepoints-directory
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">total <span class="m">0</span>
  <span class="m">17</span> drwxr-xr-x   <span class="m">3</span> root root   <span class="m">60</span> <span class="m">17</span> jul 17:05 .
   <span class="m">2</span> drwxrwxrwt <span class="m">135</span> root root <span class="m">3420</span> <span class="m">17</span> jul 17:09 ..
<span class="m">1002</span> drwxr-xr-x   <span class="m">2</span> root root  <span class="m">140</span> <span class="m">17</span> jul 17:05 savepoint-&lt;short-job-id&gt;-&lt;uuid&gt;
</code></pre></div><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># triggering stop</span>
curl -X POST localhost:8081/jobs/&lt;job-id&gt;/stop -d <span class="s1">&#39;{&#34;drain&#34;: false}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;request-id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;trigger-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># check status of stop action and retrieve savepoint path</span>
curl localhost:8081/jobs/&lt;job-id&gt;/savepoints/&lt;trigger-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;COMPLETED&#34;</span>
  <span class="p">},</span>
  <span class="nt">&#34;operation&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;location&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;savepoint-path&gt;&#34;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p><strong>步骤2a: 重启 Job，不做任何改变</strong></p>
<p>现在你可以从该保存点重新启动升级后的作业(Job)。为了简单起见，你可以在不做任何更改的情况下重新启动它。</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>一旦 Job 再次 RUNNING，你会在 <em>output</em> 主题中看到，当 Job 在处理中断期间积累的积压时，记录以较高的速度产生。此外，你会看到在升级过程中没有丢失任何数据：所有窗口都存在，数量正好是 1000。</p>
<p><strong>步骤2b: 用不同的并行度重新启动作业（重新缩放）</strong></p>
<p>另外，你也可以在重新提交时通过传递不同的并行性，从这个保存点重新缩放作业。</p>
<ul>
<li>CLI</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -p <span class="m">3</span> -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;parallelism&#34;: 3, &#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>现在，作业(Job)已经被重新提交，但它不会启动，因为没有足够的 TaskSlots 在增加的并行度下执行它（2个可用，需要3个）。使用:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose scale <span class="nv">taskmanager</span><span class="o">=</span><span class="m">2</span>
</code></pre></div><p>你可以在 Flink 集群中添加一个带有两个 TaskSlots 的第二个 TaskManager，它将自动注册到 JobManager 中。添加 TaskManager 后不久，该任务(Job)应该再次开始运行。</p>
<p>一旦 Job 再次 &ldquo;RUNNING&rdquo;，你会在 <em>output</em> Topic 中看到在重新缩放过程中没有丢失数据：所有的窗口都存在，计数正好是 1000。</p>
<h5 id="查询作业job的指标">查询作业(Job)的指标</h5>
<p>JobManager 通过其 REST API 公开系统和用户<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html">指标</a>。</p>
<p>端点取决于这些指标的范围。可以通过 <code>jobs/&lt;job-id&gt;/metrics</code> 来列出一个作业的范围内的度量。指标的实际值可以通过 get query 参数进行查询。</p>
<p><strong>请求</strong></p>
<pre><code class="language-shells" data-lang="shells">curl &quot;localhost:8081/jobs/&lt;jod-id&gt;/metrics?get=lastCheckpointSize&quot;
</code></pre><p><strong>预期的响应(美化了打印; 没有占位符)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
  <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;lastCheckpointSize&#34;</span><span class="p">,</span>
    <span class="nt">&#34;value&#34;</span><span class="p">:</span> <span class="s2">&#34;9378&#34;</span>
  <span class="p">}</span>
<span class="p">]</span>
</code></pre></div><p>REST API 不仅可以用来查询指标，还可以检索运行中的作业状态的详细信息。</p>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># find the vertex-id of the vertex of interest</span>
curl localhost:8081/jobs/&lt;jod-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
  <span class="nt">&#34;isStoppable&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&#34;state&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
  <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
  <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
  <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374793</span><span class="p">,</span>
  <span class="nt">&#34;now&#34;</span><span class="p">:</span> <span class="mi">1564467440819</span><span class="p">,</span>
  <span class="nt">&#34;timestamps&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SUSPENDED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELLING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">1564467066126</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RESTARTING&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">},</span>
  <span class="nt">&#34;vertices&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066423</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374396</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">},</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033461</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166351</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066441</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374378</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">},</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5066280</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033496</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066469</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374350</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">},</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5085332</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">316</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166305</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066476</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374343</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">},</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">20668</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">],</span>
  <span class="nt">&#34;status-counts&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">},</span>
  <span class="nt">&#34;plan&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
    <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
    <span class="nt">&#34;nodes&#34;</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">],</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{}</span>
      <span class="p">},</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;HASH&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">],</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{}</span>
      <span class="p">},</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">],</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{}</span>
      <span class="p">},</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{}</span>
      <span class="p">}</span>
    <span class="p">]</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>请查阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">REST API 参考资料</a>，了解可能查询的完整列表，包括如何查询不同作用域的指标（如 TaskManager 指标）。</p>
<h4 id="变体">变体</h4>
<p>你可能已经注意到，Click Event Count 应用程序总是以 <code>--checkpointing</code> 和 <code>--event-time</code> 程序参数启动。通过在 docker-compose.yaml 的客户端容器的命令中省略这些，你可以改变 Job 的行为。</p>
<ul>
<li>
<p><code>--checkpointing</code> 启用了 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">checkpoint</a>，这是 Flink 的容错机制。如果你在没有它的情况下运行，并通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#observing-failure--recovery">故障和恢复</a>，你应该会看到数据实际上已经丢失了。</p>
</li>
<li>
<p><code>--event-time</code> 启用了你的 Job 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间语义</a>。当禁用时，作业将根据挂钟时间而不是 ClickEvent 的时间戳将事件分配给窗口。因此，每个窗口的事件数量将不再是精确的 1000。</p>
</li>
</ul>
<p>Click Event Count 应用程序还有另一个选项，默认情况下是关闭的，你可以启用这个选项来探索这个作业在背压下的行为。你可以在 <code>docker-compose.yaml</code> 的客户端容器的命令中添加这个选项。</p>
<ul>
<li><code>--backpressure</code> 在作业中间增加了一个额外的 operator，在偶数分钟内会造成严重的背压（例如，在10:12期间，但在10:13期间不会）。这可以通过检查各种<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html#default-shuffle-service">网络指标</a>（如 outputQueueLength 和 outPoolUsage）和/或使用 WebUI 中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/back_pressure.html#monitoring-back-pressure">背压监控</a>来观察。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/playground" term="playground" label="Playground" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Python API 指南]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 操作游乐场" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Python API Tutorial</blockquote><h2 id="python-api-指南">Python API 指南</h2>
<p>本演练将快速让你开始构建一个纯 Python Flink 项目。</p>
<p>关于如何设置 Python 执行环境，请参考 Python Table API <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html">安装指南</a>。</p>
<h3 id="设置一个-python-项目">设置一个 Python 项目</h3>
<p>您可以先创建一个 Python 项目，然后按照<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html#installation-of-pyflink">安装指南</a>安装 PyFlink 包。</p>
<h3 id="编写一个-flink-python-table-api-程序">编写一个 Flink Python Table API 程序</h3>
<p>Table API 应用程序通过声明一个表环境开始；对于批处理应用程序，可以是 BatchTableEvironment，对于流式应用程序，可以是 StreamTableEnvironment。这作为与 Flink 运行时交互的主要入口点。它可以用来设置执行参数，如重启策略、默认并行度等。表配置允许设置 Table API 的具体配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">()</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>
</code></pre></div><p>在创建的表环境中，可以声明 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">()</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="s1">&#39;/tmp/input&#39;</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s1">&#39;mySource&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">()</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="s1">&#39;/tmp/output&#39;</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">())</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">())</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s1">&#39;mySink&#39;</span><span class="p">)</span>
</code></pre></div><p>你也可以使用 <code>TableEnvironment.sql_update()</code> 方法来注册 DDL 中定义的 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">my_source_ddl</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    create table mySource (
</span><span class="s2">        word VARCHAR
</span><span class="s2">    ) with (
</span><span class="s2">        &#39;connector.type&#39; = &#39;filesystem&#39;,
</span><span class="s2">        &#39;format.type&#39; = &#39;csv&#39;,
</span><span class="s2">        &#39;connector.path&#39; = &#39;/tmp/input&#39;
</span><span class="s2">    )
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">my_sink_ddl</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    create table mySink (
</span><span class="s2">        word VARCHAR,
</span><span class="s2">        `count` BIGINT
</span><span class="s2">    ) with (
</span><span class="s2">        &#39;connector.type&#39; = &#39;filesystem&#39;,
</span><span class="s2">        &#39;format.type&#39; = &#39;csv&#39;,
</span><span class="s2">        &#39;connector.path&#39; = &#39;/tmp/output&#39;
</span><span class="s2">    )
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_source_ddl</span><span class="p">)</span>
<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_sink_ddl</span><span class="p">)</span>
</code></pre></div><p>这将在执行环境中注册一个名为 <strong>mySource</strong> 的表和一个名为 <strong>mySink</strong> 的表。表 <strong>mySource</strong> 只有一列，即 <strong>word</strong>，它消耗从文件 <code>/tmp/input</code> 中读取的字符串。表 <strong>mySink</strong> 有两列，分别是 <strong>word</strong> 和 <strong>count</strong>，将数据写入文件 <code>/tmp/output</code>，用 <code>/t</code> 作为字段分隔符。</p>
<p>现在，你可以创建一个作业(job)，它从表 <strong>mySource</strong> 中读取输入，预先执行一些转换，并将结果写入表 <strong>mySink</strong>。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="s1">&#39;mySource&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;word, count(1)&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="s1">&#39;mySink&#39;</span><span class="p">)</span>
</code></pre></div><p>最后你必须执行实际的 Flink Python Table API 作业。所有的操作，如创建源、转换和 sink 都是懒惰的。只有当 <code>t_env.execute(job_name)</code> 被调用时，作业才会被运行。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&#34;tutorial_job&#34;</span><span class="p">)</span>
</code></pre></div><p>到目前为止，完整的代码如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyflink.dataset</span> <span class="kn">import</span> <span class="n">ExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">TableConfig</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">,</span> <span class="n">BatchTableEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table.descriptors</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">OldCsv</span><span class="p">,</span> <span class="n">FileSystem</span>

<span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">()</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">()</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="s1">&#39;/tmp/input&#39;</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s1">&#39;mySource&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">()</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="s1">&#39;/tmp/output&#39;</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">())</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">())</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">()))</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="s1">&#39;mySink&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="s1">&#39;mySource&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="s1">&#39;word&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;word, count(1)&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="s1">&#39;mySink&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&#34;tutorial_job&#34;</span><span class="p">)</span>
</code></pre></div><h3 id="执行-flink-python-table-api-程序">执行 Flink Python Table API 程序</h3>
<p>首先，你需要在 &ldquo;/tmp/input&rdquo; 文件中准备输入数据。你可以选择以下命令行来准备输入数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">echo</span> -e  <span class="s2">&#34;flink\npyflink\nflink&#34;</span> &gt; /tmp/input
</code></pre></div><p>接下来，你可以在命令行上运行这个例子（注意：如果结果文件 &ldquo;/tmp/output&rdquo; 已经存在，你需要在运行这个例子之前删除该文件）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ python WordCount.py
</code></pre></div><p>该命令在本地小型集群中构建并运行 Python Table API 程序。你也可以将 Python Table API 程序提交到远程集群，详情可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html#job-submission-examples">Job Submission Examples</a>。</p>
<p>最后，您可以在命令行中看到执行结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ cat /tmp/output
flink	<span class="m">2</span>
pyflink	<span class="m">1</span>
</code></pre></div><p>这应该可以让你开始编写自己的 Flink Python Table API 程序。要了解更多关于 Python Table API 的信息，你可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/python">Flink Python Table API Docs</a> 了解更多细节。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/python" term="python" label="Python" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Connectors]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-07T00:00:00+08:00</published>
            <updated>2020-08-07T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>连接器</blockquote><h1 id="apache-kafka-connector">Apache Kafka Connector</h1>
<h2 id="kafka-consumer">Kafka Consumer</h2>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;localhost:9092&#34;</span><span class="o">)</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;test&#34;</span><span class="o">)</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&#34;topic&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">))</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/connector" term="connector" label="Connector" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Julia 中的 模块]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-05-modules-in-julia/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-04-pkg-in-julia/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 中的 Pkg" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-04-dates-in-julia/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 中的日期和时间" />
                <link href="https://ohmyweekly.github.io/notes/2020-07-27-learning-julialang/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 语言学习笔记" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-05-modules-in-julia/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-05T00:00:00+08:00</published>
            <updated>2020-08-05T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Modules</blockquote><h1 id="模块">模块</h1>
<p>Julia 中的模块是独立的变量工作空间，即它们引入了一个新的全局作用域。它们在语法上是有分界的，在 <code>module Name ... end</code> 里面。模块允许您创建顶层定义（也就是全局变量），而不用担心您的代码与别人的代码一起使用时的名称冲突。在一个模块中，你可以控制哪些来自其他模块的名字是可见的（通过导入），并指定哪些名字是要公开的（通过导出）。</p>
<p>下面的例子展示了模块的主要功能。这个例子并不是为了运行，而是为了说明问题。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">module</span> <span class="n">MyModule</span>
<span class="k">using</span> <span class="n">Lib</span>

<span class="k">using</span> <span class="n">BigLib</span><span class="o">:</span> <span class="n">thing1</span><span class="p">,</span> <span class="n">thing2</span>

<span class="k">import</span> <span class="n">Base</span><span class="o">.</span><span class="n">show</span>

<span class="k">export</span> <span class="n">MyType</span><span class="p">,</span> <span class="n">foo</span>

<span class="k">struct</span> <span class="n">MyType</span>
    <span class="n">x</span>
<span class="k">end</span>

<span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span><span class="n">x</span>
<span class="n">foo</span><span class="p">(</span><span class="n">a</span><span class="o">::</span><span class="n">MyType</span><span class="p">)</span> <span class="o">=</span> <span class="n">bar</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">show</span><span class="p">(</span><span class="n">io</span><span class="o">::</span><span class="kt">IO</span><span class="p">,</span> <span class="n">a</span><span class="o">::</span><span class="n">MyType</span><span class="p">)</span> <span class="o">=</span> <span class="n">print</span><span class="p">(</span><span class="n">io</span><span class="p">,</span> <span class="s">&#34;MyType </span><span class="si">$</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">x</span><span class="p">)</span><span class="s">&#34;</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><p>需要注意的是，这个样式并不是要在模块的正文中缩进，因为这通常会导致整个文件被缩进。</p>
<p>这个模块定义了一个 <code>MyType</code> 类型和两个函数。函数 <code>foo</code> 和 <code>MyType</code> 类型是导出的，因此可以导入到其他模块中。函数 <code>bar</code> 是 <code>MyModule</code> 的私有函数。</p>
<p><code>using Lib</code> 语句意味着将有一个名为 <code>Lib</code> 的模块可以根据需要解析名称。当遇到一个全局变量在当前模块中没有定义时，系统会在 <code>Lib</code> 导出的变量中搜索它，如果在那里找到了，就会导入它。这意味着在当前模块内对该全局的所有使用都将解析为该变量在 <code>Lib</code> 中的定义。</p>
<p><code>using BigLib: thing1, thing2</code> 语句，只将标识符 <code>thing1</code> 和 <code>thing2</code> 从模块 <code>BigLib</code> 中带入作用域。如果这些名称指的是函数，那么将不允许向它们添加方法（你只能 &ldquo;使用 &ldquo;它们，而不是扩展它们）。</p>
<p><code>import</code> 关键字支持与 <code>using</code> 相同的语法。<code>import</code> 与 <code>using</code> 的不同之处在于，使用 <code>import</code> 导入的函数可以用新的方法进行扩展。</p>
<p>在上面的 <code>MyModule</code> 中，我们想给标准的 <code>show</code> 函数添加一个方法，所以我们必须写 <code>import Base.show</code>。只有通过 <code>using</code> 才能看到名字的函数不能被扩展。</p>
<p>一旦一个变量通过 <code>using</code> 或 <code>import</code> 变得可见，一个模块就不能创建自己的同名变量。导入的变量是只读的，分配给全局变量总是会影响到当前模块所拥有的变量，否则会引发错误。</p>
<h2 id="模块使用情况概述">模块使用情况概述</h2>
<p>要加载一个模块，可以使用两个主要的关键词：<code>using</code> 和 <code>import</code>。要了解它们的区别，请看下面的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">module</span> <span class="n">MyModule</span>

<span class="k">export</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="n">x</span><span class="p">()</span> <span class="o">=</span> <span class="s">&#34;x&#34;</span>
<span class="n">y</span><span class="p">()</span> <span class="o">=</span> <span class="s">&#34;y&#34;</span>
<span class="n">p</span><span class="p">()</span> <span class="o">=</span> <span class="s">&#34;p&#34;</span>

<span class="k">end</span>
</code></pre></div><p>在这个模块中，我们导出了 <code>x</code> 和 <code>y</code> 函数(用关键字 <code>export</code>)，也有非导出的函数 <code>p</code>，有几种不同的方法可以将 <code>Module</code> 及其内部函数加载到当前的工作空间中。</p>
<table>
<thead>
<tr>
<th style="text-align:left">导入命令</th>
<th style="text-align:left">带入带作用域中的东西</th>
<th style="text-align:left">可用于方法扩展</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>using MyModule</code></td>
<td style="text-align:left">所有导出的名字(<code>x</code> 和 <code>y</code>), <code>MyModule.x</code>, <code>MyModule.y</code> 和 <code>MyModule.p</code></td>
<td style="text-align:left"><code>MyModule.x</code>, <code>MyModule.y</code> 和 <code>MyModule.p</code></td>
</tr>
<tr>
<td style="text-align:left"><code>using MyModule: x, p</code></td>
<td style="text-align:left"><code>x</code> 和 <code>p</code></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"><code>import MyModule</code></td>
<td style="text-align:left"><code>MyModule.x</code>, <code>MyModule.y</code> 和 <code>MyModule.p</code></td>
<td style="text-align:left"><code>MyModule.x</code>, <code>MyModule.y</code> 和 <code>MyModule.p</code></td>
</tr>
<tr>
<td style="text-align:left"><code>import MyModule.x, MyModule.p</code></td>
<td style="text-align:left"><code>x</code> 和 <code>p</code></td>
<td style="text-align:left"><code>x</code> 和 <code>p</code></td>
</tr>
<tr>
<td style="text-align:left"><code>import MyModule: x, p</code></td>
<td style="text-align:left"><code>x</code> 和 <code>p</code></td>
<td style="text-align:left"><code>x</code> 和 <code>p</code></td>
</tr>
</tbody>
</table>
<h2 id="模块和文件">模块和文件</h2>
<p>文件和文件名大多与模块无关，模块只与模块表达式有关。一个模块可以有多个文件，一个文件可以有多个模块。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">module</span> <span class="n">Foo</span>

<span class="n">include</span><span class="p">(</span><span class="s">&#34;file1.jl&#34;</span><span class="p">)</span>
<span class="n">include</span><span class="p">(</span><span class="s">&#34;file2.jl&#34;</span><span class="p">)</span>

<span class="k">end</span>
</code></pre></div><p>在不同的模块中包含相同的代码，提供了类似 mixin 的行为。人们可以使用这一点来用不同的基础定义来运行相同的代码，例如，通过使用某些操作符的&quot;安全&quot;版本来测试代码。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">module</span> <span class="n">Normal</span>
<span class="n">include</span><span class="p">(</span><span class="s">&#34;mycode.jl&#34;</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">module</span> <span class="n">Testing</span>
<span class="n">include</span><span class="p">(</span><span class="s">&#34;safe_operators.jl&#34;</span><span class="p">)</span>
<span class="n">include</span><span class="p">(</span><span class="s">&#34;mycode.jl&#34;</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><h2 id="标准模块">标准模块</h2>
<p>There are three important standard modules:</p>
<p><a href="https://docs.julialang.org/en/v1/base/base/#Core">Core</a> 包含&quot;内置于&quot;语言中的所有功能。
<a href="https://docs.julialang.org/en/v1/base/base/#Base">Base</a> 包含几乎在所有情况下都有用的基本功能。
<a href="https://docs.julialang.org/en/v1/base/base/#Main">Main</a> 是当 Julia 被启动时的顶级模块和当前模块。</p>
<h2 id="默认的顶层定义和裸模块">默认的顶层定义和裸模块</h2>
<p>除了 <code>using Base</code> 之外，模块还自动包含 <a href="https://docs.julialang.org/en/v1/base/base/#Base.MainInclude.eval">eval</a>和 <a href="https://docs.julialang.org/en/v1/base/base/#Base.MainInclude.include">include</a> 函数的定义，这些函数在该模块的全局作用域内评估表达式/文件。</p>
<p>如果不想要这些默认的定义，可以使用关键字 <a href="https://docs.julialang.org/en/v1/base/base/#baremodule">baremodule</a> 来代替定义模块（注意： <code>Core</code> 仍然是导入的，如上所述）。以 <code>baremodule</code> 来说，一个标准的模块是这样的。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">baremodule</span> <span class="n">Mod</span>

<span class="k">using</span> <span class="n">Base</span>

<span class="n">eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">Core</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">Mod</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">include</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">include</span><span class="p">(</span><span class="n">Mod</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="o">...</span>

<span class="k">end</span>
</code></pre></div><h2 id="相对和绝对模块路径">相对和绝对模块路径</h2>
<p>给定 <code>using Foo</code> 语句，系统会查询内部的顶层模块表，寻找一个名为 <code>Foo</code> 的模块。如果该模块不存在，系统会尝试 <code>require(:Foo)</code>，这通常会导致从安装的包中加载代码。</p>
<p>然而，有些模块包含子模块，这意味着你有时需要访问一个非顶层模块。有两种方法可以做到这一点。第一种是使用绝对路径，例如 <code>using Base.Sort</code>。第二种是使用相对路径，这样可以更容易地导入当前模块的子模块或其任何一个外层模块。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">module</span> <span class="n">Parent</span>

<span class="k">module</span> <span class="n">Utils</span>
<span class="o">...</span>
<span class="k">end</span>

<span class="k">using</span> <span class="o">.</span><span class="n">Utils</span>

<span class="o">...</span>
<span class="k">end</span>
</code></pre></div><p>这里模块 <code>Parent</code> 包含一个子模块 <code>Utils</code>，<code>Parent</code> 中的代码希望 <code>Utils</code> 的内容可见。这可以通过在 <code>using</code> 路径中使用点号来实现。添加更多的前导点号会使模块的层次结构上升。例如，<code>using ..Utils</code> 会在 <code>Parent</code> 的外层模块中查找<code>Utils</code>，而不是在 <code>Parent</code> 本身中查找。</p>
<p>注意相对导入限定符只在使用和导入语句中有效。</p>
<h2 id="命名空间杂项">命名空间杂项</h2>
<p>如果一个名字是限定的(例如 <code>Base.sin</code>)，那么即使它没有被导出，也可以被访问。这在调试时往往很有用。它也可以通过使用限定名作为函数名来添加方法。但是，由于会产生语法上的歧义，如果你想给不同模块中的一个函数添加方法，而这个函数的名称只包含符号，例如一个运算符，<code>Base.+</code>，你必须使用 <code>Base.:+</code> 来引用它。如果运算符的长度超过一个字符，你必须用括号把它括起来，比如 <code>Base.:(==)</code>。</p>
<p>在导入和导出语句中，宏的名称用 <code>@</code> 书写，例如 <code>import Mod.@mac</code>。其他模块中的宏可以用 <code>Mod.@mac</code> 或 <code>@Mod.mac</code> 来调用。</p>
<p>语法 <code>M.x = y</code> 不能用于分配其他模块中的全局，全局分配总是模块-局部的。</p>
<p>变量名可以通过声明为 <code>global x</code> 来 &ldquo;保留&quot;而不分配给它，这样可以防止加载后初始化的 globals 的名称冲突。</p>
<h2 id="模块初始化和预编译">模块初始化和预编译</h2>
<p>大型模块可能需要几秒钟的时间来加载，因为执行一个模块中的所有语句往往需要编译大量的代码。Julia 创建了模块的预编译缓存来减少这个时间。</p>
<p>当使用 <code>import</code> 或 <code>using</code> 加载模块时，会自动创建并使用增量的预编译模块文件。这将导致它在第一次导入时自动编译。另外，您也可以手动调用 <a href="https://docs.julialang.org/en/v1/base/base/#Base.compilecache">Base.compilecache(modulename)</a>。由此产生的缓存文件将存储在 <code>DEPOT_PATH[1]/compiled/</code> 中。随后，只要模块的任何依赖关系发生变化，模块就会在 <code>using</code> 或 <code>import</code> 时自动重新编译；依赖关系是指导入的模块、Julia 构建的模块、包含的文件，或者模块文件中 <a href="https://docs.julialang.org/en/v1/base/base/#Base.include_dependency">include_dependency(path)</a> 声明的显式依赖关系。</p>
<p>对于文件依赖，通过检查由 <code>include</code> 加载的文件或由 <code>include_dependency</code> 显式添加的文件的修改时间(mtime)是否保持不变，或者是否等于被截断到最接近秒的修改时间(以适应无法以亚秒级精度复制 mtime 的系统)来确定变化。它还考虑到在 <code>require</code> 中搜索逻辑选择的文件路径是否与创建预编译文件的路径匹配。它还会考虑到已经加载到当前进程中的一组依赖关系，即使这些模块的文件发生变化或消失，也不会重新编译这些模块，以避免在运行系统和预编译缓存之间产生不兼容的情况。</p>
<p>如果你知道某个模块预编译你的模块是不安全的（例如，出于下面描述的原因之一），你应该在模块文件中加上 <code>__precompile__(false)</code>（通常放在顶部）。这将导致 <code>Base.compilecache</code> 抛出一个错误，并将导致 <code>using</code> / <code>import</code> 直接将其加载到当前进程中而跳过预编译和缓存。这也因此阻止了该模块被任何其他预编译模块导入。</p>
<p>您可能需要注意创建增量共享库时固有的某些行为，在编写模块时可能需要注意。例如，外部状态不会被保存。为了适应这一点，明确地将任何必须在运行时发生的初始化步骤与可以在编译时发生的步骤分开。为此，Julia 允许您在您的模块中定义一个 <code>__init__()</code> 函数来执行任何必须在运行时发生的初始化步骤。这个函数在编译时不会被调用（<code>--output-*</code>）。实际上，你可以假设它在代码的生命周期中只运行一次。当然，如果有必要的话，你可以手动调用它，但是默认情况下，你可以假设这个函数处理的是本地机器的计算状态，它不需要&ndash;甚至不应该&ndash;在编译后的镜像中捕获。它将在模块被加载到一个进程后被调用，包括如果它被加载到增量编译中(<code>--output-incremental=yes</code>)，但如果它被加载到一个完整的编译进程中，则不会被调用。</p>
<p>特别是，如果你在一个模块中定义了一个 <code>function __init__()</code>，那么 Julia 将在模块被加载后（例如通过 <code>import</code>、<code>using</code> 或 <code>require</code>）在运行时第一次立即调用 <code>__init__()</code>（也就是说，<code>__init__</code> 只被调用一次，而且是在模块中的所有语句被执行后才被调用）。因为它是在模块完全导入之后被调用的，所以任何子模块或其它导入的模块都会在外层模块的 <code>__init__</code> 之前调用它们的 <code>__init__</code> 函数。</p>
<p><code>__init__</code> 的两个典型用途是调用外部 C 库的运行时初始化函数和初始化涉及外部库返回指针的全局常量。例如，假设我们正在调用一个 C 库 <code>libfoo</code>，它要求我们在运行时调用 <code>foo_init()</code> 初始化函数。假设我们还想定义一个全局常量 <code>foo_data_ptr</code>，用来存放 <code>libfoo</code> 定义的 <code>void *foo_data()</code> 函数的返回值&ndash;这个常量必须在运行时（而不是在编译时）初始化，因为指针地址会随着运行而改变。你可以通过在你的模块中定义下面的 <code>__init__</code> 函数来实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="kd">const</span> <span class="n">foo_data_ptr</span> <span class="o">=</span> <span class="kt">Ref</span><span class="p">{</span><span class="kt">Ptr</span><span class="p">{</span><span class="n">Cvoid</span><span class="p">}}(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">function</span> <span class="n">__init__</span><span class="p">()</span>
    <span class="k">ccall</span><span class="p">((</span><span class="o">:</span><span class="n">foo_init</span><span class="p">,</span> <span class="o">:</span><span class="n">libfoo</span><span class="p">),</span> <span class="n">Cvoid</span><span class="p">,</span> <span class="p">())</span>
    <span class="n">foo_data_ptr</span><span class="p">[]</span> <span class="o">=</span> <span class="k">ccall</span><span class="p">((</span><span class="o">:</span><span class="n">foo_data</span><span class="p">,</span> <span class="o">:</span><span class="n">libfoo</span><span class="p">),</span> <span class="kt">Ptr</span><span class="p">{</span><span class="n">Cvoid</span><span class="p">},</span> <span class="p">())</span>
    <span class="nb">nothing</span>
<span class="k">end</span>
</code></pre></div><p>请注意，我们完全可以在函数内部定义一个全局，比如 <code>__init__</code>；这是使用动态语言的优势之一。但是通过在全局作用域内定义一个常量，我们可以确保编译器知道这个类型，并允许它生成更好的优化代码。显然，你的模块中任何其他依赖于 <code>foo_data_ptr</code> 的 globals 也必须在 <code>__init__</code> 中初始化。</p>
<p>涉及大多数不是由 <a href="https://docs.julialang.org/en/v1/base/c/#ccall">ccall</a> 产生的 Julia 对象的常量不需要放在 <code>__init__</code> 中：它们的定义可以被预编译并从缓存的模块映像中加载。这包括像数组这样复杂的堆分配对象。然而，任何返回原始指针值的例程都必须在运行时调用，以便预编译工作（<a href="https://docs.julialang.org/en/v1/base/c/#Core.Ptr">Ptr</a> 对象将变成空指针，除非它们被隐藏在 <a href="https://docs.julialang.org/en/v1/base/base/#Base.isbits">isbits</a> 对象中）。这包括 Julia 函数 <code>cfunction</code> 和 <a href="https://docs.julialang.org/en/v1/base/c/#Base.pointer">pointer</a> 的返回值。</p>
<p>字典和集合类型，或者一般来说任何依赖于 <code>hash(key)</code> 方法输出的东西，都是比较棘手的情况。在常见的情况下，键是数字、字符串、符号、范围、<code>Expr</code> 或这些类型的组合（通过数组、元组、集合、对等），它们可以安全地进行预编译。然而，对于其他一些关键类型，如 <code>Function</code> 或 <code>DataType</code> 和通用的用户定义类型，在这些类型中，你没有定义 <code>hash</code> 方法，回退 <code>hash</code> 方法取决于对象的内存地址（通过它的 <code>objectid</code>），因此可能会在运行时改变。如果你有这些键类型之一，或者如果你不确定，为了安全起见，你可以在你的 <code>__init__</code> 函数中初始化这个字典。或者，你也可以使用 <a href="https://docs.julialang.org/en/v1/base/collections/#Base.IdDict">IdDict</a> 字典类型，它由预编译特别处理，所以在编译时初始化是安全的。</p>
<p>在使用预编译时，保持对编译阶段和执行阶段的清晰认识很重要。在这种模式下，往往会更清楚地认识到 Julia 是一个允许执行任意 Julia 代码的编译器，而不是一个同时生成编译代码的独立解释器。</p>
<p>其他已知的潜在故障情况包括。</p>
<ol>
<li>全局计数器（例如，用于试图唯一识别对象）。考虑以下代码片段。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">mutable</span> <span class="k">struct</span> <span class="n">UniquedById</span>
    <span class="n">myid</span><span class="o">::</span><span class="kt">Int</span>
    <span class="k">let</span> <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">UniquedById</span><span class="p">()</span> <span class="o">=</span> <span class="n">new</span><span class="p">(</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div><p>虽然这段代码的目的是给每个实例一个唯一的 id，但计数器的值是在编译结束时记录的。这个增量编译模块的所有后续使用将从同一个计数器值开始。</p>
<p>请注意，<code>objectid</code>（通过哈希内存指针工作）也有类似的问题（参见下面关于 <code>Dict</code> 用法的说明）。</p>
<p>一种替代方法是使用宏来捕获 <a href="https://docs.julialang.org/en/v1/base/base/#Base.@__MODULE__">@<strong>MODULE</strong></a>，并将其与当前的计数器值一起单独存储，然而，重新设计代码使其不依赖于这个全局状态可能会更好。</p>
<ol start="2">
<li>
<p>关联集合(比如 <code>Dict</code> 和 <code>Set</code>)需要在 <code>__init__</code> 中重新洗牌(将来可能会提供一个机制来注册一个初始化函数)。</p>
</li>
<li>
<p>根据编译时的副作用在加载时持续存在。例如：修改其他 Julia 模块中的数组或其他变量；维护打开的文件或设备的句柄；存储其他系统资源（包括内存）的指针。</p>
</li>
<li>
<p>通过直接引用而不是通过它的查找路径，从另一个模块创建意外的全局状态&quot;副本&rdquo;。例如，（在全局作用域内）。</p>
</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="c">#mystdout = Base.stdout #= will not work correctly, since this will copy Base.stdout into this module =#</span>
<span class="c"># instead use accessor functions:</span>
<span class="n">getstdout</span><span class="p">()</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">stdout</span> <span class="cm">#= best option =#</span>
<span class="c"># or move the assignment into the runtime:</span>
<span class="n">__init__</span><span class="p">()</span> <span class="o">=</span> <span class="kd">global</span> <span class="n">mystdout</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">stdout</span> <span class="cm">#= also works =#</span>
</code></pre></div><p>对预编译代码时可以进行的操作进行了一些额外的限制，以帮助用户避免其他错误行为的情况。</p>
<ol>
<li>
<p>调用 <a href="https://docs.julialang.org/en/v1/base/base/#Base.MainInclude.eval">eval</a> 引起另一个模块的副作用。当增量预编译标志被设置时，这也会导致发出警告。</p>
</li>
<li>
<p>在 <code>__init__()</code> 被启动后，从本地作用域调用 <code>global const</code> 语句(参见问题 <code>#12010</code>，计划为此增加一个错误)</p>
</li>
<li>
<p>在进行增量预编译时，替换一个模块是一个运行时错误。</p>
</li>
</ol>
<p>还有几点需要注意。</p>
<ol>
<li>
<p>在对源文件本身进行修改之后，不会进行代码重载/缓存无效化（包括通过 <code>Pkg.update</code>），而且在 <code>Pkg.rm</code> 之后也不会进行清理。</p>
</li>
<li>
<p>预编译不考虑重塑数组的内存共享行为 (每个视图都有自己的副本)</p>
</li>
<li>
<p>期待文件系统在编译时和运行时之间保持不变，例如 <a href="https://docs.julialang.org/en/v1/base/file/#Base.@__FILE__">@<strong>FILE</strong></a>/<code>source_path()</code> 在运行时查找资源，或者 BinDeps 的 <code>@checked_lib</code> 宏。有时这是不可避免的。然而，在可能的情况下，在编译时将资源复制到模块中是一个很好的做法，这样它们就不需要在运行时被找到。</p>
</li>
<li>
<p><code>WeakRef</code> 对象和 finalizers 目前还没有被序列化器正确处理（这将在即将发布的版本中得到修正）。</p>
</li>
<li>
<p>通常最好避免捕获对内部元数据对象实例的引用，如 <code>Method</code>、<code>MethodInstance</code>、<code>MethodTable</code>、<code>TypeMapLevel</code>、<code>TypeMapEntry</code> 以及这些对象的字段，因为这可能会混淆序列化器，可能不会导致你想要的结果。这样做不一定会出错，但你只需要做好准备，系统会尝试复制其中的一些对象，并为其他对象创建一个唯一的实例。</p>
</li>
</ol>
<p>在模块开发过程中，有时关闭增量预编译是很有帮助的。命令行标志 <code>--compiled-modules={yes|no}</code> 可以让你开启或关闭模块预编译。当 Julia 以 <code>--compiled-modules=no</code> 启动时，当加载模块和模块依赖时，编译缓存中的序列化模块会被忽略。<code>Base.compilecache</code> 仍然可以被手动调用。这个命令行标志的状态被传递给 <code>Pkg.build</code>，以便在安装、更新和显式构建包时禁用自动预编译触发。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia" term="julia" label="julia" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/module" term="module" label="module" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Julia 中的 Pkg]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-04-pkg-in-julia/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-04-dates-in-julia/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 中的日期和时间" />
                <link href="https://ohmyweekly.github.io/notes/2020-07-27-learning-julialang/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 语言学习笔记" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-04-pkg-in-julia/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-04T00:00:00+08:00</published>
            <updated>2020-08-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Pkg</blockquote><h2 id="进入-pkg-模式">进入 Pkg 模式</h2>
<p>Pkg 是 Julia 中包管理工具。Pkg 来自于 REPL, 在 Julia 的 REPL 中按下 <code>]</code> 就进入 Pkg REPL 了。要回到 Julia REPL, 按退格键或 <code>^C</code>。</p>
<h2 id="使用-pkg">使用 Pkg</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">add JSON              <span class="c1"># 添加一个 package</span>
add JSON StaticArrays <span class="c1"># 添加多个 package</span>
rm JSON               <span class="c1"># 移除一个 package</span>
rm JSON StaticArrays  <span class="c1"># 移除多个 package</span>
add https://github.com/JuliaLang/Example.jl <span class="c1"># 添加一个未注册的 package</span>
rm Example            <span class="c1"># 按名字移除 package</span>
update Example        <span class="c1"># 升级一个已安装的 package</span>
update                <span class="c1"># 升级所有已安装的 package</span>
</code></pre></div><h2 id="environments">environments</h2>
<p>你可能已经注意到 Pkg REPL 提示符前面的 <code>(@v1.5)</code> 字符串了。这里的  <code>(@v1.5)</code> 就是激活环境(<strong>active environment</strong>)。激活环境是能被诸如 <code>add</code>、<code>rm</code> 和 <code>update</code> 等 Pkg 命令修改的环境。</p>
<p>我们可以设置一个新的激活环境用于实验。要设置激活环境, 使用 <code>activate</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>@v1.5<span class="o">)</span> pkg&gt; activate tutorial
Activating new environment at <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span>
</code></pre></div><p><code>~/tutorial/Project.toml</code> 是激活环境的项目文件。项目文件是 Pkg 存储环境的元数据的地方。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; status
Status <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span> <span class="o">(</span>empty project<span class="o">)</span>
</code></pre></div><p>现在这个新的环境是空的, 我们添加一个 package 观察下:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; add Example
   Updating registry at <span class="sb">`</span>~/.julia/registries/General<span class="sb">`</span>
   Updating git-repo <span class="sb">`</span>https://github.com/JuliaRegistries/General.git<span class="sb">`</span>
  Resolving package versions...
    Cloning <span class="o">[</span>7876af07-990d-54b4-ab0e-23690620f79a<span class="o">]</span> Example from https://github.com/JuliaLang/Example.jl.git
  Installed Example ─ v0.5.3
Updating <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> + Example v0.5.3
Updating <span class="sb">`</span>~/tutorial/Manifest.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> + Example v0.5.3
</code></pre></div><p>用 <code>status</code> 命令查看激活环境的信息:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; status
Status <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> Example v0.5.3
</code></pre></div><p>使用 <code>develop</code> 命令设置 <code>Example</code> package 的 一个 <code>git clone</code>, 以供我们修改这个本地仓库:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; develop --local Example
    Cloning git-repo <span class="sb">`</span>https://github.com/JuliaLang/Example.jl.git<span class="sb">`</span>
  Resolving package versions...
Updating <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> ~ Example v0.5.3 ⇒ v0.5.4 <span class="sb">`</span>dev/Example<span class="sb">`</span>
Updating <span class="sb">`</span>~/tutorial/Manifest.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> ~ Example v0.5.3 ⇒ v0.5.4 <span class="sb">`</span>dev/Example<span class="sb">`</span>
</code></pre></div><p>用 <code>;</code> 切换到 shell 模式, 用 vi 修改 <code>~/tutorial/dev/Example/src/Example.jl</code> 文件, 增加一个 <code>plusone</code> 函数, 保存。</p>
<p>在 Julia 的 REPL 中, 导入修改后的 <code>Example</code> package:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; import Example
<span class="o">[</span> Info: Precompiling Example <span class="o">[</span>7876af07-990d-54b4-ab0e-23690620f79a<span class="o">]</span>

julia&gt; Example.plusone<span class="o">(</span>1<span class="o">)</span>
<span class="m">2</span>

julia&gt; Example.plusone<span class="o">(</span>4<span class="o">)</span>
<span class="m">5</span>
</code></pre></div><p>可以看到我们添加的函数生效了, 这样就很方便我们添加测试新功能。如果我们已经不再需要本地的 <code>Example</code> 了, 需要使用 <code>free</code> 命令以停止使用本地克隆的 package, 转而使用已注册版本代替:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; free Example
  Resolving package versions...
Updating <span class="sb">`</span>~/tutorial/Project.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> ~ Example v0.5.4 <span class="sb">`</span>dev/Example<span class="sb">`</span> ⇒ v0.5.3
Updating <span class="sb">`</span>~/tutorial/Manifest.toml<span class="sb">`</span>
  <span class="o">[</span>7876af07<span class="o">]</span> ~ Example v0.5.4 <span class="sb">`</span>dev/Example<span class="sb">`</span> ⇒ v0.5.3
</code></pre></div><p>如果已经用 <code>tutorial</code> 做完实验了, 可以使用不带参数的 <code>activate</code> 回到默认环境:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>tutorial<span class="o">)</span> pkg&gt; activate
 Activating environment at <span class="sb">`</span>~/.julia/environments/v1.5/Project.toml<span class="sb">`</span>

<span class="o">(</span>@v1.5<span class="o">)</span> pkg&gt; 
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia" term="julia" label="julia" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/pkg" term="pkg" label="pkg" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Julia 中的日期和时间]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-04-dates-in-julia/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-04-pkg-in-julia/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 中的 Pkg" />
                <link href="https://ohmyweekly.github.io/notes/2020-07-27-learning-julialang/?utm_source=atom_feed" rel="related" type="text/html" title="Julia 语言学习笔记" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-04-dates-in-julia/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-04T00:00:00+08:00</published>
            <updated>2020-08-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Dates in Julia</blockquote><h1 id="dates-模块的加载和使用">Dates 模块的加载和使用</h1>
<p>在 Julia 的 Pkg REPL 中, 输入 <code>add Dates</code> 添加 Dates 模块。回到 Julia 的 REPL 中, 输入:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; using Dates

julia&gt; DateTime<span class="o">(</span>2020<span class="o">)</span>
2020-01-01T00:00:00

julia&gt; typeof<span class="o">(</span>DateTime<span class="o">(</span>2020<span class="o">))</span>
DateTime

julia&gt; DateTime<span class="o">(</span>2020,8,1<span class="o">)</span>
2020-08-01T00:00:00

julia&gt; DateTime<span class="o">(</span>2020,8,1,12<span class="o">)</span>
2020-08-01T12:00:00

julia&gt; DateTime<span class="o">(</span>2020,8,1,12,30<span class="o">)</span>
2020-08-01T12:30:00

julia&gt; DateTime<span class="o">(</span>2020,8,1,12,30,59<span class="o">)</span>
2020-08-01T12:30:59

julia&gt; DateTime<span class="o">(</span>2020,8,1,12,30,59, 999<span class="o">)</span>
2020-08-01T12:30:59.999

julia&gt; Date<span class="o">(</span>2020, 8<span class="o">)</span>
2020-08-01

julia&gt; Date<span class="o">(</span>2020, 8, 1<span class="o">)</span>
2020-08-01

julia&gt; Date<span class="o">(</span>Dates.Year<span class="o">(</span>2020<span class="o">)</span>,Dates.Month<span class="o">(</span>8<span class="o">)</span>,Dates.Day<span class="o">(</span>1<span class="o">))</span>
2020-08-01

julia&gt; Date<span class="o">(</span>Dates.Month<span class="o">(</span>8<span class="o">)</span>,Dates.Year<span class="o">(</span>2020<span class="o">))</span>
2020-08-01
</code></pre></div><h1 id="date-和-datetime-的算术操作">Date 和 DateTime 的算术操作</h1>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">dt</span> <span class="o">=</span> Date<span class="o">(</span>2012,2,29<span class="o">)</span>
2012-02-29

julia&gt; <span class="nv">dt2</span> <span class="o">=</span> Date<span class="o">(</span>2000,2,1<span class="o">)</span>
2000-02-01

julia&gt; dump<span class="o">(</span>dt<span class="o">)</span>
Date
  instant: Dates.UTInstant<span class="o">{</span>Day<span class="o">}</span>
    periods: Day
      value: Int64 <span class="m">734562</span>

julia&gt; dump<span class="o">(</span>dt2<span class="o">)</span>
Date
  instant: Dates.UTInstant<span class="o">{</span>Day<span class="o">}</span>
    periods: Day
      value: Int64 <span class="m">730151</span>

julia&gt; dt &gt; dt2
<span class="nb">true</span>

julia&gt; dt !<span class="o">=</span> dt2
<span class="nb">true</span>

julia&gt; dt + dt2
ERROR: MethodError: no method matching +<span class="o">(</span>::Date, ::Date<span class="o">)</span>
<span class="o">[</span>...<span class="o">]</span>

julia&gt; dt * dt2
ERROR: MethodError: no method matching *<span class="o">(</span>::Date, ::Date<span class="o">)</span>
<span class="o">[</span>...<span class="o">]</span>

julia&gt; dt / dt2
ERROR: MethodError: no method matching /<span class="o">(</span>::Date, ::Date<span class="o">)</span>

julia&gt; dt - dt2
<span class="m">4411</span> days

julia&gt; typeof<span class="o">(</span>dt - dt2<span class="o">)</span>
Day

julia&gt; dt2 - dt
-4411 days

julia&gt; <span class="nv">dt</span> <span class="o">=</span> DateTime<span class="o">(</span>2012,2,29<span class="o">)</span>
2012-02-29T00:00:00

julia&gt; <span class="nv">dt2</span> <span class="o">=</span> DateTime<span class="o">(</span>2000,2,1<span class="o">)</span>
2000-02-01T00:00:00

julia&gt; dt - dt2
<span class="m">381110400000</span> milliseconds

julia&gt; typeof<span class="o">(</span>dt - dt2<span class="o">)</span>
Millisecond
</code></pre></div><h1 id="访问器函数">访问器函数</h1>
<p>因为 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.Date">Date</a> 和 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.DateTime">DateTime</a> 类型被存储为单个 <a href="https://docs.julialang.org/en/v1/base/numbers/#Core.Int64">Int64</a> 值，所以日期部分或字段可以通过访问器函数进行检索。小写访问器函数以整数形式返回字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">t</span> <span class="o">=</span> Date<span class="o">(</span>2014, 1, 31<span class="o">)</span>
2014-01-31

julia&gt; Dates.year<span class="o">(</span>t<span class="o">)</span>
<span class="m">2014</span>

julia&gt; Dates.month<span class="o">(</span>t<span class="o">)</span>
<span class="m">1</span>

julia&gt; Dates.week<span class="o">(</span>t<span class="o">)</span>
<span class="m">5</span>

julia&gt; Dates.day<span class="o">(</span>t<span class="o">)</span>
<span class="m">31</span>
</code></pre></div><p>而专有形式返回相应 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.Period">Period</a> 类型中的相同值。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.Year<span class="o">(</span>t<span class="o">)</span>
<span class="m">2014</span> years

julia&gt; Dates.Day<span class="o">(</span>t<span class="o">)</span>
<span class="m">31</span> days
</code></pre></div><p>Julia 还提供了复合方法，因为在同时需要多个字段的情况下，这些方法提供了一种效率衡量标准。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.yearmonth<span class="o">(</span>t<span class="o">)</span>
<span class="o">(</span>2014, 1<span class="o">)</span>

julia&gt; Dates.monthday<span class="o">(</span>t<span class="o">)</span>
<span class="o">(</span>1, 31<span class="o">)</span>

julia&gt; Dates.yearmonthday<span class="o">(</span>t<span class="o">)</span>
<span class="o">(</span>2014, 1, 31<span class="o">)</span>
</code></pre></div><p>也可以访问底层 <code>UTInstant</code> 或整数值。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; dump<span class="o">(</span>t<span class="o">)</span>
Date
  instant: Dates.UTInstant<span class="o">{</span>Day<span class="o">}</span>
    periods: Day
      value: Int64 <span class="m">735264</span>

julia&gt; t.instant
Dates.UTInstant<span class="o">{</span>Day<span class="o">}(</span>Day<span class="o">(</span>735264<span class="o">))</span>

julia&gt; Dates.value<span class="o">(</span>t<span class="o">)</span>
<span class="m">735264</span>
</code></pre></div><h1 id="查询函数">查询函数</h1>
<p>查询函数提供关于 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.TimeType">TimeType</a> 的历法信息。它们包括关于一周中的某一天的信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">t</span> <span class="o">=</span> Date<span class="o">(</span>2014, 1, 31<span class="o">)</span>
2014-01-31

julia&gt; Dates.dayofweek<span class="o">(</span>t<span class="o">)</span>
<span class="m">5</span>

julia&gt; Dates.dayname<span class="o">(</span>t<span class="o">)</span>
<span class="s2">&#34;Friday&#34;</span>

julia&gt; Dates.dayofweekofmonth<span class="o">(</span>t<span class="o">)</span> <span class="c1"># 5th Friday of January</span>
<span class="m">5</span>

julia&gt; Dates.monthname<span class="o">(</span>t<span class="o">)</span>
<span class="s2">&#34;January&#34;</span>

julia&gt; Dates.daysinmonth<span class="o">(</span>t<span class="o">)</span>
<span class="m">31</span>
</code></pre></div><p>以及 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.TimeType">TimeType</a> 的年份和季度信息。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.isleapyear<span class="o">(</span>t<span class="o">)</span>
<span class="nb">false</span>

julia&gt; Dates.dayofyear<span class="o">(</span>t<span class="o">)</span>
<span class="m">31</span>

julia&gt; Dates.quarterofyear<span class="o">(</span>t<span class="o">)</span>
<span class="m">1</span>

julia&gt; Dates.dayofquarter<span class="o">(</span>t<span class="o">)</span>
<span class="m">31</span>
</code></pre></div><p><a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.dayname">dayname</a> 和 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.monthname">monthname</a> 方法也可以使用一个可选的 <code>locale</code> 关键字，它可以用来返回其他语言/地区的年份或月份的名称。这些函数也有返回缩写名称的版本，即 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.dayabbr">dayabbr</a> 和 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.monthabbr">monthabbr</a>。首先将映射加载到 <code>LOCALES</code> 变量中。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">french_months</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&#34;janvier&#34;</span>, <span class="s2">&#34;février&#34;</span>, <span class="s2">&#34;mars&#34;</span>, <span class="s2">&#34;avril&#34;</span>, <span class="s2">&#34;mai&#34;</span>, <span class="s2">&#34;juin&#34;</span>,
                        <span class="s2">&#34;juillet&#34;</span>, <span class="s2">&#34;août&#34;</span>, <span class="s2">&#34;septembre&#34;</span>, <span class="s2">&#34;octobre&#34;</span>, <span class="s2">&#34;novembre&#34;</span>, <span class="s2">&#34;décembre&#34;</span><span class="o">]</span><span class="p">;</span>

julia&gt; <span class="nv">french_monts_abbrev</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&#34;janv&#34;</span>,<span class="s2">&#34;févr&#34;</span>,<span class="s2">&#34;mars&#34;</span>,<span class="s2">&#34;avril&#34;</span>,<span class="s2">&#34;mai&#34;</span>,<span class="s2">&#34;juin&#34;</span>,
                              <span class="s2">&#34;juil&#34;</span>,<span class="s2">&#34;août&#34;</span>,<span class="s2">&#34;sept&#34;</span>,<span class="s2">&#34;oct&#34;</span>,<span class="s2">&#34;nov&#34;</span>,<span class="s2">&#34;déc&#34;</span><span class="o">]</span><span class="p">;</span>

julia&gt; <span class="nv">french_days</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&#34;lundi&#34;</span>,<span class="s2">&#34;mardi&#34;</span>,<span class="s2">&#34;mercredi&#34;</span>,<span class="s2">&#34;jeudi&#34;</span>,<span class="s2">&#34;vendredi&#34;</span>,<span class="s2">&#34;samedi&#34;</span>,<span class="s2">&#34;dimanche&#34;</span><span class="o">]</span><span class="p">;</span>

julia&gt; Dates.LOCALES<span class="o">[</span><span class="s2">&#34;french&#34;</span><span class="o">]</span> <span class="o">=</span> Dates.DateLocale<span class="o">(</span>french_months, french_monts_abbrev, french_days, <span class="o">[</span><span class="s2">&#34;&#34;</span><span class="o">])</span><span class="p">;</span>
</code></pre></div><p>然后可以利用上述函数进行查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.dayname<span class="o">(</span>t<span class="p">;</span><span class="nv">locale</span><span class="o">=</span><span class="s2">&#34;french&#34;</span><span class="o">)</span>
<span class="s2">&#34;vendredi&#34;</span>

julia&gt; Dates.monthname<span class="o">(</span>t<span class="p">;</span><span class="nv">locale</span><span class="o">=</span><span class="s2">&#34;french&#34;</span><span class="o">)</span>
<span class="s2">&#34;janvier&#34;</span>

julia&gt; Dates.monthabbr<span class="o">(</span>t<span class="p">;</span><span class="nv">locale</span><span class="o">=</span><span class="s2">&#34;french&#34;</span><span class="o">)</span>
<span class="s2">&#34;janv&#34;</span>
</code></pre></div><p>由于没有加载日期的缩写版本，试图使用函数 <code>dayabbr</code> 会出错。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.dayabbr<span class="o">(</span>t<span class="p">;</span><span class="nv">locale</span><span class="o">=</span><span class="s2">&#34;french&#34;</span><span class="o">)</span>
ERROR: BoundsError: attempt to access 1-element Array<span class="o">{</span>String,1<span class="o">}</span> at index <span class="o">[</span>5<span class="o">]</span>
Stacktrace:
<span class="o">[</span>...<span class="o">]</span>
</code></pre></div><h1 id="时间类型-周期算术">时间类型-周期算术</h1>
<p>在使用任何语言/日期框架时，熟悉如何处理日期-周期算术是一个很好的做法，因为有一些<a href="https://codeblog.jonskeet.uk/2010/12/01/the-joys-of-date-time-arithmetic/">棘手的问题</a>需要处理（尽管对于日-精度类型来说要少得多）。</p>
<p><code>Dates</code> 模块的方法试图遵循简单的原则，即在做 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.Period">Period</a> 算术时尽量少改。这种方法也常被称为历法算术，或者说如果有人在对话中问你同样的计算方法，你可能会猜到。为什么要大惊小怪呢？我们举个经典的例子：把2014年1月31日加1个月。答案是什么？Javascript 会说<a href="https://markhneedham.com/blog/2009/01/07/javascript-add-a-month-to-a-date/">3月3日</a>（假设31天）。PHP 会说<a href="https://stackoverflow.com/questions/5760262/php-adding-months-to-a-date-while-not-exceeding-the-last-day-of-the-month">3月2日</a>（假设30天）。事实上，没有正确的答案。在 <code>Dates</code> 模块中，它给出的结果是2月28日。它是如何计算出来的呢？我喜欢想到赌场里经典的 7-7-7 赌博游戏。</p>
<p>现在只要想象一下，老虎机不是 7-7-7，而是年-月-日，或者在我们的例子中，2014-01-31。当你要求在这个日期的基础上增加1个月的时候，月份槽就会递增，所以现在我们有 2014-02-31。然后检查日号是否大于新月份的最后有效日，如果大于（如上例），则日号向下调整到最后有效日（28）。这种方法的后果是什么呢？继续在我们的日期上再加一个月，<code>2014-02-28 + Month(1) == 2014-03-28</code>。什么？你是在期待3月的最后一天吗？不对，对不起，记得 7-7-7 的档期。尽可能少的槽位要改变，所以我们先把月份槽位递增1，2014-03-28，轰，我们就完成了，因为这是一个有效的日期。另一方面，如果我们要在原来的日期 2014-01-31 的基础上增加2个月，那么我们最终的结果是 2014-03-31，正如预期的那样。这种方法的另一个后果是，当强行进行特定的排序时，关联性会有所损失（即以不同的顺序添加东西会导致不同的结果）。比如说：</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="o">(</span>Date<span class="o">(</span>2014,1,29<span class="o">)</span>+Dates.Day<span class="o">(</span>1<span class="o">))</span> + Dates.Month<span class="o">(</span>1<span class="o">)</span>
2014-02-28

julia&gt; <span class="o">(</span>Date<span class="o">(</span>2014,1,29<span class="o">)</span>+Dates.Month<span class="o">(</span>1<span class="o">))</span> + Dates.Day<span class="o">(</span>1<span class="o">)</span>
2014-03-01
</code></pre></div><p>那是怎么回事呢？在第一行中，我们在1月29日的基础上加1天，结果是 2014-01-30；然后再加1个月，于是得到 2014-02-30，再往下调整为 2014-02-28。在第二个例子中，我们先加1个月，我们得到 2014-02-29，再往下调整为 2014-02-28，然后再加1天，结果是 2014-03-01。在这种情况下，有一个设计原则是有帮助的，那就是在存在多个 Periods 的情况下，操作将按照 Periods 的类型来排序，而不是按照它们的值或位置顺序来排序；这意味着总是先加 <code>Year</code>，然后加 <code>Month</code>，再加 <code>Week</code> 等。因此，以下确实会导致关联性并正好有用:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Date<span class="o">(</span>2014,1,29<span class="o">)</span> + Dates.Day<span class="o">(</span>1<span class="o">)</span> + Dates.Month<span class="o">(</span>1<span class="o">)</span>
2014-03-01

julia&gt; Date<span class="o">(</span>2014,1,29<span class="o">)</span> + Dates.Month<span class="o">(</span>1<span class="o">)</span> + Dates.Day<span class="o">(</span>1<span class="o">)</span>
2014-03-01
</code></pre></div><p>棘手吗？也许吧。一个无辜的 <code>Dates</code> 用户该怎么做？最重要的是要注意，当处理月份时，明确地强制执行某种关联性，可能会导致一些意想不到的结果，但除此之外，一切都应该按照预期工作。值得庆幸的是，在 UT 中处理时间时，日期-周期算术中的奇特情况几乎就是这样了（避免了处理夏令时、闰秒等的 &ldquo;乐趣&rdquo;）。</p>
<p>作为奖励，所有的周期算术对象都可以直接与范围一起工作。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">dr</span> <span class="o">=</span> Date<span class="o">(</span>2014,1,29<span class="o">)</span>:Day<span class="o">(</span>1<span class="o">)</span>:Date<span class="o">(</span>2014,2,3<span class="o">)</span>
Date<span class="o">(</span><span class="s2">&#34;2014-01-29&#34;</span><span class="o">)</span>:Day<span class="o">(</span>1<span class="o">)</span>:Date<span class="o">(</span><span class="s2">&#34;2014-02-03&#34;</span><span class="o">)</span>

julia&gt; collect<span class="o">(</span>dr<span class="o">)</span>
6-element Array<span class="o">{</span>Date,1<span class="o">}</span>:
 2014-01-29
 2014-01-30
 2014-01-31
 2014-02-01
 2014-02-02
 2014-02-03

julia&gt; <span class="nv">dr</span> <span class="o">=</span> Date<span class="o">(</span>2014,1,29<span class="o">)</span>:Dates.Month<span class="o">(</span>1<span class="o">)</span>:Date<span class="o">(</span>2014,07,29<span class="o">)</span>
Date<span class="o">(</span><span class="s2">&#34;2014-01-29&#34;</span><span class="o">)</span>:Month<span class="o">(</span>1<span class="o">)</span>:Date<span class="o">(</span><span class="s2">&#34;2014-07-29&#34;</span><span class="o">)</span>

julia&gt; collect<span class="o">(</span>dr<span class="o">)</span>
7-element Array<span class="o">{</span>Date,1<span class="o">}</span>:
 2014-01-29
 2014-02-28
 2014-03-29
 2014-04-29
 2014-05-29
 2014-06-29
 2014-07-29
</code></pre></div><pre><code>for i in Date(&quot;2020-08-01&quot;):Day(1):Date(&quot;2020-08-09&quot;)
           println(i)
end

2020-08-01
2020-08-02
2020-08-03
2020-08-04
2020-08-05
2020-08-06
2020-08-07
2020-08-08
2020-08-09
</code></pre><h1 id="调整器函数">调整器函数</h1>
<p>尽管日期-周期算术很方便，但经常需要在日期上进行的计算具有日历或时间的性质，而不是固定的周期数。节日就是一个很好的例子，大多数都遵循这样的规则：&ldquo;纪念日 = 五月的最后一个星期一&rdquo;，或者 &ldquo;感恩节 = 十一月的第四个星期四&rdquo;。这类时间表达式处理的是相对于日历的规则，比如本月的第一天或最后一天，下周二，或第一个和第三个星期三等。</p>
<p><code>Dates</code> 模块通过几个方便的方法提供了调整器 API，这些方法有助于简单、简洁地表达时间规则。第一组调整器方法处理周、月、季度和年的首尾。它们每个方法都接收一个单一的 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.TimeType">TimeType</a> 作为输入，并返回或调整到相对于输入的所需时期的第一个或最后一个。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.firstdayofweek<span class="o">(</span>Date<span class="o">(</span>2014,7,16<span class="o">))</span> <span class="c1"># Adjusts the input to the Monday of the input&#39;s week</span>
2014-07-14

julia&gt; Dates.lastdayofmonth<span class="o">(</span>Date<span class="o">(</span>2014,7,16<span class="o">))</span> <span class="c1"># Adjusts to the last day of the input&#39;s month</span>
2014-07-31

julia&gt; Dates.lastdayofquarter<span class="o">(</span>Date<span class="o">(</span>2014,7,16<span class="o">))</span> <span class="c1"># Adjusts to the last day of the input&#39;s quarter</span>
2014-09-30
</code></pre></div><p>接下来的两个高阶方法 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.tonext-Tuple%7BTimeType,Int64%7D">tonext</a> 和 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.toprev-Tuple%7BTimeType,Int64%7D">toprev</a>，通过将一个 <code>DateFunction</code> 和一个起始 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.TimeType">TimeType</a> 作为第一个参数来概括处理时间表达式。<code>DateFunction</code> 只是一个函数，通常是匿名的，它接受一个单一的 <a href="https://docs.julialang.org/en/v1/stdlib/Dates/#Dates.TimeType">TimeType</a> 作为输入，并返回一个 <a href="https://docs.julialang.org/en/v1/base/numbers/#Core.Bool">Bool</a>，<code>true</code> 表示满足调整标准。例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; <span class="nv">istuesday</span> <span class="o">=</span> x-&gt;Dates.dayofweek<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> Dates.Tuesday<span class="p">;</span> <span class="c1"># Returns true if the day of the week of x is Tuesday</span>

julia&gt; Dates.tonext<span class="o">(</span>istuesday, Date<span class="o">(</span>2014,7,13<span class="o">))</span> <span class="c1"># 2014-07-13 is a Sunday</span>
2014-07-15

julia&gt; Dates.tonext<span class="o">(</span>Date<span class="o">(</span>2014,7,13<span class="o">)</span>, Dates.Tuesday<span class="o">)</span> <span class="c1"># Convenience method provided for day of the week adjustments</span>
2014-07-15
</code></pre></div><p>这对于更复杂的时间表达式的 do-block 语法是很有用的。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">julia&gt; Dates.tonext<span class="o">(</span>Date<span class="o">(</span>2014,7,13<span class="o">))</span> <span class="k">do</span> x
           <span class="c1"># Return true on the 4th Thursday of November (Thanksgiving)</span>
           Dates.dayofweek<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> Dates.Thursday <span class="o">&amp;&amp;</span>
           Dates.dayofweekofmonth<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> <span class="m">4</span> <span class="o">&amp;&amp;</span>
           Dates.month<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> Dates.November
       end
2014-11-27
</code></pre></div><p><a href="https://docs.julialang.org/en/v1/base/collections/#Base.filter">Base.filter</a> 方法可以用来获取指定范围内的所有有效日期/时刻。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 匹兹堡街道清洁; 从 4月到11月的每第二个周二</span>
<span class="c1"># 日期范围从 2014-01-01 到 2015-01-01</span>
julia&gt; <span class="nv">dr</span> <span class="o">=</span> Dates.Date<span class="o">(</span>2014<span class="o">)</span>:Day<span class="o">(</span>1<span class="o">)</span>:Dates.Date<span class="o">(</span>2015<span class="o">)</span><span class="p">;</span>

julia&gt; filter<span class="o">(</span>dr<span class="o">)</span> <span class="k">do</span> x
           Dates.dayofweek<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> Dates.Tue <span class="o">&amp;&amp;</span>
           Dates.April &lt;<span class="o">=</span> Dates.month<span class="o">(</span>x<span class="o">)</span> &lt;<span class="o">=</span> Dates.Nov <span class="o">&amp;&amp;</span>
           Dates.dayofweekofmonth<span class="o">(</span>x<span class="o">)</span> <span class="o">==</span> <span class="m">2</span>
       end
8-element Array<span class="o">{</span>Date,1<span class="o">}</span>:
 2014-04-08
 2014-05-13
 2014-06-10
 2014-07-08
 2014-08-12
 2014-09-09
 2014-10-14
 2014-11-11
</code></pre></div><p>在 Raku 中上面的代码可以写成:</p>
<pre><code class="language-raku" data-lang="raku">lazy my @dates = Date.new('2014-01-01') ... Date.new('2015-01-01');

.say for @dates.grep: -&gt; $d {
    $d.day-of-week == 2 &amp;&amp;
    4  &lt;= $d.month &lt;= 11 &amp;&amp;
    $d.weekday-of-month == 2
}
</code></pre><p>其他的例子和测试可以在 <a href="https://github.com/JuliaLang/julia/blob/master/stdlib/Dates/test/adjusters.jl">stdlib/Dates/test/adjusters.jl</a> 中找到。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia" term="julia" label="julia" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dates" term="dates" label="dates" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Real Time Reporting with the Table API</blockquote><p>Apache Flink 提供的 Table API 是一个统一的、关系型的 API，用于批处理和流处理，即在无边界的、实时的流或有边界的、批处理的数据集上以相同的语义执行查询，并产生相同的结果。Flink 中的 Table API 通常用于简化数据分析、数据管道化和 ETL 应用的定义。</p>
<h2 id="你要构建什么">你要构建什么?</h2>
<p>在本教程中，你将学习如何构建一个实时的仪表盘，以按账户跟踪金融交易。该管道将从 Kafka 读取数据，并将结果写入 MySQL，通过 Grafana 可视化。</p>
<h2 id="先决条件">先决条件</h2>
<p>本演练假设你对 Java 或 Scala 有一定的熟悉，但即使你来自不同的编程语言，你也应该能够跟上。它还假设你熟悉基本的关系概念，如 SELECT 和 GROUP BY 子句。</p>
<h2 id="救命-我被卡住了">救命, 我被卡住了!</h2>
<p>如果你遇到困难，请查看<a href="https://flink.apache.org/community.html">社区支持资源</a>。特别是 Apache Flink 的<a href="https://flink.apache.org/community.html#mailing-lists">用户邮件列表</a>，它一直是 Apache 项目中最活跃的一个，也是快速获得帮助的好方法。</p>
<h2 id="如何跟进">如何跟进</h2>
<p>如果你想跟着走，你需要一台电脑与:</p>
<ul>
<li>Java 8 或 11</li>
<li>Maven</li>
<li>Docker</li>
</ul>
<p>所需的配置文件可在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 资源库中获得。下载后，在 IDE 中打开项目 flink-playground/table-walkthrough，并导航到文件 SpendReport。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>

<span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">);</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">).</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">);</span>
</code></pre></div><h2 id="拆解代码">拆解代码</h2>
<h3 id="the-execution-environment">The Execution Environment</h3>
<p>前两行设置了你的 <code>TableEnvironment</code>。表环境是你如何为你的 Job 设置属性，指定你是在写批处理还是流式应用，以及创建你的源。本演练创建了一个使用流式执行的标准表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>
</code></pre></div><h3 id="注册表">注册表</h3>
<p>接下来，在当前<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册了表，您可以使用这些表连接到外部系统，以便读写批处理和流数据。表源提供对存储在外部系统中的数据的访问，如数据库、键值存储、消息队列或文件系统。table sink 向外部存储系统发出一个表。根据源和 sink 的类型，它们支持不同的格式，如 CSV、JSON、Avro 或 Parquet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;)&#34;</span><span class="o">);</span>
</code></pre></div><p>注册了两个表：一个是交易输入表，一个是消费报告输出表。交易(transaction)表让我们可以读取信用卡交易，其中包含账户ID(account_id)、时间戳(transaction_time)和美元金额(amount)。该表是在一个名为 <code>transactions</code> 的 Kafka 主题上的逻辑视图，包含 CSV 数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>
</code></pre></div><p>第二张表 <code>spend_report</code>，存储了最终的汇总结果。其底层存储是 MySql 数据库中的一张表。</p>
<h3 id="查询">查询</h3>
<p>配置好环境和注册好表之后，你就可以构建你的第一个应用程序了。从 <code>TableEnvironment</code> 中，你可以从一个输入表中读取它的行，然后使用 <code>executeInsert</code> 将这些结果写入到一个输出表中。<code>report</code> 函数是你实现业务逻辑的地方。它目前还没有被实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">);</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">).</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">);</span>
</code></pre></div><h2 id="测试">测试</h2>
<p>该项目包含一个二次测试类 <code>SpendReportTest</code>，用于验证报表的逻辑。它以批处理模式创建了一个表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">inBatchMode</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>
</code></pre></div><p>Flink 的独特属性之一是它在批处理和流式处理之间提供一致的语义。这意味着你可以在静态数据集上以批处理模式开发和测试应用程序，并以流式应用程序的形式部署到生产中。</p>
<h2 id="尝试一下">尝试一下</h2>
<p>现在有了 Job 设置的骨架，你就可以添加一些业务逻辑了。目标是建立一个报告，显示每个账户在一天中每个小时的总支出。这意味着时间戳列需要从毫秒到小时的颗粒度进行舍入。</p>
<p>Flink 支持用纯 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/">SQL</a> 或使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 开发关系型应用。Table API 是一个受 SQL 启发的流畅 DSL，可以用 Python、Java 或 Scala 编写，并支持强大的 IDE 集成。就像 SQL 查询一样，Table 程序可以选择所需的字段，并通过你的键进行分组。这些功能，加上<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置的函数</a>，如 <code>floor</code> 和 <code>sum</code>，写这个报告问题不大。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">).</span><span class="na">floor</span><span class="o">(</span><span class="n">TimeIntervalUnit</span><span class="o">.</span><span class="na">HOUR</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><h2 id="用户定义的函数">用户定义的函数</h2>
<p>Flink 包含有限的内置函数，有时你需要用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>来扩展它。如果 <code>floor</code> 不是预定义的，你可以自己实现它。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">java.time.LocalDateTime</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.time.temporal.ChronoUnit</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyFloor</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="nf">eval</span><span class="o">(</span>
        <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">{</span>

        <span class="k">return</span> <span class="n">timestamp</span><span class="o">.</span><span class="na">truncatedTo</span><span class="o">(</span><span class="n">ChronoUnit</span><span class="o">.</span><span class="na">HOURS</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后迅速将其集成到你的应用程序中。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">call</span><span class="o">(</span><span class="n">MyFloor</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><p>这个查询会消耗 <code>transactions</code> 表的所有记录，计算报表，并以高效、可扩展的方式输出结果。使用该实现运行测试将通过。</p>
<h2 id="添加窗口">添加窗口</h2>
<p>基于时间的数据分组是数据处理中的典型操作，尤其是在处理无限流时。基于时间的分组被称为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>，Flink 提供了灵活的窗口语义。最基本的窗口类型称为 <code>Tumble</code> 窗口，它有一个固定的大小，其桶不重叠。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">Tumble</span><span class="o">.</span><span class="na">over</span><span class="o">(</span><span class="n">lit</span><span class="o">(</span><span class="n">1</span><span class="o">).</span><span class="na">hour</span><span class="o">()).</span><span class="na">on</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">).</span><span class="na">start</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><p>这就定义了你的应用程序使用基于时间戳列的一小时滚动窗口。因此，时间戳为 2019-06-01 01:23:47 的行被放在 2019-06-01 01:00:00 窗口中。</p>
<p>基于时间的聚合是独一无二的，因为在连续流应用中，时间与其他属性不同，一般是向前移动的。与 floor 和你的 UDF 不同，窗口函数是<a href="https://en.wikipedia.org/wiki/Intrinsic_function">内在的</a>，它允许运行时应用额外的优化。在批处理上下文中，窗口提供了一个方便的 API，用于通过时间戳属性对记录进行分组。</p>
<p>用这个实现运行测试也会通过。</p>
<h2 id="再来一次用流">再来一次，用流!</h2>
<p>就这样，一个功能齐全的、有状态的、分布式的流式应用! 查询不断地消耗 Kafka 的事务流，计算每小时的花费，并在结果准备好后立即发出。由于输入是有界的，所以查询一直在运行，直到手动停止。而且由于 Job 使用了基于时间窗口的聚合，所以当框架知道某个窗口不会再有记录到达时，Flink 可以进行特定的优化，比如状态清理。</p>
<p>表游乐场是完全 docker 化的，可以作为流式应用在本地运行。该环境包含一个 Kafka 主题、一个连续数据生成器、MySql 和 Grafana。</p>
<p>从 <code>table-walkthrough</code> 文件夹内启动 <code>docker-compose</code> 脚本。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose build
$ docker-compose up -d
</code></pre></div><p>你可以通过 <a href="http://localhost:8082/">Flink 控制台</a>查看正在运行的作业信息。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/spend-report-console.png" alt="img"></p>
<p>从 MySQL 里面探索结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose <span class="nb">exec</span> mysql mysql -Dsql-demo -usql-demo -pdemo-sql

mysql&gt; use sql-demo<span class="p">;</span>
Database changed

mysql&gt; <span class="k">select</span> count<span class="o">(</span>*<span class="o">)</span> from spend_report<span class="p">;</span>
+----------+
<span class="p">|</span> count<span class="o">(</span>*<span class="o">)</span> <span class="p">|</span>
+----------+
<span class="p">|</span>      <span class="m">110</span> <span class="p">|</span>
+----------+
</code></pre></div><p>最后，去 <a href="http://localhost:3000/d/FOe0PbmGk/walkthrough?viewPanel=2&amp;orgId=1&amp;refresh=5s">Grafana</a> 看看完全可视化的结果吧!</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/table_api.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/table_api.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table" term="table" label="table" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/api" term="api" label="api" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Julia 语言学习笔记]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-27-learning-julialang/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-27-learning-julialang/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Learning Julia</blockquote><h2 id="语法">语法</h2>
<h3 id="数值字面量系数">数值字面量系数</h3>
<p>在标识符或圆括号前面直接放一个数字, 例如 <code>2x</code> 或 <code>2(x+y)</code>, 会被认为是把标识符和它前面的数字相乘。这样写多项式就很方便了。</p>
<h3 id="向量化的点号运算符">向量化的点号运算符</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">.+</span> <span class="mi">3</span>

<span class="mi">3</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="mi">4</span>
 <span class="mi">5</span>
 <span class="mi">6</span>
</code></pre></div><p><code>.+</code> 类似于 Raku 中的 <code>»+»</code> 超运算符:</p>
<pre><code class="language-raku" data-lang="raku">[1,2,3] »+» 3
[4 5 6]
</code></pre><p>但是 Julia 的 <code>Vectorized &quot;dot&quot;</code> 语法没有 Raku 的超运算符语法清晰。</p>
<p>类似的例子还有:</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">sin</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="c"># 0.479425538604203</span>

<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>
<span class="n">sin</span><span class="o">.</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="mi">3</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="mf">0.479425538604203</span>
 <span class="mf">0.8414709848078965</span>
 <span class="mf">0.9974949866040544</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="mi">3</span><span class="n">x</span> <span class="o">+</span> <span class="mi">4</span><span class="n">y</span><span class="p">;</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">];</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">];</span>
<span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="nb">pi</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="mi">3</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="mf">13.42477796076938</span>
 <span class="mf">17.42477796076938</span>
 <span class="mf">21.42477796076938</span>

<span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">pi</span><span class="p">)</span>
<span class="mi">3</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="mf">15.566370614359172</span>
 <span class="mf">18.566370614359172</span>
 <span class="mf">21.566370614359172</span>

<span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="mi">3</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="mf">19.0</span>
 <span class="mf">26.0</span>
 <span class="mf">33.0</span>
</code></pre></div><p>等价的 Raku 写法为:</p>
<pre><code class="language-raku" data-lang="raku">sub f(\x, \y) { 3*x + 4*y};

my \A = [1.0, 2.0, 3.0];
my \B = [4.0, 5.0, 6.0];

A».&amp;f(pi)
[15.566370614359172 18.566370614359172 21.566370614359172]
</code></pre><h3 id="链式比较">链式比较</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="o">&lt;</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">3</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">3</span> <span class="o">!=</span> <span class="mi">5</span>
<span class="kc">true</span>
</code></pre></div><p>Raku 同样支持这种链式比较。</p>
<h3 id="虚数">虚数</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">real</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="nb">im</span><span class="p">)</span>         <span class="c"># 1</span>
<span class="n">imag</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="nb">im</span><span class="p">)</span>         <span class="c"># 2</span>
<span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="nb">im</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span><span class="nb">im</span><span class="p">)</span> <span class="c"># 5 + 0im</span>
</code></pre></div><pre><code class="language-raku" data-lang="raku">(1 + 2i).re         # 1
(1 + 2i).im         # 2
(1 + 2i) * (1 - 2i) # 5+0i
</code></pre><h3 id="命名参数">命名参数</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span> <span class="n">style</span><span class="o">=</span><span class="s">&#34;solid&#34;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#34;black&#34;</span><span class="p">)</span>
    <span class="c">###</span>
<span class="k">end</span>

<span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">:</span><span class="n">width</span> <span class="o">=&gt;</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div><h3 id="函数组合">函数组合</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="p">(</span><span class="n">sqrt</span> <span class="n">∘</span> <span class="o">+</span><span class="p">)(</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="c"># 3.0</span>

<span class="n">map</span><span class="p">(</span><span class="n">first</span> <span class="n">∘</span> <span class="n">reverse</span> <span class="n">∘</span> <span class="n">uppercase</span><span class="p">,</span> <span class="n">split</span><span class="p">(</span><span class="s">&#34;you can compose functions like this&#34;</span><span class="p">))</span>
<span class="mi">6</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Char</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
 <span class="sc">&#39;U&#39;</span>
 <span class="sc">&#39;N&#39;</span>
 <span class="sc">&#39;E&#39;</span>
 <span class="sc">&#39;S&#39;</span>
 <span class="sc">&#39;E&#39;</span>
 <span class="sc">&#39;S&#39;</span>
</code></pre></div><h3 id="piping">Piping</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="mi">1</span><span class="o">:</span><span class="mi">10</span> <span class="o">|&gt;</span> <span class="n">sum</span> <span class="o">|&gt;</span> <span class="n">sqrt</span> <span class="c"># 7.416198487095663</span>

<span class="c"># 等价于</span>
<span class="p">(</span><span class="n">sqrt</span> <span class="n">∘</span> <span class="n">sum</span><span class="p">)(</span><span class="mi">1</span><span class="o">:</span><span class="mi">10</span><span class="p">)</span>  <span class="c"># 7.416198487095663</span>
</code></pre></div><h3 id="广播和管道一起使用">广播和管道一起使用</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="p">[</span><span class="s">&#34;a&#34;</span><span class="p">,</span> <span class="s">&#34;list&#34;</span><span class="p">,</span> <span class="s">&#34;of&#34;</span><span class="p">,</span> <span class="s">&#34;strings&#34;</span><span class="p">]</span> <span class="o">.|&gt;</span> <span class="p">[</span><span class="n">uppercase</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">titlecase</span><span class="p">,</span> <span class="n">length</span><span class="p">]</span>
<span class="mi">4</span><span class="o">-</span><span class="n">element</span> <span class="kt">Array</span><span class="p">{</span><span class="kt">Any</span><span class="p">,</span><span class="mi">1</span><span class="p">}</span><span class="o">:</span>
  <span class="s">&#34;A&#34;</span>
  <span class="s">&#34;tsil&#34;</span>
  <span class="s">&#34;Of&#34;</span>
 <span class="mi">7</span>
</code></pre></div><h3 id="组合类型">组合类型</h3>
<ul>
<li>不可变组合类型</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">struct</span> <span class="n">Foo</span>
    <span class="n">bar</span>
    <span class="n">baz</span><span class="o">::</span><span class="kt">Int</span>
    <span class="n">qux</span><span class="o">::</span><span class="kt">Float64</span>
<span class="k">end</span>

<span class="n">foo</span> <span class="o">=</span> <span class="n">Foo</span><span class="p">(</span><span class="s">&#34;rakulang&#34;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">typeof</span><span class="p">(</span><span class="n">foo</span><span class="p">)</span> <span class="c"># Foo</span>
<span class="n">typeof</span><span class="p">(</span><span class="n">Foo</span><span class="p">)</span> <span class="c"># DataType</span>

<span class="n">foo</span><span class="o">.</span><span class="n">bar</span>     <span class="c"># rakulang</span>
<span class="n">foo</span><span class="o">.</span><span class="n">qux</span>     <span class="c"># 1.5</span>
<span class="n">foo</span><span class="o">.</span><span class="n">qux</span> <span class="o">=</span> <span class="mi">1</span> <span class="c"># ERROR: setfield! immutable struct of type Foo cannot be changed</span>
</code></pre></div><ul>
<li>可变组合类型</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">mutable</span> <span class="k">struct</span> <span class="n">Bar</span>
    <span class="n">baz</span>
    <span class="n">qux</span><span class="o">::</span><span class="kt">Float64</span>
<span class="k">end</span>

<span class="n">bar</span> <span class="o">=</span> <span class="n">Bar</span><span class="p">(</span><span class="s">&#34;rakudo&#34;</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">)</span>
<span class="n">bar</span><span class="o">.</span><span class="n">baz</span> <span class="o">=</span> <span class="mi">1</span><span class="o">//</span><span class="mi">2</span>
<span class="n">bar</span><span class="o">.</span><span class="n">qux</span> <span class="o">=</span> <span class="mf">2.0</span>
</code></pre></div><h3 id="联合类型">联合类型</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">IntOrString</span> <span class="o">=</span> <span class="kt">Union</span><span class="p">{</span><span class="kt">Int</span><span class="p">,</span><span class="kt">AbstractString</span><span class="p">}</span>
<span class="mi">1</span> <span class="o">::</span> <span class="n">IntOrString</span>          <span class="c"># 1</span>
<span class="s">&#34;rakulang&#34;</span> <span class="o">::</span> <span class="n">IntOrString</span> <span class="c"># rakulang</span>
</code></pre></div><h3 id="参数化类型">参数化类型</h3>
<ul>
<li>参数化组合类型</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">struct</span> <span class="n">Point</span><span class="p">{</span><span class="n">T</span><span class="p">}</span>
    <span class="n">x</span><span class="o">::</span><span class="n">T</span>
    <span class="n">y</span><span class="o">::</span><span class="n">T</span>
<span class="k">end</span>

<span class="n">point</span><span class="o">=</span><span class="n">Point</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">point</span><span class="o">.</span><span class="n">x</span> <span class="c"># 1.0</span>
<span class="n">point</span><span class="o">.</span><span class="n">y</span> <span class="c"># 2.0</span>


<span class="k">struct</span> <span class="n">Circle</span><span class="p">{</span><span class="n">T</span><span class="p">,</span><span class="n">U</span><span class="p">}</span>
    <span class="n">x</span><span class="o">::</span><span class="n">T</span>
    <span class="n">y</span><span class="o">::</span><span class="n">U</span>
<span class="k">end</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">Circle</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="kt">AbstractString</span><span class="p">}(</span><span class="mf">6.0</span><span class="p">,</span> <span class="s">&#34;rakulang&#34;</span><span class="p">)</span>
<span class="n">c</span><span class="o">.</span><span class="n">x</span> <span class="c"># 6.0</span>
<span class="n">c</span><span class="o">.</span><span class="n">y</span> <span class="c"># rakulang</span>
</code></pre></div><h3 id="多重分派">多重分派</h3>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="kt">Float64</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="kt">Float64</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="kt">Number</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="kt">Number</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span>

<span class="n">methods</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="c"># 2 methods for generic function &#34;f&#34;:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="kt">Float64</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="kt">Float64</span><span class="p">)</span> <span class="kp">in</span> <span class="n">Main</span> <span class="n">at</span> <span class="n">REPL</span><span class="p">[</span><span class="mi">33</span><span class="p">]</span><span class="o">:</span><span class="mi">1</span>
<span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">::</span><span class="kt">Number</span><span class="p">,</span> <span class="n">y</span><span class="o">::</span><span class="kt">Number</span><span class="p">)</span> <span class="kp">in</span> <span class="n">Main</span> <span class="n">at</span> <span class="n">REPL</span><span class="p">[</span><span class="mi">34</span><span class="p">]</span><span class="o">:</span><span class="mi">1</span>

<span class="n">f</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span> <span class="c"># 7</span>
<span class="n">f</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>   <span class="c"># 1</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julialang" term="julialang" label="julialang" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/julia" term="julia" label="julia" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[通过函数式编程实现更简洁的代码]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-26-cleaner-code-with-functional-programming/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-07-21-checklist-for-6-dot-d/?utm_source=atom_feed" rel="related" type="text/html" title="Checklist for Raku 6.d" />
            
                <id>https://ohmyweekly.github.io/notes/2020-07-26-cleaner-code-with-functional-programming/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Cleaner code with functional programming</blockquote><p>函数式编程是一种编程风格，现代语言或多或少都支持这种风格。在这篇文章中，我想解释一下函数式编程如何为你提供强大的抽象，使你的代码更加简洁。我将用 Raku 和 Python 中的例子来说明这一点，我们将看到这两种语言都是函数式编程的优秀语言。</p>
<h2 id="raku-简介">Raku: 简介</h2>
<p>本文的代码示例是用 Python 和 Raku 编写的。我想大多数人都熟悉 Python，但 Raku 不太为人所知，所以我先解释一下基础知识。本文中的代码不是很习惯，所以如果你懂得其他编程语言，应该很容易理解。</p>
<p>Raku 与 Perl 最为相似。两种语言在语法上都与 C/C++、Java 和 JavaScript 相似：基于块，语句用分号隔开，块用大括号分界，参数列表放在括号中，用逗号隔开。将 Perl 和 Raku 与其他语言区分开来的主要特征是使用魔符（&ldquo;有趣的字符&rdquo;）来识别变量的类型：<code>$</code> 代表标量，<code>@</code> 代表数组，<code>%</code> 代表哈希（映射），<code>&amp;</code> 代表子程序。变量也有关键字来标识它们的作用域，我只用 <code>my</code> 来标识变量的词法作用域。子程序是用 <code>sub</code> 关键字来声明的，子程序可以是命名的，也可以是匿名的。</p>
<pre><code class="language-perl6" data-lang="perl6">sub square ($x) {
    $x*$x;
}
# anonymous subroutine 
my $anon_square = sub ($x) {
    $x*$x;
}
</code></pre><p>在 Python 中，这将是：</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">square</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span>

<span class="c1"># anonymous subroutine </span>
<span class="n">anon_square</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span>
</code></pre></div><p>Raku 支持无符号变量，并使用 <code>\</code> 语法来声明它们。更多关于普通变量和无符号变量之间的区别，请参见 <a href="https://docs.raku.org/language/variables#Sigilless_variables">Raku 文档</a>。例如(<code>say</code> 打印它的参数，后面加一个换行)。</p>
<pre><code class="language-perl6" data-lang="perl6">my \x = 42; # sigilless
my $y = 43; 
say x + $y; 
</code></pre><p>在本文的代码中，我将尽可能地使用无符号变量。</p>
<p>Raku 有几种类型的序列数据结构。在下面的代码中，我将使用<a href="https://docs.raku.org/language/list">列表和数组</a>以及<a href="https://docs.raku.org/type/Range">范围</a>。在 Raku 中，列表和数组的主要区别在于，列表是不可变的，这意味着一旦创建，就不能修改。所以它是一个只读的数据结构。要&quot;更新&quot;一个不可变的数据结构，你需要创建一个更新的副本。另一方面，数组是可变的，所以我们可以更新它们的元素，扩展它们，缩小它们等等。所有的更新都发生在原始数据的位置上。</p>
<p>Raku 的数组类似于 Python 的 list，Raku 的 list 类似于 Python 的 tuple，也是不可变的。除了语法之外，Raku 中的范围与 Python 中的范围相似，都是不可变的。</p>
<pre><code class="language-perl6" data-lang="perl6">my @array1 = 1,2,3; #=&gt; an array because of the '@' sigil
my \array2 = [1,2,3]; #=&gt; an array, because of the '[...]'

my \range1 = 1 .. 10; #=&gt; a range 1 .. 10
my @array3 = 1 .. 10; #=&gt; an array from a range, because of the '@' sigil

my \list1 = 1,2,3; #=&gt; a list
my $list2 = (1,2,3); #=&gt; also a list
my \list3 = |(1 .. 10);  #=&gt; an array from a range because of the '|' flattening operation
</code></pre><p>相应的 Python 代码为:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">list1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="c1">#=&gt; a list from a tuple</span>
<span class="n">list2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">];</span> <span class="c1">#=&gt; a list, because of the &#39;[...]&#39;</span>

<span class="n">range1</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span> <span class="c1">#=&gt; a range 1 .. 10</span>
<span class="n">list3</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">));</span> <span class="c1">#=&gt; a list from a range</span>

<span class="n">tuple1</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">;</span> <span class="c1">#=&gt; a tuple</span>
<span class="n">tuple2</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="c1">#=&gt; a tuple from a list</span>
<span class="n">tuple3</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">))</span> <span class="c1">#=&gt; creates a tuple from a range</span>
</code></pre></div><p>其他具体的语法或功能将针对具体的例子进行解释。</p>
<h2 id="其他任何名称的函数---作为值的函数"><em>其他任何名称的函数</em> - 作为值的函数</h2>
<p>函数是函数式编程的精髓。正如我在<a href="https://wimvanderbauwhede.github.io/articles/everything-is-a-function">&ldquo;万物皆函数&rdquo;</a>一文中所解释的那样，在适当的函数式语言中，所有的结构都是由函数构建的。</p>
<p>所有现代编程语言都有函数、程序、子程序或方法的概念。它们是代码重用的重要机制。通常，我们认为函数是对一些输入值进行操作以产生一个或多个输出值的东西。输入值可以是全局声明的，也可以是一个类的属性，或者作为参数传递给函数。同样，输出值可以直接返回，到全局变量，作为类的属性或通过修改输入值。</p>
<p>要想从函数式编程中获益最多，最好是函数是纯粹的，这意味着对函数的调用总是对相同的输入产生相同的输出。在实践中，如果函数只接受输入作为参数，并直接返回输出，这一点比较容易实现，但这并不是必不可少的。</p>
<p>函数式编程的关键特征是，函数的输入值和输出值本身可以是函数。所以函数必须是你语言中的值。有时这被称为 &ldquo;函数必须是一等公民&rdquo;，一个接收和/或返回函数的函数有时被称为&quot;高阶函数&quot;。</p>
<p>如果函数是值，那么我们就可以将它们赋值给变量。特别是我们会将它们赋值给其他函数的参数。但我们也可以将它们赋值给普通的变量。</p>
<p>让我们考虑以下函数，<code>choose</code>，它需要三个参数 <code>t</code>，<code>f</code> 和 <code>c</code>。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub choose (\t, \f, \d) {
    if (d) {t} else {f}
}
# Python
def choose (t, f, d):
  if d:
    return t 
  else:
    return f
</code></pre><p>首先让我们用字符串作为前两个参数的值来调用 <code>choose</code>。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \tstr = &quot;True!&quot;;
my \fstr = &quot;False!&quot;;

my \res_str = choose(tstr, fstr, True);

say res_str; #=&gt; says &quot;True!&quot;
# Python
tstr = &quot;True!&quot;
fstr = &quot;False!&quot;

res_str = choose(tstr,fstr,True)

print(res_str) #=&gt; says &quot;True!&quot;
</code></pre><p>现在让我们尝试用函数作为参数:</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub tt (\s) { say &quot;True {s}!&quot; }
sub ff (\s) { say &quot;False {s}!&quot; }

my &amp;res_f = choose(&amp;tt, &amp;ff, False);

say &amp;res_f; #=&gt; says &amp;ff
res_f(&quot;rumour&quot;); #=&gt; says &quot;False rumour!&quot;
# Python
def tt(s):
  print( &quot;True &quot;+s+&quot;!&quot;)
def ff(s):  
  print( &quot;False&quot;+s+&quot;!&quot;)

res_f = choose(tt,ff,True)

print(res_f) #=&gt; says &lt;function tt at 0x7f829c3aa310&gt;
res_f(&quot;rumour&quot;) #=&gt; says &quot;False rumour!&quot;
</code></pre><p>因此，我们的函数 <code>choose</code>  接收两个函数作为它的前两个参数，并返回一个函数。在 Raku 中，我们需要在函数名上加上 <code>&amp;</code> 符号，因为否则它们会被求值：像 <code>tt</code> 这样的裸函数名就等于调用没有参数的函数 <code>tt()</code>。通过将这个函数赋值给一个变量(<code>res_f</code>)，我们现在可以将 <code>res_f</code> 作为一个函数来调用，它最终会根据选择来调用 <code>tt</code> 或 <code>ff</code>。</p>
<h2 id="函数不需要名字">函数不需要名字</h2>
<p>现在，如果我们可以将函数赋值给变量，它们本身其实并不需要一个名字。所以我们的函数可以是匿名的。大多数语言都支持匿名函数，在函数式语言中，它们通常被称为 &ldquo;lambda 函数&rdquo;。在 Raku 中，我们有两种方法来创建匿名函数。</p>
<p>使用 <code>sub (...)</code> 语法:</p>
<pre><code class="language-perl6" data-lang="perl6">my \tt = sub (\s) { say &quot;True {s}!&quot; };
</code></pre><p>或者使用<a href="https://docs.raku.org/language/functions#index-entry-pointy_blocks">&lsquo;尖号块&rsquo;</a>语法，这样更紧凑一些:</p>
<pre><code class="language-perl6" data-lang="perl6">my \ff = -&gt; \s { say &quot;False {s}!&quot; };
</code></pre><p>Python 使用 <code>lambda</code> 关键字:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">tt</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="k">print</span><span class="p">(</span> <span class="s2">&#34;True &#34;</span><span class="o">+</span><span class="n">s</span><span class="o">+</span><span class="s2">&#34;!&#34;</span> <span class="p">)</span>
<span class="n">ff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span> <span class="p">:</span> <span class="k">print</span><span class="p">(</span> <span class="s2">&#34;False &#34;</span><span class="o">+</span><span class="n">s</span><span class="o">+</span><span class="s2">&#34;!&#34;</span> <span class="p">)</span>
</code></pre></div><p>所以现在我们可以说:</p>
<pre><code class="language-perl6" data-lang="perl6">my &amp;res_f = choose(tt, ff, True);

say &amp;res_f; #=&gt; says sub { }
res_f(&quot;story&quot;); #=&gt; says &quot;True story!&quot;
</code></pre><p>当我们打印出函数所绑定的变量时，Raku 返回 <code>sub { }</code> 来表示该变量包含一个函数。</p>
<p>在 Python 中:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">res_f</span> <span class="o">=</span> <span class="n">choose</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">ff</span><span class="p">,</span> <span class="bp">True</span><span class="p">);</span>

<span class="k">print</span><span class="p">(</span> <span class="n">res_f</span><span class="p">)</span> <span class="c1">#=&gt; says &lt;function &lt;lambda&gt; at 0x7f829b298b80&gt;</span>
<span class="n">res_f</span><span class="p">(</span><span class="s2">&#34;story&#34;</span><span class="p">)</span> <span class="c1">#=&gt; says &#34;True story!&#34;</span>
</code></pre></div><h2 id="例子-map-grep-和-reduce">例子: <code>map</code>、 <code>grep</code> 和 <code>reduce</code></h2>
<p>函数的功能有很多用途，我只想重点介绍三个在 Raku 中现成的例子：<code>map</code>、<code>reduce</code> 和 <code>grep</code>。Python 有 <code>map</code> 和 <code>filter</code>，并通过 <code>functools</code> 模块提供 <code>reduce</code>。这些函数的共同点是，它们提供了一种对列表进行 <code>for</code> 循环的替代方法。</p>
<h3 id="map--对列表中的所有元素进行函数应用"><code>map</code> : 对列表中的所有元素进行函数应用</h3>
<p><code>map</code> 有两个参数：一个函数和一个列表。它将函数按顺序应用于列表中的所有值，并返回结果，例如将列表中的所有值平方。</p>
<pre><code class="language-perl6" data-lang="perl6">my \res = map -&gt; \x {x*x} , 1 .. 10;
</code></pre><p>在 Python 中，我们需要显式地创建元组，但除了语法上的差异，结构是完全一样的。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">res</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span> <span class="nb">map</span><span class="p">(</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)))</span>
</code></pre></div><p>这是对传统 <code>for</code> 循环的功能替代。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \res = [];
for 1 .. 10 -&gt; \x {
    res.push(x*x);
}
# Python
res = []
for x in range(1,11):
    res.append(x*x)
</code></pre><p>请注意，在 Raku 和 Python 中，我们需要为 <code>for</code> 循环版本使用一个可变的数据结构，而 <code>map</code> 版本则使用不可变的数据结构。</p>
<h3 id="grep--过滤列表"><code>grep</code> : 过滤列表</h3>
<p><code>grep</code> (在 Python 中称为 <code>filter</code>)也接受参数，一个函数和一个列表，但它只返回函数返回真的列表中的值。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \res = grep -&gt; \x { x % 5 == 0 }, 1 .. 30;
# Python
res = tuple(filter( lambda x : x % 5 == 0 ,range(1,31)))
</code></pre><p>当然我们也可以用 <code>for</code> 循环和 <code>if</code> 语句来写，但这又需要一个可变的数据结构。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \res = [];
for 1 .. 30 -&gt; \x {
    if (x % 5 == 0) {
    res.push(x);
    }
}
# Python
res = []
for x in range(1,31): 
  if (x % 5 == 0):
    res.append(x)
</code></pre><p><code>map</code> 和 <code>grep</code> 的好处是，你可以很容易地把它们链在一起。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
grep -&gt; \x { x % 5 == 0 }, map -&gt; \x {x*x}, 1..30
# Python
res = tuple(filter( lambda x : x % 5 == 0 ,map( lambda x : x*x ,range(1,31))))
</code></pre><p>这是因为 <code>map</code> 和 <code>grep</code> 接受一个列表并返回一个列表，所以只要你需要对一个列表进行操作，就可以通过链式调用来实现。</p>
<h3 id="reduce--化整为零"><code>reduce</code> : 化整为零</h3>
<p><code>reduce</code> 也接受一个函数和一个 list，但它使用函数将 list 的所有元素合并成一个结果。所以函数必须接受两个参数。第二个参数是从列表中取出的元素，第一个参数作为状态变量来组合所有元素。例如，计算一个数字列表的和:</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \sum = reduce sub (\acc,\elt) {acc+elt}, 1 .. 10;

say sum; #=&gt; says 55
# Python
from functools import reduce

sum = reduce(lambda acc,elt: acc+elt, range(1,11))

print( sum); #=&gt; says 55
</code></pre><p>这里发生的情况是，首先将 <code>acc</code> 设置为列表中的第一个元素(1)，然后加上第二个元素，所以 <code>acc</code> 变成 1+2=3；然后加上第三个元素(3)，以此类推。其效果是将列表中的所有数字连续相加。</p>
<p>为了更清楚地说明这一点，我们来写一个我们自己的 <code>reduce</code> 版本。</p>
<h3 id="编写你自己的">编写你自己的</h3>
<p>在许多函数式语言中，从左到右（从最低索引开始）和从右到左（从最高索引开始）的还原是有区别的。这一点很重要，因为根据做还原的函数，如果从左边或右边消耗列表，结果可能会不同。例如，假设我们的化简函数是</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
-&gt; \x,\y {x+y}
# Python
lambda x,y: x+y
</code></pre><p>那么我们从哪个方向遍历列表并不重要。但考虑以下函数:</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
-&gt; \x,\y { x &lt; y ?? x+y !! x }

# Python
lambda x,y: x+y if x&lt;y else x
</code></pre><p>( <code>... ?? ... !! ...</code> 是条件操作符的 Raku 句法，在大多数其他语言中是 <code>... ? ... : ...</code> 在 Python 中是 <code>... if ... else ...</code>)。</p>
<p>在这种情况下，如果列表从左或从右还原，结果会有所不同。在 Raku 和 Python 中，<code>reduce</code> 是一种从左到右的还原。</p>
<p>另外，<code>reduce</code> 函数可以不使用列表的第一个元素，而是取一个额外的参数，通常称为累加器。在函数式语言中，<code>reduce</code> 通常被称为 <code>fold</code>，所以我们可以有一个左折和一个右折。让我们来看看如何实现这些。</p>
<h4 id="left-fold">Left fold</h4>
<p>实现左折的直接方法（所以和 <code>reduce</code> 一样）是在函数内部使用 <code>for</code> 循环。这意味着我们必须在循环的每次迭代上更新累加器的值。在 Raku 中，无符号变量是不可变的（我在这里简化了，完整的故事请看 <a href="https://docs.raku.org/language/containers#Binding">Raku 文档</a>），所以我们需要使用一个有符号的变量，<code>$acc</code>。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub foldll (&amp;f, \iacc, \lst) { 
  my $acc = iacc; 
  for lst -&gt; \elt {
    $acc = f($acc,elt);
  }
  $acc;
}

# Python
def foldll (f, iacc, lst):
  acc = iacc
  for elt in lst:
    acc = f(acc,elt)  
  return acc
</code></pre><p>如果我们只想使用不可变的变量，我们可以使用递归。Raku 使这一点变得简单，因为它允许一个子程序有多个签名(<code>multi sub</code>)，并且它会调用与签名相匹配的变量。</p>
<p>我们的 <code>foldl</code> 将消耗输入列表 <code>lst</code>，并使用 <code>f</code> 将其元素组合到累加器 <code>acc</code> 中，当列表被消耗后，计算结束，我们可以返回 <code>acc</code> 作为结果。所以我们的第一个变体说，如果输入列表是空的，我们应该返回 <code>acc</code>。 第二个变体从列表中取出一个元素 <code>elt</code> (关于 <code>*</code> 的细节请参见 <a href="https://docs.raku.org/type/Range">Raku 文档</a>)，并将其与 <code>acc</code> 结合到 <code>f(acc,elt)</code> 中。然后用这个新的累加器和 list 的剩余部分 <code>rest</code> 再次调用 <code>foldl</code>。</p>
<pre><code class="language-perl6" data-lang="perl6"># When the list is empty, return the accumulator
multi sub foldl (&amp;f, \acc, ()) { acc }
multi sub foldl (&amp;f, \acc, \lst) {
  # Raku's way of splitting a list in the first elt and the rest
  # The '*' is a shorthand for the end of the list
   my (\elt,\rest) = lst[0, 1 .. * ]; 
   # The actual recursion
   foldl( &amp;f, f(acc, elt), rest);
}
</code></pre><p>Python 不允许这种模式匹配，所以我们需要使用条件来编写递归。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">foldl</span> <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">lst</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">lst</span> <span class="o">==</span> <span class="p">():</span> 
    <span class="k">return</span> <span class="n">acc</span> 
  <span class="k">else</span><span class="p">:</span>
  <span class="c1"># Python&#39;s way of splitting a tuple in the first elt and the rest</span>
  <span class="c1"># rest will be a list, not a tuple, but we&#39;ll let that pass</span>
   <span class="p">(</span><span class="n">elt</span><span class="p">,</span><span class="o">*</span><span class="n">rest</span><span class="p">)</span> <span class="o">=</span> <span class="n">lst</span> 
   <span class="c1"># The actual recursion</span>
   <span class="k">return</span> <span class="n">foldl</span><span class="p">(</span> <span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">elt</span><span class="p">),</span> <span class="n">rest</span><span class="p">)</span>
</code></pre></div><p>在这个实现中，所有的变量都不会被更新。所以所有的变量都可以是不可变的。</p>
<h4 id="right-fold">Right fold</h4>
<p>右折与左折颇为相似。对于基于循环的版本，我们所做的只是将列表反转(<code>reverse</code>)。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub foldrl (&amp;f, \acc, \lst) { 
  my $res = acc;
  for  lst.reverse -&gt; \elt {
    $res = f($res,elt);
  }
  $res;
}

# Python
def foldlr (f, iacc, lst):
  acc = iacc
  for elt in lst.reverse():
    acc = f(acc,elt)  
  return acc
</code></pre><p>在递归版本中，我们从列表中取最后一个元素而不是第一个元素。关于 <code>..^ * - 1</code> 语法的细节，请参见 <a href="https://docs.raku.org/language/operators#infix_..%5E">Raku 文档</a>。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
multi sub foldr ( &amp;f, \acc, ()) { acc }
multi sub foldr (&amp;f, \acc, \lst) {
    my (\rest,\elt) = lst[0..^*-1, *  ];
    foldr( &amp;f, f(acc, elt), rest);
}

# Python
def foldr (f, acc, lst):
  if lst == (): 
    return acc 
  else:
   (*rest,elt) = lst 
   return foldr( f, f(acc, elt), rest)
</code></pre><h4 id="map-and-grep-are-folds"><code>map</code> and <code>grep</code> are folds</h4>
<p>现在，<code>map</code> 和 <code>grep</code> 呢？我们当然可以用 <code>for</code> 循环来实现，但我们也可以用我们的 <code>foldl</code> 来实现它们。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub map (&amp;f,\lst) {
    foldl( sub (\acc,\elt) {
            (|acc,f(elt))
            }, (), lst);
}

# Python
def map (f,lst):
    return foldl( 
      lambda acc,elt:(*acc, f(elt))
      ,()
      ,lst
    )
</code></pre><p>因为函数 <code>f</code> 是可映射的，所以它只有一个参数。但是 <code>foldl</code> 需要一个有两个参数的函数，第一个参数为累加器。所以我们用两个参数的匿名函数调用 <code>foldl</code>。累积器本身是一个空列表。虽然我们前面说过，还原将原来列表的所有元素合并成一个返回值，当然这个返回值可以是任何数据类型，所以也是一个列表。所以我们对原始列表中的每一个元素都调用 <code>f</code>，并将其添加到累加器列表的末尾。(<code>|</code> 将列表扁平化，所以 <code>(|acc,f(elt))</code> 是一个由 <code>acc</code> 的元素和 <code>f(elt)</code> 的结果建立的新列表。)</p>
<p>类似地，我们也可以定义 <code>grep</code>:</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub grep (&amp;f,\lst) {
    foldl( sub (\acc,\elt) {
      if (f(elt)) {
          (|acc,elt)
      } else {
          acc
      }
    }, (), lst);
}

# Python
def filter (f,lst):
    return foldl( 
      lambda acc,elt:
        (*acc,elt) if f(elt) else acc
      , (), lst)
</code></pre><p>就像在 <code>map</code> 实现中一样，我们用一个匿名函数调用 <code>foldl</code>。在这个函数中，我们测试 <code>lst</code> 中的每个 <code>elt</code> 是否为 <code>f(elt)</code> 为真。如果是真，我们就从 <code>acc</code> 和 <code>elt</code> 创建一个新的列表，否则我们就只返回 <code>acc</code>。 因为 <code>map</code> 和 <code>grep</code> 分别对列表中的每个元素进行操作，所以我们也可以使用右折来实现它们。</p>
<p>通过这些例子，我希望无论是对函数工作的概念，还是对函数可能的实现方式，都变得更加清晰。递归实现的优点是它允许我们使用不可变的数据结构。</p>
<h3 id="为什么是不可变的数据结构">为什么是不可变的数据结构？</h3>
<p>你可能会好奇为什么我关注这些不可变的数据结构。正如我们将看到的那样，函数式编程与不可改变的数据结构配合得非常好。而且它们有一个很大的优势：你永远不用担心是否不小心修改了你的数据，也不用担心是否应该做一个副本来确定。所以使用不可变数据结构可以使代码不易出错，更容易调试。它们还具有潜在的性能优势。而我们接下来会看到，在 Raku 中还有另一个优势。</p>
<h2 id="返回函数的函数">返回函数的函数</h2>
<p>函数也可以返回函数。如果我们想拥有一个可参数化的函数，这一点尤其有用。举个简单的例子，假设我们想要一系列以固定值递增一个数字的函数：<code>add1</code>、<code>add2</code> 等。当然，我们可以分别写出每一个函数。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub add_1 (\x) {x+1}
sub add_2 (\x) {x+2}
sub add_3 (\x) {x+3}
sub add_4 (\x) {x+4}
sub add_5 (\x) {x+5}

say add_1(4); #=&gt; says 5
# Python
def add_1 (x) : return x+1
def add_2 (x) : return x+2
def add_3 (x) : return x+3
def add_4 (x) : return x+4
def add_5 (x) : return x+5

print( add_1(4)) #=&gt; says 5
</code></pre><p>或者我们可以使用一个充满匿名函数的列表。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \add =
sub (\x) {x},
sub (\x) {x+1},
sub (\x) {x+2},
sub (\x) {x+3},
sub (\x) {x+4},
sub (\x) {x+5};

say add[0].(4); #=&gt; says 5


# Python
add = (
lambda x : x+1,
lambda x : x+2,
lambda x : x+3,
lambda x : x+4,
lambda x : x+5
)

print( add[0](4)) #=&gt; says 5
</code></pre><p>我们可以做得更好，用一个循环来填充一个匿名函数的数组。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \add = [];
for 0 .. 5 -&gt; \n {
  add.push(sub (\x) {x+n});
}

say add[1].(4); #=&gt; says 5

# Python
add = []
for n in range(0,6):
  add.append(lambda x: x+n)
</code></pre><p>我们每次循环迭代都会创建一个新的匿名函数，并将其添加到数组中。但是，我们可以使用一个函数来创建这些匿名函数，然后我们可以使用 <code>map</code> 来代替循环，并使用一个不可改变的数据结构。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub gen_add(\n) {  
  sub (\x) {x+n}
}

my \add = map &amp;gen_add, 0..5;

say add[1].(4); #=&gt; says 5

# Python
def gen_add(n):  
  return lambda x : x+n

add = tuple(map( gen_add, range(0,6)))

print( add[1](4)) #=&gt; says 5
</code></pre><h3 id="laziness">Laziness</h3>
<p>在 Raku 中，使用(不可改变的)范围有一个额外的好处：我们可以将范围的末端设置为无穷大，在 Raku 中可以写成 <code>∞</code>(unicode 221E)、<code>*</code> 或 <code>Inf</code>。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
my \add = map &amp;gen_add, 0 .. ∞;  

say add[244].(7124); #=&gt; says 7368
</code></pre><p>这是一个所谓的&quot;懒惰求值&quot;的例子，简称 laziness：Raku 不会尝试（和失败）处理这个无限的列表。相反，它将在我们实际使用该列表中的一个元素时进行处理。表达式的评估会延迟到需要结果的时候，所以当我们调用 <code>add[244]</code> 时，发生的情况是 <code>gen_add(244)</code> 被调用来生成该函数。请注意，这在 <code>for</code> 循环中是行不通的，因为要使用 <code>for</code> 循环，我们需要一个可变的数据结构，而惰性列表必须是不可变的。所以这是一个很好的例子，说明函数式编程风格如何让你从懒惰中获益。</p>
<p>这也是为什么我们递归地实现了 <code>foldl</code>，然后用它来实现我们自己的 <code>map</code> 和 <code>grep</code>：基于递归的版本不需要更新任何变量，所以它们可以与不可变的惰性数据结构一起工作。</p>
<h2 id="函数组合">函数组合</h2>
<p>我们在上面看到，你可以把 <code>map</code> 和 <code>grep</code> 的调用链在一起。通常情况下，你只需要将 <code>map</code> 调用链在一起，例如</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
map -&gt; \x { x + 5 }, map -&gt; \x {x*x}, 1..30;

# Python
map( lambda x : x + 5, map( lambda x : x*x, range(1,31)))
</code></pre><p>在这种情况下，我们可以做得更有效率一些：比起创建一个列表，然后在这个列表上调用 <code>map</code>，我们可以通过组合函数一次完成两个计算。Raku 为此提供了一个特殊的操作符。</p>
<pre><code class="language-perl6" data-lang="perl6">map -&gt; \x { x + 5 } ∘ -&gt; \x { x * x }, 1..30;
</code></pre><p>操作符 <code>∘</code>（&ldquo;环形操作符&rdquo;，unicode 2218，但你也可以用普通的 <code>o</code>）是函数组成操作符，它的发音是 &ldquo;after&rdquo;，所以 <code>f ∘ g</code> 是 &ldquo;f after g&rdquo;。它的作用是将两个现有的函数组合起来，创建一个新的函数。</p>
<pre><code class="language-perl6" data-lang="perl6">my &amp;h = &amp;f ∘ &amp;g;
</code></pre><p>是下面的代码是一样的:</p>
<pre><code class="language-perl6" data-lang="perl6">sub h (\x) {
    f(g(x))
}
</code></pre><p>组成运算符的优点是，它可以适用于任何函数，包括匿名函数。但实际上，它只是另一个高阶函数。它只是下面函数的运算符形式。</p>
<pre><code class="language-perl6" data-lang="perl6"># Raku
sub compose(&amp;f,&amp;g) {
    sub (\x) { f(g(x)) }
}
</code></pre><p>Python 没有函数组成操作符，但你也可以很容易地在 Python 中拥有 <code>compose</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Python</span>
<span class="k">def</span> <span class="nf">compose</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">g</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div><h2 id="结论">结论</h2>
<p>在这篇文章中，我用 Raku 和 Python 的例子介绍了三种关键的函数式编程技术：对函数进行操作的函数、返回函数的函数和函数组成。我已经展示了你如何使用函数 <code>map</code>、<code>reduce</code>(折叠)和 <code>grep</code>(过滤)来操作不可变的列表。我已经解释了哟(如何用递归和不递归实现这样的函数，以及递归实现的优势是什么。下面是《 <a href="https://github.com/wimvanderbauwhede/raku-examples/blob/master/decluttering-with-functional-programming.raku">Raku</a> 与 <a href="https://github.com/wimvanderbauwhede/raku-examples/blob/master/decluttering-with-functional-programming.py">Python</a>》一文中的代码。</p>
<p>当然，函数式编程的内容还有很多，我也写了<a href="https://wimvanderbauwhede.github.io/articles/">几篇更高级的文章</a>。本文介绍的概念应该为理解那些更高级的主题打下良好的基础。如果你想了解更多关于函数式编程的知识，你可以考虑我的<a href="https://www.futurelearn.com/courses/functional-programming-haskell">免费在线课程</a>。</p>
<p>原文: <a href="https://wimvanderbauwhede.github.io/articles/decluttering-with-functional-programming/">https://wimvanderbauwhede.github.io/articles/decluttering-with-functional-programming/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/raku" term="raku" label="raku" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/functional-programming" term="functional-programming" label="functional programming" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Checklist for Raku 6.d]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-21-checklist-for-6-dot-d/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-21-checklist-for-6-dot-d/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-21T00:00:00+08:00</published>
            <updated>2020-07-21T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Checklist for 6.d</blockquote><h2 id="问题">问题</h2>
<p>在 6.d 版本中, 很多东西都发生了变化, 我们至少需要发布一个版本。<a href="https://github.com/perl6/roast/blob/master/docs/announce/6.d.md">这里有个列表</a>。然而, 覆盖面是不完整的。弃用通知采取了不同的形式, 一些新的类型和方法在那里, 一些则没有&hellip;&hellip;</p>
<p>用 <code>#2632</code> 引用这个问题, 并检查项目, 当你的工作, 无论是通过改变后的文档, 看到没有变化, 需要做它。在这种情况下, 请通过评论或如何解释为什么是这种情况。</p>
<h2 id="版本控制的变更">版本控制的变更</h2>
<ul>
<li><strong>[6.d]</strong> <code>&amp;await</code> 在等待的时候不再阻塞线程</li>
<li><strong>[6.d]</strong> <code>whenever</code> 不在 <code>react</code> 抛出的词法作用域内</li>
<li><strong>[6.d]</strong> 在 <code>sub MAIN</code> 里面的 <code>$*ARGFILES</code> 总是由 <code>$*IN</code> 馈入</li>
<li><strong>[6.d]</strong> 结构(字面上的) <code>$()</code>、<code>@()</code> 和 <code>%()</code> 不复存在</li>
<li><strong>[6.d]</strong> 带有 <code>:D</code>/<code>:U</code> 类型约束的变量默认为约束类型的类型对象(例如, 你可以在它们身上使用 <code>.new</code>)</li>
<li><strong>[6.d]</strong> <code>start</code> 块在 sink 上下文中附加异常处理程序</li>
<li><del><strong>[6.d]</strong> 例程必须使用 <code>return-rw</code> 来返回一个 <code>Proxy</code>, 即使例程被标记为 <code>is raw</code> 或 <code>is rw</code></del></li>
<li><strong>[6.d]</strong> 原生的 <code>num</code> 类型默认为 <code>0e0</code> 而不是 <code>NaN</code></li>
<li><strong>[6.d]</strong> 在子程序名中, 保留了键名为 <code>sym</code> 的冒号对（如<code>:sym&lt;foo&gt;</code>）, 以备将来使用</li>
</ul>
<h2 id="废弃">废弃</h2>
<p>这些方法在 6.d 语言中已被废弃, 并将在 6.e 中被删除。实现者可以选择发出弃用警告, 或者在 6.e 版本发布后更长的时间内提供这些方法。</p>
<ul>
<li>使用 <code>'-'</code> (单连字符)作为 <code>&amp;open</code> 的特殊路径, 表示特殊的句柄(使用 <code>IO::Special</code> 对象代替)</li>
<li><code>IO::Handle.slurp-rest</code> (使用 <code>.slurp</code> 代替)</li>
<li><code>Any.flatmap</code> (使用<code>.flat</code> 和 <code>.map</code> 方法的组合来代替)</li>
<li><code>Cool.path</code> (使用 <code>.IO</code> 代替)</li>
<li><code>Pair.freeze</code> (使用去容器化的参数的 <code>Pair.new</code> 来代替)</li>
<li><code>Str.subst-mutate</code> (使用带有 <code>.=</code> 方法调用赋值元运算符的 <code>Str.subst</code> 代替)</li>
<li><code>Rational.norm</code> (现在 <code>Rational</code> 类型必须在创建时标准化)</li>
<li><code>IO::Path.child</code> (使用 <code>.add</code> 代替)</li>
<li><code>&amp;undefine</code> (直接分配 <code>Empty</code>/<code>Nil</code> 代替)</li>
<li><code>:count</code> <code>&amp;lines</code>/<code>Str.lines</code> 例程上的参数(使用所返回的 <code>Seq</code> 上的 <code>.elems</code> 代替)</li>
<li><code>&amp;is_approx</code> in Test.pm6 (使用与 <code>&amp;is-approx</code> 非常相似的行为来代替)</li>
</ul>
<h2 id="新的行为">新的行为</h2>
<ul>
<li>通过新的可定义的 <code>&amp;RUN-MAIN</code>、<code>&amp;ARGS-TO-CAPTURE</code> 和 <code>&amp;GENERATE-USAGE</code> 子例程改善 <code>sub MAIN</code> 的自定义处理</li>
<li><code>%</code> 变量中的 <code>QuantHash</code>/<code>Map</code> 和 <code>@</code> 变量中的 <code>List</code> 可以用 <code>is</code> 特性来声明（例如，<code>my %h is Set</code>）</li>
<li>新的 <code>&lt;ww&gt;</code> regex 规则: 只在单词内匹配</li>
<li>循环可以从上一条语句的值中产生一个值的列表</li>
<li>循环中的 <code>next</code>/<code>last</code> 收集其最后的语句值, 对它们运行的迭代返回 <code>Empty</code></li>
<li><code>.perl</code> 可以在消耗过的 <code>Seq</code>、多维数组、<code>Date</code> 和 <code>CallFrame</code> 上调用</li>
<li><code>.gist</code> 可以在 <code>Attribute</code> 上调用</li>
<li>对自动生成的 <code>USAGE</code> 信息进行了大量改进</li>
<li><code>is hidden-from-USAGE</code> 特性，从自动生成的 <code>USAGE</code> 消息中隐藏 <code>sub MAIN</code> 候选者</li>
<li><code>Parameter.perl</code> 包括可内省的默认值</li>
<li><code>%*ENV</code> 值是同素异形的</li>
<li>尝试使用变量 <code>$;</code>、<code>$,</code>、<code>$.</code>、<code>$\</code>、<code>$(</code>、<code>$)</code>、<code>$&lt;</code>、<code>$&gt;</code>、<code>$/</code>、<code>$\</code>、<code>$[</code>、<code>$-</code>、<code>$+</code> 和 <code>$@</code> 会抛出 <code>X::Syntax::Perl5Var</code></li>
<li>默认的 <code>Hash.keyof</code> 返回一个 <code>Str(Any)</code> 强转类型对象</li>
<li>非 ASCII 数字可以在 <code>:42foo</code> 冒号对快捷方式中使用</li>
<li><code>StrDistance</code> 字符串化为 <code>.after</code> 字符串</li>
<li>更明确的 Pod 表格格式</li>
<li><code>Enumeration.enums</code> 返回一个 <code>Map</code></li>
<li>各种整数类型的 <code>.Range</code> 返回它们支持的值的范围</li>
<li><code>min</code>/<code>max</code>  例程也适用于 <code>Hash</code></li>
<li><code>Signature</code> 字面值可以包含字符串/数字字面值以及调用者标记</li>
<li><code>List.invert</code> 通过所需的 <code>Pair</code> 绑定映射, 导致潜在的类型检查失败</li>
<li><code>:exists</code> 可以与多维关联下标一起使用</li>
<li>动态创建的列表可以用来定义一个枚举</li>
<li>在 <code>.first</code> 中, Junction 可以作为匹配器使用</li>
<li>原生属性可以作为参数中的绑定目标</li>
<li><code>Proc</code> 可以与其他 <code>Proc</code> 中的 <code>IO::Pipe</code> 一起工作</li>
<li>类型数组可以用 <code>my SomeType @array</code> 和 <code>my @array of SomeType</code> 创建</li>
<li>当把 <code>Mixy</code> 强转为 <code>Setty</code>/<code>Baggy </code> 时, 负数权重的项将被删除</li>
<li><code>:nth</code> 副词在 <code>m//</code> 上接受一个 <code>Junction</code> 作为参数</li>
<li><code>CX::Warn' 和 </code>CX::Done<code>可以在</code>CONTROL` phaser 中捕获</li>
<li><code>next</code> 可用于 <code>whenever</code> 中</li>
<li><code>require</code> 符号不再过境性地暴露出来</li>
<li>通过 <code>{...}</code> 进行多维访问, 类似于 <code>[...]</code> 的工作方式</li>
<li>在 <code>END</code> 时间打开的任何手柄都会自动关闭</li>
<li>在缓存的 <code>Seq</code> 上, 当 <code>&amp;infix:&lt;eqv&gt;</code>、<code>.Slip</code>、<code>.join</code>、<code>.List</code>、<code>.list</code>、<code>.eager</code>、<code>.Array</code> 和 <code>.is-lazy</code> 被调用时, 就会使用缓存列表</li>
<li><code>IO::Handle.encoding</code> 以 <code>Nil</code> 表示切换到二进制模式</li>
<li><code>is default</code> 特质与属性一起工作</li>
<li>在多重分派中, 带有 <code>is rw</code> 特性的参数被认为比没有特性的参数窄</li>
<li><code>Array</code>、<code>Blob</code> 和 <code>Map</code> 的 <code>.gist</code> 被裁剪成100个元素</li>
<li>新的 <code>for</code> 语句修饰符 <code>hyper for</code>、<code>race for</code> 和 <code>lazy for</code></li>
<li><code>for</code> 循环自动序列化 <code>RaceSeq</code>/<code>HyperSeq</code>；使用新的 <code>for</code> 语句修饰符<code>hyper for</code>/<code>race for</code>避免</li>
<li><code>&amp;infix:&lt;does&gt;</code> 可用于 RHS 上的非组合实例</li>
<li>数值比较器可以与 <code>DateTime </code> 对象一起使用</li>
<li><code>Pod</code> 保留空白类型</li>
<li>定义了带 <code>@</code>、<code>%</code> 和 <code>&amp;</code> 魔符常数的语义</li>
</ul>
<h2 id="math">Math</h2>
<ul>
<li><code>Rational</code> 总是在创建时被化简, 并在其一生中保持不变</li>
<li><code>Inf</code>、<code>Inf</code> 和 <code>NaN</code> 可以分别用 <code>&lt;-1/0&gt;</code>、<code>&lt;1/0&gt;</code> 和 <code>&lt;0/0</code>&gt; 表示, 通过<code>Rational</code> 类型进行舍去。零分母 <code>Rational</code> 被标准化为这三个值之一</li>
<li>在 ±<code>Inf</code> 和 <code>NaN</code> 上调用 <code>.Int</code>, 会抛出异常</li>
<li>改进了 <code>Num</code> 运算符和数学函数的 IEEE 754-2008 合规性</li>
<li>负零 <code>Num</code>(<code>-0e0</code>)被所有例程和语法结构正确处理</li>
<li><code>Num</code> 类型的字符串化必须是可舍弃到原始 <code>Num</code> 的</li>
<li>定义了涉及零的 <code>Complex </code> 指数</li>
<li><code>.expmod</code> 中的负数幂有效</li>
</ul>
<h2 id="setsbagsmixesaka-quanthashes和集合运算符">Sets、Bags、Mixes(aka QuantHashes)和集合运算符</h2>
<ul>
<li>Set 运算符可以用在任何对象上, 在需要的时候会被强转
<ul>
<li>所以, 不需要也不希望有任何预先的强转</li>
<li>如果没有 QuantHash 就能实现所需的功能, 那么 Set 运算符可以自由地不创建任何 QuantHash</li>
</ul>
</li>
<li>对不同类型的 QuantHashes 的 Set 操作将强转到最自由的形式（Set -&gt; Bag -&gt; Mix）</li>
<li>集合运算符的 set_precedes 家族( <code>(&lt;+)</code>、<code>≼</code>、<code>(&gt;+)</code>、<code>≽</code>) 已被移除
<ul>
<li>曾经是子集运算符的 Baggy 形式</li>
<li>QuantHash 升级为最自由的形式, 所以 <code>(&lt;=)</code>、<code>⊆</code>、<code>(&gt;=)</code>、<code>⊇</code> 做正确的事情</li>
</ul>
</li>
<li><code>.classify-list</code> 方法可用于 <code>Baggy</code> 类型</li>
<li><code>.categorize-list</code> 方法可用于 <code>Baggy</code> 类型</li>
<li><code>.invert</code> 方法可用于核心 <code>QuantHash</code> 类型</li>
<li><code>.antipairs</code> 方法可用于 <code>QuantHash</code> 类型</li>
<li><code>QuantHash</code> 类型有 <code>.new-from-pairs</code> 和将一个 <code>QuantHash</code> 类型转换为另一个 <code>QuantHash</code> 类型的方法(例如 <code>Set</code> 类型的 <code>.Bag</code> 方法)</li>
<li><code>QuantHash</code> 类型上的 <code>.hash</code> 对键值进行了字符串化</li>
</ul>
<h2 id="新的形参和实参">新的形参和实参</h2>
<ul>
<li><code>Date.new</code> 接受一个 <code>:&amp;formatter</code></li>
<li><code>.first</code> 可以接受 <code>:kv</code></li>
<li><code>unique</code> 和 <code>.repeated</code> 可以接受 <code>:&amp;as</code> 和 <code>:&amp;with</code></li>
<li>Test.pm6 中的 <code>&amp;plan</code> 可以接受 <code>:skip-all</code></li>
<li><code>&amp;run</code>/<code>&amp;shell</code> 可以接受 <code>:merge</code></li>
<li><code>&amp;note</code> 可以在没有参数的情况下调用</li>
<li><code>open</code> 接受 <code>:$out-buffer</code></li>
<li><code>IO::Path.resolve</code> 可以接受 <code>:completely</code></li>
<li><code>IO::Path.parent</code> 可以接受一个 <code>Int</code> 表示父级</li>
<li><code>Proc::Async.new</code> 吞噬位置参数</li>
<li><code>Signature.ACCEPTS</code> 接受非 <code>Signature</code>/<code>Capture</code> 参数</li>
<li><code>&amp;EVAL</code> 可以接受一个 <code>Blob</code></li>
<li><code>Promise.keep</code>/<code>.break</code> 可以在没有参数的情况下调用</li>
<li>原生数组上的 <code>.sum</code> 可以接受 <code>:wrap</code></li>
<li><code>is required</code> 现在可以接受一个表示理由的参数</li>
<li><code>IO::Socket::Async.listen</code> 可以绑定到端口 <code>0</code> 以向操作系统申请免费端口</li>
<li><code>.encode</code> 可以接受 <code>:translate-nl</code></li>
</ul>
<h2 id="新的例程和运算符">新的例程和运算符</h2>
<ul>
<li>新的 <code>atomicint</code> Unicode 运算符和 ASCII 等价物, 保证线程安全, 原子操作:
<code>&amp;infix:&lt;⚛=&gt;</code>/<code>&amp;atomic-assign</code>、<code>&amp;prefix:&lt;⚛&gt;</code>/<code>&amp;atomic-fetch</code>、
<code>&amp;prefix:&lt;++⚛&gt;</code>/<code>&amp;atomic-inc-fetch</code>、<code>&amp;postfix:&lt;⚛++&gt;</code>/<code>&amp;atomic-fetch-inc</code>、
<code>&amp;prefix:&lt;--⚛&gt;</code>/<code>&amp;atomic-dec-fetch</code>、<code>&amp;postfix:&lt;⚛--&gt;</code>/<code>&amp;atomic-fetch-dec</code>、
<code>&amp;infix:&lt;⚛-=&gt;</code>/<code>&amp;infix:&lt;⚛−=&gt;</code>/<code>&amp;atomic-fetch-sub</code> 和 <code>&amp;infix:&lt;⚛+=&gt;</code>/<code>&amp;atomic-fetch-add</code></li>
<li><code>&amp;cas</code>: 原子比较与交换</li>
<li><code>≤</code>、<code>≥</code> 和 <code>≠</code> 运算符是 Unicode 运算符, 分别等价于 <code>&lt;=</code>、<code>&gt;=</code> 和 <code>!=</code></li>
<li><code>&amp;infix:&lt;unicmp&gt;</code>/<code>&amp;infix:&lt;coll&gt;</code>: <code>&amp;infix:&lt;cmp&gt;</code> 的替代行为</li>
<li><code>TR///</code>: <code>tr///</code> 的非变异版本</li>
<li><code>submethod TWEAK</code>: 与 <code>BUILD</code> 类似, 除了它与属性默认值兼容之外</li>
<li><code>&amp;duckmap</code>: 应用 <code>&amp;callable</code> 到每个元素上</li>
<li><code>&amp;deepmap</code>: 应用 <code>&amp;callable</code> 到每个元素上, 下降到 <code>Iterable</code> 中</li>
<li><code>&amp;take-rw</code>: 像 <code>&amp;take</code> 一样, 但有一个可写的容器</li>
<li><code>&amp;indir</code>: 在给定的 <code>$*CWD</code> 中执行代码</li>
<li><code>&amp;spurt</code>: 参见 <code>IO::Path.spurt</code></li>
<li><code>&amp;prompt</code>: 提示用户输入</li>
<li><code>uniprops</code>: <code>uniprop</code> 的多字符版本</li>
<li><code>symlink</code>: 建立文件符号链接</li>
<li><code>link</code>: 创建文件硬连接</li>
<li><code>.hyper</code>/<code>.race</code>: 并行处理值的列表</li>
<li><code>Seq.from-loop</code>: 从 <code>Callable</code> 生产一个 <code>Seq</code></li>
<li><code>Str.uniparse</code>: 将一个或多个 Unicode 字符名解析为实际字符</li>
<li><code>Str.parse-base</code>: <code>Int.base</code> 操作的反转</li>
<li><code>IO::Path</code> 提供了 <code>.ACCEPTS</code>、<code>.SPEC</code>、<code>.CWD</code>、<code>.Numeric</code>、<code>.add</code>、<code>.extension</code>、<code>.mode</code> 和各种文件测试、<code>.parts</code>、<code>.sibling</code> 和 <code>.spurt</code></li>
<li><code>IO::Handle</code> 提供了 <code>.READ</code>、<code>.WRITE</code>、<code>.EOF</code>、<code>.DESTROY</code>,
<code>.readchars</code>、<code>.flush</code>、<code>.lock</code>、<code>.unlock</code>、<code>.out-buffer</code>、<code>.tell</code>,
<code>.say</code>、<code>.slurp</code>、<code>.seek</code>、<code>.printf</code>、<code>.print-nl</code> 和 <code>.watch</code></li>
<li><code>IO::Pipe</code> 提供了 <code>.proc</code></li>
<li><code>Iterator</code> 提供了 <code>.skip-one</code>、<code>.skip-at-least</code> 和 <code>.skip-at-least-pull-one</code></li>
<li><code>Mu.emit</code>: <code>&amp;emit</code> 的方法形式</li>
<li>Test.pm6 模块中的 <code>&amp;fails-like</code>: 允许测试失败</li>
<li>Test.pm6 模块中的 <code>&amp;bail-out</code>: 退出失败的测试套件</li>
<li>Test.pm6 模块中的 <code>&amp;is-approx</code>: 测试一个数字近似于另一个</li>
<li><code>Buf</code> 拥有 <code>.allocate</code>、<code>.reallocate</code>、<code>.append</code>、<code>.push</code>、<code>.pop</code>、<code>.splice</code>、<code>.subbuf-rw</code>、<code>.prepend</code> 和 <code>.unshift</code> 方法</li>
<li><code>Range</code> 支持了 <code>.rand</code></li>
<li><code>Backtrace</code> 拥有方法 <code>.map</code>、<code>.flat</code>、<code>.concise</code> 和 <code>.summary</code></li>
<li><code>.classify-list</code> 方法可用于 <code>Hash</code> 类型</li>
<li><code>.categorize-list</code> 方法可用于 <code>Hash</code> 类型</li>
<li><code>Code.of</code>: 返回返回类型约束</li>
<li><code>Code.line</code>/<code>.file</code>: 返回定义的行/文件</li>
<li><code>Proc::Async</code> 提供了 <code>.Supply</code>、<code>.ready</code>、<code>.pid</code>、<code>.bind-stdin</code>、<code>.bind-stdout</code> 和 <code>.bind-stderr</code></li>
<li><code>Proc.command</code>/<code>Proc::Async.command</code>: 我们要执行的命令</li>
<li><code>Proc</code> 提供了 <code>.signal</code>、<code>.pid</code> 和 <del><code>.encoding</code></del></li>
<li><code>Complex</code> 提供了 <code>.cis</code>、<code>.reals</code>、<code>.ceiling</code>、<code>.floor</code>、<code>.round</code>、<code>.truncate</code> 和 <code>.abs</code> 方法, 并可以使用 <code>&lt;=&gt;</code> 进行比较(只要虚部可以忽略不计)</li>
<li><code>DateTime</code> 提供了 <code>.offset-in-hours</code>、<code>.hh-mm-ss</code> 和 <code>.Date</code></li>
<li><code>DateTime</code> 可以使用 <code>&lt;=&gt;</code> 运算符和其它 <code>DateTime</code> 对象进行比较</li>
<li><code>Date</code> 提供了 <code>.DateTime</code> 方法</li>
<li><code>&amp;infix:&lt;+&gt;</code>/<code>&amp;infix:&lt;-&gt;</code> 可以被 <code>Duration</code>、<code>DateTime</code> 和 <code>Real</code> 类型调用</li>
<li><code>Enumeration</code> 提供了 <code>.Int</code>、<code>.pred</code>、<code>.succ</code>、<code>.kv</code> 和 <code>.pair</code></li>
<li><code>.Date</code> 可以在 <code>Instant</code> 上调用</li>
<li>Junction 能使用 <code>Junction.new</code> 调用来创建</li>
<li><code>List</code> 类型拥有 <code>.to</code> 和 <code>.from</code> 方法</li>
<li><code>Map</code> type 提供了 <code>Int</code> 方法, 返回 pair 的数量</li>
<li><code>Any.skip</code>: 跳过列表中的值</li>
<li><code>Any.batch</code>: <code>.rotor</code> 的更基本的表兄弟</li>
<li><code>Mu.iterator</code>: 为一个列表中的值生成一个 <code>Iterator</code></li>
<li><code>IO::Spec::*</code> 类型提供了 <code>.tmpdir</code>、<code>.extension</code> 和 <code>.path</code></li>
<li><code>Pair</code> 提供了 <code>.ACCEPTS</code>、<code>.Pair</code> 和 <code>.invert</code></li>
<li><code>.Capture</code> 方法对所有核心类型都有明确定义</li>
<li>定义了 <code>.ACCEPTS</code> 在同素异形体上的语义</li>
<li><code>Failure.self</code> 使未处理的 <code>Failure</code> 爆发</li>
<li><code>Thread.is-initial-thread</code>: 我们是在初始线程中运行吗</li>
<li><code>Match</code> 提供了 <code>.Int</code> 和 <code>.actions</code></li>
<li><code>IO::Socket::Async</code> 提供了 <code>.socket-port</code> 和 <code>.peer-port</code></li>
<li><code>Promise</code> 提供了另一种构造函器 <code>.kept</code> 和 <code>.broken</code></li>
<li><code>WhateverCode</code> 提供了 <code>.assuming</code></li>
<li><code>WhateverCode</code> 和 <code>Block</code> 提供了 <code>.cando</code></li>
<li><code>.:&lt;…&gt;</code> 语法用于调用前缀运算符作为后缀</li>
<li><code>$*KERNEL</code> 提供了 <code>.hostname</code></li>
<li><code>Nil</code> 拥有定义的 <code>.FALLBACK</code> 特殊方法来返回 <code>Nil</code></li>
</ul>
<h2 id="新类型">新类型</h2>
<ul>
<li><code>atomicint</code>: 原生的 <code>int</code>, 大小可用于新的原子运算符</li>
<li><code>Lock::Async</code>: 互斥的非阻塞机制</li>
<li><code>Encoding::Registry</code>: 管理可用的编码</li>
<li><code>Encoding::Encoder</code>: 编码器, 用于特定的编码</li>
<li><code>Encoding::Decoder</code>: 解码器, 用于特定的编码</li>
<li><code>IO::CatHandle</code>: 将多个只读的 <code>IO::Handle</code> 视同一个</li>
<li>原生的 <code>str</code> 数组</li>
<li><code>Supplier::Preserving</code>: 缓存的实时 <code>Supply</code> 工厂</li>
<li><code>Semaphore</code>: 控制多线程对共享资源的访问</li>
<li><code>IO::Special</code>: 特殊I/O设备的路径 (例如 <code>STDOUT</code>)</li>
<li><code>Exceptions::JSON</code> 自定义异常处理程序的实现(可与<code>PERL6_EXCEPTIONS_HANDLER</code> 环境变量一起使用)</li>
<li><code>SeekType</code> 枚举: <code>IO::Handle.seek</code> 中使用的值</li>
</ul>
<h2 id="新的变量">新的变量</h2>
<ul>
<li>
<p><code>$*USAGE</code>: 可在 <code>MAIN</code> 子例程中使用, 包含自动生成的 <code>USAGE</code> 信息</p>
</li>
<li>
<p>%*SUB-MAIN-OPTS: 设置 <code>sub MAIN</code> 的行为</p>
<ul>
<li><code>%*SUB-MAIN-OPTS&lt;named-anywhere&gt;</code> 允许将命名参数放在命令行的任何位置</li>
</ul>
</li>
<li>
<p><code>$*COLLATION</code>: 配置四个 Unicode 校对级别</p>
</li>
<li>
<p><code>$*INIT-INSTANT</code>: 代表程序启动时间的 <code>Instant</code></p>
</li>
<li>
<p><code>$*HOME</code>: 用户的主目录, 如果存在的话</p>
</li>
<li>
<p><code>&amp;*chdir</code>: <code>Callable</code> 包含 <code>IO::Path.chdir</code> 的变体, 也设置进程的当前目录</p>
</li>
<li>
<p><code>PERL6_TEST_DIE_ON_FAIL</code> 环境变量: 在第一次失败时停止测试套件</p>
</li>
<li>
<p><code>PERL6_EXCEPTIONS_HANDLER</code> 环境变量: 指定自定义异常处理类</p>
</li>
</ul>
<h2 id="对边缘情况强转行为的澄清">对边缘情况/强转行为的澄清</h2>
<ul>
<li><code>UInt</code> 与 <code>Int</code> 类型对象智能匹配为 <code>True</code></li>
<li><code>sink</code> 语句前缀爆炸 <code>Failure</code></li>
<li>定义了1项和0项列表以及负参数和非整数参数的 <code>permutations</code>/<code>combinations</code> 的行为</li>
<li><code>&amp;val</code>、<code>Str.Numeric</code> 和其他 <code>Str</code> 数字转换方法在试图转换 Unicode <code>No</code> 字符组或合成数字时会 <code>fail</code></li>
<li><code>:42foo</code> 冒号对快捷方式中不能使用合成数字</li>
<li>现在、<code>Enumeration</code> 可以作为一个数组形状指定器使用</li>
<li>含有空格的 <code>Str</code> 的数值转换现在返回 <code>0</code></li>
<li>带空的模式参数的 <code>samark</code>, 简单地返回调用者</li>
<li><code>.polymod</code> 可用于 <code>lazy</code> 但有限的除数列表</li>
<li>定义了 <code>.[*-0]</code> 索引</li>
<li><code>.rotor</code> 中大于子列表的负数空隙抛出异常</li>
<li><code>.rotor</code> 的非 <code>Int</code> 参数被强转为 <code>Int</code> 参数</li>
<li>读取 <code>/proc</code> 文件时定义了 <code>.lines</code></li>
<li>定义了字符串上后缀/前缀  <code>++</code>/<code>--</code> 中泰语数字的行为</li>
<li>sunk <code>for</code> 里面的 <code>map</code> 被视为 sunk</li>
<li>Sunk <code>for</code> 循环将上一条语句的方法调用值下沉</li>
<li><code>Bool</code> 对象上的 <code>.Int</code> 返回一个 <code>Int</code> 对象</li>
<li><code>splice</code> 可用于扩展数组</li>
<li><code>classify</code> 可以与 <code>Junction</code> 配合使用</li>
<li><code>.pairup</code> on a type object returns an empty <code>Seq</code></li>
<li><code>.pairup</code> 总是返回一个 <code>Seq</code></li>
<li>拒绝接受  <code>Date</code>/<code>DateTime</code> 构造函数中的合成代码点</li>
<li><code>⸨</code>/<code>⸩</code> 对儿现在可以作为引号结构中的匹配字符使用</li>
<li><code>Array</code> 类型对象上的 <code>.flat</code> 简单地返回该类型对象</li>
<li>混合级 <code>classify</code> 在 <code>Hash</code> 上抛出异常</li>
<li><code>Junction</code> 可以用于给 <code>Hash</code> 指定多个键</li>
<li>给 <code>.classify-list</code> 的 <code>Callable</code> 现在保证每项只执行一次</li>
<li><code>:delete</code> 对 <code>Hash</code> 类型对象进行关联查找时返回 <code>Nil</code></li>
<li>Test.pm6 中的 <code>&amp;is-deeply</code> 会自动 <code>.cache</code> 作为参数的 <code>Seq</code>, 并使用返回的 <code>List</code> 进行测试</li>
<li><code>Complex.new()</code> 给出 <code>&lt;0+0i&gt;</code></li>
<li><code>Int.new</code> 现在可以保证构建一个新的 <code>Int</code> (而不是, 比如说, 从常量缓存中重用一个)</li>
<li>定义了一个参数(1-arg)版本的 <code>&amp;infix:&lt;=:=&gt;</code> 和 <code>&amp;infix:&lt;eqv&gt;</code></li>
<li>如果直接或间接地调用 <code>.BIND-POS</code>、<code>.BIND-KEY</code>、<code>.ASSIGN-POS</code>、<code>.ASSIGN-KEY</code>、<code>.STORE</code>、<code>.push</code>、<code>.append</code>、<code>.unshift</code>、<code>.prepend</code>、<code>Nil</code> 类型现在抛出异常</li>
<li><code>Nil.ord</code> 返回一个空的 <code>Seq</code></li>
<li><code>Nil.chrs</code> 返回一个 <code>&quot;\0&quot;</code></li>
<li><code>Num.new</code> 强转参数为 <code>Num</code></li>
<li><code>infix:&lt;Z&gt;()</code> 返回一个空的 <code>Seq</code></li>
<li><code>.comb</code> 总是返回一个 <code>Seq</code></li>
<li>用 <code>&amp;infix:&lt;+&gt;</code> 化简一个项, 简单地返回该项</li>
<li><code>()[0]</code> 返回 <code>Nil</code></li>
<li>允许在(可能是无限的) <code>Seq</code> 上使用 Regex 智能匹配</li>
<li>定义了 <code>Range</code> 对象的智能匹配</li>
<li><code>Set</code> 转换为<code>Mix</code>/<code>Bag</code> 不再有 <code>Bool</code> 权重</li>
<li>当一个或多个操作数为 <code>0</code> 时、<code>gcd</code> 是有定义的</li>
<li><code>defined</code> 例程中的 <code>Junction</code> 自动线程化</li>
<li><code>sum</code> 可以处理含有 <code>Junction</code> 的列表</li>
<li><code>Grammar.parse</code> 让顶级 <code>regex</code> 回溯</li>
<li><code>U+2212 MINUS SIGN [Sm] (-)</code> 现在得到更多结构的支持, 如 <code>Str.Numeric</code> 和 <code>&amp;val</code></li>
<li>Arity-1 <code>&amp;infix:&lt;~&gt;</code> 与 <code>Blob</code> 可以一起工作</li>
<li>在签名中, 所有的 <code>Numeric</code> 字面值都支持作为值字面值</li>
<li>正则表达式中的 <code>\b</code> 和 <code>\B</code> 抛出 <code>X::Obsolete</code></li>
<li><code>True</code> 和 <code>False</code> 作为签名中的值字面量发出警告</li>
<li><code>.sort</code> 和 <code>IO::Spec::Unix.path</code> 的返回值总是 <code>Seq</code></li>
<li><code>Range</code> 对象上的 Out-of-range <code>.AT-POS</code> 返回 <code>Nil</code></li>
<li>对于不存在的键、<code>Pair.AT-KEY</code> 返回 <code>Nil</code></li>
<li>所有的 <code>Cool</code> 类型都提供了 <code>.Rat</code>/<code>.FatRat</code> 强转器</li>
<li><code>IO::Path</code> 文件测试不缓存先前测试执行的结果</li>
<li><code>Seq</code> eqv <code>List</code> 仅根据类型不匹配就定为 <code>False</code></li>
<li><del><input disabled="" type="checkbox"> 在 <code>Hash </code>、<code>Hash </code> 和 <code>QuantHash</code> 上, 来自 <code>.kv</code>、<code>.values</code> 和 <code>.pair</code> 序列的值是可写的</del> 参见 <a href="https://github.com/Raku/roast/issues/614">Raku/roast#614</a> 和 <a href="https://github.com/Raku/doc/issues/3519">#3519</a></li>
<li><code>&amp;infix:&lt;∘&gt;</code>/<code>&amp;infix:&lt;o&gt;</code> 保留 LHF 的 <code>.of</code> 和 RHS 的 <code>.arity</code> 和 <code>.count</code></li>
<li>完善了 regex 运算符副词中的可接受参数(例如:<code>:in(…)</code>)</li>
<li>完善了 <code>IO::Handle.open</code> 中可接受的参数组合</li>
<li><code>IO::Path.Str</code> 不包含 <code>.CWD</code> 属性的值</li>
<li><code>IO::Path</code> 类型拒绝带有  <code>nul</code> 字节 (<code>&quot;\0&quot;</code>) 的路径</li>
<li><code>IO::Pipe</code> 的 <code>.path</code>/<code>.IO</code> 返回一个 <code>IO::Path</code> 类型对象</li>
<li>如果目的路径和源路径是一样的 <code>IO::Path</code> 的 <code>.copy</code>/<code>.move</code> 会 <code>fail</code></li>
<li><code>dir</code> 创建的 <code>IO::Path</code> 绝对性由调用者控制</li>
<li>更多定义的边缘行为、<code>Callable </code> 处理、<code>. defined</code> 调用, 以及 <code>&amp;infix:&lt;andthen&gt;</code>、<code>&amp;infix:&lt;orelse&gt;</code> 和 <code>&amp;infix:&lt;notandthen&gt;</code> 操作符的链接</li>
<li><code>Seq</code> 的禅切不缓存它们</li>
<li><code>List.Capture</code> 将任何包含的 <code>Pair</code> 对象的键字符串化</li>
<li>带处理的 <code>Failure</code> 参数的 <code>&amp;fail</code> 把它标记为是未处理的</li>
<li><code>use lib</code> 接受 <code>IO::Path</code> 对象</li>
<li>锚点 <code>^</code>、<code>^^</code>、<code>$</code> 和 <code>$$</code> 在环视中有效</li>
<li><code>Grammar.made</code> 支持类型对象</li>
<li><code>.isa</code> 支持 <code>subset </code> 类型对象</li>
<li><code>:delete</code> 可用于惰性数组</li>
<li><code>&amp;infix:&lt;eqv&gt;</code> 可以在某些情况下对惰性参数起作用</li>
<li>动态查询(<code>::(...)</code>) 是限制性的 regex 语法, 并且需要 <code>use MONKEY-SEE-NO-EVAL</code> 的许可</li>
<li>定义了带孔数组的 <code>.Slip</code> 和 <code>.List</code></li>
<li><code>Promise.in</code>/<code>.at</code> 和 <code>Supply.interval</code> 可以用零值和负值工作</li>
<li><code>Supply.interval</code> 最小值为 <code>0.001</code>；较低值被处理为 <code>0.001</code>, 并发出警告#, 参见 <a href="https://github.com/Raku/doc/pull/2649">https://docs.perl6.org/type/Supply#method_interval PR [#2649]</a></li>
<li><code>Supply</code> 提供了 <code>.Seq</code>、<code>.list</code> 和 <code>.zip</code></li>
<li>可以在构建方法中绑定到原生类型属性</li>
<li><code>WhateverCode</code> 传播 <code>use fatal</code></li>
<li><code>say</code>、<code>note</code>、<code>put</code>、<code>print</code> 和 <code>printf</code> 例程自动线程化 <code>Junction</code></li>
<li><code>IO::Handle.eof</code> 值在 <code>.seek</code> 过终点后再返回时也会相应改变</li>
<li>定义了 <code>.succ'、</code>.pred<code>和</code>.Bool` 的同质异形体</li>
<li>在核心 <code>Numeric</code> 上定义了 <code>.Bridge</code></li>
<li><del><input disabled="" type="checkbox"> 在核心 <code>Numeric</code> 的类型对象上定义了 <code>.Numeric</code>/<code>.Real</code></del></li>
<li>定义了关于零分母有理数的 <code>Rational.Bool</code></li>
<li><code>say</code>/<code>note</code> 保证在 <code>Str</code> 的子类上调用 <code>.gist</code></li>
<li>定义了 <code>Junction.Str</code> 返回 <code>Junction</code></li>
<li>定义了 <code>Junction.gist</code>/<code>.perl</code> 返回一个 <code>Str</code></li>
<li><code>Map</code>/<code>Hash</code> 的 <code>.list</code>/<code>.cache</code> 返回一个 <code>List</code></li>
<li>定义了 <code>.round</code> 的返回类型</li>
<li>定义了 <code>Enumeration:D</code>  不  <code>.ACCEPT</code> 一个 <code>Enumeration:U</code> , 参见 <a href="https://github.com/rakudo/rakudo/issues/2073">rakudo/rakudo#2073</a></li>
</ul>
<h2 id="杂项">杂项</h2>
<ul>
<li><code>IO::ArgFiles</code> 类型只是 <code>IO::CatHandle</code> 的一个空的子类</li>
<li>对常量的约束
<ul>
<li>约束是完全强制的</li>
<li>试图在常量上使用参数化类型约束(例如使用 <code>my Foo constant @int</code>) 会引发 <code>X::ParametricConstant</code> 异常</li>
</ul>
</li>
<li><code>Pod</code> <code>=defn</code>(定义列表)指令可用</li>
<li><code>Pod</code> 提供了 <code>:numbered</code> 配置键</li>
<li><code>.^ver</code>、<code>.^auth</code> 和 <code>.^name</code> 元方法在 <code>module</code> 中可用, 而在 <code>package</code> 中则没有, 这是设计上的原因</li>
<li><code>qww&lt;…&gt;</code> 中支持花哨的引号(<code>’…’</code>、<code>“…”</code>、<code>｢…｣</code> 和变体)</li>
<li><code>&amp;infix:&lt; &gt;</code> 支持查找自动生成的 <code>Callables</code> (例如: <code>&amp;infix:&lt;XX&gt;</code>)</li>
<li>使用命名的 <code>anon</code> 子例程不再产生重声明警告</li>
<li><code>::?MODULE</code>/<code>$?MODULE</code> 变量的扩展规范</li>
<li><code>sub MAIN</code> 可以接受一个参数上的 <code>Enumeration</code> 类型约束和 <code>where</code> 子句</li>
<li>笑脸型约束可以用在子集上</li>
<li><code>start</code> 块和 thunks 得到新的 <code>$/</code> 和 <code>$!</code></li>
<li>定义了与列表关联运算符一起使用的 <code>R</code> 元运算符</li>
<li>类型强转可以用在签名返回类型约束中</li>
<li><code>&amp;infix:&lt;x&gt;</code>/<code>&amp;infix:&lt;x&gt;</code> 抛出了 <code>-Inf</code>/<code>NaN</code> 重复参数</li>
<li>字面结构 <code>put</code> 和 <code>put for</code> 抛出, 需要使用括号</li>
<li>扩大了 Unicode 例程和功能的规范覆盖面-将覆盖面升级到 Unicode 第11版</li>
<li><code>$.</code> 方法调用语法能用在元方法中了</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/raku" term="raku" label="raku" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/6.d" term="6.d" label="6.d" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[ImageMagick - Drawing]]></title>
            <link href="https://ohmyweekly.github.io/notes/imagemagick-drawing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/imagemagick-notes/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick 笔记" />
                <link href="https://ohmyweekly.github.io/notes/imagemagick-transform/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick - Transform" />
            
                <id>https://ohmyweekly.github.io/notes/imagemagick-drawing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-05T00:00:00+08:00</published>
            <updated>2020-07-05T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>ImageMagick Drawing</blockquote><p><a href="https://imagemagick.org/Usage/draw/">https://imagemagick.org/Usage/draw/</a></p>
<p>在 IM 中绘图是在现有图像中添加新元素的方法。虽然在<a href="https://imagemagick.org/Usage/fonts/">复合字体效果</a>的示例页和<a href="https://imagemagick.org/Usage/annotating/">图像注释</a>中涵盖了很多文本绘制的内容，但本页涉及 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?draw">-draw</a>&rdquo; 操作符的其他更普遍的方面。</p>
<p>绘制命令最初是作为一种创建简单图像的手段。但随着时间的推移，它已经扩展成为矢量图形到光栅图像转换的界面。</p>
<h2 id="imagemagick-绘制命令">ImageMagick 绘制命令</h2>
<p>计算机中的图像通常以两种不同的方式保存。第一种也是你在这些示例页面中看到的最常见的方式被称为光栅图形。在这种方式中，图像是以像素的矩形阵列来存储的。</p>
<p>另一种方式不太常见，也不太容易修改，但从另一个意义上讲，它的通用性更强，即对象矢量图形。在这种形式下，图像是用线条、弧线、颜色填充，有时还有深度来描述的。这是非常有用的，因为你可以将这些图像放大到你想要的任何尺寸，而且它们仍然可以完美地显示。与光栅格式的图像相比，您还可以在很小的空间内描述非常大和复杂的图像。</p>
<p>矢量图形图像的例子包括 postscript 和新的 <a href="http://www.w3.org/TR/SVG/">SVG-可缩放矢量图形</a>。</p>
<p>True-Type 字体也是矢量图形的例子，因为它允许在任何比例下使用单个字符描述。</p>
<p>&ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?draw">-draw</a>&rdquo; 图像操作符，是进入 ImageMagick 矢量绘图功能的一个窗口，并形成了一套与 IM 的普通命令行图像操作符相当独立的命令。</p>
<blockquote>
<p>一般使用的矢量图形文件格式只有几种，因为每一种这样的格式通常与其他这样的格式有很大的不同。其结果是，很少有代码共享的可能。
基于这个原因，ImageMagick 更关注使用矢量图形来绘制 SVG 格式的图像。Postscript 和 true-type 字体图形被传递给其他外部的&quot;<a href="https://imagemagick.org/Usage/files/#delegate">代理</a>&ldquo;库和应用程序，它们更适合绘制这些类型的矢量图形格式。
这并不是说 SVG 没有代理库。一个例子是 RSVG 库或 GTK SVG 库，这些库在编译时是可用的。IM 会链接到这些库来转换 SVG，而不是自己尝试去做。</p>
</blockquote>
<h3 id="原始绘图命令">原始绘图命令</h3>
<p>让我们从 MVG 命令的 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?draw">-draw</a>&rdquo; 图像操作符中最古老、最简单、最常见的绘图原语开始。</p>
<p>请注意，所有的参数都被视为浮点数，不一定是整数，比如我在这些例子中通常使用的。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Single Pixel Draw  (两种方式 -- 这些像素点都被放大了)</span>

  <span class="c1"># Point &#39;paints&#39; the color pixel</span>
  convert -size 10x6 xc:skyblue  -fill black <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;point 3,2&#39;</span>         -scale 100x60   draw_point.gif

  <span class="c1"># Color Point &#39;replaces&#39; the color pixel</span>
  convert -size 10x6 xc:skyblue  -fill black <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 6,3 point&#39;</span>   -scale 100x60   draw_color_point.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_point.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_color_point.gif" alt="img"></p>
<p>根据给出的注释，当涉及半透明颜色时，这两种点方法会产生不同的结果。详情请参见下面的<a href="https://imagemagick.org/Usage/draw/#color">颜色填充原语</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># 矩形  /  圆角矩形  /  矩形圆弧</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;rectangle 20,10 80,50&#34;</span>       draw_rect.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;roundrectangle 20,10 80,50 20,15&#34;</span>  draw_rrect.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;arc  20,10 80,50  0,360&#34;</span>     draw_arc.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;arc  20,10 80,50 45,270&#34;</span>     draw_arc_partial.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_rect.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_rrect.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_arc.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_arc_partial.gif" alt="img"></p>
<p><code>arc</code> 绘制原语与矩形一起列出，因为它实际上只是一个&quot;椭圆&rdquo;，装在两个坐标定义的&quot;矩形&quot;(<code>rectangle</code>)内。部分弧线很少使用，因为很难确定端点，除非角度限制在九十度的倍数。</p>
<p><code>circle</code> 和 <code>ellipse</code> 原语涉及&quot;中心&quot;坐标与&quot;边缘&quot;坐标，或&quot;大小&quot;和&quot;角度&quot;值。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># 圆  /  椭圆    (以某一点为中心)</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;circle 50,30 40,10&#34;</span>          draw_circle.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;ellipse 50,30 40,20 0,360&#34;</span>   draw_ellipse.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;ellipse 50,30 40,20 45,270&#34;</span>   draw_ellipse_partial.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_circle.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_ellipse.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/draw_ellipse_partial.gif" alt="img"></p>
<p>你也可以看看 <a href="https://imagemagick.org/Usage/draw/#push_context">Push/Pop 上下文</a>，了解如何创建一个旋转的椭圆的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># 直线 / 折线 / 多边形 / 贝塞尔曲线</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;line   20,50 90,10&#34;</span>                 draw_line.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;polyline 40,10 20,50 90,10 70,40&#34;</span>   draw_polyline.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;polygon  40,10 20,50 90,10 70,40&#34;</span>   draw_polygon.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;bezier   40,10 20,50 90,10 70,40&#34;</span>   draw_bezier.gif
</code></pre></div><p>比较好的画直线和曲线的方法是使用 <a href="https://imagemagick.org/Usage/draw/#paths">SVG 路径画法</a>，它的用途更广，甚至可以实现&quot;比例画线&quot;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># text drawing  / image</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -font Candice -pointsize <span class="m">40</span> -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;text 0,0 &#39;Hello&#39;&#34;</span>   draw_text.gif

  convert -size 100x60 xc:skyblue -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;image over 0,0 0,0 &#39;terminal.gif&#39;&#34;</span>   draw_image.gif
</code></pre></div><p>最后这两个填充类型的操作是目前唯一受 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?gravity">-gravity</a>&rdquo; 影响的绘制操作。这些操作的其他修饰符，包括 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?fill">-fill</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?tile">-tile</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?origin">-origin</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?stroke">-stroke</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?strokewidth">-strokeidth</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?font">-font</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?pointsize">-pointsize</a>&quot;、&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?box">-box</a>&quot;。他们还有其他的修饰符，但这些修饰符与更高级的 <a href="https://imagemagick.org/Usage/draw/#mvg">Magick Vector Graphics</a> 语言有关。</p>
<h2 id="贝赛尔原语">贝赛尔原语</h2>
<p>&ldquo;bezier&rdquo; 原语用于绘制曲线。每条命令只画一条曲线段。通常会给出 4 个点（8 个数字）：一个起点&rsquo;结'、两个控制点和一个终点&rsquo;结'。两个控制点定义了曲线的方向以及曲线偏离附加的终点&rsquo;结&rsquo;点的速度。</p>
<p>为了顺利地将两条曲线连接起来，应该将端点的控制点通过&rsquo;结&rsquo;镜像，形成下一条贝塞尔曲线的控制点。例如这里我画了两条平稳连接在一起的贝赛尔曲线。请注意控制线和点（也是画出来的）是如何通过连接坐标直线镜像的，无论是角度还是长度。这一点很重要，否则曲线将不平滑。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;10,10 30,90   25,10 50,50   50,50 75,90   70,10 90,40&#34;</span>
  <span class="nv">clines</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$points</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/   /\n/g&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>             <span class="k">while</span> <span class="nb">read</span> line<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&#34;line </span><span class="nv">$line</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span>
  <span class="nv">symbols</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> path <span class="s2">&#34;&#39;&#34;</span><span class="p">;</span> <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nb">echo</span> <span class="s2">&#34;M </span><span class="nv">$point</span><span class="s2">   l -2,-2 +4,+4 -2,-2   l -2,+2 +4,-4 -2,+2&#34;</span>
           <span class="k">done</span><span class="p">;</span>  <span class="nb">echo</span> <span class="s2">&#34;&#39;&#34;</span><span class="sb">`</span>

  convert -size 100x100 xc:skyblue -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke gray </span><span class="nv">$clines</span><span class="s2">    stroke blue </span><span class="nv">$symbols</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 10,10 30,90   25,10 50,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 50,50 75,90   70,10 90,40 &#34;</span> <span class="se">\
</span><span class="se"></span>          draw_bezier_joined.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_bezier_joined.gif" alt="img"></p>
<p>如果我移动其中一个控制点，使它不从同一&quot;结&quot;的另一个控制点通过附加的&quot;结&quot;进行&quot;反射&rdquo;，那么曲线将不连续。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;10,10 30,90   25,10 50,50   50,50 80,50   70,10 90,40&#34;</span>
  <span class="nv">clines</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$points</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/   /\n/g&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>             <span class="k">while</span> <span class="nb">read</span> line<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&#34;line </span><span class="nv">$line</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span>
  <span class="nv">symbols</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> path <span class="s2">&#34;&#39;&#34;</span><span class="p">;</span> <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nb">echo</span> <span class="s2">&#34;M </span><span class="nv">$point</span><span class="s2">   l -2,-2 +4,+4 -2,-2   l -2,+2 +4,-4 -2,+2&#34;</span>
           <span class="k">done</span><span class="p">;</span>  <span class="nb">echo</span> <span class="s2">&#34;&#39;&#34;</span><span class="sb">`</span>

  convert -size 100x100 xc:skyblue -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke gray </span><span class="nv">$clines</span><span class="s2">    stroke blue </span><span class="nv">$symbols</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 10,10 30,90   25,10 50,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 50,50 80,50   70,10 90,40 &#34;</span> <span class="se">\
</span><span class="se"></span>          draw_bezier_disjoint.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_bezier_disjoint.gif" alt="img"></p>
<p>如果再次移动控制点，使其与相关的&quot;结&quot;点相匹配，线条将直接从该点出发，完全没有任何&quot;曲线&quot;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;10,10 30,90   25,10 50,50   50,50 50,50   70,10 90,40&#34;</span>
  <span class="nv">clines</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$points</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/   /\n/g&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>             <span class="k">while</span> <span class="nb">read</span> line<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&#34;line </span><span class="nv">$line</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span>
  <span class="nv">symbols</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> path <span class="s2">&#34;&#39;&#34;</span><span class="p">;</span> <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nb">echo</span> <span class="s2">&#34;M </span><span class="nv">$point</span><span class="s2">   l -2,-2 +4,+4 -2,-2   l -2,+2 +4,-4 -2,+2&#34;</span>
           <span class="k">done</span><span class="p">;</span>  <span class="nb">echo</span> <span class="s2">&#34;&#39;&#34;</span><span class="sb">`</span>

  convert -size 100x100 xc:skyblue -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke gray </span><span class="nv">$clines</span><span class="s2">    stroke blue </span><span class="nv">$symbols</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 10,10 30,90   25,10 50,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 50,50 50,50   70,10 90,40 &#34;</span> <span class="se">\
</span><span class="se"></span>          draw_bezier_no_curve.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_bezier_no_curve.gif" alt="img"></p>
<p>如果两个控制点都设置为各自的&quot;结点&quot;，那么就会生成一条直线。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;10,10 10,10   50,50 50,50   50,50 50,50   90,40 90,40&#34;</span>
  <span class="nv">clines</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$points</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/   /\n/g&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>             <span class="k">while</span> <span class="nb">read</span> line<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&#34;line </span><span class="nv">$line</span><span class="s2">&#34;</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span>
  <span class="nv">symbols</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> path <span class="s2">&#34;&#39;&#34;</span><span class="p">;</span> <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nb">echo</span> <span class="s2">&#34;M </span><span class="nv">$point</span><span class="s2">   l -2,-2 +4,+4 -2,-2   l -2,+2 +4,-4 -2,+2&#34;</span>
           <span class="k">done</span><span class="p">;</span>  <span class="nb">echo</span> <span class="s2">&#34;&#39;&#34;</span><span class="sb">`</span>

  convert -size 100x100 xc:skyblue -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke gray </span><span class="nv">$clines</span><span class="s2">    stroke blue </span><span class="nv">$symbols</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 10,10 10,10   50,50 50,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red  bezier 50,50 50,50   90,40 90,40 &#34;</span> <span class="se">\
</span><span class="se"></span>          draw_bezier_lines.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_bezier_lines.gif" alt="img"></p>
<p>如果不指定所有 4 个点，&lsquo;bezier&rsquo; 原语并不真正有用。只有第一个点和最后一个点被归类为&rsquo;结'，曲线将通过（或结束）这两个点。所有其他的点纯粹被视为控制点，按照给定的顺序对曲线产生影响，控制点越远，对该段曲线的影响越大。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;10,10 30,90   25,10    75,90   70,10 90,40&#34;</span>
  <span class="nv">symbols</span><span class="o">=</span><span class="sb">`</span><span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nb">echo</span> <span class="s2">&#34;M </span><span class="nv">$point</span><span class="s2">   l -2,-2 +4,+4 -2,-2   l -2,+2 +4,-4 -2,+2&#34;</span>
           <span class="k">done</span><span class="sb">`</span>

  convert -size 100x100  xc:skyblue  -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke gray  polyline </span><span class="nv">$points</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke red   bezier </span><span class="nv">$points</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke blue  path &#39;</span><span class="nv">$symbols</span><span class="s2">&#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          draw_bezier_multi.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_bezier_multi.gif" alt="img"></p>
<p>为了保持简单，不建议你每条 &lsquo;bezier&rsquo; 曲线段使用超过或少于4个点。</p>
<p>其实我建议你完全不要使用 &lsquo;bezier&rsquo; 原语，而是使用 <a href="https://imagemagick.org/Usage/draw/#cubic">SVG Path Cubic Bezier</a> 来生成曲线。它有一个特殊的 &ldquo;s&rdquo; 曲线延续功能，可以自动做相应的控制点&quot;反射&quot;，生成平滑连接的曲线段，减少你需要使用的控制点数量。您还可以定义相对于路径中最后一个端点的点。</p>
<h2 id="颜色填充原语">颜色填充原语</h2>
<p>除了上述 &ldquo;简单&quot;原语之外，&quot;<a href="https://imagemagick.org/Usage/option_link.cgi?draw">-draw</a>&ldquo;还提供了一组颜色填充或修改原语。这些原语根据所选方法，从指定的点开始修改图像中的颜色。</p>
<p>这些填充方法实际上不是真正的 &lsquo;draw&rsquo; 命令，而是颜色替换函数。它们被添加到绘图中，因为在程序的早期版本中，将它们的操作插入到 ImageMagick 中是最简单的。</p>
<p>就像上面一样，使用的颜色是用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?fill">-fill</a>&ldquo;颜色设置的，但如果设置了，就会使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?tile">-tile</a>&rdquo; 图像来代替。</p>
<p>上面的其他设置选项没有使用，对这些操作没有影响。</p>
<p>两个额外的设置也将应用于这些原语，即 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?bordercolor">-bordercolor</a>&rdquo; 和 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?fuzz">-fuzz</a>&ldquo;系数设置。但是，这些设置不能在 &ldquo;MVG&rdquo; 语言中定义，因此只能在使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?draw">-draw</a>&rdquo; 操作符之前进行设置。</p>
<p>第一个 &lsquo;color point&rsquo; 你已经看到了，它是上述例子中 &lsquo;point&rsquo; 绘制原语的替代。如果你仔细观察，你会看到我们在测试图像中设置的单个白色像素。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill white <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 point&#39;</span>      color_point.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/color_point.png" alt="img"></p>
<p>然而在绘制透明色和半透明色时，这些功能是不一样的。</p>
<p>这里我们有一个三个像素的红色图像（放大了），第二个或中间的像素我们用 <code>point</code> 函数在红色像素上画上半透明的蓝色，得到紫色的结果。然而如果使用 <code>color point</code> 函数（最后一个或右边的像素），红色完全被半透明的蓝色像素所取代。它不会被叠加。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 3x1 xc:red -matte -fill <span class="s1">&#39;#00F8&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;point 1,0&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 2,0 point&#39;</span>   -scale 33x33  draw_points.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_points.png" alt="img"></p>
<p>所有的 <code>color</code> 函数都会进行全色替换，而其他所有的颜色原语都会在图像上面&rsquo;画&rsquo;出颜色。因此，你可以使用 <code>color</code> 来绘制透明色。</p>
<p><code>color replace</code> 绘制函数将在指定的位置替换所有精确给定颜色的实例。而且正如您所看到的，这些区域不一定要连接在一起。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill white <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 replace&#39;</span>      color_replace.png

  convert color_test.png   -fill white   -fuzz 13%<span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 replace&#39;</span>      color_replace_fuzz.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/color_replace.png" alt="img"></p>
<p>然而，正如你在第一个结果中所看到的，一些沿边缘的像素没有被替换。这些像素与所选像素的颜色不完全相同，所以它们被忽略了。添加一个小的<a href="https://imagemagick.org/Usage/color_basics/#fuzz">模糊因子</a>也会包含与原色相似的颜色。如上面第二个例子所示。</p>
<p>当然，<code>fuzz factor</code> 并不是一个很好的解决方案，因为它不会捕捉所有这样的边缘像素。这是所有这些 <code>color fill</code> 方法经常出现的问题，也是一个没有通用解决方案的问题。</p>
<p>如果你想替换一个特定的已知颜色，而不是从图像本身选择一种颜色，那么可以使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?opaque">-opaque</a>&rdquo; 图像操作符来代替。该函数还使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?fuzz">-fuzz</a>&rdquo; 因子设置来增加与给定颜色相匹配的颜色范围。</p>
<p><code>floodfill</code> 的方法也很简单，因为它只会填充所选点周围的整个区域，而不会选择任何其他没有以某种方式连接的类似颜色的区域。</p>
<p>你也可以通过使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?fuzz">-fuzz</a>&rdquo; 来扩大被填充的区域，以包括相似的颜色。在这种情况下，我们选择了一个足够高的值，也包括了交叉边界，允许洪水填充&quot;泄漏&quot;到图像的另一侧。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill white <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 floodfill&#39;</span>      color_floodfill.png

  convert color_test.png   -fill white   -fuzz 15%   <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 floodfill&#39;</span>      color_floodfill_fuzz.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/color_floodfill.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/color_floodfill_fuzz.png" alt="img"></p>
<p>用颜色填充区域并非没有问题。颜色可能会越过薄薄的边界，渗入到不想要的区域，(<a href="https://imagemagick.org/Usage/formats/#bg_pattern">请看背景图案上的 GIF</a>，以证明这一点)。或者，它可能无法填满所选区域的边缘，（见<a href="https://imagemagick.org/Usage/antialiasing/#floodfill">反锯齿和泛滥填充问题</a>）。但它确实有效。</p>
<p><code>filltoborder</code> 就像 <code>floodfill</code> 一样，只是你指定了一个颜色，这个颜色的边界是要填充的区域，而不是填充过程中要替换的颜色。</p>
<p>当然也建议在该边框颜色选择中加入 <code>similar colors</code> 的<a href="https://imagemagick.org/Usage/color_basics/#fuzz">模糊因子</a>，以进一步限制洪水填充。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill white  -bordercolor royalblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 filltoborder&#39;</span>   color_filltoborder.png

  convert color_test.png   -fill white  -bordercolor blue <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 filltoborder&#39;</span>   color_filltoborder2.png

  convert color_test.png   -fill white  -bordercolor blue  -fuzz 30% <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 filltoborder&#39;</span>   color_filltoborder_fuzz.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/color_filltoborder.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/color_filltoborder2.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/color_filltoborder_fuzz.png" alt="img"></p>
<p>最后的绘制颜色方法是 <code>reset</code>，它只是将整个图像替换或重置为填充颜色。在这种情况下，实际选择的像素对结果没有任何影响。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill white <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;color 30,20 reset&#39;</span>      color_reset.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/color_reset.png" alt="img"></p>
<p>这实际上是非常有用的，因为它提供了一种简单的方法从现有图像生成纯色（或平铺图像）画布。(请参见 <a href="https://imagemagick.org/Usage/canvas/#sized">Canvases Sized to an Existing Image</a>)以了解此方法和其他做同样事情的方法。</p>
<p>未来：使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?tile">-tile</a>&rdquo; 图案来填充该区域。</p>
<h2 id="matt-填充原语">Matt 填充原语</h2>
<p><code>matte</code> 绘制原语的工作方式与上述 <code>color</code> 原语完全相同，只是它不会替换所选区域的颜色，只会替换所选区域的 <code>matte</code> 通道。（也就是只有 <code>alpha</code> 或 <code>matte</code> 通道被这些填充函数调整）。</p>
<p>就像 <code>color</code> 填充函数一样，<code>matte</code> 值使用的是填充色（除非用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?tile">-tile</a>&rdquo; 作为 <code>alpha value</code> 的来源）。</p>
<p>这里我们使用上面同样的 <code>color floodfill</code> 例子，但这里只调整 matte 通道，使填充部分完全透明。也就是说，原来的颜色仍然存在，只是透明而已!</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill none <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;matte 30,20 floodfill&#39;</span>      matte_floodfill.png

  convert color_test.png   -fill none   -fuzz 15%   <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;matte 30,20 floodfill&#39;</span>      matte_floodfill_fuzz.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/matte_floodfill.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/matte_floodfill_fuzz.png" alt="img"></p>
<p>也可以使用 <code>matte reset</code> 函数使整个图像变成半透明的。当然在这种情况下，我们必须输出到 PNG，它可以接受半透明颜色的图像。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert color_test.png   -fill <span class="s1">&#39;#00000080&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;matte 30,20 reset&#39;</span>      matte_reset.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/matte_reset.png" alt="img"></p>
<p>注意，在操作中没有使用 <code>black</code> 颜色分量，只使用了颜色的 <code>matte</code> 分量。图像的原色保持原样。</p>
<p>未来：使用 &ldquo;<a href="https://imagemagick.org/Usage/option_link.cgi?tile">-tile</a>&rdquo; 模式来制作有趣的哑光效果。</p>
<p><code>color</code> 和 <code>matte</code> 都是完全替换颜色的函数，它总是会产生一个布尔（all or nothing）类型的颜色替换。因此，这些区域的边缘总是会显示出 <a href="https://imagemagick.org/Usage/antialiasing/">Aliasing 效果</a>。</p>
<p>正因为如此，除了设置 GIF 图像的透明区域（也是布尔型）外，一般来说，这些都不是一般图像显影的好图像运算符。不过也不是全无用处，<a href="https://imagemagick.org/Usage/masking/#bg_remove">从背景去除</a>的例子中可以看出。</p>
<h2 id="关于绘图命令的具体内容">关于绘图命令的具体内容</h2>
<h3 id="像素坐标">像素坐标</h3>
<p><code>[-draw](https://imagemagick.org/Usage/option_link.cgi?draw)</code> 命令（以及IM中的许多其他命令）使用的是所谓的&quot;像素坐标&rdquo;。也就是 &ldquo;10,10&rdquo; 的坐标是左上角往下10个像素的中心。</p>
<p>在这个坐标系中，0,0 是左上角像素的中心，w-1,h-1 是右下角的中心。实际的边缘位于 -0.5,-0.5 和 w-0.5,h-0.5，中心像素（如果图像是奇数大小）位于 &lsquo;(w-1)/2,(h-1)/2&rsquo;。</p>
<p>然而，当您对图像进行数学处理时（如使用扭曲时），实际的像素没有实际意义，因此它使用&quot;图像坐标&rdquo;。在这个系统中，图像的实际边缘在 &lsquo;0,0&rsquo; 和 &lsquo;w,h&rsquo; 处。而图像的中心（可能是，也可能不是像素的中心）在 &lsquo;w/2,h/2&rsquo;。</p>
<p>要将 &lsquo;像素坐标&rsquo; 转换为图像坐标，请加上 ½ 如左上角像素的中心是 &lsquo;0.5,0.5&rsquo;，右下角像素的中心是 &lsquo;w-0.5,h-0.5&rsquo;。
<em>例如：小图像中的圆心</em></p>
<h3 id="绘制伽马和色域校正">绘制伽马和色域校正</h3>
<p>和几乎所有的 ImageMagick 操作一样， <code>[-draw](https://imagemagick.org/Usage/option_link.cgi?draw)</code> 是一个线性运算符，因此在线性 RGB 色彩空间中工作。这意味着，为了得到平滑的边缘，你可能需要对图像进行一些伽玛校正，然后再保存，这样就可以使用非线性（伽玛校正）的sRGB色彩空间来存储。</p>
<p>例如，如果你画了一个大圆，然后保存它&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 81x81 xc:black -fill white -draw <span class="s1">&#39;circle 40,40 40,3&#39;</span> <span class="se">\
</span><span class="se"></span>          circle_raw.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_raw.png" alt="img"></p>
<p>看看圆圈的边缘，其实看起来并不是真的很光滑。你可以看到明显的阶梯效果。</p>
<p>那是因为你是在线性 RGB 色彩空间中画的圆。但是你却把图像保存成了真正的 sRGB 色域！这就导致了你的图像在保存的过程中出现了明显的阶梯效果。</p>
<p>为了解决这个问题，我们需要在保存图像之前给图像添加一个伽玛校正。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 81x81 xc:black -fill white -draw <span class="s1">&#39;circle 40,40 40,3&#39;</span> <span class="se">\
</span><span class="se"></span>          -gamma 2.2 circle_gamma.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_gamma.png" alt="img"></p>
<p>现在，圆圈边缘实际上看起来光滑圆润，就像它们应该的那样。</p>
<p>如果你想正确地做这件事，我们真的应该使用色彩空间进行修正。然而，由于IM假设RGB是保存的默认色彩空间，你需要做一些棘手的处理来让它正确地做事情。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 81x81 xc:black -set colorspace RGB <span class="se">\
</span><span class="se"></span>          -fill white -draw <span class="s1">&#39;circle 40,40 40,3&#39;</span> <span class="se">\
</span><span class="se"></span>          -colorspace sRGB circle_sRGB.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_sRGB.png" alt="img"></p>
<blockquote>
<p>请注意，sRGB色彩空间（这是保存图像的正确方法）与简单地应用2.2伽玛校正并不完全相同。然而，两者之间的结果差异很小，只有在非常非常粗糙的图像中才能看到。
在IM v6.7.5-1之前，色彩空间名称 &ldquo;sRGB&rdquo; 和 &ldquo;RGB&rdquo;（线性-RGB）实际上是颠倒的。因此，在旧版本的IM中，上面的两个标签应该被调换。</p>
</blockquote>
<p>要使用真实的图像（在IMv6中）正确地绘制（或进行任何&quot;线性&quot;图像处理），你需要首先删除任何现有的伽玛，处理图像，然后恢复该伽玛校正。更多细节请参见<a href="https://imagemagick.org/Usage/resize/#resize_colorspace">使用色域校正调整大小</a>。</p>
<p>下面是一个在真实图像上绘图的例子&hellip;。首先是没有任何颜色校正（原始），然后是伽玛和色域校正。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert rose:  -fill none -stroke white -draw <span class="s1">&#39;line 5,40 65,5&#39;</span>  rose_raw.png

  convert rose: -gamma .454545 <span class="se">\
</span><span class="se"></span>          -fill none -stroke white -draw <span class="s1">&#39;line 5,40 65,5&#39;</span> <span class="se">\
</span><span class="se"></span>          -gamma 2.2 rose_gamma.png

  convert rose: -colorspace RGB <span class="se">\
</span><span class="se"></span>          -fill none -stroke white -draw <span class="s1">&#39;line 5,40 65,5&#39;</span> <span class="se">\
</span><span class="se"></span>          -colorspace sRGB rose_sRGB.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/rose_raw.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/rose_gamma.png" alt="img">
<img src="https://imagemagick.org/Usage/draw/rose_sRGB.png" alt="img"></p>
<p>正如你所看到的，通过使用伽玛或色彩空间校正，线条变得非常平滑，没有锯齿状的&quot;楼梯&quot;别离效果，比直接绘制时可以看到。(你需要一个很好的显示器才能看到它)</p>
<blockquote>
<p>上面的线条是用 <code>[-stroke](https://imagemagick.org/Usage/option_link.cgi?stroke)</code> 颜色绘制的。您可以使用 <code>[-fill](https://imagemagick.org/Usage/option_link.cgi?fill)</code> 来绘制线条，并得到同样的结果，但这样您就不能使用 <code>[-strokewidth](https://imagemagick.org/Usage/option_link.cgi?strokewidth)</code> 来控制线条粗细。更多信息请参见下面的&rdquo;<a href="https://imagemagick.org/Usage/draw/#stroke">描边颜色设置</a>&quot;。
色域名称实际上是使用&rsquo;sRGB&rsquo;色彩空间的值来定义的，但通过绘制应用，就好像图像是在线性RGB色彩空间中一样。因此，对命名的颜色（不是&quot;白&quot;或&quot;黑&rdquo;）使用上述伽玛校正将导致这些颜色变得失真。在这种情况下，最好不要使用伽玛或色域校正，这样命名的颜色就会正确映射。
命名的&rsquo;sRGB&rsquo;颜色与图像的色彩空间的正确映射，将作为IMv7开发的一部分被修正。</p>
</blockquote>
<h3 id="描边描边宽度和填充的相互作用">描边、描边宽度和填充的相互作用</h3>
<p><code>[-stroke](https://imagemagick.org/Usage/option_link.cgi?stroke)</code> 和 <code>[-strokewidth](https://imagemagick.org/Usage/option_link.cgi?strokewidth)</code> 选项用于在字体边缘绘制轮廓。</p>
<p>这些选项通常与 <code>[-fill](https://imagemagick.org/Usage/option_link.cgi?fill)</code> 一起使用，以使文字更有趣，而不费力。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 380x70 xc:lightblue -pointsize <span class="m">50</span> -font Chisel <span class="se">\
</span><span class="se"></span>            -fill green  -stroke black  -draw <span class="s1">&#39;text 10,55 &#34;Black Border&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>            stroke_font.jpg
</code></pre></div><p>默认设置是 <code>-strokewidth 1</code> 和 <code>-stroke None</code>。</p>
<p>但这样做会使轮廓笔画不可见，只留下 <code>[-fill](https://imagemagick.org/Usage/option_link.cgi?fill)</code> 的颜色，你不会看到它。</p>
<p>当 <code>-strokewidth</code> 为 &ldquo;不可见 &ldquo;时， <code>-strokewidth</code> 唯一的效果是对字体大小属性的影响，也就是说它仍然可以影响字体定位和 <a href="https://imagemagick.org/Usage/text/#label">Label 和 Caption</a> 图片生成的大小。否则，宽度在你使笔画可见之前是没有可见效果的。</p>
<p>为了了解 <code>[-strokewidth](https://imagemagick.org/Usage/option_link.cgi?strokewidth)</code> 对字体外观的实际影响（当使其可见时），我在这里绘制了一些不同宽度的文字，从 &ldquo;turned off&rdquo; 到越来越大。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 320x420 xc:lightblue -pointsize <span class="m">70</span> -font Vademecum <span class="se">\
</span><span class="se"></span>      -fill red -stroke none                 -draw <span class="s1">&#39;text 30,80  &#34;Stroke -&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>      -fill red -stroke black -strokewidth <span class="m">0</span> -draw <span class="s1">&#39;text 30,160 &#34;Stroke 0&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>      -fill red -stroke black -strokewidth <span class="m">1</span> -draw <span class="s1">&#39;text 30,240 &#34;Stroke 1&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>      -fill red -stroke black -strokewidth <span class="m">2</span> -draw <span class="s1">&#39;text 30,320 &#34;Stroke 2&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>      -fill red -stroke black -strokewidth <span class="m">3</span> -draw <span class="s1">&#39;text 30,400 &#34;Stroke 3&#34;&#39;</span> <span class="se">\
</span><span class="se"></span>      stroke_table.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/stroke_table.jpg" alt="img"></p>
<p>请注意，从上面的例子中，设置 <code>-strokewidth</code> 为 &ldquo;0&rdquo; 与设置 <code>-stroke</code> 颜色为 &ldquo;none&rdquo;（默认值）是不同的。前者会画出一个非常非常细的笔触轮廓，而后者则会有效地关闭它。在这两种情况下，笔触仍然会被绘制。</p>
<p>然而你也应该注意到，即使 <code>-strokewidth</code> 为 &ldquo;0&rdquo;，图像的轮廓也会比普通的 <code>filled</code> 图像（使用 <code>-stroke</code> 颜色为 &ldquo;none&rdquo;）扩大非常小。</p>
<p>最后，使用任何小于 &ldquo;1.0&rdquo; 的宽度都不能正常工作。在这种情况下，你应该谨慎行事。</p>
<p>但是请记住， <code>-strokewidth</code> 也是一个浮点设置。也就是说，&ldquo;0.5&rdquo; 的笔画宽度也是有效的。然而，通常只有当您试图在关闭防锐化功能的情况下绘制薄的位图圆时，这才是重要的。</p>
<p>下面是一个使用超大笔触宽度的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">   convert -size 320x100 xc:lightblue -font Candice -pointsize <span class="m">72</span> -fill white <span class="se">\
</span><span class="se"></span>           -stroke black -strokewidth <span class="m">15</span> -draw <span class="s2">&#34;text 25,65 &#39;Anthony&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>           stroke_thick.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/stroke_thick.jpg" alt="img"></p>
<p>请注意， <code>-strokewidth</code> 可以向内和向外扩展线条。下面是同样的例子，但是重新绘制了字体，没有笔画轮廓，去掉了很粗的笔画的内侧部分。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">   convert -size 320x100 xc:lightblue -font Candice -pointsize <span class="m">72</span> -fill white <span class="se">\
</span><span class="se"></span>           -stroke black -strokewidth <span class="m">15</span> -draw <span class="s2">&#34;text 25,65 &#39;Anthony&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>           -stroke none                  -draw <span class="s2">&#34;text 25,65 &#39;Anthony&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>           stroke_outline.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/stroke_outline.jpg" alt="img"></p>
<p>更多使用描边的例子请看<a href="https://imagemagick.org/Usage/fonts/">复合字体效果</a>。请特别看一下&rdquo;<a href="https://imagemagick.org/Usage/fonts/#balloon">气球效果</a>&quot;。</p>
<h3 id="绘制描边线条">绘制（描边）线条</h3>
<p>IM中的默认画线有一些奇怪的行为，值得了解。下面就为大家介绍一下默认画线&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_default.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_default.jpg" alt="img"></p>
<p>你可以用 <a href="https://imagemagick.org/Usage/option_link.cgi?fill"><code>-fill</code></a> 选项设置线条的颜色。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line.jpg" alt="img"></p>
<p>此外，你还可以通过设置 <code>[-stroke](https://imagemagick.org/Usage/option_link.cgi?stroke)</code> 颜色，使线条稍微粗一些。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -stroke black -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_stroke.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke.jpg" alt="img"></p>
<p>但是我们用 <code>-fill</code> 选项指定的白色是怎么回事呢？</p>
<p>这就是在 ImageMagick 中绘制线条的棘手之处。该程序所做的实际上是将线条视为一个约1像素宽的填充对象。这是自然的，因为通常情况下，多条线通常用于扫出一个要填充的区域。</p>
<p>所以，就像我们在上一节中使用字体的描边一样，IM 用填充色绘制线条（或对象），然后用描边色在其周围绘制。结果就是，现在上面的描边色线条稍微粗了一点，填充色完全隐藏在下面。如果你把描边色做成半透明的，就可以让这个填充色再次显现出来。</p>
<p>综上所述，线条会出现在 <code>-fill</code> 颜色下绘制，但一旦 <code>-stroke</code> 颜色被定义为默认的&quot;无&quot;或&quot;透明&quot;颜色以外的颜色，该选项就没有任何意义了。</p>
<blockquote>
<p>选项 <code>-linewidth</code> 实际上只是 <code>-strokewidth</code> 的别名，不应该被使用。</p>
</blockquote>
<p>例如，你可能会认为这个命令会产生很粗的线条。确实如此，但由于 <code>-stroke</code> 的颜色是不可见的，所以你看不到它。你只能看到线条的一个像素宽的区域的内部&quot;填充&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -strokewidth <span class="m">3</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_fill_3.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_fill_3.jpg" alt="img"></p>
<blockquote>
<p>以上的结果其实我认为是一个 BUG，什么都没画，因为没有&rsquo;区域&rsquo;填充，也没有设置线的&rsquo;描边颜色'。什么都没有画，因为没有&quot;区域 &ldquo;需要填充，也没有设置线的&quot;笔触颜色&rdquo;。IM 目前这样做的原因是为了避免新用户的混淆，但实际上这只会给高级用户带来问题。详见<a href="https://imagemagick.org/Usage/draw/#bounds">《绘制填充边界》</a>。</p>
</blockquote>
<p>但如果同时定义了描边颜色，就会得到要求的粗线&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -stroke black -strokewidth <span class="m">3</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_stroke_3.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_3.jpg" alt="img"></p>
<p>如果将 <code>-strokewidth</code> 设置为1，则上面的一行将被完全覆盖。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -stroke black -strokewidth <span class="m">1</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_stroke_1.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_1.jpg" alt="img"></p>
<p>当然当你掌握了这些知识后，你就可以利用这些知识进行创作，就像画字体一样。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -stroke black -strokewidth <span class="m">5</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          -stroke white -strokewidth <span class="m">2</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_multi.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_multi.jpg" alt="img"></p>
<p>在这里，我使用了最薄的 <code>-strokewidth</code> 设置为 &ldquo;0&rdquo;，就像我对上述字体所做的一样。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 5,35 95,5&#34;</span> <span class="se">\
</span><span class="se"></span>          line_stroke_0.jpg
</code></pre></div><p>这就产生了一个非常奇怪的结果，即由黑点和灰段组成的点线。这是笔触、填充和背景色之间奇怪的&quot;色拍频率&quot;的结果。</p>
<p>下面是线条的放大图&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 25x10 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 2,8 22,1&#34;</span> <span class="se">\
</span><span class="se"></span>          -scale 400%    line_stroke_0_white.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_0_white.jpg" alt="img"></p>
<blockquote>
<p>颜色节拍频率 &ldquo;的效果与&quot;声音节拍&quot;的效果并无二致，当你有两把非常轻微的不调的吉他时，你会得到这样的效果。在这种情况下，你会得到一个黑点，其中笔触颜色完全覆盖了基本的填充颜色，你会得到一个灰色的点，其中笔触颜色与填充和背景颜色混合。
颜色混合是反锯齿过程的自然结果，IM使用反锯齿过程来尝试改善线条和其他绘制对象的外观。更多信息请参见<a href="https://imagemagick.org/Usage/antialiasing/"> IM 中的抗锯齿</a>讨论和示例页面。</p>
</blockquote>
<p>需要注意的是，这种效果只出现在倾斜的线条上，而不是纯水平或垂直的线条，因为在这些线条上，别名没有影响，因此也就没有&quot;色拍频率&quot;的效果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x40 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill white -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 5,20 95,20&#34;</span> <span class="se">\
</span><span class="se"></span>          line_stroke_horz.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_horz.jpg" alt="img"></p>
<p>在这里，我在放大的视图上使用了不同的底层填充颜色，所以你可以看到颜色如何改变结果的节拍。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 25x10 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill none -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 2,8 22,1&#34;</span> <span class="se">\
</span><span class="se"></span>          -scale 400%     line_stroke_0_none.jpg

  convert -size 25x10 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill red -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 2,8 22,1&#34;</span> <span class="se">\
</span><span class="se"></span>          -scale 400%    line_stroke_0_red.jpg

  convert -size 25x10 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill black -stroke black -strokewidth <span class="m">0</span> -draw <span class="s2">&#34;line 2,8 22,1&#34;</span> <span class="se">\
</span><span class="se"></span>          -scale 400%    line_stroke_0_black.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_0_none.jpg" alt="img">
<img src="https://imagemagick.org/Usage/draw/line_stroke_0_red.jpg" alt="img">
<img src="https://imagemagick.org/Usage/draw/line_stroke_0_black.jpg" alt="img"></p>
<p>让我们把它和无 stroke 相比&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 25x10 xc:lightblue <span class="se">\
</span><span class="se"></span>          -fill black -stroke none -draw <span class="s2">&#34;line 2,8 22,1&#34;</span> <span class="se">\
</span><span class="se"></span>          -scale 400%    line_stroke_-_black.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/line_stroke_-_black.jpg" alt="img"></p>
<p>正如你所看到的，当绘制非常细的线条时，你可以通过使用相同的填充和描边颜色，或者将其中一种颜色设置为无来减少&quot;节拍&rdquo;。虽然后者是最好的主意，但前者可能对你的特定编程需求更实用。</p>
<p>注意，填充线的粗细是 &ldquo;0&rdquo;。但描边线可以有更大的厚度。它也是一个浮点值! 2.5像素宽的线条是完全有效的。</p>
<blockquote>
<p>这些结果不仅是由于笔画宽度为0的bug，导致颜色跳动，而且在没有实际需要填充的区域时，&ldquo;填充色&quot;被画出了额外的1.0直径厚度。这我也认为是一个bug。请看<a href="https://imagemagick.org/Usage/draw/#bounds">绘制填充边界</a>。</p>
</blockquote>
<h3 id="绘制填充边界">绘制填充边界</h3>
<p>关于各种绘制原语，还有一些其他要点需要您注意。</p>
<p>笔画宽度对于大于 1.0 的浮点值工作得很好，但对于小于 1.0 的值似乎会崩溃。这是由于使用的实现算法造成的，而不仅仅是因为它是错误的，因为它在较大厚度的线条上工作得很好。</p>
<p>基本上，如果你使用的笔画宽度为零，你可以期待没有笔画颜色会被添加。相反，你会得到一种节拍模式，当线条穿过像素的实际&quot;中心&quot;时，笔触颜色就会达到全部强度。</p>
<p>真正应该发生的是，添加到像素上的颜色数量应该反映出被绘制的线条的面积，而不是像素与该线条的距离。因此，零宽度的线条不应该给图像添加任何颜色，而厚度小于1.0的线条应该只添加较少的颜色。</p>
<p>请看上面的例子 <a href="https://imagemagick.org/Usage/draw/#strokewidth">Draw Lines, with StrokeWidth and Stroke</a>。</p>
<p>另一个问题是，填充颜色没有应用到正在绘制的形状（多边形）的边缘，而是应用到更远的半像素处。这包括没有应用&quot;描边&quot;的情况，而边缘应该是精确的。它也包括画一条&quot;线&rdquo;，它的填充厚度实际上是&quot;零&rdquo;。</p>
<p>基本上，如果你画了一条线，没有启用描边，从技术上讲，你应该看到，没有线，因为它没有&quot;填充&quot;厚度。相反，线条的绘制至少包括1个像素宽的&quot;填充&quot;颜色。这是出于历史原因，一般来说可以避免新用户对IM的混淆。不幸的是，这对高级用户来说是不正确的。</p>
<p>这意味着，如果您只使用填充色绘制两个多边形，并共享一个边缘，该边缘将重叠1个像素，因为每个多边形的所有边缘都比它大半像素。换句话说，多边形和其他形状并不适合在一起，而是重叠的。</p>
<p>例如，在这里我试着使用 <code>draw</code> 把一张图片分成两半（在白色上绘制黑色）。要做到这一点，我画了两个多边形，共享一个边缘，完全没有重叠。由此产生的&quot;微小&quot;图像，已被放大显示。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 10x10 xc: -draw <span class="s1">&#39;polygon 2,-1 7,10 10,10 10,-1&#39;</span> bound_left.gif
  convert -size 10x10 xc: -draw <span class="s1">&#39;polygon 2,-1 7,10 -1,10 -1,-1&#39;</span> bound_right.gif
  convert bound_left.gif bound_right.gif -compose Plus -composite bound_add.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/bound_left_mag.gif" alt="img">
<img src="https://imagemagick.org/Usage/img_www/plus.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/bound_right_mag.gif" alt="img">
<img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/bound_add_mag.gif" alt="img"></p>
<p>两个黑色的部分(这是实际绘制的)实际上是相互重叠的! 换句话说，尽管我们试图使用绘制的多边形分别绘制这两个区域，但填充的区域比要求的略大。</p>
<p>我还将两张图片加（<a href="https://imagemagick.org/Usage/compose/#plus">加合成</a>）在一起，这样你就可以实际看到绘制的黑色区域的重叠。如果两个多边形是完美契合的，那么 &ldquo;添加 &ldquo;的图画将是纯白色的。</p>
<p>实际的重叠量相当于默认的 <code>-strokewidth 1.0</code> 设置。因此，通常情况下，这个额外的区域会被一个正常的笔画宽度所覆盖。然而它可能会造成一些实际问题。</p>
<p>旁白: 对于一个完整的连接测试，你会在黑色背景上生成50%的灰色区域，然后把它们加在一起。这样你就可以看到这些区域是否不仅 &ldquo;重叠&rdquo;（如上图所示），而且还可以测试当你把这些区域加在一起时，它们是否 &ldquo;重叠不足&rdquo;（在填充的区域之间留下一个间隙）。所得到的图像应该是一个完美平滑的50%灰色，沿连接处没有颜色变化。透明度检查会涉及到，在一个完全透明的背景上应该使用50%透明，50%灰色的颜色。</p>
<p>要查看一个完美的剪切和重新添加的例子，基于一个单一的蒙版图像，请参阅组成方法的例子，<a href="https://imagemagick.org/Usage/compose/#dstout">组成 DstOut</a>。</p>
<p>未来BUG修复：填充的区域应该是精确的，但为了在绘制形状时进行补偿，默认的 &ldquo;描边颜色 &ldquo;应该设置为填充颜色（除非它本身被特别设置）。</p>
<h2 id="mvg---魔法矢量图形">MVG - 魔法矢量图形</h2>
<p>上面显示的原语构成了所有 <code>-draw</code> 操作的基础。它们共同构成了 ImageMagick 中特殊内部语言的起点，称为 Magick Vector Graphics 语言。关于这种语言的更多细节，请参见IM网站上的 <a href="http://www.imagemagick.org/script/magick-vector-graphics.php">MVG 原语和语法摘要</a>。</p>
<p>这种 &ldquo;MVG&rdquo; 语言的设计目标是让 ImageMagick 处理更复杂的 SVG（可缩放矢量图形）语言。它通过尝试将给定 SVG 格式的图像转换为更简单的内部 MVG 格式来实现。更多细节请看下面的 <a href="https://imagemagick.org/Usage/draw/#svg">SVG 处理</a>。</p>
<p>因此，你上面看到的只是 <code>-draw</code> 操作符的一小部分功能。如果你想绘制复杂的对象，我建议你使用SVG编辑器（如 &ldquo;Sodipodi&rdquo;）为对象创建一个单独的SVG格式图像。参见下面的非IM矢量图形程序）。</p>
<p>与 SVG 不同，MVG 没有任何形式的&quot;容器&quot;或图像命令集。在转换过程中，这些命令都被删除，以产生一个简化的 MVG 绘图命令序列。相反，它使用<a href="https://imagemagick.org/Usage/draw/#push_context">图形上下文</a>的概念来保存和恢复各种绘图设置，这就是我们现在要看的。</p>
<h3 id="命令行设置与-mvg-设置">命令行设置与 MVG 设置</h3>
<p>首先，您通过命令行选项设置的几乎所有设置，绘制原语使用的设置在 MVG 绘制命令中都有直接对应的内容。</p>
<p>通过命令行选项（如 <code>-strokewidth</code>）或使用 MVG 绘图字符串（如 <code>strok-width</code>）中的设置，两者之间的主要区别在于 MVG 设置只在 MVG 命令字符串的持续时间内有效。</p>
<p>一般绘图设置的总结:</p>
<pre><code>  __cmd_option__   __draw_MVG__        __Argument__
    -fill            fill                color/tile for inside shapes
    -tile            fill                image tile, replaces fill color

    -stroke          stroke              line color/tile around the shapes
    -strokewidth     stroke-width        pixel width
    +antialias       stroke-antialias    0/1 aliasing line edges

    -font            font                font_name / font_file
    -family          font-family            ?
    -weight            ?                    ?
    -stretch           ?                    ?
    -pointsize       font-size           height in points
    -kerning           -                 extra inter-character spacing

    +antialias       text-antialias      0/1 aliasing drawing text
    -box             text-undercolor     fill color for font bounding box
      -              decorate        (None, Underline, LineThrough or Overline)

    -gravity         gravity             (None, North, South-East,...)
    -fuzz              -                 color delta / percentage
    -bordercolor       -                 color
</code></pre><p>Notes:</p>
<pre><code>  - no such option      ? unknown
</code></pre><p>这些设置通常很好理解，因为它们经常使用，上面也有演示。</p>
<blockquote>
<p>字体、拉伸、样式和重量用于从 ImageMagick 字体列表中识别字体。然而，大多数人只是选择一个特定的字体和大小点来代替使用。因此，它们在IM中很少使用。
正如您所看到的，&ldquo;color fill&rdquo; 原语的特殊设置在 MVG 中并没有直接对应的设置。这就是 <code>-bordercolor</code> 和 <code>-fuzz</code> 因子设置。在使用 <code>-draw</code> 操作符之前，必须从命令行指定这些设置。</p>
</blockquote>
<p>有些 MVG 设置作为全局命令行设置可能更有用，比如字体绘制的 <code>decorate</code> 设置。</p>
<p>警告： <code>[-gravity](https://imagemagick.org/Usage/option_link.cgi?gravity)</code> 不是 SVG 规范的一部分。在 MVG 中，它只用于文本和图像的放置以及对齐。目前没有与默认的&quot;引力&quot;效果分开的调整设置。然而，由于调整是 SVG 文本处理的一部分，这可能会在未来的某个时候改变。</p>
<p>现在，全局命令行设置（在 MVG 绘制字符串之外）用于初始化你所应用的每个 <code>-draw</code> 操作的设置，这就是为什么你可以设置一个 <code>-fill</code> 颜色，然后你可以用它来绘制该颜色的圆。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue   -fill red <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;circle 50,30 40,10&#34;</span>          draw_circle_global.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_circle_global.gif" alt="img"></p>
<p>你可以在 MVG 参数 <code>-draw</code> 中本地覆盖全局设置&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue   -fill red <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill green   circle 50,30 40,10&#34;</span>  draw_circle_override.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_circle_override.gif" alt="img"></p>
<p>然而，在单个 <code>-draw</code> MVG 参数中设置的设置只在 <code>-draw</code> 操作期间存在。也就是说， <code>-draw</code> 中的设置只限于该次绘制，而不会带入以后单独的 <code>-draw</code> 参数中。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue   -fill red   -draw <span class="s1">&#39;fill green&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;circle 50,30 40,10&#34;</span>          draw_circle_local.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_circle_local.gif" alt="img"></p>
<p>如果你打算进行大量的操作，那么在单个 MVG 字符串中进行这些操作可能会比多个 <code>-draw</code> 操作更好。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue  <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill green  circle 41,39 44,57
</span><span class="s2">                 fill blue   circle 59,39 56,57
</span><span class="s2">                 fill red    circle 50,21 50,3  &#34;</span>  draw_circle_multi.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/draw_circle_multi.gif" alt="img"></p>
<h3 id="mvg-特定设置">MVG 特定设置</h3>
<p>其他控制线条和对象绘制方式的 MVG 设置，即使在使用原语操作时也需要了解。这些设置包括&hellip;</p>
<pre><code>   __draw_MVG__       __Description/Argument__
  fill-opacity        fill transparency, from 0.0 to 1.0
  clip-rule           fill style for crossed lines (evenodd, nonzero)

  stroke-opacity      line transparency, number from 0.0 to 1.0
  stroke-dasharray    list of 'on' and 'off' lengths for lines
  stroke-dash
  stroke-linecap      End of line look: butt round square
  stroke-linejoin     Lines joins:  butt  miter round square
  stroke-miterlimit   Angle when 'miter' joins become 'bevel' (or 'butt')
</code></pre><p>记住，所有 MVG 设置和绘图操作符的完整列表可以在 IM 网站的 <a href="http://www.imagemagick.org/script/magick-vector-graphics.php">MVG 原语和语法摘要</a>中看到。</p>
<p>让我们看看一些简单设置的效果&hellip;&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Stroke Opacity</span>
  convert -size 100x60 xc:skyblue -fill none -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                           path &#39;M 10,10 L 90,10&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-opacity 0.8         path &#39;M 10,20 L 90,20&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-opacity 0.6         path &#39;M 10,30 L 90,30&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-opacity 0.4         path &#39;M 10,40 L 90,40&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-opacity 0.2         path &#39;M 10,50 L 90,50&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_stroke_opacity.gif

  <span class="c1"># Fill Opacity</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                    rectangle  5,10 15,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-opacity 0.8    rectangle 20,10 30,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-opacity 0.6    rectangle 35,10 45,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-opacity 0.4    rectangle 50,10 60,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-opacity 0.2    rectangle 65,10 75,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-opacity  0     rectangle 80,10 90,50 &#34;</span> <span class="se">\
</span><span class="se"></span>          set_fill_opacity.gif

  <span class="c1"># Plain and Dashed Lines</span>
  convert -size 100x60 xc:skyblue -fill none -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                           path &#39;M 10,10 L 90,10&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 5 3       path &#39;M 10,20 L 90,20&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 5 5       path &#39;M 10,30 L 90,30&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 10 3 3 3  path &#39;M 10,40 L 90,40&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 1 6       path &#39;M 10,50 L 90,50&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_lines.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                           path &#39;M 10,10 L 90,10&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 5 3       path &#39;M 10,20 L 90,20&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 5 5       path &#39;M 10,30 L 90,30&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 10 3 3 3  path &#39;M 10,40 L 90,40&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-dasharray 1 6       path &#39;M 10,50 L 90,50&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_lines_fill.gif

  <span class="c1"># Note: Technically the second image should be the same as the first</span>
  <span class="c1"># as the &#39;filled&#39; lines contain no area.  This I regard as a BUG.</span>
  <span class="c1"># Stroke Ends and Joins</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black -strokewidth <span class="m">8</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                           path &#39;M 20,20 L 20,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linecap butt        path &#39;M 40,20 L 40,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linecap round       path &#39;M 60,20 L 60,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linecap square      path &#39;M 80,20 L 80,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_endcaps.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black -strokewidth <span class="m">5</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                        path &#39;M  5,70 L 20,20  35,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linejoin miter   path &#39;M 35,70 L 50,20  65,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linejoin bevel   path &#39;M 55,70 L 70,20  85,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-linejoin round   path &#39;M 75,70 L 90,20 105,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_linejoin.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black -strokewidth <span class="m">5</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;                        path &#39;M  5,70 L 20,20  35,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-miterlimit 7     path &#39;M 35,70 L 50,20  65,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke-miterlimit 6     path &#39;M 65,70 L 80,20  95,70&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          set_miterlimit.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/set_stroke_opacity.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_fill_opacity.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_lines.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_lines_fill.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_endcaps.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_linejoin.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/set_miterlimit.gif" alt="img"></p>
<p><code>stroke-miterlimit</code> 的设置是相当难以演示的。这个属性定义了将 <code>miter</code> 连接变为 <code>bevel</code> 连接的角度。基本上对于非常尖锐的角度，一个斜面可以从两条线的实际接合处延伸很长的距离。这就为这个锐角设置了一个最大限度，当它变得太长时，就会使角点变钝。但请注意，它代表的是某种角度的三角值，而不是长度或距离。该值必须大于1.0。</p>
<p>上面显示了对于我所显示的连接角度，斜角会突然转换成一个介于6到7之间的斜角。</p>
<p>例如，1.414 的 <code>troke-miterlimit</code> 会将小于90度的任何角度的 &ldquo;miter&rdquo; 转换为 <code>bevel</code> 。4.0的 值（默认值）将小于约29度的角度转换为连接。而10.0的值可以将小于约11.5度的角度转换为斜面。</p>
<h3 id="svg-s路径绘制">SVG s路径绘制</h3>
<p>SVG 路径是 SVG 的基本绘图原语。它用于绘制线型、圆、曲线、弧线等。SVG 路径的完整规范可以在 <a href="http://www.w3.org/TR/SVG/paths.html#PathDataGeneralInformation">SVG 路径规范</a>文档中找到。</p>
<p>然而这并不是一个容易阅读的文档，因为它确实是为程序员而不是用户准备的，所以我将简化和总结路径规范&hellip;</p>
<ul>
<li>字母是命令，而所有的数字（浮点）都是参数</li>
<li>逗号或空格可以作为参数分隔符，否则完全忽略</li>
<li>每个路径组件的最后两个参数 <code>(x,y)</code> 将成为该路径组件的终点(或&quot;结&rdquo;)</li>
<li>大写字母是指最终点的绝对坐标</li>
<li>小写字母是相对于前一个组件的终点而言的</li>
<li>例如 &ldquo;M 1,2 L 3,4 L 2,4&rdquo; 和 &ldquo;M 1,2 L 4,6 L 6,2&rdquo; 是一样的。</li>
<li>即在1,2上加了3,4，画线到4,6。</li>
<li>然后在1,2上加2,4，画出一条线到最后的坐标6,2。</li>
<li>每个元素的参数可以重复，不需要重新发布相同的路径字母，可以多加数字参数组。不过对于曲线，为了方便阅读，我建议你还是加上函数字母。</li>
<li>重复的参数 &ldquo;M&rdquo; 或 &ldquo;m&rdquo; 分别作为 &ldquo;L&rdquo; 或 &ldquo;l&rdquo; 处理。</li>
<li>例如：&rdquo; M 1,2 3,4 5,6 &quot; 和 &quot; M 1,2 L 3,4 L 5,6 &quot; 是一样的。</li>
<li>而：&ldquo;m 1,2 3,4 2,4 &quot; 与 &quot; m 1,2 l 3,4 l 2,4 &quot; 相同。</li>
<li>对于立方贝塞尔，所有的点（控制点和结点）都是相对于前一个路径组件的端点而言的。</li>
</ul>
<p>请注意，您可以用绝对坐标或相对坐标来指定对象。因此，你可以用相对坐标来定义一个对象，只需提供一个初始的绝对&quot;移动&quot;坐标来定位整个路径。</p>
<p>另一方面，你也可以使用其他的&quot;图形内容&quot;命令来移动整个图形在&quot;视图框&quot;或&quot;转换&quot;中的位置（见下文）。因此，在 SVG 路径中使用绝对或相对坐标并不重要。
移动、线条和路径闭合是学习 SVG 对象路径的最初起点。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Open, Completed and Closed Paths (same points)</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 40,10 L 20,50 90,10 70,40&#39;&#34;</span> path_open.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 40,10 L 20,50 90,10 70,40 40,10&#39;&#34;</span> path_complete.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 40,10 20,50 90,10 70,40 Z&#39;&#34;</span> path_closed.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_open.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_complete.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_closed.gif" alt="img"></p>
<p>但是请注意，&lsquo;z&rsquo; 只是关闭循环。它并没有创建一个单独的对象。因此，两个&quot;关闭&quot;的路径仍然被归类为一个单一的绘制对象，无论它们是重叠的还是完全断开的。</p>
<p>这里我们展示了两个闭合但重叠的循环，在同一方向上绘制。由于只使用了一条路径，所以对象是一个单一的对象，<code>fill-rule</code> 设置控制了重叠区域的填充方式。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Overlapping Paths and Fill Rule</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-rule evenodd \
</span><span class="s2">                 path &#39;M 40,10 20,20 70,50 Z
</span><span class="s2">                       M 20,40 70,40 90,10 Z&#39; &#34;</span> path_evenodd.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-rule nonzero \
</span><span class="s2">                 path &#39;M 40,10 20,20 70,50 Z
</span><span class="s2">                       M 20,40 70,40 90,10 Z&#39; &#34;</span> path_nonzero.gif

</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_evenodd.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_nonzero.gif" alt="img"></p>
<p>由于对象围绕中心以相同的角度方向绘制，两个闭合的循环将包含一个周期值为2的区域，因此 <code>evenodd</code> 规则使得该区域未被填充，而非零的 <code>nonzero</code> 规则则将其填充。但是请注意，所有的路径都是可见的，因为它们实际上是同一个对象。</p>
<p>绘制路径的方向是非常重要的，一般情况下，所有的路径相对于对象的&rsquo;内部&rsquo;应该绘制在完全相同的方向上。</p>
<p>例如这里我将第二个对象画成与第一个对象相反的方向。因此，当两个对象重叠时，该区域被圈出 &lsquo;0&rsquo; 次。也就是说，无论使用什么 <code>fill-rule</code>，它都将是未被填充的，形成一个&rsquo;洞'。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Overlapping Closed Objects, Second object drawn in reverse</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-rule evenodd \
</span><span class="s2">                 path &#39;M 40,10 20,20 70,50 Z
</span><span class="s2">                       M 20,40 90,10 70,40 Z&#39; &#34;</span> path_rvs_evenodd.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill-rule nonzero \
</span><span class="s2">                 path &#39;M 40,10 20,20 70,50 Z
</span><span class="s2">                       M 20,40 90,10 70,40 Z&#39; &#34;</span> path_rvs_nonzero.gif

</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_rvs_nonzero.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_rvs_evenodd.gif" alt="img"></p>
<p>这意味着你可以在物体上产生一个&quot;洞&rdquo;，通过反转方向，使物体的&quot;内部&quot;保持在行进方向的同一侧。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># An object with a reversed drawn hole!</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,10 20,55 70,50 80,5 Z
</span><span class="s2">                       M 50,20 60,40 40,30 Z&#39; &#34;</span> path_with_hole.gif

</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_with_hole.gif" alt="img"></p>
<p>无论 <code>fill-rule</code> 的设置如何，结果都是一样的，因为这个洞是&rsquo;偶数&rsquo;和&rsquo;零'，所以是未填充的。</p>
<p>当然，如果您使用一个完全独立的 <code>path</code> 元素，您将生成一个完全独立的对象。在这种情况下，<code>fill-rule</code> 不适用，而只是按照给定的顺序，将对象画在彼此的上方。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Separate paths are separate objects</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 40,10 20,20 70,50 Z&#39;
</span><span class="s2">                 path &#39;M 20,40 70,40 90,10 Z&#39; &#34;</span> path_separate.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_separate.gif" alt="img"></p>
<p>未来：坐标对准路径 &ldquo;H&rdquo; 和 &ldquo;V&rdquo;。</p>
<p>椭圆弧是 SVG 路径的圆圈绘制功能&hellip;</p>
<p><code>large</code> 和 <code>sweep</code> 参数特别重要，因为它们用于决定从起点到终点的四种弧线中的哪一种。</p>
<p><code>large</code> 和 <code>sweep</code> 这两个标志定义了四条弧线中哪一条弧线将连接这两个点。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1">#  Elliptical Arcs :   A  radius_x,y  angle   large,sweep  x,y</span>
  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,15 0 0,0 70,20&#39;&#34;</span>    path_arc.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,15 0 0,1 70,20&#39;&#34;</span>    path_arc2.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,15 0 1,0 70,20&#39;&#34;</span>    path_arc3.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,15 0 1,1 70,20&#39;&#34;</span>    path_arc4.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_arc.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_arc2.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_arc3.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_arc4.gif" alt="img"></p>
<p>第二个标志 <code>sweep</code> 简单地决定了弧线路径的方向的哪一边应该被绘制。</p>
<p><code>large</code> 标志是用来选择较长的路径，绕着椭圆的中心走。这是设置的角度的弧线将大于180度。如果关闭，你会得到较小的&rsquo;弧'，不包含椭圆的中心，并且弧线的角度小于180度。</p>
<p>用 &ldquo;Z&rdquo; 来关闭弧线，只是画出最后的直线段。</p>
<p>要创建一个完整的椭圆或圆，你至少需要两个&rsquo;弧线&rsquo;段，从第一点到第二点，然后回到第一点。两条弧线都应该有相同的 <code>sweep</code> 设置，所以弧线将在不同的边上，有不同的移动方向。其中一条弧线应该有 <code>large</code> 的设置。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Closed and angled elliptical arcs  (defined by two edge points)</span>

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,20  20  0,0 70,20 Z &#39;&#34;</span> path_arc5.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,20  20  1,1 70,20 Z &#39;&#34;</span> path_arc6.gif

  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40  A 30,20  20  0,0 70,20 \
</span><span class="s2">                                A 30,20  20  1,0 30,40 Z &#39;&#34;</span> path_arc7.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_arc5.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_arc6.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/path_arc7.gif" alt="img"></p>
<p>请注意，如果直线太长，在给定的角度下无法适应给定的椭圆大小，椭圆的大小将被放大，以适应以椭圆为中心的直线，这意味着通过使用小数字作为轴半径，你可以只指定轴长的比例，并保证直线路径通过椭圆的中心点。</p>
<p>这意味着，通过使用小数字的轴半径，你可以只指定一个轴长的比例，并保证直线路径穿过椭圆的中心点。也就是说，路径从椭圆的一侧到另一侧形成一个椭圆直径。这并不是椭圆的主轴或次轴，只是一个椭圆的直径。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40   A 3,2  45  0,0 70,20&#39;&#34;</span> path_arc_x.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_arc_x.gif" alt="img"></p>
<p>当然，使用长度为 &ldquo;1,1&rdquo; 的结果是一个完美的半圆，从一个点，到下一个点。在这种情况下，椭圆角不会有任何区别。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40   A 1,1  0  0,0 70,20&#39;&#34;</span> path_hcircle.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_hcircle.gif" alt="img"></p>
<p>对于以两点为中心的全圆，用&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40   A 1,1  0  0,0 70,20
</span><span class="s2">                                 A 1,1  0  1,0 30,40  Z&#39;&#34;</span> path_circle.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_circle.gif" alt="img"></p>
<p>SVG 对 &ldquo;弧线&quot;的定义也声明，如果两个半径中的任何一个是0，那么就应该画一条直线。因此，任何半径为 &ldquo;0,0&rdquo; 的圆弧，都只是一条简单的直线圆弧&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40   A 0,0  0  0,0 70,20&#39;&#34;</span> path_arc_line.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_arc_line.gif" alt="img"></p>
<p>如果你为弧线指定了一个非常大的半径，而没有为回程路径指定 <code>large sweep</code>，你可以在两点之间创建该半径的透镜形状。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 30,40   A 50,50  0  0,0 70,20
</span><span class="s2">                                 A 50,50  0  0,0 30,40  Z&#39;&#34;</span> path_lens.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_lens.gif" alt="img"></p>
<p>这种类型的弧线是一个关键特征。它可以让你很容易地把原本是直线的东西变成一条小而明显的曲线。</p>
<p>例如，与其说是一个简单的三角形，不如说是一个&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 20,55  L 25,10  L 70,5 L 20,55 Z&#39; &#34;</span>   triangle.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/triangle.gif" alt="img"></p>
<p>你可以用一个大半径的弧线代替每条线，让它们只是有轻微的曲线。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 20,55  A 100,100 0 0,0 25,10
</span><span class="s2">                                A 100,100 0 0,0 70,5
</span><span class="s2">                                A 100,100 0 0,0 20,55 Z&#39; &#34;</span> triangle_curved.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/triangle_curved.gif" alt="img"></p>
<p>线条的端点没有变化，所发生的只是每个 &ldquo;L&rdquo; 被一个弧线段代替。然而弧线的大小应该与线的长度成正比。由于我没有这样做，较长的对角线比其他两条线有更深的曲线。</p>
<p>请记住，当调整对象的大小或比例时，你也应该将半径的比例与线的长度相同，这样曲线的大小就会相应地调整，所以弧线的比例也会正确。</p>
<p>请注意，<code>sweep</code> 标志可以控制曲线是向外凸起还是向内凸起，这取决于每个路径段的绘制方向(见上文)。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 20,55  A 100,100 0 0,0 25,10
</span><span class="s2">                                A 100,100 0 0,1 70,5
</span><span class="s2">                                A 100,100 0 0,1 20,55 Z&#39; &#34;</span> triangle_bulge.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/triangle_bulge.gif" alt="img"></p>
<p>看起来 &ldquo;静态&quot;的直边三角形，现在看起来有点像充满风的帆。</p>
<p>如果你真的想让线条完美的直，而不把它们转换回真正的线段，你可以通过使用弧线半径为零来关闭曲线。</p>
<p>因此，弧线不仅适合生成椭圆和圆，而且对于绘制直线和微曲线段也很有用。它是一种非常通用的通用点到点的绘制路径。</p>
<p>使用椭圆弧来生成分离的曲线段的一个简单的替代方法是使用<a href="https://imagemagick.org/Usage/draw/#quad">四元贝塞尔段</a>来代替，主要的区别是使用一个单一的控制点，而不是一个圆形半径来定义弧线。这也允许您将弧线偏向线段的一端，但代价是难以生成对称的弧线。</p>
<p>当然，您也可以通过使用这两种方法来进行 <code>mix-n-match</code>。</p>
<h3 id="饼图示例">饼图示例</h3>
<p>为了完成对弧线的使用，让我们举个例子，使用为它们生成圆楔。当然，你可能需要使用一些外部的三角数学（你的高中数学有多好？）来确定所需的最终路径点。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 140x130 xc:white -stroke black <span class="se">\
</span><span class="se"></span>    -fill red   -draw <span class="s2">&#34;path &#39;M 60,70 L   60,20   A 50,50 0 0,1 68.7,20.8 Z&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>    -fill green -draw <span class="s2">&#34;path &#39;M 60,70 L 68.7,20.8 A 50,50 0 0,1 77.1,23.0 Z&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>    -fill blue  -draw <span class="s2">&#34;path &#39;M 68,65 L 85.1,18.0 A 50,50 0 0,1  118,65   Z&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>    -fill gold  -draw <span class="s2">&#34;path &#39;M 60,70 L  110,70   A 50,50 0 1,1   60,20   Z&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>    -fill black -stroke none  -pointsize <span class="m">10</span> <span class="se">\
</span><span class="se"></span>    -draw <span class="s2">&#34;text 57,19 &#39;10&#39; text 70,20 &#39;10&#39; text 90,19 &#39;70&#39; text 113,78 &#39;270&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>    piechart.jpg
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/piechart.jpg" alt="img"></p>
<p>请注意，所有的弧线都是画在 <code>line path</code> 的左边，并有相应的标志（使用 <code>sweep</code> 标志）。但如果弧线覆盖的角度大于180度，则需要设置 <code>large</code> 标志。见上面例子中最后一个 <code>gold</code> 组件。</p>
<p>还要注意的是，你应该完整地画出每个部分，尽管这意味着你可能要画两次边界线。如果你不这样做，你很可能要么不会完全用颜色填充该部分，要么填充颜色会覆盖之前绘制的部分轮廓。</p>
<p>避免重复绘制多条线的唯一方法是绘制所有填充区域，然后重复这样绘制轮廓。就是说你需要把所有的东西都画两遍，确保东西正确匹配。因此，将轮廓加倍可能是最简单的解决方案。</p>
<p>立方贝塞尔曲线可以使用 <code>c</code> 函数定义两个控制点，以及最终的终点。对于使用最后一个控制点的镜像的持续立方贝塞尔曲线（对于连续曲线），你可以使用 <code>s</code> 函数。</p>
<p>下面是一个例子。由于这个函数的复杂性，我预先准备了一个画布，显示控制点的位置，以及最后一个控制点的 <code>assumed mirror</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Cubic Bezier:    C  control_1_x,y control_2_x,y  x,y</span>
  <span class="c1"># Smooth &#34; :       S  control_2_x,y  x,y</span>

  convert path_cubic_canvas.gif  -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 10,30  C 10,4 50,4 50,30  S 90,55 90,30&#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          path_cubic.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_cubic.gif" alt="img"></p>
<p>连接控制点和该路径段路径上的最终点的线（控制线）基本上定义了通过路径上该点的曲线方向。长的控制线会在该点产生一条更平滑的曲线，而短的控制线则会在该点产生一条更清晰的曲线。如果控制点与曲线的点相吻合（控制线长度为零），则曲线在该点有一个尖锐的不连续性，就像只用直线段一样。</p>
<p>作为一个更实际的例子，下面的代码是从 <a href="https://imagemagick.org/Usage/scripts/generate_logo">IM 实例 Logo 生成器脚本</a>中提取出来的，该脚本创建了 <a href="https://imagemagick.org/Usage/images/logo.gif">IM 实例 Logo</a> 的曲线溅射区域。</p>
<p>这个例子的棘手之处在于，我将我使用的立方贝塞尔路径字符串，转换为另一个路径，显示用于生成贝塞尔曲线的控制线。这让我可以看到曲线的控制线角度和长度，使得调整结果变得更加容易。只需要调整一组点就可以同时显示曲线和控制线，将错误控制在最小范围内。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">   <span class="nv">curve</span><span class="o">=</span><span class="s2">&#34;M 12,27  C 7,37  18,50 18,60  S  0,80 10,94
</span><span class="s2">          S 40,74 50,78  S 60,99 76,95  S 72,70 75,65
</span><span class="s2">          S 95,55 95,42  S 69,37 66,32  S 67,2  53,7
</span><span class="s2">          S 43,17 35,22  S 17,17 12,27  Z&#34;</span>
   <span class="nv">c_ctrls</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="nv">$curve</span> <span class="p">|</span> <span class="se">\
</span><span class="se"></span>              sed <span class="s1">&#39;1s/\([0-9]\)  *\([0-9]\)/\1 M \2/;
</span><span class="s1">                   s/S/M/g; s/C/ /;&#39;</span> -<span class="sb">`</span>
   convert -size 100x100 xc:white <span class="se">\
</span><span class="se"></span>           -draw <span class="s2">&#34;stroke None  fill Green  path &#39;</span><span class="nv">$curve</span><span class="s2">&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>           -draw <span class="s2">&#34;stroke Red   fill None   path &#39;</span><span class="nv">$c_ctrls</span><span class="s2">&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>           curvy_splash.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/curvy_splash.gif" alt="img"></p>
<p>如果你仔细观察图像，你会发现曲线的起点和终点有两条方向相反的控制线。对于一个封闭的连续路径来说，开始和结束的控制线应该在相同的角度（只是在镜面方向），当然也应该是相同的长度。这一点很重要，因为很容易弄错。</p>
<p>沿着曲线的所有其他点只有一个控制点/线，它与曲线的绘制方向相反。该线段越长，曲线在该控制点处的 <code>sharp</code> 越低，长度为零则产生一个 <code>point</code>。</p>
<p><code>s</code> 函数在内部根据前一段的数据生成下一段的镜像控制点/线，从而产生曲线的平滑延续。</p>
<p>关于这个路径函数的更多例子，请看<a href="http://www.w3.org/TR/SVG/paths.html#PathDataCubicBezierCommands">《SVG：立方贝塞尔曲线命令》</a>。</p>
<p>手动生成贝塞尔曲线是比较直接的，不需要任何花哨的 GUI 工具。</p>
<ul>
<li>首先定义所有你想让曲线经过的坐标点，在列表的最后重复起始坐标。</li>
<li>现在将这个列表扩大，将所有的 <code>x,y</code> 坐标点加倍成对，并在每对坐标点前添加一个 <code>s</code>（Smooth Cubic）函数。每对中的第一个数字是控制点，连接到第二个数字代表曲线上的点。然而第一个点对却把这一点反过来了，第一个点是曲线的起点，第二个点代表第一个也是唯一一个反转的控制点。</li>
<li>将第一对坐标的函数字母由 &lsquo;S&rsquo; 改为 &lsquo;M&rsquo;，然后在这对坐标之间加一个 &lsquo;C&rsquo;。最后将第二对坐标的 &lsquo;S&rsquo; 去掉，完成初始的立方体（&lsquo;C&rsquo;）函数。</li>
<li>通过添加最后的 &lsquo;Z&rsquo; 来完成路径，关闭曲线。</li>
<li>请看上面的示例序列，它应该是怎样的。</li>
<li>此时您可以测试绘制您的路径。由于所有的控制线长度为零，所以路径将只由直线段组成。</li>
<li>现在您需要做的就是慢慢地、小心地调整控制线段的位置（每个 &ldquo;S&rdquo; 对的第一个坐标），以得到您想要的最终曲线。不要把控制线做得太长，或者方向不对，否则你会得到一条看起来非常滑稽的曲线。</li>
<li>为了帮助查看你的变化和发现错误，请使用上面的转换 &ldquo;sed&rdquo; 命令来绘制路径控制点和曲线控制点之间的控制线。但是请注意，零长度的控制线是不可见的，但是由于lin会产生一个尖锐的点，所以位置应该很明显。</li>
<li>最后，确保 &ldquo;C&rdquo; 之后的第一条控制点/线与终点控制点/线的位置完全相反。</li>
</ul>
<p>交互式曲线的生成也可以通过使用一些矢量图形编辑器来实现。</p>
<p>例如 Luis Guerra 报告说，&ldquo;Inkscape&rdquo; 生成的贝塞尔曲线可以使用 &ldquo;Edit -&gt; XML Editor&rdquo; 功能，然后选择你想要控制点的路径或形状。</p>
<blockquote>
<p>你知道有什么其他的方法可以用GUI工具来提取贝塞尔曲线（在曲线上每个点给出两个或一个控制点）。或者是一些其他的技术来生成这样的曲线？请发邮件给我! 我很乐意听到它。你将会像其他人一样，被记入该技术的名下。</p>
</blockquote>
<p>二次方贝塞尔函数是立方贝塞尔函数的简化，当两个控制点合并成一个控制点时。同样，你可以用 &lsquo;Q&rsquo; 函数开始曲线，然后用 &lsquo;T&rsquo; 函数继续曲线，镜像最后一个控制点。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1">#  Quadratic Bezier:  Q  control_x,y  x,y</span>
  <span class="c1">#  Smooth &#34; :         T  x,y</span>

  convert path_quad_canvas.gif  -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 10,30   Q 20,4 50,30   T 90,30&#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          path_quad.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/path_quad.gif" alt="img"></p>
<p>但我要提醒您，&ldquo;T&rdquo; 继续函数只适用于连接间距相等的点的路径。我不推荐使用它。</p>
<p>二次方曲线的优点是可以替代<a href="https://imagemagick.org/Usage/draw/#arcs">椭圆弧</a>，因为它使用的是实际的位置，而不是弧线的半径。它也可以使弧线偏向于一端而不是另一端，这在使用<a href="https://imagemagick.org/Usage/draw/#arcs">椭圆弧</a>时并不实用。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 20,55  Q 30,32 25,10
</span><span class="s2">                                Q 50,1 70,5
</span><span class="s2">                                Q 50,45 20,55 Z&#39; &#34;</span> triangle_bulge_2.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/triangle_bulge_2.gif" alt="img"></p>
<p>在这种情况下，弧线不是那么均匀，你得到的东西就像一个倒立的鲨鱼鳍，而不是一个帆。</p>
<p>请记住四边形弧线是抛物线，而椭圆弧线基本上是生成圆弧线段。这可能是决定你应该使用哪种类型的弧线段的关键。</p>
<p>有关此路径功能的更多例子，请参见：<a href="http://www.w3.org/TR/SVG/paths.html#PathDataQuadraticBezierCommands">SVG: Quadratic Bezier Curve Commands</a>。</p>
<h3 id="绘图表面的变形">绘图表面的变形</h3>
<p>在这些能力之上，绘制对象的绘图表面可以以各种方式变形，让你做一些令人惊奇的事情。</p>
<p>首先，你可以应用一些通用的绘图表面修改，比如&hellip; &ldquo;translate&rdquo;、&ldquo;rotate&rdquo;、&ldquo;scale&rdquo;、&ldquo;skewX&rdquo;、&ldquo;skewY&rdquo; 和 &ldquo;affine&rdquo;。</p>
<p>例如，给定一个线条的 <code>path</code>，我们可以 <code>translate</code> 绘图表面的原点或0,0点到另一个位置。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;translate 50,30
</span><span class="s2">                 image over 3,3 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>  transform_translate.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/transform_translate.gif" alt="img"></p>
<p>请注意，&ldquo;0,0&rdquo; 或绘图区域的原点现在以图像为中心，尽管Y轴在图像的顶部仍然是负数，在底部仍然是正数。</p>
<p><code>rotate</code> 操作将旋转绘图表面，所以以后在该表面上绘制的任何东西都将被旋转绘制。当然，它会围绕转换后的原点进行旋转，所以最好同时使用这两个变换运算符。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;translate 50,30    rotate -30
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>  transform_rotate.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/transform_rotate.gif" alt="img"></p>
<p><code>scale</code> 将放大和缩小原点周围的绘图面。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;translate 50,30    scale 1.5,1.5
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>  transform_scale.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/transform_scale.gif" alt="img"></p>
<p>一个常见的 <code>scale</code> 用法是将Y轴翻转，使Y的正值向上。当然原点也应该移到中心，或者左下角，以保持秩序。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;translate 50,30    scale 1,-1
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>    transform_flip.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/transform_flip.gif" alt="img"></p>
<p>最后，&ldquo;skewX&rdquo; 和 &ldquo;skewY&rdquo; 在X和Y方向上对图像进行剪切。例如，这里我们使用 &ldquo;skewX&rdquo; 给图像的垂直Y轴一个倾斜。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;translate 50,30   skewX 20
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>    transform_skewY.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/transform_skewY.gif" alt="img"></p>
<p>这些操作符在 MVG <code>-draw</code> 字符串之外有对应的操作符，供一般使用。但是这些命令行版本是运算符，并且立即应用于内存中已经存在的图像，而不是应用于尚未绘制的矢量对象的绘制表面。更多细节请看扭曲图像。</p>
<h3 id="绘制表面的平移变形">绘制表面的平移变形</h3>
<p>上述所有五种画布变换都可以组合成一个通用的 Affine Matrix Operator，可以使用 MVG 原语 &ldquo;affine&rdquo;，也可以在调用 <code>-draw</code> 之前使用 <code>-affine</code> 设置 Affine 变换。</p>
<p>Affine 变换使用一组 &ldquo;Matrix Coefficients&rdquo;，它定义了如何将你给出的坐标修改为实际的绘图坐标。</p>
<p>关于这些 &ldquo;coefficients&rdquo; 如何工作的更多细节，请参阅 <a href="https://imagemagick.org/Usage/distorts/affine/">Affine Matrix Transforms</a>。</p>
<p>例如&hellip; 要设置一个相对于对象绘制时的中心原点&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;affine 1,0,0,1,50,30
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>  affine_null.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/affine_null.gif" alt="img"></p>
<p>翻转图像&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;affine 1,0,0,-1,50,30
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span> affine_flip.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/affine_flip.gif" alt="img"></p>
<p>绕原点旋转30度&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;affine .866,-.5,.5,.866,50,30
</span><span class="s2">                 image over 4,4 0,0 &#39;terminal.gif&#39;
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 path &#39;M 0,20 -45,20 20,-25 -25,-25&#39;
</span><span class="s2">                 fill none  stroke red
</span><span class="s2">                 path &#39;M 0,10 0,-10  M 10,0 -10,0&#39; &#34;</span>    affine_rot.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/affine_rot.gif" alt="img"></p>
<p>对于更复杂的仿射变换，您可以使用为此目的创建的<a href="https://imagemagick.org/Usage/distorts/affine/#affine_scripts">仿射辅助脚本</a>。这些脚本将诸如旋转角度和中心点之类的东西转换为 Affine 坐标，你可以直接在 <code>-draw affine</code> 或 <code>-affine</code> 设置中使用。</p>
<h3 id="推弹上下文">推/弹上下文</h3>
<p>一些 MVG 原语实际上依赖于这些变换的使用才能正确使用。例如，<a href="https://imagemagick.org/Usage/draw/#primitive_circle">椭圆原语</a>只能用正交对齐的轴直接指定。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;ellipse 50,30 30,15 0,360&#34;</span>   ellipse_orthogonal.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/ellipse_orthogonal.gif" alt="img"></p>
<p>然而，通过使用<a href="https://imagemagick.org/Usage/draw/#transform">绘图变换</a>，我们可以很容易地给椭圆添加一个&quot;旋转角&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue -fill white -stroke black <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;push graphic-context
</span><span class="s2">                 translate 50,30   rotate 30
</span><span class="s2">                 fill white  stroke black
</span><span class="s2">                 ellipse 0,0 30,15 0,360
</span><span class="s2">                 pop graphic-context&#34;</span>       ellipse_rotated.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/ellipse_rotated.gif" alt="img"></p>
<p>请注意，椭圆的 <code>center</code>(旋转点)在应用旋转之前首先被转换。然后，<code>ellipse</code> 在 &ldquo;0,0&rdquo; 处的转换位置被绘制。</p>
<p>上面还显示了两个新的 MVG 绘图原语。&lsquo;push graphic-context&rsquo; 和 &lsquo;pop graphic-context&rsquo;。在上面的例子中，并不是严格意义上的需要，但在进行主要的绘图转换时，建议使用这两个原语。</p>
<p><code>push</code> 和 <code>pop</code> 原语的作用是保存当前的绘图状态或 &ldquo;graphic-context&rdquo;，然后再次恢复。在这两个原语之间更改的任何绘图设置都会被遗忘。这包括曲面变形（如 &ldquo;平移 &ldquo;和 &ldquo;旋转&rdquo;）、颜色设置 <code>fill</code> 和 <code>stroke</code> 或任何其他修改了绘图 <code>state</code> 的设置。</p>
<p>这些原语使您可以轻松地绘制具有许多变换的非常复杂的对象，然后将事物恢复到更 &ldquo;正常&quot;的状态，以便以后进行绘制操作。您可以在下面的<a href="https://imagemagick.org/Usage/draw/#arrows">绘制箭头</a>中看到更实用的演示。</p>
<h3 id="推弹特殊对象">推/弹特殊对象</h3>
<p><img src="https://imagemagick.org/Usage/img_www/const_barrier.gif" alt="img">  建设中 <img src="https://imagemagick.org/Usage/img_www/const_hole.gif" alt="img"></p>
<p>更多专门用于 MVG 处理 SVG 格式的设置。</p>
<pre><code>    font-family   font-stretch   font-style   font-weight
    encoding 'UTF-8'

    push defs

      push gradient 'def_name' linear X1,Y1 X2,Y2
        stop-color 'color' where
        stop-color 'color' where
          # where is a point between the two pixels given (0 = X1,Y1  1= X2,Y2)
        gradient-units 'objectBoundingBox|userSpaceOnUse'
        affine ....
      pop gradient

      push gradient 'def_name' radial CX,CY FX,FY R
        # Here CX,CY is the center of the radial gradient of radius R
        # the FX,FY is the focal, and is usually the same a CX,CY
        # unless you are trying to warp the gradient in a specific direction
        stop-color 'color' where
        ...
      pop gradient

    pop defs

    push graphic-context
      fill 'url(#def_name)'
      ... draw things here ...
    pop graphic-context
</code></pre><p>例子见 Florent Monnier 的开发网站&hellip;  <a href="http://www.linux-nantes.fr.eu.org/~fmonnier/OCaml/MVG/">http://www.linux-nantes.fr.eu.org/~fmonnier/OCaml/MVG/</a>。</p>
<h3 id="阅读-mvg-文件">阅读 MVG 文件</h3>
<p>正如你在上面的例子中所看到的，MVG 的 <code>-draw</code> 参数可以变得很长。事实上，SVG 到 MVG 的转换可以产生一些非常长的 MVG 绘图参数（见下文）。</p>
<p>然而，IM 的一般命令行界面允许您通过使用 <code>&quot;@filename&quot;</code> 参数从文件中读取任何字符串参数。这很方便，因为这意味着你可以从一个单独的文件中读取非常长和复杂的MVG绘图命令。</p>
<p>例如，如果我将 MVG 操作放入一个名为 &ldquo;draw_circles.mvg&rdquo; 的文件中，那么我就可以像这样绘制&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:skyblue  -draw @mvg_circles.mvg  mvg_draw.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/mvg_circles.mvg.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/mvg_draw.gif" alt="img"></p>
<p>不仅如此，ImageMagick 还懂得直接读取 &ldquo;MVG:&rdquo; 图像文件格式，让你可以更直接地绘制此类命令。然而，除非 MVG文 件定义了一个画布，否则你可能需要指定初始画布（ <code>-size</code> 和&rdquo;-background&rdquo;）来绘制。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60  -background limegreen  mvg_circles.mvg  mvg_file.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/mvg_circles.mvg.gif" alt="img"> <img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/mvg_file.gif" alt="img"></p>
<p>你可以通过在 MVG 文件中添加一个 &ldquo;viewbox&rdquo;，并添加适当的背景色填充绘制，将初始画布设置移动到 MVG 图像中。这样就完成了 MVG 图像文件作为一个完整的图像定义。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert    mvg_circles2.mvg    mvg_image.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/mvg_circles2.mvg.gif" alt="img"> <img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img"> <img src="https://imagemagick.org/Usage/draw/mvg_image.gif" alt="img"></p>
<blockquote>
<p>目前只有一种方法可以从 MVG 参数字符串中读取外部 MVG 文件，那就是使用 &ldquo;图像 &ldquo;绘图原语。遗憾的是，这将 MVG 的 include 转换为光栅图像，然后再将该图像覆盖到绘图表面。
换句话说，目前还没有MVG的 &ldquo;include&quot;功能。 :-(</p>
</blockquote>
<p><img src="https://imagemagick.org/Usage/img_www/const_barrier.gif" alt="img">  建设中 <img src="https://imagemagick.org/Usage/img_www/const_hole.gif" alt="img"></p>
<p>您可以生成IM的低级绘制操作，使用 `<a href="https://imagemagick.org/Usage/option_link.cgi?render">+render</a> 来记录它们。</p>
<p>当你再给 <code>-render</code> 设置/操作时，IM将立即绘制这些保存的操作。</p>
<p>奇怪的是，仅仅输出到 &ldquo;MVG&rdquo; 文件似乎也能做到这一点&hellip;&hellip;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">     convert  ...   -draw <span class="s1">&#39;....&#39;</span>  draw_commands.mvg
</code></pre></div><p>注意：如果你在输出 MVG 格式文件时画了一条曲线，文件中会列出以下内容。曲线是一系列的短线段，而不是原始曲线。</p>
<p>当然您也可以完全使用更通用的 SVG 格式。参见下面的 &ldquo;<a href="https://imagemagick.org/Usage/draw/#svg">SVG 格式处理</a>&quot;。</p>
<h3 id="mvg-阿尔法构成">MVG 阿尔法构成</h3>
<p><img src="https://imagemagick.org/Usage/img_www/const_barrier.gif" alt="img">  建设中 <img src="https://imagemagick.org/Usage/img_www/const_hole.gif" alt="img"></p>
<p>我没有看到任何使用 Alpha 构图的情况（除了 <code>painters</code> 的算法之外）。基本上是一种 &ldquo;over&rdquo; alpha 合成）来绘制对象。</p>
<p>然而，这并不是说不能这样做。</p>
<p>如果你喜欢将你的矩形、椭圆、圆形或其他物体用不同的阿尔法成分（如 &ldquo;DstOver&rdquo;，这是一个类似于 Under 的成分），然后在空白的透明画布上画出你的人物，同样的构图，并将其合成到您的图像上。</p>
<p>然而，由于 SVG 允许您使用 alpha 合成来绘制文本和其他的图像，因此，您可以使用 SVG 来绘制图像项目到图像上，我想这将是一个未来的补充。</p>
<p>敬请期待</p>
<h3 id="绘制符号">绘制符号</h3>
<p>有时你在图像上有一组点，你想在那里绘制参考符号，如十字、圆圈等。遗憾的是，目前IM还没有可以轻松绘制这类符号的命令，但只要稍加努力，你就可以绘制这类符号。</p>
<h4 id="符号绘制技巧">符号绘制技巧</h4>
<p>在给定的位置列表中绘制多个符号的诀窍是使用 shell 脚本或任何你正在使用的 API 生成 MVG 绘图命令，以便将给定的点集转化为适当的绘图命令集。
例如，我在这里将一条线上的点转换为每一个点的&quot;加号&rdquo;&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Define a string of X and Y coordinates</span>
  <span class="c1"># comma between values, space between coordinates.</span>
  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;6.6,7.7  25.0,75.0 42.2,85.4 75.8,94.7 51.5,39.3  92.5,66.6&#34;</span>

  <span class="c1"># convert each point into a draw command for a cross (using &#39;awk&#39;)</span>
  <span class="c1"># the &#39;tr&#39; converts spaces into &#39;newlines&#39; (one point per line).</span>
  <span class="nv">crosses</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="nv">$points</span> <span class="p">|</span> tr -s <span class="s1">&#39; &#39;</span> <span class="s1">&#39;\012&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>     awk -F, <span class="s1">&#39;{ print &#34;line &#34; $1-3 &#34;,&#34; $2 &#34; &#34; $1+3 &#34;,&#34; $2 ;
</span><span class="s1">                print &#34;line &#34; $1 &#34;,&#34; $2-3 &#34; &#34; $1 &#34;,&#34; $2+3 ; }&#39;</span> -<span class="sb">`</span>

  <span class="c1"># draw a red line between the points, and blue crosses on the points.</span>
  convert -size 100x100 xc:white <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill none stroke red   polyline </span><span class="nv">$points</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill none stroke blue  </span><span class="nv">$crosses</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          points_plus.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_plus.gif" alt="img"></p>
<p>上面使用 &ldquo;tr&rdquo; 将每个点（两个数字）分成每条线上的一个点，然后使用 &ldquo;awk&rdquo; 进行所有数学计算，在给定的点上绘制&quot;加号&rdquo;。你可以使用任何你喜欢的东西，因为我只是在输入点列表上应用了一种文本宏扩展的形式。几乎所有的编程语言都可以做到这一点。对于上面的shell脚本案例，我只是发现 &ldquo;awk&rdquo; 是最简单、最快的手段。</p>
<p>其实你甚至可以使用 Imagemagick 本身的 &ldquo;convert&rdquo; 格式选项来进行这种 &ldquo;macro&rdquo; 的扩展&hellip;比如这里我用它来计算圆周上的一个点，对于这个&quot;点符号&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Define a string of X and Y coordinates</span>
  <span class="c1"># comma between values, space between coordinates.</span>
  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;6.6,7.7  25.0,75.0 42.2,85.4 75.8,94.7 51.5,39.3  92.5,66.6&#34;</span>

  <span class="c1"># circle radius (or symbol size) to draw around each point.</span>
  <span class="nv">radius</span><span class="o">=</span>3.5

  <span class="c1"># convert each point into a draw command for a cross</span>
  <span class="c1"># In this case, points are space separated by the shell</span>
  <span class="nv">circles</span><span class="o">=</span><span class="k">$(for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
             <span class="nv">x</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$point</span><span class="s2">&#34;</span> <span class="p">|</span> cut -d, -f1<span class="k">)</span>
             <span class="nv">y</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$point</span><span class="s2">&#34;</span> <span class="p">|</span> cut -d, -f2<span class="k">)</span>
             <span class="c1"># use IM to do some floating point math, EG:  y2=$y+$radius</span>
             <span class="nv">y2</span><span class="o">=</span><span class="k">$(</span>convert xc: -format <span class="s1">&#39;%[fx:&#39;</span><span class="s2">&#34;</span><span class="nv">$y</span><span class="s2">&#34;</span><span class="s1">&#39;+&#39;</span><span class="s2">&#34;</span><span class="nv">$radius</span><span class="s2">&#34;</span><span class="s1">&#39;]&#39;</span> info:<span class="k">)</span>
             <span class="nb">echo</span> <span class="s2">&#34;circle </span><span class="nv">$x</span><span class="s2">,</span><span class="nv">$y</span><span class="s2"> </span><span class="nv">$x</span><span class="s2">,</span><span class="nv">$y2</span><span class="s2">&#34;</span>
           <span class="k">done)</span>

  <span class="c1"># Draw a red line between the points, and blue circles on the points.</span>
  convert -size 100x100 xc:white <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill none stroke red   polyline </span><span class="nv">$points</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;fill none stroke blue  </span><span class="nv">$circles</span><span class="s2"> &#34;</span> <span class="se">\
</span><span class="se"></span>          points_circle.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_circle.gif" alt="img"></p>
<p>现在，您生成的绘制字符串可能会变得相当长，并且可能会开始导致您的最终命令的长度问题。所以，与其将点转换成长字符串，然后我们在命令行上传递给 IM，不如将绘制命令以文件的形式管道化给 IM。</p>
<p>我这次也使用了 <a href="https://imagemagick.org/Usage/draw/#paths">SVG 路径</a>的绘制方法来代替 <a href="https://imagemagick.org/Usage/draw/#primitives">Draw Primitive</a> 的绘制方法。另外我生成的符号是每个点周围的三角形。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Define a string of X and Y coordinates</span>
  <span class="c1"># comma between values, space between coordinates.</span>
  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;6.6,7.7  25.0,75.0 42.2,85.4 75.8,94.7 51.5,39.3  92.5,66.6&#34;</span>

  <span class="c1"># convert each point into a draw commands to draw a triangle</span>
  <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
     <span class="nb">echo</span> <span class="s2">&#34;path &#39;M </span><span class="nv">$point</span><span class="s2">  m 0,-5 -4,+8 +8,0 -4,-8&#39;&#34;</span>
  <span class="k">done</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>    convert -size 100x100 xc:white <span class="se">\
</span><span class="se"></span>          -fill none -stroke red  -draw <span class="s2">&#34;path &#39;M </span><span class="nv">$points</span><span class="s2">&#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          -fill none -stroke blue -draw <span class="s1">&#39;@-&#39;</span> <span class="se">\
</span><span class="se"></span>          points_tri.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_tri.gif" alt="img"></p>
<p><a href="https://imagemagick.org/Usage/draw/#paths">SVG 路径</a>实际上使这一点变得更容易，通过允许相对像素移动，允许你设计符号，所以它只需要一个单一的初始绝对移动&rsquo;M'，然后再给出&rsquo;移动&rsquo;和&rsquo;线&rsquo;的序列来绘制符号。正因为如此，你实际上根本不需要任何浮点计算，因为IM draw会完成所需的定位数学。</p>
<blockquote>
<p>相对移动SVG路径项&rsquo;m&rsquo;在IM v6.4.3-5之前被破坏了。如果你的IM比这更老，上面（和下一个）的例子可能什么也画不出来。您可以通过将上面的相对移动&rsquo;m&rsquo;替换为适当的相对线序列&rsquo;l&rsquo;来解决旧版本的问题。</p>
</blockquote>
<p>现在你可以更进一步，将一个完整的MVG文件，包括画布规格，直接作为一个绘画命令的流水线输入到IM中。这次让我们做一个&rsquo;十字'，这和上面第一个&rsquo;加&rsquo;的例子类似，需要大量的计算。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="c1"># Define a string of X and Y coordinates</span>
  <span class="c1"># comma between values, space between coordinates.</span>
  <span class="nv">points</span><span class="o">=</span><span class="s2">&#34;6.6,7.7  25.0,75.0 42.2,85.4 75.8,94.7 51.5,39.3  92.5,66.6&#34;</span>

  <span class="c1"># Generate a MVG file for IM to draw all components</span>
  <span class="o">(</span> <span class="nb">echo</span> <span class="s2">&#34;viewbox 0 0 100 100   fill white  rectangle 0,0 100 100&#34;</span>
    <span class="nb">echo</span> <span class="s2">&#34;fill none stroke red   path &#39;M </span><span class="nv">$points</span><span class="s2">&#39;&#34;</span>
    <span class="nb">echo</span> <span class="s2">&#34;fill none stroke blue  path &#39;&#34;</span>
    <span class="k">for</span> point in <span class="nv">$points</span><span class="p">;</span> <span class="k">do</span>
      <span class="nb">echo</span> <span class="s2">&#34;  M </span><span class="nv">$point</span><span class="s2">  m -2,-2 +4,+4  m -4,0 +4,-4&#34;</span>
    <span class="k">done</span>
    <span class="nb">echo</span> <span class="s2">&#34;&#39;&#34;</span>
  <span class="o">)</span> <span class="p">|</span> convert mvg:- points_cross.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_cross.gif" alt="img"></p>
<p>这使用了特殊的shell编程技术，在shell括号中 &ldquo;echo&rdquo; 的任何东西都将作为MVG文件被输入到最终的&quot;转换&quot;命令中。第一个 &ldquo;echo&rdquo; 定义并填充图像的绘图画布，而 &ldquo;while&rdquo; 循环则将每个 &ldquo;点&rdquo; 转换为一个给定半径的圆。</p>
<p>这种方法的优点是，你不会受到任何字符串的限制，而使用其他两种方法可能会受到限制。</p>
<p>其他你可以生成的符号包括方框、钻石、错误条等。</p>
<p>也请参见下面的&quot;绘制圆圈&rdquo;，了解其他圆圈方法，包括不计算相对 &ldquo;路径&quot;的圆圈绘制。</p>
<h4 id="绘制符号的替代方法">绘制符号的替代方法</h4>
<p>除了直接绘制符号外，还有其他的方法可以将符号添加到图像中。</p>
<h5 id="符号字体">符号字体</h5>
<p>您可以从 <a href="https://imagemagick.org/Usage/text/#symbol">Symbol Font</a> 中提取符号，并将其保存为一个小位图。你也可以使用小的预定义但色彩丰富的图像来做这件事。</p>
<p>然而这样做可能会出现问题，无法准确定位字体相对于特定像素的位置。也就是说这不是一个非常精确的技术。但是你可以在任何像素位置组成任何图像。例如这些符号是从一些字体中提取出来的，用于这些示例页面的具体使用。</p>
<pre><code>&lt;=   =&gt;   x   +   +   +   o   o   o   o
</code></pre><p>在<a href="https://imagemagick.org/Usage/layers/#composite">分层图像</a>一节中给出了将图像合成到大背景上的例子。然而，循环的方法可能更有用，例如在<a href="https://imagemagick.org/Usage/layers/#layer_prog">分层图像</a>的程序化定位中给出了。</p>
<p>未来：使用坐标对图像进行分层的例子</p>
<h4 id="形态学">形态学</h4>
<p>另一种选择是使用<a href="https://imagemagick.org/Usage/morphology/#intro">形态学</a>，使用特殊的&quot;形状&quot;内核，如 &ldquo;磁盘&rdquo;、&ldquo;环形 &ldquo;和 &ldquo;加&rdquo;，甚至是你自己的用户定义内核，来 &ldquo;稀释&quot;单个像素。</p>
<p>例如&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 80x80 xc:black -fill white <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;point 20,15 point 55,30 point 40,60&#39;</span>  points_pixels.gif

  convert points_pixels.gif -morphology Dilate Ring    points_rings.gif

  convert points_pixels.gif -morphology Dilate Plus:4  points_pluses.gif

  convert points_pixels.gif -morphology Dilate Cross:3 points_crosses.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_pixels.gif" alt="img">
<img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/points_rings.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/points_pluses.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/points_crosses.gif" alt="img"></p>
<p>然后可以通过使用 <a href="https://imagemagick.org/Usage/masking/#alpha_shape">Alpha Shape Operator</a> 将结果直接转换为彩色叠加。</p>
<p>这样做的最大好处是，你其实不需要知道每个符号的单独位置。或者有多少个符号。但这也可能是一个缺点。一个主要的缺点是，位置只在整数位置。你不能使用浮点 &ldquo;子像素&quot;定位来&quot;绘制&rdquo;。</p>
<h4 id="卷积">卷积</h4>
<p>一个几乎相同的技术是使用 <a href="https://imagemagick.org/Usage/convolve/#convolve">Convolve</a>，使用专门设计的内核，它允许你设置不同的灰度，而不仅仅是一个简单的开/关结果，如上所述。</p>
<p>通过使用不同的<a href="https://imagemagick.org/Usage/morphology/#user">用户定义内核</a>，为图像的每一个通道（红、绿、蓝和阿尔法），甚至可以从每个像素坐标创建多色符号。</p>
<p>为此，我使用了一个我写的特殊脚本 <a href="https://imagemagick.org/Usage/scripts/image2kernel">image2kernel</a> 来将彩色图像（见右图）转换为每个通道的独立浮点卷积核。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  image2kernel -q marker.png marker.dat
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/marker.png" alt="img"></p>
<p>这将生成四个文件，比如 <a href="https://imagemagick.org/Usage/draw/marker_R.dat">marker_R.dat</a>，每个通道都有一个非常小的输入图像，这是<a href="https://imagemagick.org/Usage/morphology/#user">用户定义</a>的图像表示（原点在图像中心）。</p>
<p>现在使用这些内核数据文件，我们可以将这些单点在透明的背景上 <a href="https://imagemagick.org/Usage/convolve/#convolve">Convolve</a> 成我们彩色的标记图像。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert points_pixels.gif -alpha off <span class="se">\
</span><span class="se"></span>          <span class="se">\(</span> -clone <span class="m">0</span> -morphology Convolve @marker_R.dat <span class="se">\)</span> <span class="se">\
</span><span class="se"></span>          <span class="se">\(</span> -clone <span class="m">0</span> -morphology Convolve @marker_G.dat <span class="se">\)</span> <span class="se">\
</span><span class="se"></span>          <span class="se">\(</span> -clone <span class="m">0</span> -morphology Convolve @marker_B.dat <span class="se">\)</span> <span class="se">\
</span><span class="se"></span>          <span class="se">\(</span> -clone <span class="m">0</span> -morphology Convolve @marker_A.dat <span class="se">\)</span> <span class="se">\
</span><span class="se"></span>          -delete <span class="m">0</span> -channel RGBA -combine point_markers.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/points_pixels.gif" alt="img">
<img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/point_markers.png" alt="img"></p>
<blockquote>
<p>在IM v6.7.6-9之前，Combine Operator 要求图像的透明度通道以 &ldquo;哑光&quot;值而不是alpha值的形式给出，因此，由此产生的alpha通道需要被否定。EG:</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  ... <span class="s2">&#34;`cat marker_A.dat`&#34;</span> -negate <span class="se">\)</span> <span class="se">\
</span></code></pre></div><p>只能使用小图像，像素点要足够分散，符号不要重叠。这是因为 <a href="https://imagemagick.org/Usage/convolve/#convolve">Convolve</a> 会将重叠的区域加在一起，使其比预期的更亮。</p>
<p>以上内容已被转换成UNIX shell脚本 <a href="https://imagemagick.org/Usage/scripts/convolve_image">convolve_image</a>，以方便使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convolve_image  points_pixels.gif marker.png   point_markers.png
</code></pre></div><p>这个技术源于IM论坛上的一个讨论-<a href="https://imagemagick.org/Usage/forum_link.cgi?t=17259&amp;p=64696">IM 的有趣体验</a>。用户希望在足球场的背景图上放置小人，让他们的位置在图片中拼出一个人的名字。</p>
<h4 id="分层">分层</h4>
<p>一种不同的技术，如<a href="https://imagemagick.org/Usage/layers/">图像层</a>，使用你从源图像中提取的像素列表进行定位，可能是更好的方法。你可以先叠加更远的符号图像，然后再叠加前景图像，你可以通过编程选择或随机选择什么符号替换什么点。</p>
<p>关于这个例子，请看<a href="https://imagemagick.org/Usage/layers/#layer_pins">地图中的图钉</a>。</p>
<h4 id="绘制圆圈">绘制圆圈</h4>
<p>绘制选项为您提供了许多方法来完成一些非常基本的工作。绘制圆。</p>
<p>例如，您可以在圆周上的任何一点上画一个圆，因此您需要计算一个中心点和一个半径为25像素的第二点。因此，您需要计算一个中心点和第二个点，这个点的半径（例如25像素）离第一个点的距离。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke Firebrick  -fill tomato  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;circle 50,30 50,55&#39;</span>    circle_circle.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_circle.gif" alt="img"></p>
<p><a href="http://www.fmwconcepts.com/fmw/fmw.html">Fred Weinhaus</a> 指出，通过使用平移，你可以消除计算圆边坐标的需要，而直接给出半径即可。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke SeaGreen  -fill PaleGreen  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;translate 50,30 circle 0,0 25,0&#39;</span>    circle_circle_trans.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_circle_trans.gif" alt="img"></p>
<p>但是当绘制多个圆时，上述操作需要对每个圆进行单独的 <code>-draw</code> 操作，或者使用 <a href="https://imagemagick.org/Usage/draw/#push_context">Context Pushing</a>。</p>
<p>使用椭圆可以直接指定半径为轴长</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke Sienna  -fill Wheat  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;ellipse 50,30 25,25 0,360&#39;</span>    circle_ellipse.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_ellipse.gif" alt="img"></p>
<p>你也可以用 <code>stroke-lineecap round</code> 画一条非常非常短的线来生成一个圆。描边的宽度可以设置圆的直径。注意线条必须有一定的长度（无论多小），否则画不出任何东西。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke Blue  -strokewidth <span class="m">50</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;stroke-linecap round line 50,30 50,30.0001&#39;</span> <span class="se">\
</span><span class="se"></span>          circle_line.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_line.gif" alt="img"></p>
<p>这种技术，不幸的是不能勾勒出生成的圆，但对于覆盖大面积的区域，大笔触宽度是有用的。请看下面一些简单的例子。</p>
<p>这种方法利用了 <a href="https://imagemagick.org/Usage/draw/#paths">SVG 路径</a>的绘制方法，所以可以在不需要计算任何额外坐标的情况下绘制圆形。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke Blue  -fill DodgerBlue  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;path &#39;M 50,30  m 0,25  a 1,1 0 0,0 0,-50  a 1,1 0 1,0 0,50&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>          circle_path.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_path.gif" alt="img"></p>
<p>只有最初的绝对移动 &lsquo;M&rsquo; 是用来定义中心的，接下来的路径组件中的 &lsquo;25&rsquo; 和 &lsquo;50&rsquo; 是定义相对于这个中心的圆的半径和直径。</p>
<blockquote>
<p>在IM v6.4.3-5之前，相对移动SVG路径项 &rsquo;m' 是被破坏的。 如果您的IM比这更早，圆可能只显示为一个像素。您可以通过将上面的 &rsquo;m' 替换为 &lsquo;l&rsquo; 来修复旧版本的问题。</p>
</blockquote>
<p><a href="http://www.fmwconcepts.com/fmw/fmw.html">Fred Weinhaus</a> 添加了以下贝塞尔圆的方法。它非常接近真实的圆（虽然不精确），并且需要进行浮点计算。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">r</span><span class="o">=</span>25<span class="p">;</span>  <span class="nv">cx</span><span class="o">=</span>50<span class="p">;</span>  <span class="nv">cy</span><span class="o">=</span>30<span class="p">;</span>
  <span class="nv">x1</span><span class="o">=</span>25<span class="p">;</span>     <span class="nv">x2</span><span class="o">=</span>75<span class="p">;</span>      <span class="c1"># = cx ± radius</span>
  <span class="nv">y1</span><span class="o">=</span>-3.25<span class="p">;</span>  <span class="nv">y2</span><span class="o">=</span>63.25<span class="p">;</span>   <span class="c1"># = cy ± radius*1.275</span>

  convert -size 100x60 xc:  -stroke Purple  -fill Violet  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;bezier </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2"> </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$y1</span><span class="s2">  </span><span class="nv">$x2</span><span class="s2">,</span><span class="nv">$y1</span><span class="s2"> </span><span class="nv">$x2</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;bezier </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2"> </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$y2</span><span class="s2">  </span><span class="nv">$x2</span><span class="s2">,</span><span class="nv">$y2</span><span class="s2"> </span><span class="nv">$x2</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>          circle_bezier.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_bezier.gif" alt="img"></p>
<p>如果画一个精确的圆并不重要，你可以使用这个4 Bezier段 SVG 路径，它只使用圆的X和Y边界进行计算。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">r</span><span class="o">=</span>25<span class="p">;</span>  <span class="nv">cx</span><span class="o">=</span>50<span class="p">;</span>  <span class="nv">cy</span><span class="o">=</span>30<span class="p">;</span>
  <span class="nv">x1</span><span class="o">=</span>25<span class="p">;</span>    <span class="nv">x2</span><span class="o">=</span>75<span class="p">;</span>      <span class="c1"># X bounds = cx ± radius</span>
  <span class="nv">y1</span><span class="o">=</span>5<span class="p">;</span>     <span class="nv">y2</span><span class="o">=</span>55<span class="p">;</span>      <span class="c1"># Y bounds = cy ± radius</span>

  convert -size 100x60 xc:  -stroke Tomato  -fill Gold  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>     -draw <span class="s2">&#34;path &#39;M </span><span class="nv">$cx</span><span class="s2">,</span><span class="nv">$y1</span><span class="s2"> Q </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$y1</span><span class="s2"> </span><span class="nv">$x1</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2"> T </span><span class="nv">$cx</span><span class="s2">,</span><span class="nv">$y2</span><span class="s2"> </span><span class="nv">$x2</span><span class="s2">,</span><span class="nv">$cy</span><span class="s2"> </span><span class="nv">$cx</span><span class="s2">,</span><span class="nv">$y1</span><span class="s2"> z&#39;&#34;</span> <span class="se">\
</span><span class="se"></span>     circle_bezier_path.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_bezier_path.gif" alt="img"></p>
<p>如果你喜欢一个完全相对于中心起点绘制的，你可以使用这种技术。只使用半径值，使其生成简单，只使用 API 中的字符串函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x60 xc:  -stroke Orange  -fill LemonChiffon  -strokewidth <span class="m">2</span> <span class="se">\
</span><span class="se"></span>     -draw <span class="s2">&#34;path &#39;M 50,30  m 0,25  q 25,0 25,-25  t -25,-25  -25,25  25,25 z&#39;&#34;</span><span class="se">\
</span><span class="se"></span>     circle_bezier_path_rel.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/circle_bezier_path_rel.gif" alt="img"></p>
<p>你能想到其他画圆的方法吗？</p>
<h3 id="绘制箭头-定位旋转和缩放符号">绘制箭头-定位、旋转和缩放符号</h3>
<p>使用上述技术，你可以创建一个特殊的符号，如箭头，你可以定位，使其点在线的最末端，并画在它上面。如果你画的箭头后的线（典型的情况），那么箭头将被绘制在该行的顶部。</p>
<p>然而，他们有三种类型的箭头，可以定义，每个类型的定义在不同的方式取决于它的使用。</p>
<ul>
<li>测量时，你只是想用箭头头标记线的两端，以指示一些工程图中的测量极限。非常简单。</li>
<li>矢量，显示一些数值的方向和强度。例如在天气风图中。需要一个尾巴，0,0点就是尾巴的末端。通常情况下，这样的向量会形成一个大网格。</li>
<li>指标，指出一些细节。对于这个0,0点可能应该是箭尖，或者是箭头本身前面的一些距离。</li>
</ul>
<h4 id="测量箭头">测量箭头</h4>
<p>简单地在一条线的末端添加一个箭头是比较容易做到的。基本上，您可以创建一个 &lsquo;arrow head&rsquo; <a href="https://imagemagick.org/Usage/draw/#symbols">符号</a>，并将其画在正确的位置。</p>
<p>例如&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">arrow_head</span><span class="o">=</span><span class="s2">&#34;l -15,-5  +5,+5  -5,+5  +15,-5 z&#34;</span>

  convert -size 100x60 xc: -draw <span class="s1">&#39;line 10,30 80,30&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke blue fill skyblue
</span><span class="s2">                 path &#39;M 80,30  </span><span class="nv">$arrow_head</span><span class="s2">&#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_horizontal.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_horizontal.gif" alt="img"></p>
<p>请注意，我画的符号，使其起点是线的最末端。这样一来，它就可以在之前画好的线上面向后画，形成一个非常漂亮的整齐的符号。</p>
<p>箭头却有一个相关的方向。你可以在许多不同的角度创建大量的箭头定义，许多程序都这样做。但是既然箭头是一个矢量，那么为什么不把箭头作为一个矢量进行旋转呢。IM绘图命令内置了绘图旋转（<a href="https://imagemagick.org/Usage/draw/#transform">Canvas Warping</a>），所以让我们使用它们。</p>
<p>这样做还有一个好处，就是把位置从箭头头的 <code>path</code> 定义中移出来，让你把整个路径指定为 <code>constant</code>&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">arrow_head</span><span class="o">=</span><span class="s2">&#34;path &#39;M 0,0  l -15,-5  +5,+5  -5,+5  +15,-5 z&#39;&#34;</span>

  convert -size 100x60 xc: -draw <span class="s1">&#39;line 25,55 70,10&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke blue fill skyblue
</span><span class="s2">                 translate 70,10 rotate -45
</span><span class="s2">                 </span><span class="nv">$arrow_head</span><span class="s2">
</span><span class="s2">                &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_rotate.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_rotate.gif" alt="img"></p>
<p>如果你喜欢改变箭头的大小，可以在旋转后增加一个 <code>scale</code> 绘制选项。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">arrow_head</span><span class="o">=</span><span class="s2">&#34;path &#39;M 0,0  l -15,-5  +5,+5  -5,+5  +15,-5 z&#39;&#34;</span>

  convert -size 100x60 xc: -draw <span class="s1">&#39;line 25,55 70,10&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke blue fill skyblue
</span><span class="s2">                 translate 70,10 rotate -45 scale 2,2
</span><span class="s2">                 </span><span class="nv">$arrow_head</span><span class="s2">
</span><span class="s2">                &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_scale.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_scale.gif" alt="img"></p>
<p>请注意，它是如何放大离开箭头的&quot;尖端&rdquo;，你指定的地方。这是处理箭头的一个非常重要的方面，因为它是唯一的终点，和角度的线，你正在添加箭头的事项。</p>
<p><code>transforms</code> 的顺序是很重要的，而且实际上与它们实际被处理的顺序是相反的。也就是先将比例尺应用于座标，然后是旋转，再是平移。如果座标变换不是按照这个顺序进行的，我们最终也会对箭头的最终位置进行缩放，而不是我们期望的位置。</p>
<p>另外由于比例尺有两个数字，而原来的箭头头符号是水平设计的（角度为零），所以可以分别将箭头的宽度与高度进行比例。同时注意笔画宽度也随着箭头的大小而缩放，保持一致。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">arrow_head</span><span class="o">=</span><span class="s2">&#34;path &#39;M 0,0  l -15,-5  +5,+5  -5,+5  +15,-5 z&#39;&#34;</span>

  convert -size 100x60 xc: -draw <span class="s1">&#39;line 25,55 70,10&#39;</span> <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke blue fill skyblue
</span><span class="s2">                 translate 70,10 rotate -45 scale 2,1
</span><span class="s2">                 </span><span class="nv">$arrow_head</span><span class="s2">
</span><span class="s2">                &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_scale_aspect.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_scale_aspect.gif" alt="img"></p>
<p>现在，当你在画布上翘起一个个箭头时，也许还有许多其他的绘画操作，你可能喜欢在一次 <code>[&quot;-draw&quot;](https://imagemagick.org/Usage/option_link.cgi?draw)</code> 操作中把它们全部画完。说要画线，然后在两端添加箭头，需要不同的颜色、位置、旋转，甚至可能是不同的比例。这意味着我们需要将画布翘曲的范围限制在每个单独箭头头的绘制上。如果你不限制范围，你可能会在以后开始影响到其他后面的绘制操作，永远不能很确定你生成的是什么。</p>
<p>为了限制翘曲的范围（以及所有其他的绘图属性），您将涉及到的部分包裹在一个 <code>graphic-context</code>&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">arrow_head</span><span class="o">=</span><span class="s2">&#34;path &#39;M 0,0  l -15,-5  +5,+5  -5,+5  +15,-5 z&#39;&#34;</span>

  convert -size 100x60 xc: <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke black fill none
</span><span class="s2">                 path &#39;M 10,40 A 50,50 0 0,1 90,40&#39;
</span><span class="s2">                 push graphic-context
</span><span class="s2">                   stroke blue fill skyblue
</span><span class="s2">                   translate 10,40 rotate 135
</span><span class="s2">                   </span><span class="nv">$arrow_head</span><span class="s2">
</span><span class="s2">                 pop graphic-context
</span><span class="s2">                 push graphic-context
</span><span class="s2">                   stroke firebrick fill tomato
</span><span class="s2">                   translate 90,40 rotate 45
</span><span class="s2">                   </span><span class="nv">$arrow_head</span><span class="s2">
</span><span class="s2">                 pop graphic-context
</span><span class="s2">                &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_context.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_context.gif" alt="img"></p>
<p><code>push</code> 主要是将当前所有的绘图属性保存起来，以备将来使用，而 <code>pop</code> 则恢复这些属性，用之前保存的设置替换任何设置（颜色、扭曲、位置等）。这意味着在 &lsquo;popping&rsquo; 之后，&lsquo;canvas warp&rsquo; 会被取消，画图会回到修改之前的状态。</p>
<p>上述技术只是生成箭头的一种方法，在绘制箭头作为测量距离的一部分时，如在技术图纸中，是一种很好的方法。</p>
<h4 id="矢量箭头">矢量箭头</h4>
<p>如前所述，矢量既显示方向，又显示某个数值的强度。这意味着箭头的长度是可变的，箭头头可以在任何位置远离向量的起点。</p>
<p>现在，你可以做一些沉重的数学计算的位置，箭头头应该是地方给定的向量的长度和角度，但他们是一个更好的方法，这让 ImageMagick 为你做这些计算。</p>
<p>解决的办法是在 <a href="https://imagemagick.org/Usage/draw/#transform">Warped Canvas Space</a> 中画一条长度合适的水平线作为向量长度。当这条线画好后，只需将绘图空间再次转换到线的末端，而画布仍然是&quot;扭曲的&rdquo;(<code>warped</code>)。现在你的位置已经正确了，只要正确的旋转就可以像正常的那样画出矢量的 <code>'arrow head'</code>。</p>
<p>例如，这里我以-35度角生成一个70像素长的矢量。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  <span class="nv">vector_head</span><span class="o">=</span><span class="s2">&#34;path &#39;M 0,0  l -15,-5  +5,+5  -5,+5  +15,-5 z&#39;&#34;</span>
  <span class="nv">indicator</span><span class="o">=</span><span class="s2">&#34;path &#39;M 10,0  l +15,+5  -5,-5  +5,-5  -15,+5  m +10,0 +20,0 &#39;&#34;</span>

  convert -size 100x100 xc: <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;stroke black fill none  circle 20,50 23,50
</span><span class="s2">                 push graphic-context
</span><span class="s2">                   stroke blue fill skyblue
</span><span class="s2">                   translate 20,50 rotate -35
</span><span class="s2">                   line 0,0  70,0
</span><span class="s2">                   translate 70,0
</span><span class="s2">                   </span><span class="nv">$vector_head</span><span class="s2">
</span><span class="s2">                 pop graphic-context
</span><span class="s2">                 push graphic-context
</span><span class="s2">                   stroke firebrick fill tomato
</span><span class="s2">                   translate 20,50 rotate 40
</span><span class="s2">                   </span><span class="nv">$indicator</span><span class="s2">
</span><span class="s2">                   translate 40,0 rotate -40
</span><span class="s2">                   stroke none fill firebrick
</span><span class="s2">                   text 3,6 &#39;Center&#39;
</span><span class="s2">                 pop graphic-context
</span><span class="s2">                &#34;</span> <span class="se">\
</span><span class="se"></span>          arrow_with_tails.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arrow_with_tails.gif" alt="img"></p>
<h4 id="指示箭头">指示箭头</h4>
<p>在上面我还演示了一个指示箭头，指向之前矢量箭头的起点。</p>
<p>然而我没有像之前那样画箭头，而是将它创建为一个反向的箭头符号，它的起始点距离原点（或起始点）10像素。这是一个符号位于我想要指示的位置，所以我实际上并不希望箭头直接在那个位置上面，而是离它稍微远一点。</p>
<p>现在，虽然指示符比向量处理起来更简单，通常不需要可变长度，但你通常要在指示符的远端添加文字来指定指示的内容。和之前一样，计算这个位置可能很困难，何必呢。</p>
<p>文字定位的解决方法也和向量一样。保留原来用于绘制指示箭头的翘曲空间，并将原点转换到该箭头的尾端（在翘曲空间中水平40像素）。现在我们已经重新定位了，我们可以围绕这个新的位置解除扭曲，这样你就可以像正常的那样绘制文本（有轻微的偏移）。</p>
<p>不幸的是，虽然默认的文字对齐方式是&quot;左&rdquo;，但目前你不能在 MVG 中指定文字对齐方式，作为重力的单独设置。如果这是一个问题，请在 IM bugs 论坛上提出请求，希望文本对齐（作为独立于重力定位）能够成为现实，尤其是它实际上是 SVG 规范的一部分。</p>
<h3 id="绘制对象">绘制对象</h3>
<h4 id="宽广的色彩笔触">宽广的色彩笔触</h4>
<p>你不需要用路径或轮廓完全封闭填充区域，就能创造出各种形状。使用非常大和宽的<a href="https://imagemagick.org/Usage/draw/#stroke">笔触</a>，你可以在画布上生成大面积的颜色和色块。</p>
<p>例如，一个宽阔的笔触椭圆弧形可以生成一个漂亮的颜色区域，我实际上已经看到用于创建海报。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x100 xc: -fill none -stroke powderblue <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;stroke-width 70 ellipse -30,0 90,90 10,50&#39;</span> <span class="se">\
</span><span class="se"></span>          -rotate <span class="m">180</span>  arc_background.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/arc_background.gif" alt="img"></p>
<p>或者你可以生成一个小丑相当复杂的笑容。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 100x100 xc: <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;fill none stroke-linecap round
</span><span class="s1">             stroke-width 40 stroke tomato ellipse 50,0 70,70 65,115
</span><span class="s1">             stroke-width 2  stroke black  ellipse 50,0 70,70 60,120
</span><span class="s1">             stroke-width 40 stroke palegreen line 50,40 50,40.01&#39;</span> clown.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/clown.gif" alt="img"></p>
<p>你能想出什么办法？请告诉我们。</p>
<h4 id="圆柱体">圆柱体</h4>
<p>在 <a href="https://imagemagick.org/Usage/forum_link.cgi?t=17550">IM 论坛的讨论</a>中，有一个关于使用 ImageMagick 绘制命令绘制圆柱体（特别是阴影圆柱体）的重要讨论。</p>
<p>绘制圆柱体的诀窍是绘制 <code>roundrectangle</code> 原语，使其末端形成椭圆形。也就是说，如果圆柱体的宽度为 50 像素，则将矩形的角分别舍去 25 和 12 像素。这就是矩形宽度的一半，然后再减半。</p>
<p>这样，一个圆柱体就变成了两个相互叠加的圆角矩形。第二个颜色填充的 <code>'end oval'</code> 的大小正好是两个角的两倍。例如&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 60x100 xc:white -stroke snow4 <span class="se">\
</span><span class="se"></span>          -fill chartreuse3    -draw <span class="s1">&#39;roundrectangle 5,5 55,95 25,12&#39;</span> <span class="se">\
</span><span class="se"></span>          -fill chartreuse2    -draw <span class="s1">&#39;roundrectangle 5,5 55,29 25,12&#39;</span> <span class="se">\
</span><span class="se"></span>          cylinder.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/cylinder.gif" alt="img"></p>
<p>通过将第一种填充色替换为渐变色（使用<a href="https://imagemagick.org/Usage/canvas/#tile_memory">记忆中的平铺技术</a>），你可以让圆柱体看起来更像3D&hellip;&hellip;。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 60x100 xc:white -stroke snow4 <span class="se">\
</span><span class="se"></span>          <span class="se">\(</span> -size 1x60 gradient:chartreuse1-chartreuse4 -rotate -90 <span class="se">\
</span><span class="se"></span>             -write mpr:shading +delete <span class="se">\)</span> <span class="se">\
</span><span class="se"></span>          -tile mpr:shading  -draw <span class="s1">&#39;roundrectangle 5,5 55,95 25,12&#39;</span> +tile <span class="se">\
</span><span class="se"></span>          -fill chartreuse2  -draw <span class="s1">&#39;roundrectangle 5,5 55,29 25,12&#39;</span> <span class="se">\
</span><span class="se"></span>          cylinder_shade.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/cylinder_shade.gif" alt="img"></p>
<p>通过慢慢完善圆柱体的绘制（如IM论坛中讨论的那样），你可以走很长的路来生成非常复杂和具有视觉吸引力的圆柱体。这包括增加封闭半透明玻璃圆柱体、阴影效果和标签。</p>
<p>该讨论的最终结果是一个脚本 &ldquo;<a href="https://imagemagick.org/Usage/scripts/cylinder_bar">cylinder_bar</a>&quot;，生成一个圆柱体百分比条&hellip;&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  cylinder_bar <span class="m">95</span> cylinder_95.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/cylinder_95.png" alt="img"></p>
<p>该脚本可以生成任何尺寸的图像，根据该尺寸和脚本顶部定义的其他设置适当调整所有参数。还包括 <code>glass thickness</code> 的概念，在一个封闭的半透明玻璃圆柱体和内部的彩色圆柱体之间创造一个间隙。</p>
<p>请注意圆柱体非常微妙的阴影，特别是当绿色圆柱体的末端与玻璃圆柱体的末端重叠时。只要稍加预想，就能做出惊人的效果。</p>
<h3 id="在文字串中绘制特殊字符">在文字串中绘制特殊字符</h3>
<h4 id="引号还是反斜杠">引号还是反斜杠？</h4>
<p>人们在使用 <code>-draw</code> 时遇到的最大的问题之一是绘制字符，这些字符对 UNIX shell 和 DOS 命令行甚至其他语言如 C、Perl、PHP、R 或 Visual Basic 都有特殊意义。</p>
<p>在这方面最大的罪魁祸首是两种类型的引号字符，以及变量替换字符，如美元 <code>'$'</code> 和 shell 和 ImageMagick 的转义字符，反斜杠 <code>'\'</code>。</p>
<p>基本上作为 <code>-draw</code> 的MVG参数需要加引号，而里面的 <code>'text'</code> 字符串参数也可能需要一些额外的引号。</p>
<p>为了解决这个问题，用户通常会使用两个不同的引号字符，一个用于 shell，另一个用于 MVG 文本字符串。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">-draw <span class="s1">&#39;... text 0,0 &#34;string&#34; ...&#39;</span>
</code></pre></div><p>需要注意的是，对于 windows 用户来说，这是唯一真正的选择，它有自己的引号问题和方法。或者他们会交换引号，用&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">-draw <span class="s2">&#34;... text 0,0 &#39;string&#39; ...&#34;</span>
</code></pre></div><p>它允许你包含 shell 变量替换(使用 <code>'$'</code> 而不进行转义。)</p>
<p>选择正确的形式可以解决大多数问题，但有些字符仍然存在困难，每个解决方案都取决于你到底使用哪一组引号，因为它们也定义了特殊字符应该如何转义。</p>
<p>以下是四种情况下的引号，以及特殊字符的处理&hellip;</p>
<ul>
<li>对 shell 参数使用单引号，对 MVG 文本字符串周围使用双引号。</li>
</ul>
<p>处理绘制文本字符串的最简单的技术是为包装 shell 参数使用单引号。然而，这意味着要在绘制的字符串中包含一个撇号，你需要离开 shell 的&quot;单引号模式&rdquo;，并在 shell 的单引号之外提供撇号。</p>
<p>例如，这里是如何处理我提到的四个特殊字符。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 250x50 xc:none  -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;text 0,0 &#34;  &#39;</span><span class="se">\&#39;</span><span class="s1">&#39;  \&#34;  $  \\  &#34; &#39;</span> <span class="se">\
</span><span class="se"></span>          -trim +repage  text_special_sd.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/text_special_sd.gif" alt="img"></p>
<p>请注意，由于美元符号不需要转义，你也不能用它来替代 shell 变量的内容。</p>
<p>重要的是要记住，反斜杠是IM绘图字符串处理的唯一特殊字符。同时，它存在的原因也纯粹是为了让你可以转义任何&quot;IM 绘制字符串引号&rdquo;，比如我们在上面使用的双引号。除此以外，其他所有的怪异都是由 UNIX 命令行 shell 引起的，而不是 IM。</p>
<p>PC-DOS 有它自己的怪异之处，我希望在使用环境中的IM时，能对特殊字符进行转义。</p>
<ul>
<li>在 shell 参数中使用双引号。
在 MVG 文本字符串周围使用单引号。</li>
</ul>
<p>如果你确实想在绘制的字符串中插入一个 &lsquo;shell variable&rsquo;，那么你将不得不在 shell 参数的外面使用双引号。这使得整个事情变得更加复杂，因为你失去了 shell 的保护，你现在不仅要转义美元 <code>'$'</code> 符号，而且还要转义反斜杠 <code>'\'</code>。</p>
<p>另一方面，shell 将不需要使用单引号字符作为它的参数结束限制字符，所以这方面被简化了。让我们总结一下我们的特殊字符短名单的结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 250x50 xc:none  -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;text 0,0 &#39;  \\&#39;  \&#34;  \$  \\\\  &#39; &#34;</span> <span class="se">\
</span><span class="se"></span>          -trim +repage  text_special_ds.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/text_special_ds.gif" alt="img"></p>
<p>请注意，如果你想画一个反斜线本身，MVG 文本字符串需要将反斜线加倍（如前面的例子），但是 shell 本身也需要将每个反斜线加倍，总共产生四个反斜线才能产生一个这样的字符。</p>
<p>这种翻倍很快就会让人不知所措，需要大量的反斜杠才能达到你想要的效果。只要采取的是慢慢的、简单的方法，你就会针对自己的情况想出办法。</p>
<ul>
<li>使用单引号进行 shell 论证。
与 MVG 文本字符串周围的单引号。</li>
</ul>
<p>最后，让我们总结一下最后两种引号组合。我将让你去弄清楚它们是如何被 shell 和 MVG 解码的。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 250x50 xc:none  -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s1">&#39;text 0,0 &#39;</span><span class="se">\&#39;</span><span class="s1">&#39;  \&#39;</span><span class="se">\&#39;</span><span class="s1">&#39;  &#34;  $  \\  &#39;</span><span class="se">\&#39;</span><span class="s1">&#39; &#39;</span> <span class="se">\
</span><span class="se"></span>          -trim +repage  text_special_ss.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/text_special_ss.gif" alt="img"></p>
<ul>
<li>在shell参数中使用双引号。</li>
</ul>
<p>在 MVG 文本字符串周围加上双引号。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 250x50 xc:none  -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>          -draw <span class="s2">&#34;text 0,0 \&#34;  &#39;  \\\&#34;  \$  \\\\  \&#34;&#34;</span> <span class="se">\
</span><span class="se"></span>          -trim +repage  text_special_dd.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/text_special_dd.gif" alt="img"></p>
<p>正如你所看到的，来自命令行的 <code>-draw</code> 参数既要处理命令行 shell，也要处理 MVG 文本字符串中的反斜杠和引号转义。其结果可能会让人感到困惑和棘手。只要记住，shell 对这两种引号的处理方式不同，而 MVG 文本字符串则不同。</p>
<p>当然，在复杂的脚本中，更好的方法可能是完全避免 shell 和任何脚本问题。你可以通过读取 MVG 绘图文件中的 <code>-draw</code> 参数来实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">-draw @drawfile.mvg
</code></pre></div><p>当然，你仍然需要对你使用的任何引号字符进行反斜杠处理，以及对文本中的任何反斜杠进行处理。然而，这比起同时处理 shell 自己的引号和转义系统要简单得多。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -size 500x50 xc:lightblue  -font Candice -pointsize <span class="m">36</span> <span class="se">\
</span><span class="se"></span>          -gravity center     -draw @text_quotes.mvg      text_quotes.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/img_www/right.gif" alt="img"><img src="https://imagemagick.org/Usage/draw/text_quotes.gif" alt="img"></p>
<p>第一张图片来自我使用的一个 &ldquo;MVG&rdquo; 文本文件。它不包含转义符或引号。因此，只有 MVG 引号和转义符是存在的。</p>
<p>请注意，在上面的例子中，如果我对 MVG 文本字符串使用了单引号，唯一的变化是我需要对字符串中的单引号字符进行反斜杠处理，而不是双引号字符。</p>
<h4 id="关于百分比字符">关于百分比字符</h4>
<p>最后一点是关于 <code>&quot;-draw text&quot;</code> 操作符中的特殊 <code>escape</code> 字符。百分号字符 <code>&quot;%&quot;</code> 应该&quot;按原样&quot;绘制。你不需要做任何特殊的操作来绘制它们。如果它们不能&quot;按原样&quot;绘制，那么你的IM版本较旧，应该尽快升级。</p>
<blockquote>
<p>直到IM 6.2.4版本，<code>&quot;%&quot;</code> 字符被用作转义字符，在绘制的文本字符串中包含额外的图像信息。现在不再是这样了，因为当SVG图像也试图绘制百分数字符时，这种转义符是混乱和不正确的。
百分号 &ldquo;转义符 &ldquo;的使用（以及&rdquo;/n &ldquo;换行符）被认为与 <code>-draw</code> 操作符和MVG格式处理SVG图像格式的预期用途不兼容。因此，从 IM 6.2.4 版本开始，%转义就不适用了，反斜杠只能转义自己和周围的引号。</p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 250x50 xc:none -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>            -draw <span class="s1">&#39;text 0,0 &#34;%w\n%h&#34;&#39;</span>    -trim +repage text_escapes.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/text_escapes.gif" alt="img"></p>
<p>关于&quot;百分比错误&quot;的更多细节，以及在旧版 ImageMagick 中使用 <code>-draw</code> 时避免该错误的方法，请参见 <a href="https://imagemagick.org/Usage/bugs/draw_percent/">Drawing a Percent Bug</a> 页面。</p>
<h4 id="用注释代替绘制">用注释代替绘制</h4>
<p>避免这类问题的较好方法是使用 <code>[-annotate](https://imagemagick.org/Usage/option_link.cgi?annotate)</code> 而不是  <code>draw</code> 来绘制文本。这个操作符是 <code>draw</code> 操作符的一个封装器，可以使用 <code>draw</code> 的所有功能，但形式更简单。</p>
<p>基本上这个操作符只需要一组引号（对于 shell）。这使得处理特殊字符变得更加简单。</p>
<p>不幸的是，虽然你不再需要为 IM 转义引号，但你现在有百分比转义，如 <code>'@'</code> 文件读取，<code>'\n'</code> 换行，以及其他<a href="https://imagemagick.org/Usage/basics/#arg_percent">百分号转义</a>扩展。</p>
<p>例如，使用单引号&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 200x50 xc:none  -box white  -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>            -annotate <span class="m">0</span> <span class="s1">&#39;\@  &#39;</span><span class="se">\&#39;</span><span class="s1">&#39;  &#34;  $  \\  %% &#39;</span> <span class="se">\
</span><span class="se"></span>            -trim +repage  annotate_s.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/annotate_s.gif" alt="img"></p>
<p>而对于双引号&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 200x50 xc:none -box white -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>            -annotate <span class="m">0</span> <span class="s2">&#34;\@  &#39;  \&#34;  \$  \\\\  %% &#34;</span> <span class="se">\
</span><span class="se"></span>            -trim +repage  annotate_d.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/annotate_d.gif" alt="img"></p>
<p>然而，如果你使用 <code>'@'</code> 转义符从文件中读取字符串，所有的注释引号和转义符将被完全忽略。</p>
<p>例如，我们在这里包含了一个图像的宽度和高度的信息!</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    convert -size 200x50 xc:none -box white -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>            -annotate <span class="m">0</span> <span class="s1">&#39;%w\n%h&#39;</span> -trim +repage    annotate_percents.gif
</code></pre></div><p>然而，当从文件中读取注释字符串时，所有的转义都会被完全忽略。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">    <span class="nb">echo</span> -n <span class="s1">&#39;@ %w\n%h&#39;</span> <span class="p">|</span><span class="se">\
</span><span class="se"></span>      convert -size 200x50 xc:none -box white -pointsize <span class="m">20</span> -gravity center <span class="se">\
</span><span class="se"></span>              -annotate <span class="m">0</span> <span class="s1">&#39;@-&#39;</span>  -trim +repage  annotate_file.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/annotate_file.gif" alt="img"></p>
<p>更多信息请参见 <a href="https://imagemagick.org/Usage/text/#annotate">Annotate Text Drawing Operator</a>，特别是 <a href="https://imagemagick.org/Usage/text/#escape_chars">Annotate Escape Characters</a>。</p>
<h2 id="im-和-svg-处理">IM 和 SVG 处理</h2>
<h3 id="svg-输入驱动rsvg-与-msvg">SVG 输入驱动。RSVG 与 MSVG</h3>
<p>处理实际的 SVG 图像格式是一项非常复杂的工作。引擎需要处理 <a href="http://www.w3.org/TR/SVG/">SVG&ndash;可缩放矢量图形</a>文档所定义的所有方面。这需要大量的编程工作和时间。</p>
<p>因此，ImageMagick 在 SVG 格式图像的处理上提供了两种方法。第一种是使用一个开源的 RSV G库，将 SVG 格式转换成 IM 没有问题的光栅图像。这个引擎几乎在 SVG 处理的所有方面都是完整的。</p>
<p>第二种方法是IM尝试将 SVG 转换为 MVG，使用一个名为 MSVG 的内置IM方法。MSVG 试图将SVG图像转换成IM的 <code>-draw</code> 运算符 &ldquo;MVG&quot;绘图语言。绘制 MVG 的很多功能都是专门为此而创建的。不幸的是，虽然基本的线条绘制和着色功能是存在的，但它远不是一个完整的 SVG 转换器。</p>
<p>你可以通过使用特殊的输入格式 &ldquo;MSVG:&quot;（IM v6.3.4新增）读取 SVG 图像来强制使用内部的 MSVG 转换器。但如果 RSVG 库存在，大多数 ImageMagick 将使用它来渲染 <code>SVG</code> 图像。</p>
<p>要找出你的 IM 会做什么，请用&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -list format <span class="p">|</span> grep SVG
</code></pre></div><p>从括号中的 &ldquo;RSVG&rdquo; 可以看出，我自己的 IM 将使用我电脑上的 RSVG 库，并给出了版本。</p>
<p>在这里，我&quot;绘制&quot;了一个小的、手工制作的 SVG 图像 &ldquo;<a href="https://imagemagick.org/Usage/draw/diagonal.svg">diagonal.svg</a>&quot;（由论坛用户 <a href="https://imagemagick.org/Usage/forum_link.cgi?u=8538">penciledin</a> 贡献），它在白色背景上创建了一个简单的对角线渐变的矩形。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert diagonal.svg  diagonal_rsvg.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/diagonal_rsvg.gif" alt="img"></p>
<p>完美的。一个正确的对角线梯度被生成。</p>
<p>然而，如果你使用内部的 MSVG（如果没有 RSVG 库，则为默认值）来渲染&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert msvg:diagonal.svg  diagonal_msvg.gif
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/diagonal_msvg.gif" alt="img"></p>
<p>正如你所看到的，内部 MSVG 转换失败，返回的是垂直梯度而不是对角线。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert msvg:diagonal.svg diagonal.mvg
</code></pre></div><p>你大概可以看到MSVG转换器是如何尝试将 SVG 转换为 MVG 绘图命令的。</p>
<p>当前内部 MSVG 已知失败的地方包括&hellip;</p>
<ul>
<li>非垂直梯度(没有转换到新的MVG梯度处理)</li>
<li>沿着弯曲路径的文字</li>
<li>文本对齐（与重力分开）。</li>
</ul>
<p>然而大多数基本的绘图动作都被处理了。</p>
<p>还请记住，MVG 语言实际上可以处理 SVG 不能处理的事情，包括使用重力来定位图像和文本。重力不是 SVG 规范的一部分，尽管它是 IM 文本和字体处理的一个组成部分。</p>
<p>另外请记住，MVG 没有 SVG 所拥有的容器机制。内部的 MSVG 转换器用图形上下文的推送和弹出代替了 XML 容器（见上面的 MVG  输出），效果是一样的。
SVG 的设置</p>
<p>SVG 图像格式是一种矢量格式（请参见<a href="https://imagemagick.org/Usage/formats/#vector">关于矢量图像格式的一句话</a>），因此图像通常没有一个默认的&quot;大小&rdquo;，而是以特定的 <code> &quot;-density&quot;</code> 来 &ldquo;绘制&quot;或&quot;渲染&rdquo;，就像 postscript 一样（默认密度是72dpi）。</p>
<p>另外，如果 SVG 没有 &ldquo;绘制&quot;背景，您可以通过使用 <code>-background</code> 设置指定要使用的背景颜色。</p>
<p>例如这里是另一个小的 SVG 图像 &ldquo;home.svg&rdquo;，它已经使用3种不同的密度，3种不同的背景进行&quot;渲染&rdquo;，包括一个透明的背景。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -density <span class="m">36</span>                      home.svg  home_1.gif

  convert              -background skyblue home.svg  home_2.gif

  convert -density <span class="m">144</span> -background none    home.svg  home_3.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/home_1.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/home_2.gif" alt="img">
<img src="https://imagemagick.org/Usage/draw/home_3.png" alt="img"></p>
<p>请注意，我使用了 PNG 格式的图片来制作上面例子中较大的透明背景版本。由于半透明的边缘像素，这产生的图像比 GIF 图像格式产生的图像更干净。当最终图像中涉及到透明度时，总是建议使用 PNG。</p>
<blockquote>
<p>我发现有些 SVG 图像不能缩放。也就是说，它们被定义为&quot;像素&rdquo;，而不是现实世界中的长度，如&quot;点&rdquo;、&ldquo;英寸&quot;或&quot;毫米&rdquo;。因此，虽然 <code>-density</code> 设置可能会改变图像的整体大小（以现实世界为单位），但 &ldquo;像素 &ldquo;的大小不会改变，因此图像本身的大小也不会改变。然而这样的SVG图像是相当罕见的。</p>
</blockquote>
<p>更糟糕的是，一些 SVG 图像使用了&quot;像素&quot;和 &ldquo;点&quot;的混合测量，除非作者故意这样做，否则你可能会得到一个真正的混乱，你可以尝试使用不同的密度，而不是作者想要的。幸运的是，这种情况更加罕见。</p>
<p>一个简单的解决方法就是将 SVG 中所有的 &ldquo;像素&quot;单位改成&quot;点&rdquo;，但也不能盲目的使用，以防故意使用&quot;像素&rdquo;。</p>
<h2 id="svg-输出处理">SVG 输出处理</h2>
<p>从 IM v6.4.2 开始，IM 可以将任何位图图像转换为 SVG 矢量图! 转换并不总是成功的，但较大和/或较简单的图像（如位图蒙版）会转换得很好。</p>
<p>例如，我在这里将一个可怕的位图形状转换为SVG图像，然后再将其转换回来，以便将位图平滑为一个适当的反锯齿形状。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert -pointsize <span class="m">72</span> -font Candice label:A -threshold 50% <span class="se">\
</span><span class="se"></span>          -trim +repage -bordercolor white -border 5x5 A.gif

  convert A.gif  A.svg

  convert A.svg  A.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/A.gif" alt="img"> -&gt; <img src="https://imagemagick.org/Usage/draw/A.png" alt="img"></p>
<p>然而，要使之工作，必须安装&quot;开发&quot;的 <a href="http://autotrace.sourceforge.net/">AutoTrace</a> 库，并在IM中配置 <code>-with-autotrace</code> 开关。</p>
<p>如果没有安装 <a href="http://autotrace.sourceforge.net/">AutoTrace</a> 库并将其编译到 IM 中，那么生成的 SVG 输出将是大量的单像素圆圈，生成一个二进制结果，而不是一个平滑的 SVG 轮廓图像。这样的图像比较巨大，通过 SVG 渲染往往需要很长的时间来渲染。</p>
<p>其实需要一种更好的默认栅格到矢量的技术，可能会使用 Morphology skeletion 和 MAT 技术。</p>
<p>有一个 <code>autotrace:</code> <a href="https://imagemagick.org/Usage/files/#delegates">输入代理</a>，来&quot;平滑输入位图图像&rdquo;，直接使用 &ldquo;autotrace&rdquo; 命令一次性完成上述所有步骤。然而我最后一次看到这个代理已经消失了。</p>
<p>你应该这样使用它&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">  convert autotrace:A.gif  A_traced.png
</code></pre></div><p><img src="https://imagemagick.org/Usage/draw/A_traced.png" alt="img"></p>
<p>当然这并不能让你从 &ldquo;autotrace&rdquo; 命令中得到 SVG 输出，只是通过 SVG 过滤输入的图像来平滑它。</p>
<p>作为一种替代方法，你可以直接使用 &ldquo;autotrace&rdquo; 命令，如 <a href="https://imagemagick.org/Usage/transform/#edge_vector">Raster to Vector Edging</a> 和 <a href="https://imagemagick.org/Usage/morphology/#autotrace_skeleton">Skeleton using Autotrace</a> 示例所示。</p>
<p>你也可以看看 <a href="https://imagemagick.org/Usage/forum_link.cgi?u=39994">cancerberosgx</a> 的结果，在<a href="https://imagemagick.org/Usage/forum_link.cgi?p=167161">生成 SVG 图像</a>，他研究了转换照片的解决方案。</p>
<h2 id="非im矢量图形编辑器">非IM矢量图形编辑器</h2>
<p>ImageMagick 是一个像素数组处理器，它一般不会保存矢量图像（&lsquo;MVG&rsquo; 是唯一的例外），只会读取图像并将其转换为像素数组。</p>
<p>其他像素图像编辑器也是如此，如 Gimp、Photoshop 等。</p>
<p>对于编辑和处理基于矢量的图像，可以使用以下程序，如</p>
<ul>
<li>Sodipodi 基于SVG的矢量图形编辑器。</li>
<li>Xfig 简单但非常好的矢量对象编辑器。(适用于标志、地图和在页面上排列照片)</li>
<li>Dia</li>
<li>AutoTrace 将位图数组中的形状转换为矢量轮廓。</li>
<li>Sketch 基于 Python 的曲线文字矢量编辑器。</li>
</ul>
<p>当然，这不是一个完整的列表。即使是许多文字处理程序，如 OpenOffice、Word 和 TeX，一般都有各种简单的，虽然往往难以使用的对象编辑器。</p>
<p>然而对于一般将矢量图形格式转换为不同的矢量格式，不要使用 ImageMagick。ImageMagick 本质上是一个光栅图像或位图图形转换器和操作器，而且永远都是这样。更多信息请参见 <a href="https://imagemagick.org/Usage/formats/#vector">A word about Vector Image formats</a>。</p>
<ul>
<li>创建于: 24 March 2004</li>
<li>更新于: 14 March 2011</li>
<li>作者: Anthony Thyssen, <a href="mailto:Anthony.Thyssen@gmail.com">Anthony.Thyssen@gmail.com</a></li>
<li>Examples Generated with:  [version image]</li>
<li>URL: <a href="http://www.imagemagick.org/Usage/draw/">http://www.imagemagick.org/Usage/draw/</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/imagemagick" term="imagemagick" label="imagemagick" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/image" term="image" label="image" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[ImageMagick - Transform]]></title>
            <link href="https://ohmyweekly.github.io/notes/imagemagick-transform/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/imagemagick-drawing/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick - Drawing" />
                <link href="https://ohmyweekly.github.io/notes/imagemagick-notes/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick 笔记" />
            
                <id>https://ohmyweekly.github.io/notes/imagemagick-transform/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-05T00:00:00+08:00</published>
            <updated>2020-07-05T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>ImageMagick Transform</blockquote><p><a href="https://imagemagick.org/Usage/transform/index.html">https://imagemagick.org/Usage/transform/index.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/imagemagick" term="imagemagick" label="imagemagick" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/transform" term="transform" label="transform" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[ImageMagick 笔记]]></title>
            <link href="https://ohmyweekly.github.io/notes/imagemagick-notes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/imagemagick-drawing/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick - Drawing" />
                <link href="https://ohmyweekly.github.io/notes/imagemagick-transform/?utm_source=atom_feed" rel="related" type="text/html" title="ImageMagick - Transform" />
            
                <id>https://ohmyweekly.github.io/notes/imagemagick-notes/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-05T00:00:00+08:00</published>
            <updated>2020-07-05T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>ImageMagick</blockquote><h2 id="几个有意思的-imagemagick-脚本">几个有意思的 ImageMagick 脚本</h2>
<p><a href="http://www.fmwconcepts.com/imagemagick/randomclipart/index.php">http://www.fmwconcepts.com/imagemagick/randomclipart/index.php</a>
<a href="http://www.fmwconcepts.com/imagemagick/sketching/index.php">http://www.fmwconcepts.com/imagemagick/sketching/index.php</a>
<a href="http://www.fmwconcepts.com/imagemagick/sphericalpano2cube/index.php">http://www.fmwconcepts.com/imagemagick/sphericalpano2cube/index.php</a>
<a href="http://www.fmwconcepts.com/imagemagick/surroundblur/index.php">http://www.fmwconcepts.com/imagemagick/surroundblur/index.php</a>
<a href="http://www.fmwconcepts.com/imagemagick/transfercolor/index.php">http://www.fmwconcepts.com/imagemagick/transfercolor/index.php</a>
<a href="http://www.fmwconcepts.com/imagemagick/colorcells/index.php">http://www.fmwconcepts.com/imagemagick/colorcells/index.php</a></p>
<h2 id="给图片添加网格线">给图片添加网格线</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./glasseffects -e none -k simple -o <span class="s1">&#39;#FFDAB9&#39;</span> -t single -m overlay -c <span class="m">200</span> -w <span class="m">1</span> -s <span class="m">20</span> -r <span class="m">10</span> in.jpeg out.jpg
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./grid -o 0.3 -s <span class="m">200</span> -c white in.jpeg out.jpeg
</code></pre></div><h2 id="折叠图片">折叠图片</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./picturefold -o <span class="m">80</span> -h <span class="m">50</span> in.jpeg out.jpeg
</code></pre></div><h2 id="给图片添加心形图片">给图片添加心形图片</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./randomclipart -d <span class="s2">&#34;64,16&#34;</span> -a <span class="s2">&#34;45,-45&#34;</span> -p <span class="m">50</span> -c random in.jpeg heart.png out.jpeg
</code></pre></div><h2 id="给图片分成带颜色的方块">给图片分成带颜色的方块</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./colorcells -n 8,8 -d 100,100 in.jpeg out.jpeg
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/imagemagick" term="imagemagick" label="imagemagick" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/image" term="image" label="image" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[FFmpeg]]></title>
            <link href="https://ohmyweekly.github.io/notes/ffmpeg/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/ffmpeg-notes/?utm_source=atom_feed" rel="related" type="text/html" title="使用 FFmpeg 提取抖音短视频中的音乐" />
            
                <id>https://ohmyweekly.github.io/notes/ffmpeg/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-04T00:00:00+08:00</published>
            <updated>2020-07-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>FFmpeg</blockquote><h2 id="概要">概要</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg <span class="o">[</span>global_options<span class="o">]</span> <span class="o">{[</span>input_file_options<span class="o">]</span> -i input_url<span class="o">}</span> ... <span class="o">{[</span>output_file_options<span class="o">]</span> output_url<span class="o">}</span> ...
</code></pre></div><h2 id="描述">描述</h2>
<p><a href="https://ffmpeg.org/ffmpeg.html"><code>ffmpeg</code></a> 是一款非常快速的视频和音频转换器，它还可以从实时音频/视频源中抓取。它还可以在任意采样率之间进行转换，并通过高质量的多相滤波器在飞行中调整视频大小。</p>
<p><code>ffmpeg</code> 从任意数量的输入&quot;文件&quot;（可以是常规文件、管道、网络流、抓取设备等）中读取，由 <code>-i</code> 选项指定，并写入任意数量的输出&quot;文件&quot;，由一个普通的输出 url 指定。在命令行中找到的任何不能被解释为选项的东西都被认为是一个输出 url。</p>
<p>原则上，每个输入或输出 url 可以包含任意数量的不同类型的流（视频/音频/字幕/附件/数据）。允许的流的数量和/或类型可能受到容器格式的限制。选择哪些输入的流将进入哪些输出，可以自动完成，也可以使用 <code>-map</code> 选项完成（请参见流选择章节）。</p>
<p>要在选项中引用输入文件，您必须使用它们的索引（基于 <code>0</code>）。例如，第一个输入文件是 <code>0</code>，第二个是 <code>1</code>，等等。同样，一个文件中的流也用它们的索引来表示。例如，<code>2:3</code> 指的是第三个输入文件中的第四个流。也请参见流指定符一章。</p>
<p>一般来说，选项会应用到下一个指定的文件。因此，顺序是很重要的，您可以在命令行中多次出现同一个选项。每次出现都会被应用到下一个输入或输出文件。这条规则的例外是全局选项（例如 verbosity level），应该先指定。</p>
<p>不要混合输入和输出文件-首先指定所有输入文件，然后再指定所有输出文件。也不要混合属于不同文件的选项。所有选项只适用于下一个输入或输出文件，并在文件之间被重置。</p>
<ul>
<li>要将输出文件的视频比特率设置为 64 kbit/s:</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.avi -b:v 64k -bufsize 64k output.avi
</code></pre></div><ul>
<li>要强制输出文件的帧率为24帧/秒:</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.avi -r <span class="m">24</span> output.avi
</code></pre></div><ul>
<li>强制输入文件的帧率（仅对原始格式有效）为1帧/秒，输出文件的帧率为24帧/秒:</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -r <span class="m">1</span> -i input.m2v -r <span class="m">24</span> output.avi
</code></pre></div><p>原始输入文件可能需要格式选项。</p>
<h2 id="详情描述">详情描述</h2>
<p><code>ffmpeg</code> 中每个输出的转码过程可以用下面的图来描述:</p>
<pre><code> _______              ______________
|       |            |              |
| input |  demuxer   | encoded data |   decoder
| file  | ---------&gt; | packets      | -----+
|_______|            |______________|      |
                                           v
                                       _________
                                      |         |
                                      | decoded |
                                      | frames  |
                                      |_________|
 ________             ______________       |
|        |           |              |      |
| output | &lt;-------- | encoded data | &lt;----+
| file   |   muxer   | packets      |   encoder
|________|           |______________|
</code></pre><p><code>ffmpeg</code> 调用 libavformat 库（包含 demuxers）来读取输入文件，并从其中获取包含编码数据的数据包。当有多个输入文件时，<code>ffmpeg</code> 试图通过跟踪任何活动输入流上的最低时间戳来保持它们的同步。</p>
<p>编码后的数据包会被传递给解码器（除非为流选择了 streamcopy，详见下文）。解码器产生未压缩的帧（原始视频/PCM音频/&hellip;），这些帧可以通过过滤进一步处理（见下一节）。过滤后，这些帧被传给编码器，编码器对它们进行编码并输出编码数据包。最后，这些帧被传给 muxer，muxer 将编码后的数据包写入输出文件。</p>
<h2 id="滤波">滤波</h2>
<p>在编码之前，<code>ffmpeg</code> 可以使用 libavfilter 库中的过滤器处理原始音频和视频帧。<code>ffmpeg</code> 区分了两种类型的滤波图：简单和复杂。</p>
<h3 id="简单的滤波图">简单的滤波图</h3>
<p>简单的滤波图是指那些只有一个输入和输出的滤波图，两者类型相同。在上图中，它们可以通过简单地在解码和编码之间插入一个额外的步骤来表示:</p>
<pre><code> _________                        ______________
|         |                      |              |
| decoded |                      | encoded data |
| frames  |\                   _ | packets      |
|_________| \                  /||______________|
             \   __________   /
  simple     _\||          | /  encoder
  filtergraph   | filtered |/
                | frames   |
                |__________|
</code></pre><p>简单的滤波图是用 per-stream <code>-filter</code> 选项配置的（视频和音频分别用 <code>-vf</code> 和 <code>-af</code> 别名）。例如，一个简单的视频滤波图可以是这样的:</p>
<pre><code> _______        _____________        _______        ________
|       |      |             |      |       |      |        |
| input | ---&gt; | deinterlace | ---&gt; | scale | ---&gt; | output |
|_______|      |_____________|      |_______|      |________|
</code></pre><p>请注意，有些滤镜会改变帧的属性，但不会改变帧的内容。例如，上面例子中的 <code>fps</code> 过滤器改变了帧数，但没有触及帧内容。另一个例子是 <code>setpts</code> 过滤器，它只设置了时间戳，而在其他方面没有改变帧的内容。</p>
<h3 id="复杂的滤波图">复杂的滤波图</h3>
<p>复杂的滤波图是那些不能简单地描述为应用于一个流的线性处理链的图。例如，当图形有一个以上的输入和/或输出时，或者当输出流类型与输入不同时，就会出现这种情况。它们可以用下图来表示:</p>
<pre><code> _________
|         |
| input 0 |\                    __________
|_________| \                  |          |
             \   _________    /| output 0 |
              \ |         |  / |__________|
 _________     \| complex | /
|         |     |         |/
| input 1 |----&gt;| filter  |\
|_________|     |         | \   __________
               /| graph   |  \ |          |
              / |         |   \| output 1 |
 _________   /  |_________|    |__________|
|         | /
| input 2 |/
|_________|
</code></pre><p>复杂的滤波图是用 <code>-filter_complex</code> 选项配置的。注意这个选项是全局性的，因为复杂的滤波图，就其本质而言，不能明确地与一个单一的流或文件相关联。</p>
<p><code>-lavfi</code> 选项相当于 <code>-filter_complex</code>。</p>
<p>一个简单的例子是 <code>overlay</code> 滤波器，它有两个视频输入和一个视频输出，其中一个视频叠加在另一个视频上。它的音频对应的是 <code>amix</code> 滤波器。</p>
<h2 id="流复制">流复制</h2>
<p>流复制是通过向 <code>-codec</code> 选项提供 <code>copy</code> 参数来选择的模式，它使 <code>ffmpeg</code> 省略了对指定流的解码和编码步骤，因此它只做解复用(demuxing)和混叠(muxing)。它对于改变容器格式或修改容器级元数据非常有用。上面的图，在这种情况下，会简化成这样:</p>
<pre><code> _______              ______________            ________
|       |            |              |          |        |
| input |  demuxer   | encoded data |  muxer   | output |
| file  | ---------&gt; | packets      | -------&gt; | file   |
|_______|            |______________|          |________|
</code></pre><p>由于不需要解码或编码，所以速度非常快，而且没有质量损失。但是，由于很多因素的影响，在某些情况下可能无法工作。应用过滤器显然也是不可能的，因为过滤器是在未压缩的数据上工作的。</p>
<h2 id="流选择">流选择</h2>
<p><code>ffmpeg</code> 提供了 <code>-map</code> 选项来手动控制每个输出文件的流选择。用户可以跳过 <code>-map</code> 选项，让 <code>ffmpeg</code> 执行自动流选择，如下所述。<code>-vn / -an / -sn / -dn</code> 选项可以分别用来跳过视频、音频、字幕和数据流，无论是手动映射还是自动选择，但那些复杂的滤波图输出的流除外。</p>
<h3 id="描述-1">描述：</h3>
<p>下面的小节描述了涉及到流选择的各种规则。接下来的例子将展示这些规则是如何在实践中应用的。</p>
<p>虽然我们尽力准确地反映了程序的行为，但 FFmpeg 仍在不断地开发中，代码可能会在写这篇文章的时候有所改变。</p>
<h4 id="自动选择流">自动选择流</h4>
<p>在没有任何特定输出文件的映射选项的情况下，<code>ffmpeg</code> 会检查输出格式，以检查哪些类型的流可以被包含在其中，即视频、音频和/或字幕。对于每一种可接受的流类型，<code>ffmpeg</code> 将从所有输入中选择一个可用的流。</p>
<p>它将根据以下标准选择该流:</p>
<ul>
<li>对于视频，它是最高分辨率的流,</li>
<li>对于音频来说，它是拥有最多通道的流,</li>
<li>对于字幕，它是第一个找到的字幕流，但有一个注意事项。输出格式的默认字幕编码器可以是基于文本的，也可以是基于图像的，而且只会选择相同类型的字幕流。</li>
</ul>
<p>在几个相同类型的流速率相同的情况下，会选择指数最低的流。</p>
<p>数据流或附件流不会被自动选择，只能使用 <code>-map</code> 来包含。</p>
<h4 id="手动选择流">手动选择流</h4>
<p>当使用 <code>-map</code> 时，只有用户映射的流才会被包含在该输出文件中，下面描述的滤波图输出可能是一个例外。</p>
<h4 id="复杂的滤波图-1">复杂的滤波图</h4>
<p>如果有任何复杂的滤波图输出流带有未标记的填补(pad)，它们将被添加到第一个输出文件中。如果流类型不被输出格式支持，这将导致一个致命的错误。在没有 <code>map</code> 选项的情况下，包含这些流会导致自动选择流的类型被跳过。如果存在 <code>map</code> 选项，这些滤波图流会被包含在映射流之外。</p>
<p>带有标签填补的复杂滤波图输出流必须被映射一次，而且是精确地映射一次。</p>
<h4 id="流处理">流处理</h4>
<p>流处理是独立于流选择的，下面描述的字幕除外。流处理是通过针对特定输出文件中的流的 <code>-codec</code> 选项来设置的。特别是，编解码器选项是在流选择过程之后由 <code>ffmpeg</code> 应用的，因此不会影响后者。如果没有为某个流类型指定 <code>-codec</code> 选项，<code>ffmpeg</code> 将选择输出文件 muxer 注册的默认编码器。</p>
<p>字幕存在一个例外。<code>ffmpeg</code> 不会验证指定的编码器是否可以转换所选的流，也不会验证转换后的流是否可以在输出格式中接受。这通常也适用于：当用户手动设置编码器时，流选择过程不能检查编码后的流是否能被混入输出文件中。如果不能，<code>ffmpeg</code> 将中止，所有的输出文件将无法被处理。</p>
<h2 id="示例">示例</h2>
<p>下面的例子说明了 <code>ffmpeg</code> 流选择方法的行为、怪癖和限制。</p>
<p>它们假设以下三个输入文件:</p>
<pre><code>input file 'A.avi'
      stream 0: video 640x360
      stream 1: audio 2 channels

input file 'B.mp4'
      stream 0: video 1920x1080
      stream 1: audio 2 channels
      stream 2: subtitles (text)
      stream 3: audio 5.1 channels
      stream 4: subtitles (text)

input file 'C.mkv'
      stream 0: video 1280x720
      stream 1: audio 2 channels
      stream 2: subtitles (image)
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/ffmpeg" term="ffmpeg" label="ffmpeg" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/ffmpeg" term="ffmpeg" label="ffmpeg" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/tiktok" term="tiktok" label="tiktok" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[使用 FFmpeg 提取抖音短视频中的音乐]]></title>
            <link href="https://ohmyweekly.github.io/notes/ffmpeg-notes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/ffmpeg/?utm_source=atom_feed" rel="related" type="text/html" title="FFmpeg" />
            
                <id>https://ohmyweekly.github.io/notes/ffmpeg-notes/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-04T00:00:00+08:00</published>
            <updated>2020-07-04T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Use FFmpeg to extract music in TikTok</blockquote><p>抖音短视频有很多好听的歌, 网易云音乐、QQ音乐和虾米音乐上都没有, 但是可以把视频转成 mp3 格式。 使用 <a href="https://ffmpeg.org/ffmpeg.html">FFmpeg</a> 来搞定。点击抖音上的转发按钮, 如果「保存本地」的按钮不是灰色的, 表示可以下载到手机上。下载完后, 再转发到电脑上, 下载好 ffmpeg:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">brew install ffmpeg
</code></pre></div><h2 id="从视频中采集音频httpsstackoverflowcomquestions9913032how-can-i-extract-audio-from-video-with-ffmpeg2741382427413824"><a href="https://stackoverflow.com/questions/9913032/how-can-i-extract-audio-from-video-with-ffmpeg/27413824#27413824">从视频中采集音频</a></h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.mp4 -f mp3 -vn output.mp3
</code></pre></div><p>或</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.mp4 -q:a <span class="m">0</span> -map a output.mp3
</code></pre></div><p>或者只截取全部音频中的一小段:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -ss 00:00:03 -t 0:0:14 -i alcastar.mp4 -f mp3 -vn alcastar.mp3
</code></pre></div><p>其中 <code>-ss  00:00:03</code> 用于指定要截取的音频的起始时间, 即从第三秒开始截取; <code>-t 0:0:14</code> 用于指定要截取的音频的持续时长, 即截取 14 秒的音频。<code> -i alcastar.mp4</code> 用于指定输入文件,  即下载好的视频文件; <code>-f mp3</code> 用于指定输出格式为 mp3; <code>-vn</code> 即 no vedio, 即不保留视频; 最后的 alcastar.mp3 是输出文件名。</p>
<h2 id="去除音频中的静音httpsstackoverflowcomquestions25697596using-ffmpeg-with-silencedetect-to-remove-audio-silence2941197329411973"><a href="https://stackoverflow.com/questions/25697596/using-ffmpeg-with-silencedetect-to-remove-audio-silence/29411973#29411973">去除音频中的静音</a></h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.mp3 -af <span class="nv">silenceremove</span><span class="o">=</span>1:0:-50dB output.mp3
</code></pre></div><h2 id="给视频添加字幕httpsenwikipediaorgwikilist_of_iso_639-2_codes"><a href="https://en.wikipedia.org/wiki/List_of_ISO_639-2_codes">给视频添加字幕</a></h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i input.mp4 -i SRT文件 -c copy -c:s mov_text -metadata:s:s:0  <span class="nv">language</span><span class="o">=</span>&lt;language code&gt; output.mp4 
</code></pre></div><h2 id="移除超过1秒的静止画面httpsstackoverflowcomquestions40966394how-to-simply-remove-duplicate-frames-from-a-video-using-ffmpeg4097778640977786"><a href="https://stackoverflow.com/questions/40966394/how-to-simply-remove-duplicate-frames-from-a-video-using-ffmpeg/40977786#40977786">移除超过1秒的静止画面</a></h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -i in.mp4 -vf
<span class="s2">&#34;select=&#39;if(gt(scene,0.01),st(1,t),lte(t-ld(1),1))&#39;,setpts=N/FRAME_RATE/TB&#34;</span>
trimmed.mp4
</code></pre></div><h2 id="将图片和音频合成视频">将图片和音频合成视频</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -loop <span class="m">1</span> -i <span class="nv">$image</span> -i <span class="nv">$audio_file</span> -q:v <span class="m">1</span> -c:a copy  -shortest <span class="nv">$video_file</span>
</code></pre></div><h2 id="将多个视频合并成一个">将多个视频合并成一个</h2>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ffmpeg -safe <span class="m">0</span> -f concat -i <span class="nv">$list_file</span> -c:v libx264 <span class="nv">$final</span>
</code></pre></div><p>list file 的格式是：</p>
<pre><code>file './data_1.ts'
file './data_2.ts'
file './data_3.ts'
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/ffmpeg" term="ffmpeg" label="ffmpeg" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/ffmpeg" term="ffmpeg" label="ffmpeg" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/tiktok" term="tiktok" label="tiktok" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[创建包]]></title>
            <link href="https://ohmyweekly.github.io/notes/creating-packages/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/publishing-packages/?utm_source=atom_feed" rel="related" type="text/html" title="发布包" />
                <link href="https://ohmyweekly.github.io/notes/how-to-use-packages/?utm_source=atom_feed" rel="related" type="text/html" title="如何使用包" />
                <link href="https://ohmyweekly.github.io/notes/commonly-used-packages/?utm_source=atom_feed" rel="related" type="text/html" title="常用的包" />
                <link href="https://ohmyweekly.github.io/notes/write-http-clients/?utm_source=atom_feed" rel="related" type="text/html" title="编写HTTP客户端和服务器" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
            
                <id>https://ohmyweekly.github.io/notes/creating-packages/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-30T00:00:00+08:00</published>
            <updated>2020-06-30T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Creating packages</blockquote><p>Dart 生态系统使用<a href="https://dart.dev/guides/packages">包</a>来共享软件，如库和工具。本页告诉你如何创建一个包，重点是最常见的一种包，<a href="https://dart.dev/tools/pub/glossary#library-package">库包</a>。</p>
<h2 id="是什么造就了一个库包">是什么造就了一个库包</h2>
<p>下图是最简单的库包的布局:</p>
<p><img src="https://dart.dev/assets/libraries/simple-lib2-81ebdc20fdb53d3abbc4364956141eb0f6f8f275d1636064fc3e1db959b93c1a.png" alt="img"></p>
<p>一个库的最低要求是</p>
<p><strong>pubspec 文件</strong></p>
<p>库的 <code>pubspec.yaml</code> 文件和应用程序包的文件是一样的-没有特别的名称来表示这个包是一个库。</p>
<p><strong>lib 目录</strong></p>
<p>正如你所期望的那样，库代码存在于 <code>lib</code> 目录下，对其他包是公开的。你可以根据需要在 <code>lib</code> 下创建任何层次结构。按照惯例，实现代码被放在 <code>lib/src</code> 下。<code>lib/src</code> 下的代码被认为是私有的；其他包不应该需要导入 <code>src/...</code>。要使 <code>lib/src</code> 下的 API 公开，您可以从直接位于 <code>lib</code> 下的文件导出 <code>lib/src</code> 文件。</p>
<p>注意：当没有指定 <code>library</code> 指令时，会根据每个库的路径和文件名为其生成一个唯一的标签。因此，我们建议您从代码中省略 <code>library</code> 指令，除非您计划<a href="https://dart.dev/guides/libraries/create-library-packages#documenting-a-library">生成库级文档</a>。</p>
<h2 id="组织一个库包">组织一个库包</h2>
<p>当你创建小的、单独的库（称为迷你库）时，库包的维护、扩展和测试是最容易的。在大多数情况下，每个类都应该在自己的迷你库中，除非你有两个类是紧密耦合的情况。</p>
<p>注意：你可能听说过 <code>part</code> 指令，它允许你将一个库分割成多个 Dart 文件。我们建议你避免使用 <code>part</code> 指令，而是创建迷你库。</p>
<p>直接在 <code>lib</code> 下创建一个&quot;主&quot;库文件，<code>lib/&lt;package-name&gt;.dart</code>，导出所有的公共 API。这样用户就可以通过导入一个文件来获得一个库的所有功能。</p>
<p><code>lib</code> 目录也可能包含其他可导入的、非src的库。例如，也许你的主库可以跨平台使用，但是你创建了单独的库，这些库依赖于 <code>dart:io</code> 或者 <code>dart:html</code>。有些包有单独的库，这些库是要用前缀导入的，而主库不是。</p>
<p>让我们来看看一个现实世界中的库包的组织： shelf。<a href="https://github.com/dart-lang/shelf">shelf</a> 包提供了一种使用 Dart 创建 web 服务器的简单方法，它的布局结构是 Dart 库包常用的:</p>
<p><img src="https://dart.dev/assets/libraries/shelf-02e5fd43b660fcef7dbe6a883c40159e0379c8ee2088288ca60ed7dc8781bafd.png" alt="img"></p>
<p>直接在 <code>lib</code> 下，主库文件 <code>shelf.dart</code> 从 <code>lib/src</code> 导出几个文件:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">export</span> <span class="s1">&#39;src/cascade.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/handler.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/handlers/logger.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/hijack_exception.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/middleware.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/pipeline.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/request.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/response.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/server.dart&#39;</span><span class="p">;</span>
<span class="k">export</span> <span class="s1">&#39;src/server_handler.dart&#39;</span><span class="p">;</span>
</code></pre></div><p>shelf 包还包含一个迷你库： <code>shelf_io</code>。这个适配器处理来自 <code>dart:io</code> 的 <code>HttpRequest</code> 对象。</p>
<p>对网络应用的提示: 为了在使用 <a href="https://dart.dev/tools/dartdevc">dartdevc</a> 开发时获得最佳性能，请将<a href="https://dart.dev/tools/pub/package-layout#implementation-files">实现文件</a>放在 <code>/lib/src</code> 下，而不是放在 <code>/lib</code> 下的其他地方。同时，避免导入 <code>package:package_name/src/...</code> 的文件。</p>
<h2 id="导入库文件">导入库文件</h2>
<p>当从其他包中导入一个库文件时，使用 <code>package:</code> 指令来指定该文件的 URI。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:utilities/utilities.dart&#39;</span><span class="p">;</span>
</code></pre></div><p>当从自己的包中导入一个库文件时，当两个文件都在 lib 内，或者两个文件都在 lib 外时，使用相对路径。使用 <code>:package</code> 当导入的文件在 lib 内，而导入者在 lib 外时。</p>
<p>下图显示了如何从 lib 和 web 中导入 <code>lib/foo/a.dart</code>。</p>
<p><img src="https://dart.dev/assets/libraries/import-lib-rules-e1777e235dd56aa23f770babcccedb6a12be80af2c3e63065640b889d78be595.png" alt="img"></p>
<h2 id="有条件地导入和导出库文件">有条件地导入和导出库文件</h2>
<p>如果你的库支持多个平台，那么你可能需要有条件地导入或导出库文件。一个常见的用例是一个同时支持 web 和原生平台的库。</p>
<p>要有条件的导入或导出，你需要检查 <code>dart:*</code> 库的存在。下面是一个有条件导出代码的例子，它检查 <code>dart:io</code> 和 <code>dart:html</code> 的存在:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">export</span> <span class="s1">&#39;src/hw_none.dart&#39;</span> <span class="err">//</span> <span class="n">Stub</span> <span class="n">implementation</span>
    <span class="n">if</span> <span class="err">(</span><span class="n">dart</span><span class="err">.</span><span class="n">library</span><span class="err">.</span><span class="n">io</span><span class="err">)</span> <span class="s1">&#39;src/hw_io.dart&#39;</span> <span class="err">//</span> <span class="n">dart</span><span class="err">:</span><span class="n">io</span> <span class="n">implementation</span>
    <span class="n">if</span> <span class="err">(</span><span class="n">dart</span><span class="err">.</span><span class="n">library</span><span class="err">.</span><span class="n">html</span><span class="err">)</span> <span class="s1">&#39;src/hw_html.dart&#39;</span><span class="p">;</span> <span class="c1">// dart:html implementation
</span></code></pre></div><p>下面是这段代码的作用。</p>
<ul>
<li>在一个可以使用 <code>dart:io</code> 的应用程序中(例如，一个命令行应用程序)，导出 <code>src/hw_io.dart</code></li>
<li>在一个可以使用 <code>dart:html</code> 的应用程序中(一个 web 应用程序)，导出 <code>src/hw_html.dart</code></li>
<li>否则，导出 <code>src/hw_none.dart</code></li>
</ul>
<p>要有条件地导入一个文件，使用与上面相同的代码，但将 <code>exporrt</code> 改为 <code>import</code>。</p>
<p>注意：有条件的导入或导出只检查库在当前平台上是否可用，而不是检查是否实际导入或使用。</p>
<p>所有有条件导出的库都必须实现相同的 API。例如，这里是 <code>dart:io</code> 的实现:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>

<span class="kt">void</span> <span class="n">alarm</span><span class="p">([</span><span class="kt">String</span> <span class="n">text</span><span class="p">])</span> <span class="p">{</span>
  <span class="n">stderr</span><span class="p">.</span><span class="n">writeln</span><span class="p">(</span><span class="n">text</span> <span class="o">??</span> <span class="n">message</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">String</span> <span class="kd">get</span> <span class="n">message</span> <span class="o">=&gt;</span> <span class="s1">&#39;Hello World from the VM!&#39;</span><span class="p">;</span>
</code></pre></div><p>这里是默认的实现，它是一个抛出 UnsupportedErrors 的 stub。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">alarm</span><span class="p">([</span><span class="kt">String</span> <span class="n">text</span><span class="p">])</span> <span class="o">=&gt;</span> <span class="k">throw</span> <span class="n">UnsupportedError</span><span class="p">(</span><span class="s1">&#39;hw_none alarm&#39;</span><span class="p">);</span>

<span class="kt">String</span> <span class="kd">get</span> <span class="n">message</span> <span class="o">=&gt;</span> <span class="k">throw</span> <span class="n">UnsupportedError</span><span class="p">(</span><span class="s1">&#39;hw_none message&#39;</span><span class="p">);</span>
</code></pre></div><p>在任何平台上，你都可以导入有条件导出代码的库。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:hw_mp/hw_mp.dart&#39;</span><span class="p">;</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="n">message</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="提供补充文件">提供补充文件</h2>
<p>一个设计良好的库包是很容易测试的。我们建议你使用 <a href="https://github.com/dart-lang/test">test</a> 包来编写测试，将测试代码放在测试包顶部的 <code>test</code> 目录中。</p>
<p>如果你创建了任何旨在供公众使用的命令行工具，请将这些工具放在 <code>bin</code> 目录下，这是公共的。启用从命令行运行工具，使用 <a href="https://dart.dev/tools/pub/cmd/pub-global#activating-a-package">pub global activate</a>。将工具列在 pubspec 的<a href="https://dart.dev/tools/pub/pubspec#executables">可执行文件部分</a>，允许用户直接运行它，而无需调用 <a href="https://dart.dev/tools/pub/cmd/pub-global#running-a-script-using-pub-global-run">pub global run</a>。</p>
<p>如果你包含了一个如何使用你的库的例子，这将会很有帮助。这将被放入软件包顶部的 <code>example</code> 目录中。</p>
<p>你在开发过程中创建的任何工具或可执行文件，如果不是公开使用的，都会进入 <code>tool</code> 目录。</p>
<p>如果你把你的库发布到 pub.dev 站点，其他需要的文件，如 <code>README.md</code> 和 <code>CHANGELOG.md</code>，将在<a href="https://dart.dev/tools/pub/publishing">发布软件包</a>中描述。有关如何组织包目录的更多信息，请参见 <a href="https://dart.dev/tools/pub/package-layout">pub 包布局惯例</a>。</p>
<h2 id="编写库文档">编写库文档</h2>
<p>你可以使用 <a href="https://github.com/dart-lang/dartdoc#dartdoc">dartdoc</a> 工具为你的库生成 API 文档。Dartdoc 解析源码寻找<a href="https://dart.dev/guides/language/effective-dart/documentation#doc-comments">文档注释</a>，其中使用了 <code>///</code> 语法:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="c1">/// The event handler responsible for updating the badge in the UI.
</span><span class="c1"></span><span class="kt">void</span> <span class="n">updateBadge</span><span class="p">()</span> <span class="p">{</span>
  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div><p>关于生成文档的例子，请看 <a href="https://pub.dev/documentation/shelf/latest">shelf 文档</a>。</p>
<p>注意：要在生成的文档中包含任何库级文档，你必须指定 <code>library</code> 指令。请参阅 <a href="https://github.com/dart-lang/dartdoc/issues/1082">问题 1082</a>。</p>
<h2 id="分发一个开源库">分发一个开源库</h2>
<p>如果你的库是开源的，我们建议在 <a href="https://pub.dev/">pub.dev</a> 站点上分享它。要发布或更新库，请使用 <a href="https://dart.dev/tools/pub/cmd/pub-lish">pub publish</a>，它可以上传您的包并创建或更新其页面。例如，请看 <a href="https://pub.dev/packages/shelf">shelf 包</a>的页面。有关如何准备发布软件包的详细信息，请参见<a href="https://dart.dev/tools/pub/publishing">发布包</a>。</p>
<p>pub.dev 站点不仅托管您的软件包，而且还生成和托管您软件包的 API 参考文档。最新生成的文档的链接在软件包的 <strong>About</strong> 框中；例如，请看 shelf 包的 <a href="https://pub.dev/documentation/shelf">API 文档</a>。到以前版本的文档的链接在软件包页面的版本选项卡中。</p>
<p>要确保你的软件包的 API 文档在 pub.dev 网站上看起来不错，请按照以下步骤进行。</p>
<ul>
<li>在发布你的软件包之前，运行 <a href="https://github.com/dart-lang/dartdoc#dartdoc">dartdoc</a> 工具，以确保你的 docs 成功生成，并且看起来符合预期。</li>
<li>发布软件包后，检查 <strong>Versions</strong> 选项卡以确保文档成功生成。</li>
<li>如果文档根本没有生成，点击 <strong>Verrsions</strong> 选项卡中的 <strong>failed</strong>，查看 dartdoc 的输出。</li>
</ul>
<h2 id="资源">资源</h2>
<p>使用以下资源了解更多关于库包的信息。</p>
<ul>
<li><a href="https://dart.dev/guides/language/language-tour">语言之旅</a>中的<a href="https://dart.dev/guides/language/language-tour#libraries-and-visibility">库和可见性</a>包括使用库文件。</li>
<li><a href="https://dart.dev/guides/packages">包</a>文档很有用，特别是<a href="https://dart.dev/tools/pub/package-layout">包的布局约定</a>。</li>
<li><a href="https://dart.dev/guides/libraries/private-files">不应提交的内容</a>涵盖了哪些不应该被检查到源代码库中。</li>
<li><a href="https://github.com/dart-lang">dart-lang</a> 组织下的较新的库包倾向于展示最佳实践。可以考虑研究这些例子：<a href="https://github.com/dart-lang/dart_style">dart_style</a>、<a href="https://github.com/dart-lang/path">path</a>、<a href="https://github.com/dart-lang/shelf">shelf</a>、<a href="https://github.com/dart-lang/source_gen">source_gen</a> 和 <a href="https://github.com/dart-lang/test">test</a>。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/packages" term="packages" label="packages" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[发布包]]></title>
            <link href="https://ohmyweekly.github.io/notes/publishing-packages/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/creating-packages/?utm_source=atom_feed" rel="related" type="text/html" title="创建包" />
                <link href="https://ohmyweekly.github.io/notes/how-to-use-packages/?utm_source=atom_feed" rel="related" type="text/html" title="如何使用包" />
                <link href="https://ohmyweekly.github.io/notes/commonly-used-packages/?utm_source=atom_feed" rel="related" type="text/html" title="常用的包" />
                <link href="https://ohmyweekly.github.io/notes/write-http-clients/?utm_source=atom_feed" rel="related" type="text/html" title="编写HTTP客户端和服务器" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
            
                <id>https://ohmyweekly.github.io/notes/publishing-packages/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-30T00:00:00+08:00</published>
            <updated>2020-06-30T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Publishing packages</blockquote><p><a href="https://dart.dev/guides/packages">pub 软件包管理器</a>不仅仅是用来使用别人的软件包。它还允许你与世界分享你的软件包。如果您有一个有用的项目，并且您希望其他人能够使用它，请使用 <code>pub publish</code> 命令。</p>
<p>注意: 如果要发布到 pub.dev 以外的其他位置，或者要防止在任何地方发布，请使用 <a href="https://dart.dev/tools/pub/pubspec">pubspec</a> 中定义的  <code>publish_to</code> 字段。</p>
<h2 id="发布是永远的">发布是永远的</h2>
<p>请记住，发布是永远的。只要你发布你的包，用户就可以依赖它。一旦他们开始这样做，删除包就会破坏他们的包。为了避免这种情况，<a href="https://pub.dev/policy">pub.dev 政策</a>不允许取消发布软件包，除非是极少数情况。</p>
<p>你可以随时上传你的包的新版本，但旧的包将继续为那些还没有准备好升级的用户提供服务。</p>
<p>对于已经发布的包，如果不再相关或正在维护，你可以<a href="https://dart.dev/tools/pub/publishing#discontinue">将其标记为停止发布</a>。</p>
<h2 id="准备发布">准备发布</h2>
<p>当发布一个软件包时，遵循 <a href="https://dart.dev/tools/pub/pubspec">pubspec 格式</a>和<a href="https://dart.dev/tools/pub/package-layout">包布局惯例</a>是很重要的。其中有些是必须的，以便其他人能够使用你的软件包。另一些则是为了帮助用户更容易理解和使用您的软件包而提出的建议。在这两种情况下，pub 都会尝试帮助你，指出哪些改变会帮助你的软件包在 Dart 生态系统中发挥得更好。上传包有一些额外的要求:</p>
<ul>
<li>
<p>你必须包含一个包含<a href="https://opensource.org/">开源许可证</a>的 <code>LICENSE</code> 文件。我们推荐 <a href="https://opensource.org/licenses/BSD-3-Clause">BSD 许可证</a>，这是 Dart 自己使用的。你也必须有合法的权利来重新发布你上传的任何东西作为你的包的一部分。</p>
</li>
<li>
<p>你的软件包在经过 gzip 压缩后必须小于 10 MB。如果太大，可以考虑将其分割成多个包，或者减少包含的资源或例子的数量。</p>
</li>
<li>
<p>你的包应该只依赖托管的依赖项(来自默认的 pub 包服务器)和 SDK 依赖项(<code>sdk: flutter</code>)。这些限制确保了你的包的依赖性不会在未来变得不可用。</p>
</li>
<li>
<p>您必须有一个 <a href="https://support.google.com/accounts/answer/27441">Google 帐户</a>，pub 用来管理包的上传权限。您的 Google 账户可以与 Gmail 地址或任何其他电子邮件地址关联。</p>
</li>
</ul>
<p>注意：除非您使用<a href="https://dart.dev/tools/pub/verified-publishers">已验证的发布者</a>发布，否则 pub.dev 会显示与您的 Google 帐户关联的电子邮件地址。</p>
<h3 id="重要文件">重要文件</h3>
<p>Pub 使用一些文件的内容为你的包创建一个页面，地址是 <code>pub.dev/packages/&lt;your_package&gt;</code>。以下是影响你的包的页面外观的文件。</p>
<ul>
<li>README.md: <code>README.md</code> 文件是你的包页面中的主要内容。该文件的内容以 <a href="https://pub.dev/packages/markdown">Markdown</a> 的形式呈现。</li>
<li>CHANGELOG.md：<code>CHANGELOG.md</code> 文件是你的包页面中的主要内容。你的包的 <code>CHANGELOG.md</code> 文件，如果找到的话，也会在你的包页面的一个标签中显示，这样开发者就可以直接从 pub.dev 中读取它。该文件的内容会以 <a href="https://pub.dev/packages/markdown">Markdown</a> 的形式呈现。</li>
<li>pubspec: 你的包的 <code>pubspec.yaml</code> 文件用来在你的包的页面右侧填写关于你的包的详细信息，比如它的描述、主页等。</li>
</ul>
<h3 id="使用经过验证的发布者的优势">使用经过验证的发布者的优势</h3>
<p>您可以使用已验证的发布者（推荐）或独立的谷歌账户发布软件包。使用经过验证的发布者有以下优势。</p>
<ul>
<li>您的包的消费者知道发布者的域名已经被验证。</li>
<li>您可以避免让 pub.dev 显示您的个人电子邮件地址。取而代之的是，pub.dev会显示发布者的域名和联系地址。</li>
<li>经验证的发布者徽章 pub.dev 经验证的发布者标识会在搜索页面和单个软件包页面上显示在您的软件包名称旁边。</li>
</ul>
<h3 id="创建一个验证过的发布者">创建一个验证过的发布者</h3>
<p>要创建一个已验证的发布者，请按照以下步骤进行。</p>
<ol>
<li>进入 <a href="https://pub.dev/">pub.dev</a>。</li>
<li>使用 Google 账户登录 pub.dev。</li>
<li>在右上角的用户菜单中，选择创建发布者。</li>
<li>输入您要与您的发布者相关联的域名(例如，<code>dart.dev</code>)，然后单击&quot;创建发布者&quot;。</li>
<li>在确认对话框中，选择&quot;确定&quot;。</li>
<li>如果提示，完成验证流程，这将打开 <a href="https://search.google.com/search-console/about">Google 搜索控制台</a>。</li>
</ol>
<ul>
<li>在添加 DNS 记录时，可能需要几个小时后，搜索控制台才会反映出变化。</li>
<li>验证流程完成后，返回步骤4。</li>
</ul>
<h2 id="发布你的包">发布你的包</h2>
<p>使用 <a href="https://dart.dev/tools/pub/cmd/pub-lish">pub publish</a> 命令来首次发布您的软件包，或将其更新到新版本。</p>
<h3 id="执行-dry-run">执行 dry run</h3>
<p>为了测试 <code>pub publish</code> 的工作情况，你可以进行一次 dry run:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ pub publish --dry-run
</code></pre></div><p>Pub 会确保你的软件包遵循 <a href="https://dart.dev/tools/pub/pubspec">pubspec 格式</a>和<a href="https://dart.dev/tools/pub/package-layout">包布局约定</a>，然后将你的软件包上传到 <a href="https://pub.dev/">pub.dev</a>。Pub 还会向你展示它打算发布的所有文件。下面是一个发布名为 <code>transmogrify</code> 的软件包的例子:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="l">Publishing transmogrify 1.0.0</span><span class="w">
</span><span class="w">    </span><span class="l">.gitignore</span><span class="w">
</span><span class="w">    </span><span class="l">CHANGELOG.md</span><span class="w">
</span><span class="w">    </span><span class="l">README.md</span><span class="w">
</span><span class="w">    </span><span class="l">lib</span><span class="w">
</span><span class="w">        </span><span class="l">transmogrify.dart</span><span class="w">
</span><span class="w">        </span><span class="l">src</span><span class="w">
</span><span class="w">            </span><span class="l">transmogrifier.dart</span><span class="w">
</span><span class="w">            </span><span class="l">transmogrification.dart</span><span class="w">
</span><span class="w">    </span><span class="l">pubspec.yaml</span><span class="w">
</span><span class="w">    </span><span class="l">test</span><span class="w">
</span><span class="w">        </span><span class="l">transmogrify_test.dart</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="l">Package has 0 warnings.</span><span class="w">
</span></code></pre></div><h3 id="发布">发布</h3>
<p>当你准备好发布你的包时，请删除 <code>--dry-run</code> 参数:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ pub publish
</code></pre></div><p>注意: pub 命令目前不支持直接将新软件包发布到已验证的发布者。作为一个临时的变通方法，可以将新的软件包发布到Google账户，然后将包<a href="https://dart.dev/tools/pub/publishing#transferring-a-package-to-a-verified-publisher">转移到发布者</a>。</p>
<p>一旦软件包被转移到发布者，你就可以使用 <code>pub publish</code> 更新软件包。</p>
<p>当你的包成功上传到 pub.dev 后，任何 pub 用户都可以下载它或在他们的项目中依赖它。例如，如果你刚刚发布了 1.0.0 版本的 <code>transmogrify</code> 包，那么另一个 Dart 开发者可以在他们的 <code>pubspec.yaml</code> 中添加它作为依赖:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">dependencies</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">transmogrify</span><span class="p">:</span><span class="w"> </span><span class="l">^1.0.0</span><span class="w">
</span></code></pre></div><h3 id="将软件包传输给已验证的发布者">将软件包传输给已验证的发布者</h3>
<p>要将一个软件包转移到已验证的发布者，您必须是该软件包的<a href="https://dart.dev/tools/pub/publishing#uploaders">上传者</a>和已验证发布者的管理员。</p>
<p>注意：这个过程是不可逆的。一旦你将一个软件包转移到一个发布者，你不能将它转移回个人账户。</p>
<p>以下是如何将软件包转移到已验证的发布者:</p>
<ol>
<li>用一个被列为软件包上传者的 Google 账户登录到 <a href="https://pub.dev/">pub.dev</a>。</li>
<li>进入软件包的详细信息页面(例如，<code>https://pub.dev/packages/http</code>)。</li>
<li>选择&quot;管理&quot;选项卡。</li>
<li>输入发布者的名称，然后单击&quot;传输到发布者&quot;。</li>
</ol>
<h3 id="哪些文件会被发布">哪些文件会被发布？</h3>
<p>您的软件包中的<strong>所有</strong>文件都包含在已发布的软件包中，但有以下例外:</p>
<ul>
<li>任何包的目录。</li>
<li>您的软件包的 <a href="https://dart.dev/tools/pub/glossary#lockfile">lockfile</a> 文件。</li>
<li>如果你没有使用 Git，所有隐藏的文件（也就是名字以 <code>.</code> 开头的文件）。</li>
<li>如果使用 Git，则是所有被 <code>.gitignore</code> 文件忽略的文件。</li>
</ul>
<p>请确保删除任何你不想包含的文件(或将它们添加到 <code>.gitignore</code> 中)。 <code>pub publish</code> 在上传你的包之前列出了它要发布的所有文件，所以在完成上传之前要仔细检查列表。</p>
<h2 id="上传者">上传者</h2>
<p>谁发布了软件包的第一个版本，谁就会自动成为第一个也是唯一一个被授权上传该软件包其他版本的人。要允许或不允许其他人上传版本，请使用 <a href="https://dart.dev/tools/pub/cmd/pub-uploader">pub uploader</a> 命令或将软件包转移到<a href="https://dart.dev/tools/pub/verified-publishers">已验证的发布者</a>那里。</p>
<p>如果一个软件包有一个经过验证的发布者，那么该软件包的 pub.dev 页面会显示发布者的域名。否则，该页面将显示该软件包的授权上传者的电子邮件地址。</p>
<h2 id="发布预发包">发布预发包</h2>
<p>当你在做一个包的时候，考虑把它作为一个预发布。当以下任何一种情况发生时，预发布都是有用的。</p>
<ul>
<li>你正在积极开发软件包的下一个主要版本。</li>
<li>你想为软件包的下一个发行候选版本招募测试者。</li>
<li>该包依赖于 Dart 或 Flutter SDK 的不稳定版本。</li>
</ul>
<p>正如在<a href="https://semver.org/spec/v2.0.0-rc.1.html">语义版本化</a>中所描述的那样，为了使一个版本的预发布，你要给版本附加一个后缀。例如，要对 <code>2.0.0</code> 版本进行预发布，你可以使用 <code>2.0.0-dev.1</code> 版本。以后，当你发布 <code>2.0.0</code> 版本时，它将优先于所有 <code>2.0.0-XXX</code> 预发布版本。</p>
<p>因为 pub 更倾向于在可用的时候发布稳定版，所以一个预发布包的用户可能需要改变他们的依赖约束。例如，如果用户想要测试 2.1 版本的预发布包，那么他们可以指定 <code>^2.1.0-dev.1</code>，而不是 <code>^2.0.0</code> 或 <code>^2.1.0</code>。</p>
<p>注意: 如果依赖关系图中的稳定包依赖于一个 prerelease，那么 pub 会选择那个 prerelease 而不是稳定版本。</p>
<p>当一个 prerelease 被发布到 pub.dev 时，软件包页面会同时显示到 prerelease 和稳定版的链接。prerelease 不会影响分析得分，不会出现在搜索结果中，也不会替换包的 <code>README.md</code> 和文档。</p>
<h2 id="将软件包标记为已停产的软件包">将软件包标记为已停产的软件包</h2>
<p>尽管软件包总是保持发布，但向开发者发出信号，表明一个软件包不再被积极维护，是很有用的。为此，您可以将一个软件包标记为 <code>discontinued</code>。一个已停用的软件包仍然可以在 pub.dev 上发布和查看，但它有一个清晰的 DISCONTINUED 徽章，并且不会出现在 pub.dev 的搜索结果中。</p>
<p>要将软件包标记为已停用，请使用该软件包的上传者或已验证的发布者管理员的 Google 帐户登录 pub.dev。然后使用单个软件包的管理选项卡将该软件包标记为已停用。</p>
<h2 id="资源">资源</h2>
<p>有关更多信息，请参见以下 pub 命令的参考页面。</p>
<ul>
<li><a href="https://dart.dev/tools/pub/cmd/pub-lish">pub publish</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-uploader">pub uploader</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/packages" term="packages" label="packages" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[编写HTTP客户端和服务器]]></title>
            <link href="https://ohmyweekly.github.io/notes/write-http-clients/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/creating-packages/?utm_source=atom_feed" rel="related" type="text/html" title="创建包" />
                <link href="https://ohmyweekly.github.io/notes/publishing-packages/?utm_source=atom_feed" rel="related" type="text/html" title="发布包" />
                <link href="https://ohmyweekly.github.io/notes/how-to-use-packages/?utm_source=atom_feed" rel="related" type="text/html" title="如何使用包" />
                <link href="https://ohmyweekly.github.io/notes/commonly-used-packages/?utm_source=atom_feed" rel="related" type="text/html" title="常用的包" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
            
                <id>https://ohmyweekly.github.io/notes/write-http-clients/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-30T00:00:00+08:00</published>
            <updated>2020-06-30T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Write HTTP clients &amp; servers</blockquote><p>有什么意义呢？</p>
<ul>
<li>HTTP 协议允许客户端和服务器进行通信。</li>
<li>dart:io 包有编写 HTTP 程序的类。</li>
<li>服务器监听主机和端口上的请求。</li>
<li>客户端使用 HTTP 方法请求发送请求。</li>
<li>http_server 包提供了更高级别的构件。</li>
</ul>
<p>前提条件: HTTP 服务器和客户端严重依赖 future 和流，本教程中没有解释这些内容。你可以从<a href="https://dart.dev/codelabs/async-await">异步编程 codelab</a>和<a href="https://dart.dev/tutorials/language/streams">流教程</a>中了解它们。</p>
<p>HTTP（超文本传输协议）是一种通信协议，用于通过互联网将数据从一个程序发送到另一个程序。数据传输的一端是服务器，另一端是客户端。客户端通常是基于浏览器的（用户在浏览器中输入或在浏览器中运行的脚本），但也可能是一个独立的程序。</p>
<p>服务器与主机和端口绑定（它与一个IP地址和一个端口号建立专属连接）。然后服务器监听请求。由于 Dart 的异步性，服务器可以同时处理很多请求，具体如下。</p>
<ul>
<li>服务器监听</li>
<li>客户端连接</li>
<li>服务器接受并接收请求(并继续监听)</li>
<li>服务器可以继续接受其他请求</li>
<li>服务器写入请求的响应或几个请求，可能是交错的请求</li>
<li>服务器最终结束(关闭)响应</li>
</ul>
<p>在 Dart 中，<a href="https://api.dart.dev/stable/dart-io/dart-io-library.html">dart:io</a> 库包含了编写 HTTP 客户端和服务器所需的类和函数。此外，<a href="https://pub.dev/packages/http_server">http_server</a> 包包含了一些更高层次的类，使其更容易编写客户端和服务器。</p>
<p>重要：基于浏览器的程序不能使用 dart:io 库。</p>
<p>dart:io 库中的 API 只适用于独立的命令行程序。它们不能在浏览器中工作。要从基于浏览器的客户端发出 HTTP 请求，请参考 <a href="https://api.dart.dev/stable/dart-html/HttpRequest-class.html">dart:html HttpRequest</a> 类。</p>
<p>本教程提供了几个例子，说明编写 Dart HTTP 服务器和客户端是多么容易。从服务器的 <code>hello world</code> 开始，你将学习如何编写服务器的代码，从绑定和监听到响应请求。你还可以学习到客户端：提出不同类型的请求(GET 和 POST)，编写基于浏览器和命令行的客户端。</p>
<h2 id="获取源码">获取源码</h2>
<ul>
<li>获取 Dart 教程的<a href="https://github.com/dart-lang/dart-tutorials-samples/archive/master.zip">示例代码</a>。</li>
<li>查看 <code>httpserver</code> 目录，其中包含本教程所需的源码。</li>
</ul>
<h2 id="运行-hello-world-服务器">运行 hello world 服务器</h2>
<p>本节的示例文件：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/hello_world_server.dart">hello_world_server.dart</a>。</p>
<p>让我们从一个小型的服务器开始，用字符串 <code>Hello, world</code> 来响应所有的请求。</p>
<p>在命令行中，运行 <code>hello_world_server.dart</code> 脚本:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">$</span> <span class="n">cd</span> <span class="n">httpserver</span>
<span class="n">$</span> <span class="n">dart</span> <span class="n">bin</span><span class="o">/</span><span class="n">hello_world_server</span><span class="p">.</span><span class="n">dart</span>
<span class="n">listening</span> <span class="n">on</span> <span class="n">localhost</span><span class="p">,</span> <span class="n">port</span> <span class="m">4040</span>
</code></pre></div><p>在任何浏览器中，访问 <a href="http://localhost:4040/">localhost:4040</a>。浏览器会显示 <code>Hello, world!</code>。</p>
<p><img src="https://dart.dev/tutorials/server/images/hello_world_response.png" alt="img"></p>
<p>在这种情况下，服务器是一个 Dart 程序，客户端是你使用的浏览器。然而，你可以用 Dart 编写客户端程序-无论是基于浏览器的客户端脚本，还是独立的程序。</p>
<h3 id="快速浏览一下代码">快速浏览一下代码</h3>
<p>在 <code>hello world</code> 服务器的代码中，一个 HTTP 服务器与主机和端口绑定，监听 HTTP 请求，并写入响应。需要注意的是，该程序导入了 <a href="https://api.dart.dev/stable/dart-io/dart-io-library.html">dart:io</a> 库，其中包含了服务器端程序和客户端程序的 HTTP 相关类(但不包含 Web 应用)。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span>
    <span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span>
    <span class="m">4040</span><span class="p">,</span>
  <span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Listening on localhost:</span><span class="si">${</span><span class="n">server</span><span class="p">.</span><span class="n">port</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>

  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Hello, world!&#39;</span><span class="p">);</span>
    <span class="kd">await</span> <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>接下来的几节内容包括服务器端绑定、发出客户端 GET 请求、监听和响应。</p>
<h2 id="将服务器绑定到主机和端口">将服务器绑定到主机和端口</h2>
<p>本节示例：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/hello_world_server.dart">hello_world_server.dart</a>。</p>
<p><code>main()</code> 中的第一条语句使用 <code>HttpServer.bind()</code> 创建一个 <a href="https://api.dart.dev/stable/dart-io/HttpServer-class.html">HttpServer</a> 对象，并将其绑定到主机和端口。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span>
  <span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span>
  <span class="m">4040</span><span class="p">,</span>
<span class="p">);</span>
</code></pre></div><p>该代码使用 <code>await</code> 异步调用 <code>bind</code> 方法。</p>
<h3 id="主机名">主机名</h3>
<p><code>bind()</code> 的第一个参数是指定主机名。你可以用一个字符串来指定一个特定的主机名或IP地址，也可以用 <a href="https://api.dart.dev/stable/dart-io/InternetAddress-class.html">InternetAddress</a> 类提供的这些预定义的值来指定主机。</p>
<table>
<thead>
<tr>
<th style="text-align:left">值</th>
<th style="text-align:left">用例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">回环 IPv4 或 loopbackIPv6</td>
<td style="text-align:left">服务器在 loopback 地址上监听客户端活动，该地址实际上是 localhost。使用IP协议的4或6版本。这些主要用于测试。我们建议您使用这些值而不是 <code>localhost</code> 或 <code>127.0.0.1</code>。</td>
</tr>
<tr>
<td style="text-align:left">任何 IPv4 或 anyIPv6</td>
<td style="text-align:left">服务器监听任何 IP 地址上指定端口上的客户端活动。使用IP协议的4或6版本。</td>
</tr>
</tbody>
</table>
<p>默认情况下，当使用V6互联网地址时，也会使用V4监听器。</p>
<h3 id="端口">端口</h3>
<p><code>bind()</code> 的第二个参数是指定端口的整数。端口唯一地标识主机上的服务。1024 以下的端口号为标准服务保留(0除外)。例如，FTP 数据传输通常在端口20上运行，每日报价在端口17上运行，HTTP 在端口80上运行。你的程序应该使用1024以上的端口号。如果端口已经在使用中，你的服务器的连接将被拒绝。</p>
<h3 id="侦听请求">侦听请求</h3>
<p>服务器使用 <code>await for</code> 开始监听 HTTP 请求。每收到一个请求，代码就会发送一个 &ldquo;Hello, world!&rdquo; 的响应。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Hello, world!&#39;</span><span class="p">);</span>
  <span class="kd">await</span> <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><p>你将在<a href="https://dart.dev/tutorials/server/httpserver#httprequest-object">监听和处理请求</a>一节中了解更多关于 <a href="https://api.dart.dev/stable/dart-io/HttpRequest-class.html">HttpRequest</a> 对象包含的内容以及如何编写响应。但首先，让我们看看客户端产生请求的一种方式。</p>
<h2 id="使用-html-表单发出-get-请求">使用 HTML 表单发出 GET 请求</h2>
<p>本节的示例文件：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/number_thinker.dart">number_thinker.dart</a> 和 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/web/make_a_guess.html">make_a_guess.html</a>。</p>
<p>本节介绍了一个命令行服务器，它可以随机选择一个0到9之间的数字。客户端是一个基本的 HTML 网页，<code>make_a_guess.html</code>，你可以用它来猜数字。</p>
<p>试试吧</p>
<ol>
<li>运行数字思考者服务器</li>
</ol>
<p>在命令行，运行 <code>number_thinker.dart</code> server。你应该看到类似下面的东西:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">cd</span> httpserver
$ dart bin/number_thinker.dart
I<span class="err">&#39;</span>m thinking of a number: <span class="m">6</span>
</code></pre></div><ol start="2">
<li>启动网络服务器</li>
</ol>
<p>从应用程序的顶部目录运行 <code>webdev serve</code>。</p>
<p>更多信息：<a href="https://dart.dev/tools/webdev">webdev 文档</a></p>
<ol start="3">
<li>打开 HTML 页面</li>
</ol>
<p>在浏览器中，进入 <a href="http://localhost:8080/make_a_guess.html">localhost:8080/make_a_guess.html</a>。</p>
<ol start="4">
<li>做一个猜测</li>
</ol>
<p>选择一个数字，然后按猜测按钮。</p>
<p><img src="https://dart.dev/tutorials/server/images/guessing.png" alt="img"></p>
<p>在客户端中没有涉及到 Dart 代码。客户端请求是通过浏览器向 Dart 服务器发出的，在 <code>make_a_guess.html</code> 中的 HTML 表单，它提供了一个自动制定和发送客户端 HTTP 请求的方法。该表单包含下拉列表和按钮。该表单还指定了 URL，其中包括端口号，以及请求的种类（请求方法）。它还可能包含建立查询字符串的元素。</p>
<p>下面是 <code>make_a_guess.html</code> 中的表单 HTML。</p>
<div class="highlight"><pre class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">form</span> <span class="na">action</span><span class="o">=</span><span class="s">&#34;http://localhost:4041&#34;</span> <span class="na">method</span><span class="o">=</span><span class="s">&#34;GET&#34;</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">select</span> <span class="na">name</span><span class="o">=</span><span class="s">&#34;q&#34;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">option</span> <span class="na">value</span><span class="o">=</span><span class="s">&#34;0&#34;</span><span class="p">&gt;</span>0<span class="p">&lt;/</span><span class="nt">option</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">option</span> <span class="na">value</span><span class="o">=</span><span class="s">&#34;1&#34;</span><span class="p">&gt;</span>1<span class="p">&lt;/</span><span class="nt">option</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">option</span> <span class="na">value</span><span class="o">=</span><span class="s">&#34;2&#34;</span><span class="p">&gt;</span>2<span class="p">&lt;/</span><span class="nt">option</span><span class="p">&gt;</span>
    <span class="c">&lt;!-- ··· --&gt;</span>
    <span class="p">&lt;</span><span class="nt">option</span> <span class="na">value</span><span class="o">=</span><span class="s">&#34;9&#34;</span><span class="p">&gt;</span>9<span class="p">&lt;/</span><span class="nt">option</span><span class="p">&gt;</span>
  <span class="p">&lt;/</span><span class="nt">select</span><span class="p">&gt;</span>
  <span class="p">&lt;</span><span class="nt">input</span> <span class="na">type</span><span class="o">=</span><span class="s">&#34;submit&#34;</span> <span class="na">value</span><span class="o">=</span><span class="s">&#34;Guess&#34;</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">form</span><span class="p">&gt;</span>
</code></pre></div><p>下面是表单的工作原理:</p>
<ul>
<li>表单的 <code>action</code> 属性被分配给发送请求的 URL</li>
<li>表单的 <code>method</code> 属性定义了请求的类型，这里是 <code>GET</code>。其他常见的请求类型包括 POST、PUT 和 DELETE。</li>
<li>表单中任何有名称(<code>name</code>)的元素，比如 <code>&lt;select&gt;</code> 元素，都会成为查询字符串中的一个参数。</li>
<li>当按下提交按钮(<code>&lt;input type=&quot;submit&quot;...&gt;</code>)时，提交按钮会根据表单的内容制定请求并发送。</li>
</ul>
<h3 id="一个-restful-get-请求">一个 RESTful GET 请求</h3>
<p>REST(REpresentational State Transfer)是一套设计 Web 服务的原则。乖巧的 HTTP 客户端和服务器遵守为 GET 请求定义的 REST 原则。</p>
<p>一个 GET 请求:</p>
<ul>
<li>只检索数据</li>
<li>不会改变服务器的状态</li>
<li>有长度限制</li>
<li>可以在请求的 URL 中发送查询字符串</li>
</ul>
<p>在这个例子中，客户端发出了一个符合 REST 的 GET 请求。</p>
<h2 id="监听和处理请求">监听和处理请求</h2>
<p>本节的示例文件: <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/number_thinker.dart">number_thinker.dart</a> 和 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/web/make_a_guess.html">make_a_guess.html</a>。</p>
<p>现在你已经看到这个基于浏览器的客户端的例子，让我们看看数字思维服务器的 Dart 代码，从 <code>main()</code> 开始。</p>
<p>再一次，服务器绑定了一个主机和端口。在这里，每收到一个请求都会调用顶层的 <code>handleRequest()</code> 方法。因为 HttpServer 实现了 <a href="https://api.dart.dev/stable/dart-async/Stream-class.html">Stream</a>，所以可以使用 <code>await for</code> 来处理请求。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;dart:math&#39;</span> <span class="k">show</span> <span class="n">Random</span><span class="p">;</span>

<span class="n">Random</span> <span class="n">intGenerator</span> <span class="o">=</span> <span class="n">Random</span><span class="p">();</span>
<span class="kt">int</span> <span class="n">myNumber</span> <span class="o">=</span> <span class="n">intGenerator</span><span class="p">.</span><span class="n">nextInt</span><span class="p">(</span><span class="m">10</span><span class="p">);</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s2">&#34;I&#39;m thinking of a number: </span><span class="si">$</span><span class="n">myNumber</span><span class="s2">&#34;</span><span class="p">);</span>

  <span class="n">HttpServer</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span>
    <span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span>
    <span class="m">4041</span><span class="p">,</span>
  <span class="p">);</span>
  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">request</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">handleRequest</span><span class="p">(</span><span class="n">request</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>当一个 <code>GET</code> 请求到达时，<code>handleRequest()</code> 方法会调用 <code>handleGet()</code> 来处理该请求。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">handleRequest</span><span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;GET&#39;</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">handleGet</span><span class="p">(</span><span class="n">request</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// ···
</span><span class="c1"></span>    <span class="p">}</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Exception in handleRequest: </span><span class="si">$</span><span class="n">e</span><span class="s1">&#39;</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Request handled.&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>一个 <a href="https://api.dart.dev/stable/dart-io/HttpRequest-class.html">HttpRequest</a> 对象有很多属性，提供了关于请求的信息。下表列出了一些有用的属性。</p>
<table>
<thead>
<tr>
<th style="text-align:left">属性</th>
<th style="text-align:left">信息</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">method</td>
<td style="text-align:left">&lsquo;GET&rsquo;, &lsquo;POST&rsquo;, &lsquo;PUT&rsquo; 等方法中的一个。</td>
</tr>
<tr>
<td style="text-align:left">uri</td>
<td style="text-align:left">一个 <a href="https://api.dart.dev/stable/dart-core/Uri-class.html">Uri</a> 对象：scheme、host、port、query string 和其他关于请求资源的信息。</td>
</tr>
<tr>
<td style="text-align:left">response</td>
<td style="text-align:left">一个 <a href="https://api.dart.dev/stable/dart-io/HttpResponse-class.html">HttpResponse</a> 对象：服务器将其响应写入其中。</td>
</tr>
<tr>
<td style="text-align:left">headers</td>
<td style="text-align:left">一个 <a href="https://api.dart.dev/stable/dart-io/HttpHeaders-class.html">HttpHeaders</a> 对象：请求的头信息，包括 <a href="https://api.dart.dev/stable/dart-io/ContentType-class.html">ContentType</a>、内容长度、日期等。</td>
</tr>
</tbody>
</table>
<h3 id="使用方法属性">使用方法属性</h3>
<p>下面的数想器例子中的代码使用 HttpRequest 的 <code>method</code> 属性来确定收到了什么样的请求。这个服务器只处理 GET 请求。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">if</span> <span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;GET&#39;</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">handleGet</span><span class="p">(</span><span class="n">request</span><span class="p">);</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="n">request</span><span class="p">.</span><span class="n">response</span>
    <span class="p">..</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">methodNotAllowed</span>
    <span class="p">..</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Unsupported request: </span><span class="si">${</span><span class="n">request</span><span class="p">.</span><span class="n">method</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="p">..</span><span class="n">close</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><h3 id="使用-uri-属性">使用 uri 属性</h3>
<p>在浏览器中输入一个 URL 会产生一个 GET 请求，它只是简单地从指定的资源中请求数据。它可以通过附加在 URI 上的查询字符串随请求发送少量数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">handleGet</span><span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">guess</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">uri</span><span class="p">.</span><span class="n">queryParameters</span><span class="p">[</span><span class="s1">&#39;q&#39;</span><span class="p">];</span>
  <span class="c1">// ···
</span><span class="c1"></span><span class="p">}</span>
</code></pre></div><p>使用 HttpRequest 对象的 <code>uri</code> 属性来获取一个 <a href="https://api.dart.dev/stable/dart-core/Uri-class.html">Uri</a> 对象，这个 Uri 对象包含了用户输入的 URL 的信息。Uri 对象的 <code>queryParameters</code> 属性是一个 Map，包含查询字符串的组件。通过名称来引用所需的参数。本例使用 <code>q</code> 来标识猜测的数字。</p>
<h3 id="设置响应的状态码">设置响应的状态码</h3>
<p>服务器应该设置状态码来表示请求的成功或失败。前面看到数想家将状态码设置为 <code>methodNotAllowed</code> 来拒绝非 GET 请求。在后面的代码中，为了表示请求成功，响应完成，数想家服务器将 <code>HttpResponse</code> 状态码设置为 <code>HttpStatus.ok</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">handleGet</span><span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">guess</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">uri</span><span class="p">.</span><span class="n">queryParameters</span><span class="p">[</span><span class="s1">&#39;q&#39;</span><span class="p">];</span>
  <span class="kd">final</span> <span class="n">response</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">;</span>
  <span class="n">response</span><span class="p">.</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">ok</span><span class="p">;</span>
  <span class="c1">// ···
</span><span class="c1"></span><span class="p">}</span>
</code></pre></div><p><code>HttpStatus.ok</code> 和 <code>HttpStatus.methodNotAllowed</code> 是 <a href="https://api.dart.dev/stable/dart-io/HttpStatus-class.html">HttpStatus</a> 类中许多预定义状态码中的两个。另一个有用的预定义状态码是 <code>HttpStatus.notFound</code>(经典的 404）。</p>
<p>除了状态码(<code>statusCode</code>)，HttpResponse 对象还有其他有用的属性:</p>
<table>
<thead>
<tr>
<th style="text-align:left">属性</th>
<th style="text-align:left">信息</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">contentLength</td>
<td style="text-align:left">响应的长度，-1 表示事先不知道长度。</td>
</tr>
<tr>
<td style="text-align:left">cookies</td>
<td style="text-align:left">要在客户端设置的 <a href="https://api.dart.dev/stable/dart-io/Cookie-class.html">Cookies</a> 列表。</td>
</tr>
<tr>
<td style="text-align:left">encoding</td>
<td style="text-align:left">编写字符串时使用的<a href="https://api.dart.dev/stable/dart-convert/Encoding-class.html">编码</a>，如 JSON 和 UTF-8。</td>
</tr>
<tr>
<td style="text-align:left">headers</td>
<td style="text-align:left">响应头，是一个 <a href="https://api.dart.dev/stable/dart-io/HttpHeaders-class.html">HttpHeaders</a> 对象。</td>
</tr>
</tbody>
</table>
<h3 id="将响应写到-httpresponse-对象">将响应写到 HttpResponse 对象</h3>
<p>每个 HttpRequest 对象都有一个对应的 HttpResponse 对象。服务器通过响应对象将数据发回给客户端。</p>
<p>使用 HttpResponse 写方法之一(<code>write()</code>、<code>writeln()</code>、<code>writeAll()</code> 或 <code>writeCharCodes()</code>)将响应数据写入 HttpResponse 对象。或者通过 <code>addStream</code> 将 <code>HttpResponse</code> 对象连接到一个流，并写入流。响应完成后关闭对象。关闭 HttpResponse 对象会将数据发回给客户端。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">handleGet</span><span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// ···
</span><span class="c1"></span>  <span class="k">if</span> <span class="p">(</span><span class="n">guess</span> <span class="o">==</span> <span class="n">myNumber</span><span class="p">.</span><span class="n">toString</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">response</span>
      <span class="p">..</span><span class="n">writeln</span><span class="p">(</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
      <span class="p">..</span><span class="n">writeln</span><span class="p">(</span><span class="s2">&#34;I&#39;m thinking of another number.&#34;</span><span class="p">)</span>
      <span class="p">..</span><span class="n">close</span><span class="p">();</span>
    <span class="c1">// ···
</span><span class="c1"></span>  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="从独立的客户端进行-post-请求">从独立的客户端进行 POST 请求</h2>
<p>本节的示例文件：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/basic_writer_server.dart">basic_writer_server.dart</a> 和  <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/basic_writer_client.dart">basic_writer_client.dart</a>。</p>
<p>在 <code>hello world</code> 和 <code>number thinker</code> 的例子中，浏览器生成了简单的 GET 请求，对于更复杂的 GET 请求和其他类型的请求，如 POST、PUT 或 DELETE，你需要写一个客户端程序，其中有两种。</p>
<ul>
<li>一个独立的客户端程序，它使用 <code>dart:io</code> 的 <a href="https://api.dart.dev/stable/dart-io/HttpClient-class.html">HttpClient</a> 类。</li>
<li>基于浏览器的客户端，使用 <a href="https://api.dart.dev/stable/dart-html/dart-html-library.html">dart:html</a> 中的 API。本教程不涉及基于浏览器的客户端。要查看基于浏览器的客户端和相关服务器的代码，请参见 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/web/note_client.dart">note_client.dart</a>、<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/note_server.dart">note_server.dart</a> 和 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/web/note_taker.html">note_taker.html</a>。</li>
</ul>
<p>让我们看看一个独立的客户端，<code>basic_writer_client.dart</code> 和它的服务器 <code>basic_writer_server.dart</code>。客户端发出一个 POST 请求，将 JSON 数据保存到服务器端的文件中。服务器接受请求并保存文件。</p>
<h4 id="试试吧">试试吧</h4>
<p>在命令行上运行服务器和客户端。</p>
<ol>
<li>首先，运行服务器:</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> httpserver
$ dart bin/basic_writer_server.dart
</code></pre></div><ol start="2">
<li>在一个新的终端中，运行客户端:</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">cd</span> httpserver
$ dart bin/basic_writer_client.dart
Wrote data <span class="k">for</span> Han Solo.
</code></pre></div><p>看看服务器写入 <code>file.txt</code> 的 JSON 数据:</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span><span class="nt">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;Han Solo&#34;</span><span class="p">,</span><span class="nt">&#34;job&#34;</span><span class="p">:</span><span class="s2">&#34;reluctant hero&#34;</span><span class="p">,</span><span class="nt">&#34;BFF&#34;</span><span class="p">:</span><span class="s2">&#34;Chewbacca&#34;</span><span class="p">,</span><span class="nt">&#34;ship&#34;</span><span class="p">:</span><span class="s2">&#34;Millennium Falcon&#34;</span><span class="p">,</span><span class="nt">&#34;weakness&#34;</span><span class="p">:</span><span class="s2">&#34;smuggling debts&#34;</span><span class="p">}</span>
</code></pre></div><p>客户端创建一个 HttpClient 对象，并使用 <code>post()</code> 方法进行请求。发起一个请求涉及两个 Future。</p>
<ul>
<li><code>post()</code> 方法建立与服务器的网络连接并完成第一个 Future，返回一个 HttpClientRequest 对象。</li>
<li>客户端组成请求对象并关闭它。<code>close()</code> 方法将请求发送到服务器并返回第二个 Future，它以一个 HttpClientResponse 对象完成。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;dart:convert&#39;</span><span class="p">;</span>

<span class="kt">String</span> <span class="n">_host</span> <span class="o">=</span> <span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">.</span><span class="n">host</span><span class="p">;</span>
<span class="kt">String</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;file.txt&#39;</span><span class="p">;</span>

<span class="n">Map</span> <span class="n">jsonData</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;name&#39;</span><span class="o">:</span> <span class="s1">&#39;Han Solo&#39;</span><span class="p">,</span>
  <span class="s1">&#39;job&#39;</span><span class="o">:</span> <span class="s1">&#39;reluctant hero&#39;</span><span class="p">,</span>
  <span class="s1">&#39;BFF&#39;</span><span class="o">:</span> <span class="s1">&#39;Chewbacca&#39;</span><span class="p">,</span>
  <span class="s1">&#39;ship&#39;</span><span class="o">:</span> <span class="s1">&#39;Millennium Falcon&#39;</span><span class="p">,</span>
  <span class="s1">&#39;weakness&#39;</span><span class="o">:</span> <span class="s1">&#39;smuggling debts&#39;</span>
<span class="p">};</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">HttpClientRequest</span> <span class="n">request</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpClient</span><span class="p">().</span><span class="n">post</span><span class="p">(</span><span class="n">_host</span><span class="p">,</span> <span class="m">4049</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> <span class="cm">/*1*/</span>
    <span class="p">..</span><span class="n">headers</span><span class="p">.</span><span class="n">contentType</span> <span class="o">=</span> <span class="n">ContentType</span><span class="p">.</span><span class="n">json</span> <span class="cm">/*2*/</span>
    <span class="p">..</span><span class="n">write</span><span class="p">(</span><span class="n">jsonEncode</span><span class="p">(</span><span class="n">jsonData</span><span class="p">));</span> <span class="cm">/*3*/</span>
  <span class="n">HttpClientResponse</span> <span class="n">response</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">request</span><span class="p">.</span><span class="n">close</span><span class="p">();</span> <span class="cm">/*4*/</span>
  <span class="kd">await</span> <span class="n">utf8</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">response</span> <span class="cm">/*5*/</span><span class="p">).</span><span class="n">forEach</span><span class="p">(</span><span class="n">print</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>/<em>1</em>/ <code>post()</code> 方法需要主机、端口和请求资源的路径。除了 <code>post()</code> 之外，<a href="https://api.dart.dev/stable/dart-io/HttpClient-class.html">HttpClient</a> 类还提供了其他类型的请求函数，包括 <code>postUrl()</code>、<code>get()</code> 和 <code>open()</code>。</p>
<p>/<em>2</em>/ 一个 <a href="https://api.dart.dev/stable/dart-io/HttpClientRequest-class.html">HttpClientRequest</a> 对象有一个 <a href="https://api.dart.dev/stable/dart-io/HttpHeaders-class.html">HttpHeaders</a> 对象，它包含了请求头的信息。对于一些请求头，比如 <code>contentType</code>，HttpHeaders 有一个针对该请求头的属性。对于其他的请求头，使用 <code>set()</code> 方法将该请求头放入 HttpHeaders 对象中。</p>
<p>/<em>3</em>/ 客户端使用 <code>write()</code> 向请求对象写入数据。编码，在这个例子中是 JSON，与 <a href="https://api.dart.dev/stable/dart-io/ContentType-class.html">ContentType</a> 头中指定的类型相匹配。</p>
<p>/<em>4</em>/ <code>close()</code> 方法将请求发送到服务器，完成后返回一个 <a href="https://api.dart.dev/stable/dart-io/HttpClientResponse-class.html">HttpClientResponse</a> 对象。</p>
<p>/<em>5</em>/ 来自服务器的 UTF-8 响应将被解码。使用在 <a href="https://api.dart.dev/stable/dart-convert/dart-convert-library.html">dart:convert</a> 库中定义的转换器将数据转换为常规的 Dart 字符串格式。</p>
<h3 id="一个-restful-post-请求">一个 RESTful POST 请求</h3>
<p>与 GET 请求类似，REST 为 POST 请求提供了指导方针。</p>
<p>一个 POST 请求:</p>
<ul>
<li>创建一个资源(在这个例子中，一个文件)</li>
<li>使用一个 URI，其结构与文件和目录路径名相似；例如，URI 没有查询字符串。</li>
<li>以 JSON 或 XML 格式传输数据</li>
<li>没有状态，也不会改变服务器的状态。</li>
<li>无长度限制</li>
</ul>
<p>这个例子中的客户端发出 REST 兼容的 POST 请求。</p>
<p>要想看到使 REST 兼容的 GET 请求的客户端代码，请看 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/number_guesser.dart">number_guesser.dart</a>。它是一个独立的客户端，用于数字思考者服务器，定期进行猜测，直到猜对为止。</p>
<h2 id="在服务器中处理一个-post-请求">在服务器中处理一个 POST 请求</h2>
<p>本节的示例文件：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/basic_writer_server.dart">basic_writer_server.dart</a> 和 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/basic_writer_client.dart">basic_writer_client.dart</a>。</p>
<p>一个 HttpRequest 对象是一个字节列表流(<code>Stream&lt;List&lt;int&gt;</code>)。要获得客户端发送的数据，就要监听 HttpRequest 对象上的数据。</p>
<p>如果来自客户端的请求包含了大量的数据，数据可能会以多个分块的形式到达。你可以使用 Stream 中的 <code>join()</code> 方法来连接这些分块的字符串值。</p>
<p><img src="https://dart.dev/tutorials/server/images/flowchart.png" alt="img"></p>
<p><code>basic_writer_server.dart</code> 文件实现了一个遵循这种模式的服务器。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;dart:convert&#39;</span><span class="p">;</span>

<span class="kt">String</span> <span class="n">_host</span> <span class="o">=</span> <span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">.</span><span class="n">host</span><span class="p">;</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">_host</span><span class="p">,</span> <span class="m">4049</span><span class="p">);</span>
  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">req</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">ContentType</span> <span class="n">contentType</span> <span class="o">=</span> <span class="n">req</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="n">contentType</span><span class="p">;</span>
    <span class="n">HttpResponse</span> <span class="n">response</span> <span class="o">=</span> <span class="n">req</span><span class="p">.</span><span class="n">response</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">req</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;POST&#39;</span> <span class="o">&amp;&amp;</span>
        <span class="n">contentType</span><span class="o">?</span><span class="p">.</span><span class="n">mimeType</span> <span class="o">==</span> <span class="s1">&#39;application/json&#39;</span> <span class="cm">/*1*/</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">try</span> <span class="p">{</span>
        <span class="kt">String</span> <span class="n">content</span> <span class="o">=</span>
            <span class="kd">await</span> <span class="n">utf8</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">req</span><span class="p">).</span><span class="n">join</span><span class="p">();</span> <span class="cm">/*2*/</span>
        <span class="kd">var</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsonDecode</span><span class="p">(</span><span class="n">content</span><span class="p">)</span> <span class="o">as</span> <span class="n">Map</span><span class="p">;</span> <span class="cm">/*3*/</span>
        <span class="kd">var</span> <span class="n">fileName</span> <span class="o">=</span> <span class="n">req</span><span class="p">.</span><span class="n">uri</span><span class="p">.</span><span class="n">pathSegments</span><span class="p">.</span><span class="n">last</span><span class="p">;</span> <span class="cm">/*4*/</span>
        <span class="kd">await</span> <span class="n">File</span><span class="p">(</span><span class="n">fileName</span><span class="p">)</span>
            <span class="p">.</span><span class="n">writeAsString</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nl">mode:</span> <span class="n">FileMode</span><span class="p">.</span><span class="n">write</span><span class="p">);</span>
        <span class="n">req</span><span class="p">.</span><span class="n">response</span>
          <span class="p">..</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">ok</span>
          <span class="p">..</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Wrote data for </span><span class="si">${</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">);</span>
      <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">response</span>
          <span class="p">..</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">internalServerError</span>
          <span class="p">..</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Exception during file I/O: </span><span class="si">$</span><span class="n">e</span><span class="s1">.&#39;</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">response</span>
        <span class="p">..</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">methodNotAllowed</span>
        <span class="p">..</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Unsupported request: </span><span class="si">${</span><span class="n">req</span><span class="p">.</span><span class="n">method</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="kd">await</span> <span class="n">response</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>/<em>1</em>/ 该请求有一个 HttpHeaders 对象。记得客户端将 <code>contentType</code> 头设置为 JSON(application/json)。该服务器拒绝不是 JSON 编码的请求。</p>
<p>/<em>2</em>/ 一个 POST 请求对它可以发送的数据量没有限制，数据可能会以多块形式发送。此外，JSON 是 UTF-8，而 UTF-8 字符可以在多个字节上进行编码。<code>join()</code> 方法将这些分块放在一起。</p>
<p>/<em>3</em>/ 客户端发送的数据是 JSON 格式的。服务器使用 <a href="https://api.dart.dev/stable/dart-convert/dart-convert-library.html">dart:convert</a> 库中的 JSON 编解码器对其进行解码。</p>
<p>/<em>4</em>/ 请求的 URL 是 <a href="http://localhost:4049/file.txt">localhost:4049/file.txt</a>。代码 <code>req.uri.pathSegments.last</code> 从 URI 中提取文件名: <code>file.txt</code>。</p>
<h3 id="关于-cors-头的说明">关于 CORS 头的说明</h3>
<p>如果你想为运行在不同源头（不同主机或端口）的客户端提供服务，你需要添加 CORS 头。下面的代码，取自 note_server.dart，允许从任何来源的 POST 和 OPTIONS 请求。谨慎使用 CORS 头文件，因为它们会给你的网络带来安全风险。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">addCorsHeaders</span><span class="p">(</span><span class="n">HttpResponse</span> <span class="n">response</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">response</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;Access-Control-Allow-Origin&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">);</span>
  <span class="n">response</span><span class="p">.</span><span class="n">headers</span>
      <span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;Access-Control-Allow-Methods&#39;</span><span class="p">,</span> <span class="s1">&#39;POST, OPTIONS&#39;</span><span class="p">);</span>
  <span class="n">response</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;Access-Control-Allow-Headers&#39;</span><span class="p">,</span>
      <span class="s1">&#39;Origin, X-Requested-With, Content-Type, Accept&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>更多信息，请参考维基百科的<a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">跨源资源共享</a>一文。</p>
<h2 id="使用-http_server-包">使用 http_server 包</h2>
<p>本节的示例文件：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/mini_file_server.dart">mini_file_server.dart</a> 和 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/static_file_server.dart">static_file_server.dart</a>。</p>
<p>对于一些更高层次的构件，我们推荐你尝试 <a href="https://pub.dev/packages/http_server">http_server</a> pub 包，它包含了一组类，与 <code>dart:io</code> 库中的 HttpServer 类一起，使得实现 HTTP 务器更加容易。</p>
<p>在本节中，我们比较了一个只使用 <code>dart:io</code> 的 API 编写的服务器和一个使用 dart:io 和 http_server 一起编写的具有相同功能的服务器。</p>
<p>你可以在 <code>mini_file_server.dart</code> 中找到第一个服务器。它通过从 <code>web</code> 目录返回 <code>index.html</code> 文件的内容来响应所有请求。</p>
<h3 id="试试吧-1">试试吧</h3>
<p>在命令行中运行服务器:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">cd</span> httpserver
$ dart bin/mini_file_server.dart
</code></pre></div><p>在浏览器中输入 <a href="http://localhost:4044/">localhost:4044</a>。服务器会显示一个 HTML 文件。</p>
<p><img src="https://dart.dev/tutorials/server/images/index_file.png" alt="img"></p>
<p>这是迷你文件服务器的代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>

<span class="n">File</span> <span class="n">targetFile</span> <span class="o">=</span> <span class="n">File</span><span class="p">(</span><span class="s1">&#39;web/index.html&#39;</span><span class="p">);</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">Stream</span><span class="o">&lt;</span><span class="n">HttpRequest</span><span class="o">&gt;</span> <span class="n">server</span><span class="p">;</span>

  <span class="k">try</span> <span class="p">{</span>
    <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span> <span class="m">4044</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s2">&#34;Couldn&#39;t bind to port 4044: </span><span class="si">$</span><span class="n">e</span><span class="s2">&#34;</span><span class="p">);</span>
    <span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="m">1</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="n">HttpRequest</span> <span class="n">req</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="kd">await</span> <span class="n">targetFile</span><span class="p">.</span><span class="n">exists</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">print</span><span class="p">(</span><span class="s2">&#34;Serving </span><span class="si">${</span><span class="n">targetFile</span><span class="p">.</span><span class="n">path</span><span class="si">}</span><span class="s2">.&#34;</span><span class="p">);</span>
      <span class="n">req</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="n">contentType</span> <span class="o">=</span> <span class="n">ContentType</span><span class="p">.</span><span class="n">html</span><span class="p">;</span>
      <span class="k">try</span> <span class="p">{</span>
        <span class="kd">await</span> <span class="n">req</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">addStream</span><span class="p">(</span><span class="n">targetFile</span><span class="p">.</span><span class="n">openRead</span><span class="p">());</span>
      <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">print</span><span class="p">(</span><span class="s2">&#34;Couldn&#39;t read file: </span><span class="si">$</span><span class="n">e</span><span class="s2">&#34;</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="m">1</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">print</span><span class="p">(</span><span class="s2">&#34;Can&#39;t open </span><span class="si">${</span><span class="n">targetFile</span><span class="p">.</span><span class="n">path</span><span class="si">}</span><span class="s2">.&#34;</span><span class="p">);</span>
      <span class="n">req</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">statusCode</span> <span class="o">=</span> <span class="n">HttpStatus</span><span class="p">.</span><span class="n">notFound</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="kd">await</span> <span class="n">req</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>这段代码确定文件是否存在，如果存在，则打开文件，并将文件内容管道化到HttpResponse对象。</p>
<p>第二个服务器，你可以在 <a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/basic_file_server.dart">basic_file_server.dart</a> 中找到它的代码，使用 <a href="https://pub.dev/packages/http_server">http_server</a> 包。</p>
<h3 id="试试吧-2">试试吧</h3>
<p>在命令行中运行服务器:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">cd</span> httpserver
$ dart bin/basic_file_server.dart
</code></pre></div><p>在浏览器中输入 <a href="http://localhost:4046/">localhost:4046</a>。服务器显示与之前相同的 index.html 文件。</p>
<p><img src="https://dart.dev/tutorials/server/images/index_file_4046.png" alt="img"></p>
<p>在这个服务器中，处理请求的代码要短得多，因为 <a href="https://pub.dev/documentation/http_server/latest/http_server/VirtualDirectory-class.html">VirtualDirectory</a> 类处理服务文件的细节。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;package:http_server/http_server.dart&#39;</span><span class="p">;</span>

<span class="n">File</span> <span class="n">targetFile</span> <span class="o">=</span> <span class="n">File</span><span class="p">(</span><span class="s1">&#39;web/index.html&#39;</span><span class="p">);</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">VirtualDirectory</span> <span class="n">staticFiles</span> <span class="o">=</span> <span class="n">VirtualDirectory</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">);</span>

  <span class="kd">var</span> <span class="n">serverRequests</span> <span class="o">=</span>
      <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span> <span class="m">4046</span><span class="p">);</span>
  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">request</span> <span class="k">in</span> <span class="n">serverRequests</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">staticFiles</span><span class="p">.</span><span class="n">serveFile</span><span class="p">(</span><span class="n">targetFile</span><span class="p">,</span> <span class="n">request</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>这里，请求的资源 index.html 是由 VirtualDirectory 类中的 <code>serviceFile()</code> 方法提供的。你不需要写代码来打开一个文件并将其内容用管道传送到请求中。</p>
<p>另一个文件服务器 <code>static_file_server.dart</code> 也使用 http_server 包。这个服务器可以服务于服务器目录或子目录中的任何文件。</p>
<p>运行 <code>static_file_server.dart</code>，用 <a href="http://localhost:4048/">localhost:4048</a> 这个 URL 进行测试。</p>
<p>下面是 <code>static_file_server.dart</code> 的代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;package:http_server/http_server.dart&#39;</span><span class="p">;</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">staticFiles</span> <span class="o">=</span> <span class="n">VirtualDirectory</span><span class="p">(</span><span class="s1">&#39;web&#39;</span><span class="p">);</span>
  <span class="n">staticFiles</span><span class="p">.</span><span class="n">allowDirectoryListing</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span> <span class="cm">/*1*/</span>
  <span class="n">staticFiles</span><span class="p">.</span><span class="n">directoryHandler</span> <span class="o">=</span> <span class="p">(</span><span class="n">dir</span><span class="p">,</span> <span class="n">request</span><span class="p">)</span> <span class="cm">/*2*/</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="n">indexUri</span> <span class="o">=</span> <span class="n">Uri</span><span class="p">.</span><span class="n">file</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">path</span><span class="p">).</span><span class="n">resolve</span><span class="p">(</span><span class="s1">&#39;index.html&#39;</span><span class="p">);</span>
    <span class="n">staticFiles</span><span class="p">.</span><span class="n">serveFile</span><span class="p">(</span><span class="n">File</span><span class="p">(</span><span class="n">indexUri</span><span class="p">.</span><span class="n">toFilePath</span><span class="p">()),</span> <span class="n">request</span><span class="p">);</span> <span class="cm">/*3*/</span>
  <span class="p">};</span>

  <span class="kd">var</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">InternetAddress</span><span class="p">.</span><span class="n">loopbackIPv4</span><span class="p">,</span> <span class="m">4048</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Listening on port 4048&#39;</span><span class="p">);</span>
  <span class="kd">await</span> <span class="n">server</span><span class="p">.</span><span class="n">forEach</span><span class="p">(</span><span class="n">staticFiles</span><span class="p">.</span><span class="n">serveRequest</span><span class="p">);</span> <span class="cm">/*4*/</span>
<span class="p">}</span>
</code></pre></div><p>/<em>1</em>/ 允许客户端请求服务器目录内的文件。</p>
<p>/<em>2</em>/ 一个匿名函数，处理对目录本身的请求，即 URL 不包含文件名。该函数将这些请求重定向到 <code>index.html</code>。</p>
<p>/<em>3</em>/ <code>serveFile</code> 方法为一个文件提供服务，在这个例子中，它为目录请求服务index.html。</p>
<p>/<em>4</em>/ VirtualDirectory 类提供的 <code>serviceRequest</code> 方法处理指定文件的请求。</p>
<h2 id="使用-bindsecure-的-https-方法">使用 bindSecure() 的 https 方法</h2>
<p>本节的示例：<a href="https://github.com/dart-lang/site-www/blob/master/examples/httpserver/bin/hello_world_server_secure.dart">hello_world_server_secure.dart</a>。</p>
<p>你可能已经注意到，HttpServer 类定义了一个叫做 <code>bindSecure()</code> 的方法，它使用 HTTPS(Hyper Text Transfer Protocol with Secure Sockets Layer)提供安全连接。要使用 <code>bindSecure()</code> 方法，你需要一个证书，这个证书由证书颁发机构(CA)提供。有关证书的更多信息，请参考<a href="https://www.tldp.org/HOWTO/SSL-Certificates-HOWTO/x64.html">什么是 SSL 和什么是证书</a>？</p>
<p>为了说明问题，下面的服务器 <code>hello_world_server_secure.dart</code> 使用 Dart 团队创建的证书调用 <code>bindSecure()</code> 进行测试。你必须为你的服务器提供自己的证书。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;dart:io&#39;</span><span class="p">;</span>

<span class="kt">String</span> <span class="n">certificateChain</span> <span class="o">=</span> <span class="s1">&#39;server_chain.pem&#39;</span><span class="p">;</span>
<span class="kt">String</span> <span class="n">serverKey</span> <span class="o">=</span> <span class="s1">&#39;server_key.pem&#39;</span><span class="p">;</span>

<span class="n">Future</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">serverContext</span> <span class="o">=</span> <span class="n">SecurityContext</span><span class="p">();</span> <span class="cm">/*1*/</span>
  <span class="n">serverContext</span><span class="p">.</span><span class="n">useCertificateChain</span><span class="p">(</span><span class="n">certificateChain</span><span class="p">);</span> <span class="cm">/*2*/</span>
  <span class="n">serverContext</span><span class="p">.</span><span class="n">usePrivateKey</span><span class="p">(</span><span class="n">serverKey</span><span class="p">,</span> <span class="nl">password:</span> <span class="s1">&#39;dartdart&#39;</span><span class="p">);</span> <span class="cm">/*3*/</span>

  <span class="kd">var</span> <span class="n">server</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">HttpServer</span><span class="p">.</span><span class="n">bindSecure</span><span class="p">(</span>
    <span class="s1">&#39;localhost&#39;</span><span class="p">,</span>
    <span class="m">4047</span><span class="p">,</span>
    <span class="n">serverContext</span><span class="p">,</span> <span class="cm">/*4*/</span>
  <span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Listening on localhost:</span><span class="si">${</span><span class="n">server</span><span class="p">.</span><span class="n">port</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
  <span class="kd">await</span> <span class="k">for</span> <span class="p">(</span><span class="n">HttpRequest</span> <span class="n">request</span> <span class="k">in</span> <span class="n">server</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Hello, world!&#39;</span><span class="p">);</span>
    <span class="kd">await</span> <span class="n">request</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>/<em>1</em>/ 安全网络连接的可选设置在 SecurityContext 对象中指定，有一个默认的对象 SecurityContext.defaultContext，包括知名证书机构的可信根证书。</p>
<p>/<em>2</em>/ 一个包含从服务器证书到签名机关根证书链的文件，<a href="https://en.wikipedia.org/wiki/Privacy-Enhanced_Mail">格式为 PEM</a>。</p>
<p>/<em>3</em>/ 一个包含（加密的）服务器证书私钥的文件，<a href="https://en.wikipedia.org/wiki/Privacy-Enhanced_Mail">PEM 格式</a>。</p>
<p>/<em>4</em>/ 在服务器上，上下文参数是必需的，对客户端来说是可选的。如果省略它，则使用默认的内置可信根的上下文。</p>
<h2 id="其他资源">其他资源</h2>
<p>请访问这些 API 文档，了解本教程中讨论的类和库的更多细节。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Dart 类</th>
<th style="text-align:left">目的</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpServer-class.html">HttpServer</a></td>
<td style="text-align:left">一个 HTTP 服务器</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpClient-class.html">HttpClient</a></td>
<td style="text-align:left">一个 HTTP 客户端</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpRequest-class.html">HttpRequest</a></td>
<td style="text-align:left">一个服务器端请求对象</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpResponse-class.html">HttpResponse</a></td>
<td style="text-align:left">一个服务器端响应对象</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpClientRequest-class.html">HttpClientRequest</a></td>
<td style="text-align:left">一个客户端请求对象</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpClientResponse-class.html">HttpClientResponse</a></td>
<td style="text-align:left">一个客户端响应对象</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpHeaders-class.html">HttpHeaders</a></td>
<td style="text-align:left">请求头</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/HttpStatus-class.html">HttpStatus</a></td>
<td style="text-align:left">响应的状态</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/InternetAddress-class.html">InternetAddress</a></td>
<td style="text-align:left">一个互联网地址</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://api.dart.dev/stable/dart-io/SecurityContext-class.html">SecurityContext</a></td>
<td style="text-align:left">包含安全连接的证书、密钥和信任信息。</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/http_server">http_server</a> 包</td>
<td style="text-align:left">一个具有较高级别的 HTTP 类的包</td>
</tr>
</tbody>
</table>
<h2 id="下一步该怎么做">下一步该怎么做？</h2>
<ul>
<li>如果你还没有尝试过服务器端的 codelab，可以尝试<a href="https://dart-lang.github.io/server/codelab/">编写一个服务器应用程序</a>。</li>
<li><a href="https://dart-lang.github.io/server/">Servers with Dart</a> 链接到编写独立 Dart 应用程序的资源，包括服务器。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/client" term="client" label="client" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[如何使用包]]></title>
            <link href="https://ohmyweekly.github.io/notes/how-to-use-packages/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/commonly-used-packages/?utm_source=atom_feed" rel="related" type="text/html" title="常用的包" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app-part-two/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第二部分" />
            
                <id>https://ohmyweekly.github.io/notes/how-to-use-packages/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-29T00:00:00+08:00</published>
            <updated>2020-06-29T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Dart 包管理工具 - pub</blockquote><p>Dart 生态系统使用包来管理共享软件，如库和工具。要获得 Dart 包，你可以使用 <code>pub</code> 包管理器。你可以在 <a href="https://pub.dev/">pub.dev</a> 网站上找到公开的包，也可以从本地文件系统或其他地方加载包，比如 Git 仓库。无论你的包来自哪里，pub 都会管理版本依赖关系，帮助你获得相互之间以及与 SDK 版本兼容的包版本。</p>
<p>大多数精通 Dart 的 <a href="https://dart.dev/tools#ides-and-editors">IDE</a> 都提供了对 pub 的支持，包括创建、下载、更新和发布包。或者你可以<a href="https://dart.dev/tools/pub/cmd">在命令行中使用 pub</a>。</p>
<p>至少，一个 Dart 包是一个包含 <a href="https://dart.dev/tools/pub/pubspec">pubspec 文件</a>的目录。pubspec 包含一些关于包的元数据。此外，一个包可以包含依赖关系(在 pubspec 中列出)，Dart 库，应用程序，资源，测试，图像和例子。</p>
<p>要使用一个包，请执行以下操作:</p>
<ul>
<li>创建一个 pubspec(一个名为 <code>pubspec.yaml</code> 的文件，它列出了软件包的依赖关系，并包含其他元数据，如版本号)。</li>
<li>使用 <code>pub</code> 来获取你的包的依赖关系。</li>
<li>如果你的 Dart 代码依赖于软件包中的一个库，则导入该库。</li>
</ul>
<h2 id="创建一个-pubspec">创建一个 pubspec</h2>
<p>pubspec 是一个名为 <code>pubspec.yaml</code> 的文件，它位于你的应用程序的顶级目录中。最简单的 pubspec 只列出了包名:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="nl">name:</span> <span class="n">my_app</span>
</code></pre></div><p>下面是一个 pubspec 的例子，它声明了两个包(<code>js</code> 和 <code>intl</code>)的依赖关系，这两个包都托管在 pub.dev 站点上:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="nl">name:</span> <span class="n">my_app</span>
<span class="nl">dependencies:</span>
  <span class="nl">js:</span> <span class="o">^</span><span class="m">0.6</span><span class="p">.</span><span class="m">0</span>
  <span class="nl">intl:</span> <span class="o">^</span><span class="m">0.15</span><span class="p">.</span><span class="m">8</span>
</code></pre></div><p>关于创建 pubspec 的详细信息，请参见 <a href="https://dart.dev/tools/pub/pubspec">pubspec 文档</a>和你要使用的包的文档。</p>
<h2 id="获取软件包">获取软件包</h2>
<p>一旦你有了 pubspec，你就可以从你的应用程序的顶级目录中运行 <code>pub get</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">cd</span> &lt;path-to-my_app&gt;
$ pub get
</code></pre></div><p>这个过程被称为获取依赖关系。</p>
<p><code>pub get</code> 命令可以确定您的应用程序依赖于哪些软件包，并将它们放在中央<a href="https://dart.dev/tools/pub/glossary#system-cache">系统缓存</a>中。如果您的应用程序依赖于已发布的包，pub 会从 <a href="https://pub.dev/">pub.dev</a> 站点下载该包。对于  <a href="https://dart.dev/tools/pub/dependencies#git-packages">Git 依赖</a>，pub 会克隆 Git 仓库。还包括了过渡性依赖。例如，如果 <code>js</code> 包依赖于 <code>test</code> 包，<code>pub</code> 会同时抓取 <code>js</code> 包和 <code>test</code> 包。</p>
<p>Pub 会创建一个 <code>.packages</code> 文件(在你的应用程序的顶层目录下)，将你的应用程序所依赖的每个包名映射到系统缓存中的对应包。</p>
<h2 id="从包中导入库">从包中导入库</h2>
<p>要导入在包中找到的库，使用 <code>package:</code> 前缀:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:js/js.dart&#39;</span> <span class="k">as</span> <span class="n">js</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;package:intl/intl.dart&#39;</span><span class="p">;</span>
</code></pre></div><p>Dart 运行时在 <code>package:</code> 之后的所有内容都会在应用程序的 <code>.package</code> 文件中进行查找。</p>
<p>你也可以使用这种风格从你自己的包中导入库。比方说，<code>transmogrify</code> 包的布局如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">transmogrify/
  lib/
    transmogrify.dart
    parser.dart
  test/
    parser/
      parser_test.dart
</code></pre></div><p><code>parser_test.dart</code> 文件可以这样导入 <code>parser.dart</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:transmogrify/parser.dart&#39;</span><span class="p">;</span>
</code></pre></div><h2 id="升级依赖关系">升级依赖关系</h2>
<p>当你第一次为你的软件包获取一个新的依赖关系时，pub 会下载与你的其他依赖关系兼容的最新版本。然后，它通过创建一个 <strong>lockfile</strong> 锁文件来锁定您的软件包，使其始终使用该版本。这是一个名为 <code>pubspec.lock</code> 的文件，由 pub 创建并存储在 pubspec 的旁边。它列出了您的软件包所使用的每个依赖关系的特定版本 (即时的和过渡的)。</p>
<p>如果你的包是一个应用程序包，你应该把这个文件检查到<a href="https://dart.dev/guides/libraries/private-files">源代码控制</a>中。这样，在你的应用程序上工作的每个人都会使用所有包的相同版本。在 lockfile 文件中检查也可以确保你部署的应用使用相同版本的代码。</p>
<p>当你准备好将你的依赖项升级到最新版本时，使用 <a href="https://dart.dev/tools/pub/cmd/pub-upgrade">pub upgrade</a> 命令:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">$</span> <span class="n">pub</span> <span class="n">upgrade</span>
</code></pre></div><p><code>pub upgrade</code> 命令告诉 pub 使用你的包的依赖关系的最新版本来重新生成 lockfile 文件。如果你只想升级一个依赖关系，你可以指定要升级的软件包:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">$</span> <span class="n">pub</span> <span class="n">upgrade</span> <span class="n">transmogrify</span>
</code></pre></div><p>该命令将 <code>transmogrify</code> 升级到最新版本，但其他一切都保持不变。</p>
<p>由于 pubspec 中有冲突的版本限制，<a href="https://dart.dev/tools/pub/cmd/pub-upgrade">pub upgrade</a> 命令并不能总是将每个软件包升级到最新版本。要识别需要编辑 pubspec 的过期软件包，请使用 <a href="https://dart.dev/tools/pub/cmd/pub-outdated">pub outdated</a>。</p>
<h2 id="更多信息">更多信息</h2>
<p>下面的页面有更多关于软件包和 pub 包管理器的信息。</p>
<p>如何使用</p>
<ul>
<li><a href="https://dart.dev/guides/libraries/create-library-packages">创建包</a></li>
<li><a href="https://dart.dev/tools/pub/publishing">发布包</a></li>
</ul>
<p>参考</p>
<ul>
<li><a href="https://dart.dev/tools/pub/dependencies">Pub 依赖</a></li>
<li><a href="https://dart.dev/tools/pub/environment-variables">Pub 环境变量</a></li>
<li><a href="https://dart.dev/tools/pub/glossary">Pub 词汇表</a></li>
<li><a href="https://dart.dev/tools/pub/package-layout">Pub 包布局约定</a></li>
<li><a href="https://dart.dev/tools/pub/versioning">Pub 版本哲学</a></li>
<li><a href="https://dart.dev/tools/pub/pubspec">Pubspec 格式化</a></li>
</ul>
<p>Pub 命令</p>
<p><code>pub</code> 工具提供了以下命令:</p>
<ul>
<li><a href="https://dart.dev/tools/pub/cmd/pub-cache">pub cache</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-deps">pub deps</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-downgrade">pub downgrade</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-get">pub get</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-global">pub global</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-outdated">pub outdated</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-lish">pub publish</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-run">pub run</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-upgrade">pub upgrade</a></li>
<li><a href="https://dart.dev/tools/pub/cmd/pub-uploader">pub uploader</a></li>
</ul>
<p>有关所有 pub 命令的概述，请参阅 <a href="https://dart.dev/tools/pub/cmd">pub 工具文档</a>。</p>
<p>疑难解答</p>
<p><a href="https://dart.dev/tools/pub/troubleshoot">故障排除 pub</a> 提供了使用 pub 时可能遇到的问题的解决方案。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/packages" term="packages" label="packages" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[常用的包]]></title>
            <link href="https://ohmyweekly.github.io/notes/commonly-used-packages/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/how-to-use-packages/?utm_source=atom_feed" rel="related" type="text/html" title="如何使用包" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app-part-two/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第二部分" />
            
                <id>https://ohmyweekly.github.io/notes/commonly-used-packages/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-29T00:00:00+08:00</published>
            <updated>2020-06-29T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Commonly used packages</blockquote><p>本页列出了一些  Dart 开发者发布的最流行和最有用的<a href="https://dart.dev/guides/packages">包</a>。要找到更多的软件包&ndash;也可以搜索<a href="https://dart.dev/guides/libraries">核心库</a>&ndash;请使用 <a href="https://pub.dev/">pub.dev</a> 网站。</p>
<p>常用的软件包可分为三类:</p>
<ul>
<li><a href="https://dart.dev/guides/libraries/useful-libraries#general-purpose-packages">通用包</a></li>
<li><a href="https://dart.dev/guides/libraries/useful-libraries#packages-that-correspond-to-sdk-libraries">扩展 Dart 核心库的包</a></li>
<li><a href="https://dart.dev/guides/libraries/useful-libraries#specialized-packages">特定的包</a></li>
</ul>
<h2 id="通用包">通用包</h2>
<p>以下包对各种项目都很有用:</p>
<table>
<thead>
<tr>
<th style="text-align:left">包</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">常用的 API</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/archive">archive</a></td>
<td style="text-align:left">对各种档案和压缩格式进行编码和解码。</td>
<td style="text-align:left">Archive, ArchiveFile, TarEncoder, TarDecoder, ZipEncoder, ZipDecoder</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/characters">characters</a></td>
<td style="text-align:left">对用户感知的字符进行字符串操作(Unicode 字符簇)</td>
<td style="text-align:left">String.characters, Characters, CharacterRange</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/http">http</a></td>
<td style="text-align:left">一组高级的函数和类，使其易于消费 HTTP 资源</td>
<td style="text-align:left">delete(), get(), post(), read()</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/intl">intl</a></td>
<td style="text-align:left">国际化和本地化设施，支持复数和性别、日期和数字格式化和解析以及双向文本</td>
<td style="text-align:left">Bidi, DateFormat, MicroMoney, TextDirection</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/json_serializable">json_serializable</a></td>
<td style="text-align:left">一个易于使用的代码生成包。更多信息，请参阅 <a href="https://dart.dev/guides/json">JSON 支持</a></td>
<td style="text-align:left">@JsonSerializable</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/logging">logging</a></td>
<td style="text-align:left">一个可配置的机制，为你的应用程序添加消息记录</td>
<td style="text-align:left">LoggerHandler, Level, LogRecord</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/mockito">mockito</a></td>
<td style="text-align:left">一个在测试中模拟对象的流行框架。如果你正在编写依赖注入的测试，特别有用。与 <a href="https://pub.dev/packages/test">test</a> 包一起使用</td>
<td style="text-align:left">Answering, Expectation, Verification</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/path">path</a></td>
<td style="text-align:left">操作不同类型路径的常用操作。更多信息，请参见<a href="https://news.dartlang.org/2016/06/unboxing-packages-path.html">拆包: path</a></td>
<td style="text-align:left">absolute(), basename(), extension(), join(), normalize(), relative(), split()</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/quiver">quiver</a></td>
<td style="text-align:left">实用工具，使 Dart 核心库的使用更加方便。Quiver 提供额外支持的一些库包括 async、cache、collection、core、iterables、pattern 和 测试</td>
<td style="text-align:left">CountdownTimer (quiver.async); MapCache (quiver.cache); MultiMap, TreeSet (quiver.collection); EnumerateIterable (quiver.iterables); center(), compareIgnoreCase(), isWhiteSpace() (quiver.strings)</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/shelf">shelf</a></td>
<td style="text-align:left">Dart 的 Web 服务器中间件。Shelf 使它能轻松地创建和组成 Web 服务器，以及 Web 服务器的一部分</td>
<td style="text-align:left">Cascade, Pipeline, Request, Response, Server</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/stack_trace">stack_trace</a></td>
<td style="text-align:left">用于解析、检查和处理由底层 Dart 实现产生的堆栈痕迹的方法。还提供了以比原生 StackTrace 实现更可读的格式生成堆栈跟踪的字符串表示的函数,  更多信息，请参见<a href="https://news.dartlang.org/2016/01/unboxing-packages-stacktrace.html">拆包: stack_trace</a></td>
<td style="text-align:left">Trace.current(), Trace.format(), Trace.from()</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/stagehand">stagehand</a></td>
<td style="text-align:left">一个 Dart 项目生成器。当你创建一个新的应用程序时，WebStorm 和 IntelliJ 使用 Stagehand 模板，但你也可以从命令行使用模板</td>
<td style="text-align:left">一般通过 IDE 或 <code>stagehand</code> 命令来使用</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/test">test</a></td>
<td style="text-align:left">在 Dart 中编写和运行测试的标准方法</td>
<td style="text-align:left">expect(), group(), test()</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/yaml">yaml</a></td>
<td style="text-align:left">YAML 解析器</td>
<td style="text-align:left">loadYaml(), loadYamlStream()</td>
</tr>
</tbody>
</table>
<h2 id="扩展-dart-核心库的包">扩展 Dart 核心库的包</h2>
<p>以下每个包都建立在一个<a href="https://dart.dev/guides/libraries">核心库</a>的基础上，增加了功能并填补了缺失的功能:</p>
<table>
<thead>
<tr>
<th style="text-align:left">包</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">常用的 API</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/async">async</a></td>
<td style="text-align:left">在 dart:async 的基础上进行了扩展，增加了实用类来处理异步计算。更多信息，请参见<a href="https://news.dartlang.org/2016/03/unboxing-packages-async-part-1.html">拆包: async 第1部分</a>、<a href="https://news.dartlang.org/2016/03/unboxing-packages-async-part-2.html">第2部分</a>和<a href="https://news.dartlang.org/2016/04/unboxing-packages-async-part-3.html">第3部分</a></td>
<td style="text-align:left">AsyncMemoizer, CancelableOperation, FutureGroup, LazyStream, Result, StreamCompleter, StreamGroup, StreamSplitter</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/collection">collection</a></td>
<td style="text-align:left">在 dart:collection 的基础上进行了扩展，增加了实用函数和类，使处理集合的工作变得更加容易。更多信息，请看<a href="https://news.dartlang.org/2016/01/unboxing-packages-collection.html">拆包：collection</a></td>
<td style="text-align:left">Equality, CanonicalizedMap, MapKeySet, MapValueSet, PriorityQueue, QueueList</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/convert">convert</a></td>
<td style="text-align:left">在 dart:convert 的基础上，增加了编码器和解码器，用于在不同的数据表现形式之间进行转换。其中一种数据表示方式是百分比编码，也被称为 URL 编码</td>
<td style="text-align:left">HexDecoder, PercentDecoder</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://pub.dev/packages/io">io</a></td>
<td style="text-align:left">包含两个库，ansi和io，以简化对文件、标准流和进程的处理。使用 ansi 库可以自定义终端输出。io 库有处理进程、stdin 和文件复制的 API</td>
<td style="text-align:left">copyPath(), isExecutable(), ExitCode, ProcessManager, sharedStdIn</td>
</tr>
</tbody>
</table>
<h2 id="专用包">专用包</h2>
<p>下面是一些寻找比较专业的包的技巧，比如手机的包(Flutter)和网页开发的包。</p>
<h3 id="flutter-包">Flutter 包</h3>
<p>请看 Flutter 网站上的<a href="https://flutter.dev/docs/development/packages-and-plugins/using-packages">使用包</a>。或者使用 pub.dev 网站<a href="https://pub.dev/flutter">搜索 Flutter 包</a>。</p>
<h3 id="网络包">网络包</h3>
<p>参见<a href="https://dart.dev/web/libraries">网络库和包</a>。或者使用 pub.dev 站点<a href="https://pub.dev/web">搜索 web 包</a>。</p>
<h3 id="命令行和服务器软件包">命令行和服务器软件包</h3>
<p>参见<a href="https://dart.dev/server/libraries">命令行和服务器库和包</a>。或者使用 pub.dev 站点<a href="https://pub.dev/">搜索其他包</a>。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/packages" term="packages" label="packages" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[异步编程：futures、async、await。]]></title>
            <link href="https://ohmyweekly.github.io/notes/futures-async-await/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/dart/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 入门" />
                <link href="https://ohmyweekly.github.io/notes/dart-iterable-collections/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 可迭代集合" />
                <link href="https://ohmyweekly.github.io/notes/dart-cheatsheet-codelab/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 语言速查表" />
            
                <id>https://ohmyweekly.github.io/notes/futures-async-await/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-27T00:00:00+08:00</published>
            <updated>2020-06-27T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>这个 codelab 教你如何使用 <code>futures</code>、<code>async</code> 和 <code>await</code> 关键字编写异步代码。使用内嵌的 DartPad 编辑器，你可以通过运行示例代码和完成练习来测试你的知识。</blockquote><p><a href="https://dart.dev/codelabs/async-await">async-await</a></p>
<p>这个 codelab 教你如何使用 <code>futures</code>、<code>async</code> 和 <code>await</code> 关键字编写异步代码。使用内嵌的 DartPad 编辑器，你可以通过运行示例代码和完成练习来测试你的知识。</p>
<p>要想从这个 codelab 中获得最大的收获，你应该具备以下条件。</p>
<ul>
<li>掌握<a href="https://dart.dev/samples">基本的 Dart 语法</a></li>
<li>有用其他语言编写异步代码的经验。</li>
</ul>
<p>这个 codelab 包括以下材料。</p>
<ul>
<li>如何以及何时使用 <code>async</code> 和 <code>await</code> 关键字。</li>
<li>使用 <code>async</code> 和 <code>await</code> 如何影响执行顺序。</li>
<li>如何在 <code>async</code> 函数中使用 <code>try-catch</code> 表达式处理异步调用中的错误。</li>
</ul>
<p>估计完成这个代码实验的时间。40-60分钟</p>
<p>注意：本页面使用嵌入式 DartPads 来显示示例和练习。如果你看到的是空框而不是 DartPads，请转到 <a href="https://dart.dev/tools/dartpad/troubleshoot">DartPad 故障排除页面</a>。</p>
<h2 id="为什么异步代码很重要">为什么异步代码很重要</h2>
<p>异步操作让你的程序在等待另一个操作完成时完成工作。下面是一些常见的异步操作。</p>
<ul>
<li>通过网络获取数据。</li>
<li>写入数据库。</li>
<li>从文件中读取数据。</li>
</ul>
<p>要在 Dart 中执行异步操作，你可以使用 <code>Future</code> 类以及 <code>async</code> 和 <code>await</code> 关键字。</p>
<h3 id="例子-错误地使用异步函数">例子: 错误地使用异步函数</h3>
<p>下面的例子显示了使用异步函数(<code>fetchUserOrder()</code>)的错误方法。稍后你将使用 <code>async</code> 和 <code>await</code> 来修复这个例子。在运行这个例子之前，试着发现这个问题-你认为输出会是什么？</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="c1">// This example shows how *not* to write asynchronous Dart code.
</span><span class="c1"></span>
<span class="kt">String</span> <span class="n">createOrderMessage</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="k">return</span> <span class="s1">&#39;Your order is: </span><span class="si">$</span><span class="n">order</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="o">=&gt;</span>
    <span class="c1">// Imagine that this function is more complex and slow.
</span><span class="c1"></span>    <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span>
      <span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">2</span><span class="p">),</span>
      <span class="p">()</span> <span class="o">=&gt;</span> <span class="s1">&#39;Large Latte&#39;</span><span class="p">,</span>
    <span class="p">);</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="n">createOrderMessage</span><span class="p">());</span>
<span class="p">}</span>
</code></pre></div><p>下面是这个例子为什么不能打印 <code>fetchUserOrder()</code> 最终产生的值。</p>
<ul>
<li><code>fetchUserOrder()</code> 是一个异步函数，在延迟之后，提供一个描述用户订单的字符串：&ldquo;Large Latte&rdquo;。</li>
<li>为了得到用户的订单，<code>createOrderMessage()</code> 应该调用 <code>fetchUserOrder()</code>，并等待其完成。由于 <code>createOrderMessage()</code> 没有等待 <code>fetchUserOrder()</code> 完成，<code>createOrderMessage()</code> 无法获得 <code>fetchUserOrder()</code> 最终提供的字符串值。</li>
<li>取而代之的是，<code>createOrderMessage()</code> 得到的是待完成工作的表示：一个未完成的未来。您将在下一节了解更多关于未来的信息。</li>
<li>因为 <code>createOrderMessage()</code> 没有得到描述用户订单的值，所以这个例子没有打印 &ldquo;Large Latte&rdquo; 到控制台，而是打印 &ldquo;Your order is: Instance of &lsquo;_Future&rsquo;&quot;。</li>
</ul>
<p>在接下来的章节中，你将学习关于 futures 和关于使用 futures 的工作（使用 <code>async</code> 和 <code>await</code>），这样你就能编写必要的代码，使 <code>fetchUserOrder()</code> 向控制台打印所需的值(&ldquo;Large Latte&rdquo;)。</p>
<p>关键术语:</p>
<ul>
<li>同步操作: 同步操作会阻止其他操作的执行，直到它完成。</li>
<li>同步函数：同步函数只执行同步操作。</li>
<li>异步操作：异步操作一旦启动，就允许其他操作在它完成之前执行。</li>
<li>异步函数：异步函数至少执行一个异步操作，也可以执行同步操作。</li>
</ul>
<h2 id="什么是未来">什么是未来？</h2>
<p>future(小写 &ldquo;f&rdquo;)是 <a href="https://api.dart.dev/stable/dart-async/Future-class.html">Future</a>（大写 &ldquo;F&rdquo;）类的一个实例。一个 future 代表异步操作的结果，可以有两种状态：未完成或完成。</p>
<p>注意：未完成是一个 Dart 术语，指的是一个未来的状态，在它产生一个值之前。</p>
<h3 id="未完成的">未完成的</h3>
<p>当你调用一个异步函数时，它会返回一个未完成的未来。这个未来正在等待函数的异步操作完成或抛出一个错误。</p>
<h3 id="已完成的">已完成的</h3>
<p>如果异步操作成功，未来就以一个值完成。否则它将以一个错误完成。</p>
<h3 id="用一个值来完成">用一个值来完成</h3>
<p>类型为 <code>Future&lt;T&gt;</code> 的 future 用一个类型为 <code>T</code> 的值来完成。例如，一个类型为 <code>Future&lt;String&gt;</code> 的 future 会产生一个字符串值。如果一个 future 没有产生一个可用的值，那么 future 的类型是 <code>Future&lt;void&gt;</code>。</p>
<h3 id="用一个错误来完成">用一个错误来完成</h3>
<p>如果函数执行的异步操作因为任何原因而失败，future 就会以错误的方式完成。</p>
<h3 id="例子-介绍-future">例子: 介绍 future</h3>
<p>在下面的例子中，<code>fetchUserOrder()</code> 返回一个在打印到控制台后完成的 future。因为它没有返回一个可用的值，<code>fetchUserOrder()</code> 的类型是 <code>Future&lt;void&gt;</code>。在运行这个例子之前，试着预测一下哪个会先打印：&ldquo;Large Latte&rdquo; 或 &ldquo;Fetching user order&hellip;&quot;。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// Imagine that this function is fetching user info from another service or database.
</span><span class="c1"></span>  <span class="k">return</span> <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">2</span><span class="p">),</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Large Latte&#39;</span><span class="p">));</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Fetching user order...&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>在前面的例子中，尽管 <code>fetchUserOrder()</code> 在第8行的 <code>print()</code> 调用之前执行，控制台还是在 <code>fetchUserOrder()</code> 的输出 (&ldquo;Large Latte&rdquo;) 之前显示了第8行的输出 (&ldquo;Fetching user order&hellip;&quot;)。这是因为 <code>fetchUserOrder()</code> 在打印 &ldquo;Large Latte&rdquo; 之前会有延迟。</p>
<h3 id="例子-完成时出现错误">例子: 完成时出现错误</h3>
<p>运行下面的例子，看看未来如何完成一个错误。稍后你将学习如何处理错误。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="p">{</span>
<span class="c1">// Imagine that this function is fetching user info but encounters a bug
</span><span class="c1"></span>  <span class="k">return</span> <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">2</span><span class="p">),</span>
      <span class="p">()</span> <span class="o">=&gt;</span> <span class="k">throw</span> <span class="n">Exception</span><span class="p">(</span><span class="s1">&#39;Logout failed: user ID is invalid&#39;</span><span class="p">));</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Fetching user order...&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>在这个例子中，<code>fetchUserOrder()</code> 完成时出现错误，表明用户ID无效。</p>
<p>你已经学习了 future 和它们如何完成，但你如何使用异步函数的结果呢？在下一节中，你将学习如何使用 <code>async</code> 和 <code>await</code> 关键字来获取结果。</p>
<p>快速回顾:</p>
<ul>
<li>一个 <code>Future&lt;T&gt;</code> 实例会产生一个 <code>T</code> 类型的值。</li>
<li>如果一个 future 没有产生一个可用的值，那么 future 的类型是 <code>Future&lt;void&gt;</code>。</li>
<li>一个 future 可以处于两种状态之一：未完成或完成。</li>
<li>当你调用一个返回 future 的函数时，函数会把要做的工作排队，并返回一个未完成的 future。</li>
<li>当一个 future 的操作完成时，future 以一个值或以一个错误完成。</li>
</ul>
<p>关键术语:</p>
<ul>
<li>Future: Dart <a href="https://api.dart.dev/stable/dart-async/Future-class.html">Future</a> 类。</li>
<li>future：Dart <code>Future</code> 类的一个实例。</li>
</ul>
<h2 id="使用-futureasync-和-await">使用 future：async 和 await</h2>
<p><code>async</code> 和 <code>await</code> 关键字提供了一种声明式的方式来定义异步函数并使用它们的结果。在使用 <code>async</code> 和 <code>await</code> 时，请记住以下两个基本准则。</p>
<ul>
<li>要定义一个异步函数，请在函数主体前添加 <code>async</code>。</li>
<li><code>await</code> 关键字只能在 <code>async</code> 函数中使用。</li>
</ul>
<p>下面是一个将 <code>main()</code> 从同步函数转换为异步函数的例子。</p>
<p>首先，在函数体前添加 <code>async</code> 关键字:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span> <span class="err">···</span> <span class="p">}</span>
</code></pre></div><p>如果函数有声明的返回类型，那么更新类型为 <code>Future&lt;T&gt;</code>，其中 T 是函数返回的值的类型。如果函数没有明确返回值，那么返回类型为 <code>Future&lt;void&gt;</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span> <span class="err">···</span> <span class="p">}</span>
</code></pre></div><p>现在你已经有了一个 <code>async</code> 函数，你可以使用 <code>await</code> 关键字来等待一个 future 的完成:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">print</span><span class="p">(</span><span class="kd">await</span> <span class="n">createOrderMessage</span><span class="p">());</span>
</code></pre></div><p>正如下面两个例子所显示的，<code>async</code> 和a <code>wait</code> 关键字导致异步代码看起来很像同步代码。唯一的区别在异步示例中突出显示，如果你的窗口足够宽，它就在同步示例的右边。</p>
<p>示例：同步函数</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">createOrderMessage</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="k">return</span> <span class="s1">&#39;Your order is: </span><span class="si">$</span><span class="n">order</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="o">=&gt;</span>
    <span class="c1">// Imagine that this function is
</span><span class="c1"></span>    <span class="c1">// more complex and slow.
</span><span class="c1"></span>    <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span>
      <span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">2</span><span class="p">),</span>
      <span class="p">()</span> <span class="o">=&gt;</span> <span class="s1">&#39;Large Latte&#39;</span><span class="p">,</span>
    <span class="p">);</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Fetching user order...&#39;</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="n">createOrderMessage</span><span class="p">());</span>
<span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">Fetching user order...
Your order is: Instance of _Future&lt;String&gt;
</code></pre></div><p>例子：异步函数</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">createOrderMessage</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="k">return</span> <span class="s1">&#39;Your order is: </span><span class="si">$</span><span class="n">order</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="o">=&gt;</span>
    <span class="c1">// Imagine that this function is
</span><span class="c1"></span>    <span class="c1">// more complex and slow.
</span><span class="c1"></span>    <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span>
      <span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">2</span><span class="p">),</span>
      <span class="p">()</span> <span class="o">=&gt;</span> <span class="s1">&#39;Large Latte&#39;</span><span class="p">,</span>
    <span class="p">);</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Fetching user order...&#39;</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="kd">await</span> <span class="n">createOrderMessage</span><span class="p">());</span>
<span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">Fetching user order...
Your order is: Large Latte
</code></pre></div><p>异步示例在三个方面有所不同。</p>
<ul>
<li><code>createOrderMessage()</code> 的返回类型从 <code>String</code> 变为 <code>Future&lt;String&gt;</code>。</li>
<li><code>async</code> 关键字出现在 <code>createOrderMessage()</code> 和 <code>main()</code> 的函数体之前。</li>
<li><code>await</code> 关键字出现在调用异步函数 <code>fetchUserOrder()</code> 和 <code>createOrderMessage()</code> 之前。</li>
</ul>
<p>关键术语:</p>
<ul>
<li>async: 你可以在一个函数的主体前使用 <code>async</code> 关键字来标记它为异步函数。</li>
<li>async 函数: <code>async</code> 函数是一个标有 <code>async</code> 关键字的函数。</li>
<li>await：可以使用 <code>await</code> 关键字来获取异步表达式的完成结果。<code>await</code> 关键字只在 <code>async</code> 函数中起作用。</li>
</ul>
<h3 id="使用-async-和-await-的执行流程">使用 async 和 await 的执行流程</h3>
<p>一个异步函数在第一个 <code>await</code> 关键字之前是同步运行的。这意味着在一个 <code>async</code> 函数体中，第一个 <code>await</code> 关键字之前的所有同步代码都会立即执行。</p>
<p>版本说明：在 Dart 2.0 之前，一个异步函数立即返回，而不会在异步函数体中执行任何代码。</p>
<h3 id="例子在异步函数内执行在异步函数中执行">例子：在异步函数内执行。在异步函数中执行</h3>
<p>运行下面的例子，看看如何在异步函数体中执行。你认为输出会是什么？</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">printOrderMessage</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Awaiting user order...&#39;</span><span class="p">);</span>
  <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Your order is: </span><span class="si">$</span><span class="n">order</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// Imagine that this function is more complex and slow.
</span><span class="c1"></span>  <span class="k">return</span> <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">4</span><span class="p">),</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="s1">&#39;Large Latte&#39;</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="n">countSeconds</span><span class="p">(</span><span class="m">4</span><span class="p">);</span>
  <span class="kd">await</span> <span class="n">printOrderMessage</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// You can ignore this function - it&#39;s here to visualize delay time in this example.
</span><span class="c1"></span><span class="kt">void</span> <span class="n">countSeconds</span><span class="p">(</span><span class="kt">int</span> <span class="n">s</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">i</span> <span class="o">=</span> <span class="m">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">s</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="n">i</span><span class="p">),</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="n">print</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>运行上例中的代码后，尝试将第2行和第3行反过来。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
<span class="n">print</span><span class="p">(</span><span class="s1">&#39;Awaiting user order...&#39;</span><span class="p">);</span>
</code></pre></div><p>注意到输出的时间发生了变化，现在 <code>print('Awaiting user order')</code> 出现在 <code>printOrderMessage()</code> 中第一个 <code>await</code> 关键字之后。</p>
<h3 id="练习-练习使用-async-和-await">练习: 练习使用 async 和 await</h3>
<p>下面的练习是一个失败的单元测试，其中包含部分完成的代码片段。你的任务是通过编写代码使测试通过来完成练习。你不需要实现 <code>main()</code>。</p>
<p>为了模拟异步操作，调用以下函数，这些函数是为你提供的。</p>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">类型签名</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fetchRole()</td>
<td style="text-align:left">Future<!-- raw HTML omitted --> fetchRole()</td>
<td style="text-align:left">获取用户角色的简短描述。</td>
</tr>
<tr>
<td style="text-align:left">fetchLoginAmount()</td>
<td style="text-align:left">Future<!-- raw HTML omitted --> fetchLoginAmount()</td>
<td style="text-align:left">获取用户的登录次数。</td>
</tr>
</tbody>
</table>
<p>第1部分：<code>reportUserRole()</code></p>
<p>为 <code>reportUserRole()</code> 函数添加代码，使其执行以下操作。</p>
<ul>
<li>返回一个以下列字符串完成的 future： <code>&quot;User role: &lt;user role&gt;&quot;</code>。
<ul>
<li>注意：你必须使用 <code>fetchRole()</code> 返回的实际值；复制和粘贴示例返回值不会使测试通过。</li>
<li>示例返回值: &ldquo;User role: tester&rdquo;</li>
</ul>
</li>
<li>通过调用提供的函数 <code>fetchRole()</code> 获取用户角色。</li>
</ul>
<p>第二部分：<code>reportLogins()</code></p>
<p>实现一个异步函数 <code>reportLogins()</code>，使其执行以下操作。</p>
<ul>
<li>返回字符串 &ldquo;Total number of logins: &lt;# of logins&gt;&quot;。
<ul>
<li>注意：你必须使用 <code>fetchLoginAmount()</code> 返回的实际值；复制和粘贴示例返回值不会使测试通过。</li>
<li><code>reportLogins()</code> 的返回值示例: <code>&quot;Total number of logins: 57&quot;</code>。</li>
</ul>
</li>
<li>通过调用提供的函数 <code>fetchLoginAmount()</code> 来获取登录次数。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">reportUserRole</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">username</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchRole</span><span class="p">();</span>
  <span class="k">return</span> <span class="s1">&#39;User role: </span><span class="si">$</span><span class="n">username</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">reportLogins</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">logins</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchLoginAmount</span><span class="p">();</span>
  <span class="k">return</span> <span class="s1">&#39;Total number of logins: </span><span class="si">$</span><span class="n">logins</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><p>注意：如果你的代码通过了测试，你可以忽略信息级的消息。</p>
<h2 id="处理错误">处理错误</h2>
<p>要处理 <code>async</code> 函数中的错误，使用 <code>try-catch</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">try</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Awaiting user order...&#39;</span><span class="p">);</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Caught error: </span><span class="si">$</span><span class="n">err</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>在一个 <code>async</code> 函数中，你可以像在同步代码中一样编写 <code>try-catch</code> 子句。</p>
<h3 id="例子async-和-await-的-try-catch-子句">例子：<code>async</code> 和 <code>await</code> 的 <code>try-catch</code> 子句</h3>
<p>运行下面的例子，看看如何处理一个异步函数的错误。你认为输出会是什么？</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">printOrderMessage</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="n">order</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUserOrder</span><span class="p">();</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Awaiting user order...&#39;</span><span class="p">);</span>
    <span class="n">print</span><span class="p">(</span><span class="n">order</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Caught error: </span><span class="si">$</span><span class="n">err</span><span class="s1">&#39;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">fetchUserOrder</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// Imagine that this function is more complex.
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">str</span> <span class="o">=</span> <span class="n">Future</span><span class="p">.</span><span class="n">delayed</span><span class="p">(</span>
      <span class="n">Duration</span><span class="p">(</span><span class="nl">seconds:</span> <span class="m">4</span><span class="p">),</span>
      <span class="p">()</span> <span class="o">=&gt;</span> <span class="k">throw</span> <span class="s1">&#39;Cannot locate user order&#39;</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">str</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span> <span class="n">main</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">await</span> <span class="n">printOrderMessage</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><h3 id="练习-练习处理错误">练习: 练习处理错误</h3>
<p>下面的练习提供了使用异步代码处理错误的练习，使用上一节中描述的方法。为了模拟异步操作，你的代码将调用以下函数，该函数为你提供。</p>
<p>| 函数                | 类型签名 | 描述 |
| fetchNewUsername() | Future<!-- raw HTML omitted --> fetchNewUsername() |	返回你可以用来替换旧用户名的新用户名。|</p>
<p>使用 <code>async</code> 和 <code>await</code> 来实现一个异步的 <code>changeUsername()</code> 函数，该函数执行以下操作。</p>
<ul>
<li>调用提供的异步函数 <code>fetchNewUsername()</code> 并返回其结果。
<ul>
<li><code>changeUsername()</code> 的返回值示例: &ldquo;jane_smith_92&rdquo;</li>
</ul>
</li>
<li>捕获任何发生的错误并返回错误的字符串值。
<ul>
<li>你可以使用 <a href="https://api.dart.dev/stable/dart-core/ArgumentError/toString.html">toString()</a> 方法对 <a href="https://api.dart.dev/stable/dart-core/Exception-class.html">Exceptions</a> 和<a href="https://api.dart.dev/stable/dart-core/Error-class.html">Errors</a> 进行字符串化。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">changeUsername</span> <span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="k">return</span> <span class="kd">await</span> <span class="n">fetchNewUsername</span><span class="p">();</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">err</span><span class="p">.</span><span class="n">toString</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h3 id="练习-把所有的东西放在一起">练习: 把所有的东西放在一起</h3>
<p>现在是时候在最后一个练习中练习所学的知识了。为了模拟异步操作，本练习提供了异步函数 <code>fetchUsername()</code> 和 <code>logoutUser()</code>:</p>
<p>| 函数             | 类型签名                        | 描述 |
| fetchUsername() |	Future<!-- raw HTML omitted --> fetchUsername() | 返回与当前用户相关联的名称。 |
| logoutUser()	  | Future<!-- raw HTML omitted --> logoutUser()	   | 执行当前用户的注销，并返回被注销的用户名。 |</p>
<p>编写以下内容。</p>
<p>第一部分：<code>addHello()</code></p>
<ul>
<li>编写一个函数 <code>addHello()</code>，它接受一个单一的 <code>String</code> 参数。</li>
<li><code>addHello()</code> 返回它的 <code>String</code> 参数，前面加 &lsquo;Hello&rsquo;。
例如：<code>addHello('Jon')</code> 返回 &lsquo;Hello Jon&rsquo;。</li>
</ul>
<p>第二部分：<code>greetUser()</code></p>
<ul>
<li>编写一个不接受参数的函数 <code>greetUser()</code>。</li>
<li>为了得到用户名，<code>greetUser()</code> 调用提供的异步函数 <code>fetchUsername()</code>。</li>
<li><code>greetUser()</code> 通过调用 <code>addHello()</code> 为用户创建一个问候语，传递用户名，并返回结果。
例子: 如果 <code>fetchUsername()</code> 返回 &lsquo;Jenny&rsquo;, 那么 <code>greetUser()</code> 返回 &lsquo;Hello Jenny&rsquo;.</li>
</ul>
<p>第三部分：<code>sayGoodbye()</code></p>
<ul>
<li>
<p>编写一个函数 <code>sayGoodbye()</code>，它的功能如下。</p>
<ul>
<li>不接受任何参数</li>
<li>捕获任何错误。</li>
<li>调用所提供的异步函数 logoutUser().</li>
</ul>
</li>
<li>
<p>如果 <code>logoutUser()</code> 失败，<code>sayGoodbye()</code> 返回任何你喜欢的字符串。</p>
</li>
<li>
<p>如果 <code>logoutUser()</code> 成功，<code>sayGoodbye()</code> 返回字符串 <code>'&lt;result&gt; Thanks, see you next time'</code>，其中 <code>&lt;result&gt;</code> 是调用 <code>logoutUser()</code> 返回的字符串值。</p>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">addHello</span><span class="p">(</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="s1">&#39;Hello </span><span class="si">$</span><span class="n">user</span><span class="s1">&#39;</span><span class="p">;</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">greetUser</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">username</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">fetchUsername</span><span class="p">();</span>
  <span class="k">return</span> <span class="n">addHello</span><span class="p">(</span><span class="n">username</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">Future</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">sayGoodbye</span><span class="p">()</span> <span class="kd">async</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="n">result</span> <span class="o">=</span> <span class="kd">await</span> <span class="n">logoutUser</span><span class="p">();</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">$</span><span class="n">result</span><span class="s1"> Thanks, see you next time&#39;</span><span class="p">;</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s1">&#39;Failed to logout user: </span><span class="si">$</span><span class="n">e</span><span class="s1">&#39;</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="下一步是什么">下一步是什么？</h2>
<p>恭喜你，你已经完成了 codelab 的学习！如果你还想了解更多，这里有一些下一步的建议。</p>
<ul>
<li>玩玩 <a href="https://dartpad.dev/">DartPad</a>。</li>
<li>尝试另一个 <a href="https://dart.dev/codelabs">codelab</a>。</li>
<li>学习更多关于 futures 和异步的知识。
<ul>
<li><a href="https://dart.dev/tutorials/language/streams">Streams tutorial</a>: 学习如何使用异步事件的序列。</li>
<li><a href="https://www.youtube.com/playlist?list=PLjxrf2q8roU0Net_g1NT5_vOO3s_FR02J">来自 Google 的 Dart视频</a>: 观看一个或多个关于异步编码的视频。或者，如果你喜欢，阅读基于这些视频的文章。(从<a href="https://medium.com/dartlang/dart-asynchronous-programming-isolates-and-event-loops-bffc3e296a6a">隔离和事件循环</a>开始。)</li>
</ul>
</li>
<li><a href="https://dart.dev/get-dart">获取 Dart SDK</a>。</li>
</ul>
<p>如果你对使用嵌入式 DartPads 感兴趣，就像这个 codelab 一样，请看<a href="https://dart.dev/resources/dartpad-best-practices">教程中使用 DartPad 的最佳实践</a>。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/async" term="async" label="async" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/futures" term="futures" label="futures" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/await" term="await" label="await" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dart" term="dart" label="dart" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[编写你的第一个 Flutter 应用，第一部分]]></title>
            <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app-part-two/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第二部分" />
            
                <id>https://ohmyweekly.github.io/notes/write-your-first-flutter-app/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-26T00:00:00+08:00</published>
            <updated>2020-06-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flutter 是 Google 的 UI 工具包，用于从单一代码库中为手机、网页和桌面构建漂亮的、原生编译的应用程序。Flutter 可以与现有的代码一起使用，被世界各地的开发者和组织使用，并且是免费和开源的。</blockquote><h2 id="介绍">介绍</h2>
<p>Flutter 是 Google 的 UI 工具包，用于从单一代码库中为手机、网页和桌面构建漂亮的、原生编译的应用程序。Flutter 可以与现有的代码一起工作，被世界各地的开发者和组织使用，并且是免费和开源的。</p>
<p>在这个代码实验室中，你将创建一个简单的手机 Flutter 应用。如果你熟悉面向对象的代码和基本的编程概念-如变量、循环和条件, 那么你就可以完成这个 codelab。你不需要以前有 Dart、手机或 Web 编程的经验。</p>
<h3 id="你将在第1部分学到什么">你将在第1部分学到什么</h3>
<ul>
<li>如何编写一款在 iOS、Android 和 Web 上看起来很自然的 Flutter 应用？</li>
<li>Flutter 应用程序的基本结构。</li>
<li>寻找和使用包来扩展功能。</li>
<li>使用热重装来加快开发周期。</li>
<li>如何实现一个有状态的小组件。</li>
<li>如何创建一个无限的、懒加载的列表。</li>
</ul>
<p>在这个 codelab 的<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/index.html?index=..%2F..%2Findex#0">第2部分</a>中，你将添加交互性，修改应用程序的主题，并添加导航到新页面的能力(在 Flutter 中称为路由)。</p>
<h3 id="你将在第1部分中构建什么">你将在第1部分中构建什么</h3>
<p>你将实现一个移动应用，为一家创业公司生成建议的名字。用户可以选择和取消选择名字，保存最好的名字。代码一次懒惰地生成10个名字。随着用户的滚动，会生成更多的名字。用户可以滚动的范围没有限制。</p>
<p>下面的 GIF 动画显示了应用程序在完成部分时的工作情况。</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/6556f8b61acd6a89.gif" alt="img"></p>
<h2 id="设置你的-flutter-环境">设置你的 Flutter 环境</h2>
<p>你需要两个软件来完成这个实验室-<a href="https://flutter.io/get-started/install/">Flutter SDK</a>和<a href="https://flutter.io/get-started/editor/">一个编辑器</a>。(codelab 假设你使用 Android Studio，但你可以使用你的首选编辑器。)</p>
<p>你可以通过使用以下任何设备来运行 codelab。</p>
<ul>
<li>一个物理的 <a href="https://flutter.io/setup-macos/#set-up-your-android-device">Android</a> 或 <a href="https://flutter.io/setup-macos/#deploy-to-ios-devices">iOS</a> 设备连接到你的计算机并设置为开发者模式。</li>
<li><a href="https://flutter.io/setup-macos/#set-up-the-ios-simulator">iOS 模拟器</a>(需要安装 Xcode 工具)</li>
<li><a href="https://flutter.io/setup-macos/#set-up-the-android-emulator">安卓模拟器</a>(需要在 Android Studio 中进行设置)</li>
<li>浏览器(调试时需要使用 Chrome 浏览器)</li>
</ul>
<p>如果你想编译你的应用程序以在 web 上运行，你必须启用此功能（目前处于测试阶段）。要启用 web 支持，请使用以下说明。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">flutter channel beta
flutter upgrade
flutter config --enable-web
</code></pre></div><p>你只需要运行一次 <code>config</code> 命令。启用 Web 支持后，你创建的每个 Flutter 应用也会为 Web 编译。在你的 IDE 的<strong>设备</strong>下拉菜单下面，或者在命令行使用 <code>flutter devices</code>，你现在应该看到 Chrome 和 Web 服务器被列出。<strong>Chrome</strong> 设备会自动启动 Chrome。Web 服务器会启动一个托管应用程序的服务器，这样你就可以从任何浏览器加载它。在开发过程中使用 <strong>Chrome</strong> 设备，以便你可以使用 DevTools，而当你要在其他浏览器上进行测试时使用 Web 服务器。有关更多信息，请参阅<a href="https://flutter.dev/docs/get-started/web">使用 Flutter 构建 Web 应用程序</a>和<a href="https://flutter.dev/docs/get-started/codelab-web">在 Web 上编写你的第一个 Flutter 应用程序</a>。</p>
<h2 id="创建-flutter-应用程序的启动器">创建 Flutter 应用程序的启动器</h2>
<p>通过使用<a href="https://flutter.dev/docs/get-started/test-drive#androidstudio">创建应用程序</a>中的说明来创建一个简单的、模板化的 Flutter 应用程序。输入 <code>startup_namer</code>(而不是 <code>flutter_app</code>)作为项目名称。您将修改启动器应用程序来创建完成的应用程序。</p>
<p>提示：如果你在 IDE 中没有看到能够启动一个新的 Flutter 项目作为一个选项，那么请确保你已经<a href="https://flutter.io/get-started/editor/#androidstudio">安装了 Flutter 和 Dart 的插件</a>。</p>
<p>你将主要编辑 <code>lib/main.dart</code>，Dart 的代码就在这里。</p>
<p>替换 <code>lib/main.dart</code> 的内容。
删除 <code>lib/main.dart</code> 中的所有代码，并用下面的代码替换，在屏幕中央显示 &ldquo;Hello World&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:flutter/material.dart&#39;</span><span class="p">;</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="o">=&gt;</span> <span class="n">runApp</span><span class="p">(</span><span class="n">MyApp</span><span class="p">());</span>

<span class="kd">class</span> <span class="nc">MyApp</span> <span class="kd">extends</span> <span class="n">StatelessWidget</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MaterialApp</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">,</span>
      <span class="nl">home:</span> <span class="n">Scaffold</span><span class="p">(</span>
        <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
          <span class="nl">title:</span> <span class="kd">const</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">),</span>
        <span class="p">),</span>
        <span class="nl">body:</span> <span class="kd">const</span> <span class="n">Center</span><span class="p">(</span>
          <span class="nl">child:</span> <span class="kd">const</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Hello World&#39;</span><span class="p">),</span>
        <span class="p">),</span>
      <span class="p">),</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>提示：当把代码粘贴到你的应用程序中时，缩进会变得歪斜。你可以用以下 Flutter 工具来解决。</p>
<ul>
<li>Android Studio/IntelliJ IDEA: 右键点击 Dart 代码，选择<strong>用 dartfmt 重格式代码</strong>。</li>
<li>VS code: 右键点击并选择<strong>格式化文档</strong>。</li>
<li>终端: 运行 <code>flutter format &lt;文件名&gt;</code>。</li>
</ul>
<p><a href="https://flutter.io/get-started/test-drive/#androidstudio">运行应用程序</a>。您应该看到 Android，iOS 或 Web 输出，取决于您的设备。</p>
<p>安卓系统:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/f9df7832965ede9f.png" alt="img"></p>
<p>iOS:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/20374605026d582.png" alt="img"></p>
<p>小贴士：第一次在物理设备上运行时，可能需要一段时间来加载。之后，你可以使用热重载来快速更新。在支持的 IDE 中，如果应用正在运行，<strong>Save</strong> 也会执行热重载。当使用 <code>flutter run</code> 直接从控制台运行应用程序时，输入 <code>r</code> 来执行热重载。</p>
<p>观察:</p>
<ul>
<li>这个例子创建了一个 Material 应用。<a href="https://material.io/guidelines/">Material</a> 是一种视觉设计语言，是移动和 Web 的标准。Flutter 提供了一套丰富的 Material 部件。</li>
<li><code>main</code> 方法使用箭头(<code>=&gt;</code>)符号。对单行函数或方法使用箭头符号。</li>
<li>应用程序扩展了 <code>StatelessWidget</code>，这使得应用程序本身成为一个组件。在 Flutter 中，几乎所有的东西都是组件，包括对齐、填充和布局。</li>
<li><code>Scaffold</code> 组件来自 Material 库，它提供了一个默认的应用栏、一个标题和一个 body 属性，其中存放着主屏幕的组件树。组件子树可以相当复杂。</li>
<li>组件的主要工作是提供一个 <code>build</code> 方法，描述如何用其他低级组件来显示该组件。</li>
<li>本例的主体由包含 <code>Text</code> 子部件的 <code>Center</code> 部件组成。<code>Center</code> 组件将其组件子树对齐到屏幕的中心。</li>
</ul>
<h2 id="使用外部软件包">使用外部软件包</h2>
<p>在这一步中，您将开始使用一个名为 <code>english_words</code> 的开源包，它包含了几千个最常用的英语单词，还有一些实用函数。</p>
<p>你可以在 <a href="https://pub.dev/">pub.dev</a> 找到 <code>english_words</code> 包，以及许多其他开源包。</p>
<p>pubspec 文件管理着 Flutter 应用的资产。在 <code>pubspec.yaml</code> 中，附加 <code>english_words: ^3.1.5</code>(<code>english_words</code> 3.1.5 或更高)到依赖列表中。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">dependencies</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">flutter</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">sdk</span><span class="p">:</span><span class="w"> </span><span class="l">flutter</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">cupertino_icons</span><span class="p">:</span><span class="w"> </span><span class="l">^0.1.2</span><span class="w">
</span><span class="w">  </span><span class="nt">english_words</span><span class="p">:</span><span class="w"> </span><span class="l">^3.1.5  </span><span class="w"> </span><span class="c"># add this line</span><span class="w">
</span></code></pre></div><p>在 Android Studio 的编辑器视图中查看 pubspec 时，点击 <strong>Packages get</strong>。这将把包拉到你的项目中。你应该在控制台中看到以下内容。</p>
<div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">flutter packages get
Running &#34;flutter packages get&#34; in startup_namer...
Process finished with exit code 0
</code></pre></div><p>执行 <code>Pub get</code> 也会自动生成 &ldquo;pubspec.lock&rdquo; 文件，其中包含所有拉入项目的包的列表和它们的版本号。</p>
<p>在 <code>lib/main.dart</code> 中，导入新包:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:flutter/material.dart&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;package:english_words/english_words.dart&#39;</span><span class="p">;</span>  <span class="c1">// Add this line.
</span></code></pre></div><p>当你输入时，Android Studio 会给你建议导入的库。然后，它将导入的字符串渲染成灰色，让你知道导入的库是未使用的（到目前为止）。</p>
<p>接下来，你将使用 <code>english_words</code> 包来生成文本，而不是使用 &ldquo;Hello World&rdquo;。</p>
<p>做以下修改。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">import</span> <span class="s1">&#39;package:flutter/material.dart&#39;</span><span class="p">;</span>
<span class="k">import</span> <span class="s1">&#39;package:english_words/english_words.dart&#39;</span><span class="p">;</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="o">=&gt;</span> <span class="n">runApp</span><span class="p">(</span><span class="n">MyApp</span><span class="p">());</span>

<span class="kd">class</span> <span class="nc">MyApp</span> <span class="kd">extends</span> <span class="n">StatelessWidget</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">final</span> <span class="n">wordPair</span> <span class="o">=</span> <span class="n">WordPair</span><span class="p">.</span><span class="n">random</span><span class="p">();</span> <span class="c1">// Add this line.
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">MaterialApp</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">,</span>
      <span class="nl">home:</span> <span class="n">Scaffold</span><span class="p">(</span>
        <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
          <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">),</span>
        <span class="p">),</span>
        <span class="nl">body:</span> <span class="n">Center</span><span class="p">(</span>
          <span class="c1">//child: Text(&#39;Hello World&#39;),   // Replace this text...
</span><span class="c1"></span>          <span class="nl">child:</span> <span class="n">Text</span><span class="p">(</span><span class="n">wordPair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">),</span>  <span class="c1">// With this text.
</span><span class="c1"></span>        <span class="p">),</span>
      <span class="p">),</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>提示: Pascal 大小写(也称为上驼形大小写)意味着字符串中的每个单词，包括第一个单词，都以大写字母开头。所以，<code>uppercamelcase</code> 就变成了 <code>UpperCamelCase</code>。</p>
<p>如果应用程序正在运行，热重载来更新正在运行的应用程序。(在命令行中，你可以输入 <code>r</code> 来热重载。)每次点击热重载或保存项目时，你应该会在运行中的应用程序中看到一个不同的单词对，随机选择。这是因为单词对是在 <code>build</code> 方法里面生成的，每次 <code>MaterialApp</code> 需要渲染时，或者在 Flutter Inspector 中切换 <strong>Platform</strong> 时，都会运行该方法。</p>
<p>Android:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/57cfbac8f2b50e5b.png" alt="img"></p>
<p>iOS:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/30ed7f83a1500fa9.png" alt="img"></p>
<h3 id="有问题">有问题？</h3>
<p>如果您的应用程序没有正确运行，请查找错别字。如果需要，请使用以下链接中的代码来恢复正常。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/b3293b5bb0c0187bdbe8112f7759f4d75f4c040a/startup_namer/step2_use_package/pubspec.yaml">pubspec.yaml</a></li>
<li><a href="https://github.com/flutter/codelabs/blob/b3293b5bb0c0187bdbe8112f7759f4d75f4c040a/startup_namer/step2_use_package/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="添加一个有状态的组件">添加一个有状态的组件</h2>
<p>无状态组件是不可改变的，这意味着它们的属性不能改变-所有值都是最终值。</p>
<p>有状态组件维护的状态可能在组件的生命周期内发生变化。实现一个有状态的组件至少需要两个类。1) 一个 <a href="https://docs.flutter.io/flutter/widgets/StatefulWidget-class.html">StatefulWidget</a>，它可以创建一个 <a href="https://docs.flutter.io/flutter/widgets/State-class.html">State</a> 类的实例。<code>StatefulWidget</code> 对象本身是不可变的，可以被丢弃和再生，但 <code>State</code> 对象会在 widget 的生命周期内持久存在。</p>
<p>在这一步骤中，您将添加一个有状态的组件 <code>RandomWords</code>，并创建其 <code>State</code> 类 <code>_RandomWordsState</code>。然后，您将在现有的 MyApp 无状态组件中使用 <code>RandomWords</code> 作为子类。</p>
<p>为有状态组件创建模板代码。</p>
<p>它可以放在 <code>MyApp</code> 以外的文件中的任何位置，但解决方案将其放在文件的底部。在 <code>lib/main.dart</code> 中，将光标定位在所有代码之后，输入回车键几次，重新开始一行。在你的 IDE 中，开始输入 <code>stful</code>。编辑器会询问你是否要创建一个 <code>Stateful</code> 的组件。按回车键接受。两个类的模板代码出现了，光标定位让你输入无状态组件的名称。</p>
<p>输入 <code>RandomWords</code> 作为您的小组件的名称。</p>
<p>正如您在下面的代码中所看到的，<code>RandomWords</code> 组件除了创建它的 <code>State</code> 类之外，几乎没有其他的功能。</p>
<p>一旦您输入 <code>RandomWords</code> 作为有状态组件的名称，IDE 会自动更新相应的 <code>State</code> 类，将其命名为 <code>_RandomWordState</code>。默认情况下，<code>State</code> 类的名称是以下划线为前缀的。在标识符前加上下划线可以加强 Dart 语言的<a href="https://dart.dev/guides/language/language-tour#libraries-and-visibility">隐私性</a>，也是 <code>State</code> 对象的最佳实践。</p>
<p>IDE 也会自动更新 State 类以扩展 <code>State&lt;RandomWords&gt;</code>，表明你正在使用一个专门用于 <code>RandomWords</code> 的通用 <a href="https://api.flutter.dev/flutter/widgets/State-class.html">State</a> 类。应用程序的大部分逻辑都在这里-它为 <code>RandomWords</code> 组件维护状态。这个类保存了生成的词对列表，随着用户的滚动而无限增长，在本实验室的第二部分中，当用户通过切换心形图标从列表中添加或删除这些词对时，该类会对其进行收藏。</p>
<p>现在两个类的外观如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">RandomWords</span> <span class="kd">extends</span> <span class="n">StatefulWidget</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">_RandomWordsState</span> <span class="n">createState</span><span class="p">()</span> <span class="o">=&gt;</span> <span class="n">_RandomWordsState</span><span class="p">();</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">_RandomWordsState</span> <span class="kd">extends</span> <span class="n">State</span><span class="o">&lt;</span><span class="n">RandomWords</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">Container</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>更新 <code>_RandomWordsState</code> 中的 <code>build()</code> 方法。</p>
<p>用以下两行替换 <code>return Container();</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">_RandomWordsState</span> <span class="kd">extends</span> <span class="n">State</span><span class="o">&lt;</span><span class="n">RandomWords</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>                                  
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">final</span> <span class="n">wordPair</span> <span class="o">=</span> <span class="n">WordPair</span><span class="p">.</span><span class="n">random</span><span class="p">();</span>      <span class="c1">// NEW
</span><span class="c1"></span>    <span class="k">return</span> <span class="n">Text</span><span class="p">(</span><span class="n">wordPair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">);</span>      <span class="c1">// NEW
</span><span class="c1"></span>  <span class="p">}</span>                                         
<span class="p">}</span>
</code></pre></div><p>通过以下修改，删除 <code>MyApp</code> 中的文字生成代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyApp</span> <span class="kd">extends</span> <span class="n">StatelessWidget</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">final</span> <span class="n">wordPair</span> <span class="o">=</span> <span class="n">WordPair</span><span class="p">.</span><span class="n">random</span><span class="p">();</span>  <span class="c1">// DELETE
</span><span class="c1"></span>
    <span class="k">return</span> <span class="n">MaterialApp</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">,</span>
      <span class="nl">home:</span> <span class="n">Scaffold</span><span class="p">(</span>
        <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
          <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Welcome to Flutter&#39;</span><span class="p">),</span>
        <span class="p">),</span>
        <span class="nl">body:</span> <span class="n">Center</span><span class="p">(</span>
          <span class="c1">//child: Text(wordPair.asPascalCase), // REPLACE with... 
</span><span class="c1"></span>          <span class="nl">child:</span> <span class="n">RandomWords</span><span class="p">(),</span>                 <span class="c1">// ...this line
</span><span class="c1"></span>        <span class="p">),</span>
      <span class="p">),</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>热重载应用程序。应用程序应该像以前一样，每次热重载或保存应用程序时都会显示一个单词配对。</p>
<p>提示：如果您在热重载时看到警告，表明您可能需要重新启动应用程序，您应该考虑重新启动应用程序。这可能是一个假阳性，但重启可以确保您的更改反映在应用程序的 UI 中。</p>
<h3 id="遇到问题了">遇到问题了？</h3>
<p>如果您的应用程序没有正确运行，您可以使用以下链接中的代码来恢复正常。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/b3293b5bb0c0187bdbe8112f7759f4d75f4c040a/startup_namer/step3_stateful_widget/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="创建一个无限滚动的-listview">创建一个无限滚动的 ListView</h2>
<p>在这一步中，您将展开 <code>_RandomWordsState</code> 来生成并显示单词配对列表。随着用户的滚动，列表（显示在 ListView 小组件中）会无限增长。ListView 中的构建器工厂构造函数允许你按需懒惰地构建一个列表视图。</p>
<p>在 <code>_RandomWordState</code> 类中添加一些状态变量。</p>
<p>增加一个 <code>_suggestions</code> 列表，用于保存建议的单词配对。另外，添加一个 <code>_biggerFont</code> 变量，用于使字体大小变大。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">_RandomWordsState</span> <span class="kd">extends</span> <span class="n">State</span><span class="o">&lt;</span><span class="n">RandomWords</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">WordPair</span><span class="o">&gt;</span> <span class="n">_suggestions</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">WordPair</span><span class="o">&gt;</span><span class="p">[];</span>            <span class="c1">// NEW
</span><span class="c1"></span>  <span class="kd">final</span> <span class="n">TextStyle</span> <span class="n">_biggerFont</span> <span class="o">=</span> <span class="kd">const</span> <span class="n">TextStyle</span><span class="p">(</span><span class="nl">fontSize:</span> <span class="m">18</span><span class="p">);</span> <span class="c1">// NEW
</span><span class="c1"></span>  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div><p>接下来，你将在 <code>_RandomWordsState</code> 类中添加一个 <code>_buildSuggestions()</code> 函数。这个方法可以构建显示建议词对的 <code>ListView</code>。</p>
<p><code>ListView</code> 类提供了一个构建器属性 <code>itemBuilder</code>，它是一个工厂构建器和回调函数，指定为一个匿名函数。两个参数被传递给函数&ndash;<code>BuildContext</code> 和行迭代器 <code>i</code>。迭代器从0开始，每次调用函数时递增，每一个建议的单词配对都会递增一次。这个模型允许建议列表在用户滚动时继续增长。</p>
<p>添加整个 <code>_buildSuggestions</code> 函数。</p>
<p>在 <code>_RandomWordsState</code> 类中，添加以下函数，如果你喜欢，请删除注释:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Widget</span> <span class="n">_buildSuggestions</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">ListView</span><span class="p">.</span><span class="n">builder</span><span class="p">(</span>
      <span class="nl">padding:</span> <span class="kd">const</span> <span class="n">EdgeInsets</span><span class="p">.</span><span class="n">all</span><span class="p">(</span><span class="m">16</span><span class="p">),</span>
      <span class="c1">// The itemBuilder callback is called once per suggested 
</span><span class="c1"></span>      <span class="c1">// word pairing, and places each suggestion into a ListTile
</span><span class="c1"></span>      <span class="c1">// row. For even rows, the function adds a ListTile row for
</span><span class="c1"></span>      <span class="c1">// the word pairing. For odd rows, the function adds a 
</span><span class="c1"></span>      <span class="c1">// Divider widget to visually separate the entries. Note that
</span><span class="c1"></span>      <span class="c1">// the divider may be difficult to see on smaller devices.
</span><span class="c1"></span>      <span class="nl">itemBuilder:</span> <span class="p">(</span><span class="n">BuildContext</span> <span class="n">_context</span><span class="p">,</span> <span class="kt">int</span> <span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Add a one-pixel-high divider widget before each row 
</span><span class="c1"></span>        <span class="c1">// in the ListView.
</span><span class="c1"></span>        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">isOdd</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">return</span> <span class="n">Divider</span><span class="p">();</span>
        <span class="p">}</span>

        <span class="c1">// The syntax &#34;i ~/ 2&#34; divides i by 2 and returns an 
</span><span class="c1"></span>        <span class="c1">// integer result.
</span><span class="c1"></span>        <span class="c1">// For example: 1, 2, 3, 4, 5 becomes 0, 1, 1, 2, 2.
</span><span class="c1"></span>        <span class="c1">// This calculates the actual number of word pairings 
</span><span class="c1"></span>        <span class="c1">// in the ListView,minus the divider widgets.
</span><span class="c1"></span>        <span class="kd">final</span> <span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="n">i</span> <span class="o">~/</span> <span class="m">2</span><span class="p">;</span>
        <span class="c1">// If you&#39;ve reached the end of the available word
</span><span class="c1"></span>        <span class="c1">// pairings...
</span><span class="c1"></span>        <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">_suggestions</span><span class="p">.</span><span class="n">length</span><span class="p">)</span> <span class="p">{</span>
          <span class="c1">// ...then generate 10 more and add them to the 
</span><span class="c1"></span>          <span class="c1">// suggestions list.
</span><span class="c1"></span>          <span class="n">_suggestions</span><span class="p">.</span><span class="n">addAll</span><span class="p">(</span><span class="n">generateWordPairs</span><span class="p">().</span><span class="n">take</span><span class="p">(</span><span class="m">10</span><span class="p">));</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">_buildRow</span><span class="p">(</span><span class="n">_suggestions</span><span class="p">[</span><span class="n">index</span><span class="p">]);</span>
      <span class="p">}</span>
    <span class="p">);</span>
  <span class="p">}</span>
</code></pre></div><p><code>_buildSuggestions</code> 函数对每个词对调用一次 <code>_buildRow</code>。该函数在 <code>ListTile</code> 中显示每一个新的词对，这使得你可以在<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/index.html?index=..%2F..index#0">第2部分</a>中使行更有吸引力。</p>
<p>在 <code>_RandomWordsState</code> 中添加一个 <code>_buildRow</code> 函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Widget</span> <span class="n">_buildRow</span><span class="p">(</span><span class="n">WordPair</span> <span class="n">pair</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">ListTile</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span>
        <span class="n">pair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">,</span>
        <span class="nl">style:</span> <span class="n">_biggerFont</span><span class="p">,</span>
      <span class="p">),</span>
    <span class="p">);</span>
  <span class="p">}</span>
</code></pre></div><p>更新 <code>_RandomWordsState</code> 的构建方法。</p>
<p>将其改为使用 <code>_buildSuggestions()</code>，而不是直接调用单词生成库。(<code>Scaffold</code> 实现了基本的 Material Design 视觉布局。)</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="err">@</span><span class="n">override</span>
<span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//final wordPair = WordPair.random(); // Delete these... 
</span><span class="c1"></span>    <span class="c1">//return Text(wordPair.asPascalCase); // ... two lines.
</span><span class="c1"></span>
    <span class="k">return</span> <span class="n">Scaffold</span> <span class="p">(</span>                     <span class="c1">// Add from here... 
</span><span class="c1"></span>      <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
        <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Startup Name Generator&#39;</span><span class="p">),</span>
      <span class="p">),</span>
      <span class="nl">body:</span> <span class="n">_buildSuggestions</span><span class="p">(),</span>
    <span class="p">);</span>                                      <span class="c1">// ... to here.
</span><span class="c1"></span>  <span class="p">}</span>
</code></pre></div><p>更新 <code>MyApp</code> 的构建方法，更改标题，删除 <code>AppBar</code>，并将 home 属性改为 <code>RandomWords</code> 部件。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="err">@</span><span class="n">override</span>
<span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MaterialApp</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="s1">&#39;Startup Name Generator&#39;</span><span class="p">,</span>
      <span class="nl">home:</span> <span class="n">RandomWords</span><span class="p">(),</span>
    <span class="p">);</span>
  <span class="p">}</span>
</code></pre></div><p>重新启动应用程序。无论你滚动多远，你都应该看到一个单词配对的列表。</p>
<p>Android:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/df2b3cb779e0020e.png" alt="img"></p>
<p>iOS:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/ae47ef0ac2f492b8.png" alt="img"></p>
<h3 id="遇到问题了-1">遇到问题了？</h3>
<p>如果你的应用程序不能正常运行，你可以使用下面链接中的代码来回到正轨。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/b3293b5bb0c0187bdbe8112f7759f4d75f4c040a/startup_namer/step4_infinite_list/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="今后的步骤">今后的步骤</h2>
<p><strong>恭喜你！</strong></p>
<p>你已经完成了这个代码实验室的第一部分! 如果你想扩展这款应用，请进入<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/#0">第二部分</a>，你将对应用进行如下修改。</p>
<ul>
<li>增加互动性</li>
<li>增加导航到新路由的功能。</li>
<li>修改主题颜色。</li>
</ul>
<p>当第2部分完成后，应用程序将是这样的：</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/img/7fcab088cd22cff7.gif" alt="img"></p>
<h3 id="其他后续步骤">其他后续步骤</h3>
<p>通过以下资源了解更多关于 Flutter SDK 的信息。</p>
<ul>
<li><a href="https://flutter.dev/docs/development/ui/layout">Flutter 中的布局</a></li>
<li><a href="https://flutter.dev/docs/development/ui/interactive">增加互动性教程</a></li>
<li><a href="https://flutter.dev/docs/development/ui/widgets-intro">组件介绍</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/android-devs">为 Android 开发者提供的 Flutter</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/react-native-devs">针对 React Native 开发者的 Flutter</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/web-devs">Web 开发人员的 Flutter</a></li>
<li><a href="https://www.youtube.com/flutterdev">Flutter YouTube 频道</a></li>
</ul>
<p>其他资源包括以下几点:</p>
<ul>
<li><a href="https://www.udacity.com/course/build-native-mobile-apps-with-flutter--ud905">用 Flutter 构建本地移动应用</a></li>
<li><a href="https://codelabs.developers.google.com/codelabs/from-java-to-dart/#1">从 Java 到 Dart codelab</a></li>
<li><a href="https://flutter.dev/cookbook/">Flutter cookbook</a></li>
<li><a href="https://flutter.dev/bootstrap-into-dart/">融入 Dart 的 Bootstrap：了解更多关于这门语言的信息</a></li>
</ul>
<p>同时，<a href="https://flutter.dev/community">与 Flutter 社区联系起来!</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/app" term="app" label="app" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[编写你的第一个 Flutter 应用，第二部分]]></title>
            <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app-part-two/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/write-your-first-flutter-app/?utm_source=atom_feed" rel="related" type="text/html" title="编写你的第一个 Flutter 应用，第一部分" />
            
                <id>https://ohmyweekly.github.io/notes/write-your-first-flutter-app-part-two/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-26T00:00:00+08:00</published>
            <updated>2020-06-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flutter 是 Google 的 UI 工具包，用于从单一代码库中为手机、网页和桌面构建漂亮的、原生编译的应用程序。Flutter 可以与现有的代码一起使用，被世界各地的开发者和组织使用，并且是免费和开源的。</blockquote><h2 id="介绍">介绍</h2>
<p>Flutter 是 Google 的 UI 工具包，用于从单一代码库中为移动、Web 和桌面构建漂亮的、原生编译的应用程序。Flutter 可以与现有的代码一起工作，被世界各地的开发者和组织使用，并且是免费和开源的。</p>
<p>在这个代码实验室中，您将扩展一个基本的、移动的 Flutter 应用程序，以包含交互性。您还将创建一个用户可以导航到的第二个页面（称为路由）。最后，您将修改应用程序的主题（颜色）。这个代码实验室扩展了第1部分，在这部分中，你将<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/">创建一个无限的懒惰加载的列表</a>，但如果你想从第2部分开始，我们将提供起始代码。</p>
<h3 id="你将在第二部分学到什么">你将在第二部分学到什么</h3>
<ul>
<li>如何编写一款在 iOS、Android 和 Web 上看起来很自然的 Flutter 应用？</li>
<li>如何使用热重装，加快开发周期？</li>
<li>如何为有状态的 widget 添加交互性？</li>
<li>如何创建并导航到第二个屏幕？</li>
<li>如何使用主题来改变应用程序的外观？</li>
</ul>
<h3 id="你将在第二部分建立什么">你将在第二部分建立什么</h3>
<p>您将从一个简单的移动应用程序开始，为创业公司生成一个无尽的建议名称列表。在代码实验室结束时，您的最终用户可以选择和取消选择名称，保存最好的名称。点击应用栏右上角的列表图标可以导航到一个新的页面（称为路由），该页面只列出了最喜欢的名字。</p>
<p>下面的 GIF 动画显示了完成的应用程序将如何工作。</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/7fcab088cd22cff7.gif" alt="img"></p>
<h2 id="设置您的-flutter-环境">设置您的 Flutter 环境</h2>
<p>如果你还没有完成第1部分，请看<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/#1">设置你的 Flutter 环境</a>，在<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt1/">编写你的第一个Flutter应用，第1部分</a>，设置你的 Flutter 开发环境。</p>
<h2 id="获取启动应用程序">获取启动应用程序</h2>
<p>如果你已经完成了这个 codelab 的第一部分，你已经有了启动应用程序，<code>startup_namer</code>。你可以进行下一步。</p>
<p>如果你没有 <code>startup_namer</code>，不要害怕，你可以使用下面的说明得到它。</p>
<p>使用<a href="https://flutter.dev/get-started/test-drive/#create-app">创建应用程序</a>中的说明创建一个简单的模板化 Flutter 应用程序。将项目命名为 <code>startup_namer</code>（而不是 <code>flutter_app</code>）。</p>
<p>删除 <code>lib/main.dart</code> 中的所有代码。用这个<a href="https://github.com/flutter/codelabs/blob/b3293b5bb0c0187bdbe8112f7759f4d75f4c040a/startup_namer/step4_infinite_list/lib/main.dart">文件</a>中的代码替换，它显示了一个无限的，懒惰加载的建议启动名称列表。</p>
<p>更新 <code>pubspec.yaml</code>，加入英文单词包。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">dependencies</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">flutter</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">sdk</span><span class="p">:</span><span class="w"> </span><span class="l">flutter</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="nt">cupertino_icons</span><span class="p">:</span><span class="w"> </span><span class="l">^0.1.2</span><span class="w">
</span><span class="w">  </span><span class="nt">english_words</span><span class="p">:</span><span class="w"> </span><span class="l">^3.1.5    // NEW</span><span class="w">
</span></code></pre></div><p>英文单词包会生成一对随机的单词，作为潜在的启动名称。</p>
<p>在 Android Studio 的编辑器视图中查看 pubspec 时，点击右上角的 <strong>Pub get</strong>，这将包拉到你的项目中。你应该在控制台中看到以下内容:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">flutter pub get
Running <span class="s2">&#34;flutter pub get&#34;</span> in startup_namer...
Process finished with <span class="nb">exit</span> code <span class="m">0</span>
</code></pre></div><p>运行该应用。</p>
<p>随意滚动，查看持续供应的拟创业公司名称。</p>
<h2 id="将图标添加到列表中">将图标添加到列表中</h2>
<p>在这一步中，你将为每一行添加心形图标。在下一步中，您将使它们可点击并保存收藏夹。</p>
<p>在 <code>_RandomWordsState</code> 中添加一个 <code>_saved</code> Set。这个 <code>Set</code> 存储了用户收藏的单词配对。<code>Set</code> 比 <code>List</code> 更受欢迎，因为一个正确实现的 <code>Set</code> 不允许重复的条目。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">_RandomWordsState</span> <span class="kd">extends</span> <span class="n">State</span><span class="o">&lt;</span><span class="n">RandomWords</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">_suggestions</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">WordPair</span><span class="o">&gt;</span><span class="p">[];</span>
  <span class="kd">final</span> <span class="n">_saved</span> <span class="o">=</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">WordPair</span><span class="o">&gt;</span><span class="p">();</span>     <span class="c1">// NEW
</span><span class="c1"></span>  <span class="kd">final</span> <span class="n">_biggerFont</span> <span class="o">=</span> <span class="n">TextStyle</span><span class="p">(</span><span class="nl">fontSize:</span> <span class="m">18.0</span><span class="p">);</span>
  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div><p>在 <code>_buildRow</code> 函数中，添加一个 <code>alreadySaved</code> 检查，以确保一个单词配对还没有被添加到收藏夹中。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Widget</span> <span class="n">_buildRow</span><span class="p">(</span><span class="n">WordPair</span> <span class="n">pair</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">alreadySaved</span> <span class="o">=</span> <span class="n">_saved</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="n">pair</span><span class="p">);</span>  <span class="c1">// NEW
</span><span class="c1"></span>  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div><p>在 <code>_buildRow()</code> 中，你还将为 <code>ListTile</code> 对象添加心形图标以实现收藏夹。在下一步中，你将添加与心形图标交互的功能。</p>
<p>在文本之后添加图标，如下图所示。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Widget</span> <span class="n">_buildRow</span><span class="p">(</span><span class="n">WordPair</span> <span class="n">pair</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">alreadySaved</span> <span class="o">=</span> <span class="n">_saved</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="n">pair</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">ListTile</span><span class="p">(</span>
    <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span>
      <span class="n">pair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">,</span>
      <span class="nl">style:</span> <span class="n">_biggerFont</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nl">trailing:</span> <span class="n">Icon</span><span class="p">(</span>   <span class="c1">// NEW from here... 
</span><span class="c1"></span>      <span class="n">alreadySaved</span> <span class="o">?</span> <span class="n">Icons</span><span class="p">.</span><span class="n">favorite</span> <span class="o">:</span> <span class="n">Icons</span><span class="p">.</span><span class="n">favorite_border</span><span class="p">,</span>
      <span class="nl">color:</span> <span class="n">alreadySaved</span> <span class="o">?</span> <span class="n">Colors</span><span class="p">.</span><span class="n">red</span> <span class="o">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="p">),</span>                <span class="c1">// ... to here.
</span><span class="c1"></span>  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>热重新加载应用程序。</p>
<p>你现在应该看到每一行都有空心，但它们还没有互动。</p>
<p>Android</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/819e2ff89da9421a.png" alt="img"></p>
<p>iOS</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/4df48933551e7c48.png" alt="img"></p>
<h3 id="遇到问题了">遇到问题了？</h3>
<p>如果你的应用程序不能正常运行，你可以使用下面链接中的代码来回到正轨。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/master/startup_namer/step5_add_icons/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="增加互动性">增加互动性</h2>
<p>在这一步中，你将使心形图标可以点击。当用户点击列表中的一个条目，切换其收藏状态时，该词对就会从一组保存的收藏夹中添加或删除。</p>
<p>要做到这一点，你将修改 <code>_buildRow</code> 函数。如果一个词条已经被添加到收藏夹中，再次点击它就会将其从收藏夹中删除。当一个磁贴被点击后，函数会调用 <code>setState()</code> 来通知框架状态已经改变。</p>
<p>在 <code>_buildRow</code> 方法中加入 <code>onTap</code>，如下图所示:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Widget</span> <span class="n">_buildRow</span><span class="p">(</span><span class="n">WordPair</span> <span class="n">pair</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">alreadySaved</span> <span class="o">=</span> <span class="n">_saved</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="n">pair</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">ListTile</span><span class="p">(</span>
    <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span>
      <span class="n">pair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">,</span>
      <span class="nl">style:</span> <span class="n">_biggerFont</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nl">trailing:</span> <span class="n">Icon</span><span class="p">(</span>
      <span class="n">alreadySaved</span> <span class="o">?</span> <span class="n">Icons</span><span class="p">.</span><span class="n">favorite</span> <span class="o">:</span> <span class="n">Icons</span><span class="p">.</span><span class="n">favorite_border</span><span class="p">,</span>
      <span class="nl">color:</span> <span class="n">alreadySaved</span> <span class="o">?</span> <span class="n">Colors</span><span class="p">.</span><span class="n">red</span> <span class="o">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nl">onTap:</span> <span class="p">()</span> <span class="p">{</span>      <span class="c1">// NEW lines from here...
</span><span class="c1"></span>      <span class="n">setState</span><span class="p">(()</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">alreadySaved</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">_saved</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">pair</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> 
          <span class="n">_saved</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">pair</span><span class="p">);</span> 
        <span class="p">}</span> 
      <span class="p">});</span>
    <span class="p">},</span>               <span class="c1">// ... to here.
</span><span class="c1"></span>  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>提示：在 Flutter 的反应式框架中，调用 <code>setState()</code> 会触发对 <code>State</code> 对象的 <code>build()</code> 方法的调用，导致 UI 的更新。</p>
<p>热重载应用。</p>
<p>你应该能够点击任何磁贴来收藏或不收藏该条目。点击瓷砖会产生一个隐含的从点击点发出的泼墨动画。</p>
<p>Android</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/43dfc7ba5f728e8f.png" alt="img"></p>
<p>iOS</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/e7a99a1b94bea7d4.png" alt="img"></p>
<h3 id="遇到问题了-1">遇到问题了？</h3>
<p>如果你的应用程序不能正常运行，你可以使用下面链接中的代码来回到正轨。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/master/startup_namer/step6_add_interactivity/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="导航到一个新的屏幕">导航到一个新的屏幕</h2>
<p>在这一步中，您将添加一个新的页面（在 Flutter 中称为路由），显示收藏夹。您将学习如何在主页路线和新路由之间进行导航。</p>
<p>在 Flutter 中，<code>Navigator</code> 管理着一个包含应用程序路由的堆栈。将一个路由推到 <code>Navigator</code> 的堆栈上，会将显示更新到该路由。从 <code>Navigator</code> 的堆栈中弹出一条路由，会将显示返回到之前的路由。</p>
<p>接下来，您将在 <code>_RandomWordsState</code> 的 <code>build</code> 方法中为 <code>AppBar</code> 添加一个列表图标。当用户点击列表图标时，一个包含保存的收藏夹的新路由会被推送到 <code>Navigator</code>，显示图标。</p>
<p>在 <code>build</code> 方法中添加图标及其对应的操作:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">_RandomWordsState</span> <span class="kd">extends</span> <span class="n">State</span><span class="o">&lt;</span><span class="n">RandomWords</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="p">...</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">Scaffold</span><span class="p">(</span>
      <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
        <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Startup Name Generator&#39;</span><span class="p">),</span>
        <span class="nl">actions:</span> <span class="p">[</span>              <span class="c1">// NEW lines from here...
</span><span class="c1"></span>          <span class="n">IconButton</span><span class="p">(</span><span class="nl">icon:</span> <span class="n">Icon</span><span class="p">(</span><span class="n">Icons</span><span class="p">.</span><span class="n">list</span><span class="p">),</span> <span class="nl">onPressed:</span> <span class="n">_pushSaved</span><span class="p">),</span>
        <span class="p">],</span>                      <span class="c1">// ... to here.
</span><span class="c1"></span>      <span class="p">),</span>
      <span class="nl">home:</span> <span class="n">RandomWords</span><span class="p">(),</span>
    <span class="p">);</span>
  <span class="p">}</span>
  <span class="p">...</span>
<span class="p">}</span>
</code></pre></div><p>提示：一些小组件属性会取一个小组件(<code>child</code>)，而其他属性，如 <code>action</code>，会取一组小组件(<code>children</code>), 如方括号(<code>[]</code>)所示。</p>
<p>在 <code>_RandomWordsState</code> 类中添加一个 <code>_pushSaved()</code> 函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">_pushSaved</span><span class="p">()</span> <span class="p">{</span>
<span class="p">}</span>
</code></pre></div><p>热重新加载应用程序。<a href="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/a114478ae13b853.png">列表图标</a>出现在应用栏中。点击它还没有任何作用，因为 <code>_pushSaved</code> 函数是空的。</p>
<p>接下来，你将建立一条路由，并将其推送到 <code>Navigator</code> 的栈中。这个操作会改变屏幕以显示新的路由。新页面的内容是在 <code>MaterialPageRoute</code> 的构建器属性中以匿名函数的方式构建的。</p>
<p>调用 <code>Navigator.push</code>，如下图所示，它将路由推送到 <code>Navigator</code> 的堆栈中。IDE 会抱怨无效代码，但你会在下一节中解决这个问题。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">_pushSaved</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">Navigator</span><span class="p">.</span><span class="n">of</span><span class="p">(</span><span class="n">context</span><span class="p">).</span><span class="n">push</span><span class="p">(</span>
  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>接下来，你将添加 <code>MaterialPageRoute</code> 和它的构建器。现在，添加生成 <code>ListTile</code> 行的代码。<code>ListTile</code> 的 <code>divideTiles()</code> 方法在每个 <code>ListTile</code> 之间增加了水平间距。被划分的变量持有通过方便函数 <code>toList()</code> 转换为列表的最终行。</p>
<p>添加代码，如下面的代码片段所示:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">_pushSaved</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">Navigator</span><span class="p">.</span><span class="n">of</span><span class="p">(</span><span class="n">context</span><span class="p">).</span><span class="n">push</span><span class="p">(</span>
      <span class="n">MaterialPageRoute</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;</span><span class="p">(</span>
        <span class="c1">// NEW lines from here...
</span><span class="c1"></span>        <span class="nl">builder:</span> <span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
          <span class="kd">final</span> <span class="n">tiles</span> <span class="o">=</span> <span class="n">_saved</span><span class="p">.</span><span class="n">map</span><span class="p">(</span>
            <span class="p">(</span><span class="n">WordPair</span> <span class="n">pair</span><span class="p">)</span> <span class="p">{</span>
              <span class="k">return</span> <span class="n">ListTile</span><span class="p">(</span>
                <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span>
                  <span class="n">pair</span><span class="p">.</span><span class="n">asPascalCase</span><span class="p">,</span>
                  <span class="nl">style:</span> <span class="n">_biggerFont</span><span class="p">,</span>
                <span class="p">),</span>
              <span class="p">);</span>
            <span class="p">},</span>
          <span class="p">);</span>
          <span class="kd">final</span> <span class="n">divided</span> <span class="o">=</span> <span class="n">ListTile</span><span class="p">.</span><span class="n">divideTiles</span><span class="p">(</span>
            <span class="nl">context:</span> <span class="n">context</span><span class="p">,</span>
            <span class="nl">tiles:</span> <span class="n">tiles</span><span class="p">,</span>
          <span class="p">).</span><span class="n">toList</span><span class="p">();</span>

          <span class="k">return</span> <span class="n">Scaffold</span><span class="p">(</span>
            <span class="nl">appBar:</span> <span class="n">AppBar</span><span class="p">(</span>
              <span class="nl">title:</span> <span class="n">Text</span><span class="p">(</span><span class="s1">&#39;Saved Suggestions&#39;</span><span class="p">),</span>
            <span class="p">),</span>
            <span class="nl">body:</span> <span class="n">ListView</span><span class="p">(</span><span class="nl">children:</span> <span class="n">divided</span><span class="p">),</span>
          <span class="p">);</span>
        <span class="p">},</span> <span class="c1">// ...to here.
</span><span class="c1"></span>      <span class="p">),</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p><code>builder</code> 属性返回一个 <code>Scaffold</code>，包含名为 <code>SavedSuggestions</code> 的新路由的应用栏。新路由的主体由一个包含 <code>ListTiles</code> 行的 <code>ListView</code> 组成。每一行都由一个分隔符隔开。</p>
<p>热重载应用。将一些选择收藏起来，然后点击应用栏中的列表图标。新的路由出现，包含收藏夹。请注意，Navigator 在应用栏中增加了一个&quot;返回&quot;按钮。你不必明确地实现 <code>Navigator.pop</code>。点击&quot;返回&quot;按钮就可以返回到主路由。</p>
<p>iOS - Main route</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/928693968b8e482a.png" alt="img"></p>
<p>iOS - Saved suggestions route</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/2245376356747d5a.png" alt="img"></p>
<h3 id="遇到问题了-2">遇到问题了？</h3>
<p>如果你的应用程序没有正确运行，那么你可以使用下面链接中的代码来回到正轨。</p>
<ul>
<li><a href="https://github.com/flutter/codelabs/blob/master/startup_namer/step7_navigate_route/lib/main.dart">lib/main.dart</a></li>
</ul>
<h2 id="使用主题改变用户界面">使用主题改变用户界面</h2>
<p>在这一步中，您将修改应用程序的主题。主题控制你的应用程序的外观和感觉。您可以使用默认主题，这取决于物理设备或模拟器，或者自定义主题以反映您的品牌。</p>
<p>您可以通过配置 <a href="https://docs.flutter.io/flutter/material/ThemeData-class.html">ThemeData</a> 类轻松更改应用程序的主题。应用程序使用默认主题，但你会将应用程序的主色调改为白色。</p>
<p>在 <code>MyApp</code> 类中更改颜色:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyApp</span> <span class="kd">extends</span> <span class="n">StatelessWidget</span> <span class="p">{</span>
  <span class="err">@</span><span class="n">override</span>
  <span class="n">Widget</span> <span class="n">build</span><span class="p">(</span><span class="n">BuildContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MaterialApp</span><span class="p">(</span>
      <span class="nl">title:</span> <span class="s1">&#39;Startup Name Generator&#39;</span><span class="p">,</span>
      <span class="nl">theme:</span> <span class="n">ThemeData</span><span class="p">(</span>          <span class="c1">// Add the 3 lines from here... 
</span><span class="c1"></span>        <span class="nl">primaryColor:</span> <span class="n">Colors</span><span class="p">.</span><span class="n">white</span><span class="p">,</span>
      <span class="p">),</span>                         <span class="c1">// ... to here.
</span><span class="c1"></span>      <span class="nl">home:</span> <span class="n">RandomWords</span><span class="p">(),</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>热重载应用。现在整个背景都是白色的，甚至应用栏也是白色的。</p>
<p>作为一个练习，使用 <code>ThemeData</code> 来改变 UI 的其他方面。Material 库中的 <a href="https://docs.flutter.io/flutter/material/Colors-class.html">Colors</a> 类提供了许多你可以玩的颜色常量。热重载使得对 UI 的实验变得快速而简单。</p>
<p>Android</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/5d4ed8aeea9e4d0a.png" alt="img"></p>
<p>iOS</p>
<p><img src="https://codelabs.developers.google.com/codelabs/first-flutter-app-pt2/img/c325151f1ae4820d.png" alt="img"></p>
<h3 id="遇到问题了-3">遇到问题了？</h3>
<p>如果你已经偏离了轨道，那么使用下面链接中的代码来查看最终应用的代码。</p>
<p>= <a href="https://github.com/flutter/codelabs/blob/master/startup_namer/step8_themes/lib/main.darts">lib/main.dart</a></p>
<h2 id="做得很好">做得很好！</h2>
<p>你写了一个交互式的 Flutter 应用，可以在 iOS 和 Android 上运行，具体做法如下</p>
<ul>
<li>编写 Dart 代码。</li>
<li>使用热重载来加快开发周期。</li>
<li>实现一个有状态的 widget，为你的应用添加交互性。</li>
<li>创建途径并添加在原途径和新途径之间移动的逻辑。</li>
<li>学习如何使用主题改变你的应用程序的 UI 外观。</li>
</ul>
<h2 id="今后的步骤">今后的步骤</h2>
<p>从以下资源中了解更多关于 Flutter SDK 的信息。</p>
<ul>
<li><a href="https://flutter.dev/docs/development/ui/layout">Flutter 中的布局</a></li>
<li><a href="https://flutter.dev/docs/development/ui/interactive">增加互动性教程</a></li>
<li><a href="https://flutter.dev/docs/development/ui/widgets-intro">组件介绍</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/android-devs">为 Android 开发者提供的 Flutter</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/react-native-devs">针对 React Native 开发者的 Flutter</a></li>
<li><a href="https://flutter.dev/docs/get-started/flutter-for/web-devs">Web 开发人员的 Flutter</a></li>
<li><a href="https://www.youtube.com/flutterdev">Flutter YouTube 频道</a></li>
</ul>
<p>其他资源包括以下几点:</p>
<ul>
<li><a href="https://www.udacity.com/course/build-native-mobile-apps-with-flutter--ud905">用 Flutter 构建本地移动应用</a></li>
<li><a href="https://codelabs.developers.google.com/codelabs/from-java-to-dart/#1">从 Java 到 Dart codelab</a></li>
<li><a href="https://flutter.dev/cookbook/">Flutter cookbook</a></li>
<li><a href="https://flutter.dev/bootstrap-into-dart/">融入 Dart 的 Bootstrap：了解更多关于这门语言的信息</a></li>
</ul>
<p>同时，<a href="https://flutter.dev/community">与 Flutter 社区联系起来!</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flutter" term="flutter" label="flutter" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/app" term="app" label="app" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[第一篇日志]]></title>
            <link href="https://ohmyweekly.github.io/posts/about/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/posts/about/</id>
            
            
            <published>2020-06-24T18:21:33-05:00</published>
            <updated>2020-06-24T18:21:33-05:00</updated>
            
            
            <content type="html"><![CDATA[<p>毕竟谁人终得鹿, 不如终日梦为鱼。</p>
<h2 id="友情链接">友情链接</h2>
<ul>
<li><a href="https://ohmycloud.github.io">ohmycloud</a> ✔</li>
<li><a href="https://ohmycloudy.github.io">ohmycloudy</a> ✔</li>
<li><a href="https://ohmysummer.github.io">ohmysummer</a>  ✔</li>
<li><a href="https://ohmyshunny.github.io">ohmyshunny</a>  ✔</li>
<li><a href="https://ohmysunny.github.io">ohmysunny</a> ✔</li>
<li><a href="https://ohmyraku.github.io">ohmyraku</a> ✔</li>
<li><a href="https://ohmypanda.github.io">ohmypanda</a> ✔</li>
<li><a href="https://ohmyweekly.github.io">ohmyweekly</a> ✔</li>
<li><a href="https://rakulang.github.io">rakulang</a> ✔</li>
</ul>]]></content>
            
                 
                    
                 
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Dart 入门]]></title>
            <link href="https://ohmyweekly.github.io/notes/dart/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/dart-iterable-collections/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 可迭代集合" />
                <link href="https://ohmyweekly.github.io/notes/dart-cheatsheet-codelab/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 语言速查表" />
            
                <id>https://ohmyweekly.github.io/notes/dart/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-25T00:00:00+08:00</published>
            <updated>2020-06-25T16:02:46-04:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote><a href="https://www.dartcn.com/">Dart</a>入门指南。</blockquote><!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h2 id="dart-help">重要的概念</h2>
<p>与 Java 不同，Dart 没有关键字 &ldquo;public&rdquo;, &ldquo;protected&rdquo; 和 &ldquo;private&rdquo;。 如果标识符以下划线（<code>_</code>）开头，则它相对于库是私有的。 有关更多信息，参考<a href="https://www.dartcn.com/guides/language/language-tour#%E5%BA%93%E5%92%8C%E5%8F%AF%E8%A7%81%E6%80%A7">库和可见性</a>。</p>
<h2 id="变量">变量</h2>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Bob&#39;</span><span class="p">;</span>     <span class="c1">// 类型推断
</span><span class="c1"></span>
<span class="kt">dynamic</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Bob&#39;</span><span class="p">;</span> <span class="c1">// 动态类型
</span><span class="c1"></span><span class="kt">String</span>  <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Bob&#39;</span><span class="p">;</span> <span class="c1">// 显式声明
</span></code></pre></div><h3 id="默认值">默认值</h3>
<p>未初始化的变量默认值是 <code>null</code>。即使变量是数字, 类型默认值也是 null, 因为在 Dart 中一切都是对象，数字类型也不例外。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">int</span> <span class="n">lineCount</span><span class="p">;</span>
<span class="k">assert</span><span class="p">(</span><span class="n">lineCount</span> <span class="o">==</span> <span class="kc">null</span><span class="p">);</span>
</code></pre></div><h3 id="final-和-const">final 和 const</h3>
<p>使用 <code>final</code> 关键字声明的变量, 其值只能被设置一次, 使用 <code>const</code> 关键字声明的变量, 其值在编译时就已固定:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">final</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Bob&#39;</span><span class="p">;</span> <span class="c1">// 不使用类型注解
</span><span class="c1"></span><span class="kd">final</span> <span class="kt">String</span> <span class="n">nickname</span> <span class="o">=</span> <span class="s1">&#39;Bobby&#39;</span><span class="p">;</span>

<span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Alice&#39;</span><span class="p">;</span>     <span class="c1">// Error: final 变量只能被设置一次
</span></code></pre></div><p><code>const</code> 声明一个在<strong>编译</strong>时就固定不变的值, 例如数字字面量、字符串字面量:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">const</span> <span class="n">bar</span> <span class="o">=</span> <span class="m">1000000</span><span class="p">;</span>              <span class="c1">// 压力单位(dynes/cm2)
</span><span class="c1"></span><span class="kd">const</span> <span class="kt">double</span> <span class="n">atm</span> <span class="o">=</span> <span class="m">1.01325</span> <span class="o">*</span> <span class="n">bar</span><span class="p">;</span> <span class="c1">// 一个标准大气压强
</span></code></pre></div><h2 id="内置类型">内置类型</h2>
<p>Dart 语言支持以下内置类型:</p>
<table>
<thead>
<tr>
<th style="text-align:left">类型</th>
<th style="text-align:left">字面量</th>
<th style="text-align:left">对象</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Number</td>
<td style="text-align:left">2⁶³ -1</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">String</td>
<td style="text-align:left">&lsquo;Hello&rsquo;</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Boolean</td>
<td style="text-align:left">true,false</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">List</td>
<td style="text-align:left">[1,2,3]</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Set</td>
<td style="text-align:left">{&lsquo;raku&rsquo;,&lsquo;perl&rsquo;}</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Map</td>
<td style="text-align:left">{&lsquo;lan&rsquo;: &lsquo;raku&rsquo;}</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Rune</td>
<td style="text-align:left">\u2665, \u{1f600}</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Symbol</td>
<td style="text-align:left">#dadix, #bar</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dart" term="dart" label="dart" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/examples" term="examples" label="examples" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Dart 可迭代集合]]></title>
            <link href="https://ohmyweekly.github.io/notes/dart-iterable-collections/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/dart/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 入门" />
                <link href="https://ohmyweekly.github.io/notes/dart-cheatsheet-codelab/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 语言速查表" />
            
                <id>https://ohmyweekly.github.io/notes/dart-iterable-collections/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-25T00:00:00+08:00</published>
            <updated>2020-06-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote><a href="https://dart.dev/codelabs/iterables">Dart</a>可迭代集合。</blockquote><!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>这个代码实验室教你如何使用实现 <a href="https://api.dart.dev/stable/dart-core/Iterable-class.html">Iterable</a>类的集合-例如 <a href="https://api.dart.dev/stable/dart-core/List-class.html">List</a>和 <a href="https://api.dart.dev/stable/dart-core/Set-class.html">Set</a>。迭代类是各种 Dart 应用程序的基本构建模块，你可能已经在使用它们，甚至没有注意到。这个代码实验室将帮助你充分利用它们。</p>
<p>使用嵌入式 DartPad 编辑器，你可以通过运行示例代码和完成练习来测试你的知识。</p>
<p>要想从这个 codelab 中获得最大的收获，你应该具备基本的 <a href="https://dart.dev/samples">Dart 语法知识</a>。</p>
<p>本课程包括以下内容。</p>
<ul>
<li>如何读取一个 Iterable 的元素。</li>
<li>如何检查一个 Iterable 的元素是否满足一个条件。</li>
<li>如何过滤一个 Iterable 的内容。</li>
<li>如何将一个 Iterable 的内容映射到不同的值。</li>
</ul>
<p>估计完成这个代码实验所需的时间: 60分钟。</p>
<h2 id="什么是集合">什么是集合?</h2>
<p>集合是代表一组对象的对象，这些对象称为元素。迭代元素是集合的一种。</p>
<p>集合可以是空的，也可以包含许多元素。根据不同的目的，集合可以有不同的结构和实现。这些是一些最常见的集合类型:</p>
<ul>
<li><a href="https://api.dart.dev/stable/dart-core/List-class.html">List</a>: 用来通过索引读取元素。</li>
<li><a href="https://api.dart.dev/stable/dart-core/Set-class.html">Set</a>: 用于包含只能出现一次的元素。</li>
<li><a href="https://api.dart.dev/stable/dart-core/Map-class.html">Map</a>：用于通过键来读取元素。</li>
</ul>
<h2 id="什么是iterable">什么是Iterable?</h2>
<p><code>Iterable</code> 是一个元素的集合，它可以被依次访问。</p>
<p>在 Dart 中，<code>Iterable</code> 是一个抽象类，这意味着你不能直接实例化它。然而，你可以通过创建一个新的 <code>List</code> 或 <code>Set</code> 来创建一个新的 <code>Iterable</code>。</p>
<p><code>List</code> 和 <code>Set</code> 都是 <code>Iterable</code>，所以它们和 <code>Iterable</code> 类有相同的方法和属性。</p>
<p><code>Map</code> 在内部使用不同的数据结构，这取决于它的实现。例如，<a href="https://api.dart.dev/stable/dart-collection/HashMap-class.html">HashMap</a> 使用了一个哈希表，其中的元素(也称为值)是通过一个键获得的。通过使用 <code>Map</code> 的 <code>entries</code> 或 <code>values</code> 属性，<code>Map</code> 的元素也可以作为 <code>Iterable</code> 对象读取。</p>
<p>这个例子显示了一个 <code>int</code> 的 <code>List</code>，它也是一个 <code>int</code> 的 <code>Iterable</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">];</span>
</code></pre></div><p>与 <code>List</code> 的区别在于，使用 <code>Iterable</code>，你无法保证按索引读取元素的效率。<code>Iterable</code> 与 <code>List</code> 相比，没有 <code>[]</code> 操作符。</p>
<p>例如，考虑以下代码，这是<strong>无效的</strong>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="n">iterable</span><span class="p">[</span><span class="m">1</span><span class="p">];</span>
</code></pre></div><p>如果你用 <code>[]</code> 读取元素，编译器会告诉你 <code>'[]'</code> 这个运算符没有为 <code>Iterable</code> 类定义，这意味着在这种情况下你不能使用 <code>[index]</code>。</p>
<p>你可以用 <code>elementAt()</code> 来读取元素，它可以遍历迭代的元素，直到它到达那个位置。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="n">iterable</span><span class="p">.</span><span class="n">elementAt</span><span class="p">(</span><span class="m">1</span><span class="p">);</span>
</code></pre></div><p>继续下一节，了解更多关于如何访问 <code>Iterable</code> 的元素。</p>
<h2 id="读取元素">读取元素</h2>
<p>你可以使用 <code>for-in</code> 循环，依次读取一个迭代元素。</p>
<h3 id="例子-使用-for-in-循环">例子: 使用 for-in 循环</h3>
<p>下面的例子展示了如何使用 <code>for-in</code> 循环读取元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Salad&#39;</span><span class="p">,</span> <span class="s1">&#39;Popcorn&#39;</span><span class="p">,</span> <span class="s1">&#39;Toast&#39;</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">element</span> <span class="k">in</span> <span class="n">iterable</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="n">element</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>在幕后，<code>for-in</code> 循环使用了一个迭代器。然而，你很少看到直接使用迭代器 API，因为 <code>for-in</code> 更容易阅读和理解，而且不容易出错。</p>
<p>关键术语:</p>
<ul>
<li><strong>Iterable</strong>: Dart <a href="https://api.dart.dev/stable/dart-core/Iterable-class.html">Iterable</a> 类。</li>
<li><strong>Iterator</strong>: <code>for-in</code> 用来从一个 Iterable 对象中读取元素的对象。</li>
<li><code>for-in</code> 循环: 从一个 Iterable 对象中依次读取元素的简单方法。</li>
</ul>
<h3 id="例子使用第一个和最后一个元素">例子：使用第一个和最后一个元素</h3>
<p>在某些情况下，你只想访问一个 <code>Iterable</code> 的第一个或最后一个元素。</p>
<p>在 <code>Iterable</code> 类中，你不能直接访问元素，所以你不能调用 <code>iterable[0]</code> 来访问第一个元素。相反，你可以使用 <code>first</code>，它可以获取第一个元素。</p>
<p>另外，使用 Iterable 类，你不能使用操作符 <code>[]</code> 来访问最后一个元素，但是你可以使用 <code>last</code> 属性。</p>
<p>因为访问一个 Iterable 的最后一个元素需要踏过所有其他元素，所以 <code>last</code> 可能会很慢。在一个空的 <code>Iterable</code> 上使用 <code>first</code> 或 <code>last</code> 会导致一个 <a href="https://api.dart.dev/stable/dart-core/StateError-class.html">StateError</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">Iterable</span> <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Salad&#39;</span><span class="p">,</span> <span class="s1">&#39;Popcorn&#39;</span><span class="p">,</span> <span class="s1">&#39;Toast&#39;</span><span class="p">];</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;The first element is </span><span class="si">${</span><span class="n">iterable</span><span class="p">.</span><span class="n">first</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;The last element is </span><span class="si">${</span><span class="n">iterable</span><span class="p">.</span><span class="n">last</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>在这个例子中，你看到了如何使用 <code>first</code> 和 <code>last</code> 来获得一个 <code>Iterable</code> 的第一个和最后一个元素。也可以找到满足条件的第一个元素。下一节将展示如何使用名为 <code>firstWhere()</code> 的方法来实现这一目标。</p>
<h3 id="例子-使用-firstwhere">例子: 使用 firstWhere()</h3>
<p>你已经看到，你可以依次访问一个 <code>Iterable</code> 的元素，你可以很容易地得到第一个或最后一个元素。</p>
<p>现在，你要学习如何使用 <code>firstWhere()</code> 来寻找满足某些条件的第一个元素。这个方法需要你传递一个谓词，它是一个函数，如果输入满足一定的条件就返回 true。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">element</span> <span class="o">=</span> <span class="n">iterable</span><span class="p">.</span><span class="n">firstWhere</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="m">5</span><span class="p">);</span>
</code></pre></div><p>例如，如果你想找到第一个超过 5 个字符的 <code>String</code>，你必须传递一个当元素大小大于 5 时返回 true 的谓词。</p>
<p>运行下面的例子，看看 <code>firstWhere()</code> 是如何工作的。你认为所有的函数都会给出相同的结果吗？</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">bool</span> <span class="n">predicate</span><span class="p">(</span><span class="kt">String</span> <span class="n">element</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="m">5</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Salad&#39;</span><span class="p">,</span> <span class="s1">&#39;Popcorn&#39;</span><span class="p">,</span> <span class="s1">&#39;Toast&#39;</span><span class="p">,</span> <span class="s1">&#39;Lasagne&#39;</span><span class="p">];</span>

  <span class="c1">// You can find with a simple expression:
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">element1</span> <span class="o">=</span> <span class="n">items</span><span class="p">.</span><span class="n">firstWhere</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="m">5</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="n">element1</span><span class="p">);</span>

  <span class="c1">// Or try using a function block:
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">element2</span> <span class="o">=</span> <span class="n">items</span><span class="p">.</span><span class="n">firstWhere</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="m">5</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="n">print</span><span class="p">(</span><span class="n">element2</span><span class="p">);</span>

  <span class="c1">// Or even pass in a function reference:
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">element3</span> <span class="o">=</span> <span class="n">items</span><span class="p">.</span><span class="n">firstWhere</span><span class="p">(</span><span class="n">predicate</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="n">element3</span><span class="p">);</span>

  <span class="c1">// You can also use an `orElse` function in case no value is found!
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">element4</span> <span class="o">=</span> <span class="n">items</span><span class="p">.</span><span class="n">firstWhere</span><span class="p">(</span>
    <span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="m">10</span><span class="p">,</span>
    <span class="nl">orElse:</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="s1">&#39;None!&#39;</span><span class="p">,</span>
  <span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="n">element4</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>在这个例子中，你可以看到三种不同的方式来写一个谓词。</p>
<ul>
<li><strong>作为一个表达式</strong>: 测试代码中有一行使用了箭头语法(<code>=&gt;</code>)。</li>
<li><strong>作为一个块</strong>: 测试代码在括号和返回语句之间有多行。</li>
<li><strong>作为一个函数</strong>: 测试代码在一个外部函数中，作为参数传递给 <code>firstWhere()</code> 方法。</li>
</ul>
<p>没有正确或错误的方式。使用最适合你的方式，并且让你的代码更容易阅读和理解。</p>
<p>在这个例子中，<code>firstWhereWithOrElse()</code> 调用 <code>firstWhere()</code> 时，使用了可选的命名参数 <code>orElse</code>，它在没有找到元素时提供了一个替代方案。在这种情况下，返回文本 &ldquo;None!&quot;，因为没有元素满足提供的条件。</p>
<p>注意：如果没有元素满足测试谓词，并且没有提供 <code>orElse</code> 参数，那么 <code>firstWhere()</code> 会抛出一个 <a href="https://api.dart.dev/stable/dart-core/StateError-class.html">StateError</a>。</p>
<p>快速回顾。</p>
<ul>
<li><code>Iterable</code> 的元素必须按顺序访问。</li>
<li>迭代所有元素的最简单方法是使用 <code>for-in</code> 循环。</li>
<li>你可以使用 <code>first</code> 和 <code>last</code> getters 来获取第一个和最后一个元素。</li>
<li>你也可以用 <code>firstWhere()</code> 找到满足条件的第一个元素。</li>
<li>你可以把测试谓词写成表达式、块或函数。</li>
</ul>
<p>关键术语。</p>
<p>谓词: 当某个条件被满足时，返回 <code>true</code> 的函数。</p>
<h3 id="练习-练习写一个测试谓词">练习: 练习写一个测试谓词</h3>
<p>下面的练习是一个失败的单元测试，其中包含一个部分完整的代码片段。你的任务是通过编写代码使测试通过来完成练习。你不需要实现 <code>main()</code>。</p>
<p>这个练习介绍了 <code>singleWhere()</code> 这个方法的工作原理类似于 <code>firstWhere()</code>，但在这种情况下，它只期望 <code>Iterable</code> 中的一个元素满足谓词。如果 <code>Iterable</code> 中超过一个或没有元素满足谓词条件，那么该方法会抛出一个 <a href="https://api.dart.dev/stable/dart-core/StateError-class.html">StateError</a> 异常。</p>
<p><code>singleWhere()</code> 对整个 <code>Iterable</code> 进行步进，直到最后一个元素，如果  <code>Iterable</code> 是无限的或包含一个大的元素集合，这可能会引起问题。</p>
<p>你的目标是实现满足以下条件的 <code>singleWhere()</code> 谓词。</p>
<ul>
<li>元素包含字符 &lsquo;a&rsquo;。</li>
<li>该元素以字符 &lsquo;M&rsquo; 开头。</li>
</ul>
<p>测试数据中的所有元素都是<a href="https://api.dart.dev/stable/dart-core/String-class.html">字符串</a>，你可以查看类文档以获得帮助。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">singleWhere</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">items</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">items</span><span class="p">.</span><span class="n">singleWhere</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">startsWith</span><span class="p">(</span><span class="s1">&#39;M&#39;</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">element</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div><h2 id="检查条件">检查条件</h2>
<p>在使用 <code>Iterable</code> 时，有时你需要验证一个集合的所有元素是否满足某些条件。</p>
<p>你可能会想用 <code>for-in</code> 循环来写一个解决方案，比如这个:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">item</span> <span class="k">in</span> <span class="n">items</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">length</span> <span class="o">&lt;</span> <span class="m">5</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
</code></pre></div><p>然而，你可以使用 <code>every()</code> 方法实现同样的目的:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">return</span> <span class="n">items</span><span class="p">.</span><span class="n">every</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;=</span> <span class="m">5</span><span class="p">);</span>
</code></pre></div><p>使用 <code>every()</code> 方法可以使代码更易读、更紧凑、更不容易出错。</p>
<h3 id="例子-使用-any-和-every">例子: 使用 any() 和 every()</h3>
<p><code>Iterable</code> 类提供了两个可以用来验证条件的方法。</p>
<ul>
<li><code>any()</code>: 如果至少有一个元素满足条件，则返回 true。</li>
<li><code>every()</code>: 如果所有元素都满足条件，则返回 true。</li>
</ul>
<p>运行这个练习来看看它们的作用。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Salad&#39;</span><span class="p">,</span> <span class="s1">&#39;Popcorn&#39;</span><span class="p">,</span> <span class="s1">&#39;Toast&#39;</span><span class="p">];</span>
  
  <span class="k">if</span> <span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)))</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;At least one element contains &#34;a&#34;&#39;</span><span class="p">);</span>
  <span class="p">}</span>
  
  <span class="k">if</span> <span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">every</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;=</span> <span class="m">5</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;All elements have length &gt;= 5&#39;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>在这个例子中，<code>any()</code> 验证了至少一个元素包含字符 a，<code>every()</code> 验证了所有元素的长度等于或大于 5。</p>
<p>运行代码后，尝试更改 <code>any()</code> 的谓词，使其返回 false:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">if</span> <span class="p">(</span><span class="n">items</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">element</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">element</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;Z&#39;</span><span class="p">)))</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;At least one element contains &#34;Z&#34;&#39;</span><span class="p">);</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;No element contains &#34;Z&#34;&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>你也可以使用 <code>any()</code> 来验证一个 <code>Iterable</code> 中没有元素满足某个条件。</p>
<h3 id="练习-验证一个-iterable-是否满足一个条件">练习： 验证一个 Iterable 是否满足一个条件</h3>
<p>下面的练习提供了使用前面例子中描述的 <code>any()</code> 和 <code>every()</code> 方法的练习。在本例中，你的工作对象是一组用户，由具有成员字段 <code>age</code> 的 <code>User</code> 对象表示。</p>
<p>使用 <code>any()</code> 和 <code>every()</code> 实现两个函数。</p>
<ul>
<li>第1部分：实现 <code>anyUserUnder18()</code>。
<ul>
<li>如果至少有一个用户是17岁或更小，则返回 true。</li>
</ul>
</li>
<li>第2部分：实现 <code>everyUserOver13()</code>。
<ul>
<li>如果所有用户都是14岁或以上，则返回 true。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">bool</span> <span class="n">anyUserUnder18</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">users</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">user</span><span class="p">.</span><span class="n">age</span> <span class="o">&lt;</span> <span class="m">18</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">bool</span> <span class="n">everyUserOver13</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">users</span><span class="p">.</span><span class="n">every</span><span class="p">((</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">user</span><span class="p">.</span><span class="n">age</span> <span class="o">&gt;</span> <span class="m">13</span><span class="p">);</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">User</span> <span class="p">{</span>
  <span class="kt">String</span> <span class="n">name</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">age</span><span class="p">;</span>

  <span class="n">User</span><span class="p">(</span>
    <span class="k">this</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
    <span class="k">this</span><span class="p">.</span><span class="n">age</span><span class="p">,</span>
  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>快速回顾:</p>
<ul>
<li>虽然你可以使用 <code>for-in</code> 循环来检查条件，但还有更好的方法。</li>
<li>方法 <code>any()</code> 可以让你检查任何元素是否满足条件。</li>
<li>方法 <code>every()</code> 可以让你验证所有元素是否满足条件。</li>
</ul>
<h2 id="过滤">过滤</h2>
<p>前面的章节介绍了 <code>firstWhere()</code> 或 <code>singleWhere()</code> 等方法，这些方法可以帮助你找到满足某个谓词的元素。</p>
<p>但是如果你想找到满足某个条件的所有元素呢？你可以使用 <code>where()</code> 方法来实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">evenNumbers</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span><span class="p">.</span><span class="n">isEven</span><span class="p">);</span>
</code></pre></div><p>在这个例子中，<code>numbers</code> 包含一个有多个 <code>int</code> 值的 <code>Iterable</code>，<code>where()</code> 可以找到所有偶数的数字。</p>
<p><code>where()</code> 的输出是另一个 <code>Iterable</code>，你可以用它来迭代它或应用其他 <code>Iterable</code> 方法。在下一个例子中，<code>where()</code> 的输出直接在 <code>for-in</code> 循环中使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">evenNumbers</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span><span class="p">.</span><span class="n">isEven</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">number</span> <span class="k">in</span> <span class="n">evenNumbers</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">$</span><span class="n">number</span><span class="s1"> is even&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h3 id="例子-使用-where">例子: 使用 where()</h3>
<p>运行这个例子，看看如何将 <code>where()</code> 与其他方法如 <code>any()</code> 一起使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">evenNumbers</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="o">-</span><span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">42</span><span class="p">].</span><span class="n">where</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span><span class="p">.</span><span class="n">isEven</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">number</span> <span class="k">in</span> <span class="n">evenNumbers</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">$</span><span class="n">number</span><span class="s1"> is even.&#39;</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">evenNumbers</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span><span class="p">.</span><span class="n">isNegative</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;evenNumbers contains negative numbers.&#39;</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="c1">// If no element satisfies the predicate, the output is empty.
</span><span class="c1"></span>  <span class="kd">var</span> <span class="n">largeNumbers</span> <span class="o">=</span> <span class="n">evenNumbers</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span> <span class="o">&gt;</span> <span class="m">1000</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">largeNumbers</span><span class="p">.</span><span class="n">isEmpty</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;largeNumbers is empty!&#39;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>在这个例子中，<code>where()</code> 用于查找所有偶数，然后用 <code>any()</code> 检查结果是否包含负数。</p>
<p>在本例的后面，再次使用 <code>where()</code> 来查找所有大于1000的数字，由于没有，结果是一个空的 <code>Iterable</code>。</p>
<p>注意：如果没有元素满足 <code>where()</code> 中的谓词，那么该方法返回一个空的 <code>Iterable</code>。与 <code>singleWhere()</code> 或 <code>firstWhere()</code> 不同，<code>where()</code> 不会抛出 <a href="https://api.dart.dev/stable/dart-core/StateError-class.html">StateError</a> 异常。</p>
<h3 id="例子-使用-takewhile">例子: 使用 takeWhile</h3>
<p>方法 <code>takeWhile()</code> 和 <code>skipWhile()</code> 也可以帮助你从一个 <code>Iterable</code> 中过滤元素。</p>
<p>运行这个例子，看看 <code>takeWhile()</code> 和 <code>skipWhile()</code> 如何分割一个包含数字的 <code>Iterable</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">numbers</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="o">-</span><span class="m">2</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="m">4</span><span class="p">,</span> <span class="m">5</span><span class="p">];</span>

  <span class="kd">var</span> <span class="n">numbersUntilZero</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">takeWhile</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span> <span class="o">!=</span> <span class="m">0</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Numbers until 0: </span><span class="si">$</span><span class="n">numbersUntilZero</span><span class="s1">&#39;</span><span class="p">);</span>

  <span class="kd">var</span> <span class="n">numbersAfterZero</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">skipWhile</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span> <span class="o">!=</span> <span class="m">0</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Numbers after 0: </span><span class="si">$</span><span class="n">numbersAfterZero</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>输出如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">Numbers until 0: (1, 3, -2)
Numbers after 0: (0, 4, 5)
</code></pre></div><p>在这个例子中，<code>takeWhile()</code> 返回一个 <code>Iterable</code>，它包含了通往满足谓词的元素的所有元素。另一方面， <code>skipWhile()</code> 返回一个 <code>Iterable</code>，同时跳过满足谓词的元素之前的所有元素。请注意，满足谓词的元素也会被包含在内。</p>
<p>运行该示例后，将 <code>takeWhile()</code> 改为取元素，直到到达第一个负数。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">numbersUntilNegative</span> <span class="o">=</span>
    <span class="n">numbers</span><span class="p">.</span><span class="n">takeWhile</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="o">!</span><span class="n">number</span><span class="p">.</span><span class="n">isNegative</span><span class="p">);</span>
</code></pre></div><p>注意，条件 <code>number.isNegative</code> 是用 <code>!</code> 否定的。</p>
<h3 id="练习-从列表中过滤元素">练习: 从列表中过滤元素</h3>
<p>下面的练习提供了使用上一练习中的 <code>User</code> 类的 <code>where()</code> 方法的练习。</p>
<p>使用 <code>where()</code> 实现两个函数。</p>
<ul>
<li>第1部分：实现 <code>filterUnder21()</code>。
<ul>
<li>返回一个包含所有21岁以上用户的 <code>Iterable</code>。</li>
</ul>
</li>
<li>第2部分：实现 <code>findShortNamed()</code>。
<ul>
<li>返回一个包含所有名字长度为 3 或更少的用户的 <code>Iterable</code>。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">filterUnder21</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">users</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">user</span><span class="p">.</span><span class="n">age</span> <span class="o">&gt;=</span> <span class="m">21</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">findShortNamed</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">users</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">user</span><span class="p">.</span><span class="n">name</span><span class="p">.</span><span class="n">length</span> <span class="o">&lt;=</span> <span class="m">3</span><span class="p">);</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">User</span> <span class="p">{</span>
  <span class="kt">String</span> <span class="n">name</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">age</span><span class="p">;</span>

  <span class="n">User</span><span class="p">(</span>
    <span class="k">this</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
    <span class="k">this</span><span class="p">.</span><span class="n">age</span><span class="p">,</span>
  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>快速回顾:</p>
<ul>
<li>用 <code>where()</code> 过滤一个 <code>Iterable</code> 的元素。</li>
<li><code>where()</code> 的输出是另一个 <code>Iterable</code>。</li>
<li>使用 <code>takeWhile()</code> 和 <code>skipWhile()</code> 来获取元素，直到满足一个条件或之后。</li>
<li>这些方法的输出可以是一个空的 <code>Iterable</code>。</li>
</ul>
<h2 id="map">Map</h2>
<p>通过 <code>map()</code> 方法映射 <code>Iterables</code>，你可以在每个元素上应用一个函数，用一个新的元素替换每个元素。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">map</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span> <span class="o">*</span> <span class="m">10</span><span class="p">);</span>
</code></pre></div><p>在这个例子中，<code>Iterable</code> 数字的每个元素都被乘以 10。</p>
<p>你也可以使用 <code>map()</code> 将一个元素转换为不同的对象-例如，将所有 <code>int</code> 转换为 <code>String</code>，在下面的例子中可以看到。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">.</span><span class="n">map</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span><span class="p">.</span><span class="n">toString</span><span class="p">());</span>
</code></pre></div><p>注意：<code>map()</code> 返回一个懒惰的 <code>Iterable</code>，这意味着只有在元素被迭代时才会调用所提供的函数。</p>
<h3 id="例子-使用-map-改变元素">例子: 使用 map 改变元素</h3>
<p>运行这个例子，看看如何使用 <code>map()</code> 将一个 <code>Iterable</code> 中的所有元素乘以2，你认为输出会是什么？</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">numbersByTwo</span> <span class="o">=</span> <span class="p">[</span><span class="m">1</span><span class="p">,</span> <span class="o">-</span><span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">42</span><span class="p">].</span><span class="n">map</span><span class="p">((</span><span class="n">number</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">number</span> <span class="o">*</span> <span class="m">2</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Numbers: </span><span class="si">$</span><span class="n">numbersByTwo</span><span class="s1">.&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h3 id="练习-映射到不同类型">练习: 映射到不同类型</h3>
<p>在前面的例子中，你把一个 <code>Iterable</code> 的元素乘以2，输入和输出都是 <code>int</code> 的 <code>Iterable</code>。</p>
<p>在这个练习中，你的代码接收一个 <code>User</code>的 <code>Iterable</code>，你需要返回一个包含用户名和年龄的字符串的 <code>Iterable</code>。</p>
<p><code>Iterable</code> 中的每个字符串必须遵循这样的格式。<code>'{name} is {age}'</code>-例如 <code>'Alice is 21'</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">getNameAndAges</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">User</span><span class="o">&gt;</span> <span class="n">users</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">users</span><span class="p">.</span><span class="n">map</span><span class="p">((</span><span class="n">user</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="s1">&#39;</span><span class="si">${</span><span class="n">user</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> is </span><span class="si">${</span><span class="n">user</span><span class="p">.</span><span class="n">age</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">User</span> <span class="p">{</span>
  <span class="kt">String</span> <span class="n">name</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">age</span><span class="p">;</span>

  <span class="n">User</span><span class="p">(</span>
    <span class="k">this</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
    <span class="k">this</span><span class="p">.</span><span class="n">age</span><span class="p">,</span>
  <span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>快速回顾:</p>
<ul>
<li><code>map()</code> 将一个函数应用于一个 <code>Iterable</code> 的所有元素。</li>
<li><code>map()</code> 的输出是另一个 <code>Iterable</code>。</li>
<li>在 <code>Iterable</code> 被迭代之前，函数不会被计算。</li>
</ul>
<h2 id="练习-把所有的东西放在一起">练习: 把所有的东西放在一起</h2>
<p>现在是练习所学知识的时候了，在最后一个练习中。</p>
<p>这个练习提供了类 <code>EmailAddress</code>，它有一个构造函数，接收一个字符串。另一个提供的函数是 <code>isValidEmailAddress()</code>，它测试一个电子邮件地址是否有效。</p>
<table>
<thead>
<tr>
<th style="text-align:left">构造函数/函数</th>
<th>类型签名</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">EmailAddress()</td>
<td>EmailAddress(String address)</td>
<td style="text-align:left">为指定的地址创建一个 EmailAddress。</td>
</tr>
<tr>
<td style="text-align:left">isValidEmailAddress()</td>
<td>bool isValidEmailAddress(EmailAddress)</td>
<td style="text-align:left">如果提供的 EmailAddress 有效，返回 true。</td>
</tr>
</tbody>
</table>
<p>编写以下代码。</p>
<p>第1部分：实现 <code>parseEmailAddresses()</code>。</p>
<ul>
<li>编写函数 <code>parseEmailAddresses()</code>，它接收一个包含电子邮件地址的 <code>Iterable&lt;String&gt;</code>，并返回一个 <code>Iterable&lt;EmailAddress&gt;</code>。</li>
<li>使用方法 <code>map()</code> 从 <code>String</code> 映射到 <code>EmailAddress</code>。</li>
<li>使用构造函数 <code>EmailAddress(String)</code> 创建 <code>EmailAddress</code> 对象。</li>
</ul>
<p>第二部分：实现 <code>anyInvalidEmailAddress()</code>。</p>
<ul>
<li>编写函数 <code>anyInvalidEmailAddress()</code>，它接收一个 <code>Iterable&lt;EmailAddress&gt;</code>，并在 <code>Iterable</code> 中的任何 <code>EmailAddress</code> 无效时返回 true。</li>
<li>使用方法 <code>any()</code> 和提供的函 <code>isValidEmailAddress()</code>。</li>
</ul>
<p>第3部分：实现 <code>validEmailAddresses()</code>。</p>
<ul>
<li>编写函数 <code>validEmailAddresses()</code>，它接收一个 <code>Iterable&lt;EmailAddress&gt;</code> 并返回另一个只包含有效地址的 <code>Iterable&lt;EmailAddress&gt;</code>。</li>
<li>使用方法 <code>where()</code> 来过滤 <code>Iterable&lt;EmailAddress&gt;</code>。</li>
<li>使用提供的函数 <code>isValidEmailAddress()</code> 来评估一个 <code>EmailAddress</code> 是否有效。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">EmailAddress</span><span class="o">&gt;</span> <span class="n">parseEmailAddresses</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">strings</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">strings</span><span class="p">.</span><span class="n">map</span><span class="p">((</span><span class="n">s</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">EmailAddress</span><span class="p">(</span><span class="n">s</span><span class="p">));</span>
<span class="p">}</span>

<span class="kt">bool</span> <span class="n">anyInvalidEmailAddress</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">EmailAddress</span><span class="o">&gt;</span> <span class="n">emails</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">emails</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">email</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="o">!</span><span class="n">isValidEmailAddress</span><span class="p">(</span><span class="n">email</span><span class="p">));</span>
<span class="p">}</span>

<span class="n">Iterable</span><span class="o">&lt;</span><span class="n">EmailAddress</span><span class="o">&gt;</span> <span class="n">validEmailAddresses</span><span class="p">(</span><span class="n">Iterable</span><span class="o">&lt;</span><span class="n">EmailAddress</span><span class="o">&gt;</span> <span class="n">emails</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">emails</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">email</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">isValidEmailAddress</span><span class="p">(</span><span class="n">email</span><span class="p">));</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">EmailAddress</span> <span class="p">{</span>
  <span class="kt">String</span> <span class="n">address</span><span class="p">;</span>

  <span class="n">EmailAddress</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">address</span><span class="p">);</span>

  <span class="err">@</span><span class="n">override</span>
  <span class="kt">bool</span> <span class="kd">operator</span> <span class="o">==</span><span class="p">(</span><span class="kt">Object</span> <span class="n">other</span><span class="p">)</span> <span class="o">=&gt;</span>
      <span class="n">identical</span><span class="p">(</span><span class="k">this</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">||</span>
          <span class="n">other</span> <span class="k">is</span> <span class="n">EmailAddress</span> <span class="o">&amp;&amp;</span>
              <span class="n">runtimeType</span> <span class="o">==</span> <span class="n">other</span><span class="p">.</span><span class="n">runtimeType</span> <span class="o">&amp;&amp;</span>
              <span class="n">address</span> <span class="o">==</span> <span class="n">other</span><span class="p">.</span><span class="n">address</span><span class="p">;</span>

  <span class="err">@</span><span class="n">override</span>
  <span class="kt">int</span> <span class="kd">get</span> <span class="n">hashCode</span> <span class="o">=&gt;</span> <span class="n">address</span><span class="p">.</span><span class="n">hashCode</span><span class="p">;</span>

  <span class="err">@</span><span class="n">override</span>
  <span class="kt">String</span> <span class="n">toString</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s1">&#39;EmailAddress{address: </span><span class="si">$</span><span class="n">address</span><span class="s1">}&#39;</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="下一步是什么">下一步是什么?</h2>
<p>恭喜你，你完成了 codelab 的学习! 如果你想了解更多，这里有一些下一步的建议。</p>
<ul>
<li>玩玩 <a href="https://dartpad.dev/">DartPad</a>。</li>
<li>试试另一个<a href="https://dart.dev/codelabs">代码实验</a>。</li>
<li>阅读 <a href="https://api.dart.dev/stable/dart-core/Iterable-class.html">Iterable API</a> 参考资料，了解本 codelab 未涉及的方法。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/iterable" term="iterable" label="iterable" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/collection" term="collection" label="collection" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dart" term="dart" label="dart" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Dart 语言速查表]]></title>
            <link href="https://ohmyweekly.github.io/notes/dart-cheatsheet-codelab/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/dart/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 入门" />
                <link href="https://ohmyweekly.github.io/notes/dart-iterable-collections/?utm_source=atom_feed" rel="related" type="text/html" title="Dart 可迭代集合" />
            
                <id>https://ohmyweekly.github.io/notes/dart-cheatsheet-codelab/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-25T00:00:00+08:00</published>
            <updated>2020-06-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote><a href="https://www.dartcn.com/">Dart</a>速查表。</blockquote><!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h2 id="字符串插值">字符串插值</h2>
<p>使用 <code>${expression}</code> 将表达式的值放到字符串里面。如果表达式是一个标识符, 就可以省略 <code>{}</code>。</p>
<p>下面是字符串插值的例子:</p>
<table>
<thead>
<tr>
<th style="text-align:left">字符串</th>
<th style="text-align:left">结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">&lsquo;${3 + 2}&rsquo;</td>
<td style="text-align:left">&lsquo;5&rsquo;</td>
</tr>
<tr>
<td style="text-align:left">&lsquo;${&ldquo;word&rdquo;.toUpperCase()}&rsquo;</td>
<td style="text-align:left">&lsquo;WORD&rsquo;</td>
</tr>
<tr>
<td style="text-align:left">&lsquo;$myObject&rsquo;</td>
<td style="text-align:left">The value of myObject.toString()</td>
</tr>
</tbody>
</table>
<h3 id="代码示例">代码示例</h3>
<p>下面的函数接收两个整数作为参数。使其返回一个包含两个整数的字符串，并以空格分隔。例如 <code>stringify(2, 3)</code> 应该返回 &lsquo;2 3&rsquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">stringify</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">$</span><span class="n">x</span><span class="s1"> </span><span class="si">$</span><span class="n">y</span><span class="s1">&#39;</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><h2 id="null-无感知操作符">Null 无感知操作符</h2>
<p>Dart 提供了一些方便的操作符来处理可能为空的值。其中一个是 <code>??=</code> 赋值运算符，只有当一个变量当前为空时，它才会给这个变量赋值:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">int</span> <span class="n">a</span><span class="p">;</span>    <span class="c1">// a 的初始值为 null
</span><span class="c1"></span><span class="n">a</span> <span class="o">??=</span> <span class="m">3</span><span class="p">;</span>
<span class="n">print</span><span class="p">(</span><span class="n">a</span><span class="p">);</span> <span class="c1">// 打印 3
</span><span class="c1"></span>
<span class="n">a</span> <span class="o">??=</span> <span class="m">5</span><span class="p">;</span>
<span class="n">print</span><span class="p">(</span><span class="n">a</span><span class="p">);</span> <span class="c1">// 仍然打印 3
</span></code></pre></div><p>另一个 null-aware 操作符是 <code>??</code>，它返回其左边的表达式，除非该表达式的值为 null，在这种情况下，它计算并返回其右边的表达式:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">print</span><span class="p">(</span><span class="m">1</span> <span class="o">??</span> <span class="m">3</span><span class="p">);</span>     <span class="c1">// 打印 1
</span><span class="c1"></span><span class="n">print</span><span class="p">(</span><span class="kc">null</span> <span class="o">??</span> <span class="m">12</span><span class="p">);</span> <span class="c1">// 打印 12 
</span></code></pre></div><h3 id="代码示例-1">代码示例</h3>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">String</span> <span class="n">foo</span> <span class="o">=</span> <span class="s1">&#39;a string&#39;</span><span class="p">;</span>
<span class="kt">String</span> <span class="n">bar</span><span class="p">;</span> <span class="c1">// Unassigned objects are null by default.
</span><span class="c1"></span>
<span class="c1">// makes &#39;a string&#39; be assigned to baz.
</span><span class="c1"></span><span class="kt">String</span> <span class="n">baz</span> <span class="o">=</span> <span class="n">foo</span> <span class="o">??</span> <span class="n">bar</span><span class="p">;</span>

<span class="kt">void</span> <span class="n">updateSomeVars</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// makes &#39;a string&#39; be assigned to bar.
</span><span class="c1"></span>  <span class="n">bar</span> <span class="o">??=</span> <span class="s1">&#39;a string&#39;</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><h2 id="有条件的属性访问">有条件的属性访问</h2>
<p>要保护对对象的一个可能为空的属性或方法的访问，请在点(.)前加上一个问号(?):</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">myObject</span><span class="o">?</span><span class="p">.</span><span class="n">someProperty</span>
</code></pre></div><p>上述代码等同于以下代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="p">(</span><span class="n">myObject</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="o">?</span> <span class="n">myObject</span><span class="p">.</span><span class="n">someProperty</span> <span class="o">:</span> <span class="kc">null</span>
</code></pre></div><p>你可以在一个表达式中把 <code>?.</code> 的多个使用链接在一起:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">myObject</span><span class="o">?</span><span class="p">.</span><span class="n">someProperty</span><span class="o">?</span><span class="p">.</span><span class="n">someMethod</span><span class="p">()</span>
</code></pre></div><p>如果 <code>myObject</code> 或 <code>myObject.someProperty</code> 为 null，前面的代码将返回 null(并且从不调用 <code>someMethod()</code>)。</p>
<h3 id="代码示例-2">代码示例</h3>
<p>尝试使用条件属性访问来完成下面的代码片段。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="c1">// This method should return the uppercase version of `str`
</span><span class="c1">// or null if `str` is null.
</span><span class="c1"></span><span class="kt">String</span> <span class="n">upperCaseIt</span><span class="p">(</span><span class="kt">String</span> <span class="n">str</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Try conditionally accessing the `toUpperCase` method here.
</span><span class="c1"></span>  <span class="k">return</span> <span class="n">str</span><span class="o">?</span><span class="p">.</span><span class="n">toUpperCase</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><h2 id="集合字面量">集合字面量</h2>
<p>Dart 内置了对列表、映射和集合的支持。你可以使用字面量创建它们:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">final</span> <span class="n">aListOfStrings</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;one&#39;</span><span class="p">,</span> <span class="s1">&#39;two&#39;</span><span class="p">,</span> <span class="s1">&#39;three&#39;</span><span class="p">];</span>
<span class="kd">final</span> <span class="n">aSetOfStrings</span>  <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;one&#39;</span><span class="p">,</span> <span class="s1">&#39;two&#39;</span><span class="p">,</span> <span class="s1">&#39;three&#39;</span><span class="p">};</span>
<span class="kd">final</span> <span class="n">aMapOfStringsToInts</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;one&#39;</span><span class="o">:</span> <span class="m">1</span><span class="p">,</span>
  <span class="s1">&#39;two&#39;</span><span class="o">:</span> <span class="m">2</span><span class="p">,</span>
  <span class="s1">&#39;three&#39;</span><span class="o">:</span> <span class="m">3</span><span class="p">,</span>  
<span class="p">}</span>
</code></pre></div><p>Dart 的类型推理可以为你分配类型给这些变量。在本例中，推断的类型是 <code>List&lt;String&gt;</code>、<code>Set&lt;String&gt;</code> 和 <code>Map&lt;String, int&gt;</code>。</p>
<p>或者你可以自己指定类型:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">final</span> <span class="n">aListOfInts</span> <span class="o">=</span> <span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">[];</span>
<span class="kd">final</span> <span class="n">aSetOfInts</span>  <span class="o">=</span> <span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">{};</span>
<span class="kd">final</span> <span class="n">aMapOfIntToDouble</span> <span class="o">=</span> <span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span><span class="p">{};</span>
</code></pre></div><p>当你用子类型的内容初始化一个列表，但仍然希望列表是 <code>List&lt;BaseType&gt;</code> 时，指定类型是很方便的:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">final</span> <span class="n">aListOfBaseType</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">BaseType</span><span class="o">&gt;</span><span class="p">[</span><span class="n">SubType</span><span class="p">(),</span> <span class="n">SubType</span><span class="p">()];</span>
</code></pre></div><h3 id="代码示例-3">代码示例</h3>
<p>尝试将以下变量设置为指定的值。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="c1">// Assign this a list containing &#39;a&#39;, &#39;b&#39;, and &#39;c&#39; in that order:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">aListOfStrings</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">];</span>

<span class="c1">// Assign this a set containing 3, 4, and 5:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">aSetOfInts</span> <span class="o">=</span> <span class="p">{</span><span class="m">3</span><span class="p">,</span> <span class="m">4</span><span class="p">,</span> <span class="m">5</span><span class="p">};</span>

<span class="c1">// Assign this a map of String to int so that aMapOfStringsToInts[&#39;myKey&#39;] returns 12:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">aMapOfStringsToInts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;myKey&#39;</span><span class="o">:</span> <span class="m">12</span><span class="p">};</span>

<span class="c1">// Assign this an empty List&lt;double&gt;:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">anEmptyListOfDouble</span> <span class="o">=</span> <span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">[];</span>

<span class="c1">// Assign this an empty Set&lt;String&gt;:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">anEmptySetOfString</span> <span class="o">=</span> <span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span><span class="p">{};</span>

<span class="c1">// Assign this an empty Map of double to int:
</span><span class="c1"></span><span class="kd">final</span> <span class="n">anEmptyMapOfDoublesToInts</span> <span class="o">=</span> <span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="kt">int</span><span class="o">&gt;</span><span class="p">{};</span>
</code></pre></div><h2 id="箭头语法">箭头语法</h2>
<p>你可能在 Dart 代码中看到过 <code>=&gt;</code> 符号。这种箭头语法是一种定义函数的方式，该函数执行其右边的表达式并返回其值。</p>
<p>例如，考虑这个对 <code>List</code> 类的 <code>any()</code> 方法的调用:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">bool</span> <span class="n">hasEmpty</span> <span class="o">=</span> <span class="n">aListOfStrings</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">s</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">s</span><span class="p">.</span><span class="n">isEmpty</span><span class="p">;</span>
<span class="p">});</span>
</code></pre></div><p>这里有一个更简单的方法来写这个代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">bool</span> <span class="n">hasEmpty</span> <span class="o">=</span> <span class="n">aListOfStrings</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">s</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">s</span><span class="p">.</span><span class="n">isEmpty</span><span class="p">);</span>
</code></pre></div><h3 id="代码示例-4">代码示例</h3>
<p>试着完成以下使用箭头语法的语句:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyClass</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">_value1</span> <span class="o">=</span> <span class="m">2</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">_value2</span> <span class="o">=</span> <span class="m">3</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">_value3</span> <span class="o">=</span> <span class="m">5</span><span class="p">;</span>

  <span class="c1">// Returns the product of the above values:
</span><span class="c1"></span>  <span class="kt">int</span> <span class="kd">get</span> <span class="n">product</span> <span class="o">=&gt;</span> <span class="n">_value1</span> <span class="o">*</span> <span class="n">_value2</span> <span class="o">*</span> <span class="n">_value3</span><span class="p">;</span>
  
  <span class="c1">// Adds one to _value1:
</span><span class="c1"></span>  <span class="kt">void</span> <span class="n">incrementValue1</span><span class="p">()</span> <span class="o">=&gt;</span> <span class="n">_value1</span><span class="o">++</span><span class="p">;</span> 
  
  <span class="c1">// Returns a string containing each item in the
</span><span class="c1"></span>  <span class="c1">// list, separated by commas (e.g. &#39;a,b,c&#39;): 
</span><span class="c1"></span>  <span class="kt">String</span> <span class="n">joinWithCommas</span><span class="p">(</span><span class="n">List</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">strings</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">strings</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="级联">级联</h2>
<p>要对同一对象进行一系列操作，可以使用级联(<code>...</code>)。我们都见过这样的表达式:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">myObject</span><span class="p">.</span><span class="n">someMethod</span><span class="p">()</span>
</code></pre></div><p>它在 <code>myObject</code> 上调用 <code>someMethod()</code>，表达式的结果是 <code>someMethod()</code> 的返回值。</p>
<p>下面是同样的表达式，有一个级联:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">myObject</span><span class="p">..</span><span class="n">someMethod</span><span class="p">()</span>
</code></pre></div><p>虽然它仍然在 <code>myObject</code> 上调用 <code>someMethod()</code>，但表达式的结果并不是返回值-它是对 <code>myObject</code> 的引用! 使用级联，你可以将原本需要单独语句的操作串联起来。例如，请看以下代码:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">var</span> <span class="n">button</span> <span class="o">=</span> <span class="n">querySelector</span><span class="p">(</span><span class="s1">&#39;#confirm&#39;</span><span class="p">);</span>
<span class="n">button</span><span class="p">.</span><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;Confirm&#39;</span><span class="p">;</span>
<span class="n">button</span><span class="p">.</span><span class="n">classes</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;important&#39;</span><span class="p">);</span>
<span class="n">button</span><span class="p">.</span><span class="n">onClick</span><span class="p">.</span><span class="n">listen</span><span class="p">((</span><span class="n">e</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">window</span><span class="p">.</span><span class="n">alert</span><span class="p">(</span><span class="s1">&#39;Confirmed!&#39;</span><span class="p">));</span>
</code></pre></div><p>有了级联，代码就会变得短得多，而且你也不需要 <code>button</code> 变量:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">querySelector</span><span class="p">(</span><span class="s1">&#39;#confirm&#39;</span><span class="p">)</span>
<span class="p">..</span><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;Confirm&#39;</span>
<span class="p">..</span><span class="n">class</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;important&#39;</span><span class="p">)</span>
<span class="p">..</span><span class="n">onClick</span><span class="p">.</span><span class="n">listen</span><span class="p">((</span><span class="n">e</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">window</span><span class="p">.</span><span class="n">alert</span><span class="p">(</span><span class="s1">&#39;Confirmed!&#39;</span><span class="p">));</span>
</code></pre></div><h3 id="代码示例-5">代码示例</h3>
<p>使用级联来创建一个单一的语句，将一个 <code>BigObject</code> 的 <code>anInt</code>、<code>aString</code> 和 <code>aList</code> 属性设置为 1、&lsquo;String!&rsquo; 和 <code>[3.0]</code>(分别地)，然后调用 <code>allDone()</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">BigObject</span><span class="p">{</span>
  <span class="kt">int</span> <span class="n">anInt</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>
  <span class="kt">String</span> <span class="n">aString</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">;</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">aList</span> <span class="o">=</span> <span class="p">[];</span>
  <span class="kt">bool</span> <span class="n">_done</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>

  <span class="kt">void</span> <span class="n">allDone</span><span class="p">()</span> <span class="p">{</span>
      <span class="n">_done</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
  <span class="p">}</span>    
<span class="p">}</span>

<span class="n">BigObject</span> <span class="n">fillBigObject</span><span class="p">(</span><span class="n">BigObject</span> <span class="n">obj</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">obj</span>
      <span class="p">..</span><span class="n">anInt</span> <span class="o">=</span> <span class="m">1</span>
      <span class="p">..</span><span class="n">aString</span> <span class="o">=</span> <span class="s1">&#39;String!&#39;</span>
      <span class="p">..</span><span class="n">aList</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="m">3</span><span class="p">)</span>
      <span class="p">..</span><span class="n">allDone</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><h2 id="getters-和-setters">getters 和 setters</h2>
<p>当你需要对一个属性进行更多的控制时，你可以定义 getter 和 setter，而不是简单的字段。</p>
<p>例如，你可以确保一个属性的值是有效的:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyClass</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">_aProperty</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>

  <span class="kt">int</span> <span class="kd">get</span> <span class="n">aProperty</span> <span class="o">=&gt;</span> <span class="n">_aProperty</span><span class="p">;</span>

  <span class="kd">set</span> <span class="n">aProperty</span><span class="p">(</span><span class="kt">int</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">value</span> <span class="o">&gt;=</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">_aProperty</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>    
    <span class="p">}</span>    
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>你也可以使用 getter 来定义计算属性:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyClass</span> <span class="p">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">_values</span> <span class="o">=</span> <span class="p">[];</span>

  <span class="kt">void</span> <span class="n">addValue</span><span class="p">(</span><span class="kt">int</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">_values</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>    
  <span class="p">}</span>

  <span class="c1">// 一个计算属性
</span><span class="c1"></span>  <span class="kt">int</span> <span class="kd">get</span> <span class="n">count</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">_values</span><span class="p">.</span><span class="n">length</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-6">代码示例</h3>
<p>想象一下，你有一个购物车类，它保存了一个私有的 <code>List&lt;double&gt;</code> 的价格。添加以下内容:</p>
<ul>
<li>一个叫做 <code>total</code> 的 getter，返回价格的总和。</li>
<li>用一个新的列表替换列表的 setter，只要新的列表不包含任何负价格(在这种情况下，setter 应该抛出一个 <code>InvalidPriceException</code>)。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">InvalidPriceException</span> <span class="p">{}</span>

<span class="kd">class</span> <span class="nc">ShoppingCart</span> <span class="p">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">_prices</span> <span class="o">=</span> <span class="p">[];</span>
  
  <span class="kt">double</span> <span class="kd">get</span> <span class="n">total</span> <span class="o">=&gt;</span> <span class="n">_prices</span><span class="p">.</span><span class="n">fold</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">e</span> <span class="o">+</span> <span class="n">t</span><span class="p">);</span>
  
  <span class="kd">set</span> <span class="n">prices</span><span class="p">(</span><span class="n">List</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">value</span><span class="p">.</span><span class="n">any</span><span class="p">((</span><span class="n">p</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="m">0</span><span class="p">))</span> <span class="p">{</span>
      <span class="k">throw</span> <span class="n">InvalidPriceException</span><span class="p">();</span>
    <span class="p">}</span>
    
    <span class="n">_prices</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="可选位置参数">可选位置参数</h2>
<p>Dart 有两种函数参数：位置参数和命名参数。位置参数是你可能熟悉的那种:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">int</span> <span class="n">sumUp</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">c</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>  <span class="o">+</span> <span class="n">c</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// ...
</span><span class="c1"></span><span class="kt">int</span> <span class="n">total</span> <span class="o">=</span> <span class="n">sumUp</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">);</span>
</code></pre></div><p>在 Dart 中，你可以将这些位置参数用括号包裹起来，使其成为可选的参数:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">int</span> <span class="n">sumUpToFive</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">d</span><span class="p">,</span> <span class="kt">int</span> <span class="n">e</span><span class="p">])</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span> <span class="o">+=</span> <span class="n">b</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">c</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span> <span class="o">+=</span> <span class="n">c</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">d</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span> <span class="o">+=</span> <span class="n">d</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">e</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span> <span class="o">+=</span> <span class="n">e</span><span class="p">;</span>
  <span class="k">return</span> <span class="n">sum</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// ...
</span><span class="c1"></span><span class="kt">int</span> <span class="n">total</span> <span class="o">=</span> <span class="n">sumUpToFive</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">);</span>
<span class="kt">int</span> <span class="n">otherTotal</span> <span class="o">=</span> <span class="n">sumUpToFive</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">4</span><span class="p">,</span> <span class="m">5</span><span class="p">);</span>
</code></pre></div><p>可选的位置参数在函数的参数列表中总是最后一个。它们的默认值是空的，除非你提供了另一个默认值:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">int</span> <span class="n">sumUpToFive</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="kt">int</span> <span class="n">b</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="kt">int</span> <span class="n">c</span> <span class="o">=</span> <span class="m">3</span><span class="p">,</span> <span class="kt">int</span> <span class="n">d</span> <span class="o">=</span> <span class="m">4</span><span class="p">,</span> <span class="kt">int</span> <span class="n">e</span> <span class="o">=</span> <span class="m">5</span><span class="p">])</span> <span class="p">{</span>
<span class="c1">// ···
</span><span class="c1"></span><span class="p">}</span>
<span class="c1">// ···
</span><span class="c1"></span><span class="kt">int</span> <span class="n">newTotal</span> <span class="o">=</span> <span class="n">sumUpToFive</span><span class="p">(</span><span class="m">1</span><span class="p">);</span>
<span class="n">print</span><span class="p">(</span><span class="n">newTotal</span><span class="p">);</span> <span class="c1">// &lt;-- prints 15
</span></code></pre></div><h3 id="代码示例-7">代码示例</h3>
<p>实现一个名为 <code>joinWithCommas()</code> 的函数，接受 1 到 5 个整数，然后返回一个用逗号分隔的数字字符串。下面是一些函数调用和返回值的例子:</p>
<table>
<thead>
<tr>
<th style="text-align:left">函数调用</th>
<th style="text-align:left">返回值</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">joinWithCommas(1)</td>
<td style="text-align:left">&lsquo;1&rsquo;</td>
</tr>
<tr>
<td style="text-align:left">joinWithCommas(1, 2, 3)</td>
<td style="text-align:left">&lsquo;1,2,3&rsquo;</td>
</tr>
<tr>
<td style="text-align:left">joinWithCommas(1, 1, 1, 1, 1)</td>
<td style="text-align:left">&lsquo;1,1,1,1,1&rsquo;</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="n">res</span> <span class="o">=</span> <span class="n">joinWithCommas</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">4</span><span class="p">);</span>
  <span class="n">print</span><span class="p">(</span><span class="n">res</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">String</span> <span class="n">joinWithCommas</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">d</span><span class="p">,</span> <span class="kt">int</span> <span class="n">e</span><span class="p">])</span> <span class="p">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">sum</span> <span class="o">=</span> <span class="p">[];</span>
  <span class="n">sum</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">b</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">c</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">d</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">d</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">e</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="n">sum</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="p">);</span>

  <span class="k">return</span> <span class="n">sum</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="可选命名参数">可选命名参数</h2>
<p>使用大括号语法，你可以定义有名称的可选参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">printName</span><span class="p">(</span><span class="kt">String</span> <span class="n">firstName</span><span class="p">,</span> <span class="kt">String</span> <span class="n">lastName</span><span class="p">,</span> <span class="p">{</span><span class="kt">String</span> <span class="n">suffix</span><span class="p">})</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">$</span><span class="n">firstName</span><span class="s1"> </span><span class="si">$</span><span class="n">lastName</span><span class="s1"> </span><span class="si">${</span><span class="n">suffix</span> <span class="o">??</span> <span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// ···
</span><span class="c1"></span><span class="n">printName</span><span class="p">(</span><span class="s1">&#39;Avinash&#39;</span><span class="p">,</span> <span class="s1">&#39;Gupta&#39;</span><span class="p">);</span>
<span class="n">printName</span><span class="p">(</span><span class="s1">&#39;Poshmeister&#39;</span><span class="p">,</span> <span class="s1">&#39;Moneybuckets&#39;</span><span class="p">,</span> <span class="nl">suffix:</span> <span class="s1">&#39;IV&#39;</span><span class="p">);</span>
</code></pre></div><p>正如你所期望的，这些参数的值默认为空，但你可以提供默认值。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kt">void</span> <span class="n">printName</span><span class="p">(</span><span class="kt">String</span> <span class="n">firstName</span><span class="p">,</span> <span class="kt">String</span> <span class="n">lastName</span><span class="p">,</span> <span class="p">{</span><span class="kt">String</span> <span class="n">suffix</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">})</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">$</span><span class="n">firstName</span><span class="s1"> </span><span class="si">$</span><span class="n">lastName</span><span class="s1"> </span><span class="si">$</span><span class="n">suffix</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p>一个函数不能同时拥有可选的位置参数和可选的命名参数。</p>
<h3 id="代码示例-8">代码示例</h3>
<p>为 <code>MyDataObject</code> 类添加一个 <code>copyWith()</code> 实例方法。它应该接受三个命名参数:</p>
<ul>
<li>int newInt</li>
<li>String newString</li>
<li>double newDouble</li>
</ul>
<p>当调用时，<code>copyWith()</code> 应该基于当前实例返回一个新的 <code>MyDataObject</code>，并将前面参数（如果有的话）的数据复制到对象的属性中。例如，如果 <code>newInt</code> 是非空的，那么将其值复制到 <code>anInt</code> 中。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyDataObject</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">anInt</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">String</span> <span class="n">aString</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">double</span> <span class="n">aDouble</span><span class="p">;</span>

  <span class="n">MyDataObject</span><span class="p">({</span>
     <span class="k">this</span><span class="p">.</span><span class="n">anInt</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span>
     <span class="k">this</span><span class="p">.</span><span class="n">aString</span> <span class="o">=</span> <span class="s1">&#39;Old!&#39;</span><span class="p">,</span>
     <span class="k">this</span><span class="p">.</span><span class="n">aDouble</span> <span class="o">=</span> <span class="m">2.0</span><span class="p">,</span>
  <span class="p">});</span>

  <span class="n">MyDataObject</span> <span class="n">copyWith</span><span class="p">({</span><span class="kt">int</span> <span class="n">newInt</span><span class="p">,</span> <span class="kt">String</span> <span class="n">newString</span><span class="p">,</span> <span class="kt">double</span> <span class="n">newDouble</span><span class="p">})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MyDataObject</span><span class="p">(</span>
      <span class="nl">anInt:</span>      <span class="n">newInt</span> <span class="o">??</span> <span class="k">this</span><span class="p">.</span><span class="n">anInt</span><span class="p">,</span>
      <span class="nl">aString:</span> <span class="n">newString</span> <span class="o">??</span> <span class="k">this</span><span class="p">.</span><span class="n">aString</span><span class="p">,</span>
      <span class="nl">aDouble:</span> <span class="n">newDouble</span> <span class="o">??</span> <span class="k">this</span><span class="p">.</span><span class="n">aDouble</span><span class="p">,</span>
    <span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="异常">异常</h2>
<p>Dart 代码可以抛出和捕获异常。与 Java 相比，Dart 的所有异常都是未检查的异常。方法不声明它们可能会抛出哪些异常，你也不需要捕捉任何异常。</p>
<p>Dart 提供了 <code>Exception</code> 和 <code>Error</code> 类型，但你可以抛出任何非空对象:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">throw</span> <span class="n">Exception</span><span class="p">(</span><span class="s1">&#39;Something bad happened.&#39;</span><span class="p">);</span>
<span class="k">throw</span> <span class="s1">&#39;Waaaaaaah!&#39;</span><span class="p">;</span>
</code></pre></div><p>在处理异常时使用 <code>try</code>、<code>on</code> 和 <code>catch</code> 关键字:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">try</span> <span class="p">{</span>
  <span class="n">breedMoreLlamas</span><span class="p">();</span>
<span class="p">}</span> <span class="n">on</span> <span class="n">OutOfLlamasException</span> <span class="p">{</span>
  <span class="c1">// A specific exception
</span><span class="c1"></span>  <span class="n">buyMoreLlamas</span><span class="p">();</span>
<span class="p">}</span> <span class="n">on</span> <span class="n">Exception</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Anything else that is an exception
</span><span class="c1"></span>  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Unknown exception: </span><span class="si">$</span><span class="n">e</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// No specified type, handles all
</span><span class="c1"></span>  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;Something really unknown: </span><span class="si">$</span><span class="n">e</span><span class="s1">&#39;</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><p><code>try</code> 关键字的工作原理和其他大多数语言一样。使用 <code>on</code> 关键字按类型过滤特定的异常，使用 <code>catch</code> 关键字获取异常对象的引用。</p>
<p>如果不能完全处理异常，可以使用 <code>rethrow</code> 关键字来传播异常:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">try</span> <span class="p">{</span>
  <span class="n">breedMoreLlamas</span><span class="p">();</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;I was just trying to breed llamas!.&#39;</span><span class="p">);</span>
  <span class="n">rethrow</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><p>无论是否抛出异常，都要执行代码，使用 <code>final</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="k">try</span> <span class="p">{</span>
  <span class="n">breedMoreLlamas</span><span class="p">();</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// ... handle exception ...
</span><span class="c1"></span><span class="p">}</span> <span class="k">finally</span> <span class="p">{</span>
  <span class="c1">// Always clean up, even if an exception is thrown.
</span><span class="c1"></span>  <span class="n">cleanLlamaStalls</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-9">代码示例</h3>
<p>实现下面的 <code>tryFunction()</code>。它应该执行一个不可信的方法，然后做如下操作:</p>
<ul>
<li>如果 <code>untrustworthy()</code> 抛出一个 <code>ExceptionWithMessage</code>，调用 <code>logger.logException</code>，并提供异常类型和消息(尝试使用 <code>on</code> 和 <code>catch</code>)。</li>
<li>如果 <code>untrustworthy()</code> 抛出一个 <code>Exceptio</code>n，调用 <code>logger.logException</code>，并注明异常类型(尝试使用 <code>on</code>)。</li>
<li>如果 <code>untrustworthy()</code> 抛出任何其他对象，不要捕获异常。</li>
<li>当所有的东西都被捕获和处理后，调用 <code>logger.doneLogging</code>(尝试使用 <code>finally</code>)。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">typedef</span> <span class="n">VoidFunction</span> <span class="o">=</span> <span class="kt">void</span> <span class="n">Function</span><span class="p">();</span>

<span class="kd">class</span> <span class="nc">ExceptionWithMessage</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">String</span> <span class="n">message</span><span class="p">;</span>
  <span class="kd">const</span> <span class="n">ExceptionWithMessage</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">message</span><span class="p">);</span>
<span class="p">}</span>

<span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">Logger</span> <span class="p">{</span>
  <span class="kt">void</span> <span class="n">logException</span><span class="p">(</span><span class="n">Type</span> <span class="n">t</span><span class="p">,</span> <span class="p">[</span><span class="kt">String</span> <span class="n">msg</span><span class="p">]);</span>
  <span class="kt">void</span> <span class="n">doneLogging</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">tryFunction</span><span class="p">(</span><span class="n">VoidFunction</span> <span class="n">untrustworthy</span><span class="p">,</span> <span class="n">Logger</span> <span class="n">logger</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="n">untrustworthy</span><span class="p">();</span>
  <span class="p">}</span> <span class="n">on</span> <span class="n">ExceptionWithMessage</span> <span class="k">catch</span> <span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">logException</span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">runtimeType</span><span class="p">,</span> <span class="n">e</span><span class="p">.</span><span class="n">message</span><span class="p">);</span>
  <span class="p">}</span> <span class="n">on</span> <span class="n">Exception</span> <span class="p">{</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">logException</span><span class="p">(</span><span class="n">Exception</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">finally</span> <span class="p">{</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">doneLogging</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><h2 id="在构造函数中使用-this">在构造函数中使用 <code>this</code></h2>
<p>Dart 提供了一个方便的快捷方式来为构造函数中的属性赋值：在声明构造函数时使用 <code>this.propertyName</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyColor</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">red</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">green</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">blue</span><span class="p">;</span>

  <span class="n">MyColor</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">red</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span><span class="p">)</span>    
<span class="p">}</span>

<span class="kd">final</span> <span class="n">color</span> <span class="o">=</span> <span class="n">MyColor</span><span class="p">(</span><span class="m">80</span><span class="p">,</span> <span class="m">80</span><span class="p">,</span> <span class="m">128</span><span class="p">);</span>
</code></pre></div><p>这种技术也适用于命名参数。属性名成为参数的名称:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyColor</span> <span class="p">{</span>
  <span class="p">...</span>
  <span class="n">MyColor</span><span class="p">({</span><span class="k">this</span><span class="p">.</span><span class="n">red</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span><span class="p">});</span>    
<span class="p">}</span>
<span class="kd">final</span> <span class="n">color</span> <span class="o">=</span> <span class="n">MyColor</span><span class="p">(</span><span class="nl">red:</span> <span class="m">80</span><span class="p">,</span> <span class="nl">green:</span> <span class="m">80</span><span class="p">,</span> <span class="nl">blue:</span> <span class="m">80</span><span class="p">);</span>
</code></pre></div><p>对于可选参数，默认值按预期工作:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">MyColor</span><span class="p">([</span><span class="k">this</span><span class="p">.</span><span class="n">red</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span> <span class="o">=</span> <span class="m">0</span><span class="p">]);</span>
<span class="c1">// or
</span><span class="c1"></span><span class="n">MyColor</span><span class="p">({</span><span class="k">this</span><span class="p">.</span><span class="n">red</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span> <span class="o">=</span> <span class="m">0</span><span class="p">});</span>
</code></pre></div><h3 id="代码示例-10">代码示例</h3>
<p>为 <code>MyClass</code> 添加一个单行构造函数，使用 <code>this.</code> 语法来接收和分配类的三个属性的值:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">MyClass</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">anInt</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">String</span> <span class="n">aString</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">double</span> <span class="n">aDouble</span><span class="p">;</span>
  
  <span class="n">MyClass</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">anInt</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">aString</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">aDouble</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="初始化器列表">初始化器列表</h2>
<p>有时候，当你实现一个构造函数时，你需要在构造函数体执行之前做一些设置。例如，在构造函数体执行之前，<code>final</code> 字段必须有值。在一个初始化器列表中做这些工作，它位于构造函数的签名和它的主体之间。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">Point</span><span class="p">.</span><span class="n">fromJson</span><span class="p">(</span><span class="n">Map</span><span class="o">&lt;</span><span class="kt">String</span><span class="p">,</span> <span class="kt">num</span><span class="o">&gt;</span> <span class="n">json</span><span class="p">)</span>
    <span class="o">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">json</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">json</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;In Point.fromJson(): (</span><span class="si">$</span><span class="n">x</span><span class="s1">, </span><span class="si">$</span><span class="n">y</span><span class="s1">)&#39;</span><span class="p">);</span>  
<span class="p">}</span>
</code></pre></div><p>初始化器列表也是一个方便放置断言的地方，它只在开发过程中运行:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="n">NonNegativePoint</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
    <span class="o">:</span> <span class="k">assert</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="m">0</span><span class="p">),</span>
      <span class="k">assert</span><span class="p">(</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">print</span><span class="p">(</span><span class="s1">&#39;I just made a NonNegativePoint: (</span><span class="si">$</span><span class="n">x</span><span class="s1">, </span><span class="si">$</span><span class="n">y</span><span class="s1">)&#39;</span><span class="p">);</span>        
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-11">代码示例</h3>
<p>完成下面的 <code>FirstTwoLetters</code> 构造函数。使用初始化器列表将 <code>word</code> 中的前两个字符分配给 <code>letterOne</code> 和 <code>LetterTwo</code> 属性。为了获得额外的积分，可以添加一个断言来捕获少于两个字符的单词。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">FirstTwoLetters</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">String</span> <span class="n">letterOne</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">String</span> <span class="n">letterTwo</span><span class="p">;</span>

  <span class="c1">// Create a constructor with an initializer list here:
</span><span class="c1"></span>  <span class="n">FirstTwoLetters</span><span class="p">(</span><span class="kt">String</span> <span class="n">word</span><span class="p">)</span>
    <span class="o">:</span> <span class="k">assert</span><span class="p">(</span><span class="n">word</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;=</span><span class="m">2</span><span class="p">),</span>
      <span class="n">letterOne</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="m">0</span><span class="p">],</span>
      <span class="n">letterTwo</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="m">1</span><span class="p">];</span> 
<span class="p">}</span>
</code></pre></div><h2 id="命名构造器">命名构造器</h2>
<p>为了允许类有多个构造函数，Dart 支持命名构造函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Point</span> <span class="p">{</span>
  <span class="kt">double</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>

  <span class="n">Point</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">y</span><span class="p">);</span>

  <span class="n">Point</span><span class="p">.</span><span class="n">origin</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">x</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>    
  <span class="p">}</span>    
<span class="p">}</span>
</code></pre></div><p>要使用命名构造函数，请使用它的全名来调用它:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">final</span> <span class="n">myPoint</span> <span class="o">=</span> <span class="n">Point</span><span class="p">.</span><span class="n">origin</span><span class="p">();</span>
</code></pre></div><h3 id="代码示例-12">代码示例</h3>
<p>给 <code>Color</code> 类一个名为 <code>Color.black</code> 的构造函数，将三个属性都设置为 0。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Color</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">red</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">green</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">blue</span><span class="p">;</span>
  
  <span class="n">Color</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">red</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span><span class="p">);</span>

  <span class="n">Color</span><span class="p">.</span><span class="n">black</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">red</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>
    <span class="n">green</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>
    <span class="n">blue</span> <span class="o">=</span> <span class="m">0</span><span class="p">;</span>
  <span class="p">}</span> 
<span class="p">}</span>
</code></pre></div><h2 id="工厂构造函数">工厂构造函数</h2>
<p>Dart 支持工厂构造函数，它可以返回子类型甚至 null。要创建一个工厂构造函数，请使用 <code>factory</code> 关键字:</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Square</span> <span class="kd">extends</span> <span class="n">Shape</span> <span class="p">{}</span>

<span class="kd">class</span> <span class="nc">Circle</span> <span class="kd">extends</span> <span class="n">Shape</span> <span class="p">{}</span>

<span class="kd">class</span> <span class="nc">Shape</span> <span class="p">{</span>
  <span class="n">Shape</span><span class="p">();</span>

  <span class="kd">factory</span> <span class="n">Shape</span><span class="p">.</span><span class="n">fromTypeName</span><span class="p">(</span><span class="kt">String</span> <span class="n">typeName</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">typeName</span> <span class="o">==</span> <span class="s1">&#39;square&#39;</span><span class="p">)</span> <span class="k">return</span> <span class="n">Square</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">typeName</span> <span class="o">==</span> <span class="s1">&#39;circle&#39;</span><span class="p">)</span> <span class="k">return</span> <span class="n">Circle</span><span class="p">();</span>

    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;I don</span><span class="se">\&#39;</span><span class="s1">t recognize </span><span class="si">$</span><span class="n">typeName</span><span class="s1">&#39;</span><span class="p">);</span>
    <span class="k">return</span> <span class="kc">null</span>
  <span class="p">}</span>    
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-13">代码示例</h3>
<p>填入名为 <code>IntegerHolder.fromList</code> 的工厂构造函数，使其做以下工作:</p>
<ul>
<li>如果列表有一个值，就用这个值创建一个 <code>IntegerSingle</code>。</li>
<li>如果列表有两个值，则用该值依次创建一个 <code>IntegerDouble</code>。</li>
<li>如果列表有三个值，则按顺序创建一个 <code>IntegerTriple</code>。</li>
<li>否则，返回 null。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">IntegerHolder</span> <span class="p">{</span>
  <span class="n">IntegerHolder</span><span class="p">();</span>
  
  <span class="kd">factory</span> <span class="n">IntegerHolder</span><span class="p">.</span><span class="n">fromList</span><span class="p">(</span><span class="n">List</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">list</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">?</span><span class="p">.</span><span class="n">length</span> <span class="o">==</span> <span class="m">1</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="n">IntegerSingle</span><span class="p">(</span><span class="n">list</span><span class="p">[</span><span class="m">0</span><span class="p">]);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">?</span><span class="p">.</span><span class="n">length</span> <span class="o">==</span> <span class="m">2</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="n">IntegerDouble</span><span class="p">(</span><span class="n">list</span><span class="p">[</span><span class="m">0</span><span class="p">],</span> <span class="n">list</span><span class="p">[</span><span class="m">1</span><span class="p">]);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">?</span><span class="p">.</span><span class="n">length</span> <span class="o">==</span> <span class="m">3</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="n">IntegerTriple</span><span class="p">(</span><span class="n">list</span><span class="p">[</span><span class="m">0</span><span class="p">],</span> <span class="n">list</span><span class="p">[</span><span class="m">1</span><span class="p">],</span> <span class="n">list</span><span class="p">[</span><span class="m">2</span><span class="p">]);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">return</span> <span class="kc">null</span><span class="p">;</span>
    <span class="p">}</span> 
  <span class="p">}</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">IntegerSingle</span> <span class="kd">extends</span> <span class="n">IntegerHolder</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">a</span><span class="p">;</span>
  <span class="n">IntegerSingle</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">a</span><span class="p">);</span> 
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">IntegerDouble</span> <span class="kd">extends</span> <span class="n">IntegerHolder</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">a</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">b</span><span class="p">;</span>
  <span class="n">IntegerDouble</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">a</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">b</span><span class="p">);</span> 
<span class="p">}</span>

<span class="kd">class</span> <span class="nc">IntegerTriple</span> <span class="kd">extends</span> <span class="n">IntegerHolder</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">a</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">b</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">c</span><span class="p">;</span>
  <span class="n">IntegerTriple</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">a</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">b</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">c</span><span class="p">);</span> 
<span class="p">}</span>
</code></pre></div><h2 id="重定向构造函数">重定向构造函数</h2>
<p>有时，一个构造函数的唯一目的是重定向到同一类中的另一个构造函数。重定向构造函数的主体是空的，构造函数调用出现在冒号(:)之后。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Automobile</span> <span class="p">{</span>
  <span class="kt">String</span> <span class="n">make</span><span class="p">;</span>
  <span class="kt">String</span> <span class="n">model</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">mpg</span><span class="p">;</span>

  <span class="c1">// 这个类的主构造函数
</span><span class="c1"></span>  <span class="n">Automobile</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">make</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">mpg</span><span class="p">);</span>

  <span class="c1">// 代理到主构造函数
</span><span class="c1"></span>  <span class="n">Automobile</span><span class="p">.</span><span class="n">hybrid</span><span class="p">(</span><span class="kt">String</span> <span class="n">make</span><span class="p">,</span> <span class="kt">String</span> <span class="n">model</span><span class="p">)</span> <span class="o">:</span> <span class="k">this</span><span class="p">(</span><span class="n">make</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="m">60</span><span class="p">);</span>

  <span class="c1">// 代理到命名构造函数
</span><span class="c1"></span>  <span class="n">Automobile</span><span class="p">.</span><span class="n">fancyHybrid</span><span class="p">()</span> <span class="o">:</span> <span class="k">this</span><span class="p">.</span><span class="n">hybrid</span><span class="p">(</span><span class="s1">&#39;Futurecar&#39;</span><span class="p">,</span> <span class="s1">&#39;Mark 2&#39;</span><span class="p">);</span> 
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-14">代码示例</h3>
<p>还记得上面的 <code>Color</code> 类吗？创建一个名为 <code>black</code> 的命名构造函数，但不是手动分配属性，而是将其重定向到默认构造函数，参数为 0。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Color</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">red</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">green</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">blue</span><span class="p">;</span>
  
  <span class="n">Color</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">red</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">green</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">blue</span><span class="p">);</span>

  <span class="n">Color</span><span class="p">.</span><span class="n">black</span><span class="p">()</span> <span class="o">:</span> <span class="k">this</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="m">0</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="常量构造函数">常量构造函数</h2>
<p>如果你的类产生的对象永远不会改变，你可以让这些对象成为编译时常量。要做到这一点，请定义一个 <code>const</code> 构造函数，并确保所有的实例变量都是最终变量。</p>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">ImmutablePoint</span> <span class="p">{</span>
  <span class="kd">const</span> <span class="n">ImmutablePoint</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">y</span><span class="p">);</span>

  <span class="kd">final</span> <span class="kt">int</span> <span class="n">x</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">y</span><span class="p">;</span>

  <span class="kd">static</span> <span class="kd">const</span> <span class="n">ImmutablePoint</span> <span class="n">origin</span> <span class="o">=</span> <span class="n">ImmutablePoint</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">0</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h3 id="代码示例-15">代码示例</h3>
<p>修改 <code>Recipe</code> 类，使它的实例可以是常量，并创建一个常量构造函数，执行以下操作。</p>
<ul>
<li>有三个参数： <code>ingredients</code>, <code>calories</code> 和 <code>milligramsOfSodium</code>(按顺序)。</li>
<li>使用 <code>this.</code> 语法，自动将参数值分配给同名的对象属性。</li>
<li>是常量，在构造函数声明中，<code>const</code> 关键字就在 <code>Recipe</code> 前面。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-dart" data-lang="dart"><span class="kd">class</span> <span class="nc">Recipe</span> <span class="p">{</span>
  <span class="kd">final</span> <span class="n">List</span><span class="o">&lt;</span><span class="kt">String</span><span class="o">&gt;</span> <span class="n">ingredients</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">int</span> <span class="n">calories</span><span class="p">;</span>
  <span class="kd">final</span> <span class="kt">double</span> <span class="n">milligramsOfSodium</span><span class="p">;</span>

  <span class="kd">const</span> <span class="n">Recipe</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="n">ingredients</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">calories</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="n">milligramsOfSodium</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div><h2 id="下一步是什么">下一步是什么？</h2>
<p>我们希望你喜欢使用这个 codelab 来学习或测试你对 Dart 语言一些最有趣的功能的知识。这里有一些关于现在要做什么的建议。</p>
<ul>
<li>试试<a href="https://dart.dev/codelabs">其他的 Dart 代码实验室</a>.</li>
<li>阅读 <a href="https://dart.dev/guides/language/language-tour">Dart 语言之旅</a>。</li>
<li>玩 <a href="https://dartpad.dev/">DartPad</a>。</li>
<li>获取 <a href="https://dart.dev/get-dart">Dart SDK</a>。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/string" term="string" label="string" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/cheatsheet" term="cheatsheet" label="cheatsheet" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/dart" term="dart" label="dart" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[一起爬山吗?]]></title>
            <link href="https://ohmyweekly.github.io/notes/go-hiking/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/go-hiking/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-06-25T00:00:00+08:00</published>
            <updated>2020-06-25T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>端午佳节, 登高望远。</blockquote><p>端午节快乐, 一起爬山吗？</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/hiking" term="hiking" label="hiking" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/holiday" term="holiday" label="holiday" />
                            
                        
                    
                
            
        </entry>
    
</feed>
