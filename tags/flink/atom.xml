<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.63.2">Hugo</generator><title type="html"><![CDATA[Flink on 焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/tags/flink/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/tags/flink/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/tags/flink/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/tags/flink/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2020-08-19T10:54:04+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/tags/flink/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 操作游乐场]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="related" type="text/html" title="Python API 指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Operations Playground</blockquote><h2 id="flink-操作游乐场">Flink 操作游乐场</h2>
<p>在各种环境中部署和操作 Apache Flink 的方法有很多。无论这种多样性如何，Flink 集群的基本构件保持不变，类似的操作原则也适用。</p>
<p>在这个操场上，你将学习如何管理和运行 Flink Jobs。您将看到如何部署和监控应用程序，体验 Flink 如何从 Job 故障中恢复，并执行日常操作任务，如升级和重新缩放。</p>
<h3 id="这个游乐场的解剖">这个游乐场的解剖</h3>
<p>这个游乐场由一个持久的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink Session Cluster</a>和一个 Kafka Cluster 组成。</p>
<p>一个 Flink Cluster 总是由一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 和一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager">Flink TaskManager</a> 组成。JobManager 负责处理 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Job</a> 提交，监督 Job 以及资源管理。Flink TaskManager 是 worker 进程，负责执行构成 Flink Job 的实际<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">任务</a>。在这个游戏场中，你将从一个单一的 TaskManager 开始，但以后会扩展到更多的 TaskManager。此外，这个游乐场还带有一个专门的客户端容器，我们使用它来提交 Flink Job，并在以后执行各种操作任务。客户端容器不是 Flink Cluster 本身需要的，只是为了方便使用才包含在里面。</p>
<p>Kafka 集群由一个 Zookeeper 服务器和一个 Kafka Broker 组成。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/flink-docker-playground.svg" alt="img"></p>
<p>当游乐场启动时，一个名为 Flink Event Count 的 Flink Job 将被提交给 JobManager。此外，还会创建两个 Kafka 主题 <em>input</em> 和 <em>output</em>。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/click-event-count-example.svg" alt="img"></p>
<p>该作业从 <em>input</em> 主题中消耗点击事件(<strong>ClickEvent</strong>)，每个点击事件(<strong>ClickEvent</strong>)都有一个时间戳(<strong>timestamp</strong>)和一个页面(<strong>page</strong>)。然后按页面对事件进行分组(<strong>keyed by</strong>)，并在 15 秒的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>中进行计数。结果被写入 <em>output</em> 主题。</p>
<p>有6个不同的页面，我们在每个页面和15秒内产生1000个点击事件。因此，Flink 作业的输出应该显示每个页面和窗口有1000个浏览量。</p>
<h3 id="启动游乐场">启动游乐场</h3>
<p>游戏场环境的设置只需几步。我们将引导你完成必要的命令，并展示如何验证一切都在正确运行。</p>
<p>我们假设你的机器上安装了 <a href="https://docs.docker.com/">Docker</a>（1.12+）和 <a href="https://docs.docker.com/compose/">docker-compose</a>（2.1+）。</p>
<p>所需的配置文件可以在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 仓库中找到。检查一下，然后对齐环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">git clone --branch release-1.11 https://github.com/apache/flink-playgrounds.git
<span class="nb">cd</span> flink-playgrounds/operations-playground
docker-compose build
docker-compose up -d
</code></pre></div><p>之后，你可以用以下命令检查正在运行的 Docker 容器。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose ps

                    Name                                  Command               State                   Ports                
-----------------------------------------------------------------------------------------------------------------------------
operations-playground_clickevent-generator_1   /docker-entrypoint.sh java ...   Up       6123/tcp, 8081/tcp                  
operations-playground_client_1                 /docker-entrypoint.sh flin ...   Exit <span class="m">0</span>                                       
operations-playground_jobmanager_1             /docker-entrypoint.sh jobm ...   Up       6123/tcp, 0.0.0.0:8081-&gt;8081/tcp    
operations-playground_kafka_1                  start-kafka.sh                   Up       0.0.0.0:9094-&gt;9094/tcp              
operations-playground_taskmanager_1            /docker-entrypoint.sh task ...   Up       6123/tcp, 8081/tcp                  
operations-playground_zookeeper_1              /bin/sh -c /usr/sbin/sshd  ...   Up       2181/tcp, 22/tcp, 2888/tcp, 3888/tcp
</code></pre></div><p>这表明客户端容器已经成功提交了 Flink Job（Exit 0），所有集群组件以及数据生成器都在运行（Up）。</p>
<p>您可以通过调用来停止游乐场环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose down -v
</code></pre></div><h3 id="进入游乐场">进入游乐场</h3>
<p>在这个游乐场中，有很多东西你可以尝试和检查。在下面的两节中，我们将向您展示如何与 Flink 集群进行交互，并展示 Flink 的一些关键功能。</p>
<h4 id="flink-webui">Flink WebUI</h4>
<p>观察你的 Flink 集群最自然的出发点是在 <a href="http://localhost:8081/">http://localhost:8081</a> 下暴露的 WebUI。如果一切顺利，你会看到集群最初由一个任务管理器组成，并执行一个名为 Click Event Count 的 Job。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui.png" alt="img"></p>
<p>Flink WebUI 包含了很多关于 Flink 集群和它的工作的有用和有趣的信息（JobGraph, Metrics, Checkpointing Statistics, TaskManager Status, &hellip;）。</p>
<h4 id="日志">日志</h4>
<h5 id="jobmanager">JobManager</h5>
<p>可以通过 <code>docker-compose</code> 对 JobManager 日志进行跟踪。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f jobmanager
</code></pre></div><p>在初始启动后，你应该主要看到每一个检查点完成的日志信息。</p>
<h5 id="taskmanager">TaskManager</h5>
<p>TaskManager 的日志也可以用同样的方式进行 tail。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f taskmanager
</code></pre></div><p>在初始启动后，你应该主要看到每个检查点完成的日志信息。</p>
<h4 id="flink-cli">Flink CLI</h4>
<p>Flink CLI 可以在客户端容器中使用。例如，要打印 Flink CLI 的帮助信息，你可以运行以下命令</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink --help
</code></pre></div><h4 id="flink-rest-api">Flink REST API</h4>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">Flink REST API</a> 通过主机上的 localhost:8081 或客户端容器中的 jobmanager:8081 暴露出来，例如，要列出所有当前正在运行的作业，你可以运行:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">curl localhost:8081/jobs
</code></pre></div><h4 id="kafka-topics">Kafka Topics</h4>
<p>你可以通过运行以下命令来查看写入 Kafka 主题的记录</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">//input topic <span class="o">(</span><span class="m">1000</span> records/s<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic input

//output topic <span class="o">(</span><span class="m">24</span> records/min<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><h4 id="time-to-play">Time to Play!</h4>
<p>现在你已经学会了如何与 Flink 和 Docker 容器进行交互，让我们来看看一些常见的操作任务，你可以在我们的游乐场上尝试一下。所有这些任务都是相互独立的，即你可以以任何顺序执行它们。大多数任务可以通过 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-cli">CLI</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-rest-api">REST API</a> 来执行。</p>
<h5 id="列出正在运行的-job">列出正在运行的 Job</h5>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink list
</code></pre></div><p><strong>期望的输出</strong></p>
<pre><code>Waiting for response...
------------------ Running/Restarting Jobs -------------------
16.07.2019 16:37:55 : &lt;job-id&gt; : Click Event Count (RUNNING)
--------------------------------------------------------------
No scheduled jobs.
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<pre><code>curl localhost:8081/jobs
</code></pre><p><strong>期待的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobs&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div><p>JobID 在提交时被分配给作业(Job)，并且需要通过 CLI 或 REST API 对作业(Job)执行操作。</p>
<h5 id="观察故障和恢复">观察故障和恢复</h5>
<p>Flink 在(部分)失败下提供了精确的一次处理保证。在这个游乐场中，你可以观察并在一定程度上验证这种行为。</p>
<p><strong>步骤1：观察输出</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#anatomy-of-this-playground">如上所述</a>，在这个游乐场中的事件是这样生成的，每个窗口正好包含一千条记录。因此，为了验证 Flink 是否成功地从 TaskManager 故障中恢复，而没有数据丢失或重复，你可以跟踪 <em>output</em> 主题，并检查恢复后所有的窗口都存在，而且计数是正确的。</p>
<p>为此，从 <em>output</em> 主题开始读取，并让这个命令运行到恢复后（步骤3）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第二步：引入故障</strong></p>
<p>为了模拟部分故障，你可以杀死一个 TaskManager，在生产设置中，这可能对应于 TaskManager 进程、TaskManager 机器的丢失，或者仅仅是框架或用户代码抛出的瞬时异常（例如由于暂时不可用）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">kill</span> taskmanager
</code></pre></div><p>几秒钟后，JobManager 会注意到 TaskManager 的丢失，取消受影响的 Job，并立即重新提交它进行恢复。当 Job 被重新启动后，其任务仍处于 <strong>SCHEDULED</strong> 状态，由紫色的方块表示（见下面的截图）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui-failure.png" alt="img"></p>
<p>注意：即使作业(Job)的任务(Task)处于 <strong>SCHEDULED</strong> 状态而不是 <strong>RUNNING</strong> 状态，作业(Job)的整体状态也会显示为 <strong>RUNNING</strong>。</p>
<p>此时，Job 的任务(Task)不能从 <strong>SCHEDULED</strong> 状态转为 <strong>RUNNING</strong> 状态，因为没有资源(<strong>TaskManager</strong> 提供的 <strong>TaskSlots</strong>）来运行这些任务。在新的 TaskManager 可用之前，Job 将经历一个取消和重新提交的循环。</p>
<p>同时，数据生成器会不断地将 ClickEvents 推送到 <em>input</em> 主题中。这类似于真正的生产设置，在生产数据的同时，要处理数据的 Job 却宕机了。</p>
<p><strong>步骤3：恢复</strong></p>
<p>一旦你重新启动 TaskManager，它就会重新连接到 JobManager。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose up -d taskmanager
</code></pre></div><p>当 JobManager 被通知到新的 TaskManager 时，它将恢复中的 Job 的任务(tasks)调度到新的可用 TaskSlots。重新启动后，任务会从故障前最后一次成功的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">检查点</a>恢复其状态，并切换到 RUNNING 状态。</p>
<p>Job 将快速处理来自 Kafka 的全部积压输入事件(在故障期间积累的)，并以更高的速度(&gt;24条记录/分钟)产生输出，直到到达流的头部。在输出中，你会看到所有的键(页面)都存在于所有的时间窗口中，而且每个计数都是精确的 1000。由于我们是在&quot;至少一次&quot;模式下使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/kafka.html#kafka-producers-and-fault-tolerance">FlinkKafkaProducer</a>，所以你有可能会看到一些重复的输出记录。</p>
<p>注意：大多数生产设置依赖于资源管理器(Kubernetes、Yarn、Mesos)来自动重启失败的进程。</p>
<h5 id="升级和重新缩放作业">升级和重新缩放作业</h5>
<p>升级 Flink 作业总是涉及两个步骤。首先，用一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>优雅地停止 Flink Job。保存点是在一个明确定义的、全局一致的时间点(类似于检查点)上的完整应用状态的一致快照。其次，升级后的 Flink Job 从 Savepoint 开始。在这种情况下，&ldquo;升级&quot;可以意味着不同的事情，包括以下内容:</p>
<ul>
<li>配置的升级（包括作业的并行性）。</li>
<li>对 Job 的拓扑结构进行升级（增加/删除 Operator）。</li>
<li>对 Job 的用户定义的函数进行升级。</li>
</ul>
<p>在开始升级之前，你可能要开始 tailing <em>output</em> 主题，以观察在升级过程中没有数据丢失或损坏。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第一步：停止工作</strong></p>
<p>要优雅地停止作业，您需要使用 CLI 或 REST API 的 &ldquo;stop&rdquo; 命令。为此，您需要该作业的 JobID，您可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#listing-running-jobs">列出所有正在运行的 Job</a> 或从 WebUI 中获得。有了 JobID，您就可以继续停止该作业:</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink stop &lt;job-id&gt;
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Suspending job &quot;&lt;job-id&gt;&quot; with a savepoint.
Suspended job &quot;&lt;job-id&gt;&quot; with a savepoint.
</code></pre><p>Savepoint 已经被存储到 flink-conf.yaml 中配置的 state.savepoint.dir 中，它被安装在本地机器的 /tmp/flink-savepoints-directory/ 下。在下一步中，你将需要这个 Savepoint 的路径。在 REST API 的情况下，这个路径已经是响应的一部分，你将需要直接查看文件系统。</p>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ls -lia /tmp/flink-savepoints-directory
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">total <span class="m">0</span>
  <span class="m">17</span> drwxr-xr-x   <span class="m">3</span> root root   <span class="m">60</span> <span class="m">17</span> jul 17:05 .
   <span class="m">2</span> drwxrwxrwt <span class="m">135</span> root root <span class="m">3420</span> <span class="m">17</span> jul 17:09 ..
<span class="m">1002</span> drwxr-xr-x   <span class="m">2</span> root root  <span class="m">140</span> <span class="m">17</span> jul 17:05 savepoint-&lt;short-job-id&gt;-&lt;uuid&gt;
</code></pre></div><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># triggering stop</span>
curl -X POST localhost:8081/jobs/&lt;job-id&gt;/stop -d <span class="s1">&#39;{&#34;drain&#34;: false}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;request-id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;trigger-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># check status of stop action and retrieve savepoint path</span>
curl localhost:8081/jobs/&lt;job-id&gt;/savepoints/&lt;trigger-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;COMPLETED&#34;</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;operation&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;location&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;savepoint-path&gt;&#34;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p><strong>步骤2a: 重启 Job，不做任何改变</strong></p>
<p>现在您可以从该保存点重新启动升级后的作业(Job)。为了简单起见，您可以在不做任何更改的情况下重新启动它。</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>一旦 Job 再次 RUNNING，你会在 <em>output</em> 主题中看到，当 Job 在处理中断期间积累的积压时，记录以较高的速度产生。此外，你会看到在升级过程中没有丢失任何数据：所有窗口都存在，数量正好是 1000。</p>
<p><strong>步骤2b: 用不同的并行度重新启动作业（重新缩放）</strong></p>
<p>另外，您也可以在重新提交时通过传递不同的并行性，从这个保存点重新缩放作业。</p>
<ul>
<li>CLI</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -p <span class="m">3</span> -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;parallelism&#34;: 3, &#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>现在，作业(Job)已经被重新提交，但它不会启动，因为没有足够的 TaskSlots 在增加的并行度下执行它（2个可用，需要3个）。使用:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose scale <span class="nv">taskmanager</span><span class="o">=</span><span class="m">2</span>
</code></pre></div><p>你可以在 Flink 集群中添加一个带有两个 TaskSlots 的第二个 TaskManager，它将自动注册到 JobManager 中。添加 TaskManager 后不久，该任务(Job)应该再次开始运行。</p>
<p>一旦 Job 再次 &ldquo;RUNNING&rdquo;，你会在 <em>output</em> Topic 中看到在重新缩放过程中没有丢失数据：所有的窗口都存在，计数正好是 1000。</p>
<h5 id="查询作业job的指标">查询作业(Job)的指标</h5>
<p>JobManager 通过其 REST API 公开系统和用户<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html">指标</a>。</p>
<p>端点取决于这些指标的范围。可以通过 <code>jobs/&lt;job-id&gt;/metrics</code> 来列出一个作业的范围内的度量。指标的实际值可以通过 get query 参数进行查询。</p>
<p><strong>请求</strong></p>
<pre><code class="language-shells" data-lang="shells">curl &quot;localhost:8081/jobs/&lt;jod-id&gt;/metrics?get=lastCheckpointSize&quot;
</code></pre><p><strong>预期的响应(美化了打印; 没有占位符)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
  <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;lastCheckpointSize&#34;</span><span class="p">,</span>
    <span class="nt">&#34;value&#34;</span><span class="p">:</span> <span class="s2">&#34;9378&#34;</span>
  <span class="p">}</span>
<span class="p">]</span>
</code></pre></div><p>REST API 不仅可以用来查询指标，还可以检索运行中的作业状态的详细信息。</p>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># find the vertex-id of the vertex of interest</span>
curl localhost:8081/jobs/&lt;jod-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
  <span class="nt">&#34;isStoppable&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&#34;state&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
  <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
  <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
  <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374793</span><span class="p">,</span>
  <span class="nt">&#34;now&#34;</span><span class="p">:</span> <span class="mi">1564467440819</span><span class="p">,</span>
  <span class="nt">&#34;timestamps&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SUSPENDED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELLING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">1564467066126</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RESTARTING&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;vertices&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066423</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374396</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033461</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166351</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066441</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374378</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5066280</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033496</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066469</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374350</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5085332</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">316</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166305</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066476</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374343</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">20668</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span><span class="p">,</span>
  <span class="nt">&#34;status-counts&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;plan&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
    <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
    <span class="nt">&#34;nodes&#34;</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;HASH&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span>
    <span class="p">]</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>请查阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">REST API 参考资料</a>，了解可能查询的完整列表，包括如何查询不同作用域的指标（如 TaskManager 指标）。</p>
<h4 id="变体">变体</h4>
<p>你可能已经注意到，Click Event Count 应用程序总是以 <code>--checkpointing</code> 和 <code>--event-time</code> 程序参数启动。通过在 docker-compose.yaml 的客户端容器的命令中省略这些，你可以改变 Job 的行为。</p>
<ul>
<li>
<p><code>--checkpointing</code> 启用了 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">checkpoint</a>，这是 Flink 的容错机制。如果你在没有它的情况下运行，并通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#observing-failure--recovery">故障和恢复</a>，你应该会看到数据实际上已经丢失了。</p>
</li>
<li>
<p><code>--event-time</code> 启用了你的 Job 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间语义</a>。当禁用时，作业将根据挂钟时间而不是 ClickEvent 的时间戳将事件分配给窗口。因此，每个窗口的事件数量将不再是精确的 1000。</p>
</li>
</ul>
<p>Click Event Count 应用程序还有另一个选项，默认情况下是关闭的，你可以启用这个选项来探索这个作业在背压下的行为。你可以在 <code>docker-compose.yaml</code> 的客户端容器的命令中添加这个选项。</p>
<ul>
<li><code>--backpressure</code> 在作业中间增加了一个额外的 operator，在偶数分钟内会造成严重的背压（例如，在10:12期间，但在10:13期间不会）。这可以通过检查各种<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html#default-shuffle-service">网络指标</a>（如 outputQueueLength 和 outPoolUsage）和/或使用 WebUI 中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/back_pressure.html#monitoring-back-pressure">背压监控</a>来观察。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/playground" term="playground" label="Playground" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Python API 指南]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 操作游乐场" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Python API Tutorial</blockquote><h2 id="python-api-指南">Python API 指南</h2>
<p>本演练将快速让你开始构建一个纯 Python Flink 项目。</p>
<p>关于如何设置 Python 执行环境，请参考 Python Table API <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html">安装指南</a>。</p>
<h3 id="设置一个-python-项目">设置一个 Python 项目</h3>
<p>您可以先创建一个 Python 项目，然后按照<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html#installation-of-pyflink">安装指南</a>安装 PyFlink 包。</p>
<h3 id="编写一个-flink-python-table-api-程序">编写一个 Flink Python Table API 程序</h3>
<p>Table API 应用程序通过声明一个表环境开始；对于批处理应用程序，可以是 BatchTableEvironment，对于流式应用程序，可以是 StreamTableEnvironment。这作为与 Flink 运行时交互的主要入口点。它可以用来设置执行参数，如重启策略、默认并行度等。表配置允许设置 Table API 的具体配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">(</span><span class="p">)</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">(</span><span class="p">)</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>
</code></pre></div><p>在创建的表环境中，可以声明 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/input</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/output</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>你也可以使用 <code>TableEnvironment.sql_update()</code> 方法来注册 DDL 中定义的 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">my_source_ddl</span> <span class="o">=</span> <span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    create table mySource (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        word VARCHAR</span><span class="s2">
</span><span class="s2"></span><span class="s2">    ) with (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">filesystem</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">format.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">csv</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.path</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">/tmp/input</span><span class="s2">&#39;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    )</span><span class="s2">
</span><span class="s2"></span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">my_sink_ddl</span> <span class="o">=</span> <span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    create table mySink (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        word VARCHAR,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        `count` BIGINT</span><span class="s2">
</span><span class="s2"></span><span class="s2">    ) with (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">filesystem</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">format.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">csv</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.path</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">/tmp/output</span><span class="s2">&#39;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    )</span><span class="s2">
</span><span class="s2"></span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_source_ddl</span><span class="p">)</span>
<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_sink_ddl</span><span class="p">)</span>
</code></pre></div><p>这将在执行环境中注册一个名为 <strong>mySource</strong> 的表和一个名为 <strong>mySink</strong> 的表。表 <strong>mySource</strong> 只有一列，即 <strong>word</strong>，它消耗从文件 <code>/tmp/input</code> 中读取的字符串。表 <strong>mySink</strong> 有两列，分别是 <strong>word</strong> 和 <strong>count</strong>，将数据写入文件 <code>/tmp/output</code>，用 <code>/t</code> 作为字段分隔符。</p>
<p>现在，你可以创建一个作业(job)，它从表 <strong>mySource</strong> 中读取输入，预先执行一些转换，并将结果写入表 <strong>mySink</strong>。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word, count(1)</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>最后你必须执行实际的 Flink Python Table API 作业。所有的操作，如创建源、转换和 sink 都是懒惰的。只有当 <code>t_env.execute(job_name)</code> 被调用时，作业才会被运行。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">tutorial_job</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><p>到目前为止，完整的代码如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyflink.dataset</span> <span class="kn">import</span> <span class="n">ExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">TableConfig</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">,</span> <span class="n">BatchTableEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table.descriptors</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">OldCsv</span><span class="p">,</span> <span class="n">FileSystem</span>

<span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">(</span><span class="p">)</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">(</span><span class="p">)</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/input</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/output</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word, count(1)</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">tutorial_job</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><h3 id="执行-flink-python-table-api-程序">执行 Flink Python Table API 程序</h3>
<p>首先，你需要在 &ldquo;/tmp/input&rdquo; 文件中准备输入数据。你可以选择以下命令行来准备输入数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">echo</span> -e  <span class="s2">&#34;flink\npyflink\nflink&#34;</span> &gt; /tmp/input
</code></pre></div><p>接下来，你可以在命令行上运行这个例子（注意：如果结果文件 &ldquo;/tmp/output&rdquo; 已经存在，你需要在运行这个例子之前删除该文件）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ python WordCount.py
</code></pre></div><p>该命令在本地小型集群中构建并运行 Python Table API 程序。你也可以将 Python Table API 程序提交到远程集群，详情可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html#job-submission-examples">Job Submission Examples</a>。</p>
<p>最后，您可以在命令行中看到执行结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ cat /tmp/output
flink	<span class="m">2</span>
pyflink	<span class="m">1</span>
</code></pre></div><p>这应该可以让你开始编写自己的 Flink Python Table API 程序。要了解更多关于 Python Table API 的信息，你可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/python">Flink Python Table API Docs</a> 了解更多细节。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/python" term="python" label="Python" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Connectors]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-07T00:00:00+08:00</published>
            <updated>2020-08-07T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>连接器</blockquote><h1 id="apache-kafka-connector">Apache Kafka Connector</h1>
<h2 id="kafka-consumer">Kafka Consumer</h2>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">(</span><span class="o">)</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;localhost:9092&#34;</span><span class="o">)</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;test&#34;</span><span class="o">)</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span><span class="o">(</span><span class="s">&#34;topic&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="n">properties</span><span class="o">)</span><span class="o">)</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/connector" term="connector" label="Connector" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Real Time Reporting with the Table API</blockquote><p>Apache Flink 提供的 Table API 是一个统一的、关系型的 API，用于批处理和流处理，即在无边界的、实时的流或有边界的、批处理的数据集上以相同的语义执行查询，并产生相同的结果。Flink 中的 Table API 通常用于简化数据分析、数据管道化和 ETL 应用的定义。</p>
<h2 id="你要构建什么">你要构建什么?</h2>
<p>在本教程中，你将学习如何构建一个实时的仪表盘，以按账户跟踪金融交易。该管道将从 Kafka 读取数据，并将结果写入 MySQL，通过 Grafana 可视化。</p>
<h2 id="先决条件">先决条件</h2>
<p>本演练假设你对 Java 或 Scala 有一定的熟悉，但即使你来自不同的编程语言，你也应该能够跟上。它还假设你熟悉基本的关系概念，如 SELECT 和 GROUP BY 子句。</p>
<h2 id="救命-我被卡住了">救命, 我被卡住了!</h2>
<p>如果你遇到困难，请查看<a href="https://flink.apache.org/community.html">社区支持资源</a>。特别是 Apache Flink 的<a href="https://flink.apache.org/community.html#mailing-lists">用户邮件列表</a>，它一直是 Apache 项目中最活跃的一个，也是快速获得帮助的好方法。</p>
<h2 id="如何跟进">如何跟进</h2>
<p>如果你想跟着走，你需要一台电脑与。</p>
<ul>
<li>Java 8 或 11</li>
<li>Maven</li>
<li>Docker</li>
</ul>
<p>所需的配置文件可在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 资源库中获得。下载后，在 IDE 中打开项目 flink-playground/table-walkthrough，并导航到文件 SpendReport。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">)</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="拆解代码">拆解代码</h2>
<h3 id="the-execution-environment">The Execution Environment</h3>
<p>前两行设置了你的 <code>TableEnvironment</code>。表环境是你如何为你的 Job 设置属性，指定你是在写批处理还是流式应用，以及创建你的源。本演练创建了一个使用流式执行的标准表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="注册表">注册表</h3>
<p>接下来，在当前<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册了表，您可以使用这些表连接到外部系统，以便读写批处理和流数据。表源提供对存储在外部系统中的数据的访问，如数据库、键值存储、消息队列或文件系统。table sink 向外部存储系统发出一个表。根据源和 sink 的类型，它们支持不同的格式，如 CSV、JSON、Avro 或 Parquet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>注册了两个表：一个是交易输入表，一个是消费报告输出表。交易(transaction)表让我们可以读取信用卡交易，其中包含账户ID(account_id)、时间戳(transaction_time)和美元金额(amount)。该表是在一个名为 <code>transactions</code> 的 Kafka 主题上的逻辑视图，包含 CSV 数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>第二张表 <code>spend_report</code>，存储了最终的汇总结果。其底层存储是 MySql 数据库中的一张表。</p>
<h3 id="查询">查询</h3>
<p>配置好环境和注册好表之后，你就可以构建你的第一个应用程序了。从 <code>TableEnvironment</code> 中，你可以从一个输入表中读取它的行，然后使用 <code>executeInsert</code> 将这些结果写入到一个输出表中。<code>report</code> 函数是你实现业务逻辑的地方。它目前还没有被实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">)</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="测试">测试</h2>
<p>该项目包含一个二次测试类 <code>SpendReportTest</code>，用于验证报表的逻辑。它以批处理模式创建了一个表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">inBatchMode</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>Flink 的独特属性之一是它在批处理和流式处理之间提供一致的语义。这意味着你可以在静态数据集上以批处理模式开发和测试应用程序，并以流式应用程序的形式部署到生产中。</p>
<h2 id="尝试一下">尝试一下</h2>
<p>现在有了 Job 设置的骨架，你就可以添加一些业务逻辑了。目标是建立一个报告，显示每个账户在一天中每个小时的总支出。这意味着时间戳列需要从毫秒到小时的颗粒度进行舍入。</p>
<p>Flink 支持用纯 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/">SQL</a> 或使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 开发关系型应用。Table API 是一个受 SQL 启发的流畅 DSL，可以用 Python、Java 或 Scala 编写，并支持强大的 IDE 集成。就像 SQL 查询一样，Table 程序可以选择所需的字段，并通过你的键进行分组。这些功能，加上<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置的函数</a>，如 <code>floor</code> 和 <code>sum</code>，写这个报告问题不大。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">floor</span><span class="o">(</span><span class="n">TimeIntervalUnit</span><span class="o">.</span><span class="na">HOUR</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><h2 id="用户定义的函数">用户定义的函数</h2>
<p>Flink 包含有限的内置函数，有时你需要用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>来扩展它。如果 <code>floor</code> 不是预定义的，你可以自己实现它。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">java.time.LocalDateTime</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.time.temporal.ChronoUnit</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyFloor</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="nf">eval</span><span class="o">(</span>
        <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">{</span>

        <span class="k">return</span> <span class="n">timestamp</span><span class="o">.</span><span class="na">truncatedTo</span><span class="o">(</span><span class="n">ChronoUnit</span><span class="o">.</span><span class="na">HOURS</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后迅速将其集成到你的应用程序中。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">call</span><span class="o">(</span><span class="n">MyFloor</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>这个查询会消耗 <code>transactions</code> 表的所有记录，计算报表，并以高效、可扩展的方式输出结果。使用该实现运行测试将通过。</p>
<h2 id="添加窗口">添加窗口</h2>
<p>基于时间的数据分组是数据处理中的典型操作，尤其是在处理无限流时。基于时间的分组被称为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>，Flink 提供了灵活的窗口语义。最基本的窗口类型称为 <code>Tumble</code> 窗口，它有一个固定的大小，其桶不重叠。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">Tumble</span><span class="o">.</span><span class="na">over</span><span class="o">(</span><span class="n">lit</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">.</span><span class="na">hour</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">on</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">start</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>这就定义了你的应用程序使用基于时间戳列的一小时翻滚窗口。因此，时间戳为 2019-06-01 01:23:47 的行被放在 2019-06-01 01:00:00 窗口中。</p>
<p>基于时间的聚合是独一无二的，因为在连续流应用中，时间与其他属性不同，一般是向前移动的。与 floor 和你的 UDF 不同，窗口函数是<a href="https://en.wikipedia.org/wiki/Intrinsic_function">内在的</a>，它允许运行时应用额外的优化。在批处理上下文中，窗口提供了一个方便的 API，用于通过时间戳属性对记录进行分组。</p>
<p>用这个实现运行测试也会通过。</p>
<h2 id="再来一次用流">再来一次，用流!</h2>
<p>就这样，一个功能齐全的、有状态的、分布式的流式应用! 查询不断地消耗 Kafka 的事务流，计算每小时的花费，并在结果准备好后立即发出。由于输入是界的，所以查询一直在运行，直到手动停止。而且由于 Job 使用了基于时间窗口的聚合，所以当框架知道某个窗口不会再有记录到达时，Flink 可以进行特定的优化，比如状态清理。</p>
<p>表游乐场是完全 docker 化的，可以作为流式应用在本地运行。该环境包含一个 Kafka 主题、一个连续数据生成器、MySql 和 Grafana。</p>
<p>从 <code>table-walkthrough</code> 文件夹内启动 <code>docker-compose</code> 脚本。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose build
$ docker-compose up -d
</code></pre></div><p>你可以通过 <a href="http://localhost:8082/">Flink 控制台</a>查看正在运行的作业信息。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/spend-report-console.png" alt="img"></p>
<p>从 MySQL 里面探索结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose <span class="nb">exec</span> mysql mysql -Dsql-demo -usql-demo -pdemo-sql

mysql&gt; use sql-demo<span class="p">;</span>
Database changed

mysql&gt; <span class="k">select</span> count<span class="o">(</span>*<span class="o">)</span> from spend_report<span class="p">;</span>
+----------+
<span class="p">|</span> count<span class="o">(</span>*<span class="o">)</span> <span class="p">|</span>
+----------+
<span class="p">|</span>      <span class="m">110</span> <span class="p">|</span>
+----------+
</code></pre></div><p>最后，去 <a href="http://localhost:3000/d/FOe0PbmGk/walkthrough?viewPanel=2&amp;orgId=1&amp;refresh=5s">Grafana</a> 看看完全可视化的结果吧!</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table" term="table" label="table" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/api" term="api" label="api" />
                            
                        
                    
                
            
        </entry>
    
</feed>
