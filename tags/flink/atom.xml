<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.63.2">Hugo</generator><title type="html"><![CDATA[Flink on 焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/tags/flink/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/tags/flink/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/tags/flink/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/tags/flink/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2020-08-20T22:57:39+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/tags/flink/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 的架构]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Architecture</blockquote><p>Flink 是一个分布式系统，为了执行流式应用，需要对计算资源进行有效的分配和管理。它集成了所有常见的集群资源管理器，如 <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html">Hadoop YARN</a>、<a href="https://mesos.apache.org/">Apache Mesos</a> 和 <a href="https://kubernetes.io/">Kubernetes</a>，但也可以设置为独立集群甚至作为库运行。</p>
<p>本节包含 Flink 架构的概述，并描述了其主要组件如何交互执行应用程序并从故障中恢复。</p>
<h2 id="flink-集群的解剖">Flink 集群的解剖</h2>
<p>Flink 运行时由两种类型的进程组成：一个 JobManager 和一个或多个 TaskManagers。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/processes.svg" alt="img"></p>
<p>客户端不是运行时和程序执行的一部分，而是用来准备并向 JobManager 发送数据流。之后，客户端可以断开连接（分离模式），或者保持连接以接收进度报告（附加模式）。客户端既可以作为触发执行的 Java/Scala 程序的一部分运行，也可以在命令行进程 <code>./bin/flink run</code> &hellip;中运行。</p>
<p>JobManager 和 TaskManagers 可以以各种方式启动：直接在机器上作为一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html">独立的集群</a>，在容器中，或由 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/yarn_setup.html">YARN</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/mesos.html">Mesos</a> 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作。</p>
<h3 id="jobmanager">JobManager</h3>
<p>JobManager 有一些与协调 Flink 应用的分布式执行有关的职责：它决定何时安排下一个任务（或一组任务），对已完成的任务或执行失败作出反应，协调检查点，并协调失败时的恢复等。这个过程由三个不同的组件组成。</p>
<ul>
<li><strong>资源管理器(ResourceManager)</strong></li>
</ul>
<p>ResourceManager 负责 Flink 集群中的资源去/分配和供应&ndash;它管理任务槽(<strong>task slots</strong>)，任务槽是 Flink 集群中资源调度的单位（见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#taskmanagers">TaskManagers</a>）。Flink 针对不同的环境和资源提供者（如 YARN、Mesos、Kubernetes 和独立部署）实现了多个 ResourceManagers。在独立设置中，ResourceManager 只能分配可用的 TaskManagers 的槽位，不能自行启动新的 TaskManagers。</p>
<ul>
<li><strong>Dispatcher</strong></li>
</ul>
<p>Dispatcher 提供了一个 REST 接口来提交 Flink 应用执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 来提供作业执行的信息。</p>
<ul>
<li><strong>JobMaster</strong></li>
</ul>
<p>一个 JobMaster 负责管理一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">JobGraph</a> 的执行。在一个 Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。</p>
<p>总是至少有一个 JobManager。一个高可用性设置可能有多个 JobManagers，其中一个总是领导者，其他的是备用的（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/jobmanager_high_availability.html">高可用性（HA）</a>）。</p>
<h3 id="taskmanagers">TaskManagers</h3>
<p>任务管理器（TaskManagers）（也叫 worker）执行数据流的任务，并缓冲和交换数据流。</p>
<p>必须始终有至少一个TaskManager。TaskManager中资源调度的最小单位是一个任务槽。一个任务管理器中任务槽的数量表示并发处理任务的数量。请注意，一个任务槽中可以执行多个操作者（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#tasks-and-operator-chains">Tasks 和 Operator 链</a>）。</p>
<h3 id="tasks-和-operator-chains">Tasks 和 Operator Chains</h3>
<p>对于分布式执行，Flink 将操作者的子任务链成任务。每个任务由一个线程执行。将运算符一起链入任务是一种有用的优化：它减少了线程到线程的交接和缓冲的开销，增加了整体的吞吐量，同时降低了延迟。链锁行为可以配置，详情请看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#task-chaining-and-resource-groups">chaining 文档</a>。</p>
<p>下图中的示例数据流是以五个子任务，也就是五个并行线程来执行的。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_chains.svg" alt="img"></p>
<h2 id="任务槽和资源task-slots-和-resources">任务槽和资源(Task Slots 和 Resources)</h2>
<p>每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个子任务。为了控制一个任务管理器接受多少任务，它有所谓的任务槽（至少一个）。</p>
<p>每个任务槽代表任务管理器的一个固定的资源子集。例如，一个有三个槽的任务管理器，将把其管理内存的1/3奉献给每个槽。槽位资源意味着一个子任务不会与其他任务的子任务争夺管理内存，而是拥有一定量的预留管理内存。需要注意的是，这里并没有发生 CPU 隔离，目前插槽只是将任务的管理内存分开。</p>
<p>通过调整任务槽的数量，用户可以定义子任务之间的隔离方式。每个任务管理器有一个插槽意味着每个任务组都在一个单独的 JVM 中运行（例如可以在一个单独的容器中启动）。拥有多个插槽意味着更多的子任务共享同一个 JVM。同一 JVM 中的任务共享 TCP 连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每个任务的开销。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_slots.svg" alt="img"></p>
<p>默认情况下，Flink 允许子任务共享槽，即使它们是不同任务的子任务，只要它们来自同一个作业。其结果是，一个槽可以容纳整个作业的流水线。允许这种槽位共享有两个主要好处。</p>
<ul>
<li>
<p>一个 Flink 集群需要的任务槽数量正好与作业中使用的最高并行度相同。不需要计算一个程序总共包含多少个任务（具有不同的并行度）。</p>
</li>
<li>
<p>更容易获得更好的资源利用率。如果没有槽位共享，非密集型的 <code>source/map()</code> 子任务和资源密集型的 window 子任务一样，会阻塞很多资源。有了槽位共享，在我们的例子中，将基础并行度从2个增加到6个，就会产生槽位资源的充分利用，同时确保重度子任务在 TaskManager 中公平分配。</p>
</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/slot_sharing.svg" alt="img"></p>
<h2 id="flink-应用执行">Flink 应用执行</h2>
<p>Flink 应用程序是任何从其 <code>main()</code> 方法中生成一个或多个 Flink 作业的用户程序。这些作业的执行可以发生在本地 JVM（LocalEnvironment）中，也可以发生在多台机器的远程集群设置（RemoteEnvironment）中。对于每个程序，ExecutionEnvironment 提供了控制作业执行的方法（例如设置并行性）和与外界交互的方法（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">Anatomy of a Flink Program</a>）。</p>
<p>Flink 应用的作业可以提交到一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink 会话集群</a>、一个专门的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster">Flink 作业集群</a>或一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink 应用集群</a>。这些选项之间的区别主要与集群的生命周期和资源隔离保证有关。</p>
<h3 id="flink-会话集群">Flink 会话集群</h3>
<ul>
<li>
<p>集群生命周期：在 Flink 会话集群中，客户端连接到一个预先存在的、长期运行的集群，可以接受多个作业提交。即使在所有作业完成后，集群（和 JobManager）将继续运行，直到会话被手动停止。因此，一个 Flink 会话集群的寿命不受任何 Flink 作业寿命的约束。</p>
</li>
<li>
<p>资源隔离。TaskManager 插槽由 ResourceManager 在作业提交时分配，作业完成后释放。因为所有作业都共享同一个集群，所以对集群资源有一定的竞争&ndash;比如提交作业阶段的网络带宽。这种共享设置的一个限制是，如果一个任务管理器崩溃，那么所有在这个任务管理器上有任务运行的作业都会失败；同样，如果在作业管理器上发生一些致命的错误，也会影响集群中运行的所有作业。</p>
</li>
<li>
<p>其他考虑因素：拥有一个预先存在的集群，可以节省大量申请资源和启动 TaskManagers 的时间。这在作业的执行时间非常短，高启动时间会对端到端的用户体验产生负面影响的场景中非常重要&ndash;就像对短查询的交互式分析一样，希望作业能够利用现有资源快速执行计算。</p>
</li>
</ul>
<p>注：以前，Flink 会话集群也被称为会话模式下的 Flink 集群。</p>
<h3 id="flink-作业集群">Flink 作业集群</h3>
<ul>
<li>
<p>集群生命周期：在 Flink Job Cluster 中，可用的集群管理器（如 YARN 或 Kubernetes）为每个提交的作业旋转一个集群，这个集群只对该作业可用。在这里，客户端首先向集群管理器请求资源来启动 JobManager，并将作业提交给运行在这个进程内部的 Dispatcher。然后根据作业的资源需求，懒惰地分配 TaskManager。作业完成后，Flink Job Cluster 就会被拆掉。</p>
</li>
<li>
<p>资源隔离：JobManager 的致命错误只影响该 Flink Job Cluster 中运行的一个作业。</p>
</li>
</ul>
<p>其他考虑因素：由于 ResourceManager 需要申请并等待外部资源管理组件来启动 TaskManager 进程并分配资源，因此 Flink Job Cluster 更适合运行时间长、稳定性要求高、对启动时间较长不敏感的大型作业。</p>
<p>注：以前，Flink Job Cluster 也被称为作业（或每作业）模式下的 Flink Cluster。</p>
<h3 id="flink-应用集群flink-application-cluster">Flink 应用集群(Flink Application Cluster)</h3>
<ul>
<li>
<p>集群生命周期：Flink 应用集群是一个专用的 Flink 集群，它只执行来自一个 Flink 应用的作业，并且 <code>main()</code> 方法运行在集群上而不是客户端上。作业提交是一个一步到位的过程：你不需要先启动一个 Flink 集群，然后向现有的集群会话提交作业，而是将你的应用逻辑和依赖关系打包成一个可执行的作业 JAR，集群入口点(ApplicationClusterEntryPoint)负责调用 <code>main()</code> 方法来提取作业图。这样你就可以像在 Kubernetes 上部署其他应用一样部署 Flink 应用，例如。因此，Flink Application Cluster 的寿命与 Flink Application 的寿命是绑定的。</p>
</li>
<li>
<p>资源隔离：在 Flink Application Cluster 中，ResourceManager 和 Dispatcher 的范围是单一的 Flink Application，这比 Flink Session Cluster 提供了更好的分离关注点。</p>
</li>
</ul>
<p>注：Flink Job Cluster 可以看作是 Flink Application Cluster 的 &ldquo;run-on-client&rdquo; 替代品。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/architecture" term="architecture" label="architecture" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[及时的流处理]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Timely Stream Processing</blockquote><h2 id="介绍">介绍</h2>
<p>及时流处理是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态流处理</a>的一种扩展，其中时间在计算中起着一定的作用。其中，当你做时间序列分析时，当做基于特定时间段（通常称为窗口）的聚合时，或者当你做事件处理时，事件发生的时间很重要时，都是这种情况。</p>
<p>在下面的章节中，我们将着重介绍一些您在使用及时 Flink 应用时应该考虑的主题。</p>
<h2 id="时间的概念事件时间和处理时间">时间的概念：事件时间和处理时间</h2>
<p>当在流程序中提到时间时（例如定义窗口），可以提到不同的时间概念。</p>
<ul>
<li>处理时间。处理时间指的是正在执行相应操作的机器的系统时间。</li>
</ul>
<p>当流程序在处理时间上运行时，所有基于时间的操作(如时间窗口)将使用运行各操作的机器的系统时钟。一个小时的处理时间窗口将包括在系统时钟指示整小时的时间之间到达特定操作者的所有记录。例如，如果一个应用程序在上午9:15开始运行，则第一个小时处理时间窗口将包括上午9:15到10:00之间处理的事件，下一个窗口将包括上午10:00到11:00之间处理的事件，以此类推。</p>
<p>处理时间是最简单的时间概念，不需要流和机器之间的协调。它提供了最好的性能和最低的延迟。然而，在分布式和异步环境中，处理时间并不能提供确定性，因为它很容易受到记录到达系统的速度（例如从消息队列）、记录在系统内部的操作员之间流动的速度以及中断（计划性的或其他）的影响。</p>
<ul>
<li>事件时间。事件时间是指每个事件在其生产设备上发生的时间。这个时间通常在记录进入 Flink 之前就被嵌入到记录中，该事件时间戳可以从每个记录中提取出来。在事件时间中，时间的进展取决于数据，而不是任何挂钟。事件时间程序必须指定如何生成事件时间水印，这是事件时间中信号进度的机制。这个水印机制将在后面的章节中描述，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html#event-time-and-watermarks">下面</a>。</li>
</ul>
<p>在一个完美的世界里，事件时间处理将产生完全一致和确定的结果，不管事件何时到达，或它们的顺序如何。然而，除非已知事件是按顺序到达的（通过时间戳），否则事件时间处理在等待失序事件时就会产生一些延迟。由于只能在有限的时间内等待，这就对事件时间应用的确定性提出了限制。</p>
<p>假设所有的数据都已经到达，事件时间操作将按照预期的方式进行，即使在处理失序或迟到的事件时，或者在重新处理历史数据时，也能产生正确和一致的结果。例如，每小时事件时间窗口将包含所有携带事件时间戳的记录，这些记录属于该小时，无论它们到达的顺序如何，也无论它们何时被处理。更多信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html#late-elements">&ldquo;迟到事件&rdquo;</a>一节）。</p>
<p>需要注意的是，有时事件时间程序在实时处理实时数据时，会使用一些处理时间操作来保证其及时进行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/event_processing_time.svg" alt="img"></p>
<h2 id="事件时间和水印">事件时间和水印</h2>
<p>注：Flink 实现了 Dataflow 模型中的许多技术。对于事件时间和水印的介绍，可以看看下面的文章。</p>
<ul>
<li>Tyler Akidau 的 <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Streaming 101</a>。</li>
<li><a href="https://research.google.com/pubs/archive/43864.pdf">数据流模型论文</a></li>
</ul>
<p>一个支持事件时间的流处理器需要一种方法来测量事件时间的进度。例如，当事件时间已经超过一小时结束时，需要通知建立小时窗口的窗口操作员，以便操作员可以关闭正在进行的窗口。</p>
<p>事件时间的进展可以独立于处理时间(由挂钟测量)。例如，在一个程序中，操作者的当前事件时间可能略微落后于处理时间(考虑到接收事件的延迟)，而两者以相同的速度进行。另一方面，另一个流程序可能通过快进一些已经缓冲在 Kafka 主题（或另一个消息队列）中的历史数据，只用几秒钟的处理时间就可以完成几周的事件时间的进展。</p>
<p>Flink 中衡量事件时间进度的机制是水印。水印作为数据流的一部分流动，并携带一个时间戳 <em>t</em>，一个 Watermark(t) 声明该数据流中的事件时间已经达到了时间 <em>t</em>，也就是说该数据流中不应该再有时间戳 <em>t'&lt;=t</em> 的元素（即事件的时间戳大于或等于水印）。</p>
<p>下图显示了一个带有（逻辑）时间戳的事件流，以及水印的内联流。在这个例子中，事件是按顺序排列的（相对于它们的时间戳），这意味着水印只是流中的周期性标记。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_watermark_in_order.svg" alt="img"></p>
<p>水印对于无序流来说是至关重要的，如下图所示，在这种情况下，事件不是按照时间戳来排序的。一般来说，水印是一种声明，即在流中的那一点上，所有事件在某个时间戳之前都应该已经到达。一旦水印到达操作者，操作者可以将其内部事件时间时钟提前到水印的值。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_watermark_out_of_order.svg" alt="img"></p>
<p>请注意，事件时间是由新创建的流元素（或元素）从产生它们的事件或触发创建这些元素的水印中继承的。</p>
<h3 id="并行流中的水印">并行流中的水印</h3>
<p>水印是在源函数处或直接在源函数后生成的。源函数的每个并行子任务通常都会独立地生成其水印。这些水印定义了该特定并行源的事件时间。</p>
<p>当水印流经流程序时，它们会在它们到达的操作符处提前事件时间。每当一个操作者提前其事件时间时，它就会在下游为其后续操作者生成一个新的水印。</p>
<p>有些运算符会消耗多个输入流；例如，一个联合，或者在 <code>keyBy(...)</code> 或 <code>partition(...)</code> 函数之后的运算符。这种运算符的当前事件时间是其输入流事件时间的最小值。当它的输入流更新它们的事件时间时，该运算符也会更新。</p>
<p>下图显示了事件和水印在并行流中流动的例子，以及运算符跟踪事件时间的例子。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel_streams_watermarks.svg" alt="img"></p>
<h2 id="延时">延时</h2>
<p>某些元素有可能会违反水印条件，也就是说，即使在水印(t)发生后，也会有更多时间戳 <em>t'&lt;=t</em> 的元素发生。事实上，在许多现实世界的设置中，某些元素可以任意延迟，这使得无法指定某个事件时间戳的所有元素在什么时候发生。此外，即使延迟时间可以被限定，但延迟水印的时间过长往往是不可取的，因为它对事件时间窗口的评估造成过多的延迟。</p>
<p>出于这个原因，流媒体程序可能会显式地期望一些迟到的元素。晚期元素是指在系统的事件时间时钟（由水印发出的信号）已经过了晚期元素的时间戳之后到达的元素。有关如何在事件时间窗口中处理迟到元素的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#allowed-lateness">允许的延时</a>。</p>
<h2 id="窗口">窗口</h2>
<p>聚合事件（如计数、求和）在流上的工作方式与批处理中的工作方式不同。例如，不可能对一个流中的所有元素进行计数，因为流一般是无限的（无边界的）。相反，流上的聚合（计数、求和等）是由窗口来限定范围的，比如 &ldquo;过去5分钟的计数&rdquo;，或者&quot;过去100个元素的总和&rdquo;。</p>
<p>窗口可以是时间驱动的（例如：每30秒），也可以是数据驱动的（例如：每100个元素）。人们通常会区分不同类型的窗口，如翻滚窗口（无重叠）、滑动窗口（有重叠）和会话窗口（以不活动的间隙为点）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/windows.svg" alt="img"></p>
<p>请查看这篇<a href="https://flink.apache.org/news/2015/12/04/Introducing-windows.html">博客文章</a>，了解更多的窗口示例，或查看 DataStream API 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口文档</a>。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/stream" term="stream" label="stream" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[有状态的流处理]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Stateful Stream Processing</blockquote><h2 id="什么是状态">什么是状态？</h2>
<p>虽然数据流中的许多操作一次只看一个单独的事件（例如事件分析器），但有些操作会记住多个事件的信息（例如窗口 operator ）。这些操作被称为有状态操作。</p>
<p>一些有状态操作的例子:</p>
<ul>
<li>当一个应用程序搜索某些事件模式时，状态将存储到目前为止遇到的事件序列。</li>
<li>当按分钟/小时/天聚合事件时，状态会保存待聚合的事件。</li>
<li>当在数据点流上训练机器学习模型时，状态会保存模型参数的当前版本。</li>
<li>当需要管理历史数据时，状态可以有效访问过去发生的事件。</li>
</ul>
<p>Flink 需要了解状态，以便使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">检查点</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>使其具有容错性。</p>
<p>关于状态的知识还允许重新缩放 Flink 应用，这意味着 Flink 负责在并行实例之间重新分配状态。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">可查询状态</a>允许你在运行时从 Flink 外部访问状态。</p>
<p>在处理状态时，阅读一下 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">Flink 的状态后端</a>可能也很有用。Flink 提供了不同的状态后端，指定了状态的存储方式和位置。</p>
<h2 id="keyed-state">Keyed State</h2>
<p>Keyed state 被维护在可以被认为是一个嵌入式键/值存储中。该状态严格地与有状态 operator 读取的流一起被分割和分配。因此，对键/值状态的访问只有在 <em>keyed streams</em> 上，即在 keyed/分区数据交换之后才有可能，并且仅限于与当前事件的键相关联的值。将流和状态的键对齐，可以确保所有的状态更新都是本地操作，保证了一致性，而没有事务开销。这种对齐方式还允许 Flink 透明地重新分配状态和调整流分区。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/state_partitioning.svg" alt="img"></p>
<p>Keyed State 被进一步组织成所谓的 Key Groups。Key Groups 是 Flink 可以重新分配 Keyed State 的原子单位；Key Groups 的数量正好与定义的最大并行度相同。在执行过程中，keyed operator 的每个并行实例都与一个或多个 Key Groups 的键一起工作。</p>
<h2 id="状态持久化">状态持久化</h2>
<p>Flink 使用流重放(<strong>stream replay</strong>)和检查点(<strong>checkpointing</strong>)的组合来实现容错。一个检查点标记了每个输入流中的一个特定点以及每个 operator 的相应状态。通过恢复运算符的状态，从检查点开始重放记录，可以从检查点恢复流数据流，同时保持一致性（精确的一次处理语义）。</p>
<p>检查点间隔是用恢复时间（需要重放的记录数量）来交换执行过程中容错的开销的一种手段。</p>
<p>容错机制不断地绘制分布式流数据流的快照。对于状态较小的流媒体应用，这些快照非常轻量级，可以频繁地绘制，而不会对性能产生太大的影响。流应用的状态存储在一个可配置的地方，通常是在一个分布式文件系统中。</p>
<p>在程序失败的情况下（由于机器、网络或软件故障），Flink会停止分布式流数据流。然后系统会重新启动 operator ，并将其重置到最新的成功检查点。输入流被重置到状态快照的点。作为重新启动的并行数据流的一部分处理的任何记录都保证不影响之前的检查点状态。</p>
<p>注: 默认情况下，检查点被禁用。有关如何启用和配置检查点的详细信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">检查点</a>。</p>
<p>注: 为了实现这种机制的完全保证，数据流源（如消息队列或 broker）需要能够将数据流倒退到一个定义的最近点。<a href="http://kafka.apache.org/">Apache Kafka</a> 具有这种能力，Flink 的 Kafka 连接器利用了这一点。参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/guarantees.html">数据源和接收器的容错保证</a>，了解更多关于 Flink 连接器提供的保证的信息。</p>
<p>注: 因为 Flink 的检查点是通过分布式快照实现的，所以我们互换使用快照和检查点这两个词。通常我们也使用术语快照来表示检查点或保存点。</p>
<h3 id="检查点">检查点</h3>
<p>Flink 容错机制的核心部分是绘制分布式数据流和 operator 状态的一致快照。这些快照作为一致的检查点，系统在发生故障时可以回退。Flink 绘制这些快照的机制在 <a href="http://arxiv.org/abs/1506.08603">&ldquo;Lightweight Asynchronous Snapshots for Distributed Dataflows&rdquo;</a> 中描述。它的灵感来自于分布式快照的标准 <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf">Chandy-Lamport 算法</a>，并专门为 Flink 的执行模型量身定做。</p>
<p>请记住，所有与检查点有关的事情都可以异步完成。检查点屏障不按锁步走，操作可以异步快照其状态。</p>
<p>自 Flink 1.11 以来，检查点可以在有或没有对齐的情况下进行。在本节中，我们先介绍对齐的检查点。</p>
<h4 id="屏障">屏障</h4>
<p>Flink 的分布式快照中的一个核心元素是流屏障。这些屏障被注入到数据流中，并作为数据流的一部分与记录一起流动。屏障永远不会超越记录，它们严格按照线路流动。屏障将数据流中的记录分为进入当前快照的记录集和进入下一个快照的记录。每个屏障都带有其记录被推到前面的快照的ID。屏障不会中断数据流的流动，因此非常轻量级。不同快照的多个屏障可以同时出现在流中，这意味着不同的快照可以同时发生。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_barriers.svg" alt="img"></p>
<p>流屏障是在流源处注入并行数据流。快照n的屏障被注入的点（我们称它为 Sₙ）是源流中快照覆盖数据的位置。例如，在 Apache Kafka 中，这个位置将是分区中最后一条记录的偏移。这个位置 Sₙ 被报告给检查点协调器（Flink 的 JobManager）。</p>
<p>然后，屏障就会流向下游。当一个中间 operator 从它的所有输入流中接收到一个快照n的屏障时，它就会向它的所有输出流中发出一个快照n的屏障。一旦一个汇 operator （流 DAG 的末端）从它的所有输入流中接收到屏障n，它就会向检查点协调器确认该快照n。在所有的接收器(sink)确认了一个快照之后，它就被认为完成了。</p>
<p>一旦快照n完成后，作业再也不会向源头询问 Sₙ 之前的记录，因为此时这些记录（以及它们的子孙记录）将通过整个数据流拓扑。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_aligning.svg" alt="img"></p>
<p>接收多个输入流的 operator 需要将输入流对准快照屏障。上图就说明了这一点。</p>
<ul>
<li>一旦 operator 从一个输入流中接收到快照屏障n，它就不能再处理该流的任何记录，直到它也从其他输入中接收到屏障n。否则，它就会把属于快照n的记录和属于快照n+1的记录混在一起。</li>
<li>一旦最后一个流收到了屏障n， operator 就会发出所有的待发记录，然后自己发出快照n的屏障。</li>
<li>它快照状态并恢复处理所有输入流的记录，在处理流的记录之前，先处理输入缓冲区的记录。</li>
<li>最后， operator 将状态异步写入状态后端。</li>
</ul>
<p>需要注意的是，所有具有多个输入的 operator 和洗牌后的 operator 在消耗多个上游子任务的输出流时，都需要进行对齐。</p>
<h4 id="快照-operator-state">快照 Operator State</h4>
<p>当 operator 包含任何形式的状态时，这个状态也必须是快照的一部分。</p>
<p>Operator 在从输入流接收到所有快照屏障后，在向输出流发出屏障之前，在这个时间点快照其状态。这时，所有来自屏障之前的记录对状态的更新都已经进行了，而没有依赖于屏障之后的记录的更新。由于快照的状态可能很大，所以它被存储在一个可配置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a>。默认情况下，这是 JobManager 的内存，但对于生产使用，应该配置一个分布式的可靠存储（如 HDFS）。状态存储完毕后， operator 确认检查点，向输出流发出快照屏障，然后继续进行。</p>
<p>现在产生的快照包含。</p>
<ul>
<li>对于每个并行流数据源，当快照开始时，流中的偏移量/位置。</li>
<li>对于每个 operator，一个指向作为快照的一部分存储的状态的指针。</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/checkpointing.svg" alt="img"></p>
<h4 id="恢复">恢复</h4>
<p>这种机制下的恢复是直接的。系统会重新部署整个分布式数据流，并给每个 operator 提供快照的状态，作为检查点 <em>k</em> 的一部分。 来源被设置为从位置 Sₖ 开始读取数据流。例如在 Apache Kafka 中，这意味着告诉消费者从偏移量 Sₖ 开始获取。</p>
<p>如果状态是增量快照的，则运算符从最新的完整快照的状态开始，然后对该状态应用一系列增量快照更新。</p>
<p>更多信息请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/task_failure_recovery.html#restart-strategies">重启策略</a>。</p>
<h3 id="不对齐检查点">不对齐检查点</h3>
<p>从 Flink 1.11 开始，检查点也可以在不对齐的情况下进行。基本思路是，只要飞行中的数据成为 operator 状态的一部分，检查点就可以覆盖所有飞行中的数据。</p>
<p>请注意，这种方法实际上更接近 <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf">Chandy-Lamport 算法</a> ，但 Flink 仍然在源中插入屏障，以避免超载检查点协调器。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_unaligning.svg" alt="img"></p>
<p>该图描述了一个 operator 如何处理不对齐的检查点屏障。</p>
<ul>
<li>operator 对输入缓冲区中存储的第一个屏障作出反应。</li>
<li>它立即将屏障转发给下游 operator ，将其添加到输出缓冲区的末尾。</li>
<li>operator 将所有被超越的记录标记为异步存储，并创建自己状态的快照。</li>
</ul>
<p>因此， operator 只短暂地停止对输入的处理以标记缓冲区，转发屏障，并创建其他状态的快照。</p>
<p>不对齐的检查点确保屏障以最快的速度到达汇流排。它特别适合于至少有一条缓慢移动的数据路径的应用，在这种应用中，对齐时间可能达到数小时。然而，由于它增加了额外的I/O压力，所以当状态后端的I/O是瓶颈时，它并没有帮助。关于其他的局限性，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html#unaligned-checkpoints">运维</a>中更深入的讨论。</p>
<p>请注意，保存点将始终是对齐的。</p>
<h4 id="未对齐的恢复">未对齐的恢复</h4>
<p>operator 首先恢复飞行中的数据，然后才开始处理来自上游 operator 在不结盟检查点的任何数据。除此之外，它执行的步骤与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html#recovery">恢复对齐检查点</a>时相同。</p>
<h3 id="状态后端">状态后端</h3>
<p>键/值索引的具体数据结构取决于所选择的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a>。一种状态后端将数据存储在内存中的哈希图中，另一种状态后端使用 <a href="http://rocksdb.org/">RocksDB</a> 作为键/值存储。除了定义持有状态的数据结构外，状态后端还实现了对键/值状态进行时间点快照的逻辑，并将该快照作为检查点的一部分进行存储。状态后端可以在不改变应用逻辑的情况下进行配置。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/checkpoints.svg" alt="img"></p>
<h3 id="保存点">保存点</h3>
<p>所有使用检查点的程序都可以从保存点(<strong>savepoint</strong>)恢复执行。保存点允许在不丢失任何状态的情况下同时更新你的程序和 Flink 集群。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>是<strong>手动触发的检查点</strong>，它采取程序的快照并将其写入状态后端。它们依靠常规的检查点机制来实现。</p>
<p>保存点与检查点类似，只是它们是<strong>由用户触发的</strong>，当新的检查点完成后，它们<strong>不会自动失效</strong>。</p>
<h3 id="完全一次与至少一次">完全一次与至少一次</h3>
<p>对齐步骤可能会给流媒体程序增加延迟。通常，这种额外的延迟是在几毫秒的数量级，但我们已经看到一些异常值的延迟明显增加的情况。对于要求所有记录持续超低延迟（几毫秒）的应用，Flink 有一个开关，可以在检查点期间跳过流对齐。只要 operator 从每个输入中看到检查点屏障，检查点快照仍然会被绘制。</p>
<p>当跳过对齐时， operator 会继续处理所有的输入，甚至在一些检查点 <em>n</em> 的检查点屏障到达后， operator 也会继续处理。这样一来， operator 也会在检查点 <em>n</em> 的状态快照被采集之前处理属于检查点 <em>n+1</em> 的元素。在还原时，这些记录将作为重复发生，因为它们都包含在检查点 <em>n</em> 的状态快照中，并将在检查点 <em>n</em> 之后作为数据的一部分重放。</p>
<p>注意对齐只发生在有多个前辈的 operator （连接）以及有多个发送者的 operator （流重新分区/洗牌后）。正因为如此，即使在至少一次的模式下，只有令人尴尬的并行流操作(<code>map()</code>, <code>flatMap()</code>, <code>filter()</code>, &hellip;)的数据流实际上也会给出精确的一次保证。</p>
<h2 id="批量程序中的状态和容错能力">批量程序中的状态和容错能力</h2>
<p>Flink 执行<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html">批处理程序</a>是流程序的一种特殊情况，其中流是有界的（元素数量有限）。一个 DataSet 在内部被当作一个数据流。因此，上述概念适用于批处理程序的方式与适用于流程序的方式相同，但有一些小的例外。</p>
<ul>
<li>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/fault_tolerance.html">批处理程序的容错</a>不使用检查点。恢复是通过完全重放流发生的。这是可能的，因为输入是有界的。这将成本更多地推向恢复，但使常规处理更便宜，因为它避免了检查点。</p>
</li>
<li>
<p>DataSet API 中的有状态操作使用简化的内存内/核心外数据结构，而不是键/值索引。</p>
</li>
<li>
<p>DataSet API 引入了特殊的同步（基于superstep的）迭代，只有在有界流上才能实现。详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/iterations.html">迭代文档</a>。</p>
</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/stateful" term="stateful" label="stateful" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[术语表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="related" type="text/html" title="概念" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-glossary/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Glossary</blockquote><p><strong>Flink Application Cluster</strong></p>
<p>Flink 应用集群是一个专用的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>，它只执行一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用</a>的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a>。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>的寿命与 Flink 应用的寿命绑定。</p>
<p><strong>Flink Job Cluster</strong></p>
<p>Flink Job Cluster 是一个专用的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a>，它只执行一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a>。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a> 的寿命与 Flink Job 的寿命绑定。</p>
<p><strong>Flink Cluster</strong></p>
<p>一个分布式系统由（通常）一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 和一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager">Flink TaskManager</a> 进程组成。</p>
<p><strong>Event</strong></p>
<p>事件是关于应用程序所模拟的域的状态变化的声明。事件可以是流或批处理应用程序的输入和/或输出。事件是特殊类型的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record">记录</a>。</p>
<p><strong>ExecutionGraph</strong></p>
<p>参见物理图(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph">Physical Graph</a>)</p>
<p><strong>Function</strong></p>
<p>函数由用户实现，封装了 Flink 程序的应用逻辑。大多数 Functions 都由相应的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 封装。</p>
<p><strong>Instance</strong></p>
<p>术语 instance 用于描述运行时特定类型（通常是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a>）的具体实例。由于 Apache Flink 大部分是用 Java 编写的，所以对应于 Java 中的 Instance 或 Object 的定义。在 Apache Flink 的上下文中，并行实例这个术语也经常被用来强调同一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a> 类型的多个实例在并行运行。</p>
<p><strong>Flink Application</strong></p>
<p>Flink 应用程序是一个 Java 应用程序，它从 <code>main()</code> 方法(或通过其他方式)提交一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a>。提交作业通常是通过调用执行环境上的 <code>execute()</code> 来完成的。</p>
<p>应用程序的作业可以提交到一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink 会话集群</a>，也可以提交到一个专门的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink 应用集群</a>，或者提交到一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster">Flink 作业集群</a>。</p>
<p><strong>Flink Job</strong></p>
<p>Flink Job 是指在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用</a>中通过调用 <code>execute()</code> 来创建和提交的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>（也常称为数据流图）的运行时表示。</p>
<p><strong>JobGraph</strong></p>
<p>参见逻辑图(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">Logical Graph</a>)</p>
<p><strong>Flink JobManager</strong></p>
<p>JobManager 是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink 集群</a>的协调器。它包含了三个不同的组件：Flink 资源管理器、Flink 调度器和每个运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink 作业</a> 一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmaster">Flink JobMaster</a>。</p>
<p><strong>Flink JobMaster</strong></p>
<p>JobMasters 是运行在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 中的组件之一。一个 JobMaster 负责监督单个作业的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a> 的执行情况。</p>
<p><strong>Logical Graph</strong></p>
<p>逻辑图是一个有向图，其中节点是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operators</a>，边缘定义了 operator 的输入/输出关系，并对应数据流或数据集。逻辑图是通过从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application">Flink 应用程序</a>提交作业来创建的。</p>
<p>逻辑图也常被称为数据流图。</p>
<p><strong>Managed State</strong></p>
<p>Managed State 描述的是已经在框架中注册的应用状态。对于托管状态，Apache Flink 将负责处理持久性和重新缩放等问题。</p>
<p><strong>Operator</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>的节点。Operator 执行某种操作，通常由 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Function</a> 执行。源和接收器是数据摄入和数据输出的特殊 Operator。</p>
<p><strong>Operator Chain</strong></p>
<p>一个 Operator 链由两个或多个连续的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 组成，中间没有任何重新分区。同一 Operator 链内的 operattor 直接相互转发记录，而不需要经过序列化或 Flink 的网络栈。</p>
<p><strong>Partition</strong></p>
<p>分区是整个数据流或数据集的一个独立子集。通过将每条<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record">记录</a>分配到一个或多个分区，将数据流或数据集划分为多个分区。数据流或数据集的分区在运行时由<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a>消耗。改变数据流或数据集分区方式的转换通常称为重新分区。</p>
<p><strong>Physical Graph</strong></p>
<p>物理图是翻译<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph">逻辑图</a>的结果，以便在分布式运行时执行。节点是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a>，边缘表示输入/输出关系或数据流或数据集的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition">分区</a>。</p>
<p><strong>Record</strong></p>
<p>记录是数据集或数据流的组成元素。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Function">Functions</a> 接收记录作为输入，并发出记录作为输出。</p>
<p><strong>Flink Session Cluster</strong></p>
<p>一个长期运行的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a>，它接受多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a> 的执行。该  Flink Cluster 的寿命不受任何 Flink Job 寿命的约束。以前，Flink Session Cluster 也被称为会话模式下的 Flink Cluster。与 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster">Flink Application Cluster</a> 比较。</p>
<p><strong>State Backend</strong></p>
<p>对于流处理程序来说，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Flink Job</a> 的状态后端决定了它的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#managed-state">状态</a>如何存储在每个 TaskManager 上（TaskManager 的 Java 堆或（嵌入式）RocksDB），以及它在检查点时的写入位置（<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 的 Java 堆或 Filesystem）。</p>
<p><strong>Sub-Task</strong></p>
<p>子任务( Sub-Task)是指负责处理数据流的一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition">分区</a>的任务(<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Task</a>)。术语&quot;子任务&quot;强调同一 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain">Operator 链</a>有多个并行的 Task。</p>
<p><strong>Task</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph">物理图</a>的节点。Task 是工作的基本单位，由 Flink 的运行时执行。任务正好封装了一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain">Operator 链</a> 的一个并行实例。</p>
<p><strong>Flink TaskManager</strong></p>
<p>TaskManager 是 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster">Flink Cluster</a> 的工作进程。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">Tasks</a> 被安排给 TaskManagers 执行。它们相互通信，在后续的 Task 之间交换数据。</p>
<p><strong>Transformation</strong></p>
<p>变换应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。变换可能会在每条记录的基础上改变数据流或数据集，但也可能只改变其分区或执行聚合。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function">Functions</a>是 Flink 的 API 的 &ldquo;物理&quot;部分，而变换只是一个 API 概念。具体来说，大多数变换是由某些 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator">Operator</a> 实现的。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/architecture" term="architecture" label="architecture" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[概念]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 的架构" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-timely-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="及时的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-stateful-stream-processing/?utm_source=atom_feed" rel="related" type="text/html" title="有状态的流处理" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-20-glossary/?utm_source=atom_feed" rel="related" type="text/html" title="术语表" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-20-concepts-overview/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-20T00:00:00+08:00</published>
            <updated>2020-08-20T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Concepts</blockquote><h2 id="概念">概念</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/">实践培训</a>解释了作为 Flink 的 API 基础的有状态和及时流处理的基本概念，并提供了这些机制如何在应用中使用的例子。有状态的流处理是在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/etl.html#stateful-transformations">数据管道</a>和ETL的背景下介绍的，并在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">容错</a>部分进一步发展。在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html">&ldquo;流分析&rdquo;</a>一节中介绍了及时的流处理。</p>
<p>本概念深度部分提供了对 Flink 的架构和运行时如何实现这些概念的更深入的理解。</p>
<h2 id="flink-的-api">Flink 的 API</h2>
<p>Flink 为开发流式/批量应用提供了不同层次的抽象。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/levels_of_abstraction.svg" alt="img"></p>
<ul>
<li>
<p>最底层的抽象只是提供<strong>有状态和及时的流处理</strong>。它通过 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">Process Function</a> 嵌入到 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API</a> 中。它允许用户自由处理来自一个或多个流的事件，并提供一致的、容错的状态。此外，用户还可以注册事件时间和处理时间的回调，使程序可以实现复杂的计算。</p>
</li>
<li>
<p>在实际应用中，很多应用程序并不需要上述的低级抽象，而是可以针对 <strong>Core APIs</strong> 进行编程：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream API</a>（有界/无界流）和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/">DataSet API</a>（有界数据集）。这些流畅的 API 为数据处理提供了常见的构件，比如各种形式的用户指定的转换、连接、聚合、窗口、状态等。在这些 API 中处理的数据类型在各自的编程语言中被表示为类。</p>
</li>
</ul>
<p>低级 Process Function 与 DataStream API 相集成，因此可以根据需要使用低级抽象。DataSet API 提供了关于有界数据集的附加原语，如循环/迭代。</p>
<ul>
<li><strong>Table API</strong> 是以表为中心的声明式 DSL，它可能是动态变化的表（当表示流时）。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">Table API</a> 遵循（扩展的）关系模型。表有一个附加的模式（类似于关系数据库中的表），API 提供了可比较的操作，如select、project、join、group-by、aggregation 等。Table API 程序声明式地定义了应该做什么逻辑操作，而不是具体规定操作的代码是怎样的。虽然 Table API 可以通过各种类型的用户定义函数进行扩展，但它的表现力不如 Core API，使用起来更简洁（写的代码更少）。此外，Table API 程序在执行前还要经过一个优化器，应用优化规则。</li>
</ul>
<p>人们可以在表和 DataStream/DataSet 之间无缝转换，允许程序将 Table API 与 DataStream 和 DataSet API 混合使用。</p>
<ul>
<li>Flink 提供的最高级抽象是 <strong>SQL</strong>。这个抽象在语义和表现形式上都与 Table API 相似，但将程序表示为 SQL 查询表达式。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11//ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/#sql">SQL</a> 抽象与 Table API 紧密交互，SQL 查询可以在 Table API 中定义的表上执行。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/%E6%A6%82%E5%BF%B5" term="%E6%A6%82%E5%BF%B5" label="概念" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[DataStream API 介绍]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Intro to the DataStream API</blockquote><p>本次培训的重点是广泛地介绍 DataStream API，使你能够开始编写流式应用程序。</p>
<h2 id="什么可以被流式化">什么可以被流式化？</h2>
<p>Flink 的 DataStream API(Java 和 Scala)可以让你流化任何可以序列化的东西。Flink 自己的序列化器用于:</p>
<ul>
<li>基本类型，即 String, Long, Integer, Boolean, Array</li>
<li>复合类型。Tuples, POJOs 和 Scala case classes</li>
</ul>
<p>而 Flink 又回到了 Kryo 的其他类型。也可以在 Flink 中使用其他序列化器。特别是 Avro，得到了很好的支持。</p>
<h3 id="java-元组-和-pojo">Java 元组 和 POJO</h3>
<p>Flink 的本地序列化器可以有效地操作元组和 POJO。</p>
<p><strong>元组</strong></p>
<p>对于 Java，Flink 定义了自己的 Tuple0 到 Tuple25 类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">person</span> <span class="o">=</span> <span class="n">Tuple2</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// zero based index!  
</span><span class="c1"></span><span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="n">person</span><span class="o">.</span><span class="na">f0</span><span class="o">;</span>
<span class="n">Integer</span> <span class="n">age</span> <span class="o">=</span> <span class="n">person</span><span class="o">.</span><span class="na">f1</span><span class="o">;</span>
</code></pre></div><p><strong>POJO</strong></p>
<p>如果满足以下条件，Flink 将数据类型识别为 POJO 类型（并允许&quot;按名称&quot;字段引用）。</p>
<ul>
<li>类是公共的和独立的（没有非静态的内部类）。</li>
<li>该类有一个公共的无参数构造函数。</li>
<li>类（以及所有超级类）中的所有非静态、非瞬态字段要么是公共的（而且是非最终的），要么有公共的 getter- 和 setter- 方法，这些方法遵循 Java beans 中 getter 和 setter 的命名约定。</li>
</ul>
<p>例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Person</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span>  
    <span class="kd">public</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">;</span>  
    <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span><span class="o">}</span><span class="o">;</span>  
    <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">)</span> <span class="o">{</span>  
        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span><span class="o">;</span>  
<span class="o">}</span>  

<span class="n">Person</span> <span class="n">person</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Fred Flintstone&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>Flink 的序列化器<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/schema_evolution.html#pojo-types">支持 POJO 类型的模式进化</a>。</p>
<h3 id="scala-元组和-case-class">Scala 元组和 case class</h3>
<p>这些工作就像你期望的那样。</p>
<h2 id="一个完整的例子">一个完整的例子</h2>
<p>这个例子将一个关于人的记录流作为输入，并将其过滤为只包括成年人。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.datastream.DataStream</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.api.common.functions.FilterFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Example</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[</span><span class="o">]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span>
                <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="n">flintstones</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">)</span><span class="o">,</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Wilma&#34;</span><span class="o">,</span> <span class="n">35</span><span class="o">)</span><span class="o">,</span>
                <span class="k">new</span> <span class="n">Person</span><span class="o">(</span><span class="s">&#34;Pebbles&#34;</span><span class="o">,</span> <span class="n">2</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="n">adults</span> <span class="o">=</span> <span class="n">flintstones</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="n">FilterFunction</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span>
            <span class="nd">@Override</span>
            <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">filter</span><span class="o">(</span><span class="n">Person</span> <span class="n">person</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">person</span><span class="o">.</span><span class="na">age</span> <span class="o">&gt;</span><span class="o">=</span> <span class="n">18</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">}</span><span class="o">)</span><span class="o">;</span>

        <span class="n">adults</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

        <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Person</span> <span class="o">{</span>
        <span class="kd">public</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span>
        <span class="kd">public</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">;</span>
        <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span><span class="o">}</span><span class="o">;</span>

        <span class="kd">public</span> <span class="nf">Person</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">Integer</span> <span class="n">age</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
            <span class="k">this</span><span class="o">.</span><span class="na">age</span> <span class="o">=</span> <span class="n">age</span><span class="o">;</span>
        <span class="o">}</span><span class="o">;</span>

        <span class="kd">public</span> <span class="n">String</span> <span class="nf">toString</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">return</span> <span class="k">this</span><span class="o">.</span><span class="na">name</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="o">)</span> <span class="o">+</span> <span class="s">&#34;: age &#34;</span> <span class="o">+</span> <span class="k">this</span><span class="o">.</span><span class="na">age</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h2 id="流执行环境">流执行环境</h2>
<p>每个 Flink 应用都需要一个执行环境，本例中的 env。流式应用需要使用一个 StreamExecutionEnvironment。</p>
<p>在你的应用程序中进行的 DataStream API 调用建立了一个作业图(job graph)，这个作业图被附加到 StreamExecutionEnvironment 上。当调用 env.execute() 时，这个图会被打包并发送给 JobManager，JobManager 将作业并行化，并将它的片断分配给 Task Manager 执行。你的作业的每个并行片断将在一个任务槽(task slot)中执行。</p>
<p>注意，如果你不调用 execute()，你的应用程序将不会被运行。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/distributed-runtime.svg" alt="img"></p>
<p>这种分布式运行时取决于你的应用程序是可序列化的。它还要求所有的依赖关系都能在集群中的每个节点上使用。</p>
<h3 id="基本的流源">基本的流源</h3>
<p>上面的例子使用 <code>env.fromElements(...)</code> 构造了一个 <code>DataStream[Person]</code>。这是一种方便的方法，可以将一个简单的流组合起来，用于原型或测试。StreamExecutionEnvironment 上还有一个 fromCollection(Collection) 方法。所以，你可以用这个方法来代替。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">people</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">Person</span><span class="o">&gt;</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Fred&#34;</span><span class="o">,</span> <span class="mi">35</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Wilma&#34;</span><span class="o">,</span> <span class="mi">35</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="n">people</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Person</span><span class="o">(</span><span class="s">&#34;Pebbles&#34;</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="k">val</span> <span class="n">flintstones</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">people</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>另一种方便的方法是在原型开发时将一些数据导入流中，使用 socket:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">lines</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">socketTextStream</span><span class="o">(</span><span class="s">&#34;localhost&#34;</span><span class="o">,</span> <span class="mi">9999</span><span class="o">)</span>
</code></pre></div><p>或从文件中读取:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">lines</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&#34;file:///path&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>在实际应用中，最常用的数据源是那些支持低延迟、高吞吐量并行读取并结合倒带和重放的数据源&ndash;这是高性能和容错的先决条件&ndash;如 Apache Kafka、Kinesis 和各种文件系统。REST API 和数据库也经常被用于流的丰富。</p>
<h3 id="基本的流式接收器">基本的流式接收器</h3>
<p>上面的例子使用 <code>adults.print()</code> 将其结果打印到 task manager 的日志中（当在 IDE 中运行时，它将出现在你的 IDE 的控制台中）。这将在流的每个元素上调用 <code>toString()</code>。</p>
<p>输出结果看起来像这样：</p>
<pre><code>1&gt; Fred: age 35
2&gt; Wilma: age 35
</code></pre><p>其中 <code>1&gt;</code> 和 <code>2&gt;</code> 表示哪个子任务（即线程）产生的输出。</p>
<p>在生产中，常用的接收器括 StreamingFileSink、各种数据库和一些 pub-sub 系统。</p>
<h2 id="调试">调试</h2>
<p>在生产中，你的应用程序将在远程集群或一组容器中运行。而如果它失败了，它将会远程失败。JobManager 和 TaskManager 日志对调试此类故障非常有帮助，但在 IDE 内部进行本地调试要容易得多，Flink 支持这一点。你可以设置断点，检查本地变量，并逐步检查你的代码。你也可以步入 Flink 的代码，如果你好奇 Flink 是如何工作的，这可以是一个很好的方式来了解它的内部结构。</p>
<h2 id="实践">实践</h2>
<p>在这一点上，你知道了足够的知识，可以开始编码和运行一个简单的 DataStream 应用程序。克隆 <a href="https://github.com/apache/flink-training/tree/release-1.11">flink-training</a> repo，按照 README 中的说明操作后，进行第一个练习。<a href="https://github.com/apache/flink-training/tree/release-1.11/ride-cleansing">过滤一个流（Ride Cleansing）</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://flink.apache.org/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink序列化调优第一卷：选择你的序列化器&ndash;如果你可以的话</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program">Flink 程序的解剖</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#data-sources">数据源</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#data-sinks">数据接收器</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/">DataStream 连接器</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[事件驱动型应用程序]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Event-driven Applications</blockquote><h2 id="process-functions">Process Functions</h2>
<h3 id="介绍">介绍</h3>
<p>ProcessFunction 将事件处理与定时器和状态结合起来，使其成为流处理应用的强大构件。这是用 Flink 创建事件驱动应用的基础。它与 RichFlatMapFunction 非常相似，但增加了定时器。</p>
<h3 id="实例">实例</h3>
<p>如果你做过<a href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics">流分析</a>培训中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html#hands-on">实战练习</a>，你会记得它使用 TumblingEventTimeWindow 来计算每个司机在每个小时内的小费之和，就像这样:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="o">(</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">AddTips</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>用 KeyedProcessFunction 做同样的事情是相当直接的，也是很有教育意义的。让我们先把上面的代码替换成这样:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="o">(</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">PseudoWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>在这段代码中，一个名为 PseudoWindow 的 KeyedProcessFunction 被应用于一个 keyed 流，其结果是一个 <code>DataStream&lt;Tuple3&lt;Long，Long，Float&gt;&gt;</code>（就是使用 Flink 内置时间窗口的实现所产生的那种流）。</p>
<p>PseudoWindow 的整体轮廓是这样的形状:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Compute the sum of the tips for each driver in hour-long windows.
</span><span class="c1"></span><span class="c1">// The keys are driverIds.
</span><span class="c1"></span><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">PseudoWindow</span> <span class="kd">extends</span> 
        <span class="n">KeyedProcessFunction</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">TaxiFare</span><span class="o">,</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">durationMsec</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">PseudoWindow</span><span class="o">(</span><span class="n">Time</span> <span class="n">duration</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">durationMsec</span> <span class="o">=</span> <span class="n">duration</span><span class="o">.</span><span class="na">toMilliseconds</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called once during initialization.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called as each fare arrives to be processed.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span>
            <span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="c1">// Called when the current watermark indicates that a window is now complete.
</span><span class="c1"></span>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onTimer</span><span class="o">(</span><span class="kt">long</span> <span class="n">timestamp</span><span class="o">,</span> 
            <span class="n">OnTimerContext</span> <span class="n">context</span><span class="o">,</span> 
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

        <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>需要注意的事情。</p>
<ul>
<li>
<p>ProcessFunctions 有好几种类型&ndash;这是一个 KeyedProcessFunctions，但还有 CoProcessFunctions、BroadcastProcessFunctions 等。</p>
</li>
<li>
<p>KeyedProcessFunction 是 RichFunction的一种。作为一个 RichFunction，它可以访问在管理 keyed state 下工作所需的 <code>open</code> 和 <code>getRuntimeContext</code> 方法。</p>
</li>
<li>
<p>有两个回调要实现：<code>processElement</code> 和 <code>onTimer</code>。<code>processElement</code> 在每次传入事件时被调用；<code>onTimer</code> 在定时器发射时被调用。这些定时器可以是事件时间，也可以是处理时间定时器。<code>processElement</code> 和 <code>onTimer</code> 都提供了一个上下文对象，该对象可以用来与 <code>TimerService</code> 交互（除其他外）。两个回调都还传递了一个可以用来发出结果的 Collector。</p>
</li>
</ul>
<h4 id="open-方法">open() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Keyed, managed state, with an entry for each window, keyed by the window&#39;s end time.
</span><span class="c1"></span><span class="c1">// There is a separate MapState object for each driver.
</span><span class="c1"></span><span class="kd">private</span> <span class="kd">transient</span> <span class="n">MapState</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">sumOfTips</span><span class="o">;</span>

<span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>

    <span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">sumDesc</span> <span class="o">=</span>
            <span class="k">new</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="o">&gt;</span><span class="o">(</span><span class="s">&#34;sumOfTips&#34;</span><span class="o">,</span> <span class="n">Long</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Float</span><span class="o">.</span><span class="na">class</span><span class="o">)</span><span class="o">;</span>
    <span class="n">sumOfTips</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">getMapState</span><span class="o">(</span><span class="n">sumDesc</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>由于票价事件可能会不按顺序到达，所以有时需要处理一个小时的事件，然后再完成前一个小时的结果计算。事实上，如果水印延迟比窗口长度长得多，那么可能会同时打开许多窗口，而不是只有两个。本实现通过使用 <code>MapState</code> 来支持这一点，<code>MapState</code> 将每个窗口结束的时间戳映射到该窗口的提示之和。</p>
<h4 id="processelement-方法">processElement() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span>
        <span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">,</span>
        <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span>
        <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

    <span class="kt">long</span> <span class="n">eventTime</span> <span class="o">=</span> <span class="n">fare</span><span class="o">.</span><span class="na">getEventTime</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="n">TimerService</span> <span class="n">timerService</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="na">timerService</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

    <span class="k">if</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">&lt;</span><span class="o">=</span> <span class="n">timerService</span><span class="o">.</span><span class="na">currentWatermark</span><span class="o">(</span><span class="o">)</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// This event is late; its window has already been triggered.
</span><span class="c1"></span>    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="c1">// Round up eventTime to the end of the window containing this event.
</span><span class="c1"></span>        <span class="kt">long</span> <span class="n">endOfWindow</span> <span class="o">=</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">-</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">%</span> <span class="n">durationMsec</span><span class="o">)</span> <span class="o">+</span> <span class="n">durationMsec</span> <span class="o">-</span> <span class="n">1</span><span class="o">)</span><span class="o">;</span>

        <span class="c1">// Schedule a callback for when the window has been completed.
</span><span class="c1"></span>        <span class="n">timerService</span><span class="o">.</span><span class="na">registerEventTimeTimer</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">)</span><span class="o">;</span>

        <span class="c1">// Add this fare&#39;s tip to the running total for that window.
</span><span class="c1"></span>        <span class="n">Float</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">sumOfTips</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">)</span><span class="o">;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">sum</span> <span class="o">=</span><span class="o">=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">sum</span> <span class="o">=</span> <span class="n">0</span><span class="o">.</span><span class="na">0F</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="n">sum</span> <span class="o">+</span><span class="o">=</span> <span class="n">fare</span><span class="o">.</span><span class="na">tip</span><span class="o">;</span>
        <span class="n">sumOfTips</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">endOfWindow</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>要考虑的事情:</p>
<ul>
<li>
<p>迟到的事件会怎样？在水印后面的事件（即迟到）会被丢弃。如果你想做一些比这更好的事情，可以考虑使用侧输出，这将在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#side-outputs">下一节</a>解释。</p>
</li>
<li>
<p>这个例子使用了一个 MapState，其中键是时间戳，并为同一个时间戳设置一个 Timer。这是一种常见的模式；它使得在定时器发射时查找相关信息变得简单而高效。</p>
</li>
</ul>
<h4 id="ontimer-方法">onTimer() 方法</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kt">void</span> <span class="nf">onTimer</span><span class="o">(</span>
        <span class="kt">long</span> <span class="n">timestamp</span><span class="o">,</span> 
        <span class="n">OnTimerContext</span> <span class="n">context</span><span class="o">,</span> 
        <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

    <span class="kt">long</span> <span class="n">driverId</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getCurrentKey</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="c1">// Look up the result for the hour that just ended.
</span><span class="c1"></span>    <span class="n">Float</span> <span class="n">sumOfTips</span> <span class="o">=</span> <span class="k">this</span><span class="o">.</span><span class="na">sumOfTips</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">timestamp</span><span class="o">)</span><span class="o">;</span>

    <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">driverId</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">,</span> <span class="n">sumOfTips</span><span class="o">)</span><span class="o">;</span>
    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">result</span><span class="o">)</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">sumOfTips</span><span class="o">.</span><span class="na">remove</span><span class="o">(</span><span class="n">timestamp</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>观察:</p>
<ul>
<li>
<p>传递给 onTimer 的 OnTimerContext 上下文可以用来确定当前的键。</p>
</li>
<li>
<p>我们的伪窗口是在当前水印到达每个小时结束时被触发的，此时调用 onTimer。这个 onTimer 方法从 sumOfTips 中删除了相关的条目，这样做的效果是无法容纳迟到的事件。这相当于在使用 Flink 的时间窗口时，将 allowLateness 设置为零。</p>
</li>
</ul>
<h3 id="性能方面的考虑">性能方面的考虑</h3>
<p>Flink 提供了针对 RocksDB 优化的 MapState 和 ListState 类型。在可能的情况下，应该使用这些类型来代替持有某种集合的 ValueState 对象。RocksDB 状态后端可以追加到 ListState，而不需要经过(去)序列化，对于 MapState，每个键/值对都是一个单独的 RocksDB 对象，因此 MapState 可以有效地被访问和更新。</p>
<h2 id="侧输出">侧输出</h2>
<h3 id="介绍-1">介绍</h3>
<p>有几个很好的理由可以让 Flink operator 有一个以上的输出流，比如报告:</p>
<ul>
<li>异常</li>
<li>畸形事件</li>
<li>迟到事件</li>
<li>操作警报，如与外部服务的连接超时。</li>
</ul>
<p>侧输出是一种方便的方式。除了错误报告，侧输出也是实现流的多路分割的好方法。</p>
<h3 id="例子">例子</h3>
<p>现在，您可以对上一节中被忽略的迟到事件做些什么了。</p>
<p>一个侧输出通道与一个 <code>OutputTag&lt;T&gt;</code> 相关联。这些标签具有与侧输出的 DataStream 的类型相对应的通用类型，它们有名称。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">TaxiFare</span><span class="o">&gt;</span> <span class="n">lateFares</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">TaxiFare</span><span class="o">&gt;</span><span class="o">(</span><span class="s">&#34;lateFares&#34;</span><span class="o">)</span> <span class="o">{</span><span class="o">}</span><span class="o">;</span>
</code></pre></div><p>上面展示的是一个静态的 <code>OutputTag&lt;TaxiFare&gt;</code>，它既可以在 PseudoWindow 的 processElement 方法中发出迟到事件时被引用。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="k">if</span> <span class="o">(</span><span class="n">eventTime</span> <span class="o">&lt;</span><span class="o">=</span> <span class="n">timerService</span><span class="o">.</span><span class="na">currentWatermark</span><span class="o">(</span><span class="o">)</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// This event is late; its window has already been triggered.
</span><span class="c1"></span>    <span class="n">ctx</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">lateFares</span><span class="o">,</span> <span class="n">fare</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
    <span class="o">.</span> <span class="o">.</span> <span class="o">.</span>
<span class="o">}</span>
</code></pre></div><p>并在访问这一侧输出的流时，在作业的 <code>main</code> 方法中输出:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// compute the sum of the tips per hour for each driver
</span><span class="c1"></span><span class="n">SingleOutputStreamOperator</span> <span class="n">hourlyTips</span> <span class="o">=</span> <span class="n">fares</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="o">(</span><span class="n">TaxiFare</span> <span class="n">fare</span><span class="o">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">fare</span><span class="o">.</span><span class="na">driverId</span><span class="o">)</span>
        <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">PseudoWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">hours</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="n">hourlyTips</span><span class="o">.</span><span class="na">getSideOutput</span><span class="o">(</span><span class="n">lateFares</span><span class="o">)</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>或者，您可以使用两个具有相同名称的 OutputTags 来引用同一侧面输出，但如果您这样做，它们必须具有相同的类型。</p>
<h2 id="结束语">结束语</h2>
<p>在这个例子中，你已经看到了如何使用 ProcessFunction 来重新实现一个直接的时间窗口。当然，如果 Flink 内置的窗口 API 满足你的需求，无论如何，请继续使用它。但如果你发现自己在考虑用 Flink 的窗口做一些变形，不要害怕推出自己的窗口。</p>
<p>此外，ProcessFunction 对于计算分析之外的许多其他用例也很有用。下面的实践练习提供了一个完全不同的例子。</p>
<p>ProcessFunction 的另一个常见用例是用于过期的陈旧状态。如果你回想一下 <a href="https://github.com/apache/flink-training/tree/release-1.11/rides-and-fares">Rides 和 Fares 练习</a>，其中使用 RichCoFlatMapFunction 来计算一个简单的连接，示例解决方案假设 TaxiRides 和 TaxiFares 是完美匹配的，每个 rideId 是一对一的。如果一个事件丢失了，同一乘车 ID 的其他事件将永远保持在状态。这可以替换为一个 KeyedCoProcessFunction 来实现，并且可以使用一个定时器来检测和清除任何陈旧的状态。</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实战练习是 <a href="https://github.com/apache/flink-training/tree/release-1.11/long-ride-alerts">Long Ride Alerts 练习</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/process_function.html">ProcessFunction</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/side_output.html">侧输出</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[学习 Flink: 实践培训]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Learn Flink: Hands-on Training</blockquote><h2 id="本次培训的目标和范围">本次培训的目标和范围</h2>
<p>本培训介绍了 Apache Flink，包括足够的内容让你开始编写可扩展的流式 ETL，分析和事件驱动的应用程序，同时省略了很多（最终重要的）细节。本书的重点是为 Flink 管理状态和时间的 API 提供直接的介绍，希望在掌握了这些基础知识后，你能更好地从更详细的参考文档中获取其余需要了解的内容。每一节末尾的链接将引导你到可以学习更多知识的地方。</p>
<p>具体来说，您将学习:</p>
<ul>
<li>如何实现流数据处理管道</li>
<li>Flink 如何以及为何管理状态</li>
<li>如何使用事件时间来持续计算准确的分析结果？</li>
<li>如何在连续流上构建事件驱动的应用程序？</li>
<li>Flink 是如何提供具有精确只读语义的容错、有状态的流处理的？</li>
</ul>
<p>本培训主要介绍四个关键概念：流数据的连续处理、事件时间、有状态的流处理和状态快照。本页介绍了这些概念。</p>
<p>注: 伴随本培训的是一套实践练习，它将指导您学习如何使用所介绍的概念。每一节的最后都提供了相关练习的链接。</p>
<h2 id="流处理">流处理</h2>
<p>流是数据的天然栖息地。无论是来自网络服务器的事件，还是来自股票交易所的交易，或者是来自工厂车间机器的传感器读数，数据都是作为流的一部分被创建的。但当你分析数据时，你可以围绕有界流或无界流组织处理，而你选择哪种范式会产生深远的影响。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/bounded-unbounded.png" alt="img"></p>
<p>当你处理一个有边界的数据流时，<strong>批处理</strong>是工作的范式。在这种操作模式下，你可以选择在产生任何结果之前摄取整个数据集，这意味着，例如，可以对数据进行排序，计算全局统计，或产生一个汇总所有输入的最终报告。</p>
<p>另一方面，<strong>流处理</strong>涉及无边界的数据流。至少在概念上，输入可能永远不会结束，因此你不得不在数据到达时持续处理数据。</p>
<p>在 Flink 中，应用程序由<strong>流式数据流</strong>组成，这些数据流可以通过用户定义的<strong>运算符</strong>进行转换。这些数据流形成有向图，从一个或多个源开始，到一个或多个 sink 结束。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/program_dataflow.svg" alt="img"></p>
<p>通常，程序中的变换(transformation)和数据流(dataflow)中的运算符(operator)之间存在一对一的对应关系。但有时，一个变换可能由多个运算符(operator)组成。</p>
<p>一个应用程序可能会消耗来自流式源的实时数据，如消息队列或分布式日志，如 Apache Kafka 或 Kinesis。但 Flink 也可以消耗来自各种数据源的有界历史数据。同样，Flink 应用正在产生的结果流也可以被发送到各种各样的系统，这些系统可以作为 sink 连接。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/flink-application-sources-sinks.png" alt="img"></p>
<h3 id="并行数据流">并行数据流</h3>
<p>Flink 中的程序本质上是并行和分布式的。在执行过程中，一个流有一个或多个流分区(<strong>stream partitions</strong>)，每个运算符(operator)有一个或多个运算符子任务(<strong>operator subtasks</strong>)。运算符子任务(<strong>operator subtasks</strong>)相互独立，在不同的线程中执行，也可能在不同的机器或容器上执行。</p>
<p>运算符符子任务(<strong>operator subtasks</strong>)的数量就是该特定运算符(operator)的并行度(<strong>parallelism</strong>)。同一程序的不同运算符可能具有不同的并行度水平。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel_dataflow.svg" alt="img"></p>
<p>流可以在两个运算符之间以一对一（或转发）的模式或以重分发的模式传输数据。</p>
<ul>
<li>
<p>一对一的流（例如上图中 Source 和 map() 运算符之间）保留了元素的分区和排序。这意味着 map() 运算符的 subtask[1] 将看到与 Source 运算符的 subtask[1] 所产生的元素顺序相同的元素。</p>
</li>
<li>
<p>重新分发流（如上面 map() 和 keyBy/window 之间，以及 keyBy/window 和 Sink 之间）会改变流的分区。每个运算符子任务(operator subtask)都会根据所选的转换将数据发送到不同的目标子任务。例如 keyBy()（通过散列键来重新分区）、broadcast() 或 rebalance()（随机重新分区）。在重分发交换中，元素之间的排序只在每一对发送和接收子任务中被保留（例如，map() 的 subtask[1] 和 keyBy/window 的 subtask[2]）。因此，例如，上面显示的 keyBy/window 和 Sink 运算符之间的重新分发，引入了关于不同键的聚合结果到达 Sink 的顺序的非确定性。</p>
</li>
</ul>
<h2 id="及时的流处理">及时的流处理</h2>
<p>对于大多数流式应用来说，能够用处理实时数据的相同代码重新处理历史数据是非常有价值的&ndash;无论如何，都能产生确定性的、一致的结果。</p>
<p>此外，关注事件发生的顺序，而不是事件交付处理的顺序，并且能够推理出一组事件何时（或应该）完成也是至关重要的。例如，考虑电子商务交易，或金融贸易中涉及的一系列事件。</p>
<p>通过使用记录在数据流中的事件时间戳，而不是使用处理数据的机器的时钟，可以满足这些及时流处理的要求。</p>
<h2 id="有状态的流处理">有状态的流处理</h2>
<p>Flink 的操作可以是有状态的。这意味着一个事件的处理方式可以取决于之前所有事件的累积效果。状态可以用于一些简单的事情，例如计算每分钟的事件以显示在仪表板上，或者用于一些更复杂的事情，例如计算欺诈检测模型的功能。</p>
<p>一个 Flink 应用是在分布式集群上并行运行的。一个给定的运算符的各种并行实例将以不同的线程独立执行，一般来说，它们将在不同的机器上运行。</p>
<p>一个有状态运算符的并行实例集实际上是一个分片的键值存储。每一个并行实例负责处理一组特定键的事件，这些键的状态被保存在本地。</p>
<p>下图显示了一个作业(Job)，在作业图(job graph)中的前三个运算符上运行的并行度为2，终止于一个并行度为 1 的 sink。第三个运算符是有状态的，你可以看到在第二个和第三个运算符之间发生了一个完全连接的网络洗牌。这是在通过一些键来对流进行分区，这样所有需要一起处理的事件，都会被一起处理。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/parallel-job.png" alt="img"></p>
<p>状态总是在本地访问，这有助于 Flink 应用实现高吞吐量和低延迟。你可以选择将状态保存在 JVM 堆上，如果状态太大，也可以将其保存在有效组织的磁盘数据结构中。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/local-state.png" alt="img"></p>
<h2 id="通过状态快照进行容错">通过状态快照进行容错</h2>
<p>Flink 能够通过状态快照和流重放的组合，提供容错、精确的一次性语义。这些快照捕获了分布式管道的整个状态，记录了进入输入队列的偏移以及整个作业图(job graph)中因摄取了该点数据而产生的状态。当发生故障时，源会被重放，状态被恢复，并恢复处理。如上所述，这些状态快照是异步捕获的，不会妨碍正在进行的处理。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[数据管道和 ETL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Data Pipelines &amp; ETL</blockquote><p>对于 Apache Flink 来说，一个非常常见的用例是实现 ETL（提取、转换、加载）管道，从一个或多个源中获取数据，进行一些转换和/或丰富，然后将结果存储在某个地方。在这一节中，我们将看看如何使用 Flink 的 DataStream API 来实现这种应用。</p>
<p>请注意，Flink的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">Table 和 SQL API</a>很适合许多 ETL 用例。但无论你最终是否直接使用 DataStream API，对这里介绍的基础知识有一个扎实的理解都是有价值的。</p>
<h2 id="无状态转换">无状态转换</h2>
<p>本节介绍了 map() 和 flatmap()，它们是用来实现无状态转换的基本操作。本节中的例子假设你熟悉 <a href="https://github.com/apache/flink-training/tree/release-1.11">flink-training</a> 仓库中的实战练习中使用的出租车乘车数据。</p>
<h3 id="map">map()</h3>
<p>在第一个练习中，你过滤了一个打车事件的流，在同一个代码库中，有一个 GeoUtils 类，它提供了一个静态方法 GeoUtils.mapToGridCell(float lon, float lat)，该方法将一个 location (longitude, latitude) 映射到一个网格单元，该单元指的是一个大约100x100米大小的区域。</p>
<p>现在让我们通过为每个事件添加 startCell 和 endCell 字段来丰富我们的打车对象流。你可以创建一个 EnrichedRide 对象，扩展 TaxiRide，添加这些字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">EnrichedRide</span> <span class="kd">extends</span> <span class="n">TaxiRide</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">startCell</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">endCell</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">EnrichedRide</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span><span class="o">}</span>

    <span class="kd">public</span> <span class="nf">EnrichedRide</span><span class="o">(</span><span class="n">TaxiRide</span> <span class="n">ride</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">rideId</span> <span class="o">=</span> <span class="n">ride</span><span class="o">.</span><span class="na">rideId</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">isStart</span> <span class="o">=</span> <span class="n">ride</span><span class="o">.</span><span class="na">isStart</span><span class="o">;</span>
        <span class="o">.</span><span class="o">.</span><span class="o">.</span>
        <span class="k">this</span><span class="o">.</span><span class="na">startCell</span> <span class="o">=</span> <span class="n">GeoUtils</span><span class="o">.</span><span class="na">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="na">startLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="na">startLat</span><span class="o">)</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">endCell</span> <span class="o">=</span> <span class="n">GeoUtils</span><span class="o">.</span><span class="na">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="na">endLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="na">endLat</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">toString</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="kd">super</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="o">)</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span>
            <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">startCell</span><span class="o">)</span> <span class="o">+</span> <span class="s">&#34;,&#34;</span> <span class="o">+</span>
            <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">endCell</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后，您可以创建一个应用程序，将流转化为:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">TaxiRideSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="k">val</span> <span class="n">enrichedNYCRides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">]</span>  <span class="k">=</span> <span class="n">rides</span>
    <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">new</span> <span class="nc">RideCleansingSolution</span><span class="o">.</span><span class="nc">NYCFilter</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">Enrichment</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="n">enrichedNYCRides</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>使用这个 MapFunction:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">Enrichment</span> <span class="k">extends</span> <span class="nc">MapFunction</span><span class="o">[</span><span class="kt">TaxiRide</span>, <span class="kt">EnrichedRide</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">taxiRide</span><span class="k">:</span> <span class="kt">TaxiRide</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="nc">EnrichedRide</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="flatmap">flatmap()</h3>
<p><code>MapFunction</code> 只适用于执行一对一的转换：对于每一个进入的流元素，<code>map()</code> 将发出一个转换后的元素。否则，你将需要使用 <code>flatmap()</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">TaxiRideSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="k">val</span> <span class="n">enrichedNYCRides</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">]</span> <span class="k">=</span> <span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="n">enrichedNYCRides</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>加上一个 <code>FlatMapFunction</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">NYCEnrichment</span> <span class="k">extends</span> <span class="nc">FlatMapFunction</span><span class="o">[</span><span class="kt">TaxiRide</span>, <span class="kt">EnrichedRide</span><span class="o">]</span> <span class="o">{</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">flatMap</span><span class="o">(</span><span class="n">taxiRide</span><span class="k">:</span> <span class="kt">TaxiRide</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">EnrichedRide</span><span class="o">]</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">valid</span><span class="k">:</span> <span class="kt">FilterFunction</span><span class="o">[</span><span class="kt">TaxiRide</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RideCleansing</span><span class="o">.</span><span class="nc">NYCFilter</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">valid</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">)</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="k">new</span> <span class="nc">EnrichedRide</span><span class="o">(</span><span class="n">taxiRide</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>通过这个接口提供的 Collector，<code>flatmap()</code> 方法可以随心所欲地发射许多流元素，包括完全不发射元素。</p>
<h2 id="keyed-streams">Keyed Streams</h2>
<h3 id="keyby">keyBy()</h3>
<p>通常，能够围绕一个属性对一个流进行分区是非常有用的，这样所有具有相同属性值的事件就会被归为一组。例如，假设你想找到从每个网格单元开始的最长的出租车乘车时间。从 SQL 查询的角度考虑，这意味着要对 startCell 进行某种 GROUP BY，而在 Flink 中，这是用 <code>keyBy(KeySelector)</code> 来完成的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&#34;startCell&#34;</span><span class="o">)</span>
</code></pre></div><p>每一个 <code>keyBy</code> 都会引起一次网络洗牌，对流进行重新分区。一般来说，这是很昂贵的，因为它涉及到网络通信以及序列化和反序列化。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/keyBy.png" alt="img"></p>
<p>在上面的例子中，键是由一个字段名 &ldquo;startCell&rdquo; 指定的。这种键选择的风格有一个缺点，那就是编译器无法推断用于键选择的字段的类型，因此 Flink 会将键值作为元组传递，这可能会很笨拙。最好是使用一个正确类型的 <code>KeySelector</code>，例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">rides</span>
    <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">NYCEnrichment</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span>
        <span class="k">new</span> <span class="n">KeySelector</span><span class="o">&lt;</span><span class="n">EnrichedRide</span><span class="o">,</span> <span class="kt">int</span><span class="o">&gt;</span><span class="o">(</span><span class="o">)</span> <span class="o">{</span>

            <span class="nd">@Override</span>
            <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getKey</span><span class="o">(</span><span class="n">EnrichedRide</span> <span class="n">enrichedRide</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="na">startCell</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">}</span><span class="o">)</span>
</code></pre></div><p>可以用 lambda 更简洁地表达出来。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">rides</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nc">NYCEnrichment</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="n">enrichedRide</span> <span class="o">-&gt;</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="n">startCell</span><span class="o">)</span>
</code></pre></div><h3 id="keys-are-computed">Keys are computed</h3>
<p>KeySelectors 并不局限于从你的事件中提取一个键，相反，它们可以用任何你想要的方式来计算键，只要产生的键是确定性的，并且有有效的 <code>hashCode()</code> 和 <code>equals()</code> 的实现。这个限制排除了生成随机数，或者返回数组或枚举的 KeySelectors，但是你可以使用元组或 POJOs 来生成复合键，例如，只要它们的元素遵循这些相同的规则。</p>
<p>键必须以确定性的方式产生，因为每当需要它们时，它们就会被重新计算，而不是附加到流记录上。</p>
<p>例如，我们不是创建一个新的 <code>EnrichedRide</code> 类，该类有一个 <code>startCell</code> 字段，然后我们将其用作键:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyBy</span><span class="o">(</span><span class="n">enrichedRide</span> <span class="o">-&gt;</span> <span class="n">enrichedRide</span><span class="o">.</span><span class="n">startCell</span><span class="o">)</span>
</code></pre></div><p>相反, 我们可以这样做:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyBy</span><span class="o">(</span><span class="n">ride</span> <span class="o">-&gt;</span> <span class="nc">GeoUtils</span><span class="o">.</span><span class="n">mapToGridCell</span><span class="o">(</span><span class="n">ride</span><span class="o">.</span><span class="n">startLon</span><span class="o">,</span> <span class="n">ride</span><span class="o">.</span><span class="n">startLat</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><h3 id="keyed-流的聚合">Keyed 流的聚合</h3>
<p>这段代码为每个 end-of-ride 事件创建一个新的元组流，其中包含 <code>startCell</code> 和持续时间（分钟）。</p>
<pre><code>import org.joda.time.Interval;

DataStream&lt;Tuple2&lt;Integer, Minutes&gt;&gt; minutesByStartCell = enrichedNYCRides
    .flatMap(new FlatMapFunction&lt;EnrichedRide, Tuple2&lt;Integer, Minutes&gt;&gt;() {

        @Override
        public void flatMap(EnrichedRide ride,
                            Collector&lt;Tuple2&lt;Integer, Minutes&gt;&gt; out) throws Exception {
            if (!ride.isStart) {
                Interval rideInterval = new Interval(ride.startTime, ride.endTime);
                Minutes duration = rideInterval.toDuration().toStandardMinutes();
                out.collect(new Tuple2&lt;&gt;(ride.startCell, duration));
            }
        }
    });
</code></pre><p>现在可以产生一个流，其中只包含那些对每个 <code>startCell</code> 来说是有史以来（至此）最长的乘车记录。</p>
<p>有多种方式可以表达作为键的字段。之前你看到了一个 EnrichedRide POJO 的例子，在这个例子中，要用作键的字段是用它的名字指定的。这个例子涉及到 Tuple2 对象，元组中的索引（从0开始）被用来指定键。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">minutesByStartCell</span>
  <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="c1">// startCell
</span><span class="c1"></span>  <span class="o">.</span><span class="n">maxBy</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="c1">// duration
</span><span class="c1"></span>  <span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>现在，每当持续时间达到一个新的最大值时，输出流就会包含一个针对每个键的记录&ndash;如这里的50797单元格所示。</p>
<pre><code>...
4&gt; (64549,5M)
4&gt; (46298,18M)
1&gt; (51549,14M)
1&gt; (53043,13M)
1&gt; (56031,22M)
1&gt; (50797,6M)
...
1&gt; (50797,8M)
...
1&gt; (50797,11M)
...
1&gt; (50797,12M)
</code></pre><h3 id="implicit-state">(Implicit) State</h3>
<p>这是本次训练中第一个涉及有状态流的例子。虽然状态被透明地处理，但 Flink 必须跟踪每个不同键的最大持续时间。</p>
<p>每当状态涉及到你的应用时，你应该考虑状态可能会变得多大。每当键空间是无限制的，那么 Flink 需要的状态量也是无限制的。</p>
<p>当处理流时，一般来说，在有限的窗口上考虑聚合比在整个流上考虑更有意义。</p>
<h3 id="reduce-和其他聚合器">reduce() 和其他聚合器</h3>
<p>上文中使用的 <code>maxBy()</code> 只是 Flink 的 KeyedStreams 上众多聚合函数中的一个例子。还有一个更通用的 <code>reduce()</code> 函数，你可以用它来实现自己的自定义聚合。</p>
<h2 id="状态转换">状态转换</h2>
<h3 id="为什么-flink-要参与管理状态">为什么 Flink 要参与管理状态？</h3>
<p>你的应用程序当然能够在没有让 Flink 参与管理状态的情况下使用状态&ndash;但 Flink 为它所管理的状态提供了一些引人注目的功能。</p>
<ul>
<li>本地化。Flink 状态被保存在处理它的机器的本地，并且可以以内存速度被访问。</li>
<li>耐用。Flink 状态是容错的，即每隔一段时间就会自动检查一次，一旦失败就会恢复。</li>
<li>纵向可扩展。Flink 状态可以保存在嵌入式 RocksDB 实例中，通过增加更多的本地磁盘来扩展。</li>
<li>横向可扩展。随着集群的增长和收缩，Flink 状态会被重新分配。</li>
<li>可查询。Flink 状态可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/queryable_state.html">可查询状态 API</a> 进行外部查询。</li>
</ul>
<p>在本节中，您将学习如何使用 Flink 的 API 管理 keyed 状态。</p>
<h3 id="rich-函数">Rich 函数</h3>
<p>此时你已经看到了 Flink 的几个函数接口，包括 <code>FilterFunction</code>、<code>MapFunction</code> 和 <code>FlatMapFunction</code>。这些都是单一抽象方法模式的例子。</p>
<p>对于每一个接口，Flink 还提供了一个所谓的&quot;富&quot;变体，例如，<code>RichFlatMapFunction</code>，它有一些额外的方法，包括:</p>
<ul>
<li>open(Configuration c)</li>
<li>close()</li>
<li>getRuntimeContext()</li>
</ul>
<p><code>open()</code> 在操作符初始化期间被调用一次。这是一个加载一些静态数据的机会，或者, 例如打开一个外部服务的连接。</p>
<p><code>getRuntimeContext()</code> 提供了对一整套潜在的有趣的东西的访问，但最值得注意的是它是如何创建和访问由 Flink 管理的状态。</p>
<h3 id="一个带有-keyed-state-的例子">一个带有 Keyed State 的例子</h3>
<p>在这个例子中，想象一下，你有一个事件流，你想去掉重复，所以你只保留每个键的第一个事件。这里有一个应用程序可以做到这一点，使用一个名为 <code>Deduplicator</code> 的 <code>RichFlatMapFunction</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Event</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">key</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">timestamp</span><span class="o">;</span>
    <span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[</span><span class="o">]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
  
    <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">EventSource</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">e</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">e</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
        <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">Deduplicator</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
  
    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>为了达到这个目的，Deduplicator 将需要以某种方式记住，对于每个键来说，是否已经有了该键的事件。它将使用 Flink 的 <em>keyed state</em> 接口来做到这一点。</p>
<p>当你在使用像这样的 <em>keyed</em> 流时，Flink 将为每个被管理的状态项目维护一个键/值存储。</p>
<p>Flink 支持几种不同类型的 <em>keyed state</em>，本例使用的是最简单的一种，即 <code>ValueState</code>。这意味着对于每个键，Flink 将存储一个单一的对象&ndash;在本例中，一个类型为 Boolean 的对象。</p>
<p>我们的 Deduplicator 类有两个方法：<code>open()</code> 和 <code>flatMap()</code>。<code>open</code> 方法通过定义一个 ValueStateDescriptor<!-- raw HTML omitted -->` 来建立对托管状态的使用。构造函数的参数为这个 <em>keyed state</em> 项指定了一个名称（&ldquo;keyHasBeenSeen&rdquo;），并提供了可用于序列化这些对象的信息（在本例中，Types.BOOLEAN）。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Deduplicator</span> <span class="kd">extends</span> <span class="n">RichFlatMapFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">Event</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">keyHasBeenSeen</span><span class="o">;</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">desc</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="o">&gt;</span><span class="o">(</span><span class="s">&#34;keyHasBeenSeen&#34;</span><span class="o">,</span> <span class="n">Types</span><span class="o">.</span><span class="na">BOOLEAN</span><span class="o">)</span><span class="o">;</span>
        <span class="n">keyHasBeenSeen</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">getState</span><span class="o">(</span><span class="n">desc</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="na">value</span><span class="o">(</span><span class="o">)</span> <span class="o">=</span><span class="o">=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">event</span><span class="o">)</span><span class="o">;</span>
            <span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>当 <code>flatMap</code> 方法调用 <code>keyHasBeenSeen.value()</code> 时，Flink 的运行时会在上下文中查找 key 的这块状态值，只有当它为 null 时，它才会去收集事件到输出。在这种情况下，它还会将 <code>keyHasBeenSeen</code> 更新为 true。</p>
<p>这种访问和更新 key-partitioned 状态的机制可能看起来相当神奇，因为在我们的 Deduplicator 的实现中，key 并不是显式可见的。当 Flink 的运行时调用我们的 <code>RichFlatMapFunction</code> 的 <code>open</code> 方法时，没有任何事件，因此那一刻上下文中没有 key。但是当它调用 <code>flatMap</code> 方法时，被处理的事件的 key 对运行时来说是可用的，并在幕后用于确定 Flink 的状态后端中的哪个条目被操作。</p>
<p>当部署到分布式集群时，会有很多这个 Deduplicator 的实例，每个实例将负责整个键空间的一个不相干子集。因此，当你看到一个 ValueState 的单项，如:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">keyHasBeenSeen</span><span class="o">;</span>
</code></pre></div><p>理解这不仅仅是一个单一的布尔值，而是一个分布式的、分片式的、键/值存储。</p>
<h3 id="清除状态">清除状态</h3>
<p>上面的例子有一个潜在的问题。如果键的空间是无限制的，会发生什么？Flink 是在某个地方为每一个被使用的不同键存储一个布尔的实例。如果有一个有界的键集，那么这将是很好的，但是在键集以无界的方式增长的应用中，有必要为不再需要的键清除状态。这是通过调用状态对象上的 <code>clear()</code> 来实现的，如:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">keyHasBeenSeen</span><span class="o">.</span><span class="n">clear</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><p>例如，你可能想在给定键的一段时间不活动后这样做。当你在事件驱动的应用程序一节中学习 <code>ProcessFunction</code> 时，你将看到如何使用 <code>Timer</code> 来实现这一点。</p>
<p>此外，还有一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#state-time-to-live-ttl">状态存活时间(TTL)</a>选项，你可以用状态描述符来配置，指定什么时候自动清除陈旧键的状态。</p>
<h3 id="non-keyed-state">Non-keyed State</h3>
<p>也可以在 non-keyed 的上下文中使用托管状态。这有时被称为 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/state.html#operator-state">operator state</a>。所涉及的接口有些不同，由于用户定义的函数需要 non-keyed state 是不常见的，所以这里不做介绍。这个功能最常用于源和接收器(sink)的实现。</p>
<h2 id="connected-streams">Connected Streams</h2>
<p>有时不是应用这样的预定义变换:</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/transformation.svg" alt="img"></p>
<p>你希望能够动态地改变变换的某些方面&ndash;通过流的阈值，或规则，或其他参数。Flink 中支持这种模式的是一种叫做连接流(connected streams)的东西，其中一个 operator 有两个输入流，就像这样:</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/connected-streams.svg" alt="img"></p>
<p>连接流也可以用来实现流式连接(streaming joins.)。</p>
<h3 id="例子">例子</h3>
<p>在这个例子中，控制流被用来指定必须从  streamOfWords 中过滤掉的单词。一个名为 ControlFunction 的 RichCoFlatMapFunction 被应用到连接的流中来完成这个任务。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[</span><span class="o">]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

    <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">control</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">&#34;DROP&#34;</span><span class="o">,</span> <span class="s">&#34;IGNORE&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">x</span><span class="o">)</span><span class="o">;</span>
    <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">streamOfWords</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="s">&#34;Apache&#34;</span><span class="o">,</span> <span class="s">&#34;DROP&#34;</span><span class="o">,</span> <span class="s">&#34;Flink&#34;</span><span class="o">,</span> <span class="s">&#34;IGNORE&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">x</span><span class="o">)</span><span class="o">;</span>
  
    <span class="n">control</span>
        <span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="n">datastreamOfWords</span><span class="o">)</span>
        <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">ControlFunction</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

    <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>注意，被连接的两个流必须以兼容的方式进行 keyed。keyBy 的作用是对流的数据进行分区，当 keyed 流连接时，必须以同样的方式进行分区。这样就可以保证两个流中具有相同 key 的事件都会被发送到同一个实例中。那么，这就使得将该键上的两个流连接起来成为可能，例如。</p>
<p>在这种情况下，两个流的类型都是 <code>DataStream[String]</code>，并且两个流都以字符串为键。如下所示，这个 <code>RichCoFlatMapFunction</code> 在  keyed state 下存储了一个布尔值，而这个布尔值是由两个流共享的。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ControlFunction</span> <span class="kd">extends</span> <span class="n">RichCoFlatMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">ValueState</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">&gt;</span> <span class="n">blocked</span><span class="o">;</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">config</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">blocked</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">getState</span><span class="o">(</span><span class="k">new</span> <span class="n">ValueStateDescriptor</span><span class="o">&lt;</span><span class="o">&gt;</span><span class="o">(</span><span class="s">&#34;blocked&#34;</span><span class="o">,</span> <span class="n">Boolean</span><span class="o">.</span><span class="na">class</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap1</span><span class="o">(</span><span class="n">String</span> <span class="n">control_value</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">blocked</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="n">Boolean</span><span class="o">.</span><span class="na">TRUE</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
      
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">flatMap2</span><span class="o">(</span><span class="n">String</span> <span class="n">data_value</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">blocked</span><span class="o">.</span><span class="na">value</span><span class="o">(</span><span class="o">)</span> <span class="o">=</span><span class="o">=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">data_value</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>RichCoFlatMapFunction 是 FlatMapFunction 的一种，它可以应用于一对连接的流，并且它可以访问富函数接口。这意味着它可以被做成有状态的。</p>
<p>屏蔽的(blocked)布尔正在被用来记住控制流上提到的键（在这里是单词），这些词被过滤出 streamOfWords 流。这就是 <em>keyed state</em>，它在两个流之间是共享的，这就是为什么两个流要共享同一个键空间。</p>
<p><code>flatMap1</code> 和 <code>flatMap2</code> 被 Flink 运行时调用，分别来自两个连接流的元素&ndash;在我们的例子中，来自控制流的元素被传入 <code>flatMap1</code>，来自 <code>streamOfWords</code> 的元素被传入 <code>flatMap2</code>。这是由使用 <code>control.connect(datastreamOfWords)</code> 连接两个流的顺序决定的。</p>
<p>重要的是要认识到，你无法控制调用 <code>flatMap1</code> 和 <code>flatMap2</code> 回调的顺序。这两个输入流在相互竞争，Flink 运行时将对来自一个流或另一个流的事件的消耗做它想做的事。在时间和/或顺序很重要的情况下，你可能会发现有必要在托管的 Flink 状态下缓冲事件，直到你的应用程序准备好处理它们。(注意：如果你真的很绝望，可以通过使用实现 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/streaming/api/operators/InputSelectable.html">InputSelectable</a> 接口的自定义 Operator 来对双输入 operator 消耗输入的顺序进行一些有限的控制。)</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实践练习是<a href="https://github.com/apache/flink-training/tree/release-1.11/rides-and-fares">&ldquo;乘车与票价练习&rdquo;</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#datastream-transformations">数据流转换</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态的流处理</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[流分析]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="related" type="text/html" title="通过状态快照进行容错" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Streaming Analytics</blockquote><h2 id="event-time-和-watermarks">Event Time 和 Watermarks</h2>
<h3 id="介绍">介绍</h3>
<p>Flink 明确支持三种不同的时间概念。</p>
<p>事件时间：事件发生的时间，由产生（或存储）该事件的设备记录的时间</p>
<p>摄取时间：Flink 在摄取事件时记录的时间戳。</p>
<p>处理时间：您的管道中的特定 operator 处理事件的时间。</p>
<p>为了获得可重复的结果，例如，在计算某一天股票在交易的第一个小时内达到的最高价格时，您应该使用事件时间(event time)。这样一来，结果就不会依赖于计算的时间。这种实时应用有时会使用处理时间(processing time)，但这样一来，结果就会由该小时内恰好处理的事件决定，而不是由当时发生的事件决定。基于处理时间的计算分析会导致不一致，并使重新分析历史数据或测试新的实现变得困难。</p>
<h3 id="使用事件时间">使用事件时间</h3>
<p>默认情况下，Flink 将使用处理时间(processing time)。要改变这一点，您可以设置时间特性(Time Characteristic)。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span>
    <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="n">env</span><span class="o">.</span><span class="na">setStreamTimeCharacteristic</span><span class="o">(</span><span class="n">TimeCharacteristic</span><span class="o">.</span><span class="na">EventTime</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>如果你想使用事件时间，你还需要提供一个时间戳提取器和水印生成器，Flink 将使用它们来跟踪事件时间的进展。这将在下面的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/streaming_analytics.html#working-with-watermarks">&ldquo;使用水印&rdquo;</a>一节中介绍，但首先我们应该解释一下什么是水印。</p>
<h3 id="水印">水印</h3>
<p>让我们通过一个简单的例子来说明为什么需要水印，以及它们是如何工作的。</p>
<p>在这个例子中，你有一个带时间戳的事件流，这些事件的到达顺序有些混乱，如下所示。显示的数字是时间戳，表示这些事件实际发生的时间。第一个到达的事件发生在时间 4，随后是更早发生的事件，在时间 2，以此类推。</p>
<pre><code>··· 23 19 22 24 21 14 17 13 12 15 9 11 7 2 4 →
</code></pre><p>现在想象一下，你正在尝试创建一个流排序器(stream sorter)。这个应用程序的目的是处理流中的每个事件，并发出一个新的流，其中包含相同的事件，但按时间戳排序。</p>
<p>一些观察:</p>
<p>(1)你的流排序器看到的第一个元素是 4， 但你不能马上把它作为排序流的第一个元素释放出来。它可能已经不按顺序到达，而更早的事件可能还没有到达。事实上，你对这个流的未来有一些神一样的知识，你可以看到，你的流排序器至少应该等到 2 到达后再产生任何结果。</p>
<p>一些缓冲，和一些延迟，是必要的。</p>
<p>(2)如果你做错了，你可能最终会永远等待。首先，排序器看到了一个来自时间 4 的事件，然后是一个来自时间 2 的事件。一个时间戳小于 2 的事件会不会永远到达？也许会，也许不会。也许不会。你可以永远等待，永远看不到 1。</p>
<p>最终你必须鼓起勇气，发出 2 作为排序流的开始。</p>
<p>(3)那么你需要的是某种策略，它定义了对于任何给定的时间戳事件，何时停止等待早期事件的到来。</p>
<p>这正是水印的作用&ndash;它们定义了何时停止等待早期(earlier)事件。</p>
<p>Flink 中的事件时间处理依赖于水印生成器，这些水印生成器将特殊的时间戳元素插入到流中，称为水印。时间 t 的水印是一种断言，即到时间 t 为止，流现在（可能）是完整的。</p>
<p>这个流排序器应该在什么时候停止等待，并推出2开始排序流？当一个时间戳为 2，或更大的水印到达时。</p>
<p>(4)你可以想象不同的策略来决定如何生成水印。</p>
<p>每一个事件都是在一些延迟之后到达的，而这些延迟是不同的，所以一些事件的延迟比其他事件更多。一个简单的方法是假设这些延迟被某个最大延迟所约束。Flink 将这种策略称为有界无序水印。很容易想象更复杂的水印方法，但对于大多数应用来说，固定的延迟已经足够好了。</p>
<h3 id="延迟与完整性">延迟与完整性</h3>
<p>关于水印的另一种思考方式是，水印让你这个流式应用的开发者能够控制延迟和完整性之间的权衡。与批处理不同的是，在批处理中，人们可以在产生任何结果之前完全了解输入，而在流式处理中，你最终必须停止等待看到更多的输入，并产生某种结果。</p>
<p>你可以积极地配置你的水印，用一个很短的延迟，从而承担在对输入不完全了解的情况下产生结果的风险&ndash;也就是说，一个可能是错误的结果，很快就产生了。或者你可以等待更长时间，并利用对输入流更完整的知识产生结果。</p>
<p>也可以实现混合解决方案，快速生成初始结果，然后在处理额外（后期）数据时对这些结果进行更新。对于某些应用来说，这是一种很好的方法。</p>
<h3 id="延迟">延迟</h3>
<p>迟到的定义是相对于水印而言的。水印(t)声明流在时间t之前是完整的；在这个水印之后的任何事件，如果时间戳 ≤t，则为延迟。</p>
<h3 id="使用水印">使用水印</h3>
<p>为了执行基于事件时间的事件处理，Flink 需要知道与每个事件相关联的时间，还需要流包含水印。</p>
<p>实践练习中使用的 Taxi 数据源为你处理了这些细节。但在你自己的应用程序中，你必须自己处理这些事情，通常是通过实现一个类来实现，该类从事件中提取时间戳，并按需生成水印。最简单的方法是使用 WatermarkStrategy:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">strategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
        <span class="o">.</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="n">20</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="o">(</span><span class="n">event</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">timestamp</span><span class="o">)</span><span class="o">;</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">withTimestampsAndWatermarks</span> <span class="o">=</span>
    <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">strategy</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="窗口">窗口</h2>
<p>Flink 具有非常有表现力的窗口语义。</p>
<p>在本节中，你将学习</p>
<ul>
<li>如何使用窗口来计算无边界流的聚合。</li>
<li>Flink 支持哪些类型的窗口，以及</li>
<li>如何实现一个窗口化聚合的 DataStream 程序？</li>
</ul>
<h3 id="介绍-1">介绍</h3>
<p>在做流处理的时候，自然而然地想要计算流的有界子集的聚合分析，以回答这样的问题。</p>
<ul>
<li>每分钟的页面浏览量</li>
<li>每个用户每周会话数</li>
<li>每个传感器每分钟的最高温度</li>
</ul>
<p>用 Flink 计算窗口化分析依赖于两个主要的抽象。窗口分配器（Window Assigners）将事件分配给窗口（必要时创建新的窗口对象），窗口函数（Window Functions）应用于分配给窗口的事件。</p>
<p>Flink 的窗口 API 还有 Triggers 的概念，它决定什么时候调用窗口函数，还有 Evictors，它可以删除窗口中收集的元素。</p>
<p>在它的基本形式中，你将窗口化应用到像这样的 keyed stream 中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="o">&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="o">&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">|</span><span class="n">aggregate</span><span class="o">|</span><span class="n">process</span><span class="o">(</span><span class="o">&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;</span><span class="o">)</span>
</code></pre></div><p>您也可以对 non-keyed stream 使用窗口化，但请记住，在这种情况下，处理将不会并行进行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="n">windowAll</span><span class="o">(</span><span class="o">&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="o">|</span><span class="n">aggregate</span><span class="o">|</span><span class="n">process</span><span class="o">(</span><span class="o">&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;</span><span class="o">)</span>
</code></pre></div><h3 id="窗口分配器">窗口分配器</h3>
<p>Flink 有几种内置的窗口分配器类型，下面进行说明。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/window-assigners.svg" alt="img"></p>
<p>一些例子说明这些窗口分配器的用途，以及如何指定它们:</p>
<ul>
<li>
<p>滚动时间窗口</p>
</li>
<li>
<p>每分钟浏览量</p>
</li>
<li>
<p>TumblingEventTimeWindows.of(Time.minutes(1))</p>
</li>
<li>
<p>滑动时间窗口</p>
</li>
<li>
<p>每10秒计算的每分钟页面浏览量</p>
</li>
<li>
<p>SlidingEventTimeWindows.of(Time.min(1), Time.seconds(10))</p>
</li>
<li>
<p>会话窗口</p>
</li>
<li>
<p>每节课的页面浏览量，其中每节课之间至少有30分钟的间隔。</p>
</li>
<li>
<p>EventTimeSessionWindows.withGap(Time.minutes(30))</p>
</li>
</ul>
<p>可以使用 Time.milliseconds(n), Time.seconds(n), Time.minutes(n), Time.hours(n), 和 Time.days(n) 中的一种指定持续时间。</p>
<p>基于时间的窗口分配器（包括会话窗口）有事件时间(event time)和处理时间(processing time)两种风味。这两种类型的时间窗口之间有显著的权衡。对于处理时间窗口，你必须接受这些限制:</p>
<ul>
<li>不能正确处理历史数据。</li>
<li>不能正确处理失序数据。</li>
<li>结果将是非确定性的。</li>
</ul>
<p>但具有较低延迟的优势。</p>
<p>当使用基于计数的窗口时，请记住，这些窗口将不会启动，直到一个批次完成。没有超时和处理部分窗口的选项，尽管你可以用自定义的触发器自己实现这种行为。</p>
<p>全局窗口分配器将每个事件（用相同的键）分配到同一个全局窗口。只有当你打算使用自定义触发器来做你自己的自定义窗口时，这才是有用的。在许多看似有用的情况下，您最好使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#process-functions">另一节</a>中描述的 ProcessFunction。</p>
<h3 id="窗口函数">窗口函数</h3>
<p>对于如何处理窗口的内容，您有三个基本选项。</p>
<ol>
<li>作为一个批次，使用一个 ProcessWindowFunction，它将被传递一个包含窗口内容的 Iterable。</li>
<li>以增量方式，使用 ReduceFunction 或 AggregateFunction，当每个事件被分配到窗口时被调用。</li>
<li>或两者结合，当窗口被触发时，ReduceFunction 或 AggregateFunction 的预聚集结果被提供给 ProcessWindowFunction。</li>
</ol>
<p>这里是方法1和3的例子。每个实现都在1分钟的事件时间窗口中从每个传感器中找到峰值值，并产生一个包含(key, end-of-window-timestamp, max_value) 的 Tuples 流。</p>
<h4 id="processwindowfunction-示例">ProcessWindowFunction 示例</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="n">input</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">x</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">MyWastefulMax</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyWastefulMax</span> <span class="kd">extends</span> <span class="n">ProcessWindowFunction</span><span class="o">&lt;</span>
        <span class="n">SensorReading</span><span class="o">,</span>                  <span class="c1">// input type
</span><span class="c1"></span>        <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span><span class="o">,</span>  <span class="c1">// output type
</span><span class="c1"></span>        <span class="n">String</span><span class="o">,</span>                         <span class="c1">// key type
</span><span class="c1"></span>        <span class="n">TimeWindow</span><span class="o">&gt;</span> <span class="o">{</span>                   <span class="c1">// window type
</span><span class="c1"></span>    
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span>
            <span class="n">String</span> <span class="n">key</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">context</span><span class="o">,</span> 
            <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">events</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>

        <span class="kt">int</span> <span class="n">max</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">SensorReading</span> <span class="n">event</span> <span class="o">:</span> <span class="n">events</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">max</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">event</span><span class="o">.</span><span class="na">value</span><span class="o">,</span> <span class="n">max</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">context</span><span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">getEnd</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="n">max</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>在这个实现中，有几件事需要注意。</p>
<ul>
<li>所有分配给窗口的事件都必须在 keyed Flink state 下被缓冲，直到窗口被触发。这可能是相当昂贵的。</li>
<li>我们的 ProcessWindowFunction 被传递了一个 Context 对象，其中包含了窗口的信息。它的接口是这样的:</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">Context</span> <span class="kd">implements</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">Serializable</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">W</span> <span class="nf">window</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">long</span> <span class="nf">currentProcessingTime</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="kt">long</span> <span class="nf">currentWatermark</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>

    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">KeyedStateStore</span> <span class="nf">windowState</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kd">abstract</span> <span class="n">KeyedStateStore</span> <span class="nf">globalState</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>windowState 和 globalState 是您可以存储该键的所有窗口的 per-key, per-window, 或全局 per-key 信息的地方。例如，如果您想记录一些关于当前窗口的信息，并在处理后续窗口时使用这些信息，这可能会很有用。</p>
<h4 id="递增聚合示例">递增聚合示例</h4>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="n">input</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">x</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">x</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(</span><span class="k">new</span> <span class="n">MyReducingMax</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="n">MyWindowFunction</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyReducingMax</span> <span class="kd">implements</span> <span class="n">ReduceFunction</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="n">SensorReading</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">SensorReading</span> <span class="n">r1</span><span class="o">,</span> <span class="n">SensorReading</span> <span class="n">r2</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">r1</span><span class="o">.</span><span class="na">value</span><span class="o">(</span><span class="o">)</span> <span class="o">&gt;</span> <span class="n">r2</span><span class="o">.</span><span class="na">value</span><span class="o">(</span><span class="o">)</span> <span class="o">?</span> <span class="n">r1</span> <span class="o">:</span> <span class="n">r2</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyWindowFunction</span> <span class="kd">extends</span> <span class="n">ProcessWindowFunction</span><span class="o">&lt;</span>
    <span class="n">SensorReading</span><span class="o">,</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">SensorReading</span><span class="o">&gt;</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span>
            <span class="n">String</span> <span class="n">key</span><span class="o">,</span>
            <span class="n">Context</span> <span class="n">context</span><span class="o">,</span>
            <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">SensorReading</span><span class="o">&gt;</span> <span class="n">maxReading</span><span class="o">,</span>
            <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">SensorReading</span><span class="o">&gt;</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>

        <span class="n">SensorReading</span> <span class="n">max</span> <span class="o">=</span> <span class="n">maxReading</span><span class="o">.</span><span class="na">iterator</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">next</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
        <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="n">Tuple3</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">context</span><span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">getEnd</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="n">max</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>请注意，<code>Iterable&lt;SensorReading&gt;</code> 将只包含一个读数&ndash;由 MyReducingMax 计算的 pre-aggregated 最大值。</p>
<h3 id="迟来的事件">迟来的事件</h3>
<p>默认情况下，当使用事件时间窗口时，迟到的事件会被丢弃。窗口 API 有两个可选部分可以让您对此有更多的控制。</p>
<p>您可以使用名为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/event_driven.html#side-outputs">&ldquo;侧输出&rdquo;</a>的机制，安排将被丢弃的事件收集到一个备用的输出流中。下面是一个例子，说明这可能是什么样子的:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">lateTag</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="o">(</span><span class="s">&#34;late&#34;</span><span class="o">)</span><span class="o">{</span><span class="o">}</span><span class="o">;</span>

<span class="n">SingleOutputStreamOperator</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
    <span class="o">.</span><span class="na">sideOutputLateData</span><span class="o">(</span><span class="n">lateTag</span><span class="o">)</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">;</span>
  
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">lateStream</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">getSideOutput</span><span class="o">(</span><span class="n">lateTag</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>您还可以指定允许的延迟时间间隔，在此期间，延迟事件将继续分配给相应的窗口（其状态将被保留）。默认情况下，每个延迟事件都会导致窗口函数再次被调用（有时称为延迟发射）。</p>
<p>换句话说，水印后面的元素会被丢弃（或发送到侧输出）。</p>
<p>比如说:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">stream</span><span class="o">.</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
    <span class="o">.</span><span class="na">allowedLateness</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="n">10</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>当允许的延迟大于零时，只有那些晚到会被丢弃的事件才会被发送到侧输出（如果已经配置了）。</p>
<h3 id="惊喜">惊喜</h3>
<p>Flink 的 windowing API 的某些方面可能并不像你所期望的那样。基于 <a href="https://flink.apache.org/community.html#mailing-lists">flink 用户邮件列表</a>和其他地方的常见问题，这里有一些关于窗口的事实可能会让你感到惊讶。</p>
<h4 id="滑动窗口会进行复制">滑动窗口会进行复制</h4>
<p>滑动窗口分配器可以创建很多窗口对象，并会将每个事件复制到每个相关窗口中。例如，如果你每15分钟有一个长度为24小时的滑动窗口，每个事件将被复制到 4*24=96 个窗口中。</p>
<h4 id="时间窗口与纪元对齐">时间窗口与纪元对齐</h4>
<p>仅仅因为你使用了一个小时的处理时间窗口，并且在 12:05 开始运行你的应用程序，并不意味着第一个窗口会在 1:05 关闭。第一个窗口将长达 55 分钟，并在 1:00 关闭。</p>
<p>但是请注意，滚动窗口和滑动窗口分配器采用一个可选的偏移参数，可以用来改变窗口的对齐方式。详情请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#tumbling-windows">滚动窗口</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#sliding-windows">滑动窗口</a>。</p>
<h4 id="窗口可以跟随窗口">窗口可以跟随窗口</h4>
<p>例如，这样做是可行的:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">stream</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">t</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">t</span><span class="o">.</span><span class="na">key</span><span class="o">)</span>
    <span class="o">.</span><span class="na">timeWindow</span><span class="o">(</span><span class="o">&lt;</span><span class="n">time</span> <span class="n">specification</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(</span><span class="o">&lt;</span><span class="n">reduce</span> <span class="n">function</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">timeWindowAll</span><span class="o">(</span><span class="o">&lt;</span><span class="n">same</span> <span class="n">time</span> <span class="n">specification</span><span class="o">&gt;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">reduce</span><span class="o">(</span><span class="o">&lt;</span><span class="n">same</span> <span class="n">reduce</span> <span class="n">function</span><span class="o">&gt;</span><span class="o">)</span>
</code></pre></div><p>你可能会期望 Flink 的运行时足够聪明，能够为你做这种并行的预聚合（前提是你使用的是 ReduceFunction 或 AggregateFunction），但事实并非如此。</p>
<p>之所以这样做的原因是，一个时间窗口产生的事件会根据窗口结束的时间分配时间戳。所以，例如，一个小时长的窗口产生的所有事件都会有标记一个小时结束的时间戳。任何消耗这些事件的后续窗口的持续时间应该与前一个窗口的持续时间相同，或者是其倍数。</p>
<h4 id="空的时间窗口没有结果">空的时间窗口没有结果</h4>
<p>只有当事件被分配到窗口时，才会创建窗口。因此，如果在给定的时间帧内没有事件，就不会报告结果。</p>
<h4 id="迟来的事件会导致迟来的合并">迟来的事件会导致迟来的合并</h4>
<p>会话窗口是基于可以合并的窗口的抽象。每个元素最初都被分配到一个新的窗口，之后只要窗口之间的间隙足够小，就会合并。这样一来，一个迟到的事件可以弥合分开两个之前独立的会话的差距，产生迟到的合并。</p>
<h2 id="实践">实践</h2>
<p>与本节配套的实战练习是 <a href="https://github.com/apache/flink-training/tree/release-1.11/hourly-tips">Hourly Tips Exercise</a>。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html">及时的流处理</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[通过状态快照进行容错]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-intro-to-the-datastream-api/?utm_source=atom_feed" rel="related" type="text/html" title="DataStream API 介绍" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-event-driven-applications/?utm_source=atom_feed" rel="related" type="text/html" title="事件驱动型应用程序" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-learn-flink-hands-on-training/?utm_source=atom_feed" rel="related" type="text/html" title="学习 Flink: 实践培训" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-data-pipelines-and-etl/?utm_source=atom_feed" rel="related" type="text/html" title="数据管道和 ETL" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-19-streaming-analytics/?utm_source=atom_feed" rel="related" type="text/html" title="流分析" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-19-fault-tolerance/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-19T00:00:00+08:00</published>
            <updated>2020-08-19T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Fault Tolerance via State Snapshots</blockquote><h2 id="状态后端">状态后端</h2>
<p>Flink 管理的 keyed state 是一种碎片化的、键/值存储，每项 keyed state 的工作副本都被保存在负责该键的 taskmanager 的本地某处。Operator 的状态也被保存在需要它的机器的本地。Flink 会定期对所有状态进行持久化快照，并将这些快照复制到某个更持久的地方，比如分布式文件系统。</p>
<p>在发生故障的情况下，Flink 可以恢复你的应用程序的完整状态，并恢复处理，就像什么都没有发生过一样。</p>
<p>Flink 管理的这种状态被存储在状态后端中。状态后端有两种实现&ndash;一种是基于 RocksDB 的，它是一个嵌入式的键/值存储，将其工作状态保存在磁盘上；另一种是基于堆的状态后端，将其工作状态保存在内存中，在 Java 堆上。这种基于堆的状态后端有两种风味：将其状态快照持久化到分布式文件系统的 FsStateBackend 和使用 JobManager 的堆的 MemoryStateBackend。</p>
<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">工作状态</th>
<th align="left">状态备份</th>
<th align="left">快照</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">RocksDBStateBackend</td>
<td align="left">本地磁盘(tmp dir)</td>
<td align="left">分布式文件系统</td>
<td align="left">完全/增量</td>
</tr>
<tr>
<td align="left">支持大于可用内存的状态; 经验法则：比基于堆的后端慢10倍。</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">FsStateBackend</td>
<td align="left">JVM Heap</td>
<td align="left">分布式文件系统</td>
<td align="left">Full</td>
</tr>
<tr>
<td align="left">速度快，需要大量堆积; 受制于 GC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">MemoryStateBackend</td>
<td align="left">JVM Heap</td>
<td align="left">JobManager JVM Heap</td>
<td align="left">Full</td>
</tr>
<tr>
<td align="left">有利于小状态（地方）的测试和实验。</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>当处理保存在基于堆的状态后端的状态时，访问和更新涉及到在堆上读写对象。但是对于保存在 RocksDBStateBackend 中的对象，访问和更新涉及到序列化和反序列化，因此成本更高。但是使用 RocksDB 可以拥有的状态数量只受限于本地磁盘的大小。还要注意的是，只有 RocksDBStateBackend 能够进行增量快照，这对于有大量缓慢变化的状态的应用来说是一个很大的好处。</p>
<p>所有这些状态后端都能够进行异步快照，这意味着它们可以在不妨碍正在进行的流处理的情况下进行快照。</p>
<h2 id="状态快照">状态快照</h2>
<h3 id="定义">定义</h3>
<ul>
<li>快照&ndash;一个通用术语，指的是一个 Flink 作业状态的全局、一致的图像。快照包括进入每个数据源的指针（例如，进入文件或 Kafka 分区的偏移），以及来自每个作业的有状态操作符的状态副本，这些操作符是在处理了所有事件后产生的，直到源中的这些位置。</li>
<li>检查点&ndash;Flink 为了能够从故障中恢复而自动拍摄的快照。检查点可以是增量的，并为快速恢复进行了优化。</li>
<li>外部化检查点&ndash;通常检查点不打算被用户操纵。Flink 只在作业运行时保留n个最近的检查点（n是可配置的），并在作业取消时删除它们。但你也可以配置它们被保留，在这种情况下，你可以手动从它们恢复。</li>
<li>保存点&ndash;由用户（或API调用）手动触发的快照，用于某些操作目的，例如有状态的重新部署/升级/重新缩放操作。保存点始终是完整的，并为操作的灵活性进行了优化。</li>
</ul>
<h3 id="状态快照是如何工作的">状态快照是如何工作的？</h3>
<p>Flink 使用 <a href="https://en.wikipedia.org/wiki/Chandy-Lamport_algorithm">Chandy-Lamport</a> 算法的一个变体，称为异步屏障快照。</p>
<p>当任务管理器被检查点协调器（作业管理器的一部分）指示开始检查点时，它让所有的源记录它们的偏移量，并在它们的流中插入编号的检查点障碍。这些屏障在作业图(job graph)中流动，指示每个检查点前后的流的部分。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_barriers.svg" alt="img"></p>
<p>检查点n将包含每个 operator 的状态，这些状态是由于消耗了检查点障碍n之前的每个事件，而没有消耗它之后的任何事件。</p>
<p>当作业图中的每个 operator 接收到这些障碍之一时，它就会记录其状态。具有两个输入流（如 CoProcessFunction）的 operator 执行屏障对齐，这样快照将反映消耗两个输入流的事件所产生的状态，直到（但不超过）两个屏障。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/stream_aligning.svg" alt="img"></p>
<p>Flink 的状态后端使用复制-写机制，允许在异步快照状态的旧版本时，流处理不受阻碍地继续。只有当快照被持久化后，这些旧版本的状态才会被垃圾回收。</p>
<h3 id="一次性保证">一次性保证</h3>
<p>当流处理应用中出现问题时，有可能出现丢失，或者重复的结果。在 Flink 中，根据你对应用的选择和你运行它的集群，这些结果中的任何一种都是可能的。</p>
<ul>
<li>Flink 不努力从故障中恢复（最多一次）。</li>
<li>没有任何损失，但您可能会遇到重复的结果（至少一次）。</li>
<li>没有任何东西丢失或重复（精确地一次）。</li>
</ul>
<p>鉴于 Flink 通过倒带和重放源数据流从故障中恢复，当理想情况被描述为精确一次时，这并不意味着每个事件都将被精确处理一次。相反，它意味着每一个事件都会对 Flink 所管理的状态产生一次确切的影响。</p>
<p>Barrier 对齐只需要用于提供精确的一次保证。如果你不需要这个，你可以通过配置 Flink 使用 CheckpointingMode.AT_LEAST_ONCE 来获得一些性能，它的效果是禁用屏障对齐。</p>
<h3 id="精确一次-端到端">精确一次, 端到端</h3>
<p>为了实现端到端精确的一次，让源的每个事件精确地影响汇，以下几点必须是真的。</p>
<ol>
<li>你的源必须是可重播的，并且</li>
<li>你的接收器必须是事务性的(或幂等的)</li>
</ol>
<h2 id="实践">实践</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html">Flink Operations Playground</a> 包括<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#observing-failure--recovery">观察故障和恢复</a>的部分。</p>
<h2 id="进一步阅读">进一步阅读</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html">有状态的流处理</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/state_backends.html">状态后端</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/guarantees.html">数据源和接收器的容错保证</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html">启用和配置检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html">检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/large_state_tuning.html">调整检查点和大状态</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/checkpoint_monitoring.html">监测检查点</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/task_failure_recovery.html">任务故障恢复</a></li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/training" term="training" label="Training" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 操作游乐场]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="related" type="text/html" title="Python API 指南" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Flink Operations Playground</blockquote><h2 id="flink-操作游乐场">Flink 操作游乐场</h2>
<p>在各种环境中部署和操作 Apache Flink 的方法有很多。无论这种多样性如何，Flink 集群的基本构件保持不变，类似的操作原则也适用。</p>
<p>在这个操场上，你将学习如何管理和运行 Flink Jobs。您将看到如何部署和监控应用程序，体验 Flink 如何从 Job 故障中恢复，并执行日常操作任务，如升级和重新缩放。</p>
<h3 id="这个游乐场的解剖">这个游乐场的解剖</h3>
<p>这个游乐场由一个持久的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster">Flink Session Cluster</a>和一个 Kafka Cluster 组成。</p>
<p>一个 Flink Cluster 总是由一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager">JobManager</a> 和一个或多个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager">Flink TaskManager</a> 组成。JobManager 负责处理 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job">Job</a> 提交，监督 Job 以及资源管理。Flink TaskManager 是 worker 进程，负责执行构成 Flink Job 的实际<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task">任务</a>。在这个游戏场中，你将从一个单一的 TaskManager 开始，但以后会扩展到更多的 TaskManager。此外，这个游乐场还带有一个专门的客户端容器，我们使用它来提交 Flink Job，并在以后执行各种操作任务。客户端容器不是 Flink Cluster 本身需要的，只是为了方便使用才包含在里面。</p>
<p>Kafka 集群由一个 Zookeeper 服务器和一个 Kafka Broker 组成。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/flink-docker-playground.svg" alt="img"></p>
<p>当游乐场启动时，一个名为 Flink Event Count 的 Flink Job 将被提交给 JobManager。此外，还会创建两个 Kafka 主题 <em>input</em> 和 <em>output</em>。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/click-event-count-example.svg" alt="img"></p>
<p>该作业从 <em>input</em> 主题中消耗点击事件(<strong>ClickEvent</strong>)，每个点击事件(<strong>ClickEvent</strong>)都有一个时间戳(<strong>timestamp</strong>)和一个页面(<strong>page</strong>)。然后按页面对事件进行分组(<strong>keyed by</strong>)，并在 15 秒的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>中进行计数。结果被写入 <em>output</em> 主题。</p>
<p>有6个不同的页面，我们在每个页面和15秒内产生1000个点击事件。因此，Flink 作业的输出应该显示每个页面和窗口有1000个浏览量。</p>
<h3 id="启动游乐场">启动游乐场</h3>
<p>游戏场环境的设置只需几步。我们将引导你完成必要的命令，并展示如何验证一切都在正确运行。</p>
<p>我们假设你的机器上安装了 <a href="https://docs.docker.com/">Docker</a>（1.12+）和 <a href="https://docs.docker.com/compose/">docker-compose</a>（2.1+）。</p>
<p>所需的配置文件可以在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 仓库中找到。检查一下，然后对齐环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">git clone --branch release-1.11 https://github.com/apache/flink-playgrounds.git
<span class="nb">cd</span> flink-playgrounds/operations-playground
docker-compose build
docker-compose up -d
</code></pre></div><p>之后，你可以用以下命令检查正在运行的 Docker 容器。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose ps

                    Name                                  Command               State                   Ports                
-----------------------------------------------------------------------------------------------------------------------------
operations-playground_clickevent-generator_1   /docker-entrypoint.sh java ...   Up       6123/tcp, 8081/tcp                  
operations-playground_client_1                 /docker-entrypoint.sh flin ...   Exit <span class="m">0</span>                                       
operations-playground_jobmanager_1             /docker-entrypoint.sh jobm ...   Up       6123/tcp, 0.0.0.0:8081-&gt;8081/tcp    
operations-playground_kafka_1                  start-kafka.sh                   Up       0.0.0.0:9094-&gt;9094/tcp              
operations-playground_taskmanager_1            /docker-entrypoint.sh task ...   Up       6123/tcp, 8081/tcp                  
operations-playground_zookeeper_1              /bin/sh -c /usr/sbin/sshd  ...   Up       2181/tcp, 22/tcp, 2888/tcp, 3888/tcp
</code></pre></div><p>这表明客户端容器已经成功提交了 Flink Job（Exit 0），所有集群组件以及数据生成器都在运行（Up）。</p>
<p>您可以通过调用来停止游乐场环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose down -v
</code></pre></div><h3 id="进入游乐场">进入游乐场</h3>
<p>在这个游乐场中，有很多东西你可以尝试和检查。在下面的两节中，我们将向您展示如何与 Flink 集群进行交互，并展示 Flink 的一些关键功能。</p>
<h4 id="flink-webui">Flink WebUI</h4>
<p>观察你的 Flink 集群最自然的出发点是在 <a href="http://localhost:8081/">http://localhost:8081</a> 下暴露的 WebUI。如果一切顺利，你会看到集群最初由一个任务管理器组成，并执行一个名为 Click Event Count 的 Job。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui.png" alt="img"></p>
<p>Flink WebUI 包含了很多关于 Flink 集群和它的工作的有用和有趣的信息（JobGraph, Metrics, Checkpointing Statistics, TaskManager Status, &hellip;）。</p>
<h4 id="日志">日志</h4>
<h5 id="jobmanager">JobManager</h5>
<p>可以通过 <code>docker-compose</code> 对 JobManager 日志进行跟踪。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f jobmanager
</code></pre></div><p>在初始启动后，你应该主要看到每一个检查点完成的日志信息。</p>
<h5 id="taskmanager">TaskManager</h5>
<p>TaskManager 的日志也可以用同样的方式进行 tail。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose logs -f taskmanager
</code></pre></div><p>在初始启动后，你应该主要看到每个检查点完成的日志信息。</p>
<h4 id="flink-cli">Flink CLI</h4>
<p>Flink CLI 可以在客户端容器中使用。例如，要打印 Flink CLI 的帮助信息，你可以运行以下命令</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink --help
</code></pre></div><h4 id="flink-rest-api">Flink REST API</h4>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">Flink REST API</a> 通过主机上的 localhost:8081 或客户端容器中的 jobmanager:8081 暴露出来，例如，要列出所有当前正在运行的作业，你可以运行:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">curl localhost:8081/jobs
</code></pre></div><h4 id="kafka-topics">Kafka Topics</h4>
<p>你可以通过运行以下命令来查看写入 Kafka 主题的记录</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">//input topic <span class="o">(</span><span class="m">1000</span> records/s<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic input

//output topic <span class="o">(</span><span class="m">24</span> records/min<span class="o">)</span>
docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><h4 id="time-to-play">Time to Play!</h4>
<p>现在你已经学会了如何与 Flink 和 Docker 容器进行交互，让我们来看看一些常见的操作任务，你可以在我们的游乐场上尝试一下。所有这些任务都是相互独立的，即你可以以任何顺序执行它们。大多数任务可以通过 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-cli">CLI</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#flink-rest-api">REST API</a> 来执行。</p>
<h5 id="列出正在运行的-job">列出正在运行的 Job</h5>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink list
</code></pre></div><p><strong>期望的输出</strong></p>
<pre><code>Waiting for response...
------------------ Running/Restarting Jobs -------------------
16.07.2019 16:37:55 : &lt;job-id&gt; : Click Event Count (RUNNING)
--------------------------------------------------------------
No scheduled jobs.
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<pre><code>curl localhost:8081/jobs
</code></pre><p><strong>期待的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobs&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div><p>JobID 在提交时被分配给作业(Job)，并且需要通过 CLI 或 REST API 对作业(Job)执行操作。</p>
<h5 id="观察故障和恢复">观察故障和恢复</h5>
<p>Flink 在(部分)失败下提供了精确的一次处理保证。在这个游乐场中，你可以观察并在一定程度上验证这种行为。</p>
<p><strong>步骤1：观察输出</strong></p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#anatomy-of-this-playground">如上所述</a>，在这个游乐场中的事件是这样生成的，每个窗口正好包含一千条记录。因此，为了验证 Flink 是否成功地从 TaskManager 故障中恢复，而没有数据丢失或重复，你可以跟踪 <em>output</em> 主题，并检查恢复后所有的窗口都存在，而且计数是正确的。</p>
<p>为此，从 <em>output</em> 主题开始读取，并让这个命令运行到恢复后（步骤3）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第二步：引入故障</strong></p>
<p>为了模拟部分故障，你可以杀死一个 TaskManager，在生产设置中，这可能对应于 TaskManager 进程、TaskManager 机器的丢失，或者仅仅是框架或用户代码抛出的瞬时异常（例如由于暂时不可用）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">kill</span> taskmanager
</code></pre></div><p>几秒钟后，JobManager 会注意到 TaskManager 的丢失，取消受影响的 Job，并立即重新提交它进行恢复。当 Job 被重新启动后，其任务仍处于 <strong>SCHEDULED</strong> 状态，由紫色的方块表示（见下面的截图）。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/playground-webui-failure.png" alt="img"></p>
<p>注意：即使作业(Job)的任务(Task)处于 <strong>SCHEDULED</strong> 状态而不是 <strong>RUNNING</strong> 状态，作业(Job)的整体状态也会显示为 <strong>RUNNING</strong>。</p>
<p>此时，Job 的任务(Task)不能从 <strong>SCHEDULED</strong> 状态转为 <strong>RUNNING</strong> 状态，因为没有资源(<strong>TaskManager</strong> 提供的 <strong>TaskSlots</strong>）来运行这些任务。在新的 TaskManager 可用之前，Job 将经历一个取消和重新提交的循环。</p>
<p>同时，数据生成器会不断地将 ClickEvents 推送到 <em>input</em> 主题中。这类似于真正的生产设置，在生产数据的同时，要处理数据的 Job 却宕机了。</p>
<p><strong>步骤3：恢复</strong></p>
<p>一旦你重新启动 TaskManager，它就会重新连接到 JobManager。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose up -d taskmanager
</code></pre></div><p>当 JobManager 被通知到新的 TaskManager 时，它将恢复中的 Job 的任务(tasks)调度到新的可用 TaskSlots。重新启动后，任务会从故障前最后一次成功的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">检查点</a>恢复其状态，并切换到 RUNNING 状态。</p>
<p>Job 将快速处理来自 Kafka 的全部积压输入事件(在故障期间积累的)，并以更高的速度(&gt;24条记录/分钟)产生输出，直到到达流的头部。在输出中，你会看到所有的键(页面)都存在于所有的时间窗口中，而且每个计数都是精确的 1000。由于我们是在&quot;至少一次&quot;模式下使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/kafka.html#kafka-producers-and-fault-tolerance">FlinkKafkaProducer</a>，所以你有可能会看到一些重复的输出记录。</p>
<p>注意：大多数生产设置依赖于资源管理器(Kubernetes、Yarn、Mesos)来自动重启失败的进程。</p>
<h5 id="升级和重新缩放作业">升级和重新缩放作业</h5>
<p>升级 Flink 作业总是涉及两个步骤。首先，用一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html">保存点</a>优雅地停止 Flink Job。保存点是在一个明确定义的、全局一致的时间点(类似于检查点)上的完整应用状态的一致快照。其次，升级后的 Flink Job 从 Savepoint 开始。在这种情况下，&ldquo;升级&quot;可以意味着不同的事情，包括以下内容:</p>
<ul>
<li>配置的升级（包括作业的并行性）。</li>
<li>对 Job 的拓扑结构进行升级（增加/删除 Operator）。</li>
<li>对 Job 的用户定义的函数进行升级。</li>
</ul>
<p>在开始升级之前，你可能要开始 tailing <em>output</em> 主题，以观察在升级过程中没有数据丢失或损坏。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose <span class="nb">exec</span> kafka kafka-console-consumer.sh <span class="se">\
</span><span class="se"></span>  --bootstrap-server localhost:9092 --topic output
</code></pre></div><p><strong>第一步：停止工作</strong></p>
<p>要优雅地停止作业，您需要使用 CLI 或 REST API 的 &ldquo;stop&rdquo; 命令。为此，您需要该作业的 JobID，您可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#listing-running-jobs">列出所有正在运行的 Job</a> 或从 WebUI 中获得。有了 JobID，您就可以继续停止该作业:</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink stop &lt;job-id&gt;
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Suspending job &quot;&lt;job-id&gt;&quot; with a savepoint.
Suspended job &quot;&lt;job-id&gt;&quot; with a savepoint.
</code></pre><p>Savepoint 已经被存储到 flink-conf.yaml 中配置的 state.savepoint.dir 中，它被安装在本地机器的 /tmp/flink-savepoints-directory/ 下。在下一步中，你将需要这个 Savepoint 的路径。在 REST API 的情况下，这个路径已经是响应的一部分，你将需要直接查看文件系统。</p>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">ls -lia /tmp/flink-savepoints-directory
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">total <span class="m">0</span>
  <span class="m">17</span> drwxr-xr-x   <span class="m">3</span> root root   <span class="m">60</span> <span class="m">17</span> jul 17:05 .
   <span class="m">2</span> drwxrwxrwt <span class="m">135</span> root root <span class="m">3420</span> <span class="m">17</span> jul 17:09 ..
<span class="m">1002</span> drwxr-xr-x   <span class="m">2</span> root root  <span class="m">140</span> <span class="m">17</span> jul 17:05 savepoint-&lt;short-job-id&gt;-&lt;uuid&gt;
</code></pre></div><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># triggering stop</span>
curl -X POST localhost:8081/jobs/&lt;job-id&gt;/stop -d <span class="s1">&#39;{&#34;drain&#34;: false}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;request-id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;trigger-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># check status of stop action and retrieve savepoint path</span>
curl localhost:8081/jobs/&lt;job-id&gt;/savepoints/&lt;trigger-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;COMPLETED&#34;</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;operation&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;location&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;savepoint-path&gt;&#34;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p><strong>步骤2a: 重启 Job，不做任何改变</strong></p>
<p>现在您可以从该保存点重新启动升级后的作业(Job)。为了简单起见，您可以在不做任何更改的情况下重新启动它。</p>
<ul>
<li>CLI</li>
</ul>
<p><strong>命令</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的输出</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>一旦 Job 再次 RUNNING，你会在 <em>output</em> 主题中看到，当 Job 在处理中断期间积累的积压时，记录以较高的速度产生。此外，你会看到在升级过程中没有丢失任何数据：所有窗口都存在，数量正好是 1000。</p>
<p><strong>步骤2b: 用不同的并行度重新启动作业（重新缩放）</strong></p>
<p>另外，您也可以在重新提交时通过传递不同的并行性，从这个保存点重新缩放作业。</p>
<ul>
<li>CLI</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose run --no-deps client flink run -p <span class="m">3</span> -s &lt;savepoint-path&gt; <span class="se">\
</span><span class="se"></span>  -d /opt/ClickCountJob.jar <span class="se">\
</span><span class="se"></span>  --bootstrap.servers kafka:9092 --checkpointing --event-time
</code></pre></div><p><strong>预期的输出</strong></p>
<pre><code>Starting execution of program
Job has been submitted with JobID &lt;job-id&gt;
</code></pre><ul>
<li>REST API</li>
</ul>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Uploading the JAR from the Client container</span>
docker-compose run --no-deps client curl -X POST -H <span class="s2">&#34;Expect:&#34;</span> <span class="se">\
</span><span class="se"></span>  -F <span class="s2">&#34;jarfile=@/opt/ClickCountJob.jar&#34;</span> http://jobmanager:8081/jars/upload
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;filename&#34;</span><span class="p">:</span> <span class="s2">&#34;/tmp/flink-web-&lt;uuid&gt;/flink-web-upload/&lt;jar-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;success&#34;</span>
<span class="p">}</span>
</code></pre></div><p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># Submitting the Job</span>
curl -X POST http://localhost:8081/jars/&lt;jar-id&gt;/run <span class="se">\
</span><span class="se"></span>  -d <span class="s1">&#39;{&#34;parallelism&#34;: 3, &#34;programArgs&#34;: &#34;--bootstrap.servers kafka:9092 --checkpointing --event-time&#34;, &#34;savepointPath&#34;: &#34;&lt;savepoint-path&gt;&#34;}&#39;</span>
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jobid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span>
<span class="p">}</span>
</code></pre></div><p>现在，作业(Job)已经被重新提交，但它不会启动，因为没有足够的 TaskSlots 在增加的并行度下执行它（2个可用，需要3个）。使用:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker-compose scale <span class="nv">taskmanager</span><span class="o">=</span><span class="m">2</span>
</code></pre></div><p>你可以在 Flink 集群中添加一个带有两个 TaskSlots 的第二个 TaskManager，它将自动注册到 JobManager 中。添加 TaskManager 后不久，该任务(Job)应该再次开始运行。</p>
<p>一旦 Job 再次 &ldquo;RUNNING&rdquo;，你会在 <em>output</em> Topic 中看到在重新缩放过程中没有丢失数据：所有的窗口都存在，计数正好是 1000。</p>
<h5 id="查询作业job的指标">查询作业(Job)的指标</h5>
<p>JobManager 通过其 REST API 公开系统和用户<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html">指标</a>。</p>
<p>端点取决于这些指标的范围。可以通过 <code>jobs/&lt;job-id&gt;/metrics</code> 来列出一个作业的范围内的度量。指标的实际值可以通过 get query 参数进行查询。</p>
<p><strong>请求</strong></p>
<pre><code class="language-shells" data-lang="shells">curl &quot;localhost:8081/jobs/&lt;jod-id&gt;/metrics?get=lastCheckpointSize&quot;
</code></pre><p><strong>预期的响应(美化了打印; 没有占位符)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
  <span class="p">{</span>
    <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;lastCheckpointSize&#34;</span><span class="p">,</span>
    <span class="nt">&#34;value&#34;</span><span class="p">:</span> <span class="s2">&#34;9378&#34;</span>
  <span class="p">}</span>
<span class="p">]</span>
</code></pre></div><p>REST API 不仅可以用来查询指标，还可以检索运行中的作业状态的详细信息。</p>
<p><strong>请求</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># find the vertex-id of the vertex of interest</span>
curl localhost:8081/jobs/&lt;jod-id&gt;
</code></pre></div><p><strong>预期的响应(美化了打印)</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
  <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
  <span class="nt">&#34;isStoppable&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&#34;state&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
  <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
  <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
  <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374793</span><span class="p">,</span>
  <span class="nt">&#34;now&#34;</span><span class="p">:</span> <span class="mi">1564467440819</span><span class="p">,</span>
  <span class="nt">&#34;timestamps&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">1564467066026</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SUSPENDED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELLING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">1564467066126</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RESTARTING&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;vertices&#34;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066423</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374396</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033461</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166351</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066441</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374378</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5066280</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">5033496</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">166349</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066469</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374350</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">5085332</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">316</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">166305</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span><span class="p">,</span>
    <span class="p">{</span>
      <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
      <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
      <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="s2">&#34;RUNNING&#34;</span><span class="p">,</span>
      <span class="nt">&#34;start-time&#34;</span><span class="p">:</span> <span class="mi">1564467066476</span><span class="p">,</span>
      <span class="nt">&#34;end-time&#34;</span><span class="p">:</span> <span class="mi">-1</span><span class="p">,</span>
      <span class="nt">&#34;duration&#34;</span><span class="p">:</span> <span class="mi">374343</span><span class="p">,</span>
      <span class="nt">&#34;tasks&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="nt">&#34;metrics&#34;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&#34;read-bytes&#34;</span><span class="p">:</span> <span class="mi">20668</span><span class="p">,</span>
        <span class="nt">&#34;read-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-bytes-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;read-records&#34;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="nt">&#34;read-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;write-records&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&#34;write-records-complete&#34;</span><span class="p">:</span> <span class="kc">true</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">]</span><span class="p">,</span>
  <span class="nt">&#34;status-counts&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;CREATED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FINISHED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;DEPLOYING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RUNNING&#34;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="nt">&#34;CANCELING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;FAILED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;CANCELED&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;RECONCILING&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&#34;SCHEDULED&#34;</span><span class="p">:</span> <span class="mi">0</span>
  <span class="p">}</span><span class="p">,</span>
  <span class="nt">&#34;plan&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;jid&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;job-id&gt;&#34;</span><span class="p">,</span>
    <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;Click Event Count&#34;</span><span class="p">,</span>
    <span class="nt">&#34;nodes&#34;</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEventStatistics Sink&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Counter&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;HASH&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;Timestamps/Watermarks&#34;</span><span class="p">,</span>
        <span class="nt">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="nt">&#34;num&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
            <span class="nt">&#34;ship_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;FORWARD&#34;</span><span class="p">,</span>
            <span class="nt">&#34;exchange&#34;</span><span class="p">:</span> <span class="s2">&#34;pipelined_bounded&#34;</span>
          <span class="p">}</span>
        <span class="p">]</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span><span class="p">,</span>
      <span class="p">{</span>
        <span class="nt">&#34;id&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;vertex-id&gt;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;parallelism&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="nt">&#34;operator&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;operator_strategy&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">,</span>
        <span class="nt">&#34;description&#34;</span><span class="p">:</span> <span class="s2">&#34;ClickEvent Source&#34;</span><span class="p">,</span>
        <span class="nt">&#34;optimizer_properties&#34;</span><span class="p">:</span> <span class="p">{</span><span class="p">}</span>
      <span class="p">}</span>
    <span class="p">]</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>请查阅 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html#api">REST API 参考资料</a>，了解可能查询的完整列表，包括如何查询不同作用域的指标（如 TaskManager 指标）。</p>
<h4 id="变体">变体</h4>
<p>你可能已经注意到，Click Event Count 应用程序总是以 <code>--checkpointing</code> 和 <code>--event-time</code> 程序参数启动。通过在 docker-compose.yaml 的客户端容器的命令中省略这些，你可以改变 Job 的行为。</p>
<ul>
<li>
<p><code>--checkpointing</code> 启用了 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/learn-flink/fault_tolerance.html">checkpoint</a>，这是 Flink 的容错机制。如果你在没有它的情况下运行，并通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/flink-operations-playground.html#observing-failure--recovery">故障和恢复</a>，你应该会看到数据实际上已经丢失了。</p>
</li>
<li>
<p><code>--event-time</code> 启用了你的 Job 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间语义</a>。当禁用时，作业将根据挂钟时间而不是 ClickEvent 的时间戳将事件分配给窗口。因此，每个窗口的事件数量将不再是精确的 1000。</p>
</li>
</ul>
<p>Click Event Count 应用程序还有另一个选项，默认情况下是关闭的，你可以启用这个选项来探索这个作业在背压下的行为。你可以在 <code>docker-compose.yaml</code> 的客户端容器的命令中添加这个选项。</p>
<ul>
<li><code>--backpressure</code> 在作业中间增加了一个额外的 operator，在偶数分钟内会造成严重的背压（例如，在10:12期间，但在10:13期间不会）。这可以通过检查各种<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/metrics.html#default-shuffle-service">网络指标</a>（如 outputQueueLength 和 outPoolUsage）和/或使用 WebUI 中的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/back_pressure.html#monitoring-back-pressure">背压监控</a>来观察。</li>
</ul>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/playground" term="playground" label="Playground" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Python API 指南]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-17-flink-operations-playground/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 操作游乐场" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="related" type="text/html" title="Flink 中的 Connectors" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-17-python-api-tutorial/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-17T00:00:00+08:00</published>
            <updated>2020-08-17T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Python API Tutorial</blockquote><h2 id="python-api-指南">Python API 指南</h2>
<p>本演练将快速让你开始构建一个纯 Python Flink 项目。</p>
<p>关于如何设置 Python 执行环境，请参考 Python Table API <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html">安装指南</a>。</p>
<h3 id="设置一个-python-项目">设置一个 Python 项目</h3>
<p>您可以先创建一个 Python 项目，然后按照<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/installation.html#installation-of-pyflink">安装指南</a>安装 PyFlink 包。</p>
<h3 id="编写一个-flink-python-table-api-程序">编写一个 Flink Python Table API 程序</h3>
<p>Table API 应用程序通过声明一个表环境开始；对于批处理应用程序，可以是 BatchTableEvironment，对于流式应用程序，可以是 StreamTableEnvironment。这作为与 Flink 运行时交互的主要入口点。它可以用来设置执行参数，如重启策略、默认并行度等。表配置允许设置 Table API 的具体配置。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">(</span><span class="p">)</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">(</span><span class="p">)</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>
</code></pre></div><p>在创建的表环境中，可以声明 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/input</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/output</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>你也可以使用 <code>TableEnvironment.sql_update()</code> 方法来注册 DDL 中定义的 source/sink 表。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">my_source_ddl</span> <span class="o">=</span> <span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    create table mySource (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        word VARCHAR</span><span class="s2">
</span><span class="s2"></span><span class="s2">    ) with (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">filesystem</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">format.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">csv</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.path</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">/tmp/input</span><span class="s2">&#39;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    )</span><span class="s2">
</span><span class="s2"></span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">my_sink_ddl</span> <span class="o">=</span> <span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    create table mySink (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        word VARCHAR,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        `count` BIGINT</span><span class="s2">
</span><span class="s2"></span><span class="s2">    ) with (</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">filesystem</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">format.type</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">csv</span><span class="s2">&#39;</span><span class="s2">,</span><span class="s2">
</span><span class="s2"></span><span class="s2">        </span><span class="s2">&#39;</span><span class="s2">connector.path</span><span class="s2">&#39;</span><span class="s2"> = </span><span class="s2">&#39;</span><span class="s2">/tmp/output</span><span class="s2">&#39;</span><span class="s2">
</span><span class="s2"></span><span class="s2">    )</span><span class="s2">
</span><span class="s2"></span><span class="s2">&#34;&#34;&#34;</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_source_ddl</span><span class="p">)</span>
<span class="n">t_env</span><span class="o">.</span><span class="n">sql_update</span><span class="p">(</span><span class="n">my_sink_ddl</span><span class="p">)</span>
</code></pre></div><p>这将在执行环境中注册一个名为 <strong>mySource</strong> 的表和一个名为 <strong>mySink</strong> 的表。表 <strong>mySource</strong> 只有一列，即 <strong>word</strong>，它消耗从文件 <code>/tmp/input</code> 中读取的字符串。表 <strong>mySink</strong> 有两列，分别是 <strong>word</strong> 和 <strong>count</strong>，将数据写入文件 <code>/tmp/output</code>，用 <code>/t</code> 作为字段分隔符。</p>
<p>现在，你可以创建一个作业(job)，它从表 <strong>mySource</strong> 中读取输入，预先执行一些转换，并将结果写入表 <strong>mySink</strong>。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word, count(1)</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><p>最后你必须执行实际的 Flink Python Table API 作业。所有的操作，如创建源、转换和 sink 都是懒惰的。只有当 <code>t_env.execute(job_name)</code> 被调用时，作业才会被运行。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">tutorial_job</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><p>到目前为止，完整的代码如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyflink.dataset</span> <span class="kn">import</span> <span class="n">ExecutionEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="n">TableConfig</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">,</span> <span class="n">BatchTableEnvironment</span>
<span class="kn">from</span> <span class="nn">pyflink.table.descriptors</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">OldCsv</span><span class="p">,</span> <span class="n">FileSystem</span>

<span class="n">exec_env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="n">get_execution_environment</span><span class="p">(</span><span class="p">)</span>
<span class="n">exec_env</span><span class="o">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_config</span> <span class="o">=</span> <span class="n">TableConfig</span><span class="p">(</span><span class="p">)</span>
<span class="n">t_env</span> <span class="o">=</span> <span class="n">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">exec_env</span><span class="p">,</span> <span class="n">t_config</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/input</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">FileSystem</span><span class="p">(</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">/tmp/output</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="n">OldCsv</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field_delimiter</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">(</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">STRING</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">count</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="n">BIGINT</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">create_temporary_table</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySource</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">word, count(1)</span><span class="s1">&#39;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">insert_into</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">mySink</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">t_env</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">tutorial_job</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><h3 id="执行-flink-python-table-api-程序">执行 Flink Python Table API 程序</h3>
<p>首先，你需要在 &ldquo;/tmp/input&rdquo; 文件中准备输入数据。你可以选择以下命令行来准备输入数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">echo</span> -e  <span class="s2">&#34;flink\npyflink\nflink&#34;</span> &gt; /tmp/input
</code></pre></div><p>接下来，你可以在命令行上运行这个例子（注意：如果结果文件 &ldquo;/tmp/output&rdquo; 已经存在，你需要在运行这个例子之前删除该文件）。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ python WordCount.py
</code></pre></div><p>该命令在本地小型集群中构建并运行 Python Table API 程序。你也可以将 Python Table API 程序提交到远程集群，详情可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html#job-submission-examples">Job Submission Examples</a>。</p>
<p>最后，您可以在命令行中看到执行结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ cat /tmp/output
flink	<span class="m">2</span>
pyflink	<span class="m">1</span>
</code></pre></div><p>这应该可以让你开始编写自己的 Flink Python Table API 程序。要了解更多关于 Python Table API 的信息，你可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/python">Flink Python Table API Docs</a> 了解更多细节。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/python" term="python" label="Python" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Connectors]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-08-05-connectors-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-07T00:00:00+08:00</published>
            <updated>2020-08-07T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>连接器</blockquote><h1 id="apache-kafka-connector">Apache Kafka Connector</h1>
<h2 id="kafka-consumer">Kafka Consumer</h2>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">(</span><span class="o">)</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;localhost:9092&#34;</span><span class="o">)</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;test&#34;</span><span class="o">)</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span><span class="o">(</span><span class="s">&#34;topic&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="n">properties</span><span class="o">)</span><span class="o">)</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/connector" term="connector" label="Connector" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Real Time Reporting with the Table API</blockquote><p>Apache Flink 提供的 Table API 是一个统一的、关系型的 API，用于批处理和流处理，即在无边界的、实时的流或有边界的、批处理的数据集上以相同的语义执行查询，并产生相同的结果。Flink 中的 Table API 通常用于简化数据分析、数据管道化和 ETL 应用的定义。</p>
<h2 id="你要构建什么">你要构建什么?</h2>
<p>在本教程中，你将学习如何构建一个实时的仪表盘，以按账户跟踪金融交易。该管道将从 Kafka 读取数据，并将结果写入 MySQL，通过 Grafana 可视化。</p>
<h2 id="先决条件">先决条件</h2>
<p>本演练假设你对 Java 或 Scala 有一定的熟悉，但即使你来自不同的编程语言，你也应该能够跟上。它还假设你熟悉基本的关系概念，如 SELECT 和 GROUP BY 子句。</p>
<h2 id="救命-我被卡住了">救命, 我被卡住了!</h2>
<p>如果你遇到困难，请查看<a href="https://flink.apache.org/community.html">社区支持资源</a>。特别是 Apache Flink 的<a href="https://flink.apache.org/community.html#mailing-lists">用户邮件列表</a>，它一直是 Apache 项目中最活跃的一个，也是快速获得帮助的好方法。</p>
<h2 id="如何跟进">如何跟进</h2>
<p>如果你想跟着走，你需要一台电脑与。</p>
<ul>
<li>Java 8 或 11</li>
<li>Maven</li>
<li>Docker</li>
</ul>
<p>所需的配置文件可在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 资源库中获得。下载后，在 IDE 中打开项目 flink-playground/table-walkthrough，并导航到文件 SpendReport。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">)</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="拆解代码">拆解代码</h2>
<h3 id="the-execution-environment">The Execution Environment</h3>
<p>前两行设置了你的 <code>TableEnvironment</code>。表环境是你如何为你的 Job 设置属性，指定你是在写批处理还是流式应用，以及创建你的源。本演练创建了一个使用流式执行的标准表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="注册表">注册表</h3>
<p>接下来，在当前<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册了表，您可以使用这些表连接到外部系统，以便读写批处理和流数据。表源提供对存储在外部系统中的数据的访问，如数据库、键值存储、消息队列或文件系统。table sink 向外部存储系统发出一个表。根据源和 sink 的类型，它们支持不同的格式，如 CSV、JSON、Avro 或 Parquet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>注册了两个表：一个是交易输入表，一个是消费报告输出表。交易(transaction)表让我们可以读取信用卡交易，其中包含账户ID(account_id)、时间戳(transaction_time)和美元金额(amount)。该表是在一个名为 <code>transactions</code> 的 Kafka 主题上的逻辑视图，包含 CSV 数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>第二张表 <code>spend_report</code>，存储了最终的汇总结果。其底层存储是 MySql 数据库中的一张表。</p>
<h3 id="查询">查询</h3>
<p>配置好环境和注册好表之后，你就可以构建你的第一个应用程序了。从 <code>TableEnvironment</code> 中，你可以从一个输入表中读取它的行，然后使用 <code>executeInsert</code> 将这些结果写入到一个输出表中。<code>report</code> 函数是你实现业务逻辑的地方。它目前还没有被实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">)</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="测试">测试</h2>
<p>该项目包含一个二次测试类 <code>SpendReportTest</code>，用于验证报表的逻辑。它以批处理模式创建了一个表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">inBatchMode</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>Flink 的独特属性之一是它在批处理和流式处理之间提供一致的语义。这意味着你可以在静态数据集上以批处理模式开发和测试应用程序，并以流式应用程序的形式部署到生产中。</p>
<h2 id="尝试一下">尝试一下</h2>
<p>现在有了 Job 设置的骨架，你就可以添加一些业务逻辑了。目标是建立一个报告，显示每个账户在一天中每个小时的总支出。这意味着时间戳列需要从毫秒到小时的颗粒度进行舍入。</p>
<p>Flink 支持用纯 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/">SQL</a> 或使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 开发关系型应用。Table API 是一个受 SQL 启发的流畅 DSL，可以用 Python、Java 或 Scala 编写，并支持强大的 IDE 集成。就像 SQL 查询一样，Table 程序可以选择所需的字段，并通过你的键进行分组。这些功能，加上<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置的函数</a>，如 <code>floor</code> 和 <code>sum</code>，写这个报告问题不大。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">floor</span><span class="o">(</span><span class="n">TimeIntervalUnit</span><span class="o">.</span><span class="na">HOUR</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><h2 id="用户定义的函数">用户定义的函数</h2>
<p>Flink 包含有限的内置函数，有时你需要用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>来扩展它。如果 <code>floor</code> 不是预定义的，你可以自己实现它。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">java.time.LocalDateTime</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.time.temporal.ChronoUnit</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyFloor</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="nf">eval</span><span class="o">(</span>
        <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">{</span>

        <span class="k">return</span> <span class="n">timestamp</span><span class="o">.</span><span class="na">truncatedTo</span><span class="o">(</span><span class="n">ChronoUnit</span><span class="o">.</span><span class="na">HOURS</span><span class="o">)</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后迅速将其集成到你的应用程序中。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">call</span><span class="o">(</span><span class="n">MyFloor</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>这个查询会消耗 <code>transactions</code> 表的所有记录，计算报表，并以高效、可扩展的方式输出结果。使用该实现运行测试将通过。</p>
<h2 id="添加窗口">添加窗口</h2>
<p>基于时间的数据分组是数据处理中的典型操作，尤其是在处理无限流时。基于时间的分组被称为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>，Flink 提供了灵活的窗口语义。最基本的窗口类型称为 <code>Tumble</code> 窗口，它有一个固定的大小，其桶不重叠。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">Tumble</span><span class="o">.</span><span class="na">over</span><span class="o">(</span><span class="n">lit</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">.</span><span class="na">hour</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">on</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">)</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">start</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">)</span><span class="o">,</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div><p>这就定义了你的应用程序使用基于时间戳列的一小时翻滚窗口。因此，时间戳为 2019-06-01 01:23:47 的行被放在 2019-06-01 01:00:00 窗口中。</p>
<p>基于时间的聚合是独一无二的，因为在连续流应用中，时间与其他属性不同，一般是向前移动的。与 floor 和你的 UDF 不同，窗口函数是<a href="https://en.wikipedia.org/wiki/Intrinsic_function">内在的</a>，它允许运行时应用额外的优化。在批处理上下文中，窗口提供了一个方便的 API，用于通过时间戳属性对记录进行分组。</p>
<p>用这个实现运行测试也会通过。</p>
<h2 id="再来一次用流">再来一次，用流!</h2>
<p>就这样，一个功能齐全的、有状态的、分布式的流式应用! 查询不断地消耗 Kafka 的事务流，计算每小时的花费，并在结果准备好后立即发出。由于输入是界的，所以查询一直在运行，直到手动停止。而且由于 Job 使用了基于时间窗口的聚合，所以当框架知道某个窗口不会再有记录到达时，Flink 可以进行特定的优化，比如状态清理。</p>
<p>表游乐场是完全 docker 化的，可以作为流式应用在本地运行。该环境包含一个 Kafka 主题、一个连续数据生成器、MySql 和 Grafana。</p>
<p>从 <code>table-walkthrough</code> 文件夹内启动 <code>docker-compose</code> 脚本。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose build
$ docker-compose up -d
</code></pre></div><p>你可以通过 <a href="http://localhost:8082/">Flink 控制台</a>查看正在运行的作业信息。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/spend-report-console.png" alt="img"></p>
<p>从 MySQL 里面探索结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose <span class="nb">exec</span> mysql mysql -Dsql-demo -usql-demo -pdemo-sql

mysql&gt; use sql-demo<span class="p">;</span>
Database changed

mysql&gt; <span class="k">select</span> count<span class="o">(</span>*<span class="o">)</span> from spend_report<span class="p">;</span>
+----------+
<span class="p">|</span> count<span class="o">(</span>*<span class="o">)</span> <span class="p">|</span>
+----------+
<span class="p">|</span>      <span class="m">110</span> <span class="p">|</span>
+----------+
</code></pre></div><p>最后，去 <a href="http://localhost:3000/d/FOe0PbmGk/walkthrough?viewPanel=2&amp;orgId=1&amp;refresh=5s">Grafana</a> 看看完全可视化的结果吧!</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table" term="table" label="table" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/api" term="api" label="api" />
                            
                        
                    
                
            
        </entry>
    
</feed>
