<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.79.0">Hugo</generator><title type="html"><![CDATA[Data Sources on 焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/tags/data-sources/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/tags/data-sources/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/tags/data-sources/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/tags/data-sources/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2021-01-23T22:00:20+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/tags/data-sources/</id>
    
        
        <entry>
            <title type="html"><![CDATA[数据源]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-data-sources/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-java-lambda-expressions/?utm_source=atom_feed" rel="related" type="text/html" title="Java Lambda 表达式" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-joining/?utm_source=atom_feed" rel="related" type="text/html" title="Joining" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-operators/?utm_source=atom_feed" rel="related" type="text/html" title="Operators" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-scala-api-extensions/?utm_source=atom_feed" rel="related" type="text/html" title="Scala API 扩展" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-side-outputs/?utm_source=atom_feed" rel="related" type="text/html" title="侧输出" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-data-sources/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Data Sources</blockquote><p>注：这描述了新的数据源 API ，作为 FLIP-27 的一部分在 Flink 1.11 中引入。这个新的 API 目前处于 BETA 状态。
大多数现有的源连接器还没有（截至 Flink 1.11 ）使用这个新的 API 实现，而是使用以前的 API ，基于 SourceFunction 。
本页介绍了 Flink 的数据源 API 及其背后的概念和架构。如果你对 Flink 中的数据源是如何工作的，或者你想实现一个新的数据源，请阅读本页面。</p>
<p>如果您正在寻找预定义的源连接器，请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/">连接器文档</a>。</p>
<h2 id="数据源概念">数据源概念</h2>
<p><strong>核心部件</strong></p>
<p>一个数据源有三个核心组件。<code>Split</code>、<code>SplitEnumerator</code> 和 <code>SourceReader</code>。</p>
<ul>
<li>
<p><code>Split</code> 是数据源所消耗的一部分数据，就像一个文件或一个日志分区。<code>Split</code> 是源分配工作和并行读取数据的粒度。</p>
</li>
<li>
<p><code>SourceReader</code> 请求 <code>Split</code> 并进行处理，例如读取 <code>Split</code> 所代表的文件或日志分区。<code>SourceReader</code> 在 <code>SourceOperators</code> 的 Task Manager 上并行运行，并产生事件/记录的并行流。</p>
</li>
<li>
<p><code>SplitEnumerator</code> 生成 <code>Split</code> 并将它们分配给 <code>SourceReader</code> 。它作为单个实例在任务管理器上运行，负责维护待处理的 <code>Split</code> 的积压，并以平衡的方式将它们分配给读者。</p>
</li>
</ul>
<p><code>Source</code> 类是将上述三个组件联系在一起的 API 入口点。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/source_components.svg" alt="img"></p>
<p><strong>统一的跨流和批处理</strong></p>
<p>数据源 API 以统一的方式支持无界流源和有界批处理源。</p>
<p>这两种情况的区别很小：在有界/批处理的情况下，枚举器生成一组固定的 split ，而且每个 split 必然是有限的。在无界流的情况下，这两种情况中的一种是不正确的（ split 不是有限的，或者枚举器不断产生新的 split ）。</p>
<h3 id="例子">例子</h3>
<p>下面是一些简化的概念性例子，以说明在流式和批处理情况下，数据源组件如何交互。</p>
<p>请注意，这并不能准确地描述 Kafka 和 File 源的实现是如何工作的；部分内容是简化的，用于说明目的。</p>
<p><strong>绑定的文件源</strong></p>
<p>源有一个要读取的目录的 URI/路径，以及一个定义如何解析文件的格式。</p>
<ul>
<li><code>Split</code> 是一个文件，或者一个文件的一个区域（如果数据格式支持分割文件）。</li>
<li><code>SplitEnumerator</code> 列出了给定目录路径下的所有文件。它将 <code>Split</code> 分配给下一个请求 <code>Split</code> 的读者。一旦所有的 <code>Split</code> 都分配完毕，它就会用 <code>NoMoreSplits</code> 来响应请求。</li>
<li>SourceReader 请求一个 <code>Split</code> ，并读取被分配的 <code>Split</code> （文件或文件区域），并使用给定的格式进行解析。如果它没有得到另一个 <code>Split</code> ，而是得到一个 <code>NoMoreSplits</code> 消息，它就结束了。</li>
</ul>
<p><strong>非绑定流文件源</strong></p>
<p>这个源的工作方式和上面描述的一样，除了 <code>SplitEnumerator</code> 从不响应 <code>NoMoreSplits</code> ，而是周期性地列出给定 <code>URI/Path</code> 下的内容以检查新文件。一旦发现新文件，它就会为它们生成新的 <code>Splits</code> ，并可以将它们分配给可用的 <code>SourceReaders</code>。</p>
<p><strong>无界流 Kafka 源</strong></p>
<p>该源有一个 Kafka Topic （或 Topic 列表或 Topic regex ）和一个 Deserializer 来解析记录。</p>
<ul>
<li>一个 Split 就是一个 Kafka Topic 分区。</li>
<li>SplitEnumerator 连接到 brokers ，以列出所有涉及订阅的主题分区。枚举器可以选择重复这个操作来发现新添加的主题/分区。</li>
<li>SourceReader 使用 KafkaConsumer 读取分配的 split （主题分区），并使用提供的 Deserializer 反序列化记录。分割(Topic Partitions) 没有终点，所以读取器永远不会到达数据的终点。</li>
</ul>
<p><strong>绑定的 Kafka 源</strong></p>
<p>和上面一样，只是每个 Split （主题分区）有一个定义的结束偏移量。一旦 SourceReader 达到一个 Split 的结束偏移量，它就会完成该 Split 。一旦所有分配的 Split 结束， SourceReader 就结束了。</p>
<h2 id="数据源-api">数据源 API</h2>
<p>本节介绍了 FLIP-27 中新引入的 Source API 的主要接口，并为开发者提供了 Source 开发的技巧。</p>
<h3 id="source">Source</h3>
<p><a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Source.java">Source</a> API 是一个工厂风格的接口，用于创建以下组件。</p>
<ul>
<li>Split Enumerator</li>
<li>源读取器</li>
<li>分离式序列器</li>
<li>枚举器检查点序列器</li>
</ul>
<p>除此之外， Source 还提供了源的<a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Boundedness.java">边界</a>属性，这样 Flink 可以选择合适的模式来运行 Flink 作业。</p>
<p>Source 的实现应该是可序列化的，因为 Source 实例在运行时被序列化并上传到 Flink 集群。</p>
<h3 id="splitenumerator">SplitEnumerator</h3>
<p><a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/SplitEnumerator.java">SplitEnumerator</a> 有望成为 Source 的&quot;大脑&quot;。SplitEnumerator 的典型实现会做以下工作。</p>
<ul>
<li>SourceReader 注册处理</li>
<li>SourceReader 失败处理
<ul>
<li>当 SourceReader 失败时，将调用 <code>addSplitsBack()</code> 方法。SplitEnumerator 应该收回未被失败的 SourceReader 承认的分割分配。</li>
</ul>
</li>
<li>SourceEvent 处理
<ul>
<li>SourceEvents 是在 SplitEnumerator 和 SourceReader 之间发送的自定义事件。实现可以利用这种机制来进行复杂的协调。</li>
</ul>
</li>
<li>分割发现和分配
<ul>
<li>SplitEnumerator 可以根据各种事件将 split 分配给 SourceReaders ，包括发现新的 split 、新的 SourceReader 注册、 SourceReader 失败等。</li>
</ul>
</li>
</ul>
<p>SplitEnumerator 可以借助 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/SplitEnumeratorContext.java">SplitEnumeratorContext</a> 完成上述工作， SplitEnumeratorContext 是在创建或恢复 SplitEnumerator 时提供给 Source 的。SplitEnumeratorContext 允许 SplitEnumerator 检索读取器的必要信息并执行协调动作。Source 实现应该将 SplitEnumeratorContext 传递给 SplitEnumerator 实例。</p>
<p>虽然 SplitEnumerator 实现可以通过只在它的方法被调用时采取协调动作的被动方式很好地工作，但一些 SplitEnumerator 实现可能希望主动采取行动。例如，一个 SplitEnumerator 可能希望定期运行 split discovery ，并将新的 split 分配给 SourceReaders 。这样的实现可能会发现调用 Async() 方法 SplitEnumeratorContext 很方便。下面的代码片段展示了 SplitEnumerator 实现如何在不维护自己的线程的情况下实现这一点。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MySplitEnumerator</span> <span class="n">implements</span> <span class="nc">SplitEnumerator</span><span class="o">&lt;</span><span class="nc">MySplit</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="k">private</span> <span class="k">final</span> <span class="n">long</span> <span class="nc">DISCOVER_INTERVAL</span> <span class="k">=</span> <span class="mi">60</span><span class="n">_000L</span><span class="o">;</span>

    <span class="cm">/**
</span><span class="cm">     * A method to discover the splits.
</span><span class="cm">     */</span>
    <span class="k">private</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">MySplit</span><span class="o">&gt;</span> <span class="n">discoverSplits</span><span class="o">()</span> <span class="o">{...}</span>
    
    <span class="nd">@Override</span>
    <span class="n">public</span> <span class="n">void</span> <span class="n">start</span><span class="o">()</span> <span class="o">{</span>
        <span class="o">...</span>
        <span class="n">enumContext</span><span class="o">.</span><span class="n">callAsync</span><span class="o">(</span><span class="k">this:</span><span class="kt">:discoverSplits</span><span class="o">,</span> <span class="n">splits</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">MockSourceSplit</span><span class="o">&gt;&gt;</span> <span class="n">assignments</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashMap</span><span class="o">&lt;&gt;();</span>
            <span class="n">int</span> <span class="n">parallelism</span> <span class="k">=</span> <span class="n">enumContext</span><span class="o">.</span><span class="n">currentParallelism</span><span class="o">();</span>
            <span class="k">for</span> <span class="o">(</span><span class="nc">MockSourceSplit</span> <span class="n">split</span> <span class="k">:</span> <span class="kt">splits</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">int</span> <span class="n">owner</span> <span class="k">=</span> <span class="n">split</span><span class="o">.</span><span class="n">splitId</span><span class="o">().</span><span class="n">hashCode</span><span class="o">()</span> <span class="o">%</span> <span class="n">parallelism</span><span class="o">;</span>
                <span class="n">assignments</span><span class="o">.</span><span class="n">computeIfAbsent</span><span class="o">(</span><span class="n">owner</span><span class="o">,</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;()).</span><span class="n">add</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>
            <span class="o">}</span>
            <span class="n">enumContext</span><span class="o">.</span><span class="n">assignSplits</span><span class="o">(</span><span class="k">new</span> <span class="nc">SplitsAssignment</span><span class="o">&lt;&gt;(</span><span class="n">assignments</span><span class="o">));</span>
        <span class="o">},</span> <span class="mi">0L</span><span class="o">,</span> <span class="nc">DISCOVER_INTERVAL</span><span class="o">);</span>
        <span class="o">...</span>
    <span class="o">}</span>
    <span class="o">...</span>
<span class="o">}</span>
</code></pre></div><h2 id="sourcereader">SourceReader</h2>
<p>SourceReader 是一个运行在 Task Manager 中的组件，用于消耗来自 Splits 的记录。</p>
<p>SourceReader 暴露了一个基于拉的消费接口。一个 Flink 任务在循环中不断调用 pollNext(ReaderOutput) 来轮询 SourceReader 的记录。pollNext(ReaderOutput) 方法的返回值表示源阅读器的状态。</p>
<ul>
<li>MORE_AVAILABLE - SourceReader 立即有更多的记录可用。</li>
<li>NOTHING_AVAILABLE - SourceReader 此时没有更多的记录可用，但将来可能会有更多的记录。</li>
<li>END_OF_INPUT - SourceReader 已经用完了所有的记录，达到了数据的终点。这意味着 SourceReader 可以被关闭。</li>
</ul>
<p>为了保证性能，会给 pollNext(ReaderOutput) 方法提供一个 ReaderOutput ，所以如果有必要， SourceReader 可以在一次调用 pollNext() 的过程中发出多条记录。例如，有时外部系统的工作粒度是块。一个块可能包含多条记录，但源码只能在块的边界处进行检查点。在这种情况下， SourceReader 可以一次将一个块中的所有记录排放到 ReaderOutput 。但是，除非必要， SourceReader 的实现应该避免在一次 pollNext(ReaderOutput) 的调用中发射多条记录。这是因为从 SourceReader 中进行轮询的任务线程是在事件循环中工作的，不能阻塞。</p>
<p>SourceReader 的所有状态都应该维护在 SourceSplits 里面，这些状态在 snapshotState() 调用时返回。这样做可以在需要时将 SourceSplits 重新分配给其他 SourceReaders 。</p>
<p>在创建 SourceReader 时，会向 Source 提供一个 SourceReaderContext 。预计 Source 将把上下文传递给 SourceReader 实例。SourceReader 可以通过 SourceReaderContext 向其 SplitEnumerator 发送 SourceEvent 。Source 的一个典型的设计模式是让 SourceReaders 向 SplitEnumerator 报告它们的本地信息， SplitEnumerator 有一个全局视图来做决策。</p>
<p>SourceReader API 是一个低级的 API ，它允许用户手动处理 split ，并有自己的线程模型来获取和交接记录。为了方便 SourceReader 的实现， Flink 提供了一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/SourceReaderBase.java">SourceReaderBase</a> 类，大大减少了编写 SourceReader 的工作量。强烈建议连接器开发人员利用 SourceReaderBase ，而不是从头开始编写 SourceReaders 。更多细节请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html#the-split-reader-api">Split Reader API</a> 部分。</p>
<h3 id="使用-source">使用 Source</h3>
<p>为了从 Source 创建 DataStream ，需要将 Source 传递给 StreamExecutionEnvironment。例如:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">mySource</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySource</span><span class="o">(...)</span>

<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromSource</span><span class="o">(</span>
      <span class="n">mySource</span><span class="o">,</span>
      <span class="nc">WatermarkStrategy</span><span class="o">.</span><span class="n">noWatermarks</span><span class="o">(),</span>
      <span class="s">&#34;MySourceName&#34;</span><span class="o">)</span>
<span class="o">...</span>
</code></pre></div><h2 id="split-读取器-api">Split 读取器 API</h2>
<p>核心的 SourceReader API 是完全异步的，需要实现者手动管理异步拆分读取。然而，在实践中，大多数 Source 使用执行阻塞操作，比如在客户端（例如 KafkaConsumer ）上阻塞 poll() 调用，或者在分布式文件系统（ HDFS ， S3 ，&hellip;）上阻塞 I/O 操作。为了与异步的 Source API 兼容，这些阻塞（同步）操作需要发生在单独的线程中，线程将数据交给异步部分的阅读器。</p>
<p><a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/splitreader/SplitReader.java">SplitReader</a> 是用于简单的基于同步读取/轮询的源码实现的高级 API ，比如文件读取、 Kafka 等。</p>
<p>核心是 SourceReaderBase 类，它接收一个 SplitReader 并创建运行 SplitReader 的 fetcher 线程，支持不同的消费线程模型。</p>
<h3 id="splitreader">SplitReader</h3>
<p>SplitReader API 只有三个方法。</p>
<ul>
<li>一个阻塞获取方法，返回一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/RecordsWithSplitIds.java">RecordsWithSplitIds</a> 。</li>
<li>一种非阻塞方法，用于处理拆分变化。</li>
<li>一个非阻塞的唤醒方法，用于唤醒阻塞的获取操作。</li>
</ul>
<p>SplitReader 只专注于从外部系统读取记录，因此比 SourceReader 简单得多。详情请查看该类的 Java 文档。</p>
<h3 id="sourcereaderbase">SourceReaderBase</h3>
<p>SourceReader 的实现很常见，它做了以下工作。</p>
<ul>
<li>拥有一个线程池，以阻塞的方式从外部系统的分割处获取数据。</li>
<li>处理内部获取线程和其他方法调用之间的同步，如 pollNext(ReaderOutput) 。</li>
<li>维护每个 split 的水印，以便进行水印对齐。</li>
<li>维护每个分身的状态，以便检查点。</li>
</ul>
<p>为了减少编写一个新的 SourceReader 的工作， Flink 提供了一个 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/SourceReaderBase.java">SourceReaderBase</a> 类作为 SourceReader 的基础实现。SourceReaderBase 开箱即完成了上述所有工作。如果要编写一个新的 SourceReader ，只需要让 SourceReader 实现继承 SourceReaderBase ，填充一些方法，然后实现一个高级的 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/splitreader/SplitReader.java">SplitReader</a> 就可以了。</p>
<h3 id="splitfetchermanager">SplitFetcherManager</h3>
<p>SourceReaderBase 支持一些开箱即用的线程模型，这取决于与之合作的 <a href="https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/source/reader/fetcher/SplitFetcherManager.java">SplitFetcherManager</a> 的行为。SplitFetcherManager 帮助创建和维护一个 SplitFetcher 池，每个 SplitFetcher 用一个 SplitReader 来获取。它还决定了如何将 split 分配给每个 split fetcher 。</p>
<p>举个例子，如下图所示，一个 SplitFetcherManager 可能有固定数量的线程，每个线程从分配给 SourceReader 的一些 split 中获取。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/source_reader.svg" alt="img"></p>
<p>下面的代码片段实现了这个线程模型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * A SplitFetcherManager that has a fixed size of split fetchers and assign splits 
</span><span class="cm"> * to the split fetchers based on the hash code of split IDs.
</span><span class="cm"> */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">FixedSizeSplitFetcherManager</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span> <span class="kd">extends</span> <span class="n">SourceSplit</span><span class="o">&gt;</span> 
        <span class="kd">extends</span> <span class="n">SplitFetcherManager</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">numFetchers</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">FixedSizeSplitFetcherManager</span><span class="o">(</span>
            <span class="kt">int</span> <span class="n">numFetchers</span><span class="o">,</span>
            <span class="n">FutureNotifier</span> <span class="n">futureNotifier</span><span class="o">,</span>
            <span class="n">FutureCompletingBlockingQueue</span><span class="o">&lt;</span><span class="n">RecordsWithSplitIds</span><span class="o">&lt;</span><span class="n">E</span><span class="o">&gt;&gt;</span> <span class="n">elementsQueue</span><span class="o">,</span>
            <span class="n">Supplier</span><span class="o">&lt;</span><span class="n">SplitReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitReaderSupplier</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">futureNotifier</span><span class="o">,</span> <span class="n">elementsQueue</span><span class="o">,</span> <span class="n">splitReaderSupplier</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">numFetchers</span> <span class="o">=</span> <span class="n">numFetchers</span><span class="o">;</span>
        <span class="c1">// Create numFetchers split fetchers.
</span><span class="c1"></span>        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">numFetchers</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="n">startFetcher</span><span class="o">(</span><span class="n">createSplitFetcher</span><span class="o">());</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">addSplits</span><span class="o">(</span><span class="n">List</span><span class="o">&lt;</span><span class="n">SplitT</span><span class="o">&gt;</span> <span class="n">splitsToAdd</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Group splits by their owner fetchers.
</span><span class="c1"></span>        <span class="n">Map</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitsByFetcherIndex</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
        <span class="n">splitsToAdd</span><span class="o">.</span><span class="na">forEach</span><span class="o">(</span><span class="n">split</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">ownerFetcherIndex</span> <span class="o">=</span> <span class="n">split</span><span class="o">.</span><span class="na">hashCode</span><span class="o">()</span> <span class="o">%</span> <span class="n">numFetchers</span><span class="o">;</span>
            <span class="n">splitsByFetcherIndex</span>
                    <span class="o">.</span><span class="na">computeIfAbsent</span><span class="o">(</span><span class="n">ownerFetcherIndex</span><span class="o">,</span> <span class="n">s</span> <span class="o">-&gt;</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;&gt;())</span>
                    <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>
        <span class="o">});</span>
        <span class="c1">// Assign the splits to their owner fetcher.
</span><span class="c1"></span>        <span class="n">splitsByFetcherIndex</span><span class="o">.</span><span class="na">forEach</span><span class="o">((</span><span class="n">fetcherIndex</span><span class="o">,</span> <span class="n">splitsForFetcher</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="n">fetchers</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">fetcherIndex</span><span class="o">).</span><span class="na">addSplits</span><span class="o">(</span><span class="n">splitsForFetcher</span><span class="o">);</span>
        <span class="o">});</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>而使用这个线程模型的 SourceReader 可以创建如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">FixedFetcherSizeSourceReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitT</span> <span class="kd">extends</span> <span class="n">SourceSplit</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span>
        <span class="kd">extends</span> <span class="n">SourceReaderBase</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nf">FixedFetcherSizeSourceReader</span><span class="o">(</span>
            <span class="n">FutureNotifier</span> <span class="n">futureNotifier</span><span class="o">,</span>
            <span class="n">FutureCompletingBlockingQueue</span><span class="o">&lt;</span><span class="n">RecordsWithSplitIds</span><span class="o">&lt;</span><span class="n">E</span><span class="o">&gt;&gt;</span> <span class="n">elementsQueue</span><span class="o">,</span>
            <span class="n">Supplier</span><span class="o">&lt;</span><span class="n">SplitReader</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">SplitT</span><span class="o">&gt;&gt;</span> <span class="n">splitFetcherSupplier</span><span class="o">,</span>
            <span class="n">RecordEmitter</span><span class="o">&lt;</span><span class="n">E</span><span class="o">,</span> <span class="n">T</span><span class="o">,</span> <span class="n">SplitStateT</span><span class="o">&gt;</span> <span class="n">recordEmitter</span><span class="o">,</span>
            <span class="n">Configuration</span> <span class="n">config</span><span class="o">,</span>
            <span class="n">SourceReaderContext</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span>
                <span class="n">futureNotifier</span><span class="o">,</span>
                <span class="n">elementsQueue</span><span class="o">,</span>
                <span class="k">new</span> <span class="n">FixedSizeSplitFetcherManager</span><span class="o">&lt;&gt;(</span>
                        <span class="n">config</span><span class="o">.</span><span class="na">getInteger</span><span class="o">(</span><span class="n">SourceConfig</span><span class="o">.</span><span class="na">NUM_FETCHERS</span><span class="o">),</span>
                        <span class="n">futureNotifier</span><span class="o">,</span>
                        <span class="n">elementsQueue</span><span class="o">,</span>
                        <span class="n">splitFetcherSupplier</span><span class="o">),</span>
                <span class="n">recordEmitter</span><span class="o">,</span>
                <span class="n">config</span><span class="o">,</span>
                <span class="n">context</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">onSplitFinished</span><span class="o">(</span><span class="n">Collection</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">finishedSplitIds</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Do something in the callback for the finished splits.
</span><span class="c1"></span>    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">SplitStateT</span> <span class="nf">initializedState</span><span class="o">(</span><span class="n">SplitT</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">protected</span> <span class="n">SplitT</span> <span class="nf">toSplitType</span><span class="o">(</span><span class="n">String</span> <span class="n">splitId</span><span class="o">,</span> <span class="n">SplitStateT</span> <span class="n">splitState</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>显然， SourceReader 的实现也可以在 SplitFetcherManager 和 SourceReaderBase 之上轻松实现自己的线程模型。</p>
<h2 id="事件时间和水印">事件时间和水印</h2>
<p>事件时间分配和水印生成作为数据源的一部分发生。离开源读取器的事件流具有事件时间戳，并且（在流执行期间）包含水印。有关事件时间和水印的介绍，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/timely-stream-processing.html">及时流处理</a>。</p>
<p>重要事项 基于传统 <a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SourceFunction.java">SourceFunction</a> 的应用程序通常会在后面单独的步骤中通过 stream.assignTimestampsAndWatermarks(WatermarkStrategy) 生成时间戳和水印。这个函数不应该被用于新的源，因为时间戳将被分配，并且它将覆盖之前的分割感知水印。</p>
<h3 id="api">API</h3>
<p>在 DataStream API 创建期间， WatermarkStrategy 被传递给 Source，并创建 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/eventtime/TimestampAssigner.java">TimestampAssigner</a> 和 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/eventtime/WatermarkGenerator.java">WatermarkGenerator</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">environment</span><span class="o">.</span><span class="n">fromSource</span><span class="o">(</span>
    <span class="nc">Source</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">,</span> <span class="o">?,</span> <span class="o">?&gt;</span> <span class="n">source</span><span class="o">,</span>
    <span class="nc">WatermarkStrategy</span><span class="o">&lt;</span><span class="nc">OUT</span><span class="o">&gt;</span> <span class="n">timestampsAndWatermarks</span><span class="o">,</span>
    <span class="nc">String</span> <span class="n">sourceName</span><span class="o">)</span>
</code></pre></div><p>TimestampAssigner 和 WatermarkGenerator 作为 ReaderOutput(或 SourceOutput) 的一部分透明地运行，因此源码实现者不必实现任何时间戳提取和水印生成代码。</p>
<h3 id="事件时间戳">事件时间戳</h3>
<p>事件时间戳的分配有两个步骤。</p>
<ol>
<li>
<p>SourceReader 可以通过调用 SourceOutput.collect(event, timestamp) 将源记录时间戳附加到事件上。这只与基于记录且有时间戳的数据源有关，如 Kafka 、 Kinesis 、 Pulsar 或 Pravega 。不基于记录且有时间戳的数据源（如文件）没有源记录时间戳。这一步是源连接器实现的一部分，而不是由使用源的应用程序参数化。</p>
</li>
<li>
<p>由应用程序配置的 TimestampAssigner 分配最终的时间戳。TimestampAssigner 看到原始源记录时间戳和事件。分配者可以使用源记录时间戳或访问事件的一个字段获得最终的事件时间戳。</p>
</li>
</ol>
<p>这种两步法允许用户同时引用源系统的时间戳和事件数据中的时间戳作为事件时间戳。</p>
<p>注意：当使用没有源记录时间戳的数据源（如文件），并选择源记录时间戳作为最终的事件时间戳时，事件将得到一个默认的时间戳，等于 LONG_MIN （=-9,223,372,036,854,775,808 ）。</p>
<h3 id="水印生成">水印生成</h3>
<p>水印生成器仅在流式执行期间激活。批量执行会停用水印生成器；下面描述的所有相关操作都将成为有效的无操作。</p>
<p>数据源 API 支持每次拆分单独运行水印生成器。这使得 Flink 可以单独观察每个分体的事件时间进度，这对于正确处理事件时间偏斜和防止空闲分区拖累整个应用的事件时间进度非常重要。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/per_split_watermarks.svg" alt="img"></p>
<p>当使用 Split Reader API 实现一个源连接器时，会自动处理这个问题。所有基于 Split Reader API 的实现都具有开箱即用的 split-aware 水印。</p>
<p>对于一个低级别的 SourceReader API 的实现来说，要使用 split-aware 水印的生成，该实现必须将不同的 split 事件输出到不同的输出中： Split-local SourceOutputs 。分割本地输出可以通过 createOutputForSplit(splitId) 和 releaseOutputForSplit(splitId) 方法在主 <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/ReaderOutput.java">ReaderOutput</a> 上创建和释放。详情请参考该类和方法的 JavaDocs 。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/sources.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/datastream-api" term="datastream-api" label="DataStream API" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/data-sources" term="data-sources" label="Data Sources" />
                            
                        
                    
                
            
        </entry>
    
</feed>
