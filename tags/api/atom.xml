<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.79.0">Hugo</generator><title type="html"><![CDATA[api on 焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/tags/api/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/tags/api/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/tags/api/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/tags/api/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2020-12-23T23:17:55+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/tags/api/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Flink 中的 Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://ohmyweekly.github.io/notes/2020-07-30-table-api-in-flink/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-07-26T00:00:00+08:00</published>
            <updated>2020-07-26T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Real Time Reporting with the Table API</blockquote><p>Apache Flink 提供的 Table API 是一个统一的、关系型的 API，用于批处理和流处理，即在无边界的、实时的流或有边界的、批处理的数据集上以相同的语义执行查询，并产生相同的结果。Flink 中的 Table API 通常用于简化数据分析、数据管道化和 ETL 应用的定义。</p>
<h2 id="你要构建什么">你要构建什么?</h2>
<p>在本教程中，你将学习如何构建一个实时的仪表盘，以按账户跟踪金融交易。该管道将从 Kafka 读取数据，并将结果写入 MySQL，通过 Grafana 可视化。</p>
<h2 id="先决条件">先决条件</h2>
<p>本演练假设你对 Java 或 Scala 有一定的熟悉，但即使你来自不同的编程语言，你也应该能够跟上。它还假设你熟悉基本的关系概念，如 SELECT 和 GROUP BY 子句。</p>
<h2 id="救命-我被卡住了">救命, 我被卡住了!</h2>
<p>如果你遇到困难，请查看<a href="https://flink.apache.org/community.html">社区支持资源</a>。特别是 Apache Flink 的<a href="https://flink.apache.org/community.html#mailing-lists">用户邮件列表</a>，它一直是 Apache 项目中最活跃的一个，也是快速获得帮助的好方法。</p>
<h2 id="如何跟进">如何跟进</h2>
<p>如果你想跟着走，你需要一台电脑与:</p>
<ul>
<li>Java 8 或 11</li>
<li>Maven</li>
<li>Docker</li>
</ul>
<p>所需的配置文件可在 <a href="https://github.com/apache/flink-playgrounds">flink-playgrounds</a> 资源库中获得。下载后，在 IDE 中打开项目 flink-playground/table-walkthrough，并导航到文件 SpendReport。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;   &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>

<span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">);</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">).</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">);</span>
</code></pre></div><h2 id="拆解代码">拆解代码</h2>
<h3 id="the-execution-environment">The Execution Environment</h3>
<p>前两行设置了你的 <code>TableEnvironment</code>。表环境是你如何为你的 Job 设置属性，指定你是在写批处理还是流式应用，以及创建你的源。本演练创建了一个使用流式执行的标准表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>
</code></pre></div><h3 id="注册表">注册表</h3>
<p>接下来，在当前<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册了表，您可以使用这些表连接到外部系统，以便读写批处理和流数据。表源提供对存储在外部系统中的数据的访问，如数据库、键值存储、消息队列或文件系统。table sink 向外部存储系统发出一个表。根据源和 sink 的类型，它们支持不同的格式，如 CSV、JSON、Avro 或 Parquet。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE transactions (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    account_id  BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    amount      BIGINT,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    transaction_time TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    WATERMARK FOR transaction_time AS transaction_time - INTERVAL &#39;5&#39; SECOND\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;connector&#39; = &#39;kafka&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;topic&#39;     = &#39;transactions&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;properties.bootstrap.servers&#39; = &#39;kafka:9092&#39;,\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;    &#39;format&#39;    = &#39;csv&#39;\n&#34;</span> <span class="o">+</span>
     <span class="s">&#34;)&#34;</span><span class="o">);</span>
</code></pre></div><p>注册了两个表：一个是交易输入表，一个是消费报告输出表。交易(transaction)表让我们可以读取信用卡交易，其中包含账户ID(account_id)、时间戳(transaction_time)和美元金额(amount)。该表是在一个名为 <code>transactions</code> 的 Kafka 主题上的逻辑视图，包含 CSV 数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE spend_report (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    account_id BIGINT,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    log_ts     TIMESTAMP(3),\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    amount     BIGINT\n,&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    PRIMARY KEY (account_id, log_ts) NOT ENFORCED&#34;</span> <span class="o">+</span>
    <span class="s">&#34;) WITH (\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;connector&#39;  = &#39;jdbc&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;url&#39;        = &#39;jdbc:mysql://mysql:3306/sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;table-name&#39; = &#39;spend_report&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;driver&#39;     = &#39;com.mysql.jdbc.Driver&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;username&#39;   = &#39;sql-demo&#39;,\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;    &#39;password&#39;   = &#39;demo-sql&#39;\n&#34;</span> <span class="o">+</span>
    <span class="s">&#34;)&#34;</span><span class="o">);</span>
</code></pre></div><p>第二张表 <code>spend_report</code>，存储了最终的汇总结果。其底层存储是 MySql 数据库中的一张表。</p>
<h3 id="查询">查询</h3>
<p>配置好环境和注册好表之后，你就可以构建你的第一个应用程序了。从 <code>TableEnvironment</code> 中，你可以从一个输入表中读取它的行，然后使用 <code>executeInsert</code> 将这些结果写入到一个输出表中。<code>report</code> 函数是你实现业务逻辑的地方。它目前还没有被实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">Table</span> <span class="n">transactions</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;transactions&#34;</span><span class="o">);</span>
<span class="n">report</span><span class="o">(</span><span class="n">transactions</span><span class="o">).</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;spend_report&#34;</span><span class="o">);</span>
</code></pre></div><h2 id="测试">测试</h2>
<p>该项目包含一个二次测试类 <code>SpendReportTest</code>，用于验证报表的逻辑。它以批处理模式创建了一个表环境。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">EnvironmentSettings</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">().</span><span class="n">inBatchMode</span><span class="o">().</span><span class="n">build</span><span class="o">();</span>
<span class="nc">TableEnvironment</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">);</span>
</code></pre></div><p>Flink 的独特属性之一是它在批处理和流式处理之间提供一致的语义。这意味着你可以在静态数据集上以批处理模式开发和测试应用程序，并以流式应用程序的形式部署到生产中。</p>
<h2 id="尝试一下">尝试一下</h2>
<p>现在有了 Job 设置的骨架，你就可以添加一些业务逻辑了。目标是建立一个报告，显示每个账户在一天中每个小时的总支出。这意味着时间戳列需要从毫秒到小时的颗粒度进行舍入。</p>
<p>Flink 支持用纯 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/">SQL</a> 或使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 开发关系型应用。Table API 是一个受 SQL 启发的流畅 DSL，可以用 Python、Java 或 Scala 编写，并支持强大的 IDE 集成。就像 SQL 查询一样，Table 程序可以选择所需的字段，并通过你的键进行分组。这些功能，加上<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置的函数</a>，如 <code>floor</code> 和 <code>sum</code>，写这个报告问题不大。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">).</span><span class="na">floor</span><span class="o">(</span><span class="n">TimeIntervalUnit</span><span class="o">.</span><span class="na">HOUR</span><span class="o">).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><h2 id="用户定义的函数">用户定义的函数</h2>
<p>Flink 包含有限的内置函数，有时你需要用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>来扩展它。如果 <code>floor</code> 不是预定义的，你可以自己实现它。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">java.time.LocalDateTime</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.time.temporal.ChronoUnit</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyFloor</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="nf">eval</span><span class="o">(</span>
        <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;TIMESTAMP(3)&#34;</span><span class="o">)</span> <span class="n">LocalDateTime</span> <span class="n">timestamp</span><span class="o">)</span> <span class="o">{</span>

        <span class="k">return</span> <span class="n">timestamp</span><span class="o">.</span><span class="na">truncatedTo</span><span class="o">(</span><span class="n">ChronoUnit</span><span class="o">.</span><span class="na">HOURS</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>然后迅速将其集成到你的应用程序中。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span><span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">call</span><span class="o">(</span><span class="n">MyFloor</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><p>这个查询会消耗 <code>transactions</code> 表的所有记录，计算报表，并以高效、可扩展的方式输出结果。使用该实现运行测试将通过。</p>
<h2 id="添加窗口">添加窗口</h2>
<p>基于时间的数据分组是数据处理中的典型操作，尤其是在处理无限流时。基于时间的分组被称为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">窗口</a>，Flink 提供了灵活的窗口语义。最基本的窗口类型称为 <code>Tumble</code> 窗口，它有一个固定的大小，其桶不重叠。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">report</span><span class="o">(</span><span class="n">Table</span> <span class="n">transactions</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">transactions</span>
        <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">Tumble</span><span class="o">.</span><span class="na">over</span><span class="o">(</span><span class="n">lit</span><span class="o">(</span><span class="n">1</span><span class="o">).</span><span class="na">hour</span><span class="o">()).</span><span class="na">on</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;transaction_time&#34;</span><span class="o">)).</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="na">select</span><span class="o">(</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;account_id&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">).</span><span class="na">start</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;log_ts&#34;</span><span class="o">),</span>
            <span class="n">$</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">).</span><span class="na">sum</span><span class="o">().</span><span class="na">as</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div><p>这就定义了你的应用程序使用基于时间戳列的一小时滚动窗口。因此，时间戳为 2019-06-01 01:23:47 的行被放在 2019-06-01 01:00:00 窗口中。</p>
<p>基于时间的聚合是独一无二的，因为在连续流应用中，时间与其他属性不同，一般是向前移动的。与 floor 和你的 UDF 不同，窗口函数是<a href="https://en.wikipedia.org/wiki/Intrinsic_function">内在的</a>，它允许运行时应用额外的优化。在批处理上下文中，窗口提供了一个方便的 API，用于通过时间戳属性对记录进行分组。</p>
<p>用这个实现运行测试也会通过。</p>
<h2 id="再来一次用流">再来一次，用流!</h2>
<p>就这样，一个功能齐全的、有状态的、分布式的流式应用! 查询不断地消耗 Kafka 的事务流，计算每小时的花费，并在结果准备好后立即发出。由于输入是有界的，所以查询一直在运行，直到手动停止。而且由于 Job 使用了基于时间窗口的聚合，所以当框架知道某个窗口不会再有记录到达时，Flink 可以进行特定的优化，比如状态清理。</p>
<p>表游乐场是完全 docker 化的，可以作为流式应用在本地运行。该环境包含一个 Kafka 主题、一个连续数据生成器、MySql 和 Grafana。</p>
<p>从 <code>table-walkthrough</code> 文件夹内启动 <code>docker-compose</code> 脚本。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose build
$ docker-compose up -d
</code></pre></div><p>你可以通过 <a href="http://localhost:8082/">Flink 控制台</a>查看正在运行的作业信息。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/spend-report-console.png" alt="img"></p>
<p>从 MySQL 里面探索结果。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">$ docker-compose <span class="nb">exec</span> mysql mysql -Dsql-demo -usql-demo -pdemo-sql

mysql&gt; use sql-demo<span class="p">;</span>
Database changed

mysql&gt; <span class="k">select</span> count<span class="o">(</span>*<span class="o">)</span> from spend_report<span class="p">;</span>
+----------+
<span class="p">|</span> count<span class="o">(</span>*<span class="o">)</span> <span class="p">|</span>
+----------+
<span class="p">|</span>      <span class="m">110</span> <span class="p">|</span>
+----------+
</code></pre></div><p>最后，去 <a href="http://localhost:3000/d/FOe0PbmGk/walkthrough?viewPanel=2&amp;orgId=1&amp;refresh=5s">Grafana</a> 看看完全可视化的结果吧!</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/table_api.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/try-flink/table_api.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/programming" term="programming" label="programming" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table" term="table" label="table" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/api" term="api" label="api" />
                            
                        
                    
                
            
        </entry>
    
</feed>
