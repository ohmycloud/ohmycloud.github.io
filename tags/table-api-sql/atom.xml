<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
    <generator uri="https://gohugo.io/" version="0.63.2">Hugo</generator><title type="html"><![CDATA[Table API & SQL on 焉知非鱼]]></title>
    
        <subtitle type="html"><![CDATA[rakulang, dartlang, nimlang, golang, rustlang, lang lang no see]]></subtitle>
    
    
    
            <link href="https://ohmyweekly.github.io/tags/table-api-sql/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://ohmyweekly.github.io/tags/table-api-sql/index.xml" rel="alternate" type="application/rss+xml" title="RSS" />
            <link href="https://ohmyweekly.github.io/tags/table-api-sql/atom.xml" rel="self" type="application/atom+xml" title="Atom" />
            <link href="https://ohmyweekly.github.io/tags/table-api-sql/jf2feed.json" rel="alternate" type="application/jf2feed+json" title="jf2feed" />
    <updated>2020-09-03T20:20:09+08:00</updated>
    
    
    
    
        <id>https://ohmyweekly.github.io/tags/table-api-sql/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Alter 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>ALTER Statements</blockquote><h1 id="alter-语句">ALTER 语句</h1>
<p>ALTER 语句用于修改目录中注册的表/视图/函数定义。</p>
<p>Flink SQL 目前支持以下 ALTER 语句。</p>
<ul>
<li>ALTER TABLE</li>
<li>ALTER DATABASE</li>
<li>ALTER FUNCTION</li>
</ul>
<h2 id="运行-alter-语句">运行 ALTER 语句</h2>
<p>ALTER 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法在 ALTER 操作成功时返回 &ldquo;OK&rdquo;，否则将抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 ALTER 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// a string array: [&#34;Orders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span><span class="c1"></span>
<span class="c1">// rename &#34;Orders&#34; to &#34;NewOrders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;ALTER TABLE Orders RENAME TO NewOrders;&#34;</span><span class="o">)</span>

<span class="c1">// a string array: [&#34;NewOrders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span></code></pre></div><h2 id="alter-table">ALTER TABLE</h2>
<ul>
<li>Rename Table</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">new_table_name</span>
</code></pre></div><p>将给定的表名重命名为另一个新表名。</p>
<ul>
<li>设置或更改表属性</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span> <span class="k">SET</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>
</code></pre></div><p>设置指定表格中的一个或多个属性。如果某个属性已经在表中被设置，则用新的属性覆盖旧的值。</p>
<h2 id="alter-database">ALTER DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="n">db_name</span> <span class="k">SET</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>
</code></pre></div><p>在指定的数据库中设置一个或多个属性。如果某个属性已经在数据库中被设置，则用新的属性覆盖旧的值。</p>
<h2 id="alter-function">ALTER FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> 
  <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="n">function_name</span> 
  <span class="k">AS</span> <span class="n">identifier</span> <span class="p">[</span><span class="k">LANGUAGE</span> <span class="n">JAVA</span><span class="o">|</span><span class="n">SCALA</span><span class="o">|</span><span class="n">PYTHON</span><span class="p">]</span>
</code></pre></div><p>用新的标识符和可选的语言标签改变一个目录函数。如果一个函数在目录中不存在，就会抛出一个异常。</p>
<p>如果语言标签是 JAVA/SCALA，标识符是 UDF 的完整 classpath。关于 Java/Scala UDF 的实现，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">User-defined Functions</a> 了解详情。</p>
<p>如果语言标签是 PYTHON，标识符是 UDF 的完全限定名，例如 pyflink.table.test.test_udf.add。关于 Python UDF 的实现，更多细节请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>。</p>
<p><strong>TEMPORARY</strong></p>
<p>改变具有目录和数据库命名空间的临时目录功能，并覆盖目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>更改没有命名空间的临时系统函数，并覆盖内置函数。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果函数不存在，就不会发生任何事情。</p>
<p><strong>LANGUAGE JAVA|SCALA|PYTHON</strong></p>
<p>语言标签，用于指导 flink 运行时如何执行函数。目前只支持 JAVA、SCALA 和 PYTHON，函数的默认语言是 JAVA。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Catalogs]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-catalogs/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Catalogs</blockquote><h1 id="catalogs">Catalogs</h1>
<p>目录提供了元数据，如数据库、表、分区、视图以及访问数据库或其他外部系统中存储的数据所需的功能和信息。</p>
<p>数据处理中最关键的一个方面是管理元数据。它可能是短暂的元数据，如临时表，或针对表环境注册的 UDF。或者是永久性的元数据，比如 Hive Metastore 中的元数据。目录为管理元数据提供了统一的 API，并使其可以从表 API 和 SQL 查询中访问。</p>
<p>Catalog 使用户能够引用数据系统中现有的元数据，并自动将它们映射到 Flink 的相应元数据中。例如，Flink 可以将 JDBC 表自动映射到 Flink 表，用户不必在 Flink 中手动重新编写 DDL。Catalog 大大简化了用户现有系统上手 Flink 所需的步骤，大大提升了用户体验。</p>
<h2 id="catalog-类型">Catalog 类型</h2>
<h3 id="genericinmemorycatalog">GenericInMemoryCatalog</h3>
<p>GenericInMemoryCatalog 是一个目录的内存实现。所有对象只在会话的生命周期内可用。</p>
<h3 id="jdbccatalog">JdbcCatalog</h3>
<p>JdbcCatalog 使用户能够通过 JDBC 协议将 Flink 与关系型数据库连接起来。PostgresCatalog 是目前 JDBC Catalog 的唯一实现。关于设置目录的更多细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/jdbc.html">JdbcCatalog 文档</a>。</p>
<h3 id="hivecatalog">HiveCatalog</h3>
<p>HiveCatalog 有两个目的，一是作为纯 Flink 元数据的持久化存储，二是作为读写现有 Hive 元数据的接口。Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/index.html">Hive 文档</a>提供了设置目录和与现有 Hive 安装接口的完整细节。</p>
<p>警告: Hive Metastore 将所有的元对象名称都存储为小写。这与 GenericInMemoryCatalog 不同，后者是区分大小写的。</p>
<h3 id="用户定义的-catalog">用户定义的 Catalog</h3>
<p>目录是可插拔的，用户可以通过实现 Catalog 接口来开发自定义目录。要在 SQL CLI 中使用自定义目录，用户应该通过实现 CatalogFactory 接口同时开发目录和它对应的目录工厂。</p>
<p>目录工厂定义了一组属性，用于在 SQL CLI 引导时配置目录。该属性集将被传递给发现服务，服务会尝试将属性与 CatalogFactory 匹配，并启动相应的目录实例。</p>
<h2 id="如何创建和注册-flink-table-到目录上">如何创建和注册 Flink Table 到目录上</h2>
<h3 id="使用-sql-ddl">使用 SQL DDL</h3>
<p>用户可以使用 SQL DDL 在 Table API 和 SQL 中创建目录中的表。</p>
<ul>
<li>Flink SQL</li>
</ul>
<pre><code>// the catalog should have been registered via yaml file
Flink SQL&gt; CREATE DATABASE mydb WITH (...);

Flink SQL&gt; CREATE TABLE mytable (name STRING, age INT) WITH (...);

Flink SQL&gt; SHOW TABLES;
mytable
</code></pre><p>详细信息，请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">Flink SQL CREATE DDL</a>。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// Create a HiveCatalog 
</span><span class="c1"></span><span class="k">val</span> <span class="n">catalog</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="s">&#34;&lt;path_of_hive_conf&gt;&#34;</span><span class="o">)</span>

<span class="c1">// Register the catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="n">catalog</span><span class="o">)</span>

<span class="c1">// Create a catalog database
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE DATABASE mydb WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// Create a catalog table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE mytable (name STRING, age INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span> <span class="c1">// should return the tables in current catalog and database.
</span></code></pre></div><p>For detailed information, please check out Flink SQL CREATE DDL.</p>
<h3 id="使用-java-scala-或-python">使用 Java, Scala 或 Python</h3>
<p>用户可以使用 Java、Scala 或 Python 来编程创建目录表。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.catalog._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.catalog.hive.HiveCatalog</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.descriptors.Kafka</span>

<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">.</span><span class="n">build</span><span class="o">)</span>

<span class="c1">// Create a HiveCatalog 
</span><span class="c1"></span><span class="k">val</span> <span class="n">catalog</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="s">&#34;&lt;path_of_hive_conf&gt;&#34;</span><span class="o">)</span>

<span class="c1">// Register the catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">&#34;myhive&#34;</span><span class="o">,</span> <span class="n">catalog</span><span class="o">)</span>

<span class="c1">// Create a catalog database 
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// Create a catalog table
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="nc">TableSchema</span><span class="o">.</span><span class="n">builder</span><span class="o">(</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;age&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span>

<span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span>
        <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> 
        <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(</span>
            <span class="n">schema</span><span class="o">,</span>
            <span class="k">new</span> <span class="nc">Kafka</span><span class="o">(</span><span class="o">)</span>
                <span class="o">.</span><span class="n">version</span><span class="o">(</span><span class="s">&#34;0.11&#34;</span><span class="o">)</span>
                <span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
                <span class="o">.</span><span class="n">startFromEarlist</span><span class="o">(</span><span class="o">)</span>
                <span class="o">.</span><span class="n">toProperties</span><span class="o">(</span><span class="o">)</span><span class="o">,</span>
            <span class="s">&#34;my comment&#34;</span>
        <span class="o">)</span><span class="o">,</span>
        <span class="kc">false</span>
    <span class="o">)</span>
    
<span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span> <span class="c1">// tables should contain &#34;mytable&#34;
</span></code></pre></div><h2 id="catalog-api">Catalog API</h2>
<p>注意：这里只列出了目录程序的 API，用户可以通过 SQL DDL 实现许多相同的功能。用户可以通过 SQL DDL 实现许多相同的功能。详细的 DDL 信息，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">SQL CREATE DDL</a>。</p>
<h3 id="数据库操作">数据库操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// drop database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// alter database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogDatabaseImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// get database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getDatabase</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// check if a database exist
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">databaseExists</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list databases in a catalog
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listDatabases</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="table-操作">Table 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// drop table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// alter table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogTableImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// rename table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">renameTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="s">&#34;my_new_table&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// get table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getTable</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// check if a table exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">tableExists</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list tables in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="视图操作">视图操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogViewImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// drop view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// alter view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogViewImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// rename view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">renameTable</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myview&#34;</span><span class="o">)</span><span class="o">,</span> <span class="s">&#34;my_new_view&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// get view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getTable</span><span class="o">(</span><span class="s">&#34;myview&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// check if a view exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">tableExists</span><span class="o">(</span><span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list views in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listViews</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="partition-操作">Partition 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create view
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createPartition</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span>
    <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// drop partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// alter partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterPartition</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">CatalogPartitionImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span>
    <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// get partition
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getPartition</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// check if a partition exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">partitionExists</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list partitions of a table
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitions</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list partitions of a table under a give partition spec
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitions</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogPartitionSpec</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list partitions of a table by expression filter
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listPartitionsByFilter</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;mytable&#34;</span><span class="o">)</span><span class="o">,</span> <span class="nc">Arrays</span><span class="o">.</span><span class="n">asList</span><span class="o">(</span><span class="n">epr1</span><span class="o">,</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h3 id="function-操作">Function 操作</h3>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">createFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogFunctionImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// drop function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">dropFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// alter function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">alterFunction</span><span class="o">(</span><span class="k">new</span> <span class="nc">ObjectPath</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">,</span> <span class="s">&#34;myfunc&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CatalogFunctionImpl</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// get function
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">getFunction</span><span class="o">(</span><span class="s">&#34;myfunc&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// check if a function exist or not
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">functionExists</span><span class="o">(</span><span class="s">&#34;myfunc&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// list functions in a database
</span><span class="c1"></span><span class="n">catalog</span><span class="o">.</span><span class="n">listFunctions</span><span class="o">(</span><span class="s">&#34;mydb&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><h2 id="目录的-table-api-和-sql">目录的 Table API 和 SQL</h2>
<h3 id="注册目录">注册目录</h3>
<p>用户可以访问一个名为 default_catalog 的默认内存目录，这个目录总是默认创建的。该目录默认有一个名为 default_database 的单一数据库。用户也可以在现有的 Flink 会话中注册额外的目录。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomCatalog</span><span class="o">(</span><span class="s">&#34;myCatalog&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>YAML</li>
</ul>
<p>所有使用 YAML 定义的目录必须提供一个 <code>type</code> 属性，指定目录的类型。以下类型是开箱即用的。</p>
<table>
<thead>
<tr>
<th align="left">Catalog</th>
<th align="left">Type Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">GenericInMemory</td>
<td align="left">generic_in_memory</td>
</tr>
<tr>
<td align="left">Hive</td>
<td align="left">hive</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">   </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>myCatalog<span class="w">
</span><span class="w">     </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>custom_catalog<span class="w">
</span><span class="w">     </span><span class="k">hive-conf-dir</span><span class="p">:</span><span class="w"> </span>...<span class="w">
</span></code></pre></div><h3 id="更改当前目录和数据库">更改当前目录和数据库</h3>
<p>Flink 将始终搜索当前目录和数据库中的表、视图和 UDF。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">useCatalog</span><span class="o">(</span><span class="s">&#34;myCatalog&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">useDatabase</span><span class="o">(</span><span class="s">&#34;myDb&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; USE CATALOG myCatalog<span class="p">;</span>
Flink SQL&gt; USE myDB<span class="p">;</span>
</code></pre></div><p>通过提供 catalog.database.object 形式的完全限定名称，可以访问非当前目录的元数据。</p>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;not_the_current_catalog.not_the_current_db.my_table&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; SELECT * FROM not_the_current_catalog.not_the_current_db.my_table<span class="p">;</span>
</code></pre></div><h3 id="列出可用的目录">列出可用的目录</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listCatalogs</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show catalogs<span class="p">;</span>
</code></pre></div><h3 id="列出可用的数据库">列出可用的数据库</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listDatabases</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show databases<span class="p">;</span>
</code></pre></div><h3 id="列出可用的表">列出可用的表</h3>
<ul>
<li>Scala</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><ul>
<li>Flink SQL</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; show tables<span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/catalogs" term="catalogs" label="Catalogs" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Create 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-create-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Create Statements</blockquote><h1 id="create-语句">CREATE 语句</h1>
<p>CREATE 语句用于在当前或指定的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>中注册一个表/视图/函数。注册的表/视图/函数可以在 SQL 查询中使用。</p>
<p>Flink SQL 目前支持以下 CREATE 语句。</p>
<ul>
<li>CREATE TABLE</li>
<li>CREATE DATABASE</li>
<li>CREATE VIEW</li>
<li>CREATE FUNCTION</li>
</ul>
<h2 id="运行一条-create-语句">运行一条 CREATE 语句</h2>
<p>CREATE 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中执行。executeSql()方法对于一个成功的 CREATE 操作会返回&rsquo;OK&rsquo;，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 CREATE 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Scala
</span><span class="c1"></span><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// SQL query with a registered table
</span><span class="c1"></span><span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="c1">// run a SQL query on the Table and retrieve the result as a new Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// Execute insert SQL with a registered table
</span><span class="c1"></span><span class="c1">// register a TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE RubberOrders(product STRING, amount INT) WITH (&#39;connector.path&#39;=&#39;/path/to/file&#39; ...)&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="c1">// run an insert SQL on the Table and emit the result to the TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; CREATE TABLE Orders <span class="o">(</span><span class="sb">`</span>user<span class="sb">`</span> BIGINT, product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; CREATE TABLE RubberOrders <span class="o">(</span>product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE <span class="s1">&#39;%Rubber%&#39;</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Submitting SQL update statement to the cluster...
</code></pre></div><h2 id="create-table">CREATE TABLE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span>
  <span class="p">(</span>
    <span class="err">{</span> <span class="o">&lt;</span><span class="n">column_definition</span><span class="o">&gt;</span> <span class="o">|</span> <span class="o">&lt;</span><span class="n">computed_column_definition</span><span class="o">&gt;</span> <span class="err">}</span><span class="p">[</span> <span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="n">n</span><span class="p">]</span>
    <span class="p">[</span> <span class="o">&lt;</span><span class="n">watermark_definition</span><span class="o">&gt;</span> <span class="p">]</span>
    <span class="p">[</span> <span class="o">&lt;</span><span class="n">table_constraint</span><span class="o">&gt;</span> <span class="p">]</span><span class="p">[</span> <span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="n">n</span><span class="p">]</span>
  <span class="p">)</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">table_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">partition_column_name1</span><span class="p">,</span> <span class="n">partition_column_name2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span><span class="p">]</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>
  <span class="p">[</span> <span class="k">LIKE</span> <span class="n">source_table</span> <span class="p">[</span><span class="p">(</span> <span class="o">&lt;</span><span class="n">like_options</span><span class="o">&gt;</span> <span class="p">)</span><span class="p">]</span> <span class="p">]</span>
   
<span class="o">&lt;</span><span class="n">column_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="k">column_name</span> <span class="n">column_type</span> <span class="p">[</span> <span class="o">&lt;</span><span class="n">column_constraint</span><span class="o">&gt;</span> <span class="p">]</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">column_comment</span><span class="p">]</span>
  
<span class="o">&lt;</span><span class="n">column_constraint</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="p">[</span><span class="k">CONSTRAINT</span> <span class="k">constraint_name</span><span class="p">]</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="k">NOT</span> <span class="n">ENFORCED</span>

<span class="o">&lt;</span><span class="n">table_constraint</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="p">[</span><span class="k">CONSTRAINT</span> <span class="k">constraint_name</span><span class="p">]</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="k">column_name</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span> <span class="k">NOT</span> <span class="n">ENFORCED</span>

<span class="o">&lt;</span><span class="n">computed_column_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="k">column_name</span> <span class="k">AS</span> <span class="n">computed_column_expression</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">column_comment</span><span class="p">]</span>

<span class="o">&lt;</span><span class="n">watermark_definition</span><span class="o">&gt;</span><span class="p">:</span>
  <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">rowtime_column_name</span> <span class="k">AS</span> <span class="n">watermark_strategy_expression</span>
  
<span class="o">&lt;</span><span class="n">like_options</span><span class="o">&gt;</span><span class="p">:</span>
<span class="err">{</span>
   <span class="err">{</span> <span class="k">INCLUDING</span> <span class="o">|</span> <span class="k">EXCLUDING</span> <span class="err">}</span> <span class="err">{</span> <span class="k">ALL</span> <span class="o">|</span> <span class="k">CONSTRAINTS</span> <span class="o">|</span> <span class="n">PARTITIONS</span> <span class="err">}</span>
 <span class="o">|</span> <span class="err">{</span> <span class="k">INCLUDING</span> <span class="o">|</span> <span class="k">EXCLUDING</span> <span class="o">|</span> <span class="n">OVERWRITING</span> <span class="err">}</span> <span class="err">{</span> <span class="k">GENERATED</span> <span class="o">|</span> <span class="k">OPTIONS</span> <span class="o">|</span> <span class="n">WATERMARKS</span> <span class="err">}</span> 
<span class="err">}</span><span class="p">[</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span>
</code></pre></div><p>用给定的名称创建一个表。如果目录中已经存在同名表，则抛出一个异常。</p>
<p><strong>计算列</strong></p>
<p>计算列是使用 &ldquo;column_name AS computed_column_expression&rdquo; 语法生成的虚拟列。它是由一个非查询表达式生成的，这个表达式使用同一张表中的其他列，而不是实际存储在表中。例如，计算列可以定义为 <code>cost AS price * quantity</code>。表达式可以包含物理列、常量、函数或变量的任意组合。表达式不能包含子查询。</p>
<p>计算列在 Flink 中通常用于在 CREATE TABLE 语句中定义<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。可以通过 <code>proc AS PROCTIME()</code> 使用系统 <code>proctime()</code> 函数轻松定义一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">处理时间属性</a>。另一方面，计算列可以用来派生事件时间列，因为事件时间列可能需要从现有的字段中派生出来，比如原来的字段不是 TIMESTAMP(3)类型，或者嵌套在 JSON 字符串中。</p>
<p>注意：</p>
<ul>
<li>在源表上定义的计算列是在从源表读取后计算出来的，它可以用在下面的 SELECT 查询语句中。</li>
<li>计算列不能作为 INSERT 语句的目标。在 INSERT 语句中，SELECT 子句的模式应该与没有计算列的目标表的模式相匹配。</li>
</ul>
<p><strong>WATERMARK</strong></p>
<p>WATERMARK 定义了表的事件时间属性，其形式为 <code>WATERMARK FOR rowtime_column_name AS watermark_strategy_expression</code>。</p>
<p><code>rowtime_column_name</code> 定义了一个现有的列，该列被标记为表的事件时间属性。这个列的类型必须是 TIMESTAMP(3)，并且是模式中的顶层列。它可以是一个计算列。</p>
<p><code>watermark_strategy_expression</code> 定义了水印生成策略。它允许任意的非查询表达式，包括计算列，来计算水印。表达式的返回类型必须是 TIMESTAMP(3)，它表示自 Epoch 以来的时间戳。只有当返回的水印是非空的，并且它的值大于之前发出的本地水印时，才会发出水印（以保留升水印的契约）。水印生成表达式由框架对每条记录进行评估。框架将定期发射最大的生成水印。如果当前的水印仍然与上一个水印相同，或者是空的，或者返回的水印值小于上一次发射的水印值，那么将不会发射新的水印。水印是在 <code>pipeline.auto-watermark-interval</code> 配置定义的时间间隔内发出的。如果水印间隔为 0ms，如果生成的水印不是空的，并且大于最后一个水印，则每条记录都会发出水印。</p>
<p>当使用事件时间语义时，表必须包含事件时间属性和水印策略。</p>
<p>Flink 提供了几种常用的水印策略。</p>
<ul>
<li>
<p>严格的升序时间戳。WATERMARK FOR rowtime_column AS rowtime_column。</p>
</li>
<li>
<p>发出迄今为止观察到的最大时间戳的水印。时间戳小于最大时间戳的行不会迟到。</p>
</li>
<li>
<p>升序时间戳。WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;0.001&rsquo; SECOND.</p>
</li>
<li>
<p>发出迄今为止观察到的最大时间戳的水印减 1。时间戳等于或小于最大时间戳的行不会迟到。</p>
</li>
<li>
<p>绑定出顺序性的时间戳。WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;string&rsquo; timeUnit.</p>
</li>
</ul>
<p>发出水印，水印是最大观察到的时间戳减去指定的延迟，例如：WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &lsquo;5&rsquo; SECOND 是 5 秒的延迟水印策略。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="p">,</span>
    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">5</span><span class="s1">&#39;</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span> <span class="p">.</span> <span class="p">.</span> <span class="p">.</span> <span class="p">)</span><span class="p">;</span>
<span class="k">PRIMARY</span> <span class="k">KEY</span>
</code></pre></div><p><strong>PRIMARY KEY</strong></p>
<p>Flink 利用优化的一个提示。它告诉我们一个表或视图的一列或一组列是唯一的，它们不包含空值。主键中的两列都不能为空。因此，主键可以唯一地识别表中的某一行。</p>
<p>主键约束既可以和列定义一起声明（列约束），也可以作为单行（表约束）。对于这两种情况，只能将其声明为一个单子。如果你同时定义了多个主键约束，就会抛出一个异常。</p>
<p><strong>有效性检查</strong></p>
<p>SQL 标准规定，一个约束可以是 ENFORCED 或 NOT ENFORCED。这控制了约束检查是否会在输入/输出数据上执行。Flink 并不拥有数据，因此我们要支持的唯一模式是 NOT ENFORCED 模式。用户要确保查询强制执行密钥的完整性。</p>
<p>Flink 会假设主键的正确性，假设列的空性与主键的列对齐。连接器应该确保这些是对齐的。</p>
<p>注意事项: 在 CREATE TABLE 语句中，创建主键约束会改变列的可空性，也就是说，有主键约束的列是不可空的。</p>
<p><strong>PARTITIONED BY</strong></p>
<p>按指定的列对创建的表进行分区。如果该表被用作文件系统汇，则会为每个分区创建一个目录。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>表属性用于创建表源/接收器。这些属性通常用于查找和创建底层连接器。</p>
<p>表达式 key1=val1 的键和值都应该是字符串文字。关于不同连接器的所有支持的表属性，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统</a>中的详细信息。</p>
<p>注释：表名可以有三种格式。表名可以有三种格式。</p>
<ol>
<li>catalog_name.db_name.table_name</li>
<li>db_name.table_name</li>
<li>table_name。</li>
</ol>
<p>对于 catalog_name.db_name.table_name，表将被注册到元存储中，目录名为 &ldquo;catalog_name&rdquo;，数据库名为 &ldquo;db_name&rdquo;；对于 db_name.table_name，表将被注册到执行表环境的当前目录中，数据库名为 &ldquo;db_name&rdquo;；对于 table_name，表将被注册到执行表环境的当前目录和数据库中。</p>
<p>注意事项: 用 CREATE TABLE 语句注册的表既可以作为表源，也可以作为表汇，在 DMLs 中没有引用之前，我们不能决定它是作为表源还是表汇使用。</p>
<p><strong>LIKE 子句</strong></p>
<p>LIKE 子句是 SQL 特征的变体/组合（特征 T171，&ldquo;表定义中的 LIKE 子句&quot;和特征 T173，&ldquo;表定义中的扩展 LIKE 子句&rdquo;）。该子句可用于根据现有表的定义创建一个表。此外，用户还可以扩展原表或排除其中的某些部分。与 SQL 标准不同的是，该子句必须在 CREATE 语句的顶层定义。这是因为该子句适用于定义的多个部分，而不仅仅是模式部分。</p>
<p>你可以使用该子句来重用（并可能覆盖）某些连接器属性，或者为外部定义的表添加水印。例如，您可以为 Apache Hive 中定义的表添加水印。</p>
<p>请考虑下面的示例语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span> 
    <span class="s1">&#39;</span><span class="s1">connector</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">kafka</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="s1">scan.startup.mode</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">earliest-offset</span><span class="s1">&#39;</span>
<span class="p">)</span><span class="p">;</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_with_watermark</span> <span class="p">(</span>
    <span class="c1">-- Add watermark definition
</span><span class="c1"></span>    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">5</span><span class="s1">&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="c1">-- Overwrite the startup-mode
</span><span class="c1"></span>    <span class="s1">&#39;</span><span class="s1">scan.startup.mode</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">latest-offset</span><span class="s1">&#39;</span>
<span class="p">)</span>
<span class="k">LIKE</span> <span class="n">Orders</span><span class="p">;</span>
</code></pre></div><p>由此产生的 Orders_with_watermark 表将等同于用以下语句创建的表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_with_watermark</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="p">,</span>
    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">5</span><span class="s1">&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="s1">&#39;</span><span class="s1">connector</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">kafka</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="s1">scan.startup.mode</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">latest-offset</span><span class="s1">&#39;</span>
<span class="p">)</span><span class="p">;</span>
</code></pre></div><p>可以用同类选项控制表功能的合并逻辑。</p>
<p>您可以控制以下的合并行为:</p>
<ul>
<li>CONSTRAINTS - 主键和唯一键等约束条件。</li>
<li>GENERATED-计算列</li>
<li>OPTIONS - 描述连接器和格式属性的连接器选项。</li>
<li>PARTITIONS - 表的分区</li>
<li>WATERMARKS - 水印声明</li>
</ul>
<p>有三种不同的合并策略。</p>
<ul>
<li>INCLUDING - 包括源表的特征，对重复的条目失败，例如，如果两个表中都存在相同键的选项。</li>
<li>EXCLUDING - 不包含源表的给定特征。</li>
<li>OVERWRITING - 包括源表的特征，用新表的属性覆盖源表的重复条目，例如，如果两个表中都存在具有相同键的选项，则将使用当前语句中的选项。</li>
</ul>
<p>此外，可以使用 INCLUDING/EXCLUDING ALL 选项来指定如果没有定义特定的策略应该是什么，即如果使用 EXCLUDING ALL INCLUDING WATERMARKS，则只从源表中包含水印。</p>
<p>例子：</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="c1">-- A source table stored in a filesystem
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_in_file</span> <span class="p">(</span>
    <span class="k">user</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">product</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time_string</span> <span class="n">STRING</span><span class="p">,</span>
    <span class="n">order_time</span> <span class="k">AS</span> <span class="n">to_timestamp</span><span class="p">(</span><span class="n">order_time</span><span class="p">)</span>
    
<span class="p">)</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="k">user</span> 
<span class="k">WITH</span> <span class="p">(</span> 
    <span class="s1">&#39;</span><span class="s1">connector</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">filesystem</span><span class="s1">&#39;</span>
    <span class="s1">&#39;</span><span class="s1">path</span><span class="s1">&#39;</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">...</span><span class="s1">&#39;</span>
<span class="p">)</span><span class="p">;</span>

<span class="c1">-- A corresponding table we want to store in kafka
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">Orders_in_kafka</span> <span class="p">(</span>
    <span class="c1">-- Add watermark definition
</span><span class="c1"></span>    <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">order_time</span> <span class="k">AS</span> <span class="n">order_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">5</span><span class="s1">&#39;</span> <span class="k">SECOND</span> 
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="s1">&#39;</span><span class="s1">connector</span><span class="s1">&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="s1">kafka</span><span class="s1">&#39;</span>
    <span class="p">.</span><span class="p">.</span><span class="p">.</span>
<span class="p">)</span>
<span class="k">LIKE</span> <span class="n">Orders_in_file</span> <span class="p">(</span>
    <span class="c1">-- Exclude everything besides the computed columns which we need to generate the watermark for.
</span><span class="c1"></span>    <span class="c1">-- We do not want to have the partitions or filesystem options as those do not apply to kafka. 
</span><span class="c1"></span>    <span class="k">EXCLUDING</span> <span class="k">ALL</span>
    <span class="k">INCLUDING</span> <span class="k">GENERATED</span>
<span class="p">)</span><span class="p">;</span>
</code></pre></div><p>如果您没有提供同类选项，则默认使用 <code>INCLUDING ALL OVERWRITING OPTIONS</code>。</p>
<p>注意: 您无法控制合并物理字段的行为。这些字段将被合并，就像您应用 <strong>INCLUDING</strong> 策略一样。</p>
<h2 id="create-catalog">CREATE CATALOG</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">CATALOG</span> <span class="k">catalog_name</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>
</code></pre></div><p>用给定的目录属性创建一个目录。如果已经存在同名的目录，则会产生异常。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>目录属性，用于存储与本目录相关的额外信息。表达式 key1=val1 的键和值都应该是字符串文字。</p>
<p>更多详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>。</p>
<h2 id="create-database">CREATE DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="n">db_name</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">database_comment</span><span class="p">]</span>
  <span class="k">WITH</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>
</code></pre></div><p>用给定的数据库属性创建一个数据库，如果目录中已经存在同名的数据库，则抛出异常。如果目录中已经存在相同名称的数据库，则会抛出异常。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果数据库已经存在，则不会发生任何事情。</p>
<p><strong>WITH OPTIONS</strong></p>
<p>数据库属性，用于存储与本数据库相关的额外信息。表达式 key1=val1 的键和值都应该是字符串文字。</p>
<h2 id="create-view">CREATE VIEW</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="k">VIEW</span> <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="n">view_name</span>
  <span class="p">[</span><span class="err">{</span><span class="n">columnName</span> <span class="p">[</span><span class="p">,</span> <span class="n">columnName</span> <span class="p">]</span><span class="o">*</span> <span class="err">}</span><span class="p">]</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">view_comment</span><span class="p">]</span>
  <span class="k">AS</span> <span class="n">query_expression</span>
</code></pre></div><p>用给定的查询表达式创建一个视图，如果目录中已经存在同名的视图，则抛出异常。如果目录中已经存在同名的视图，则会抛出异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>创建具有目录和数据库命名空间并覆盖视图的临时视图。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果视图已经存在，则不会发生任何事情。</p>
<h2 id="create-function">CREATE FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> 
  <span class="p">[</span><span class="k">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="n">function_name</span> 
  <span class="k">AS</span> <span class="n">identifier</span> <span class="p">[</span><span class="k">LANGUAGE</span> <span class="n">JAVA</span><span class="o">|</span><span class="n">SCALA</span><span class="o">|</span><span class="n">PYTHON</span><span class="p">]</span>
</code></pre></div><p>创建一个目录函数，该函数具有目录和数据库的名称空间，并带有标识符和可选的语言标签。如果目录中已经存在同名函数，则会抛出一个异常。</p>
<p>如果语言标签是 JAVA/SCALA，标识符是 UDF 的完整 classpath。关于 Java/Scala UDF 的实现，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">User-defined Functions</a> 了解详情。</p>
<p>如果语言标签是 PYTHON，标识符是 UDF 的完全限定名，例如 pyflink.table.test.test_udf.add。关于 Python UDF 的实现，更多细节请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>。</p>
<p><strong>TEMPORARY</strong></p>
<p>创建具有目录和数据库命名空间并覆盖目录功能的临时目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>创建没有命名空间并覆盖内置函数的临时系统函数。</p>
<p><strong>IF NOT EXISTS</strong></p>
<p>如果函数已经存在，则不会发生任何事情。</p>
<p><strong>LANGUAGE JAVA|SCALA|PYTHON</strong></p>
<p>语言标签，用于指示 Flink 运行时如何执行函数。目前只支持 JAVA、SCALA 和 PYTHON，函数的默认语言是 JAVA。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Drop 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Drop Statements</blockquote><h1 id="drop-语句">DROP 语句</h1>
<p>DROP 语句用于从当前或指定的目录中删除一个注册的表/视图/函数。</p>
<p>Flink SQL 目前支持以下 DROP 语句。</p>
<ul>
<li>DROP TABLE</li>
<li>DROP DATABASE</li>
<li>DROP VIEW</li>
<li>DROP FUNCTION</li>
</ul>
<h2 id="运行一个-drop-语句">运行一个 DROP 语句</h2>
<p>DROP 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法对于一个成功的 DROP 操作会返回&rsquo;OK&rsquo;，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 DROP 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// a string array: [&#34;Orders&#34;]
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span><span class="c1"></span>
<span class="c1">// drop &#34;Orders&#34; table from catalog
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;DROP TABLE Orders&#34;</span><span class="o">)</span>

<span class="c1">// an empty string array
</span><span class="c1"></span><span class="k">val</span> <span class="n">tables</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">listTables</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// or tableEnv.executeSql(&#34;SHOW TABLES&#34;).print()
</span></code></pre></div><h2 id="drop-table">DROP TABLE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">TABLE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span>
</code></pre></div><p>删除一个给定表名的表。如果要删除的表不存在，则抛出一个异常。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果该表不存在，就不会发生任何事情。</p>
<h2 id="drop-database">DROP DATABASE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="n">db_name</span> <span class="p">[</span> <span class="p">(</span><span class="k">RESTRICT</span> <span class="o">|</span> <span class="k">CASCADE</span><span class="p">)</span> <span class="p">]</span>
</code></pre></div><p>删除一个给定数据库名称的数据库，如果要删除的数据库不存在，会产生异常。如果要删除的数据库不存在，则抛出一个异常。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果数据库不存在，则不会发生任何事情。</p>
<p><strong>RESTRICT</strong></p>
<p>丢弃非空数据库会触发异常。默认为启用。</p>
<p><strong>CASCADE</strong></p>
<p>丢弃一个非空的数据库也会丢弃所有相关的表和函数。</p>
<h2 id="drop-view">DROP VIEW</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="k">VIEW</span>  <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="n">view_name</span>
</code></pre></div><p>丢弃一个有目录和数据库命名空间的视图。如果要删除的视图不存在，则会产生一个异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>删除具有目录和数据库命名空间的临时视图。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果视图不存在，则不会发生任何事情。</p>
<p>维护依赖关系 Flink 没有通过 CASCADE/RESTRICT 关键字来维护视图的依赖关系，当前的方式是当用户试图在诸如视图的底层表被删除的情况下使用视图时，会产生延迟错误消息。</p>
<h2 id="drop-function">DROP FUNCTION</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="o">|</span><span class="k">TEMPORARY</span> <span class="k">SYSTEM</span><span class="p">]</span> <span class="k">FUNCTION</span> <span class="p">[</span><span class="k">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="n">function_name</span><span class="p">;</span>
</code></pre></div><p>删除一个有目录和数据库命名空间的目录函数。如果要放弃的函数不存在，则会产生一个异常。</p>
<p><strong>TEMPORARY</strong></p>
<p>丢弃具有目录和数据库命名空间的临时目录功能。</p>
<p><strong>TEMPORARY SYSTEM</strong></p>
<p>删除没有命名空间的临时系统函数。</p>
<p><strong>IF EXISTS</strong></p>
<p>如果函数不存在，就不会发生任何事情。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Explan 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Explan Statements</blockquote><h1 id="explain-语句">EXPLAIN 语句</h1>
<p>EXPLAIN 语句用于解释一个查询或 INSERT 语句的逻辑和优化查询计划。</p>
<h2 id="运行-explain-语句">运行 EXPLAIN 语句</h2>
<p>EXPLAIN 语句可以用 <code>TableEnvironment 的 executeSql()</code> 方法执行，也可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中执行。<code>executeSql()</code> 方法在 EXPLAIN 操作成功后返回解释结果，否则将抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 SQL CLI 中运行 EXPLAIN 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE MyTable1 (count bigint, work VARCHAR(256) WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE MyTable2 (count bigint, work VARCHAR(256) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// explain SELECT statement through TableEnvironment.explainSql()
</span><span class="c1"></span><span class="k">val</span> <span class="n">explanation</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">explainSql</span><span class="o">(</span>
  <span class="s">&#34;SELECT count, word FROM MyTable1 WHERE word LIKE &#39;F%&#39; &#34;</span> <span class="o">+</span>
  <span class="s">&#34;UNION ALL &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable2&#34;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span>

<span class="c1">// explain SELECT statement through TableEnvironment.executeSql()
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;EXPLAIN PLAN FOR &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable1 WHERE word LIKE &#39;F%&#39; &#34;</span> <span class="o">+</span>
  <span class="s">&#34;UNION ALL &#34;</span> <span class="o">+</span> 
  <span class="s">&#34;SELECT count, word FROM MyTable2&#34;</span><span class="o">)</span>
<span class="n">tableResult</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><p>EXPLAIN 的结果是：</p>
<pre><code>== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
    FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, MyTable1]], fields=[count, word])
  FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, MyTable2]], fields=[count, word])
  

== Optimized Logical Plan ==
DataStreamUnion(all=[true], union all=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')])
    TableSourceScan(table=[[default_catalog, default_database, MyTable1]], fields=[count, word])
  TableSourceScan(table=[[default_catalog, default_database, MyTable2]], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

Stage 2 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 3 : Operator
		content : from: (count, word)
		ship_strategy : REBALANCE

		Stage 4 : Operator
			content : where: (LIKE(word, _UTF-16LE'F%')), select: (count, word)
			ship_strategy : FORWARD

			Stage 5 : Operator
				content : from: (count, word)
				ship_strategy : REBALANCE
</code></pre><h2 id="语法">语法</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">EXPLAIN</span> <span class="n">PLAN</span> <span class="k">FOR</span> <span class="o">&lt;</span><span class="n">query_statement_or_insert_statement</span><span class="o">&gt;</span>
</code></pre></div><p>关于查询语法，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#supported-syntax">查询</a>页面。关于 INSERT，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">INSERT</a> 页面。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Insert 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Insert Statements</blockquote><h1 id="insert-语句">INSERT 语句</h1>
<p>INSERT 语句用于向表中添加行。</p>
<h2 id="运行-insert-语句">运行 INSERT 语句</h2>
<p>单条 INSERT 语句可以通过 TableEnvironment 的 <code>executeSql()</code> 方法执行，也可以在 SQL CLI 中执行。INSERT 语句的 <code>executeSql()</code> 方法会立即提交一个 Flink 作业，并返回一个与提交的作业相关联的 TableResult 实例。多个 INSERT 语句可以通过 StatementSet 的 <code>addInsertSql()</code> 方法执行，StatementSet 可以由 <code>TableEnvironment.createStatementSet()</code> 方法创建。<code>addInsertSql()</code> 方法是一种懒惰的执行方式，它们只有在调用 <code>StatementSet.execute()</code> 时才会被执行。</p>
<p>下面的例子展示了如何在 TableEnvironment 中运行一条 INSERT 语句，以及在 SQL CLI 中，在 StatementSet 中运行多条 INSERT 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; CREATE TABLE Orders <span class="o">(</span><span class="sb">`</span>user<span class="sb">`</span> BIGINT, product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; CREATE TABLE RubberOrders<span class="o">(</span>product STRING, amount INT<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>

Flink SQL&gt; SHOW TABLES<span class="p">;</span>
Orders
RubberOrders

Flink SQL&gt; INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE <span class="s1">&#39;%Rubber%&#39;</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Submitting SQL update statement to the cluster...
<span class="o">[</span>INFO<span class="o">]</span> Table update statement has been successfully submitted to the cluster:
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a source table named &#34;Orders&#34; and a sink table named &#34;RubberOrders&#34;
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE RubberOrders(product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// run a single INSERT query on the registered source table and emit the result to registered sink table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult1</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
<span class="c1">// get job status through TableResult
</span><span class="c1"></span><span class="n">println</span><span class="o">(</span><span class="n">tableResult1</span><span class="o">.</span><span class="n">getJobClient</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">getJobStatus</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>

<span class="c1">//----------------------------------------------------------------------------
</span><span class="c1"></span><span class="c1">// register another sink table named &#34;GlassOrders&#34; for multiple INSERT queries
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE GlassOrders(product VARCHAR, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// run multiple INSERT queries on the registered source table and emit the result to registered sink tables
</span><span class="c1"></span><span class="k">val</span> <span class="n">stmtSet</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">createStatementSet</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// only single INSERT query can be accepted by `addInsertSql` method
</span><span class="c1"></span><span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsertSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsertSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO GlassOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Glass%&#39;&#34;</span><span class="o">)</span>
<span class="c1">// execute all statements together
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult2</span> <span class="k">=</span> <span class="n">stmtSet</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// get job status through TableResult
</span><span class="c1"></span><span class="n">println</span><span class="o">(</span><span class="n">tableResult2</span><span class="o">.</span><span class="n">getJobClient</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">getJobStatus</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><h2 id="insert-from-select-queries">Insert from select queries</h2>
<p>查询结果可以通过使用插入子句插入到表中。</p>
<h3 id="语法">语法</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="err">{</span> <span class="k">INTO</span> <span class="o">|</span> <span class="n">OVERWRITE</span> <span class="err">}</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span> <span class="p">[</span><span class="n">PARTITION</span> <span class="n">part_spec</span><span class="p">]</span> <span class="n">select_statement</span>

<span class="n">part_spec</span><span class="p">:</span>
  <span class="p">(</span><span class="n">part_col_name1</span><span class="o">=</span><span class="n">val1</span> <span class="p">[</span><span class="p">,</span> <span class="n">part_col_name2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span><span class="p">)</span>
</code></pre></div><p><strong>OVERWRITE</strong></p>
<p>INSERT OVERWRITE 将覆盖表或分区中的任何现有数据。否则，将追加新数据。</p>
<p><strong>PARTITION</strong></p>
<p>PARTITION 子句应包含本次插入的静态分区列。</p>
<h3 id="例子">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="c1">-- Creates a partitioned table
</span><span class="c1"></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">country_page_view</span> <span class="p">(</span><span class="k">user</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">cnt</span> <span class="nb">INT</span><span class="p">,</span> <span class="nb">date</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">country</span> <span class="n">STRING</span><span class="p">)</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="nb">date</span><span class="p">,</span> <span class="n">country</span><span class="p">)</span>
<span class="k">WITH</span> <span class="p">(</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span>

<span class="c1">-- Appends rows into the static partition (date=&#39;2019-8-30&#39;, country=&#39;China&#39;)
</span><span class="c1"></span><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">2019-8-30</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">country</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">China</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Appends rows into partition (date, country), where date is static partition with value &#39;2019-8-30&#39;,
</span><span class="c1"></span><span class="c1">-- country is dynamic partition whose value is dynamic determined by each row.
</span><span class="c1"></span><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">2019-8-30</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span><span class="p">,</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Overwrites rows into static partition (date=&#39;2019-8-30&#39;, country=&#39;China&#39;)
</span><span class="c1"></span><span class="k">INSERT</span> <span class="n">OVERWRITE</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">2019-8-30</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">country</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">China</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>

<span class="c1">-- Overwrites rows into partition (date, country), where date is static partition with value &#39;2019-8-30&#39;,
</span><span class="c1"></span><span class="c1">-- country is dynamic partition whose value is dynamic determined by each row.
</span><span class="c1"></span><span class="k">INSERT</span> <span class="n">OVERWRITE</span> <span class="n">country_page_view</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="nb">date</span><span class="o">=</span><span class="s1">&#39;</span><span class="s1">2019-8-30</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">cnt</span><span class="p">,</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">page_view_source</span><span class="p">;</span>
</code></pre></div><h2 id="insert-values-into-tables">Insert values into tables</h2>
<p>INSERT&hellip;VALUES 语句可以用来直接从 SQL 中向表中插入数据。</p>
<h3 id="语法-1">语法</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="err">{</span> <span class="k">INTO</span> <span class="o">|</span> <span class="n">OVERWRITE</span> <span class="err">}</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span> <span class="k">VALUES</span> <span class="n">values_row</span> <span class="p">[</span><span class="p">,</span> <span class="n">values_row</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span>

<span class="n">values_row</span><span class="p">:</span>
    <span class="p">:</span> <span class="p">(</span><span class="n">val1</span> <span class="p">[</span><span class="p">,</span> <span class="n">val2</span><span class="p">,</span> <span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span><span class="p">)</span>
</code></pre></div><p><strong>OVERWRITE</strong></p>
<p>INSERT OVERWRITE 将覆盖表中的任何现有数据。否则，将追加新数据。</p>
<h3 id="例子-1">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">students</span> <span class="p">(</span><span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">,</span> <span class="n">gpa</span> <span class="nb">DECIMAL</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span><span class="p">;</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">students</span>
  <span class="k">VALUES</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">fred flintstone</span><span class="s1">&#39;</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">1</span><span class="p">.</span><span class="mi">28</span><span class="p">)</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">barney rubble</span><span class="s1">&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">.</span><span class="mi">32</span><span class="p">)</span><span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Show 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-show-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Show Statements</blockquote><h1 id="show-语句">SHOW 语句</h1>
<p>SHOW 语句用于列出所有目录，或列出当前目录中的所有数据库，或列出当前目录和当前数据库中的所有表/视图，或列出当前目录和当前数据库中的所有函数，包括临时系统函数、系统函数、临时目录函数和目录函数。</p>
<p>Flink SQL 目前支持以下 SHOW 语句。</p>
<ul>
<li>SHOW CATALOGS</li>
<li>SHOW DATABASES</li>
<li>SHOW TABLES</li>
<li>SHOW VIEWS</li>
<li>SHOW FUNCTIONS</li>
</ul>
<h2 id="运行-show-语句">运行 SHOW 语句</h2>
<p>SHOW 语句可以用 TableEnvironment 的 executeSql()方法执行，也可以在 SQL CLI 中执行。executeSql()方法会对成功的 SHOW 操作返回对象，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中运行 SHOW 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">Flink SQL&gt; SHOW CATALOGS<span class="p">;</span>
default_catalog

Flink SQL&gt; SHOW DATABASES<span class="p">;</span>
default_database

Flink SQL&gt; CREATE TABLE my_table <span class="o">(</span>...<span class="o">)</span> WITH <span class="o">(</span>...<span class="o">)</span><span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> Table has been created.

Flink SQL&gt; SHOW TABLES<span class="p">;</span>
my_table

Flink SQL&gt; CREATE VIEW my_view AS ...<span class="p">;</span>
<span class="o">[</span>INFO<span class="o">]</span> View has been created.

Flink SQL&gt; SHOW VIEWS<span class="p">;</span>
my_view

Flink SQL&gt; SHOW FUNCTIONS<span class="p">;</span>
mod
sha256
...
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// show catalogs
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW CATALOGS&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +-----------------+
</span><span class="c1"></span><span class="c1">// |    catalog name |
</span><span class="c1"></span><span class="c1">// +-----------------+
</span><span class="c1"></span><span class="c1">// | default_catalog |
</span><span class="c1"></span><span class="c1">// +-----------------+
</span><span class="c1"></span>
<span class="c1">// show databases
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +------------------+
</span><span class="c1"></span><span class="c1">// |    database name |
</span><span class="c1"></span><span class="c1">// +------------------+
</span><span class="c1"></span><span class="c1">// | default_database |
</span><span class="c1"></span><span class="c1">// +------------------+
</span><span class="c1"></span>
<span class="c1">// create a table
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE my_table (...) WITH (...)&#34;</span><span class="o">)</span>
<span class="c1">// show tables
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW TABLES&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +------------+
</span><span class="c1"></span><span class="c1">// | table name |
</span><span class="c1"></span><span class="c1">// +------------+
</span><span class="c1"></span><span class="c1">// |   my_table |
</span><span class="c1"></span><span class="c1">// +------------+
</span><span class="c1"></span>
<span class="c1">// create a view
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE VIEW my_view AS ...&#34;</span><span class="o">)</span>
<span class="c1">// show views
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW VIEWS&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +-----------+
</span><span class="c1"></span><span class="c1">// | view name |
</span><span class="c1"></span><span class="c1">// +-----------+
</span><span class="c1"></span><span class="c1">// |   my_view |
</span><span class="c1"></span><span class="c1">// +-----------+
</span><span class="c1"></span>
<span class="c1">// show functions
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW FUNCTIONS&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// | function name |
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// |           mod |
</span><span class="c1"></span><span class="c1">// |        sha256 |
</span><span class="c1"></span><span class="c1">// |           ... |
</span><span class="c1"></span><span class="c1">// +---------------+
</span></code></pre></div><h2 id="show-catalogs">SHOW CATALOGS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">CATALOGS</span>
</code></pre></div><p>显示所有目录。</p>
<h2 id="show-databases">SHOW DATABASES</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">DATABASES</span>
</code></pre></div><p>显示当前目录中的所有数据库。</p>
<h2 id="show-tables">SHOW TABLES</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">TABLES</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有表。</p>
<h2 id="show-views">SHOW VIEWS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">VIEWS</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有视图。</p>
<h2 id="show-functions">SHOW FUNCTIONS</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SHOW</span> <span class="n">FUNCTIONS</span>
</code></pre></div><p>显示当前目录和当前数据库中的所有功能，包括临时系统功能、系统功能、临时目录功能和目录功能。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-overview/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Overview</blockquote><h1 id="sql">SQL</h1>
<p>本页介绍了 Flink 支持的 SQL 语言，包括数据定义语言（DDL）、数据操作语言（DML）和查询语言。Flink 的 SQL 支持是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。</p>
<p>本页列出了目前 Flink SQL 支持的所有语句。</p>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html">SELECT (Queries)</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html">CREATE TABLE, DATABASE, VIEW, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/drop.html">DROP TABLE, DATABASE, VIEW, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/alter.html">ALTER TABLE, DATABASE, FUNCTION</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/insert.html">INSERT</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html">SQL HINTS</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html">DESCRIBE</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/explain.html">EXPLAIN</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html">USE</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/show.html">SHOW</a></li>
</ul>
<h2 id="数据类型">数据类型</h2>
<p>请看关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的专门页面。</p>
<p>通用类型和(嵌套的)复合类型(例如 POJOs、tuple、行、Scala case 类)也可以是行的字段。</p>
<p>具有任意嵌套的复合类型的字段可以用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html#value-access-functions">值访问函数</a>来访问。</p>
<p>通用类型被当作一个黑盒子，可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>进行传递或处理。</p>
<p>对于 DDL，我们支持页面数据类型中定义的完整<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>。</p>
<p>注意事项: 有些数据类型在 SQL 查询中还不支持（即在投递表达式或字元中）。例如：STRING, BYTES, RAW, WITHOUT TIME ZONE 的 TIME(p), WITH LOCAL TIME ZONE 的 TIME(p), WITHOUT TIME ZONE 的 TIMESTAMP(p), WITH LOCAL TIME ZONE 的 TIMESTAMP(p), ARRAY, MULTISET, ROW。</p>
<h2 id="保留关键词">保留关键词</h2>
<p>虽然并不是每一个 SQL 功能都已实现，但有些字符串组合已经被保留为关键字，供将来使用。如果你想使用下面的一个字符串作为字段名，请确保在它们周围加上反引号（例如<code>value</code>，<code>count</code>）。</p>
<pre><code>A, ABS, ABSOLUTE, ACTION, ADA, ADD, ADMIN, AFTER, ALL, ALLOCATE, ALLOW, ALTER, ALWAYS, AND, ANY, ARE, ARRAY, AS, ASC, ASENSITIVE, ASSERTION, ASSIGNMENT, ASYMMETRIC, AT, ATOMIC, ATTRIBUTE, ATTRIBUTES, AUTHORIZATION, AVG, BEFORE, BEGIN, BERNOULLI, BETWEEN, BIGINT, BINARY, BIT, BLOB, BOOLEAN, BOTH, BREADTH, BY, BYTES, C, CALL, CALLED, CARDINALITY, CASCADE, CASCADED, CASE, CAST, CATALOG, CATALOG_NAME, CEIL, CEILING, CENTURY, CHAIN, CHAR, CHARACTER, CHARACTERISTICS, CHARACTERS, CHARACTER_LENGTH, CHARACTER_SET_CATALOG, CHARACTER_SET_NAME, CHARACTER_SET_SCHEMA, CHAR_LENGTH, CHECK, CLASS_ORIGIN, CLOB, CLOSE, COALESCE, COBOL, COLLATE, COLLATION, COLLATION_CATALOG, COLLATION_NAME, COLLATION_SCHEMA, COLLECT, COLUMN, COLUMN_NAME, COMMAND_FUNCTION, COMMAND_FUNCTION_CODE, COMMIT, COMMITTED, CONDITION, CONDITION_NUMBER, CONNECT, CONNECTION, CONNECTION_NAME, CONSTRAINT, CONSTRAINTS, CONSTRAINT_CATALOG, CONSTRAINT_NAME, CONSTRAINT_SCHEMA, CONSTRUCTOR, CONTAINS, CONTINUE, CONVERT, CORR, CORRESPONDING, COUNT, COVAR_POP, COVAR_SAMP, CREATE, CROSS, CUBE, CUME_DIST, CURRENT, CURRENT_CATALOG, CURRENT_DATE, CURRENT_DEFAULT_TRANSFORM_GROUP, CURRENT_PATH, CURRENT_ROLE, CURRENT_SCHEMA, CURRENT_TIME, CURRENT_TIMESTAMP, CURRENT_TRANSFORM_GROUP_FOR_TYPE, CURRENT_USER, CURSOR, CURSOR_NAME, CYCLE, DATA, DATABASE, DATE, DATETIME_INTERVAL_CODE, DATETIME_INTERVAL_PRECISION, DAY, DEALLOCATE, DEC, DECADE, DECIMAL, DECLARE, DEFAULT, DEFAULTS, DEFERRABLE, DEFERRED, DEFINED, DEFINER, DEGREE, DELETE, DENSE_RANK, DEPTH, DEREF, DERIVED, DESC, DESCRIBE, DESCRIPTION, DESCRIPTOR, DETERMINISTIC, DIAGNOSTICS, DISALLOW, DISCONNECT, DISPATCH, DISTINCT, DOMAIN, DOUBLE, DOW, DOY, DROP, DYNAMIC, DYNAMIC_FUNCTION, DYNAMIC_FUNCTION_CODE, EACH, ELEMENT, ELSE, END, END-EXEC, EPOCH, EQUALS, ESCAPE, EVERY, EXCEPT, EXCEPTION, EXCLUDE, EXCLUDING, EXEC, EXECUTE, EXISTS, EXP, EXPLAIN, EXTEND, EXTERNAL, EXTRACT, FALSE, FETCH, FILTER, FINAL, FIRST, FIRST_VALUE, FLOAT, FLOOR, FOLLOWING, FOR, FOREIGN, FORTRAN, FOUND, FRAC_SECOND, FREE, FROM, FULL, FUNCTION, FUSION, G, GENERAL, GENERATED, GET, GLOBAL, GO, GOTO, GRANT, GRANTED, GROUP, GROUPING, HAVING, HIERARCHY, HOLD, HOUR, IDENTITY, IMMEDIATE, IMPLEMENTATION, IMPORT, IN, INCLUDING, INCREMENT, INDICATOR, INITIALLY, INNER, INOUT, INPUT, INSENSITIVE, INSERT, INSTANCE, INSTANTIABLE, INT, INTEGER, INTERSECT, INTERSECTION, INTERVAL, INTO, INVOKER, IS, ISOLATION, JAVA, JOIN, K, KEY, KEY_MEMBER, KEY_TYPE, LABEL, LANGUAGE, LARGE, LAST, LAST_VALUE, LATERAL, LEADING, LEFT, LENGTH, LEVEL, LIBRARY, LIKE, LIMIT, LN, LOCAL, LOCALTIME, LOCALTIMESTAMP, LOCATOR, LOWER, M, MAP, MATCH, MATCHED, MAX, MAXVALUE, MEMBER, MERGE, MESSAGE_LENGTH, MESSAGE_OCTET_LENGTH, MESSAGE_TEXT, METHOD, MICROSECOND, MILLENNIUM, MIN, MINUTE, MINVALUE, MOD, MODIFIES, MODULE, MONTH, MORE, MULTISET, MUMPS, NAME, NAMES, NATIONAL, NATURAL, NCHAR, NCLOB, NESTING, NEW, NEXT, NO, NONE, NORMALIZE, NORMALIZED, NOT, NULL, NULLABLE, NULLIF, NULLS, NUMBER, NUMERIC, OBJECT, OCTETS, OCTET_LENGTH, OF, OFFSET, OLD, ON, ONLY, OPEN, OPTION, OPTIONS, OR, ORDER, ORDERING, ORDINALITY, OTHERS, OUT, OUTER, OUTPUT, OVER, OVERLAPS, OVERLAY, OVERRIDING, PAD, PARAMETER, PARAMETER_MODE, PARAMETER_NAME, PARAMETER_ORDINAL_POSITION, PARAMETER_SPECIFIC_CATALOG, PARAMETER_SPECIFIC_NAME, PARAMETER_SPECIFIC_SCHEMA, PARTIAL, PARTITION, PASCAL, PASSTHROUGH, PATH, PERCENTILE_CONT, PERCENTILE_DISC, PERCENT_RANK, PLACING, PLAN, PLI, POSITION, POWER, PRECEDING, PRECISION, PREPARE, PRESERVE, PRIMARY, PRIOR, PRIVILEGES, PROCEDURE, PUBLIC, QUARTER, RANGE, RANK, RAW, READ, READS, REAL, RECURSIVE, REF, REFERENCES, REFERENCING, REGR_AVGX, REGR_AVGY, REGR_COUNT, REGR_INTERCEPT, REGR_R2, REGR_SLOPE, REGR_SXX, REGR_SXY, REGR_SYY, RELATIVE, RELEASE, REPEATABLE, RESET, RESTART, RESTRICT, RESULT, RETURN, RETURNED_CARDINALITY, RETURNED_LENGTH, RETURNED_OCTET_LENGTH, RETURNED_SQLSTATE, RETURNS, REVOKE, RIGHT, ROLE, ROLLBACK, ROLLUP, ROUTINE, ROUTINE_CATALOG, ROUTINE_NAME, ROUTINE_SCHEMA, ROW, ROWS, ROW_COUNT, ROW_NUMBER, SAVEPOINT, SCALE, SCHEMA, SCHEMA_NAME, SCOPE, SCOPE_CATALOGS, SCOPE_NAME, SCOPE_SCHEMA, SCROLL, SEARCH, SECOND, SECTION, SECURITY, SELECT, SELF, SENSITIVE, SEQUENCE, SERIALIZABLE, SERVER, SERVER_NAME, SESSION, SESSION_USER, SET, SETS, SIMILAR, SIMPLE, SIZE, SMALLINT, SOME, SOURCE, SPACE, SPECIFIC, SPECIFICTYPE, SPECIFIC_NAME, SQL, SQLEXCEPTION, SQLSTATE, SQLWARNING, SQL_TSI_DAY, SQL_TSI_FRAC_SECOND, SQL_TSI_HOUR, SQL_TSI_MICROSECOND, SQL_TSI_MINUTE, SQL_TSI_MONTH, SQL_TSI_QUARTER, SQL_TSI_SECOND, SQL_TSI_WEEK, SQL_TSI_YEAR, SQRT, START, STATE, STATEMENT, STATIC, STDDEV_POP, STDDEV_SAMP, STREAM, STRING, STRUCTURE, STYLE, SUBCLASS_ORIGIN, SUBMULTISET, SUBSTITUTE, SUBSTRING, SUM, SYMMETRIC, SYSTEM, SYSTEM_USER, TABLE, TABLESAMPLE, TABLE_NAME, TEMPORARY, THEN, TIES, TIME, TIMESTAMP, TIMESTAMPADD, TIMESTAMPDIFF, TIMEZONE_HOUR, TIMEZONE_MINUTE, TINYINT, TO, TOP_LEVEL_COUNT, TRAILING, TRANSACTION, TRANSACTIONS_ACTIVE, TRANSACTIONS_COMMITTED, TRANSACTIONS_ROLLED_BACK, TRANSFORM, TRANSFORMS, TRANSLATE, TRANSLATION, TREAT, TRIGGER, TRIGGER_CATALOG, TRIGGER_NAME, TRIGGER_SCHEMA, TRIM, TRUE, TYPE, UESCAPE, UNBOUNDED, UNCOMMITTED, UNDER, UNION, UNIQUE, UNKNOWN, UNNAMED, UNNEST, UPDATE, UPPER, UPSERT, USAGE, USER, USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_CODE, USER_DEFINED_TYPE_NAME, USER_DEFINED_TYPE_SCHEMA, USING, VALUE, VALUES, VARBINARY, VARCHAR, VARYING, VAR_POP, VAR_SAMP, VERSION, VIEW, WEEK, WHEN, WHENEVER, WHERE, WIDTH_BUCKET, WINDOW, WITH, WITHIN, WITHOUT, WORK, WRAPPER, WRITE, XML, YEAR, ZONE
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL 客户端]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-client/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-client/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Client</blockquote><h2 id="sql-client">SQL Client</h2>
<p>Flink 的 Table &amp; SQL API 使得它可以使用 SQL 语言编写的查询，但是这些查询需要嵌入到一个用 Java 或 Scala 编写的表程序中。而且，这些程序在提交给集群之前需要用构建工具打包。这或多或少限制了 Flink 对 Java/Scala 程序员的使用。</p>
<p>SQL Client 旨在提供一种简单的方式来编写、调试和提交表程序到 Flink 集群，而不需要任何一行 Java 或 Scala 代码。SQL Client CLI 允许在命令行上从运行的分布式应用中检索和可视化实时结果。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/sql_client_demo.gif" alt="img"></p>
<h2 id="入门">入门</h2>
<p>本节介绍如何从命令行设置和运行第一个 Flink SQL 程序。</p>
<p>SQL Client 被捆绑在常规的 Flink 发行版中，因此可以开箱即运行。它只需要一个正在运行的 Flink 集群，在那里可以执行表程序。关于设置 Flink 集群的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html">集群和部署</a>部分。如果你只是想试用 SQL Client，也可以使用下面的命令用一个 worker 启动一个本地集群。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/start-cluster.sh
</code></pre></div><h3 id="启动-sql-客户端-cli">启动 SQL 客户端 CLI</h3>
<p>SQL Client 脚本也位于 Flink 的二进制目录中。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#limitations--future">在未来</a>，用户将有两种启动 SQL Client CLI 的可能性，一是通过启动一个嵌入式的独立进程，二是通过连接到一个远程 SQL Client 网关。目前只支持嵌入式模式。你可以通过调用来启动 CLI。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">./bin/sql-client.sh embedded
</code></pre></div><p>默认情况下，SQL 客户端将从位于 <code>./conf/sql-client-defaults.yaml</code> 的环境文件中读取其配置。有关环境文件结构的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#environment-files">配置部分</a>。</p>
<h3 id="运行-sql-查询">运行 SQL 查询</h3>
<p>一旦启动 CLI，您可以使用 HELP 命令列出所有可用的 SQL 语句。为了验证你的设置和集群连接，你可以输入第一个 SQL 查询，然后按回车键执行。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="s1">&#39;</span><span class="s1">Hello World</span><span class="s1">&#39;</span><span class="p">;</span>
</code></pre></div><p>这个查询不需要表源(table source)，并产生一个单行结果。CLI 将从集群中检索结果，并将其可视化。您可以按Q键关闭结果视图。</p>
<p>CLI 支持三种模式来维护和可视化结果。</p>
<p>table 模式将结果在内存中具体化，并以常规的、分页的表格表示方式将其可视化。可以通过在 CLI 中执行以下命令启用该模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>table<span class="p">;</span>
</code></pre></div><p><strong>changelog</strong> 模式不将结果具体化，而是将由插入(+)和收回(-)组成的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html#continuous-queries">连续查询</a>所产生的结果流可视化。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>changelog<span class="p">;</span>
</code></pre></div><p><strong>tableau</strong> 模式更像是传统的方式，将结果以 tableau 的形式直接显示在屏幕上。显示内容会受到查询执行类型(execute.type)的影响。</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">SET execution.result-mode<span class="o">=</span>tableau<span class="p">;</span>
</code></pre></div><p>请注意，当您使用此模式进行流式查询时，结果将在控制台中连续打印。如果这个查询的输入数据是有边界的，那么在Flink处理完所有输入数据后，作业就会终止，打印也会自动停止。否则，如果你想终止一个正在运行的查询，在这种情况下只要输入CTRL-C键，作业和打印就会停止。</p>
<p>你可以使用下面的查询来查看所有的结果模式。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">name</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cnt</span> <span class="k">FROM</span> <span class="p">(</span><span class="k">VALUES</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">Bob</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">Alice</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">Greg</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;</span><span class="s1">Bob</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">)</span> <span class="k">AS</span> <span class="n">NameTable</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">name</span><span class="p">;</span>
</code></pre></div><p>这个查询执行一个有界字数的例子。</p>
<p>在 changelog 模式下，可视化的 changelog 应该类似于。</p>
<pre><code>+ Bob, 1
+ Alice, 1
+ Greg, 1
- Bob, 1
+ Bob, 2
</code></pre><p>在 table 模式下，可视化的结果表会持续更新，直到表程序结束。</p>
<pre><code>Bob, 2
Alice, 1
Greg, 1
</code></pre><p>在tableau模式下，如果你在流模式下运行查询，显示的结果将是。</p>
<pre><code>+-----+----------------------+----------------------+
| +/- |                 name |                  cnt |
+-----+----------------------+----------------------+
|   + |                  Bob |                    1 |
|   + |                Alice |                    1 |
|   + |                 Greg |                    1 |
|   - |                  Bob |                    1 |
|   + |                  Bob |                    2 |
+-----+----------------------+----------------------+
Received a total of 5 rows
</code></pre><p>而如果你在批处理模式下运行查询，显示的结果将是。</p>
<pre><code>+-------+-----+
|  name | cnt |
+-------+-----+
| Alice |   1 |
|   Bob |   2 |
|  Greg |   1 |
+-------+-----+
3 rows in set
</code></pre><p>在 SQL 查询的原型设计过程中，所有这些结果模式都是有用的。在所有这些模式中，结果都存储在 SQL 客户端的 Java 堆内存中。为了保持CLI界面的响应性，changelog 模式只显示最新的1000个变化。表模式允许浏览更大的结果，这些结果仅受可用主内存和配置的最大行数（<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#configuration">max-table-result-rows</a>）的限制。</p>
<p>注意：在批处理环境中执行的查询，只能使用table或tableau结果模式进行检索。</p>
<p>在定义了一个查询后，可以将其作为一个长期运行的、分离的 Flink 作业提交给集群。为此，需要使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#detached-sql-queries">INSERT INTO 语句</a>指定存储结果的目标系统。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#configurations">配置部分</a>解释了如何声明 table source 以读取数据，如何声明 table sink 以写入数据，以及如何配置其他表程序属性。</p>
<h2 id="配置">配置</h2>
<p>SQL Client 可以通过以下可选的CLI命令来启动。这些命令将在后面的段落中详细讨论。</p>
<pre><code>./bin/sql-client.sh embedded --help

Mode &quot;embedded&quot; submits Flink jobs from the local machine.

  Syntax: embedded [OPTIONS]
  &quot;embedded&quot; mode options:
     -d,--defaults &lt;environment file&gt;      The environment properties with which
                                           every new session is initialized.
                                           Properties might be overwritten by
                                           session properties.
     -e,--environment &lt;environment file&gt;   The environment properties to be
                                           imported into the session. It might
                                           overwrite default environment
                                           properties.
     -h,--help                             Show the help message with
                                           descriptions of all options.
     -hist,--history &lt;History file path&gt;   The file which you want to save the
                                           command history into. If not
                                           specified, we will auto-generate one
                                           under your user's home directory.
     -j,--jar &lt;JAR file&gt;                   A JAR file to be imported into the
                                           session. The file might contain
                                           user-defined classes needed for the
                                           execution of statements such as
                                           functions, table sources, or sinks.
                                           Can be used multiple times.
     -l,--library &lt;JAR directory&gt;          A JAR file directory with which every
                                           new session is initialized. The files
                                           might contain user-defined classes
                                           needed for the execution of
                                           statements such as functions, table
                                           sources, or sinks. Can be used
                                           multiple times.
     -pyarch,--pyArchives &lt;arg&gt;            Add python archive files for job. The
                                           archive files will be extracted to
                                           the working directory of python UDF
                                           worker. Currently only zip-format is
                                           supported. For each archive file, a
                                           target directory be specified. If the
                                           target directory name is specified,
                                           the archive file will be extracted to
                                           a name can directory with the
                                           specified name. Otherwise, the
                                           archive file will be extracted to a
                                           directory with the same name of the
                                           archive file. The files uploaded via
                                           this option are accessible via
                                           relative path. '#' could be used as
                                           the separator of the archive file
                                           path and the target directory name.
                                           Comma (',') could be used as the
                                           separator to specify multiple archive
                                           files. This option can be used to
                                           upload the virtual environment, the
                                           data files used in Python UDF (e.g.:
                                           --pyArchives
                                           file:///tmp/py37.zip,file:///tmp/data
                                           .zip#data --pyExecutable
                                           py37.zip/py37/bin/python). The data
                                           files could be accessed in Python
                                           UDF, e.g.: f = open('data/data.txt',
                                           'r').
     -pyexec,--pyExecutable &lt;arg&gt;          Specify the path of the python
                                           interpreter used to execute the
                                           python UDF worker (e.g.:
                                           --pyExecutable
                                           /usr/local/bin/python3). The python
                                           UDF worker depends on Python 3.5+,
                                           Apache Beam (version == 2.19.0), Pip
                                           (version &gt;= 7.1.0) and SetupTools
                                           (version &gt;= 37.0.0). Please ensure
                                           that the specified environment meets
                                           the above requirements.
     -pyfs,--pyFiles &lt;pythonFiles&gt;         Attach custom python files for job.
                                           These files will be added to the
                                           PYTHONPATH of both the local client
                                           and the remote python UDF worker. The
                                           standard python resource file
                                           suffixes such as .py/.egg/.zip or
                                           directory are all supported. Comma
                                           (',') could be used as the separator
                                           to specify multiple files (e.g.:
                                           --pyFiles
                                           file:///tmp/myresource.zip,hdfs:///$n
                                           amenode_address/myresource2.zip).
     -pyreq,--pyRequirements &lt;arg&gt;         Specify a requirements.txt file which
                                           defines the third-party dependencies.
                                           These dependencies will be installed
                                           and added to the PYTHONPATH of the
                                           python UDF worker. A directory which
                                           contains the installation packages of
                                           these dependencies could be specified
                                           optionally. Use '#' as the separator
                                           if the optional parameter exists
                                           (e.g.: --pyRequirements
                                           file:///tmp/requirements.txt#file:///
                                           tmp/cached_dir).
     -s,--session &lt;session identifier&gt;     The identifier for a session.
                                           'default' is the default identifier.
     -u,--update &lt;SQL update statement&gt;    Experimental (for testing only!):
                                           Instructs the SQL Client to
                                           immediately execute the given update
                                           statement after starting up. The
                                           process is shut down after the
                                           statement has been submitted to the
                                           cluster and returns an appropriate
                                           return code. Currently, this feature
                                           is only supported for INSERT INTO
                                           statements that declare the target
                                           sink table.

</code></pre><h3 id="环境文件">环境文件</h3>
<p>一个SQL查询需要一个配置环境来执行。所谓的环境文件定义了可用的目录(catalogs)、table source 和 sink、用户定义的函数以及执行和部署所需的其他属性。</p>
<p>每个环境文件都是一个常规的 <a href="http://yaml.org/">YAML 文件</a>。下面是这样一个文件的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># Define tables here such as sources, sinks, views, or temporal tables.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">tables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyTableSource<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>source-table<span class="w">
</span><span class="w">    </span><span class="k">update-mode</span><span class="p">:</span><span class="w"> </span>append<span class="w">
</span><span class="w">    </span><span class="k">connector</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>filesystem<span class="w">
</span><span class="w">      </span><span class="k">path</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/path/to/something.csv&#34;</span><span class="w">
</span><span class="w">    </span><span class="k">format</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>csv<span class="w">
</span><span class="w">      </span><span class="k">fields</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">        </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyField1<span class="w">
</span><span class="w">          </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>INT<span class="w">
</span><span class="w">        </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyField2<span class="w">
</span><span class="w">          </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>VARCHAR<span class="w">
</span><span class="w">      </span><span class="k">line-delimiter</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;\n&#34;</span><span class="w">
</span><span class="w">      </span><span class="k">comment-prefix</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;#&#34;</span><span class="w">
</span><span class="w">    </span><span class="k">schema</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyField1<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>INT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyField2<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>VARCHAR<span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyCustomView<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>view<span class="w">
</span><span class="w">    </span><span class="k">query</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;SELECT MyField2 FROM MyTableSource&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Define user-defined functions here.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">functions</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>myUDF<span class="w">
</span><span class="w">    </span><span class="k">from</span><span class="p">:</span><span class="w"> </span>class<span class="w">
</span><span class="w">    </span><span class="k">class</span><span class="p">:</span><span class="w"> </span>foo.bar.AggregateUDF<span class="w">
</span><span class="w">    </span><span class="k">constructor</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span>- <span class="m">7.6</span><span class="w">
</span><span class="w">      </span>- <span class="kc">false</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Define available catalogs</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">   </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>catalog_1<span class="w">
</span><span class="w">     </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>hive<span class="w">
</span><span class="w">     </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="k">hive-conf-dir</span><span class="p">:</span><span class="w"> </span>...<span class="w">
</span><span class="w">   </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>catalog_2<span class="w">
</span><span class="w">     </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>hive<span class="w">
</span><span class="w">     </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="k">default-database</span><span class="p">:</span><span class="w"> </span>mydb2<span class="w">
</span><span class="w">     </span><span class="k">hive-conf-dir</span><span class="p">:</span><span class="w"> </span>...<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Properties that change the fundamental execution behavior of a table program.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">execution</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">planner: blink                    # optional</span><span class="p">:</span><span class="w"> </span>either<span class="w"> </span><span class="s1">&#39;blink&#39;</span><span class="w"> </span>(default)<span class="w"> </span>or<span class="w"> </span><span class="s1">&#39;old&#39;</span><span class="w">
</span><span class="w">  </span><span class="k">type: streaming                   # required</span><span class="p">:</span><span class="w"> </span>execution<span class="w"> </span>mode<span class="w"> </span>either<span class="w"> </span><span class="s1">&#39;batch&#39;</span><span class="w"> </span>or<span class="w"> </span><span class="s1">&#39;streaming&#39;</span><span class="w">
</span><span class="w">  </span><span class="k">result-mode: table                # required</span><span class="p">:</span><span class="w"> </span>either<span class="w"> </span><span class="s1">&#39;table&#39;</span><span class="w"> </span>or<span class="w"> </span><span class="s1">&#39;changelog&#39;</span><span class="w">
</span><span class="w">  </span><span class="k">max-table-result-rows: 1000000    # optional</span><span class="p">:</span><span class="w"> </span>maximum<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>maintained<span class="w"> </span>rows<span class="w"> </span>in<span class="w">
</span><span class="w">                                    </span><span class="c">#   &#39;table&#39; mode (1000000 by default, smaller 1 means unlimited)</span><span class="w">
</span><span class="w">  </span><span class="k">time-characteristic: event-time   # optional</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;processing-time&#39;</span><span class="w"> </span>or<span class="w"> </span><span class="s1">&#39;event-time&#39;</span><span class="w"> </span>(default)<span class="w">
</span><span class="w">  </span><span class="k">parallelism: 1                    # optional</span><span class="p">:</span><span class="w"> </span>Flink<span class="s1">&#39;s parallelism (1 by default)
</span><span class="s1">  periodic-watermarks-interval: 200 # optional: interval for periodic watermarks (200 ms by default)
</span><span class="s1">  max-parallelism: 16               # optional: Flink&#39;</span>s<span class="w"> </span>maximum<span class="w"> </span>parallelism<span class="w"> </span>(<span class="m">128</span><span class="w"> </span>by<span class="w"> </span>default)<span class="w">
</span><span class="w">  </span><span class="k">min-idle-state-retention: 0       # optional</span><span class="p">:</span><span class="w"> </span>table<span class="w"> </span>program<span class="s1">&#39;s minimum idle state time
</span><span class="s1">  max-idle-state-retention: 0       # optional: table program&#39;</span>s<span class="w"> </span>maximum<span class="w"> </span>idle<span class="w"> </span>state<span class="w"> </span>time<span class="w">
</span><span class="w">  </span><span class="k">current-catalog: catalog_1        # optional</span><span class="p">:</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>current<span class="w"> </span>catalog<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>session<span class="w"> </span>(<span class="s1">&#39;default_catalog&#39;</span><span class="w"> </span>by<span class="w"> </span>default)<span class="w">
</span><span class="w">  </span><span class="k">current-database: mydb1           # optional</span><span class="p">:</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>current<span class="w"> </span>database<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>current<span class="w"> </span>catalog<span class="w">
</span><span class="w">                                    </span><span class="c">#   (default database of the current catalog by default)</span><span class="w">
</span><span class="w">  </span><span class="k">restart-strategy:                 # optional</span><span class="p">:</span><span class="w"> </span>restart<span class="w"> </span>strategy<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>fallback<span class="w">                  </span><span class="c">#   &#34;fallback&#34; to global restart strategy by default</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Configuration options for adjusting and tuning table programs.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># A full list of options and their default values can be found</span><span class="w">
</span><span class="w"></span><span class="c"># on the dedicated &#34;Configuration&#34; page.</span><span class="w">
</span><span class="w"></span><span class="k">configuration</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">table.optimizer.join-reorder-enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">table.exec.spill-compression.enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">table.exec.spill-compression.block-size</span><span class="p">:</span><span class="w"> </span>128kb<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># Properties that describe the cluster to which table programs are submitted to.</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">deployment</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">response-timeout</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></code></pre></div><p>这份配置:</p>
<ul>
<li>定义了一个表源 <code>MyTableSource</code> 的环境，该表源从 CSV 文件中读取。</li>
<li>定义了一个视图 <code>MyCustomView</code>，该视图使用 SQL 查询声明了一个虚拟表。</li>
<li>定义了一个用户定义的函数 <code>myUDF</code>，可以使用类名和两个构造函数参数来实例化。</li>
<li>连接两个 Hive 目录，并使用 catalog_1 作为当前目录，mydb1 作为目录的当前数据库。</li>
<li>在流式模式下使用 blink planner，运行具有事件时间特性和并行度为1的语句。</li>
<li>在 table 结果模式下运行探索性查询。</li>
<li>并通过配置选项围绕连接重排序和溢出进行一些 planner 调整。</li>
</ul>
<p>根据使用情况，一个配置可以被分割成多个文件。因此，可以为一般目的创建环境文件（使用 <code>--defaults</code> 创建默认环境文件），也可以为每个会话创建环境文件（使用 <code>--environment</code> 创建会话环境文件）。每一个 CLI 会话都会用默认属性和会话属性来初始化。例如，<code>defaults</code> 环境文件可以指定在每个会话中应该可以查询的所有 table source，而 <code>session</code> 环境文件只声明特定的状态保留时间和并行度。在启动CLI应用程序时，可以同时传递默认环境文件和会话环境文件。如果没有指定默认环境文件，SQL Client 会在 Flink 的配置目录下搜索 <code>./conf/sql-client-defaults.yaml</code>。</p>
<p>注意：在 CLI 会话中设置的属性（例如使用SET命令）具有最高优先权。</p>
<pre><code>CLI commands &gt; session environment file &gt; defaults environment file
</code></pre><h3 id="重启策略">重启策略</h3>
<p>重启策略控制 Flink 作业在发生故障时如何重启。与 Flink 集群的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/restart_strategies.html">全局重启策略</a>类似，可以在环境文件中声明一个更精细的重启配置。</p>
<p>支持以下策略。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">execution</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="c"># falls back to the global strategy defined in flink-conf.yaml</span><span class="w">
</span><span class="w">  </span><span class="k">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>fallback<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># job fails directly and no restart is attempted</span><span class="w">
</span><span class="w">  </span><span class="k">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>none<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># attempts a given number of times to restart the job</span><span class="w">
</span><span class="w">  </span><span class="k">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>fixed-delay<span class="w">
</span><span class="w">    </span><span class="k">attempts: 3      # retries before job is declared as failed (default</span><span class="p">:</span><span class="w"> </span>Integer.MAX_VALUE)<span class="w">
</span><span class="w">    </span><span class="k">delay: 10000     # delay in ms between retries (default</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w"> </span>s)<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># attempts as long as the maximum number of failures per time interval is not exceeded</span><span class="w">
</span><span class="w">  </span><span class="k">restart-strategy</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>failure-rate<span class="w">
</span><span class="w">    </span><span class="k">max-failures-per-interval: 1   # retries in interval until failing (default</span><span class="p">:</span><span class="w"> </span><span class="m">1</span>)<span class="w">
</span><span class="w">    </span><span class="k">failure-rate-interval</span><span class="p">:</span><span class="w"> </span><span class="m">60000</span><span class="w">   </span><span class="c"># measuring interval in ms for failure rate</span><span class="w">
</span><span class="w">    </span><span class="k">delay: 10000                   # delay in ms between retries (default</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w"> </span>s)<span class="w">
</span></code></pre></div><h3 id="依赖性">依赖性</h3>
<p>SQL Client 不需要使用 Maven 或 SBT 设置一个 Java 项目。相反，你可以将依赖关系作为常规的 JAR 文件传递给集群。你可以单独指定每个 JAR 文件（使用 <code>--jar</code>）或定义整个库目录（使用 <code>--library</code>）。对于连接到外部系统（如 Apache Kafka）的连接器和相应的数据格式（如JSON），Flink 提供了现成的 JAR bundles。这些 JAR 文件可以从 Maven 中央仓库为每个版本下载。</p>
<p>所提供的 SQL JAR 的完整列表和关于如何使用它们的文档可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统页面</a>上找到。</p>
<p>下面的例子显示了一个环境文件，它定义了一个从 Apache Kafka 读取 JSON 数据的 table source。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">tables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>TaxiRides<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>source-table<span class="w">
</span><span class="w">    </span><span class="k">update-mode</span><span class="p">:</span><span class="w"> </span>append<span class="w">
</span><span class="w">    </span><span class="k">connector</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>kafka<span class="w">
</span><span class="w">      </span><span class="k">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;0.11&#34;</span><span class="w">
</span><span class="w">      </span><span class="k">topic</span><span class="p">:</span><span class="w"> </span>TaxiRides<span class="w">
</span><span class="w">      </span><span class="k">startup-mode</span><span class="p">:</span><span class="w"> </span>earliest-offset<span class="w">
</span><span class="w">      </span><span class="k">properties</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">        </span><span class="k">bootstrap.servers</span><span class="p">:</span><span class="w"> </span>localhost<span class="p">:</span><span class="m">9092</span><span class="w">
</span><span class="w">        </span><span class="k">group.id</span><span class="p">:</span><span class="w"> </span>testGroup<span class="w">
</span><span class="w">    </span><span class="k">format</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>json<span class="w">
</span><span class="w">      </span><span class="k">schema</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;ROW&lt;rideId LONG, lon FLOAT, lat FLOAT, rideTime TIMESTAMP&gt;&#34;</span><span class="w">
</span><span class="w">    </span><span class="k">schema</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>rideId<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>BIGINT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>lon<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>FLOAT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>lat<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>FLOAT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>rowTime<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>TIMESTAMP(<span class="m">3</span>)<span class="w">
</span><span class="w">        </span><span class="k">rowtime</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">          </span><span class="k">timestamps</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">            </span><span class="k">type</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;from-field&#34;</span><span class="w">
</span><span class="w">            </span><span class="k">from</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;rideTime&#34;</span><span class="w">
</span><span class="w">          </span><span class="k">watermarks</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">            </span><span class="k">type</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;periodic-bounded&#34;</span><span class="w">
</span><span class="w">            </span><span class="k">delay</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;60000&#34;</span><span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>procTime<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>TIMESTAMP(<span class="m">3</span>)<span class="w">
</span><span class="w">        </span><span class="k">proctime</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></code></pre></div><p>由此产生的 <code>TaxiRide</code> 表的模式(schema)包含了 JSON 模式(schema)的大部分字段。此外，它还增加了一个行时间属性 <code>rowTime</code> 和处理时间属性 <code>procTime</code>。</p>
<p><code>connector</code> 和 <code>format</code> 都允许定义一个属性版本（目前是版本1），以便于将来向后兼容。</p>
<h3 id="用户定义的函数">用户定义的函数</h3>
<p>SQL Client 允许用户创建自定义的、用户定义的函数，以便在 SQL 查询中使用。目前，这些函数被限制在 Java/Scala 类或 Python  文件中以编程方式定义。</p>
<p>为了提供一个 Java/Scala 用户定义的函数，你需要首先实现和编译一个扩展 ScalarFunction、AggregateFunction 或 TableFunction 的函数类（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>）。然后可以将一个或多个函数打包到 SQL Client 的依赖 JAR 中。</p>
<p>为了提供一个 Python 用户定义函数，你需要编写一个 Python 函数，并用 <code>pyflink.table.udf.udf</code> 或 <code>pyflink.table.udf.udtf</code> 装饰器来装饰它(见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/udfs/python_udfs.html">Python UDFs</a>)。然后可以将一个或多个函数放入一个 Python 文件中。Python 文件和相关的依赖关系需要通过环境文件中的配置 (参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/python/user-guide/table/python_config.html">Python 配置</a>) 或命令行选项 (参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/cli.html#usage">命令行用法</a>) 来指定。</p>
<p>所有函数在被调用之前必须在环境文件中声明。对于函数列表中的每一项，必须指定</p>
<ul>
<li>注册该函数的名称。</li>
<li>函数的源，使用 <code>from</code> (暂时限制为 class (Java/Scala UDF) 或 python (Python UDF))。</li>
</ul>
<p>Java/Scala UDF 必须指定:</p>
<ul>
<li><code>class</code>，表示函数的完全限定类名和一个可选的实例化构造参数列表。</li>
</ul>
<p>Python 的 UDF 必须指定:</p>
<ul>
<li><code>fully-qualified-name</code>: 表示完全限定的名称，即函数的&rdquo;[模块名].[对象名]&quot;。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">functions</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name: java_udf               # required</span><span class="p">:</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w">
</span><span class="w">    </span><span class="k">from: class                  # required</span><span class="p">:</span><span class="w"> </span>source<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w">
</span><span class="w">    </span><span class="k">class: ...                   # required</span><span class="p">:</span><span class="w"> </span>fully<span class="w"> </span>qualified<span class="w"> </span>class<span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w">
</span><span class="w">    </span><span class="k">constructor:                 # optional</span><span class="p">:</span><span class="w"> </span>constructor<span class="w"> </span>parameters<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w"> </span>class<span class="w">
</span><span class="w">      </span>- <span class="k">...                      # optional</span><span class="p">:</span><span class="w"> </span>a<span class="w"> </span>literal<span class="w"> </span>parameter<span class="w"> </span>with<span class="w"> </span>implicit<span class="w"> </span>type<span class="w">
</span><span class="w">      </span>- <span class="k">class: ...               # optional</span><span class="p">:</span><span class="w"> </span>full<span class="w"> </span>class<span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>parameter<span class="w">
</span><span class="w">        </span><span class="k">constructor:             # optional</span><span class="p">:</span><span class="w"> </span>constructor<span class="w"> </span>parameters<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>parameter&#39;s<span class="w"> </span>class<span class="w">
</span><span class="w">          </span>- <span class="k">type: ...            # optional</span><span class="p">:</span><span class="w"> </span>type<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>literal<span class="w"> </span>parameter<span class="w">
</span><span class="w">            </span><span class="k">value: ...           # optional</span><span class="p">:</span><span class="w"> </span>value<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>literal<span class="w"> </span>parameter<span class="w">
</span><span class="w">  </span>- <span class="k">name: python_udf             # required</span><span class="p">:</span><span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w">
</span><span class="w">    </span><span class="k">from: python                 # required</span><span class="p">:</span><span class="w"> </span>source<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w"> 
</span><span class="w">    </span><span class="k">fully-qualified-name: ...    # required</span><span class="p">:</span><span class="w"> </span>fully<span class="w"> </span>qualified<span class="w"> </span>class<span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>function<span class="w">      
</span></code></pre></div><p>对于 Java/Scala UDF，请确保指定参数的顺序和类型严格匹配你的函数类的一个构造函数。</p>
<h3 id="构造函数参数">构造函数参数</h3>
<p>根据用户定义的函数，在 SQL 语句中使用它之前，可能需要对实现进行参数化。</p>
<p>如前面的例子所示，在声明用户定义函数时，可以通过以下三种方式之一使用构造函数参数来配置类。</p>
<p>一个隐含类型的字面值。SQL Client 会根据字面值本身自动推导出类型。目前，这里只支持 BOOLEAN、INT、DOUBLE 和 VARCHAR 的值。如果自动推导没有达到预期的效果（例如，你需要一个 VARCHAR false），请使用显式类型代替。</p>
<pre><code>- true         # -&gt; BOOLEAN (case sensitive)
- 42           # -&gt; INT
- 1234.222     # -&gt; DOUBLE
- foo          # -&gt; VARCHAR
</code></pre><p>一个具有明确类型的字面值。明确声明参数的 <code>type</code> 和 <code>value</code> 属性，以保证类型安全。</p>
<pre><code>- type: DECIMAL
  value: 11111111111111111
</code></pre><p>下表说明了支持的 Java 参数类型和相应的 SQL 类型字符串。</p>
<table>
<thead>
<tr>
<th align="left">Java type</th>
<th align="left">SQL type</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">java.math.BigDecimal</td>
<td align="left">DECIMAL</td>
</tr>
<tr>
<td align="left">java.lang.Boolean</td>
<td align="left">BOOLEAN</td>
</tr>
<tr>
<td align="left">java.lang.Byte</td>
<td align="left">TINYINT</td>
</tr>
<tr>
<td align="left">java.lang.Double</td>
<td align="left">DOUBLE</td>
</tr>
<tr>
<td align="left">java.lang.Float</td>
<td align="left">REAL, FLOAT</td>
</tr>
<tr>
<td align="left">java.lang.Integer</td>
<td align="left">INTEGER, INT</td>
</tr>
<tr>
<td align="left">java.lang.Long</td>
<td align="left">BIGINT</td>
</tr>
<tr>
<td align="left">java.lang.Short</td>
<td align="left">SMALLINT</td>
</tr>
<tr>
<td align="left">java.lang.String</td>
<td align="left">VARCHAR</td>
</tr>
</tbody>
</table>
<p>目前还不支持更多的类型（如 TIMESTAMP 或 ARRAY）、原语类型和 null。</p>
<p>一个（嵌套的）类实例。除了字面值，你还可以通过指定 <code>class</code> 和 <code>constructor</code> 函数属性，为构造函数参数创建（嵌套）类实例。这个过程可以递归执行，直到所有的构造参数都用字面值表示。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">- <span class="k">class</span><span class="p">:</span><span class="w"> </span>foo.bar.paramClass<span class="w">
</span><span class="w">  </span><span class="k">constructor</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span>- StarryName<span class="w">
</span><span class="w">    </span>- <span class="k">class</span><span class="p">:</span><span class="w"> </span>java.lang.Integer<span class="w">
</span><span class="w">      </span><span class="k">constructor</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">        </span>- <span class="k">class</span><span class="p">:</span><span class="w"> </span>java.lang.String<span class="w">
</span><span class="w">          </span><span class="k">constructor</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">            </span>- <span class="k">type</span><span class="p">:</span><span class="w"> </span>VARCHAR<span class="w">
</span><span class="w">              </span><span class="k">value</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div><h3 id="catalogs">Catalogs</h3>
<p>Catalogs 可以定义为一组 YAML 属性，在启动 SQL Client 时自动注册到环境中。</p>
<p>用户可以在 SQL CLI 中指定要使用哪个目录(catalog)作为当前目录(catalog)，以及要使用该目录(catalog)的哪个数据库作为当前数据库。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">catalogs</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">   </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>catalog_1<span class="w">
</span><span class="w">     </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>hive<span class="w">
</span><span class="w">     </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="k">default-database</span><span class="p">:</span><span class="w"> </span>mydb2<span class="w">
</span><span class="w">     </span><span class="k">hive-conf-dir</span><span class="p">:</span><span class="w"> </span>&lt;path<span class="w"> </span>of<span class="w"> </span>Hive<span class="w"> </span>conf<span class="w"> </span>directory<span class="sd">&gt;
</span><span class="sd">  </span><span class="sd"> </span><span class="sd">- name: catalog_2</span><span class="w">
</span><span class="w">     </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>hive<span class="w">
</span><span class="w">     </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">     </span><span class="k">hive-conf-dir</span><span class="p">:</span><span class="w"> </span>&lt;path<span class="w"> </span>of<span class="w"> </span>Hive<span class="w"> </span>conf<span class="w"> </span>directory<span class="sd">&gt;
</span><span class="sd"></span><span class="sd">
</span><span class="sd"></span><span class="sd">execution:</span><span class="w">
</span><span class="w">   </span>...<span class="w">
</span><span class="w">   </span><span class="k">current-catalog</span><span class="p">:</span><span class="w"> </span>catalog_1<span class="w">
</span><span class="w">   </span><span class="k">current-database</span><span class="p">:</span><span class="w"> </span>mydb1<span class="w">
</span></code></pre></div><p>关于目录的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>。</p>
<h2 id="分离式-sql-查询">分离式 SQL 查询</h2>
<p>为了定义端到端 SQL 管道，SQL 的 INSERT INTO 语句可以用于向 Flink 集群提交长期运行的、分离的查询。这些查询将其结果产生到外部系统中，而不是 SQL Client。这允许处理更高的并行性和更大的数据量。CLI 本身对提交后的分离查询没有任何控制。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">MyTableSink</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">MyTableSource</span>
</code></pre></div><p>表接收器 <code>MyTableSink</code> 必须在环境文件中声明。有关支持的外部系统及其配置的更多信息，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接页面</a>。下面是一个 Apache Kafka 表接收器的例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">tables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyTableSink<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>sink-table<span class="w">
</span><span class="w">    </span><span class="k">update-mode</span><span class="p">:</span><span class="w"> </span>append<span class="w">
</span><span class="w">    </span><span class="k">connector</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>kafka<span class="w">
</span><span class="w">      </span><span class="k">version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;0.11&#34;</span><span class="w">
</span><span class="w">      </span><span class="k">topic</span><span class="p">:</span><span class="w"> </span>OutputTopic<span class="w">
</span><span class="w">      </span><span class="k">properties</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">        </span><span class="k">bootstrap.servers</span><span class="p">:</span><span class="w"> </span>localhost<span class="p">:</span><span class="m">9092</span><span class="w">
</span><span class="w">        </span><span class="k">group.id</span><span class="p">:</span><span class="w"> </span>testGroup<span class="w">
</span><span class="w">    </span><span class="k">format</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span><span class="k">property-version</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>json<span class="w">
</span><span class="w">      </span><span class="k">derive-schema</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="k">schema</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>rideId<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>BIGINT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>lon<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>FLOAT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>lat<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>FLOAT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>rideTime<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>TIMESTAMP(<span class="m">3</span>)<span class="w">
</span></code></pre></div><p>SQL 客户端确保语句成功提交到集群。一旦提交查询，CLI 将显示有关 Flink 作业的信息。</p>
<pre><code>[INFO] Table update statement has been successfully submitted to the cluster:
Cluster ID: StandaloneClusterId
Job ID: 6f922fe5cba87406ff23ae4a7bb79044
Web interface: http://localhost:8081
</code></pre><p>注意: SQL 客户端在提交后不会跟踪正在运行的 Flink 作业的状态。CLI 进程可以在提交后被关闭，而不影响分离查询。Flink 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/restart_strategies.html">重启策略</a>照顾到了容错。可以使用 Flink 的 Web 界面、命令行或 REST API 来取消查询。</p>
<h2 id="sql-视图">SQL 视图</h2>
<p>视图允许从 SQL 查询中定义虚拟表。视图定义会被立即解析和验证。然而，实际的执行发生在提交一般的 INSERT INTO 或 SELECT 语句期间访问视图时。</p>
<p>视图可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html#environment-files">环境文件</a>中定义，也可以在 CLI 会话中定义。</p>
<p>下面的例子显示了如何在一个文件中定义多个视图。视图是按照它们在环境文件中定义的顺序注册的。支持诸如视图 A 依赖于视图 B 依赖于视图 C 的引用链。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">tables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyTableSource<span class="w">
</span><span class="w">    </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyRestrictedView<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>view<span class="w">
</span><span class="w">    </span><span class="k">query</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;SELECT MyField2 FROM MyTableSource&#34;</span><span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>MyComplexView<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>view<span class="w">
</span><span class="w">    </span><span class="k">query</span><span class="p">:</span><span class="w"> </span><span class="sd">&gt;
</span><span class="sd">     </span><span class="sd"> </span><span class="sd">SELECT MyField2 + 42, CAST(MyField1 AS VARCHAR)</span><span class="w">
</span><span class="w">      </span>FROM<span class="w"> </span>MyTableSource<span class="w">
</span><span class="w">      </span>WHERE<span class="w"> </span>MyField2<span class="w"> </span>&gt;<span class="w"> </span><span class="m">200</span><span class="w">
</span></code></pre></div><p>与 table source 和 sink 类似，会话环境文件中定义的视图具有最高优先级。</p>
<p>视图也可以在 CLI 会话中使用 <code>CREATE VIEW</code> 语句创建。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="n">MyNewView</span> <span class="k">AS</span> <span class="k">SELECT</span> <span class="n">MyField2</span> <span class="k">FROM</span> <span class="n">MyTableSource</span><span class="p">;</span>
</code></pre></div><p>在 CLI 会话中创建的视图也可以使用 <code>DROP VIEW</code> 语句再次删除。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DROP</span> <span class="k">VIEW</span> <span class="n">MyNewView</span><span class="p">;</span>
</code></pre></div><p>注意: CLI 中视图的定义仅限于上述语法。在未来的版本中，将支持为视图定义模式或在表名中转义空格。</p>
<h2 id="临时表">临时表</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>允许对变化的历史表进行（参数化的）查看，该表在特定的时间点返回一个表的内容。这对于将一个表与另一个表在特定时间戳的内容连接起来特别有用。更多信息可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#join-with-a-temporal-table">临时表连接</a>页面中找到。</p>
<p>下面的示例展示了如何定义一个临时表 <code>SourceTemporalTable</code>。</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">tables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">
</span><span class="w">  </span><span class="c"># Define the table source (or view) that contains updates to a temporal table</span><span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>HistorySource<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>source-table<span class="w">
</span><span class="w">    </span><span class="k">update-mode</span><span class="p">:</span><span class="w"> </span>append<span class="w">
</span><span class="w">    </span><span class="k">connector</span><span class="p">:</span><span class="w"> </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="k">format</span><span class="p">:</span><span class="w"> </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="k">schema</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>integerField<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>INT<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>stringField<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>STRING<span class="w">
</span><span class="w">      </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>rowtimeField<span class="w">
</span><span class="w">        </span><span class="k">data-type</span><span class="p">:</span><span class="w"> </span>TIMESTAMP(<span class="m">3</span>)<span class="w">
</span><span class="w">        </span><span class="k">rowtime</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">          </span><span class="k">timestamps</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">            </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>from-field<span class="w">
</span><span class="w">            </span><span class="k">from</span><span class="p">:</span><span class="w"> </span>rowtimeField<span class="w">
</span><span class="w">          </span><span class="k">watermarks</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">            </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>from-source<span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># Define a temporal table over the changing history table with time attribute and primary key</span><span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>SourceTemporalTable<span class="w">
</span><span class="w">    </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>temporal-table<span class="w">
</span><span class="w">    </span><span class="k">history-table</span><span class="p">:</span><span class="w"> </span>HistorySource<span class="w">
</span><span class="w">    </span><span class="k">primary-key</span><span class="p">:</span><span class="w"> </span>integerField<span class="w">
</span><span class="w">    </span><span class="k">time-attribute</span><span class="p">:</span><span class="w"> </span>rowtimeField<span class="w">  </span><span class="c"># could also be a proctime field</span><span class="w">
</span></code></pre></div><p>如示例中所示，table source、视图和临时表的定义可以相互混合。它们按照在环境文件中定义的顺序进行注册。例如，一个临时表可以引用一个视图，该视图可以依赖于另一个视图或 table source。</p>
<h2 id="限制和未来">限制和未来</h2>
<p>目前的 SQL Client 只支持嵌入式模式。未来，社区计划通过提供基于 REST 的 SQL Client 网关来扩展其功能，详见 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-24+-+SQL+Client">FLIP-24</a> 和 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-91%3A+Support+SQL+Client+Gateway">FLIP-91</a>。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[SQL 提示]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-show-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Show 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>SQL Hints</blockquote><h1 id="sql-提示">SQL 提示</h1>
<p>SQL 提示可以与 SQL 语句一起使用，以改变执行计划。本章解释了如何使用提示来强制各种方法。</p>
<p>一般来说，一个提示可以用来。</p>
<p>强制执行计划器：没有完美的计划器，所以实现提示让用户更好地控制执行是有意义的。
Append meta data(或统计)：一些统计，比如&quot;扫描的表索引&quot;和 &ldquo;一些 shuffle 键的 skew info&rdquo;，对于查询来说是有些动态的，用提示来配置它们会非常方便，因为我们从 planner 得到的规划元数据往往不是那么准确。
运算符资源约束：对于很多情况，我们会给执行运算符一个默认的资源配置，比如最小并行或管理内存（耗费资源的 UDF）或特殊的资源需求（GPU 或 SSD 磁盘）等等，用提示对每个查询（而不是 Job）的资源进行配置会非常灵活。</p>
<h2 id="动态表选项">动态表选项</h2>
<p>动态表选项允许动态指定或覆盖表选项，与 SQL DDL 或连接 API 定义的静态表选项不同，这些选项可以在每个查询中的每个表范围内灵活指定。</p>
<p>因此，它非常适用于交互式终端的临时查询，例如，在 SQL-CLI 中，只需添加一个动态选项 <code>/*+ OPTIONS('csv.ignore-parse-errors'='true') */</code>，就可以指定忽略 CSV 源的解析错误。</p>
<p>注意：动态表选项默认是禁止使用的，因为它可能会改变查询的语义。您需要将配置选项 table.dynamic-table-options.enabled 显式地设置为 true（默认为 false），有关如何设置配置选项的详细信息，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html">配置</a>。</p>
<h3 id="语法">语法</h3>
<p>为了不破坏 SQL 的兼容性，我们使用 Oracle 风格的 SQL 提示语法。</p>
<pre><code>table_path /*+ OPTIONS(key=val [, key=val]*) */

key:
    stringLiteral
val:
    stringLiteral
</code></pre><h3 id="例子">例子</h3>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_table1</span> <span class="p">(</span><span class="n">id</span> <span class="nb">BIGINT</span><span class="p">,</span> <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_table2</span> <span class="p">(</span><span class="n">id</span> <span class="nb">BIGINT</span><span class="p">,</span> <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span> <span class="n">age</span> <span class="nb">INT</span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">)</span><span class="p">;</span>

<span class="c1">-- override table options in query source
</span><span class="c1"></span><span class="k">select</span> <span class="n">id</span><span class="p">,</span> <span class="n">name</span> <span class="k">from</span> <span class="n">kafka_table1</span> <span class="cm">/*</span><span class="cm">+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) </span><span class="cm">*/</span><span class="p">;</span>

<span class="c1">-- override table options in join
</span><span class="c1"></span><span class="k">select</span> <span class="o">*</span> <span class="k">from</span>
    <span class="n">kafka_table1</span> <span class="cm">/*</span><span class="cm">+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) </span><span class="cm">*/</span> <span class="n">t1</span>
    <span class="k">join</span>
    <span class="n">kafka_table2</span> <span class="cm">/*</span><span class="cm">+ OPTIONS(&#39;scan.startup.mode&#39;=&#39;earliest-offset&#39;) </span><span class="cm">*/</span> <span class="n">t2</span>
    <span class="k">on</span> <span class="n">t1</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">t2</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>

<span class="c1">-- override table options for INSERT target table
</span><span class="c1"></span><span class="k">insert</span> <span class="k">into</span> <span class="n">kafka_table1</span> <span class="cm">/*</span><span class="cm">+ OPTIONS(&#39;sink.partitioner&#39;=&#39;round-robin&#39;) </span><span class="cm">*/</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">kafka_table2</span><span class="p">;</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/hints.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Table API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Table API</blockquote><h1 id="table-api">Table API</h1>
<p>表 API 是一个统一的关系型 API，用于流处理和批处理。Table API 查询可以在批处理或流处理输入上运行，无需修改。Table API 是 SQL 语言的超级集，是专门为 Apache Flink 工作而设计的。Table API 是 Scala、Java 和 Python 的语言集成 API。Table API 查询不是像 SQL 那样以字符串值的方式指定查询，而是以语言嵌入的方式在 Java、Scala 或 Python 中定义查询，并支持自动完成和语法验证等 IDE。</p>
<p>Table API 与 Flink 的 SQL 集成共享许多概念和部分 API。请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">通用概念</a>和 API，了解如何注册表或创建表对象。<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">流概念</a>页面讨论了流的具体概念，如动态表和<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>。</p>
<p>下面的例子假设一个名为 Orders 的注册表具有属性（a, b, c, rowtime）。rowtime 字段在流式中是一个逻辑<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>，在批处理中是一个常规的时间戳字段。</p>
<h2 id="概述和示例">概述和示例</h2>
<p>Table API 可用于 Scala、Java 和 Python。Scala Table API 利用的是 Scala 表达式，Java Table API 既支持 Expression DSL，也支持解析并转换为等价表达式的字符串，Python Table API 目前只支持解析并转换为等价表达式的字符串。</p>
<p>下面的例子显示了 Scala、Java 和 Python Table API 之间的差异。表程序是在批处理环境中执行的。它扫描 Orders 表，按字段 a 分组，并计算每组的结果行。</p>
<p>通过导入 <code>org.apache.flink.table.api._</code>、<code>org.apache.flink.api.scala._</code> 和 <code>org.apache.flink.table.api.bridge.scala._</code>（用于桥接到/来自 DataStream）来启用 Scala Table API。</p>
<p>下面的例子展示了 Scala Table API 程序是如何构造的。表字段使用 Scala 的字符串插值，使用美元字符（<code>$</code>）引用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala._</span>

<span class="c1">// environment configuration
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register Orders table in table environment
</span><span class="c1"></span><span class="c1">// ...
</span><span class="c1"></span>
<span class="c1">// specify table program
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span> <span class="c1">// schema (a, b, c, rowtime)
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
               <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
               <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">count</span> <span class="n">as</span> <span class="s">&#34;cnt&#34;</span><span class="o">)</span>
               <span class="o">.</span><span class="n">toDataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="c1">// conversion to DataSet
</span><span class="c1"></span>               <span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><p>下一个例子显示了一个更复杂的 Table API 程序。该程序再次扫描 Orders 表，过滤空值，对类型为 String 的字段 a 进行归一化处理，并为每个小时和产品 a 计算平均计费金额 b。它过滤空值，对类型为 String 的字段 a 进行标准化，并为每个小时和产品 a 计算平均账单金额 b。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// environment configuration
</span><span class="c1"></span><span class="c1">// ...
</span><span class="c1"></span>
<span class="c1">// specify table program
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span> <span class="c1">// schema (a, b, c, rowtime)
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
        <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">isNotNull</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">isNotNull</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">.</span><span class="n">isNotNull</span><span class="o">)</span>
        <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">lowerCase</span><span class="o">(</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">1.</span><span class="n">hour</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;hourlyWindow&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;hourlyWindow&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;hourlyWindow&#34;</span><span class="o">.</span><span class="n">end</span> <span class="n">as</span> <span class="s">&#34;hour&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span> <span class="n">as</span> <span class="s">&#34;avgBillingAmount&#34;</span><span class="o">)</span>
</code></pre></div><p>由于表 API 是针对批处理和流数据的统一 API，所以这两个示例程序都可以在批处理和流输入上执行，而不需要对表程序本身进行任何修改。在这两种情况下，考虑到流式记录不会迟到，程序会产生相同的结果（详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/">流概念</a>）。</p>
<h2 id="操作">操作</h2>
<p>表 API 支持以下操作。请注意，并不是所有的操作都能在批处理和流式处理中使用，它们都有相应的标签。</p>
<h3 id="scan-projection-和-filter">Scan, Projection 和 Filter</h3>
<ul>
<li>From(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 FROM 子句。执行对注册的表的扫描。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Values(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 VALUES 子句。从提供的行中产生一个内联表。</p>
<p>你可以使用 <code>row(...)</code> 表达式来创建复合行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromValues</span><span class="o">(</span>
   <span class="n">row</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;ABC&#34;</span><span class="o">)</span><span class="o">,</span>
   <span class="n">row</span><span class="o">(</span><span class="mi">2L</span><span class="o">,</span> <span class="s">&#34;ABCDE&#34;</span><span class="o">)</span>
<span class="o">)</span>
</code></pre></div><p>将产生一个模式(schema)如下的表。</p>
<pre><code>root
|-- f0: BIGINT NOT NULL     // original types INT and BIGINT are generalized to BIGINT
|-- f1: VARCHAR(5) NOT NULL // original types CHAR(3) and CHAR(5) are generalized
                            // to VARCHAR(5). VARCHAR is used instead of CHAR so that
                            // no padding is applied
</code></pre><p>该方法将从输入的表达式中自动得出类型，如果某个位置的类型不同，该方法将尝试为所有类型找到共同的超级类型。如果某个位置的类型不同，方法将尝试为所有类型找到一个共同的超级类型。如果一个共同的超级类型不存在，将抛出一个异常。</p>
<p>您也可以明确地指定请求的类型。这可能对分配更多的通用类型（如 DECIMAL）或为列命名很有帮助。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromValues</span><span class="o">(</span>
    <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span>
        <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">FIELD</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">DECIMAL</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span><span class="o">,</span>
        <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">FIELD</span><span class="o">(</span><span class="s">&#34;name&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">)</span><span class="o">,</span>
    <span class="n">row</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;ABC&#34;</span><span class="o">)</span><span class="o">,</span>
    <span class="n">row</span><span class="o">(</span><span class="mi">2L</span><span class="o">,</span> <span class="s">&#34;ABCDE&#34;</span><span class="o">)</span>
<span class="o">)</span>
</code></pre></div><p>将产生一个模式(schema)如下的表。</p>
<pre><code>root
|-- id: DECIMAL(10, 2)
|-- name: STRING
</code></pre><ul>
<li>Select(Batch/Streaming)</li>
</ul>
<p>类似于 SQL SELECT 语句。执行选择操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
</code></pre></div><p>你可以使用星号（<code>*</code>）作为通配符，选择表中所有的列。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;*&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>As(Batch/Streaming)</li>
</ul>
<p>重新命名字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">,</span> <span class="s">&#34;z&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Where / Filter(Batch/Streaming)</li>
</ul>
<p>类似于 SQL WHERE 子句。过滤掉没有通过过滤谓词的记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">===</span> <span class="mi">0</span><span class="o">)</span>
</code></pre></div><p>或:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span> <span class="o">===</span> <span class="s">&#34;red&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="列操作">列操作</h3>
<ul>
<li>AddColumns(Batch/Streaming)</li>
</ul>
<p>执行字段添加操作。如果添加的字段已经存在，它将抛出一个异常。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">addColumns</span><span class="o">(</span><span class="n">concat</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="s">&#34;Sunny&#34;</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><ul>
<li>AddOrReplaceColumns(Batch/Streaming)</li>
</ul>
<p>执行字段添加操作。如果添加的列名与现有的列名相同，那么现有的字段将被替换。此外，如果添加的字段名与现有字段名重复，则使用最后一个字段名。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">addOrReplaceColumns</span><span class="o">(</span><span class="n">concat</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="s">&#34;Sunny&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;desc&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>DropColumns(Batch/Streaming)</li>
</ul>
<p>执行字段删除操作。字段表达式应该是字段引用表达式，并且只能删除现有的字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">dropColumns</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>RenameColumns(Batch/Streaming)</li>
</ul>
<p>执行字段重命名操作。字段表达式应为别名表达式，且只能对现有字段进行重命名。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">renameColumns</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span> <span class="n">as</span> <span class="s">&#34;b2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span> <span class="n">as</span> <span class="s">&#34;c2&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="聚合aggregations">聚合(Aggregations)</h3>
<ul>
<li>GroupBy 聚合(Batch/Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 GROUP BY 子句。将分组键上的行与下面的运行聚合操作符进行分组，以分组方式聚合行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;d&#34;</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会无限增长，这取决于聚合的类型和不同分组键的数量。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>GroupBy 窗口聚合(Batch/Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能的一个或多个分组键上对一个表进行分组和聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span> <span class="c1">// access window properties and aggregate
</span></code></pre></div><ul>
<li>Over 窗口聚合(Streaming)</li>
</ul>
<p>类似于 SQL OVER 子句。根据前后记录的窗口(范围)，为每条记录计算 OVER 窗口汇总。更多细节请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#over-windows">over 窗口</a>部分。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">orders</span>
    <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">window</span><span class="o">(</span>
        <span class="nc">Over</span>
          <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span>
          <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span>
          <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span>
          <span class="n">following</span> <span class="nc">CURRENT_RANGE</span>
          <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">over</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">over</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span><span class="o">)</span> <span class="c1">// sliding aggregate
</span></code></pre></div><p>注意：所有的聚合必须定义在同一个窗口上，即相同的分区、排序和范围。目前，只支持对 CURRENT ROW 范围的 PRECEDING（UNBOUNDED 和 bounded）窗口。还不支持带 FOLLOWING 的范围。ORDER BY 必须在单个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>上指定。</p>
<ul>
<li>Distinct 聚合(Batch Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 DISTINCT AGGREGATION 子句，如 <code>COUNT(DISTINCT a)</code>。Distinct 聚合声明一个聚合函数（内置的或用户定义的）只应用在不同的输入值上，Distinct 可以应用于 GroupBy 聚合，GroupBy 窗口聚合和 Over 窗口聚合。Distinct 可以应用于 GroupBy 聚合、GroupBy 窗口聚合和 Over 窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="c1">// Distinct aggregation on group by
</span><span class="c1"></span><span class="k">val</span> <span class="n">groupByDistinctResult</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">distinct</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
<span class="c1">// Distinct aggregation on time window group by
</span><span class="c1"></span><span class="k">val</span> <span class="n">groupByWindowDistinctResult</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">distinct</span> <span class="n">as</span> <span class="s">&#34;d&#34;</span><span class="o">)</span>
<span class="c1">// Distinct aggregation on over window
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span>
        <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span>
        <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span>
        <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span>
        <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">avg</span><span class="o">.</span><span class="n">distinct</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">max</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">min</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><p>用户自定义的聚合函数也可以与 DISTINCT 修饰符一起使用。如果只计算不同值的聚合结果，只需在聚合函数中添加 distinct 修饰符即可。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span><span class="o">;</span>

<span class="c1">// Use distinct aggregation for user-defined aggregate functions
</span><span class="c1"></span><span class="k">val</span> <span class="n">myUdagg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyUdagg</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
<span class="n">orders</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;users&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;users&#34;</span><span class="o">,</span> <span class="n">myUdagg</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;points&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;myDistinctResult&#34;</span><span class="o">)</span><span class="o">;</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Distinct(Batch Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL 的 DISTINCT 子句。返回具有不同值组合的记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">distinct</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。如果启用了状态清洗功能，Distinct 必须发出消息，以防止下游操作者过早地驱逐状态，从而使 Distinct 包含结果更新。详见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="joins">Joins</h3>
<ul>
<li>Inner Join(Batch/Streaming)</li>
</ul>
<p>类似于 SQL JOIN 子句。连接两个表。两个表必须有不同的字段名，并且必须通过 join 操作符或使用 where 或 filter 操作符定义至少一个平等连接谓词。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">right</span><span class="o">)</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Outer Join(Batch/Streaming/Result Updating)</li>
</ul>
<p>类似于 SQL LEFT/RIGHT/FULL OUTER JOIN 子句。连接两个表。两个表必须有不同的字段名，并且必须定义至少一个平等连接谓词。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataSet</span><span class="o">(</span><span class="n">ds1</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataSet</span><span class="o">(</span><span class="n">ds2</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">leftOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">leftOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">rightOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">rightOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">fullOuterResult</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">fullOuterJoin</span><span class="o">(</span><span class="n">right</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Interval Join(Batch/Streaming)</li>
</ul>
<p>注：区间连接是常规连接的一个子集，可以用流式处理。</p>
<p>一个区间连接至少需要一个等价连接谓词和一个连接条件，以限制双方的时间。这样的条件可以由两个合适的范围谓词（&lt;，&lt;=，&gt;=，&gt;）或一个比较两个输入表的相同类型的<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>（即处理时间或事件时间）的单一平等谓词来定义。</p>
<p>例如，以下谓词是有效的区间连接条件。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span>
<span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&gt;=</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&lt;</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">+</span> <span class="mf">10.</span><span class="n">minutes</span>
<span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;d&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
  <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;d&#34;</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&gt;=</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">-</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="o">&amp;&amp;</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span> <span class="o">&lt;</span> <span class="n">$</span><span class="s">&#34;rtime&#34;</span> <span class="o">+</span> <span class="mf">10.</span><span class="n">minutes</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;ltime&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Inner Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每条记录都与相应的表函数调用所产生的所有记录合并。如果左（外）表的表函数调用返回的结果是空的，则放弃该表的某行。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate User-Defined Table Function
</span><span class="c1"></span><span class="k">val</span> <span class="n">split</span><span class="k">:</span> <span class="kt">TableFunction</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySplitUDTF</span><span class="o">(</span><span class="o">)</span>

<span class="c1">// join
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">table</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">split</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="s">&#34;v&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Left Outer Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每一行都与相应的表函数调用所产生的所有行相连接。如果表函数调用返回的结果为空，则保留相应的外侧行，并将结果用空值填充。</p>
<p>注意：目前，表函数左外侧连接的谓词只能是空或字面为真。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// instantiate User-Defined Table Function
</span><span class="c1"></span><span class="k">val</span> <span class="n">split</span><span class="k">:</span> <span class="kt">TableFunction</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MySplitUDTF</span><span class="o">(</span><span class="o">)</span>

<span class="c1">// join
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">table</span>
    <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">split</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="s">&#34;v&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;s&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;t&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Join with Temporal Table(Streaming)</li>
</ul>
<p><a href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables">时间表</a>是跟踪其随时间变化的表。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>提供了对时间表在特定时间点的状态的访问。用时态表函数连接表的语法与带表函数的内部连接中的语法相同。</p>
<p>目前只支持与时态表的内联接。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">ratesHistory</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;RatesHistory&#34;</span><span class="o">)</span>

<span class="c1">// register temporal table function with a time attribute and primary key
</span><span class="c1"></span><span class="k">val</span> <span class="n">rates</span> <span class="k">=</span> <span class="n">ratesHistory</span><span class="o">.</span><span class="n">createTemporalTableFunction</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;r_proctime&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span><span class="o">)</span>

<span class="c1">// join with &#34;Orders&#34; based on the time attribute and key
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">rates</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;o_rowtime&#34;</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span> <span class="o">===</span> <span class="n">$</span><span class="s">&#34;o_currency&#34;</span><span class="o">)</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables">时间表概念说明</a>。</p>
<h3 id="集合操作">集合操作</h3>
<ul>
<li>Union(Batch)</li>
</ul>
<p>类似于 SQL UNION 子句。将两个表联合起来，去除重复记录，两个表必须有相同的字段类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>UnionAll(Batch/Streaming)</li>
</ul>
<p>类似于 SQL UNION ALL 子句。联合两个表，两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>Intersect(Batch)</li>
</ul>
<p>类似于 SQL INTERSECT 子句。Intersect 子句返回的是两个表中都存在的记录。如果一条记录在一个表或两个表中存在一次以上，则只返回一次，即结果表没有重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;g&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">intersect</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>IntersectAll(Batch)</li>
</ul>
<p>类似于 SQL 的 INTERSECT ALL 子句。IntersectAll 子句返回两个表中都存在的记录。如果一条记录在两张表中都存在一次以上，那么就会按照它在两张表中存在的次数来返回，也就是说，得到的表可能有重复的记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;e&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;f&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;g&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">intersectAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>Minus(Batch)</li>
</ul>
<p>类似于 SQL EXCEPT 子句。Minus 返回左表中不存在于右表中的记录。左表中的重复记录只返回一次，即删除重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">minus</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>MinusAll(Batch)</li>
</ul>
<p>类似于 SQL EXCEPT ALL 子句。MinusAll 子句返回右表中不存在的记录。一条记录在左表中出现 n 次，在右表中出现 m 次，则返回(n - m)次，即删除右表中存在的重复记录。两个表的字段类型必须相同。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">minusAll</span><span class="o">(</span><span class="n">right</span><span class="o">)</span>
</code></pre></div><ul>
<li>In(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 的 IN 子句。如果一个表达式存在于给定的表子查询中，In 子句返回 true。子查询表必须由一列组成。该列必须与表达式具有相同的数据类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">left</span> <span class="k">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">right</span> <span class="k">=</span> <span class="n">ds2</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">left</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">in</span><span class="o">(</span><span class="n">right</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="orderby-offset-和-fetch">OrderBy, Offset 和 Fetch</h3>
<ul>
<li>Order By(Batch)</li>
</ul>
<p>类似于 SQL ORDER BY 子句。返回所有平行分区的全局排序记录。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">)</span>
</code></pre></div><ul>
<li>Offset 和 Fetch(Batch)</li>
</ul>
<p>类似于 SQL 的 OFFSET 和 FETCH 子句。Offset 和 Fetch 限制了排序结果中返回的记录数量。Offset 和 Fetch 在技术上是 Order By 操作符的一部分，因此必须在它前面。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">in</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span>

<span class="c1">// returns the first 5 records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">)</span><span class="o">.</span><span class="n">fetch</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="c1">// skips the first 3 records and returns all following records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">)</span><span class="o">.</span><span class="n">offset</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="c1">// skips the first 10 records and returns the next 5 records from the sorted result
</span><span class="c1"></span><span class="k">val</span> <span class="n">result3</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="n">orderBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">.</span><span class="n">asc</span><span class="o">)</span><span class="o">.</span><span class="n">offset</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span><span class="o">.</span><span class="n">fetch</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</code></pre></div><h3 id="insert">Insert</h3>
<ul>
<li>Insert Into(Batch/Streaming)</li>
</ul>
<p>类似于 SQL 查询中的 <code>INSERT INTO</code> 子句，该方法执行插入到一个注册的输出表中。<code>executeInsert()</code> 方法将立即提交一个执行插入操作的 Flink 作业。</p>
<p>输出表必须在 TableEnvironment 中注册（见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#connector-tables">连接器表</a>）。此外，注册表的模式必须与查询的模式相匹配。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="n">orders</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;OutOrders&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="group-窗口">Group 窗口</h3>
<p>分组窗口根据时间或行数间隔将分组行汇总成有限的组，每组评估一次汇总函数。对于批处理表来说，窗口是按时间间隔对记录进行分组的便捷捷径。</p>
<p>窗口是使用 window(w: GroupWindow)子句定义的，并且需要一个别名，这个别名是使用 as 子句指定的。为了通过窗口对表进行分组，必须在 groupBy(&hellip;)子句中像常规分组属性一样引用窗口别名。下面的例子展示了如何在表上定义窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="o">[</span><span class="kt">w</span><span class="kt">:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>  <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>   <span class="c1">// group the table by window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>  <span class="c1">// aggregate
</span></code></pre></div><p>在流式环境中，只有当窗口聚合除窗口外还对一个或多个属性进行分组时，才能并行计算，即 groupBy(&hellip;)子句引用了一个窗口别名和至少一个附加属性。仅引用窗口别名的 groupBy(&hellip;) 子句（如上面的例子）只能由单个非并行任务来评估。下面的示例显示了如何定义具有附加分组属性的窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="o">[</span><span class="kt">w</span><span class="kt">:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>  <span class="c1">// group the table by attribute a and window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>  <span class="c1">// aggregate
</span></code></pre></div><p>窗口属性，如时间窗口的开始、结束或行时间戳，可以在选择语句中作为窗口别名的属性，分别添加为 w.start、w.end 和 w.rowtime。窗口开始时间和行时间时间戳是包含的窗口下界和上界。相反，窗口结束时间戳是专属的上层窗口边界。例如一个从下午 2 点开始的 30 分钟的翻滚窗口，其起始时间戳为 14:00:00.000，行时时间戳为 14:29:59.999，结束时间戳为 14:30:00.000。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="o">[</span><span class="kt">w</span><span class="kt">:</span> <span class="kt">GroupWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>  <span class="c1">// define window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span>  <span class="c1">// group the table by attribute a and window w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">count</span><span class="o">)</span> <span class="c1">// aggregate and add window start, end, and rowtime timestamps
</span></code></pre></div><p>窗口参数定义了如何将行映射到窗口。Window 不是一个用户可以实现的接口。相反，Table API 提供了一组具有特定语义的预定义 Window 类，它们被翻译成底层的 DataStream 或 DataSet 操作。下面列出了支持的窗口定义。</p>
<h4 id="滚动窗口">滚动窗口</h4>
<p>滚动窗口将行分配到固定长度的非重叠的连续窗口。例如，5 分钟的滚动窗口以 5 分钟的间隔将行分组。滚动窗口可以在事件时间、处理时间或行数上定义。</p>
<p>滚动窗口可以通过使用 Tumble 类来定义，具体如下。</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">over</td>
<td align="left">定义窗口的长度，可以是时间或行数间隔。</td>
</tr>
<tr>
<td align="left">on</td>
<td align="left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td align="left">as</td>
<td align="left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Tumbling Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Tumbling Processing-time Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Tumbling Row-count Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="slide-滑动窗口">Slide (滑动窗口)</h4>
<p>滑动窗口有一个固定的尺寸，并按指定的滑动间隔滑动，如果滑动间隔小于窗口尺寸，滑动窗口就会重叠。如果滑动间隔小于窗口大小，滑动窗口就会重叠。因此，行可以分配给多个窗口。例如，一个 15 分钟大小和 5 分钟滑动间隔的滑动窗口将每行分配到 3 个不同的 15 分钟大小的窗口，这些窗口以 5 分钟的间隔进行评估。滑动窗口可以在事件时间、处理时间或行数上定义。</p>
<p>滑动窗口是通过使用 Slide 类来定义的，具体如下。</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">over</td>
<td align="left">定义窗口的长度，可以是时间或行数间隔。</td>
</tr>
<tr>
<td align="left">every</td>
<td align="left">定义滑动间隔，可以是时间间隔或行数间隔。缩放间隔的类型必须与尺寸间隔相同。</td>
</tr>
<tr>
<td align="left">on</td>
<td align="left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td align="left">as</td>
<td align="left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Sliding Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Sliding Processing-time window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Sliding Row-count window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Slide</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">every</span> <span class="mf">5.</span><span class="n">rows</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="session-会话窗口">Session (会话窗口)</h4>
<p>会话窗口没有固定的大小，但它们的界限是由不活动的时间间隔来定义的，也就是说，如果在定义的间隙期没有事件出现，会话窗口就会被关闭。例如，有 30 分钟间隔的会话窗口在 30 分钟不活动后观察到一行时开始（否则该行将被添加到现有的窗口中），如果在 30 分钟内没有行被添加，则关闭。会话窗口可以在事件时间或处理时间工作。</p>
<p>通过使用 Session 类定义会话窗口，如下所示。</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">withGap</td>
<td align="left">将两个窗口之间的间隔定义为时间间隔。</td>
</tr>
<tr>
<td align="left">on</td>
<td align="left">要对其进行分组（时间间隔）或排序（行数）的时间属性。对于批处理查询，这可能是任何 Long 或 Timestamp 属性。对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。</td>
</tr>
<tr>
<td align="left">as</td>
<td align="left">为窗口指定一个别名。该别名用于在下面的 groupBy()子句中引用窗口，并在 select()子句中选择窗口属性，如窗口开始、结束或行时间戳。</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Session Event-time Window
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Session</span> <span class="n">withGap</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Session Processing-time Window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Session</span> <span class="n">withGap</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="over-窗口">Over 窗口</h3>
<p>Over 窗口聚合是从标准 SQL（over 子句）中得知的，并在查询的 SELECT 子句中定义。与组窗口不同的是，组窗口是在 GROUP BY 子句中指定的，over 窗口不折叠行。相反，over 窗口聚合计算的是每条输入行在其相邻行的范围内的聚合。</p>
<p>Over 窗口是使用 window(w: OverWindow*)子句来定义的(在 Python API 中使用 over_window(*OverWindow))，并且在 select()方法中通过别名来引用。下面的例子展示了如何在表上定义一个 <code>over</code> 窗口聚合。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="o">[</span><span class="kt">w</span><span class="kt">:</span> <span class="kt">OverWindow</span><span class="o">]</span> <span class="n">as</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span>              <span class="c1">// define over window with alias w
</span><span class="c1"></span>  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">.</span><span class="n">min</span> <span class="n">over</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// aggregate over the over window w
</span></code></pre></div><p>OverWindow 定义了计算汇总的行的范围。OverWindow 不是一个用户可以实现的接口。相反，Table API 提供了 Over 类来配置 over 窗口的属性。Over 窗口可以在事件时间或处理时间上定义，也可以在指定为时间间隔或行数的范围上定义。支持的 over 窗口定义是以 Over（和其他类）上的方法暴露出来的，下面列出了这些方法。</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">Required</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">partitionBy</td>
<td align="left">Optional</td>
<td align="left">定义输入的一个或多个属性的分区。每个分区都被单独排序，聚合函数被分别应用到每个分区。注意：在流环境中，只有当窗口包含 partitionBy 子句时，才能并行计算 over window aggregates。如果没有 partitionBy(&hellip;)，流就会被一个单一的、非并行的任务处理。</td>
</tr>
<tr>
<td align="left">orderBy</td>
<td align="left">Required</td>
<td align="left">定义每个分区中行的顺序，从而定义聚合函数应用到行的顺序。注意：对于流式查询，这必须是一个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">声明的事件时间或处理时间时间属性</a>。目前，只支持单个排序属性。</td>
</tr>
<tr>
<td align="left">preceding</td>
<td align="left">Optional</td>
<td align="left">定义包含在窗口中并在当前行之前的行的间隔。这个间隔可以指定为时间间隔或行数间隔。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#bounded-over-windows">有边界的窗口</a>用间隔的大小来指定，例如，时间间隔为 10.分钟，行数间隔为 10.行。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#unbounded-over-windows">无边界的窗口</a>用一个常数来指定，例如，时间间隔为 UNBOUNDED_RANGE，行数间隔为 UNBOUNDED_ROW。未绑定的窗口从分区的第一行开始。如果省略了前面的子句，UNBOUNDED_RANGE 和 CURRENT_RANGE 被用作窗口的默认前后。</td>
</tr>
<tr>
<td align="left">following</td>
<td align="left">Optional</td>
<td align="left">定义包含在窗口中并跟随当前行的行的窗口间隔。这个间隔必须与前一个间隔的单位（时间或行数）相同。目前，不支持在当前行之后添加行的窗口。您可以指定两个常量中的一个。CURRENT_ROW 将窗口的上界设置为当前行。CURRENT_RANGE 将窗口的上界设置为当前行的排序键，也就是说，所有与当前行具有相同排序键的行都包含在窗口中。如果省略下面的子句，时间间隔窗口的上界定义为 CURRENT_RANGE，行数间隔窗口的上界定义为 CURRENT_ROW。</td>
</tr>
<tr>
<td align="left">as</td>
<td align="left">Required</td>
<td align="left">为 over 窗口指定一个别名。该别名用于在下面的 select()子句中引用 over 窗口。</td>
</tr>
</tbody>
</table>
<p>注意：目前，在同一个 select()调用中，所有的聚合函数都必须在同一个 over 窗口中计算。</p>
<h4 id="unbounded-over-windows">Unbounded Over Windows</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Unbounded Event-time over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Unbounded Processing-time over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_RANGE</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Unbounded Event-time Row-count over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_ROW</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
 
<span class="c1">// Unbounded Processing-time Row-count over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="nc">UNBOUNDED_ROW</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h4 id="bounded-over-windows">Bounded Over Windows</h4>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Bounded Event-time over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="mf">1.</span><span class="n">minutes</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Bounded Processing-time over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="mf">1.</span><span class="n">minutes</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>

<span class="c1">// Bounded Event-time Row-count over window (assuming an event-time attribute &#34;rowtime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">preceding</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
  
<span class="c1">// Bounded Processing-time Row-count over window (assuming a processing-time attribute &#34;proctime&#34;)
</span><span class="c1"></span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Over</span> <span class="n">partitionBy</span> <span class="n">$</span><span class="s">&#34;a&#34;</span> <span class="n">orderBy</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span> <span class="n">preceding</span> <span class="mf">10.</span><span class="n">rows</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="基于行的操作">基于行的操作</h3>
<p>基于行的操作产生多列的输出。</p>
<ul>
<li>Map(Batch/Streaming)</li>
</ul>
<p>使用用户定义的标量函数或内置的标量函数执行 map 操作。如果输出类型是复合类型，则输出将被扁平化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyMapFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="s">&#34;pre-&#34;</span> <span class="o">+</span> <span class="n">a</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="o">(</span><span class="n">signature</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Class</span><span class="o">[</span><span class="k">_</span><span class="o">]</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span>
    <span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">func</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMapFunction</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">func</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>FlatMap(Batch/Streaming)</li>
</ul>
<p>用表格函数执行 <code>flatMap</code> 操作。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyFlatMapFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&#34;#&#34;</span><span class="o">)</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;#&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="o">{</span> <span class="n">s</span> <span class="k">=&gt;</span>
        <span class="k">val</span> <span class="n">row</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Row</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
        <span class="n">row</span><span class="o">.</span><span class="n">setField</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">s</span><span class="o">)</span>
        <span class="n">row</span><span class="o">.</span><span class="n">setField</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">length</span><span class="o">)</span>
        <span class="n">collect</span><span class="o">(</span><span class="n">row</span><span class="o">)</span>
      <span class="o">}</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">func</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyFlatMapFunction</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">func</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;c&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Aggregate(Batch/Streaming/Result Updating)</li>
</ul>
<p>用一个聚合函数执行一个聚合操作。必须用 select 语句关闭&quot;聚合&rdquo;，select 语句不支持聚合函数。如果输出类型是复合类型，聚合的输出将被扁平化。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">MyMinMaxAcc</span><span class="o">(</span><span class="k">var</span> <span class="n">min</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="k">var</span> <span class="n">max</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>

<span class="k">class</span> <span class="nc">MyMinMax</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">Row</span>, <span class="kt">MyMinMaxAcc</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">value</span> <span class="o">&lt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">min</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">min</span> <span class="k">=</span> <span class="n">value</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">value</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">max</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">max</span> <span class="k">=</span> <span class="n">value</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span> <span class="o">=</span> <span class="nc">MyMinMaxAcc</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span>

  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">min</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">max</span> <span class="k">=</span> <span class="mi">0</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">MyMinMaxAcc</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">min</span><span class="o">)</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">max</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">RowTypeInfo</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">myAggFunc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMinMax</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="n">myAggFunc</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;y&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>Group 窗口聚合(Batch/Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能的一个或多个分组键上对一个表进行分组和聚合。你必须用 select 语句关闭&quot;聚合&rdquo;。而且选择语句不支持 &ldquo;*&rdquo; 或聚合函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">myAggFunc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyMinMax</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">input</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="n">myAggFunc</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="s">&#34;y&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;x&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;y&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">)</span> <span class="c1">// access window properties and aggregate results
</span></code></pre></div><ul>
<li>FlatAggregate(Streaming/Result Updating)</li>
</ul>
<p>类似于 GroupBy 聚合。将分组键上的行与下面的运行表聚合运算符进行分组，将行进行分组。与 AggregateFunction 的不同之处在于，TableAggregateFunction 可以为一个组返回 0 条或多条记录。你必须用 select 语句关闭 &ldquo;flatAggregate&rdquo;。而 select 语句不支持聚合函数。</p>
<p>不使用 emitValue 输出结果，还可以使用 emitUpdateWithRetract 方法。与 emitValue 不同的是，emitUpdateWithRetract 用于输出已经更新的值。这个方法以回缩模式增量输出数据，也就是说，一旦有更新，我们必须在发送新的更新记录之前回缩旧的记录。如果在表聚合函数中定义了 emitUpdateWithRetract 方法，那么 emitUpdateWithRetract 方法将优先于 emitValue 方法使用，因为该方法被视为比 emitValue 更有效，因为它可以增量输出值。详见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html#table-aggregation-functions">表聚合函数</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> Accumulator for top2.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> The top2 user-defined table aggregate function.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">JIterable</span><span class="o">[</span><span class="kt">Top2Accum</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">its</span><span class="o">.</span><span class="n">iterator</span><span class="o">(</span><span class="o">)</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">first</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">second</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// emit the value and rank
</span><span class="c1"></span>    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2</span>
<span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;key&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会无限增长，这取决于聚合的类型和不同分组键的数量。请提供具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请参见<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Group Window FlatAggregate(Streaming)</li>
</ul>
<p>在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">分组窗口</a>和可能一个或多个分组键上对一个表进行分组和聚合。你必须用 select 语句关闭 &ldquo;flatAggregate&rdquo;。而 select 语句不支持聚合函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2</span>
<span class="k">val</span> <span class="n">orders</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">5.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span> <span class="n">as</span> <span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// define window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">)</span> <span class="c1">// group by key and window
</span><span class="c1"></span>    <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;b&#34;</span><span class="o">)</span> <span class="n">as</span> <span class="o">(</span><span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="n">w</span><span class="o">.</span><span class="n">start</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">end</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;w&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;v&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rank&#34;</span><span class="o">)</span> <span class="c1">// access window properties and aggregate results
</span></code></pre></div><h2 id="数据类型">数据类型</h2>
<p>请看关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的专门页面。</p>
<p>通用类型和(嵌套的)复合类型(例如 POJOs、tuple、行、Scala case 类)也可以是行的字段。</p>
<p>具有任意嵌套的复合类型的字段可以用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html#value-access-functions">值访问函数</a>来访问。</p>
<p>通用类型被视为一个黑盒，可以通过<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">用户定义的函数</a>进行传递或处理。</p>
<h2 id="表达式语法">表达式语法</h2>
<p>前面几节中的一些操作符都期望有一个或多个表达式。表达式可以使用内嵌的 Scala DSL 或作为字符串来指定。请参考上面的例子来了解如何指定表达式。</p>
<p>这是表达式的 EBNF 语法。</p>
<pre><code>expressionList = expression , { &quot;,&quot; , expression } ;

expression = overConstant | alias ;

alias = logic | ( logic , &quot;as&quot; , fieldReference ) | ( logic , &quot;as&quot; , &quot;(&quot; , fieldReference , { &quot;,&quot; , fieldReference } , &quot;)&quot; ) ;

logic = comparison , [ ( &quot;&amp;&amp;&quot; | &quot;||&quot; ) , comparison ] ;

comparison = term , [ ( &quot;=&quot; | &quot;==&quot; | &quot;===&quot; | &quot;!=&quot; | &quot;!==&quot; | &quot;&gt;&quot; | &quot;&gt;=&quot; | &quot;&lt;&quot; | &quot;&lt;=&quot; ) , term ] ;

term = product , [ ( &quot;+&quot; | &quot;-&quot; ) , product ] ;

product = unary , [ ( &quot;*&quot; | &quot;/&quot; | &quot;%&quot;) , unary ] ;

unary = [ &quot;!&quot; | &quot;-&quot; | &quot;+&quot; ] , composite ;

composite = over | suffixed | nullLiteral | prefixed | atom ;

suffixed = interval | suffixAs | suffixCast | suffixIf | suffixDistinct | suffixFunctionCall | timeIndicator ;

prefixed = prefixAs | prefixCast | prefixIf | prefixDistinct | prefixFunctionCall ;

interval = timeInterval | rowInterval ;

timeInterval = composite , &quot;.&quot; , (&quot;year&quot; | &quot;years&quot; | &quot;quarter&quot; | &quot;quarters&quot; | &quot;month&quot; | &quot;months&quot; | &quot;week&quot; | &quot;weeks&quot; | &quot;day&quot; | &quot;days&quot; | &quot;hour&quot; | &quot;hours&quot; | &quot;minute&quot; | &quot;minutes&quot; | &quot;second&quot; | &quot;seconds&quot; | &quot;milli&quot; | &quot;millis&quot;) ;

rowInterval = composite , &quot;.&quot; , &quot;rows&quot; ;

suffixCast = composite , &quot;.cast(&quot; , dataType , &quot;)&quot; ;

prefixCast = &quot;cast(&quot; , expression , dataType , &quot;)&quot; ;

dataType = &quot;BYTE&quot; | &quot;SHORT&quot; | &quot;INT&quot; | &quot;LONG&quot; | &quot;FLOAT&quot; | &quot;DOUBLE&quot; | &quot;BOOLEAN&quot; | &quot;STRING&quot; | &quot;DECIMAL&quot; | &quot;SQL_DATE&quot; | &quot;SQL_TIME&quot; | &quot;SQL_TIMESTAMP&quot; | &quot;INTERVAL_MONTHS&quot; | &quot;INTERVAL_MILLIS&quot; | ( &quot;MAP&quot; , &quot;(&quot; , dataType , &quot;,&quot; , dataType , &quot;)&quot; ) | ( &quot;PRIMITIVE_ARRAY&quot; , &quot;(&quot; , dataType , &quot;)&quot; ) | ( &quot;OBJECT_ARRAY&quot; , &quot;(&quot; , dataType , &quot;)&quot; ) ;

suffixAs = composite , &quot;.as(&quot; , fieldReference , &quot;)&quot; ;

prefixAs = &quot;as(&quot; , expression, fieldReference , &quot;)&quot; ;

suffixIf = composite , &quot;.?(&quot; , expression , &quot;,&quot; , expression , &quot;)&quot; ;

prefixIf = &quot;?(&quot; , expression , &quot;,&quot; , expression , &quot;,&quot; , expression , &quot;)&quot; ;

suffixDistinct = composite , &quot;distinct.()&quot; ;

prefixDistinct = functionIdentifier , &quot;.distinct&quot; , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

suffixFunctionCall = composite , &quot;.&quot; , functionIdentifier , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

prefixFunctionCall = functionIdentifier , [ &quot;(&quot; , [ expression , { &quot;,&quot; , expression } ] , &quot;)&quot; ] ;

atom = ( &quot;(&quot; , expression , &quot;)&quot; ) | literal | fieldReference ;

fieldReference = &quot;*&quot; | identifier ;

nullLiteral = &quot;nullOf(&quot; , dataType , &quot;)&quot; ;

timeIntervalUnit = &quot;YEAR&quot; | &quot;YEAR_TO_MONTH&quot; | &quot;MONTH&quot; | &quot;QUARTER&quot; | &quot;WEEK&quot; | &quot;DAY&quot; | &quot;DAY_TO_HOUR&quot; | &quot;DAY_TO_MINUTE&quot; | &quot;DAY_TO_SECOND&quot; | &quot;HOUR&quot; | &quot;HOUR_TO_MINUTE&quot; | &quot;HOUR_TO_SECOND&quot; | &quot;MINUTE&quot; | &quot;MINUTE_TO_SECOND&quot; | &quot;SECOND&quot; ;

timePointUnit = &quot;YEAR&quot; | &quot;MONTH&quot; | &quot;DAY&quot; | &quot;HOUR&quot; | &quot;MINUTE&quot; | &quot;SECOND&quot; | &quot;QUARTER&quot; | &quot;WEEK&quot; | &quot;MILLISECOND&quot; | &quot;MICROSECOND&quot; ;

over = composite , &quot;over&quot; , fieldReference ;

overConstant = &quot;current_row&quot; | &quot;current_range&quot; | &quot;unbounded_row&quot; | &quot;unbounded_row&quot; ;

timeIndicator = fieldReference , &quot;.&quot; , ( &quot;proctime&quot; | &quot;rowtime&quot; ) ;
</code></pre><p>字符。在这里，literal 是一个有效的 Java 字元。字符串的字元可以使用单引号或双引号来指定。复制引号进行转义（例如 &lsquo;It&rsquo;s me.&rsquo; 或 &ldquo;I &ldquo;&ldquo;like &ldquo;dog.&quot;）。</p>
<p>空符。空符必须有一个类型。使用 nullOf(type)(例如 nullOf(INT))来创建一个空值。</p>
<p>字段引用。fieldReference 指定数据中的一列（如果使用 <code>*</code>，则指定所有列），functionIdentifier 指定一个支持的标量函数。列名和函数名遵循 Java 标识符语法。</p>
<p>函数调用。作为字符串指定的表达式也可以使用前缀符号代替后缀符号来调用运算符和函数。</p>
<p>小数。如果需要处理精确的数值或大的小数，Table API 也支持 Java 的 BigDecimal 类型。在 Scala Table API 中，小数可以通过 BigDecimal(&ldquo;123456&rdquo;)来定义，而在 Java 中，可以通过附加一个 &ldquo;p&rdquo; 来表示精确，例如 123456p。</p>
<p>时间表示法。为了处理时间值，Table API 支持 Java SQL 的 Date, Time 和 Timestamp 类型。在 Scala Table API 中，可以通过使用 java.sql.Date.valueOf(&ldquo;2016-06-27&rdquo;)、java.sql.Time.valueOf(&ldquo;10:10:42&rdquo;) 或 java.sql.Timestamp.valueOf(&ldquo;2016-06-27 10:10:42.123&rdquo;) 来定义字符。Java 和 Scala Table API 还支持调用 &ldquo;2016-06-27&rdquo;.toDate()、&ldquo;10:10:42&rdquo;.toTime() 和  &ldquo;2016-06-27 10:10:42.123&rdquo;.toTimestamp() 来将 Strings 转换为时间类型。注意：由于 Java 的时态 SQL 类型依赖于时区，请确保 Flink 客户端和所有的 TaskManagers 使用相同的时区。</p>
<p>时间间隔。时间间隔可以用月数（Types.INTERVAL_MONTHS）或毫秒数（Types.INTERVAL_MILLIS）表示。同一类型的时间间隔可以加减(例如：1.小时+10.分钟)。可以将毫秒的时间间隔加到时间点上（如 &ldquo;2016-08-10&rdquo;.toDate + 5.days）。</p>
<p>Scala 表达式。Scala 表达式使用隐式转换。因此，确保在你的程序中添加通配符 <code>import org.apache.flink.table.api._</code>。如果一个字词没有被当作表达式，可以使用.toExpr 如 3.toExpr 来强制转换一个字词。</p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Table API 和 SQL]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-and-sql/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api-and-sql/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Table API &amp; SQL</blockquote><h2 id="table-api-和-sql">Table API 和 SQL</h2>
<p>Apache Flink 具有两个关系型 API - Table API 和 SQL - 用于统一的流和批处理。Table API 是 Scala 和 Java 的语言集成查询 API，它允许用非常直观的方式从关系运算符（如选择、过滤和连接）组成查询。Flink 的 SQL 支持是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。无论输入是批处理输入（DataSet）还是流输入（DataStream），在任一接口中指定的查询都具有相同的语义，并指定相同的结果。</p>
<p>表 API 和 SQL 接口与 Flink 的 DataStream 和 DataSet API 紧密集成。你可以很容易地在所有 API 和建立在 API 基础上的库之间切换。例如，您可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/cep.html">CEP 库</a> 从 DataStream 中提取模式，随后使用 Table API 来分析模式，或者您可能会在预处理数据上运行 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/gelly">Gelly 图算法</a>之前，使用 SQL 查询扫描、过滤和聚合一个批处理表。</p>
<p>请注意，Table API 和 SQL 的功能还不完善，正在积极开发中。并非所有的操作都被 [Table API, SQL] 和 [stream, batch] 输入的每个组合所支持。</p>
<h3 id="依赖结构">依赖结构</h3>
<p>从 Flink 1.9 开始，Flink 为评估 Table &amp; SQL API 程序提供了两种不同的规划器实现：Blink planner 和 Flink 1.9 之前的旧 planner。Planner 负责将关系运算符转化为可执行的、优化的 Flink 作业。这两种 planner 都有不同的优化规则和运行时类。它们在支持的功能集上也可能有所不同。</p>
<p>注意: 对于生产用例，我们推荐 blink planner，它从 1.11 开始成为默认 planner。</p>
<p>所有的 Table API 和 SQL 组件都捆绑在 flink-table 或 flink-table-blink Maven 构件中。</p>
<p>以下是与大多数项目相关的依赖关系。</p>
<ul>
<li>flink-table-common: 一个通用模块，用于通过自定义函数、格式等扩展表生态系统。</li>
<li>flink-table-api-java: 使用 Java 编程语言的纯表程序的 Table &amp; SQL API（处于早期开发阶段，不推荐！）。</li>
<li>flink-table-api-scala: Table 和 SQL API，用于使用 Java 编程语言的纯表程序（处于早期开发阶段，不推荐）。</li>
<li>flink-table-api-java-bridge: 使用 Java 编程语言支持 DataStream/DataSet API 的 Table &amp; SQL API。</li>
<li>flink-table-api-scala-bridge: 使用 Scala 编程语言，支持 DataStream/DataSet API 的表和 SQL API。</li>
<li>flink-table-planner: 表程序 planner 和运行时。这是在 1.9 版本之前 Flink 唯一的 planner。从 Flink 1.11 开始，不再推荐使用它。</li>
<li>flink-table-planner-link: 新的 Blink 计划器，从 Flink 1.11 开始成为默认的。</li>
<li>flink-table-runtim-blink: 新的 Blink 运行时。</li>
<li>flink-table-uber: 将上面的 API 模块加上旧的规划器打包成一个适用于大多数 Table &amp; SQL API 使用案例的发行版。uber JAR 文件 <code>flink-table-*.jar</code> 默认位于 Flink 版本的 <code>/lib</code> 目录下。</li>
<li>flink-table-uber-blink: 将上面的 API 模块加上 Blink 的特定模块打包成一个适用于大多数 Table &amp; SQL API 用例的发行版。uber JAR 文件 <code>flink-table-blink-*.jar</code> 默认位于 Flink 版本的 <code>/lib</code> 目录下。</li>
</ul>
<p>关于如何在表程序中切换新旧 Blink planner，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">通用 API</a> 页面。</p>
<h3 id="表程序依赖">表程序依赖</h3>
<p>根据目标编程语言的不同，您需要将 Java 或 Scala API 添加到项目中，以便使用 Table API 和 SQL 来定义管道。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="c">&lt;!--</span><span class="c"> Either... </span><span class="c">--&gt;</span>
<span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-table-api-java-bridge_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!--</span><span class="c"> or... </span><span class="c">--&gt;</span>
<span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-table-api-scala-bridge_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>此外，如果你想在 IDE 中本地运行 Table API 和 SQL 程序，你必须添加以下一组模块，这取决于你想使用的计划器。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="c">&lt;!--</span><span class="c"> Either... (for the old planner that was available before Flink 1.9) </span><span class="c">--&gt;</span>
<span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-table-planner_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!--</span><span class="c"> or.. (for the new Blink planner) </span><span class="c">--&gt;</span>
<span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-table-planner-blink_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>在内部，表生态系统的部分内容是在 Scala 中实现的。因此，请确保为批处理和流应用添加以下依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-streaming-scala_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><h3 id="扩展依赖性">扩展依赖性</h3>
<p>如果你想实现与 Kafka 交互的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#define-a-tablefactory">自定义格式</a>或一组<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">用户定义的函数</a>，下面的依赖就足够了，可以用于 SQL 客户端的 JAR 文件。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-table-common<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;scope</span><span class="nt">&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>目前，该模块包括以下扩展点：</p>
<ul>
<li>SerializationSchemaFactory</li>
<li>DeserializationSchemaFactory</li>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h3 id="下一步怎么走">下一步怎么走？</h3>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">概念与通用 API</a>: Table API 和 SQL 的共享概念和 API。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>: 列出了预先定义的数据类型及其属性。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming">流概念</a>: 表 API 或 SQL 的流特定文档，如时间属性的配置和更新结果的处理。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接到外部系统</a>: 可用的连接器和格式，用于向外部系统读写数据。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a>。支持的操作和表 API 的 API。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL</a>。支持 SQL 的操作和语法。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/systemFunctions.html">内置函数</a>: 表 API 和 SQL 中支持的函数。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL 客户端</a>: 玩转 Flink SQL，并向集群提交表格程序，无需编程知识。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-use-statements/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-use-statements/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Use Statements</blockquote><h1 id="use-语句">USE 语句</h1>
<p>USE 语句用于设置当前数据库或目录。</p>
<h2 id="运行-use-语句">运行 USE 语句</h2>
<p>USE 语句可以通过 TableEnvironment 的 executeSql() 方法执行，也可以在 SQL CLI 中执行。executeSql() 方法会对一个成功的 USE 操作返回 &lsquo;OK&rsquo;， 否则会抛出一个异常。</p>
<p>下面的例子展示了如何在 TableEnvironment 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sqlClient.html">SQL CLI</a> 中运行一条 USE 语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// create a catalog
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE CATALOG cat1 WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW CATALOGS&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +-----------------+
</span><span class="c1"></span><span class="c1">// |    catalog name |
</span><span class="c1"></span><span class="c1">// +-----------------+
</span><span class="c1"></span><span class="c1">// | default_catalog |
</span><span class="c1"></span><span class="c1">// | cat1            |
</span><span class="c1"></span><span class="c1">// +-----------------+
</span><span class="c1"></span>
<span class="c1">// change default catalog
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;USE CATALOG cat1&#34;</span><span class="o">)</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// databases are empty
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// | database name |
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span>
<span class="c1">// create a database
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE DATABASE db1 WITH (...)&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SHOW DATABASES&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
<span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// | database name |
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span><span class="c1">// |        db1    |
</span><span class="c1"></span><span class="c1">// +---------------+
</span><span class="c1"></span>
<span class="c1">// change default database
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;USE db1&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="use-catloag">USE CATLOAG</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">USE</span> <span class="k">CATALOG</span> <span class="k">catalog_name</span>
</code></pre></div><p>设置当前目录。所有没有明确指定目录的后续命令将使用这个目录。如果所提供的目录不存在，则会抛出一个异常。默认的当前目录是default_catalog。</p>
<h2 id="use">USE</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">USE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="n">database_name</span>
</code></pre></div><p>设置当前数据库。所有没有明确指定数据库的后续命令将使用这个数据库。如果提供的数据库不存在，则会抛出一个异常。默认的当前数据库是default_database。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/use.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[临时表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-temporal-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Temporal Tables</blockquote><h1 id="时间表">时间表</h1>
<p>时间表代表了对变化表的（参数化）视图的概念，该视图返回一个表在特定时间点的内容。</p>
<p>变化表可以是跟踪变化的变化历史表（如数据库变化日志），也可以是将变化具体化的变化维度表（如数据库表）。</p>
<p>对于变化的历史表，Flink 可以跟踪变化，并允许在查询中的某个时间点访问表的内容。在 Flink 中，这种表用 Temporal Table Function 来表示。</p>
<p>对于变化的维度表，Flink 允许在查询内的处理时间点访问表的内容。在 Flink 中，这种表是由一个 Temporal Table 来表示的。</p>
<h2 id="动机">动机</h2>
<h3 id="与不断变化的历史表相关联">与不断变化的历史表相关联</h3>
<p>假设我们有以下表格 RatesHistory。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">RatesHistory</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">15</span>   <span class="n">Euro</span>        <span class="mi">119</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">49</span>   <span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>RatesHistory 代表了一个不断增长的对日元（汇率为 1）的货币汇率附加表。例如，从 09:00 到 10:45，欧元对日元的汇率是 114，从 10:45 到 11:15 是 116。从 10:45 到 11:15 是 116。</p>
<p>考虑到我们希望输出 10:58 时的所有当前汇率，我们将需要以下 SQL 查询来计算结果表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">=</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span>
  <span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r2</span>
  <span class="k">WHERE</span> <span class="n">r2</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span>
  <span class="k">AND</span> <span class="n">r2</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">&lt;</span><span class="o">=</span> <span class="n">TIME</span> <span class="s1">&#39;</span><span class="s1">10:58</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">;</span>
</code></pre></div><p>相关子查询确定相应货币的最大时间低于或等于期望时间。外层查询列出具有最大时间戳的汇率。</p>
<p>下表显示了这种计算的结果。在我们的例子中，10:45 的欧元更新被考虑在内，然而，11:15 的欧元更新和新输入的英镑在 10:58 的表格中没有被考虑。</p>
<pre><code>rowtime currency   rate
======= ======== ======
09:00   US Dollar   102
09:00   Yen           1
10:45   Euro        116
</code></pre><p>Temporal Tables 的概念旨在简化此类查询，加快其执行速度，并减少 Flink 的状态使用。Temporal Table 是一个关于 append-only 表的参数化视图，它将 append-only 表的行解释为表的 changelog，并提供该表在特定时间点的版本。将 append-only 表解释为变更日志需要指定一个主键属性和一个时间戳属性。主键决定哪些行会被覆盖，时间戳决定行的有效时间。</p>
<p>在上面的例子中，currency 是 RatesHistory 表的主键，rowtime 是时间戳属性。</p>
<p>在 Flink 中，这是由一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-function">Temporal Table Function</a> 来表示的。</p>
<h3 id="与变化的维度表相关联">与变化的维度表相关联</h3>
<p>另一方面，有些用例需要加入一个不断变化的维度表，而这个表是一个外部数据库表。</p>
<p>让我们假设 LatestRates 是一张表（例如存储在），它是以最新的速率来物化的。LatestRates 是物化的历史 RatesHistory。那么 LatestRates 表在时间 10:58 时的内容将是。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">10</span><span class="p">:</span><span class="mi">58</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>
<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Yen</span>           <span class="mi">1</span>
<span class="n">Euro</span>        <span class="mi">116</span>
</code></pre></div><p>12:00 时 LatestRates 表的内容将是：</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">12</span><span class="p">:</span><span class="mi">00</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>
<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Yen</span>           <span class="mi">1</span>
<span class="n">Euro</span>        <span class="mi">119</span>
<span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>在 Flink 中，这用一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>来表示。</p>
<h2 id="时间表函数">时间表函数</h2>
<p>为了访问时态表中的数据，必须传递一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>，该属性决定了将返回的表的版本。Flink 使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html#table-functions">表函数</a>的 SQL 语法来提供一种表达方式。</p>
<p>一旦定义好，一个时态表函数就会接受一个单一的时间参数 timeAttribute，并返回一组行。这个集合包含了所有现有主键相对于给定时间属性的最新版本的行。</p>
<p>假设我们基于 RatesHistory 表定义了一个时态表函数 <code>Rates(timeAttribute)</code>，我们可以用下面的方式查询这样的函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Rates</span><span class="p">(</span><span class="s1">&#39;</span><span class="s1">10:15</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Rates</span><span class="p">(</span><span class="s1">&#39;</span><span class="s1">11:00</span><span class="s1">&#39;</span><span class="p">)</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>每次查询 <code>Rates(timeAttribute)</code> 都会返回给定时间属性的 Rates 的状态。</p>
<p>注意：目前，Flink 不支持直接查询带有恒定时间属性参数的时态表函数。目前，时态表函数只能用于连接。上面的例子是用来提供对函数 <code>Rates(timeAttribute)</code> 返回内容的直观认识。</p>
<p>关于如何使用时态表进行联接的更多信息，还请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询的连接</a>页面。</p>
<h2 id="定义时态表函数">定义时态表函数</h2>
<p>下面的代码片段说明了如何从一个仅有追加的表创建一个时态表函数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Get the stream and table environments.
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Provide a static data set of the rates history table.
</span><span class="c1"></span><span class="k">val</span> <span class="n">ratesHistoryData</span> <span class="k">=</span> <span class="k">new</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">MutableList</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span><span class="o">]</span>
<span class="n">ratesHistoryData</span><span class="o">.</span><span class="o">+=</span><span class="o">(</span><span class="o">(</span><span class="s">&#34;US Dollar&#34;</span><span class="o">,</span> <span class="mi">102L</span><span class="o">)</span><span class="o">)</span>
<span class="n">ratesHistoryData</span><span class="o">.</span><span class="o">+=</span><span class="o">(</span><span class="o">(</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">114L</span><span class="o">)</span><span class="o">)</span>
<span class="n">ratesHistoryData</span><span class="o">.</span><span class="o">+=</span><span class="o">(</span><span class="o">(</span><span class="s">&#34;Yen&#34;</span><span class="o">,</span> <span class="mi">1L</span><span class="o">)</span><span class="o">)</span>
<span class="n">ratesHistoryData</span><span class="o">.</span><span class="o">+=</span><span class="o">(</span><span class="o">(</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">116L</span><span class="o">)</span><span class="o">)</span>
<span class="n">ratesHistoryData</span><span class="o">.</span><span class="o">+=</span><span class="o">(</span><span class="o">(</span><span class="s">&#34;Euro&#34;</span><span class="o">,</span> <span class="mi">119L</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// Create and register an example table using above data set.
</span><span class="c1"></span><span class="c1">// In the real setup, you should replace this with your own table.
</span><span class="c1"></span><span class="k">val</span> <span class="n">ratesHistory</span> <span class="k">=</span> <span class="n">env</span>
  <span class="o">.</span><span class="n">fromCollection</span><span class="o">(</span><span class="n">ratesHistoryData</span><span class="o">)</span>
  <span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> &#39;r_currency<span class="o">,</span> &#39;r_rate<span class="o">,</span> &#39;r_proctime<span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;RatesHistory&#34;</span><span class="o">,</span> <span class="n">ratesHistory</span><span class="o">)</span>

<span class="c1">// Create and register TemporalTableFunction.
</span><span class="c1"></span><span class="c1">// Define &#34;r_proctime&#34; as the time attribute and &#34;r_currency&#34; as the primary key.
</span><span class="c1"></span><span class="k">val</span> <span class="n">rates</span> <span class="k">=</span> <span class="n">ratesHistory</span><span class="o">.</span><span class="n">createTemporalTableFunction</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;r_proctime&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;r_currency&#34;</span><span class="o">)</span> <span class="c1">// &lt;==== (1)
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerFunction</span><span class="o">(</span><span class="s">&#34;Rates&#34;</span><span class="o">,</span> <span class="n">rates</span><span class="o">)</span>                                          <span class="c1">// &lt;==== (2)
</span></code></pre></div><p>第(1)行创建了一个 Rates <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时态表函数</a>，这使得我们可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 中的函数 Rates。</p>
<p>第(2)行在我们的表环境中以 Rates 的名义注册这个函数，这使得我们可以在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 中使用 Rates 函数。</p>
<h2 id="时态表">时态表</h2>
<p>注意: 这只在 Blink planner 中支持。</p>
<p>为了访问时间表中的数据，目前必须定义一个 LookupableTableSource 的 TableSource。Flink 使用 SQL:2011 中提出的 SQL 语法 FOR SYSTEM_TIME AS OF 来查询时间表。</p>
<p>假设我们定义了一个名为 LatestRates 的时态表，我们可以用下面的方式查询这样的表。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">TIME</span> <span class="s1">&#39;</span><span class="s1">10:15</span><span class="s1">&#39;</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">TIME</span> <span class="s1">&#39;</span><span class="s1">11:00</span><span class="s1">&#39;</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">116</span>
<span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>注意：目前，Flink 不支持直接查询时间恒定的时态表。目前，时态表只能用在 join 中。上面的例子是用来提供一个直观的时间表 LatestRates 返回的内容。</p>
<p>更多关于如何使用时态表进行连接的信息，请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询的连接</a>页面。</p>
<h2 id="定义时态表">定义时态表</h2>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Get the stream and table environments.
</span><span class="c1"></span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">,</span> <span class="n">settings</span><span class="o">)</span>
<span class="c1">// or val tEnv = TableEnvironment.create(settings)
</span><span class="c1"></span>
<span class="c1">// Define an HBase table with DDL, then we can use it as a temporal table in sql
</span><span class="c1"></span><span class="c1">// Column &#39;currency&#39; is the rowKey in HBase table
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
    <span class="s">s&#34;&#34;&#34;</span><span class="s">
</span><span class="s">       |CREATE TABLE LatestRates (
</span><span class="s">       |    currency STRING,
</span><span class="s">       |    fam1 ROW&lt;rate DOUBLE&gt;
</span><span class="s">       |) WITH (
</span><span class="s">       |    &#39;connector&#39; = &#39;hbase-1.4&#39;,
</span><span class="s">       |    &#39;table-name&#39; = &#39;Rates&#39;,
</span><span class="s">       |    &#39;zookeeper.quorum&#39; = &#39;localhost:2181&#39;
</span><span class="s">       |)
</span><span class="s">       |</span><span class="s">&#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><p>也请参见如何定义 LookupableTableSource 的页面。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/?utm_source=atom_feed" rel="related" type="text/html" title="用户定义函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Functions</blockquote><h1 id="函数">函数</h1>
<p>Flink Table API &amp; SQL 使用户能够通过函数进行数据转换。</p>
<h2 id="函数的类型">函数的类型</h2>
<p>Flink 中的函数有两个维度来分类。</p>
<p>一个维度是系统（或内置）函数 v.s. 目录函数。系统函数没有命名空间，可以只用名字来引用。目录函数属于目录和数据库，因此它们有目录和数据库的命名空间，它们可以用完全/部分限定名（<code>catalog.db.func</code> 或 <code>db.func</code>）或者只用函数名来引用。</p>
<p>另一个维度是临时函数 v.s. 持久化函数。临时函数是不稳定的，只存在于一个会话的生命周期内，它们总是由用户创建的。而持久性函数则是在会话的生命周期内存在的，它们要么是由系统提供的，要么是在目录中持久存在的。</p>
<p>这两个维度给 Flink 用户提供了4类函数。</p>
<ol>
<li>临时系统函数</li>
<li>系统函数</li>
<li>临时目录函数</li>
<li>目录函数</li>
</ol>
<h2 id="引用函数">引用函数</h2>
<p>在 Flink 中，用户有两种引用函数的方式 - 精确引用函数或模棱两可的引用函数。</p>
<h3 id="精确的函数引用">精确的函数引用</h3>
<p>精确的函数引用使用户能够专门使用目录函数，并且跨目录和跨数据库，例如从 <code>mytable</code> 中选择 <code>mycatalog.mydb.myfunc(x)</code>，从 <code>mytable</code> 中选择 <code>mydb.myfunc(x)</code>。</p>
<p>这只从 Flink 1.10 开始支持。</p>
<h3 id="模棱两可的函数引用">模棱两可的函数引用</h3>
<p>在模棱两可的函数引用中，用户只需在 SQL 查询中指定函数名称即可，例如：<code>select myfunc(x) from mytable</code>。</p>
<h2 id="函数解析顺序">函数解析顺序</h2>
<p>只有当有不同类型但名称相同的函数时，解析顺序才是重要的，比如有三个函数都名为 &ldquo;myfunc&rdquo;，但分别是临时目录、目录和系统函数。如果没有函数名冲突，则函数将被解析为唯一的一个。</p>
<h3 id="精确的函数引用-1">精确的函数引用</h3>
<p>因为系统函数没有命名空间，所以 Flink 中的精确函数引用必须指向临时目录函数或目录函数。</p>
<p>其解析顺序是：</p>
<ol>
<li>临时目录函数</li>
<li>目录函数</li>
</ol>
<h3 id="含糊不清的函数参考">含糊不清的函数参考</h3>
<p>解析顺序是:</p>
<ol>
<li>临时系统函数</li>
<li>系统函数</li>
<li>临时目录函数，在当前目录和当前数据库中的会话。</li>
<li>目录函数，在当前目录和当前数据库中的会话。</li>
</ol>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/function" term="function" label="Function" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[动态表]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Dynamic Tables</blockquote><h1 id="动态表">动态表</h1>
<p>SQL 和关系代数在设计时并没有考虑到流数据。因此，关系代数（和 SQL）和流处理之间几乎没有概念上的差距。</p>
<p>本页讨论了这些差异，并解释了 Flink 如何在无界数据上实现与常规数据库引擎在有界数据上相同的语义。</p>
<h2 id="数据流的关系查询">数据流的关系查询</h2>
<p>下表比较了传统的关系代数和流处理在输入数据、执行和输出结果方面的情况。</p>
<table>
<thead>
<tr>
<th align="left">关系代数/SQL</th>
<th align="left">流处理</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">关系（或表）是有界（多）元组的集合。</td>
<td align="left">流是一个无限的元组序列。</td>
</tr>
<tr>
<td align="left">在批数据上执行的查询（如关系数据库中的表）可以访问完整的输入数据。</td>
<td align="left">流式查询在启动时不能访问所有的数据，必须&quot;等待&quot;数据流进来。</td>
</tr>
<tr>
<td align="left">批量查询在产生一个固定大小的结果后就会终止。</td>
<td align="left">流式查询根据接收到的记录不断地更新其结果，并且永远不会完成。</td>
</tr>
</tbody>
</table>
<p>尽管存在这些差异，但用关系查询和 SQL 处理流并不是不可能的。先进的关系数据库系统提供了一种叫做物化视图的功能。物化视图被定义为一个 SQL 查询，就像一个普通的虚拟视图一样。与虚拟视图不同，物化视图会缓存查询的结果，这样在访问视图时就不需要对查询进行评估。缓存的一个常见挑战是防止缓存提供过时的结果。当其定义查询的基表被修改时，一个物化视图就会过时。急切的视图维护是一种技术，它可以在更新基表时立即更新一个物化视图。</p>
<p>如果我们考虑以下几点，急切的视图维护和流上的 SQL 查询之间的联系就会变得很明显。</p>
<ul>
<li>数据库表是一个 INSERT、UPDATE 和 DELETE DML 语句流的结果，通常称为 changelog 流。</li>
<li>物化视图被定义为一个 SQL 查询。为了更新视图，查询不断处理视图的基础关系的 changelog 流。</li>
<li>物化视图是流式 SQL 查询的结果。</li>
</ul>
<p>考虑到这些要点，我们在下一节介绍以下动态表的概念。</p>
<h2 id="动态表与连续查询">动态表与连续查询</h2>
<p>动态表是 Flink 的表 API 和 SQL 支持流数据的核心概念。与代表批处理数据的静态表相比，动态表是随时间变化的。它们可以像静态批处理表一样被查询。查询动态表会产生一个连续查询。一个连续查询永远不会终止，并产生一个动态表作为结果。查询不断地更新它的（动态）结果表，以反映其（动态）输入表的变化。本质上，对动态表的连续查询与定义物化视图的查询非常相似。</p>
<p>需要注意的是，连续查询的结果在语义上总是等同于在输入表的快照上以批处理模式执行相同查询的结果。</p>
<p>下图直观地展示了流、动态表和连续查询的关系。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/stream-query-stream.png" alt="img"></p>
<ol>
<li>一个流被转换为一个动态表。</li>
<li>对动态表进行连续查询，得到一个新的动态表。</li>
<li>产生的动态表又被转换回流。</li>
</ol>
<p>注意：动态表首先是一个逻辑概念。动态表在查询执行过程中不一定（完全）实体化。</p>
<p>在下文中，我们将解释动态表和连续查询的概念，其点击事件流的模式如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">[</span>
  <span class="err">u</span><span class="err">s</span><span class="err">e</span><span class="err">r</span><span class="err">:</span>  <span class="err">V</span><span class="err">A</span><span class="err">R</span><span class="err">C</span><span class="err">H</span><span class="err">A</span><span class="err">R</span><span class="p">,</span>   <span class="err">/</span><span class="err">/</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">n</span><span class="err">a</span><span class="err">m</span><span class="err">e</span> <span class="err">o</span><span class="err">f</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">u</span><span class="err">s</span><span class="err">e</span><span class="err">r</span>
  <span class="err">c</span><span class="err">T</span><span class="err">i</span><span class="err">m</span><span class="err">e</span><span class="err">:</span> <span class="err">T</span><span class="err">I</span><span class="err">M</span><span class="err">E</span><span class="err">S</span><span class="err">T</span><span class="err">A</span><span class="err">M</span><span class="err">P</span><span class="p">,</span> <span class="err">/</span><span class="err">/</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">t</span><span class="err">i</span><span class="err">m</span><span class="err">e</span> <span class="err">w</span><span class="err">h</span><span class="err">e</span><span class="err">n</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">U</span><span class="err">R</span><span class="err">L</span> <span class="err">w</span><span class="err">a</span><span class="err">s</span> <span class="err">a</span><span class="err">c</span><span class="err">c</span><span class="err">e</span><span class="err">s</span><span class="err">s</span><span class="err">e</span><span class="err">d</span>
  <span class="err">u</span><span class="err">r</span><span class="err">l</span><span class="err">:</span>   <span class="err">V</span><span class="err">A</span><span class="err">R</span><span class="err">C</span><span class="err">H</span><span class="err">A</span><span class="err">R</span>    <span class="err">/</span><span class="err">/</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">U</span><span class="err">R</span><span class="err">L</span> <span class="err">t</span><span class="err">h</span><span class="err">a</span><span class="err">t</span> <span class="err">w</span><span class="err">a</span><span class="err">s</span> <span class="err">a</span><span class="err">c</span><span class="err">c</span><span class="err">e</span><span class="err">s</span><span class="err">s</span><span class="err">e</span><span class="err">d</span> <span class="err">b</span><span class="err">y</span> <span class="err">t</span><span class="err">h</span><span class="err">e</span> <span class="err">u</span><span class="err">s</span><span class="err">e</span><span class="err">r</span>
<span class="p">]</span>
</code></pre></div><h2 id="在流上定义一个表">在流上定义一个表</h2>
<p>为了用关系查询来处理一个流，必须把它转换成一个表。从概念上讲，流的每一条记录都被解释为对生成的表进行 INSERT 修改。从本质上讲，我们是从一个仅有 INSERT 的 changelog 流建立一个表。</p>
<p>下图直观地展示了点击事件流（左手边）是如何转换为表（右手边）的。随着更多的点击流记录被插入，生成的表在不断增长。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/append-mode.png" alt="img"></p>
<p>注意：一个定义在流上的表在内部是不被实现的。</p>
<h3 id="连续查询">连续查询</h3>
<p>连续查询是在动态表上进行评估，并生成一个新的动态表作为结果。与批处理查询不同，连续查询永远不会终止，并根据输入表的更新更新其结果表。在任何时间点上，连续查询的结果在语义上等同于在输入表的快照上以批处理模式执行相同查询的结果。</p>
<p>在下面我们展示了在点击事件流上定义的点击表上的两个查询示例。</p>
<p>第一个查询是一个简单的 GROUP-BY COUNT 聚合查询。它对用户字段的点击表进行分组，并统计访问的 URL 数量。下图显示了当点击表更新了更多的行时，查询是如何随着时间的推移进行评估的。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/query-groupBy-cnt.png" alt="img"></p>
<p>查询开始时，点击表（左侧）为空。当第一条记录被插入到 clicks 表中时，查询开始计算结果表。插入第一行 <code>[Mary, ./home]</code> 后，结果表（右侧，顶部）由一条行 <code>[Mary, 1]</code> 组成。当第二条记录 <code>[Bob, ./cart]</code> 插入点击表后，查询更新结果表，插入一条新的记录 <code>[Bob, 1]</code>。第三条记录 <code>[Mary, ./prod?id=1]</code> 产生对已经计算好的结果行的更新，这样 <code>[Mary, 1]</code> 就更新为 <code>[Mary, 2]</code>。最后，查询将第三条记录 <code>[Liz，1]</code> 插入到结果表中，这时第四条记录被追加到点击表中。</p>
<p>第二个查询与第一个查询类似，但将点击表除了用户属性也分组在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">一个小时滚动窗口</a>上，然后再统计 URL 的数量（窗口等基于时间的计算是基于特殊的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>，后面会讨论）。同样，图中显示了不同时间点的输入和输出，以直观地显示动态表的变化性质。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/query-groupBy-window-cnt.png" alt="img"></p>
<p>和以前一样，输入表的点击率在左边显示。查询每隔一小时持续计算结果并更新结果表。clicks 表包含四条记录，时间戳（cTime）在 12:00:00 和 12:59:59 之间。查询从这个输入中计算出两条结果行（每个用户一条），并将它们追加到结果表中。对于 13:00:00 和 13:59:59 之间的下一个窗口，点击表包含三条记录，结果是另外两条记录被追加到结果表中。随着时间的推移，更多的行被追加到点击表中，结果表会被更新。</p>
<h3 id="更新和追加查询">更新和追加查询</h3>
<p>虽然这两个例子查询看起来很相似（都是计算一个分组计数合计），但它们在一个重要方面有所不同。</p>
<ul>
<li>第一个查询更新了之前发出的结果，即定义结果表的 changelog 流包含了 INSERT 和 UPDATE 变化。</li>
<li>第二个查询只对结果表进行追加，即结果表的 changelog 流只包含 insert 更改。</li>
</ul>
<p>查询产生的是只追加表还是更新表有一定的影响。</p>
<ul>
<li>产生更新变化的查询通常要维护更多的状态（见下节）。</li>
<li>将仅有附录的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html#table-to-stream-conversion">表转换为流</a>与更新表的转换是不同的（参见表到流的转换部分）。</li>
</ul>
<h3 id="查询限制">查询限制</h3>
<p>许多（但不是全部）语义有效的查询可以作为流上的连续查询来评估。有些查询的计算成本太高，要么是由于它们需要维护的状态大小，要么是由于计算更新太贵。</p>
<ul>
<li>状态大小。连续查询是在无边界的流上进行评估的，通常应该运行数周或数月。因此，一个连续查询处理的数据总量可能非常大。必须更新之前发出的结果的查询需要维护所有发出的行，以便能够更新它们。例如，第一个示例查询需要存储每个用户的 URL 计数，以便能够增加计数，并在输入表收到新行时发出新结果。如果只跟踪注册用户，需要维护的计数数量可能不会太高。但是，如果非注册用户被分配了一个唯一的用户名，那么需要维护的次数会随着时间的推移而增加，最终可能会导致查询失败。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">clicks</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">user</span><span class="p">;</span>
</code></pre></div><ul>
<li>计算更新。有些查询需要重新计算和更新大部分发出的结果行，即使只增加或更新一条输入记录。显然，这种查询并不适合作为连续查询来执行。一个例子是下面的查询，它根据最后一次点击的时间为每个用户计算一个 rank。只要点击表收到一条新的记录，该用户的 lastAction 就会被更新，必须计算新的 rank。但是由于两行不能有相同的 rank，所以所有排名较低的行也需要更新。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">RANK</span><span class="p">(</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">lastLogin</span><span class="p">)</span>
<span class="k">FROM</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">MAX</span><span class="p">(</span><span class="n">cTime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">lastAction</span> <span class="k">FROM</span> <span class="n">clicks</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="k">user</span>
<span class="p">)</span><span class="p">;</span>
</code></pre></div><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>页面讨论了控制连续查询执行的参数。有些参数可用于以维护状态的大小来换取结果的准确性。</p>
<h2 id="表到流的转换">表到流的转换</h2>
<p>动态表可以像普通的数据库表一样，通过 INSERT、UPDATE 和 DELETE 的修改不断地进行修改。它可能是一张只有一行的表，不断地更新，也可能是一张只有插入的表，没有 UPDATE 和 DELETE 的修改，或者是介于两者之间的任何表。</p>
<p>当把动态表转换为流或写入外部系统时，需要对这些变化进行编码。Flink 的表 API 和 SQL 支持三种方式来编码动态表的变化。</p>
<ul>
<li>
<p>只添加流。一个只被 INSERT 修改的动态表，可以通过发出插入的行来转换成流。</p>
</li>
<li>
<p>撤回流。缩回流是指有两种消息的流，即添加消息和缩回消息。通过将 INSERT 变更编码为添加消息，将 DELETE 变更编码为回撤消息，将 UPDATE 变更编码为更新（上一条）行的回撤消息和更新（新一条）行的添加消息，就可以将一张动态表转换为回撤流。下图直观地展示了动态表转换为回撤流的过程。</p>
</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/undo-redo-mode.png" alt="img"></p>
<ul>
<li>Upsert 流。Upsert 流是一个有两种消息类型的流，即 upsert 消息和删除消息。一个动态表被转换为 upsert 流需要一个（可能是复合的）唯一键。通过将 INSERT 和 UPDATE 更改编码为 upsert 消息，将 DELETE 更改编码为 delete 消息，将具有唯一键的动态表转换为流。消耗流的操作者需要知道唯一键属性，以便正确应用消息。与 retract 流的主要区别在于 update 变更用一条消息进行编码，因此效率更高。下图直观地展示了动态表转换为 update 流的过程。</li>
</ul>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/table-streaming/redo-mode.png" alt="img"></p>
<p>将动态表转换为 DataStream 的 API 在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#convert-a-table-into-a-datastream">通用概念</a>页面上讨论。请注意，在将动态表转换为 DataStream 时，只支持追加和收回流。在 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#define-a-tablesink">TableSources 和 TableSinks</a> 页面上讨论了将动态表发射到外部系统的 TableSink 接口。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[时间属性]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-time-attributes/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Time Attributes</blockquote><h1 id="时间属性">时间属性</h1>
<p>Flink 能够根据不同的时间概念来处理流数据。</p>
<ul>
<li>处理时间是指正在执行相应操作的机器的系统时间（也称为&quot;挂钟时间&rdquo;）。</li>
<li>事件时间指的是基于时间戳对流媒体数据的处理，时间戳附加在每一行上。时间戳可以编码事件发生的时间。</li>
<li>摄取时间是事件进入 Flink 的时间；在内部，它的处理方式与事件时间类似。</li>
</ul>
<p>关于 Flink 中时间处理的更多信息，请参见关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">事件时间和水印</a>的介绍。</p>
<p>本页解释了如何在 Flink 的表 API 和 SQL 中为基于时间的操作定义时间属性。</p>
<h2 id="时间属性介绍">时间属性介绍</h2>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#group-windows">Table API</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">SQL</a> 中的窗口等基于时间的操作都需要时间概念及其来源的信息。因此，表可以提供逻辑时间属性，用于指示时间和在表程序中访问相应的时间戳。</p>
<p>时间属性可以成为每个表模式的一部分。它们是在从 CREATE TABLE DDL 或 DataStream 创建表时定义的，或者是在使用 TableSource 时预先定义的。一旦在开始时定义了时间属性，它就可以作为一个字段被引用，并且可以在基于时间的操作中使用。</p>
<p>只要时间属性没有被修改，只是从查询的一个部分转发到另一个部分，它仍然是一个有效的时间属性。时间属性的行为就像常规的时间戳一样，可以被访问进行计算。如果在计算中使用了时间属性，它将被具体化并成为常规时间戳。常规时间戳不与 Flink 的时间和水印系统合作，因此不能再用于基于时间的操作。</p>
<p>表程序要求已经为流环境指定了相应的时间特征。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="n">env</span><span class="o">.</span><span class="n">setStreamTimeCharacteristic</span><span class="o">(</span><span class="nc">TimeCharacteristic</span><span class="o">.</span><span class="nc">ProcessingTime</span><span class="o">)</span> <span class="c1">// default
</span><span class="c1"></span>
<span class="c1">// alternatively:
</span><span class="c1"></span><span class="c1">// env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)
</span><span class="c1"></span><span class="c1">// env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
</span></code></pre></div><h2 id="处理时间">处理时间</h2>
<p>处理时间允许表程序根据本地机器的时间产生结果。它是最简单的时间概念，但不提供确定性。它既不需要提取时间戳，也不需要生成水印。</p>
<p>有三种方法可以定义处理时间属性。</p>
<h3 id="在创建表-ddl-中定义">在创建表 DDL 中定义</h3>
<p>处理时间属性是在创建表 DDL 中使用系统 PROCTIME()函数定义为计算列。关于计算列的更多信息请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html#create-table">CREATE TABLE DDL</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">user_actions</span> <span class="p">(</span>
  <span class="n">user_name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="k">data</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">user_action_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">(</span><span class="p">)</span> <span class="c1">-- declare an additional field as a processing time attribute
</span><span class="c1"></span><span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
  <span class="p">.</span><span class="p">.</span><span class="p">.</span>
<span class="p">)</span><span class="p">;</span>

<span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">10</span><span class="s1">&#39;</span> <span class="k">MINUTE</span><span class="p">)</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_name</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">user_actions</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">10</span><span class="s1">&#39;</span> <span class="k">MINUTE</span><span class="p">)</span><span class="p">;</span>
</code></pre></div><h3 id="在-datastream-to-table-转换期间">在 DataStream-to-Table 转换期间</h3>
<p>处理时间属性是在模式定义过程中用 <code>.proctime</code> 属性定义的。时间属性只能通过一个额外的逻辑字段来扩展物理模式。因此，它只能在模式定义的最后定义。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// declare an additional logical field as a processing time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;UserActionTimestamp&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="使用-table-source">使用 Table Source</h3>
<p>处理时间属性由实现 <code>DefinedProctimeAttribute</code> 接口的 <code>TableSource</code> 定义。逻辑时间属性附加到由 <code>TableSource</code> 的返回类型定义的物理模式中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// define a table source with a processing attribute
</span><span class="c1"></span><span class="k">class</span> <span class="nc">UserActionSource</span> <span class="k">extends</span> <span class="nc">StreamTableSource</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">with</span> <span class="nc">DefinedProctimeAttribute</span> <span class="o">{</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getReturnType</span> <span class="k">=</span> <span class="o">{</span>
		<span class="k">val</span> <span class="n">names</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span><span class="o">(</span><span class="s">&#34;user_name&#34;</span> <span class="o">,</span> <span class="s">&#34;data&#34;</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">types</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]</span><span class="o">]</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">)</span>
		<span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="n">names</span><span class="o">,</span> <span class="n">types</span><span class="o">)</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getDataStream</span><span class="o">(</span><span class="n">execEnv</span><span class="k">:</span> <span class="kt">StreamExecutionEnvironment</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// create stream
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>
		<span class="n">stream</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getProctimeAttribute</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// field with this name will be appended as a third field
</span><span class="c1"></span>		<span class="s">&#34;user_action_time&#34;</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="c1">// register table source
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">UserActionSource</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">tEnv</span>
	<span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="事件时间">事件时间</h3>
<p>事件时间允许表格程序根据每条记录中包含的时间产生结果。这使得即使在事件失序或事件迟到的情况下，也能得到一致的结果。当从持久存储中读取记录时，它还能保证表程序的结果可重放。</p>
<p>此外，事件时间允许在批处理和流环境中对表程序进行统一的语法。流式环境中的时间属性可以是批处理环境中记录的常规字段。</p>
<p>为了处理失序事件，区分流式环境中事件的准时和迟到，Flink 需要从事件中提取时间戳，并在时间上做出某种进展（所谓的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">水印</a>）。</p>
<p>事件时间属性既可以在创建表 DDL 中定义，也可以在 DataStream 到表的转换过程中定义，或者使用 TableSource 定义。</p>
<h3 id="在创建表-ddl-中定义-1">在创建表 DDL 中定义</h3>
<p>事件时间属性是在 CREATE TABLE DDL 中使用 WATERMARK 语句定义的。水印语句在现有的事件时间字段上定义了一个水印生成表达式，将事件时间字段标记为事件时间属性。关于水印语句和水印策略的更多信息，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/create.html#create-table">CREATE TABLE DDL</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">user_actions</span> <span class="p">(</span>
  <span class="n">user_name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="k">data</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">user_action_time</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="p">,</span>
  <span class="c1">-- declare user_action_time as event time attribute and use 5 seconds delayed watermark strategy
</span><span class="c1"></span>  <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">user_action_time</span> <span class="k">AS</span> <span class="n">user_action_time</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">5</span><span class="s1">&#39;</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
  <span class="p">.</span><span class="p">.</span><span class="p">.</span>
<span class="p">)</span><span class="p">;</span>

<span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">10</span><span class="s1">&#39;</span> <span class="k">MINUTE</span><span class="p">)</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_name</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">user_actions</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">user_action_time</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">10</span><span class="s1">&#39;</span> <span class="k">MINUTE</span><span class="p">)</span><span class="p">;</span>
</code></pre></div><h3 id="在-datastream-to-table-转换期间-1">在 DataStream-to-Table 转换期间</h3>
<p>事件时间属性是在模式定义期间用 <code>.rowtime</code> 属性定义的。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">时间戳和水印</a>必须在被转换的 DataStream 中被分配。</p>
<p>在将 DataStream 转换为表时，有两种方法可以定义时间属性。根据指定的.rowtime 字段名是否存在于 DataStream 的模式中，时间戳字段要么是</p>
<ul>
<li>作为一个新的字段添加到模式中，或</li>
<li>替换一个现有的字段。</li>
</ul>
<p>无论哪种情况，事件时间戳字段都将持有 DataStream 事件时间戳的值。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Option 1:
</span><span class="c1"></span>
<span class="c1">// extract timestamp and assign watermarks based on knowledge of the stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// declare an additional logical field as an event time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>


<span class="c1">// Option 2:
</span><span class="c1"></span>
<span class="c1">// extract timestamp from first field, and assign watermarks based on knowledge of the stream
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// the first field has been used for timestamp extraction, and is no longer necessary
</span><span class="c1"></span><span class="c1">// replace first field with a logical event time attribute
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;data&#34;</span><span class="o">)</span>

<span class="c1">// Usage:
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="使用-tablesource">使用 TableSource</h2>
<p>事件时间属性由一个实现 <code>DefinedRowtimeAttributes</code> 接口的 <code>TableSource</code> 定义。<code>getRowtimeAttributeDescriptors()</code> 方法返回一个 <code>RowtimeAttributeDescriptor</code> 列表，用于描述时间属性的最终名称，一个用于导出属性值的时间戳提取器，以及与属性相关的水印策略。</p>
<p>请确保 <code>getDataStream()</code> 方法返回的 DataStream 与定义的时间属性一致。只有当定义了 StreamRecordTimestamp 时间戳提取器时，才会考虑 DataStream 的时间戳（由 TimestampAssigner 分配的时间戳）。只有定义了 PreserveWatermarks 水印策略，DataStream 的水印才会被保留。否则，只有 TableSource 的 rowtime 属性的值是相关的。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// define a table source with a rowtime attribute
</span><span class="c1"></span><span class="k">class</span> <span class="nc">UserActionSource</span> <span class="k">extends</span> <span class="nc">StreamTableSource</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">with</span> <span class="nc">DefinedRowtimeAttributes</span> <span class="o">{</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getReturnType</span> <span class="k">=</span> <span class="o">{</span>
		<span class="k">val</span> <span class="n">names</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span><span class="o">(</span><span class="s">&#34;user_name&#34;</span> <span class="o">,</span> <span class="s">&#34;data&#34;</span><span class="o">,</span> <span class="s">&#34;user_action_time&#34;</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">types</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]</span><span class="o">]</span><span class="o">(</span><span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span><span class="o">)</span>
		<span class="nc">Types</span><span class="o">.</span><span class="nc">ROW</span><span class="o">(</span><span class="n">names</span><span class="o">,</span> <span class="n">types</span><span class="o">)</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getDataStream</span><span class="o">(</span><span class="n">execEnv</span><span class="k">:</span> <span class="kt">StreamExecutionEnvironment</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// create stream
</span><span class="c1"></span>		<span class="c1">// ...
</span><span class="c1"></span>		<span class="c1">// assign watermarks based on the &#34;user_action_time&#34; attribute
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">stream</span> <span class="k">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
		<span class="n">stream</span>
	<span class="o">}</span>

	<span class="k">override</span> <span class="k">def</span> <span class="n">getRowtimeAttributeDescriptors</span><span class="k">:</span> <span class="kt">util.List</span><span class="o">[</span><span class="kt">RowtimeAttributeDescriptor</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
		<span class="c1">// Mark the &#34;user_action_time&#34; attribute as event-time attribute.
</span><span class="c1"></span>		<span class="c1">// We create one attribute descriptor of &#34;user_action_time&#34;.
</span><span class="c1"></span>		<span class="k">val</span> <span class="n">rowtimeAttrDescr</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RowtimeAttributeDescriptor</span><span class="o">(</span>
			<span class="s">&#34;user_action_time&#34;</span><span class="o">,</span>
			<span class="k">new</span> <span class="nc">ExistingField</span><span class="o">(</span><span class="s">&#34;user_action_time&#34;</span><span class="o">)</span><span class="o">,</span>
			<span class="k">new</span> <span class="nc">AscendingTimestamps</span><span class="o">)</span>
		<span class="k">val</span> <span class="n">listRowtimeAttrDescr</span> <span class="k">=</span> <span class="nc">Collections</span><span class="o">.</span><span class="n">singletonList</span><span class="o">(</span><span class="n">rowtimeAttrDescr</span><span class="o">)</span>
		<span class="n">listRowtimeAttrDescr</span>
	<span class="o">}</span>
<span class="o">}</span>

<span class="c1">// register the table source
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">UserActionSource</span><span class="o">)</span>

<span class="k">val</span> <span class="n">windowedTable</span> <span class="k">=</span> <span class="n">tEnv</span>
	<span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;user_actions&#34;</span><span class="o">)</span>
	<span class="o">.</span><span class="n">window</span><span class="o">(</span><span class="nc">Tumble</span> <span class="n">over</span> <span class="mf">10.</span><span class="n">minutes</span> <span class="n">on</span> <span class="n">$</span><span class="s">&#34;user_action_time&#34;</span> <span class="n">as</span> <span class="s">&#34;userActionWindow&#34;</span><span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[查询]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-queries/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-queries/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Queries</blockquote><h1 id="查询">查询</h1>
<p>SELECT 语句和 VALUES 语句是用 TableEnvironment 的 sqlQuery()方法指定的。该方法将 SELECT 语句（或 VALUES 语句）的结果作为一个表返回。表可以在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#mixing-table-api-and-sql">后续的 SQL 和 Table API 查询</a>中使用，可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">转换为 DataSet 或 DataStream</a>，也可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#emit-a-table">写入 TableSink</a>。SQL 和 Table API 查询可以无缝混合，并进行整体优化，转化为一个程序。</p>
<p>为了在 SQL 查询中访问一个表，必须<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-tables-in-the-catalog">在 TableEnvironment 中注册</a>。表可以从 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-tablesource">TableSource</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-table">Table</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#create-table">CREATE TABLE 语句</a>、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-datastream-or-dataset-as-table">DataStream 或 DataSet</a> 中注册。另外，用户也可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">在 TableEnvironment 中注册目录</a>来指定数据源的位置。</p>
<p>为了方便起见，Table.toString()会自动在其 TableEnvironment 中以唯一的名称注册表，并返回名称。所以，Table 对象可以直接内联到 SQL 查询中，如下例所示。</p>
<p>注意：包含不支持的 SQL 特性的查询会导致 TableException。批量表和流式表的 SQL 支持的功能在下面的章节中列出。</p>
<h2 id="指定查询">指定查询</h2>
<p>下面的例子显示了如何在注册表和内联表上指定 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">Integer</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// SQL query with an inlined (unregistered) table
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tableEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">s&#34;</span><span class="s">SELECT SUM(amount) FROM </span><span class="si">$table</span><span class="s"> WHERE product LIKE &#39;%Rubber%&#39;</span><span class="s">&#34;</span><span class="o">)</span>

<span class="c1">// SQL query with a registered table
</span><span class="c1"></span><span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">)</span>
<span class="c1">// run a SQL query on the Table and retrieve the result as a new Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>

<span class="c1">// create and register a TableSink
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">(</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;amount&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/path/to/file&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;RubberOrders&#34;</span><span class="o">)</span>

<span class="c1">// run an INSERT SQL on the Table and emit the result to the TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
  <span class="s">&#34;INSERT INTO RubberOrders SELECT product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="执行查询">执行查询</h2>
<p>可以通过 TableEnvironment.executeSql()方法执行 SELECT 语句或 VALUES 语句，将内容收集到本地。该方法将 SELECT 语句（或 VALUES 语句）的结果作为 TableResult 返回。与 SELECT 语句类似，可以使用 Table.execute()方法执行 Table 对象，将查询的内容收集到本地客户端。TableResult.collect()方法返回一个可关闭的行迭代器。除非收集完所有的结果数据，否则选择作业不会结束。我们应该通过 CloseableIterator#close()方法主动关闭作业，避免资源泄露。我们也可以通过 TableResult.print()方法将选择结果打印到客户端控制台。TableResult 中的结果数据只能被访问一次。因此，collect()和 print()不能相继被调用。</p>
<p>对于流式作业，TableResult.collect()方法或 TableResult.print()方法可以保证端到端的精确一次记录传递。这需要启用检查点机制。默认情况下，检查点机制是被禁用的。要启用检查点，我们可以通过 TableConfig 设置检查点属性（详见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/config.html#checkpointing">检查点配置</a>）。所以一条结果记录只有在其对应的检查点完成后才能被客户端访问。</p>
<p>注意事项 对于流媒体模式，现在只支持只追加查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">,</span> <span class="n">settings</span><span class="o">)</span>
<span class="c1">// enable checkpointing
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">getConfiguration</span><span class="o">.</span><span class="n">set</span><span class="o">(</span>
  <span class="nc">ExecutionCheckpointingOptions</span><span class="o">.</span><span class="nc">CHECKPOINTING_MODE</span><span class="o">,</span> <span class="nc">CheckpointingMode</span><span class="o">.</span><span class="nc">EXACTLY_ONCE</span><span class="o">)</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">getConfiguration</span><span class="o">.</span><span class="n">set</span><span class="o">(</span>
  <span class="nc">ExecutionCheckpointingOptions</span><span class="o">.</span><span class="nc">CHECKPOINTING_INTERVAL</span><span class="o">,</span> <span class="nc">Duration</span><span class="o">.</span><span class="n">ofSeconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span><span class="o">)</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;CREATE TABLE Orders (`user` BIGINT, product STRING, amount INT) WITH (...)&#34;</span><span class="o">)</span>

<span class="c1">// execute SELECT statement
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;SELECT * FROM Orders&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">it</span> <span class="k">=</span> <span class="n">tableResult1</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="o">)</span>
<span class="k">try</span> <span class="k">while</span> <span class="o">(</span><span class="n">it</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">row</span> <span class="k">=</span> <span class="n">it</span><span class="o">.</span><span class="n">next</span>
  <span class="c1">// handle row
</span><span class="c1"></span><span class="o">}</span>
<span class="k">finally</span> <span class="n">it</span><span class="o">.</span><span class="n">close</span><span class="o">(</span><span class="o">)</span> <span class="c1">// close the iterator to avoid resource leak
</span><span class="c1"></span>
<span class="c1">// execute Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT * FROM Orders&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="o">)</span>
<span class="n">tableResult2</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><h2 id="语法">语法</h2>
<p>Flink 使用 <a href="https://calcite.apache.org/docs/reference.html">Apache Calcite</a> 解析 SQL，它支持标准的 ANSI SQL。</p>
<p>下面的 BNF-语法描述了在批处理和流式查询中支持的 SQL 特性的超集。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#operations">操作</a>部分显示了支持的特性的例子，并指出哪些特性只支持批处理或流式查询。</p>
<pre><code>query:
  values
  | {
      select
      | selectWithoutFrom
      | query UNION [ ALL ] query
      | query EXCEPT query
      | query INTERSECT query
    }
    [ ORDER BY orderItem [, orderItem ]* ]
    [ LIMIT { count | ALL } ]
    [ OFFSET start { ROW | ROWS } ]
    [ FETCH { FIRST | NEXT } [ count ] { ROW | ROWS } ONLY]

orderItem:
  expression [ ASC | DESC ]

select:
  SELECT [ ALL | DISTINCT ]
  { * | projectItem [, projectItem ]* }
  FROM tableExpression
  [ WHERE booleanExpression ]
  [ GROUP BY { groupItem [, groupItem ]* } ]
  [ HAVING booleanExpression ]
  [ WINDOW windowName AS windowSpec [, windowName AS windowSpec ]* ]

selectWithoutFrom:
  SELECT [ ALL | DISTINCT ]
  { * | projectItem [, projectItem ]* }

projectItem:
  expression [ [ AS ] columnAlias ]
  | tableAlias . *

tableExpression:
  tableReference [, tableReference ]*
  | tableExpression [ NATURAL ] [ LEFT | RIGHT | FULL ] JOIN tableExpression [ joinCondition ]

joinCondition:
  ON booleanExpression
  | USING '(' column [, column ]* ')'

tableReference:
  tablePrimary
  [ matchRecognize ]
  [ [ AS ] alias [ '(' columnAlias [, columnAlias ]* ')' ] ]

tablePrimary:
  [ TABLE ] [ [ catalogName . ] schemaName . ] tableName [ dynamicTableOptions ]
  | LATERAL TABLE '(' functionName '(' expression [, expression ]* ')' ')'
  | UNNEST '(' expression ')'

dynamicTableOptions:
  /*+ OPTIONS(key=val [, key=val]*) */

key:
  stringLiteral

val:
  stringLiteral

values:
  VALUES expression [, expression ]*

groupItem:
  expression
  | '(' ')'
  | '(' expression [, expression ]* ')'
  | CUBE '(' expression [, expression ]* ')'
  | ROLLUP '(' expression [, expression ]* ')'
  | GROUPING SETS '(' groupItem [, groupItem ]* ')'

windowRef:
    windowName
  | windowSpec

windowSpec:
    [ windowName ]
    '('
    [ ORDER BY orderItem [, orderItem ]* ]
    [ PARTITION BY expression [, expression ]* ]
    [
        RANGE numericOrIntervalExpression {PRECEDING}
      | ROWS numericExpression {PRECEDING}
    ]
    ')'

matchRecognize:
      MATCH_RECOGNIZE '('
      [ PARTITION BY expression [, expression ]* ]
      [ ORDER BY orderItem [, orderItem ]* ]
      [ MEASURES measureColumn [, measureColumn ]* ]
      [ ONE ROW PER MATCH ]
      [ AFTER MATCH
            ( SKIP TO NEXT ROW
            | SKIP PAST LAST ROW
            | SKIP TO FIRST variable
            | SKIP TO LAST variable
            | SKIP TO variable )
      ]
      PATTERN '(' pattern ')'
      [ WITHIN intervalLiteral ]
      DEFINE variable AS condition [, variable AS condition ]*
      ')'

measureColumn:
      expression AS alias

pattern:
      patternTerm [ '|' patternTerm ]*

patternTerm:
      patternFactor [ patternFactor ]*

patternFactor:
      variable [ patternQuantifier ]

patternQuantifier:
      '*'
  |   '*?'
  |   '+'
  |   '+?'
  |   '?'
  |   '??'
  |   '{' { [ minRepeat ], [ maxRepeat ] } '}' ['?']
  |   '{' repeat '}'
</code></pre><p>Flink SQL 对标识符（表名、属性名、函数名）使用了类似 Java 的词汇策略。</p>
<p>无论标识符是否被引用，它们的大小写都会被保留。
之后，标识符会被大小写敏感地匹配。
与 Java 不同的是，回标允许标识符包含非字母数字字符（例如：&ldquo;SELECT a AS<code>my field</code>FROM t&rdquo;）。
字符串必须用单引号括起来（例如，SELECT &lsquo;Hello World&rsquo;）。重复一个单引号进行转义（例如，SELECT &lsquo;It&rsquo;s me.'）。字符串中支持 Unicode 字符。如果需要明确的 unicode 码点，请使用以下语法。</p>
<p>使用反斜杠（\）作为转义字符（默认）。SELECT U&amp;'\263A&rsquo;
使用自定义转义字符。SELECT U&amp;'#263A&rsquo; UESCAPE &lsquo;#'。</p>
<h2 id="operations">Operations</h2>
<h3 id="scan-projection-和-filter">Scan, Projection 和 Filter</h3>
<ul>
<li>Scan / Select / As(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span>

<span class="k">SELECT</span> <span class="n">a</span><span class="p">,</span> <span class="k">c</span> <span class="k">AS</span> <span class="n">d</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><ul>
<li>Where / Filter(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">red</span><span class="s1">&#39;</span>

<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div><ul>
<li>用户定义标量函数 (Scalar UDF)(Batch/Streaming)</li>
</ul>
<p>UDF 必须在 TableEnvironment 中注册。关于如何指定和注册标量 UDF 的详细信息，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">PRETTY_PRINT</span><span class="p">(</span><span class="k">user</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><h3 id="聚合">聚合</h3>
<ul>
<li>GroupBy 聚合(Batch/Streaming/Result Updating)</li>
</ul>
<p>注意：流表上的 GroupBy 会产生更新结果。详情请参见<a href="https://ohmyweekly.github.io/notes/2020-08-22-dynamic-tables">动态表流</a>概念页面。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">a</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">as</span> <span class="n">d</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">a</span>
</code></pre></div><ul>
<li>GroupBy 窗口聚合(Batch/Streaming)</li>
</ul>
<p>使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">分组窗口</a>来计算每个组的单一结果行。更多细节请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#group-windows">分组窗口</a>部分。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">rowtime</span><span class="p">,</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">1</span><span class="s1">&#39;</span> <span class="k">DAY</span><span class="p">)</span><span class="p">,</span> <span class="k">user</span>
</code></pre></div><ul>
<li>Over 窗口聚合(Streaming)</li>
</ul>
<p>注意：所有的聚合必须定义在同一个窗口上，即相同的分区、排序和范围。目前，只支持对 CURRENT ROW 范围的 PRECEDING（UNBOUNDED 和 bounded）窗口。还不支持带 FOLLOWING 的范围。ORDER BY 必须在单个<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>上指定。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="k">user</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="mi">2</span> <span class="n">PRECEDING</span> <span class="k">AND</span> <span class="k">CURRENT</span> <span class="k">ROW</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>

<span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="n">w</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="n">OVER</span> <span class="n">w</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="n">WINDOW</span> <span class="n">w</span> <span class="k">AS</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="k">user</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="mi">2</span> <span class="n">PRECEDING</span> <span class="k">AND</span> <span class="k">CURRENT</span> <span class="k">ROW</span><span class="p">)</span>
</code></pre></div><ul>
<li>Distinct(Batch/Streaming/Result Updating)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="n">users</span> <span class="k">FROM</span> <span class="n">Orders</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同字段的数量而无限增长。请提供一个有效的保留时间间隔的查询配置，以防止过大的状态大小。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Grouping sets, Rollup, Cube(Batch/Streaming/Result Updating)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="k">GROUPING</span> <span class="k">SETS</span> <span class="p">(</span><span class="p">(</span><span class="k">user</span><span class="p">)</span><span class="p">,</span> <span class="p">(</span><span class="n">product</span><span class="p">)</span><span class="p">)</span>
</code></pre></div><p>注：流式模式分组集、Rollup 和 Cube 仅在 Blink 计划器中支持。</p>
<ul>
<li>Having(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">users</span>
<span class="k">HAVING</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span>
</code></pre></div><ul>
<li>用户定义聚合函数 (UDAGG)(Batch/Streaming)</li>
</ul>
<p>UDAGG 必须在 TableEnvironment 中注册。关于如何指定和注册 UDAGG 的细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">MyAggregate</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">users</span>
</code></pre></div><h3 id="joins">Joins</h3>
<ul>
<li>Inner Equi-join(Batch/Streaming)</li>
</ul>
<p>目前，只支持等价连接，即至少有一个带有平等谓词的共轭条件的连接，不支持任意的交叉连接或θ连接。不支持任意的交叉连接或θ连接。</p>
<p>注意：连接的顺序没有被优化。表的连接顺序是按照 FROM 子句中指定的顺序进行的。确保指定表的顺序不会产生交叉连接（笛卡尔乘积），因为交叉连接不支持，会导致查询失败。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Outer Equi-join(Batch/Streaming/Result Updating)</li>
</ul>
<p>目前，只支持 equi-joins 连接，即至少有一个带有平等谓词的共轭条件的连接，不支持任意的交叉连接或θ连接。不支持任意的交叉连接或θ连接。</p>
<p>注意：连接的顺序没有被优化。表的连接顺序是按照 FROM 子句中指定的顺序进行的。确保指定表的顺序不会产生交叉连接（笛卡尔乘积），因为交叉连接不支持，会导致查询失败。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">LEFT</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>

<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">RIGHT</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>

<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">FULL</span> <span class="k">OUTER</span> <span class="k">JOIN</span> <span class="n">Product</span> <span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>注意：对于流式查询，计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供一个具有有效保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Interval Join(Batch/Streaming)</li>
</ul>
<p>注：区间连接是常规连接的一个子集，可以用流式处理。</p>
<p>一个区间连接至少需要一个等价连接谓词和一个连接条件，以限制双方的时间。这样的条件可以由两个合适的范围谓词（&lt;，&lt;=，&gt;=，&gt;）、一个 BETWEEN 谓词或一个比较两个输入表的相同类型的<a href="https://ohmyweekly.github.io/notes/2020-08-22-time-attributes">时间属性</a>（即处理时间或事件时间）的单一平等谓词来定义。</p>
<p>例如，以下谓词是有效的区间连接条件。</p>
<ul>
<li>ltime = rtime</li>
<li>ltime &gt;= rtime AND ltime &lt; rtime + INTERVAL &lsquo;10&rsquo; MINUTE</li>
<li>ltime BETWEEN rtime - INTERVAL &lsquo;10&rsquo; SECOND AND rtime + INTERVAL &lsquo;5&rsquo; SECOND</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="n">o</span><span class="p">,</span> <span class="n">Shipments</span> <span class="n">s</span>
<span class="k">WHERE</span> <span class="n">o</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">orderId</span> <span class="k">AND</span>
      <span class="n">o</span><span class="p">.</span><span class="n">ordertime</span> <span class="k">BETWEEN</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">4</span><span class="s1">&#39;</span> <span class="n">HOUR</span> <span class="k">AND</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span>
</code></pre></div><p>上面的例子中，如果在收到订单 4 小时后才发货，那么就会将所有的订单与其对应的货物加入。</p>
<ul>
<li>将数组扩展为关系(Batch/Streaming)</li>
</ul>
<p>还不支持 Unnesting With ORDINALITY。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">CROSS</span> <span class="k">JOIN</span> <span class="k">UNNEST</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span> <span class="p">(</span><span class="n">tag</span><span class="p">)</span>
</code></pre></div><ul>
<li>Join with Table Function (UDTF)(Batch/Streaming)</li>
</ul>
<p>用表格函数的结果连接一个表格。左表（外表）的每一行都与表函数的相应调用所产生的所有行相连接。</p>
<p>用户定义表函数（UDTF）必须在之前注册。关于如何指定和注册 UDTF 的细节，请参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">UDF 文档</a>。</p>
<p><strong>Inner Join</strong></p>
<p>左表（外表）的一行，如果它的表函数调用返回一个空的结果，就会被删除。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span><span class="p">,</span> <span class="k">LATERAL</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">unnest_udtf</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span><span class="p">)</span> <span class="n">t</span> <span class="k">AS</span> <span class="n">tag</span>
</code></pre></div><p><strong>Left Outer Join</strong></p>
<p>如果表函数调用返回的结果为空，则保留相应的外行，并将结果用空值填充。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">users</span><span class="p">,</span> <span class="n">tag</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">LEFT</span> <span class="k">JOIN</span> <span class="k">LATERAL</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">unnest_udtf</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span><span class="p">)</span> <span class="n">t</span> <span class="k">AS</span> <span class="n">tag</span> <span class="k">ON</span> <span class="k">TRUE</span>
</code></pre></div><p>注意：目前，只有字面意义上的 &ldquo;TRUE &ldquo;被支持为针对横向表的左外连接的谓词。</p>
<ul>
<li>Join with Temporal Table Function(Streaming)</li>
</ul>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>是跟踪随时间变化的表。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>提供了对时间表在特定时间点的状态的访问。使用时态表函数连接表的语法与使用表函数连接相同。</p>
<p>注意：目前只支持与时态表的内部连接。</p>
<p>假设 Rates 是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table-functions">时间表函数</a>，连接可以用 SQL 表达如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o_amount</span><span class="p">,</span> <span class="n">r_rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o_proctime</span><span class="p">)</span><span class="p">)</span>
<span class="k">WHERE</span>
  <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表概念</a>说明。</p>
<ul>
<li>Join with Temporal Table(Batch/Streaming)</li>
</ul>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>是跟踪随时间变化的表。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>提供了对时间表在特定时间点的版本的访问。</p>
<p>只支持与处理时间的时态表进行内联和左联。</p>
<p>下面的例子假设 LatestRates 是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>，它是以最新的速率来具体化的。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amout</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span><span class="p">,</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o</span><span class="p">.</span><span class="n">proctime</span> <span class="k">AS</span> <span class="n">r</span>
  <span class="k">ON</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>更多信息请查看更详细的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">时间表</a>概念描述。</p>
<p>仅支持 Blink 计划器。</p>
<h3 id="集合运算">集合运算</h3>
<ul>
<li>Union(Batch)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">UNION</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>UnionAll(Batch/Streaming)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">UNION</span> <span class="k">ALL</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>Intersect / Except(Batch)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">INTERSECT</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="p">(</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">EXCEPT</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">user</span> <span class="k">FROM</span> <span class="n">Orders</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><ul>
<li>In(Batch/Streaming)</li>
</ul>
<p>如果给定表的子查询中存在表达式，则返回 true。子查询表必须由一列组成。该列必须与表达式具有相同的数据类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">WHERE</span> <span class="n">product</span> <span class="k">IN</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="n">product</span> <span class="k">FROM</span> <span class="n">NewProducts</span>
<span class="p">)</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<ul>
<li>Exists(Batch/Streaming)</li>
</ul>
<p>如果子查询至少返回一条记录，则返回 true。只有当操作可以被重写成联接和分组操作时才支持。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="k">user</span><span class="p">,</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">WHERE</span> <span class="n">product</span> <span class="k">EXISTS</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="n">product</span> <span class="k">FROM</span> <span class="n">NewProducts</span>
<span class="p">)</span>
</code></pre></div><p>注意：对于流式查询，该操作被重写为加入和分组操作。计算查询结果所需的状态可能会根据不同输入行的数量而无限增长。请提供有效的保留时间间隔的查询配置，以防止状态大小过大。详情请看<a href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration">查询配置</a>。</p>
<h3 id="orderby-和-limit">OrderBy 和 Limit</h3>
<ul>
<li>Order By</li>
</ul>
<p>批量流注：流查询的结果必须主要按升序时间属性进行排序。支持其他排序属性。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">orderTime</span>
</code></pre></div><ul>
<li>Limit(Batch)</li>
</ul>
<p>注意：LIMIT 子句需要一个 ORDER BY 子句。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">orderTime</span>
<span class="k">LIMIT</span> <span class="mi">3</span>
</code></pre></div><h3 id="top-n">Top-N</h3>
<p>注意 Top-N 只在 Blink planner 中支持。</p>
<p>Top-N 查询要求按列排序的 N 个最小或最大的值。最小值和最大值集都被认为是 Top-N 查询。当需要从批处理/流处理表中只显示 N 条最底层或最上层的记录时，Top-N 查询非常有用。这个结果集可以用于进一步分析。</p>
<p>Flink 使用 OVER 窗口子句和过滤条件的组合来表达 Top-N 查询。借助 OVER window PARTITION BY 子句的强大功能，Flink 还支持每组 Top-N。例如，每个类别中实时销售量最大的前五个产品。对于批处理表和流处理表的 SQL，都支持 Top-N 查询。</p>
<p>下面是 TOP-N 语句的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="p">(</span>
   <span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span><span class="p">,</span>
     <span class="n">ROW_NUMBER</span><span class="p">(</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span><span class="p">[</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">col1</span><span class="p">[</span><span class="p">,</span> <span class="n">col2</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span><span class="p">]</span>
       <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">col1</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">]</span><span class="p">[</span><span class="p">,</span> <span class="n">col2</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">]</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rownum</span>
   <span class="k">FROM</span> <span class="k">table_name</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">rownum</span> <span class="o">&lt;</span><span class="o">=</span> <span class="n">N</span> <span class="p">[</span><span class="k">AND</span> <span class="n">conditions</span><span class="p">]</span>
</code></pre></div><p>参数说明:</p>
<ul>
<li>ROW_NUMBER()。根据分区内行的顺序，给每一行分配一个唯一的、连续的数字，从 1 开始。目前，我们只支持 ROW_NUMBER 作为 over window 函数。在未来，我们将支持 RANK()和 DENSE_RANK()。</li>
<li>PARTITION BY col1[，col2&hellip;]。指定分区列。每个分区将有一个 Top-N 的结果。</li>
<li>ORDER BY col1[asc|desc][，col2[asc|desc]&hellip;]：指定排序列。指定排序列。不同列的排序方向可以不同。</li>
<li>WHERE rownum &lt;= N：为了让 Flink 识别这个查询是 Top-N 查询，需要 rownum &lt;= N。N 代表将保留 N 条最小或最大的记录。</li>
<li>[AND 条件]。在 where 子句中可以自由添加其他条件，但其他条件只能与 rownum &lt;= N 使用 AND 连接组合。</li>
</ul>
<p>流模式下的注意点: TopN 查询是结果更新。Flink SQL 会根据顺序键对输入的数据流进行排序，所以如果前 N 条记录发生了变化，变化后的记录会作为回撤/更新记录发送到下游。建议使用支持更新的存储作为 Top-N 查询的汇。另外，如果 Top N 记录需要存储在外部存储中，结果表应该与 Top-N 查询的唯一键相同。</p>
<p>Top-N 查询的唯一键是分区列和 rownum 列的组合。Top-N 查询也可以得出上游的唯一键。以下面的工作为例，假设 product_id 是 ShopSales 的唯一键，那么 Top-N 查询的唯一键是[category，rownum]和[product_id]。</p>
<p>下面的例子展示了如何在流表上使用 Top-N 指定 SQL 查询。这个例子是为了得到我们上面提到的 &ldquo;每个类别实时销量最大的前五个产品&rdquo;。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
<span class="c1">// register the DataStream under the name &#34;ShopSales&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;ShopSales&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;category&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;sales&#34;</span><span class="o">)</span>


<span class="c1">// select top-5 products per category which have the maximum sales.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT *
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as row_num
</span><span class="s">      |   FROM ShopSales)
</span><span class="s">      |WHERE row_num &lt;= 5
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h4 id="无排名输出优化">无排名输出优化</h4>
<p>如上所述，rownum 字段将作为唯一键的一个字段写入结果表，这可能导致很多记录被写入结果表。例如，当排名 9 的记录（比如产品-1001）更新，其排名升级为 1 时，排名 1~9 的所有记录都会作为更新消息输出到结果表。如果结果表接收的数据过多，就会成为 SQL 作业的瓶颈。</p>
<p>优化的方式是在 Top-N 查询的外侧 SELECT 子句中省略 rownum 字段。这样做是合理的，因为 Top N 记录的数量通常不多，因此消费者可以自己快速排序。如果没有 rownum 字段，在上面的例子中，只需要将改变的记录（product-1001）发送到下游，这样可以减少很多结果表的 IO。</p>
<p>下面的例子展示了如何用这种方式优化上面的 Top-N 例子。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
<span class="c1">// register the DataStream under the name &#34;ShopSales&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;ShopSales&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;category&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product_name&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;sales&#34;</span><span class="o">)</span>


<span class="c1">// select top-5 products per category which have the maximum sales.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT product_id, category, product_name, sales  -- omit row_num field in the output
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY category ORDER BY sales DESC) as row_num
</span><span class="s">      |   FROM ShopSales)
</span><span class="s">      |WHERE row_num &lt;= 5
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><p>流模式下的注意点: 为了将上述查询输出到外部存储中，并得到正确的结果，外部存储必须与 Top-N 查询具有相同的唯一键，在上面的示例查询中，如果 product_id 是查询的唯一键，那么外部表也应该以 product_id 作为唯一键。在上面的示例查询中，如果 product_id 是查询的唯一键，那么外部表也应该以 product_id 作为唯一键。</p>
<h3 id="重复数据删除">重复数据删除</h3>
<p>注意 重复数据删除只在 Blink planner 中支持。</p>
<p>重复数据删除就是删除一组列上重复的行，只保留第一条或最后一条。在某些情况下，上游 ETL 作业并不是端到端完全对接的，这可能会导致在故障切换时，sink 中有重复的记录。但是，重复的记录会影响到下游分析作业（如 SUM、COUNT）的正确性。所以在进一步分析之前需要进行重复数据删除。</p>
<p>Flink 使用 ROW_NUMBER()来删除重复记录，就像 Top-N 查询的方式一样。理论上，重复数据删除是 Top-N 的一个特例，N 为 1，按处理时间或事件时间排序。</p>
<p>下面是重复数据删除语句的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="p">(</span>
   <span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span><span class="p">,</span>
     <span class="n">ROW_NUMBER</span><span class="p">(</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span><span class="p">[</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">col1</span><span class="p">[</span><span class="p">,</span> <span class="n">col2</span><span class="p">.</span><span class="p">.</span><span class="p">.</span><span class="p">]</span><span class="p">]</span>
       <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">time_attr</span> <span class="p">[</span><span class="k">asc</span><span class="o">|</span><span class="k">desc</span><span class="p">]</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rownum</span>
   <span class="k">FROM</span> <span class="k">table_name</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">rownum</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div><p>参数说明:</p>
<ul>
<li>ROW_NUMBER()。为每一行指定一个唯一的、连续的编号，从 1 开始。</li>
<li>PARTITION BY col1[，col2&hellip;]: 指定分区列，即重复复制键。</li>
<li>ORDER BY time_attr[asc|desc]。指定排序列，必须是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。目前只支持 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">proctime 属性</a>。未来将支持 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#event-time">Rowtime 属性</a>。用 ASC 排序表示保留第一行，用 DESC 排序表示保留最后一行。</li>
<li>WHERE rownum = 1：为了让 Flink 识别这个查询是重复数据删除，需要 rownum = 1。</li>
</ul>
<p>下面的例子展示了如何在流表上指定使用重复数据删除的 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
<span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;order_id&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;number&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">)</span>

<span class="c1">// remove duplicate rows on order_id and keep the first occurrence row,
</span><span class="c1"></span><span class="c1">// because there shouldn&#39;t be two orders with the same order_id.
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT order_id, user, product, number
</span><span class="s">      |FROM (
</span><span class="s">      |   SELECT *,
</span><span class="s">      |       ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY proctime DESC) as row_num
</span><span class="s">      |   FROM Orders)
</span><span class="s">      |WHERE row_num = 1
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="group-windows">Group Windows</h3>
<p>组窗口是在 SQL 查询的 GROUP BY 子句中定义的。就像使用常规的 GROUP BY 子句的查询一样，使用包含组窗口函数的 GROUP BY 子句的查询是为每个组计算一条结果行。在批处理表和流式表上的 SQL 支持以下组窗口函数。</p>
<table>
<thead>
<tr>
<th align="left">分组窗口函数</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">TUMBLE(time_attr, interval)</td>
<td align="left">定义一个滚动时间窗口。滚动时间窗口将行分配到具有固定持续时间（间隔）的非重叠的连续窗口。例如，一个 5 分钟的时间窗口可以将行以 5 分钟的间隔进行分组。滚动窗口可以在事件时间（流+批次）或处理时间（流）上定义。</td>
</tr>
<tr>
<td align="left">HOP(time_attr, interval, interval)</td>
<td align="left">定义一个跳转时间窗口（在表 API 中称为滑动窗口）。跳跃时间窗口有一个固定的持续时间（第二个间隔参数），并按指定的跳跃间隔（第一个间隔参数）进行跳转。如果跳转间隔小于窗口大小，则跳转窗口是重叠的。因此，可以将行分配到多个窗口。例如，15 分钟大小的跳转窗口和 5 分钟的跳转间隔将每行分配给 3 个 15 分钟大小的不同窗口，这些窗口以 5 分钟的间隔进行评估。滚动窗口可以在事件时间（流+批处理）或处理时间（流）上定义。</td>
</tr>
<tr>
<td align="left">SESSION(time_attr, interval)</td>
<td align="left">定义一个会话时间窗口。会话时间窗口没有固定的持续时间，但其边界由不活动的时间间隔定义，即如果在定义的间隙期内没有事件出现，则会话窗口关闭。例如，有 30 分钟间隙的会话窗口在 30 分钟不活动后观察到一行时开始（否则该行将被添加到现有的窗口中），如果在 30 分钟内没有行被添加，则关闭。会话窗口可以在事件时间（流+批处理）或处理时间（流）上工作。</td>
</tr>
</tbody>
</table>
<h4 id="时间属性">时间属性</h4>
<p>对于流表的 SQL 查询，组窗口函数的 time_attr 参数必须引用一个有效的时间属性，该属性指定行的处理时间或事件时间。请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性的文档</a>，了解如何定义时间属性。</p>
<p>对于批处理表上的 SQL，组窗口函数的 time_attr 参数必须是类型为 TIMESTAMP 的属性。</p>
<h4 id="选择组窗口的开始和结束时间戳">选择组窗口的开始和结束时间戳</h4>
<p>可以通过以下辅助功能选择组窗口的开始和结束时间戳以及时间属性。</p>
<table>
<thead>
<tr>
<th align="left">Auxiliary 函数</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">TUMBLE_START(time_attr, interval),HOP_START(time_attr, interval, interval),SESSION_START(time_attr, interval)</td>
<td align="left">返回对应的滚动、跳跃或会话窗口的包容下界的时间戳。</td>
</tr>
<tr>
<td align="left">TUMBLE_END(time_attr, interval),HOP_END(time_attr, interval, interval),SESSION_END(time_attr, interval)</td>
<td align="left">返回对应的翻滚、跳跃或会话窗口的专属上界的时间戳。注意：在后续的基于时间的操作中，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或 over 窗口聚合</a>中，不能将专属上界时间戳作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">行时间属性</a>使用。</td>
</tr>
<tr>
<td align="left">TUMBLE_ROWTIME(time_attr, interval),HOP_ROWTIME(time_attr, interval, interval),SESSION_ROWTIME(time_attr, interval)</td>
<td align="left">返回对应的翻滚、跳跃或会话窗口的包容上界的时间戳。产生的属性是一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">行时间属性</a>，可以用于后续的基于时间的操作，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或窗口聚合</a>。</td>
</tr>
<tr>
<td align="left">TUMBLE_PROCTIME(time_attr, interval),HOP_PROCTIME(time_attr, interval, interval),SESSION_PROCTIME(time_attr, interval)</td>
<td align="left">返回一个 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">proctime 属性</a>，该属性可用于后续基于时间的操作，如<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">区间连接</a>和<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#aggregations">分组窗口或过窗口聚合</a>。</td>
</tr>
</tbody>
</table>
<p>注意：在调用辅助函数时，必须使用与 GROUP BY 子句中的组窗口函数完全相同的参数。</p>
<p>下面的例子展示了如何在流式表上使用组窗口指定 SQL 查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// read a DataStream from an external source
</span><span class="c1"></span><span class="k">val</span> <span class="n">ds</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
<span class="c1">// register the DataStream under the name &#34;Orders&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">,</span> <span class="n">ds</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;user&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;product&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;amount&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;proctime&#34;</span><span class="o">.</span><span class="n">proctime</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;rowtime&#34;</span><span class="o">.</span><span class="n">rowtime</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per day (in event-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result1</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT
</span><span class="s">      |  user,
</span><span class="s">      |  TUMBLE_START(rowtime, INTERVAL &#39;1&#39; DAY) as wStart,
</span><span class="s">      |  SUM(amount)
</span><span class="s">      | FROM Orders
</span><span class="s">      | GROUP BY TUMBLE(rowtime, INTERVAL &#39;1&#39; DAY), user
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per day (in processing-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result2</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT user, SUM(amount) FROM Orders GROUP BY TUMBLE(proctime, INTERVAL &#39;1&#39; DAY), user&#34;</span><span class="o">)</span>

<span class="c1">// compute every hour the SUM(amount) of the last 24 hours in event-time
</span><span class="c1"></span><span class="k">val</span> <span class="n">result3</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT product, SUM(amount) FROM Orders GROUP BY HOP(rowtime, INTERVAL &#39;1&#39; HOUR, INTERVAL &#39;1&#39; DAY), product&#34;</span><span class="o">)</span>

<span class="c1">// compute SUM(amount) per session with 12 hour inactivity gap (in event-time)
</span><span class="c1"></span><span class="k">val</span> <span class="n">result4</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
    <span class="s">&#34;&#34;&#34;
</span><span class="s">      |SELECT
</span><span class="s">      |  user,
</span><span class="s">      |  SESSION_START(rowtime, INTERVAL &#39;12&#39; HOUR) AS sStart,
</span><span class="s">      |  SESSION_END(rowtime, INTERVAL &#39;12&#39; HOUR) AS sEnd,
</span><span class="s">      |  SUM(amount)
</span><span class="s">      | FROM Orders
</span><span class="s">      | GROUP BY SESSION(rowtime(), INTERVAL &#39;12&#39; HOUR), user
</span><span class="s">    &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="模式识别">模式识别</h3>
<ul>
<li>MATCH_RECOGNIZE(Streaming)</li>
</ul>
<p>根据 MATCH_RECOGNIZE <a href="https://standards.iso.org/ittf/PubliclyAvailableStandards/c065143_ISO_IEC_TR_19075-5_2016.zip">ISO 标准</a>在流表中搜索给定模式。这使得在 SQL 查询中表达复杂事件处理（CEP）逻辑成为可能。</p>
<p>更详细的描述，请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html">检测表中模式</a>的专门页面。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">T</span><span class="p">.</span><span class="n">aid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">bid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">cid</span>
<span class="k">FROM</span> <span class="n">MyTable</span>
<span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
  <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">userid</span>
  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
  <span class="n">MEASURES</span>
    <span class="n">A</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">aid</span><span class="p">,</span>
    <span class="n">B</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">bid</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">cid</span>
  <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span> <span class="k">C</span><span class="p">)</span>
  <span class="n">DEFINE</span>
    <span class="n">A</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">a</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="n">B</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">b</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="k">C</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">c</span><span class="s1">&#39;</span>
<span class="p">)</span> <span class="k">AS</span> <span class="n">T</span>
</code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[查询配置]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-query-configuration/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-query-configuration/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Query Configuration</blockquote><h1 id="查询配置">查询配置</h1>
<p>表 API 和 SQL 查询具有相同的语义，无论其输入是有限的行集还是无限制的表变化流。在许多情况下，对流输入的连续查询能够计算出与离线计算结果相同的准确结果。然而，对于一些连续查询，你必须限制它们所维持的状态的大小，以避免在摄取无约束的输入流时耗尽存储。这取决于输入数据的特性和查询本身是否需要限制状态大小，以及它是否和如何影响计算结果的准确性。</p>
<p>Flink 的 Table API 和 SQL 接口提供了参数来调整连续查询的准确性和资源消耗。这些参数是通过 TableConfig 对象指定的，可以从 TableEnvironment 中获得。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// obtain query configuration from TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tConfig</span><span class="k">:</span> <span class="kt">TableConfig</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">getConfig</span>
<span class="c1">// set query parameters
</span><span class="c1"></span><span class="n">tConfig</span><span class="o">.</span><span class="n">setIdleStateRetentionTime</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">12</span><span class="o">)</span><span class="o">,</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">24</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// define query
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">???</span>

<span class="c1">// create TableSink
</span><span class="c1"></span><span class="k">val</span> <span class="n">sink</span><span class="k">:</span> <span class="kt">TableSink</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">???</span>

<span class="c1">// register TableSink
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSink</span><span class="o">(</span>
  <span class="s">&#34;outputTable&#34;</span><span class="o">,</span>                  <span class="c1">// table name
</span><span class="c1"></span>  <span class="nc">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span>             <span class="c1">// field names
</span><span class="c1"></span>  <span class="nc">Array</span><span class="o">[</span><span class="kt">TypeInformation</span><span class="o">[</span><span class="k">_</span><span class="o">]</span><span class="o">]</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">,</span> <span class="c1">// field types
</span><span class="c1"></span>  <span class="n">sink</span><span class="o">)</span>                           <span class="c1">// table sink
</span><span class="c1"></span>
<span class="c1">// emit result Table via a TableSink
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>

<span class="c1">// convert result Table into a DataStream[Row]
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span>
</code></pre></div><p>下面我们介绍 TableConfig 的参数，以及它们如何影响查询的准确性和资源消耗。</p>
<h2 id="闲置状态保留时间">闲置状态保留时间</h2>
<p>许多查询在一个或多个键属性上聚合或连接记录。当这样的查询在一个流上执行时，连续查询需要收集记录或维护每个键的部分结果。如果输入流的键域是不断变化的，即活跃的键值是随着时间的推移而变化的，那么随着观察到越来越多不同的键，连续查询会积累越来越多的状态。然而，往往键在一段时间后就会变得不活跃，其相应的状态也就变得陈旧无用。</p>
<p>例如下面的查询计算每节课的点击次数。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">sessionId</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">clicks</span> <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">sessionId</span><span class="p">;</span>
</code></pre></div><p>sessionId 属性被用作分组键，连续查询会对它观察到的每个 sessionId 进行计数。sessionId 属性是随着时间的推移而不断变化的，sessionId 值只有在会话结束之前才是有效的，即在有限的时间内。然而，连续查询无法知道 sessionId 的这一属性，它期望每个 sessionId 值都能在任何时间点出现。它为每一个观察到的 sessionId 值维持一个计数。因此，随着观察到的 sessionId 值越来越多，查询的总状态大小也在不断增加。</p>
<p>闲置状态保留时间参数定义了一个键的状态在被移除之前不被更新的保留时间。对于前面的示例查询，只要在配置的时间段内没有更新，sessionId 的计数就会被删除。</p>
<p>通过删除一个键的状态，连续查询就会完全忘记它以前见过这个键。如果处理一条带有键的记录，其状态在之前已经被删除，则该记录将被视为带有相应键的第一条记录。对于上面的例子来说，这意味着一个 sessionId 的计数将重新开始为 0。</p>
<p>有两个参数可以配置空闲状态保留时间。</p>
<ul>
<li>最小空闲状态保留时间定义了一个非活动键的状态在被移除之前至少保留多长时间。</li>
<li>最大空闲状态保留时间定义了非活动键的状态在被删除前最多保留多长时间。</li>
</ul>
<p>参数指定如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">tConfig</span><span class="k">:</span> <span class="kt">TableConfig</span> <span class="o">=</span> <span class="o">???</span>

<span class="c1">// set idle state retention time: min = 12 hours, max = 24 hours
</span><span class="c1"></span><span class="n">tConfig</span><span class="o">.</span><span class="n">setIdleStateRetentionTime</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">12</span><span class="o">)</span><span class="o">,</span> <span class="nc">Time</span><span class="o">.</span><span class="n">hours</span><span class="o">(</span><span class="mi">24</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><p>清理状态需要额外的记账，对于 minTime 和 maxTime 的较大差异，记账成本较低。minTime 和 maxTime 之间的差异必须至少为 5 分钟。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[检测表中的模式]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-detecting-patterns-in-tables/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-detecting-patterns-in-tables/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Detecting Patterns in Tables</blockquote><p>检测表格中的模式
搜索一组事件模式是一个常见的用例，特别是在数据流的情况下。Flink 自带复杂事件处理（CEP）库，可以在事件流中进行模式检测。此外，Flink 的 SQL API 提供了一种关系型的查询表达方式，有大量的内置函数和基于规则的优化，可以开箱即用。</p>
<p>2016 年 12 月，国际标准化组织（ISO）发布了新版本的 SQL 标准，其中包括 SQL 中的行模式识别（ISO/IEC TR 19075-5:2016）。它允许 Flink 使用 MATCH_RECOGNIZE 子句整合 CEP 和 SQL API，用于 SQL 中的复杂事件处理。</p>
<p>MATCH_RECOGNIZE 子句可以实现以下任务。</p>
<p>对使用 partition by 和 order by 子句的数据进行逻辑分区和排序。
使用 PATTERN 子句定义要寻找的行的模式。这些模式使用类似于正则表达式的语法。
行模式变量的逻辑成分在 DEFINE 子句中指定。
在 MEASURES 子句中定义措施，这些措施是在 SQL 查询的其他部分中可用的表达式。
下面的例子说明了基本模式识别的语法。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="n">T</span><span class="p">.</span><span class="n">aid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">bid</span><span class="p">,</span> <span class="n">T</span><span class="p">.</span><span class="n">cid</span>
<span class="k">FROM</span> <span class="n">MyTable</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
      <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">userid</span>
      <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">proctime</span>
      <span class="n">MEASURES</span>
        <span class="n">A</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">aid</span><span class="p">,</span>
        <span class="n">B</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">bid</span><span class="p">,</span>
        <span class="k">C</span><span class="p">.</span><span class="n">id</span> <span class="k">AS</span> <span class="n">cid</span>
      <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span> <span class="k">C</span><span class="p">)</span>
      <span class="n">DEFINE</span>
        <span class="n">A</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">a</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="n">B</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">b</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="k">C</span> <span class="k">AS</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s1">c</span><span class="s1">&#39;</span>
    <span class="p">)</span> <span class="k">AS</span> <span class="n">T</span>
</code></pre></div><p>本页将更详细地解释每个关键字，并将说明更复杂的例子。</p>
<p>注意 Flink 对 MATCH_RECOGNIZE 子句的实现是完整标准的一个子集。只有那些在下面的章节中记录的功能得到了支持。根据社区反馈，可能会支持更多的功能，也请看一下已知的限制。</p>
<p>介绍和示例
安装指南
模式识别功能内部使用了 Apache Flink 的 CEP 库。为了能够使用 MATCH_RECOGNIZE 子句，需要将该库作为一个依赖项添加到你的 Maven 项目中。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency</span><span class="nt">&gt;</span>
  <span class="nt">&lt;groupId</span><span class="nt">&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId</span><span class="nt">&gt;</span>flink-cep_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version</span><span class="nt">&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>另外，你也可以将依赖关系添加到集群 classpath 中（更多信息请参见依赖关系部分）。</p>
<p>如果你想在 SQL 客户端中使用 MATCH_RECOGNIZE 子句，你不需要做任何事情，因为所有的依赖关系都是默认的。</p>
<p>SQL 语义
每个 MATCH_RECOGNIZE 查询都由以下子句组成。</p>
<p>PARTITION BY - 定义表的逻辑分区；类似于 GROUP BY 操作。</p>
<p>MEASURES - 定义子句的输出；类似于 SELECT 子句。
ONE ROW PER MATCH - 输出模式，定义每次匹配应该产生多少行。
AFTER MATCH SKIP&ndash;指定下一个匹配应该从哪里开始；这也是控制一个事件可以属于多少个不同匹配的方法。
PATTERN - 允许使用类似于正则表达式的语法来构建搜索的模式。
DEFINE - 这一部分定义了模式变量必须满足的条件。
注意 目前，MATCH_RECOGNIZE 子句只能应用于追加表。此外，它也总是产生一个追加表。</p>
<p>例子
在我们的例子中，我们假设已经注册了一个 Ticker 表。该表包含股票在某一特定时间点的价格。</p>
<p>该表的模式如下：</p>
<pre><code>Ticker
     |-- symbol: String                           # symbol of the stock
     |-- price: Long                              # price of the stock
     |-- tax: Long                                # tax liability of the stock
     |-- rowtime: TimeIndicatorTypeInfo(rowtime)  # point in time when the change to those values happened
</code></pre><p>为了简化，我们只考虑单只股票 ACME 的传入数据。一个行情可以类似于下表，其中行是连续追加的。</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   12      1
'ACME'  '01-Apr-11 10:00:01'   17      2
'ACME'  '01-Apr-11 10:00:02'   19      1
'ACME'  '01-Apr-11 10:00:03'   21      3
'ACME'  '01-Apr-11 10:00:04'   25      2
'ACME'  '01-Apr-11 10:00:05'   18      1
'ACME'  '01-Apr-11 10:00:06'   15      1
'ACME'  '01-Apr-11 10:00:07'   14      2
'ACME'  '01-Apr-11 10:00:08'   24      2
'ACME'  '01-Apr-11 10:00:09'   25      2
'ACME'  '01-Apr-11 10:00:10'   19      1
</code></pre><p>现在的任务是寻找单一行情的价格不断下降的时期。为此，可以写一个类似的查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="n">START_ROW</span><span class="p">.</span><span class="n">rowtime</span> <span class="k">AS</span> <span class="n">start_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">bottom_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_UP</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">end_tstamp</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="k">TO</span> <span class="k">LAST</span> <span class="n">PRICE_UP</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">START_ROW</span> <span class="n">PRICE_DOWN</span><span class="o">+</span> <span class="n">PRICE_UP</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">PRICE_DOWN</span> <span class="k">AS</span>
                <span class="p">(</span><span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">IS</span> <span class="k">NULL</span> <span class="k">AND</span> <span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="n">START_ROW</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">OR</span>
                    <span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="p">,</span>
            <span class="n">PRICE_UP</span> <span class="k">AS</span>
                <span class="n">PRICE_UP</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">PRICE_DOWN</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span> <span class="n">MR</span><span class="p">;</span>
</code></pre></div><p>该查询按符号列对 Ticker 表进行分区，并按行时间属性进行排序。</p>
<p>PATTERN 子句指定我们感兴趣的模式是以 START_ROW 事件为起点，然后是一个或多个 PRICE_DOWN 事件，最后是 PRICE_UP 事件。如果能找到这样的模式，下一个模式匹配将在最后一个 PRICE_UP 事件中寻找，如 AFTER MATCH SKIP TO LAST 子句所示。</p>
<p>DEFINE 子句指定了 PRICE_DOWN 和 PRICE_UP 事件需要满足的条件。虽然 START_ROW 模式变量并不存在，但它有一个隐含的条件，这个条件总是被评估为 TRUE。</p>
<p>模式变量 PRICE_DOWN 被定义为价格小于满足 PRICE_DOWN 条件的最后一行的价格。对于初始情况或者没有满足 PRICE_DOWN 条件的最后一行，这一行的价格应该小于模式中前一行的价格（由 START_ROW 引用）。</p>
<p>模式变量 PRICE_UP 被定义为价格大于满足 PRICE_DOWN 条件的最后一行的价格的行。</p>
<p>该查询为股票价格连续下跌的每个时期产生一条汇总行。</p>
<p>输出行的具体表示方法在查询的 MEASURES 部分定义。输出行的数量由 ONE ROW PER MATCH 输出模式定义。</p>
<pre><code> symbol       start_tstamp       bottom_tstamp         end_tstamp
=========  ==================  ==================  ==================
ACME       01-APR-11 10:00:04  01-APR-11 10:00:07  01-APR-11 10:00:08
</code></pre><p>结果一行描述了从 01-APR-11 10:00:04 开始的价格下降期，在 01-APR-11 10:00:07 达到最低价，在 01-APR-11 10:00:08 再次上涨。</p>
<p>分割
可以在分区数据中寻找模式，例如，单个股票或特定用户的趋势。这可以使用 partition by 子句来表达。该子句类似于使用 GROUP BY 进行聚合。</p>
<p>注意 强烈建议对输入的数据进行分区，否则 MATCH_RECOGNIZE 子句将被翻译成一个非平行操作符，以确保全局排序。</p>
<p>事件的顺序
Apache Flink 允许根据时间来搜索模式；无论是处理时间还是事件时间。</p>
<p>在事件时间的情况下，事件在被传递到内部模式状态机之前会被排序。因此，产生的输出将是正确的，不管行被附加到表中的顺序如何。相反，模式是按照每行包含的时间所指定的顺序来评估的。</p>
<p>MATCH_RECOGNIZE 子句假设时间属性以升序作为 ORDER BY 子句的第一个参数。</p>
<p>对于 Ticker 表的例子，像 ORDER BY rowtime ASC, price DESC 这样的定义是有效的，但是 ORDER BY price, rowtime 或者 ORDER BY rowtime DESC, price ASC 是无效的。</p>
<p>定义和测量
DEFINE 和 MEASURES 关键字的含义类似于简单 SQL 查询中的 WHERE 和 SELECT 子句。</p>
<p>MEASURES 子句定义了匹配模式的输出中会包含哪些内容。它可以投射列和定义评估的表达式。产生的行数取决于输出模式的设置。</p>
<p>DEFINE 子句指定了行必须满足的条件，以便将其分类到相应的模式变量。如果没有为模式变量定义条件，那么将使用一个默认条件，该条件对每条记录的评价为真。</p>
<p>关于这些子句中可以使用的表达式的更详细解释，请看事件流导航部分。</p>
<p>聚合
聚合可以在 DEFINE 和 MEASURES 子句中使用。同时支持内置和自定义的用户定义函数。</p>
<p>聚合函数被应用于映射到匹配的行的每个子集。为了了解这些子集是如何被评估的，请看一下事件流导航部分。</p>
<p>下面这个例子的任务是找到一个股票平均价格不低于某个阈值的最长时间段。它显示了 MATCH_RECOGNIZE 可以如何通过聚合来表达。这个任务可以用下面的查询来执行。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span> <span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">start_tstamp</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">end_tstamp</span><span class="p">,</span>
            <span class="k">AVG</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">avgPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="n">B</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">AVG</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">15</span>
    <span class="p">)</span> <span class="n">MR</span><span class="p">;</span>
</code></pre></div><p>给定这个查询和以下输入值：</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   12      1
'ACME'  '01-Apr-11 10:00:01'   17      2
'ACME'  '01-Apr-11 10:00:02'   13      1
'ACME'  '01-Apr-11 10:00:03'   16      3
'ACME'  '01-Apr-11 10:00:04'   25      2
'ACME'  '01-Apr-11 10:00:05'   2       1
'ACME'  '01-Apr-11 10:00:06'   4       1
'ACME'  '01-Apr-11 10:00:07'   10      2
'ACME'  '01-Apr-11 10:00:08'   15      2
'ACME'  '01-Apr-11 10:00:09'   25      2
'ACME'  '01-Apr-11 10:00:10'   25      1
'ACME'  '01-Apr-11 10:00:11'   30      1
</code></pre><p>只要事件的平均价格不超过 15，查询就会将事件累积为模式变量 A 的一部分。例如，这样的超限事件发生在 01-4-11 10:00:04。接下来的时期在 01-4-11 10:00:11 再次超过 15 的平均价格。因此，所述查询的结果将是：。</p>
<pre><code> symbol       start_tstamp       end_tstamp          avgPrice
=========  ==================  ==================  ============
ACME       01-APR-11 10:00:00  01-APR-11 10:00:03     14.5
ACME       01-APR-11 10:00:05  01-APR-11 10:00:10     13.5
</code></pre><p>注意 聚合可以应用于表达式，但只有当它们引用一个单一的模式变量时才可以。因此 SUM(A.price * A.tax)是有效的，但是 AVG(A.price * B.tax)不是。</p>
<p>注意不支持 DISTINCT 聚合。</p>
<p>定义一个模式
MATCH_RECOGNIZE 子句允许用户在事件流中搜索模式，使用一种强大的、富有表现力的语法，这种语法与广泛使用的正则表达式语法有些相似。</p>
<p>每个模式都是由基本的构件构成的，称为模式变量，可以对其应用运算符（量化符和其他修饰符）。整个模式必须用括号括起来。</p>
<p>一个模式的例子可以是这样的。</p>
<pre><code>PATTERN (A B+ C* D)
</code></pre><p>我们可以使用以下操作符。</p>
<p>并集 &ndash; 像(A B)这样的模式意味着 A 和 B 之间的相邻性是严格的，因此，中间不能有没有映射到 A 或 B 的行。
定量符&ndash;修改可以映射到模式变量的行数。</p>
<pre><code>* — 0 or more rows
+ — 1 or more rows
? — 0 or 1 rows
{ n } — exactly n rows (n &gt; 0)
{ n, } — n or more rows (n ≥ 0)
{ n, m } — between n and m (inclusive) rows (0 ≤ n ≤ m, 0 &lt; m)
{ , m } — between 0 and m (inclusive) rows (m &gt; 0)
</code></pre><p>注意 不支持可能产生空匹配的模式。这类模式的例子有 PATTERN (A*)、PATTERN (A?B*)、PATTERN (A{0,} B{0,} C*)等。</p>
<p>贪婪和不情愿的量化器
每个量化器可以是贪婪的（默认行为）或勉强的。贪婪的量化器试图匹配尽可能多的记录，而不情愿的量化器试图匹配尽可能少的记录。</p>
<p>为了说明两者的区别，我们可以查看下面的示例，在这个示例中，一个贪婪的量化器被应用于 B 变量。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">lastPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span><span class="o">*</span> <span class="k">C</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">,</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="p">,</span>
            <span class="k">C</span> <span class="k">AS</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="mi">12</span>
    <span class="p">)</span>
</code></pre></div><p>鉴于我们有以下输入。</p>
<pre><code> symbol  tax   price          rowtime
======= ===== ======== =====================
 XYZ     1     10       2018-09-17 10:00:02
 XYZ     2     11       2018-09-17 10:00:03
 XYZ     1     12       2018-09-17 10:00:04
 XYZ     2     13       2018-09-17 10:00:05
 XYZ     1     14       2018-09-17 10:00:06
 XYZ     2     16       2018-09-17 10:00:07
</code></pre><p>上述模式将产生以下输出。</p>
<pre><code> symbol   lastPrice
======== ===========
 XYZ      16
</code></pre><p>同样的查询，将 <code>B*</code> 修改为 <code>B*</code> 吗，即 B*应该是不愿意的，会产生。</p>
<pre><code> symbol   lastPrice
======== ===========
 XYZ      13
 XYZ      16
</code></pre><p>模式变量 B 只匹配到价格为 12 的行，而不是吞掉价格为 12、13、14 的行。</p>
<p>注意 对于一个模式的最后一个变量，不可能使用贪婪的量化符。因此，像（A B*）这样的模式是不允许的。这可以通过引入一个人为的状态（如 C）来轻松解决，这个状态具有 B 的否定条件，所以你可以使用这样的查询。</p>
<pre><code>PATTERN (A B* C)
DEFINE
    A AS condA(),
    B AS condB(),
    C AS NOT condB()
</code></pre><p>注意 目前不支持可选的勉强量化符(A??或 A{0,1}?)。</p>
<p>时间限制
特别是对于流式使用案例，通常要求一个模式在给定的时间内完成。这允许限制 Flink 必须在内部维护的整体状态大小，即使在贪婪的量化器的情况下。</p>
<p>因此，Flink SQL 支持额外的（非标准 SQL）WITHIN 子句来定义模式的时间约束。该子句可以定义在 PATTERN 子句之后，并以毫秒为间隔进行解析。</p>
<p>如果一个潜在匹配的第一个事件和最后一个事件之间的时间长于给定的值，这样的匹配将不会被追加到结果表中。</p>
<p>注意 一般鼓励使用 within 子句，因为它有助于 Flink 进行有效的内存管理。一旦达到阈值，底层状态可以被修剪。</p>
<p>注意 然而，WITHIN 子句不是 SQL 标准的一部分。推荐的处理时间限制的方式可能会在未来发生变化。</p>
<p>在下面的查询示例中说明了 WITHIN 子句的使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">C</span><span class="p">.</span><span class="n">rowtime</span> <span class="k">AS</span> <span class="n">dropTime</span><span class="p">,</span>
            <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">dropDiff</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">SKIP</span> <span class="n">PAST</span> <span class="k">LAST</span> <span class="k">ROW</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span> <span class="n">B</span><span class="o">*</span> <span class="k">C</span><span class="p">)</span> <span class="n">WITHIN</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">1</span><span class="s1">&#39;</span> <span class="n">HOUR</span>
        <span class="n">DEFINE</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="mi">10</span>
            <span class="k">C</span> <span class="k">AS</span> <span class="k">C</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">-</span> <span class="mi">10</span>
    <span class="p">)</span>
</code></pre></div><p>查询检测到在 1 小时的时间间隔内发生的价格下跌 10。</p>
<p>假设该查询用于分析以下行情数据。</p>
<pre><code>symbol         rowtime         price    tax
======  ====================  ======= =======
'ACME'  '01-Apr-11 10:00:00'   20      1
'ACME'  '01-Apr-11 10:20:00'   17      2
'ACME'  '01-Apr-11 10:40:00'   18      1
'ACME'  '01-Apr-11 11:00:00'   11      3
'ACME'  '01-Apr-11 11:20:00'   14      2
'ACME'  '01-Apr-11 11:40:00'   9       1
'ACME'  '01-Apr-11 12:00:00'   15      1
'ACME'  '01-Apr-11 12:20:00'   14      2
'ACME'  '01-Apr-11 12:40:00'   24      2
'ACME'  '01-Apr-11 13:00:00'   1       2
'ACME'  '01-Apr-11 13:20:00'   19      1
</code></pre><p>查询将产生以下结果。</p>
<pre><code>symbol         dropTime         dropDiff
======  ====================  =============
'ACME'  '01-Apr-11 13:00:00'      14
</code></pre><p>结果行表示价格从 15（在 4 月 1 日 12:00:00）下降到 1（在 4 月 1 日 13:00:00）。dropDiff 列包含了价格差。</p>
<p>请注意，即使价格也以更高的数值下降，例如，下降 11（在 01-Apr-11 10:00:00 和 01-Apr-11 11:40:00 之间），这两个事件之间的时间差大于 1 小时。因此，它们不会产生匹配。</p>
<p>输出模式
输出模式描述了每找到一个匹配的记录应该发出多少行。SQL 标准描述了两种模式。</p>
<pre><code>ALL ROWS PER MATCH
ONE ROW PER MATCH.
</code></pre><p>目前，唯一支持的输出模式是 ONE ROW PER MATCH，对于每一个找到的匹配项，总会产生一个输出汇总行。</p>
<p>输出行的模式将是[分区列]+[措施列]按该特定顺序的连接。</p>
<p>下面的例子显示了一个定义为查询的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">startPrice</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">topPrice</span><span class="p">,</span>
            <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="k">AS</span> <span class="n">lastPrice</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="n">B</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">IS</span> <span class="k">NULL</span> <span class="k">OR</span> <span class="n">A</span><span class="p">.</span><span class="n">price</span> <span class="o">&gt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="p">,</span>
            <span class="n">B</span> <span class="k">AS</span> <span class="n">B</span><span class="p">.</span><span class="n">price</span> <span class="o">&lt;</span> <span class="k">LAST</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div><p>对于以下输入行：</p>
<pre><code> symbol   tax   price          rowtime
======== ===== ======== =====================
 XYZ      1     10       2018-09-17 10:00:02
 XYZ      2     12       2018-09-17 10:00:03
 XYZ      1     13       2018-09-17 10:00:04
 XYZ      2     11       2018-09-17 10:00:05
</code></pre><p>查询将产生以下输出。</p>
<pre><code> symbol   startPrice   topPrice   lastPrice
======== ============ ========== ===========
 XYZ      10           13         11
</code></pre><p>模式识别是按符号列进行分区的。尽管在 MEASURES 子句中没有明确提到，但在结果的开头会添加分区列。</p>
<p>模式导航
DEFINE 和 MEASURES 子句允许在（可能）匹配模式的行列表中进行导航。</p>
<p>本节将讨论这种用于声明条件或产生输出结果的导航。</p>
<p>模式变量引用
模式变量引用允许引用映射到 DEFINE 或 MEASURES 子句中特定模式变量的一组行。</p>
<p>例如，表达式 A.price 描述了迄今为止映射到 A 的一组行，再加上当前行，如果我们尝试将当前行与 A 进行匹配。如果 DEFINE/MEASURES 子句中的表达式需要单行（例如 A.price 或 A.price&gt;10），则选择属于相应集合的最后一个值。</p>
<p>如果没有指定模式变量（例如 SUM(price)），表达式会引用默认的模式变量*，它引用模式中的所有变量。换句话说，它创建了一个迄今为止映射到任何变量的所有行加上当前行的列表。</p>
<p>例子</p>
<p>要想了解更透彻的例子，可以看看下面的模式和相应的条件。</p>
<pre><code>PATTERN (A B+)
DEFINE
  A AS A.price &gt; 10,
  B AS B.price &gt; A.price AND SUM(price) &lt; 100 AND SUM(B.price) &lt; 80
</code></pre><p>下表描述了如何评估每个传入事件的这些条件。</p>
<p>该表由以下几栏组成：</p>
<pre><code># - the row identifier that uniquely identifies an incoming row in the lists [A.price]/[B.price]/[price].
price - the price of the incoming row.
[A.price]/[B.price]/[price] - describe lists of rows which are used in the DEFINE clause to evaluate conditions.
Classifier - the classifier of the current row which indicates the pattern variable the row is mapped to.
A.price/B.price/SUM(price)/SUM(B.price) - describes the result after those expressions have been evaluated.
#	price	Classifier	[A.price]	[B.price]	[price]	A.price	B.price	SUM(price)	SUM(B.price)
#1	10	-&gt; A	#1	-	-	10	-	-	-
#2	15	-&gt; B	#1	#2	#1, #2	10	15	25	15
#3	20	-&gt; B	#1	#2, #3	#1, #2, #3	10	20	45	35
#4	31	-&gt; B	#1	#2, #3, #4	#1, #2, #3, #4	10	31	76	66
#5	35		#1	#2, #3, #4, #5	#1, #2, #3, #4, #5	10	35	111	101
</code></pre><p>从表中可以看出，第一行被映射到模式变量 A，随后的行被映射到模式变量 B，但是最后一行不满足 B 的条件，因为所有映射行的 SUM(价格)和 B 中所有行的总和超过了指定的阈值。</p>
<p>逻辑偏移
逻辑偏移可以在映射到特定模式变量的事件中进行导航。这可以用两个相应的函数来表示。</p>
<p>偏移函数 描述
LAST(variable.field, n)
返回事件中被映射到变量第 n 个最后元素的字段的值。从映射到的最后一个元素开始计算。</p>
<p>FIRST(variable.field, n)
返回事件中被映射到变量第 n 个元素的字段值。从映射到的第一个元素开始计算。</p>
<p>示例</p>
<p>为了更透彻的举例，可以看看下面的模式和相应的条件。</p>
<pre><code>PATTERN (A B+)
DEFINE
  A AS A.price &gt; 10,
  B AS (LAST(B.price, 1) IS NULL OR B.price &gt; LAST(B.price, 1)) AND
       (LAST(B.price, 2) IS NULL OR B.price &gt; 2 * LAST(B.price, 2))
</code></pre><p>下表描述了如何评估每个传入事件的这些条件。</p>
<p>该表由以下几栏组成：</p>
<pre><code>price - the price of the incoming row.
Classifier - the classifier of the current row which indicates the pattern variable the row is mapped to.
LAST(B.price, 1)/LAST(B.price, 2) - describes the result after those expressions have been evaluated.
price	Classifier	LAST(B.price, 1)	LAST(B.price, 2)	Comment
10	-&gt; A			
15	-&gt; B	null	null	Notice that LAST(A.price, 1) is null because there is still nothing mapped to B.
20	-&gt; B	15	null	
31	-&gt; B	20	15	
35		31	20	Not mapped because 35 &lt; 2 * 20.
</code></pre><p>使用默认的模式变量与逻辑偏移量也可能是有意义的。</p>
<p>在这种情况下，偏移量会考虑到目前为止映射的所有行。</p>
<pre><code>PATTERN (A B? C)
DEFINE
  B AS B.price &lt; 20,
  C AS LAST(price, 1) &lt; C.price
price	Classifier	LAST(price, 1)	Comment
10	-&gt; A		
15	-&gt; B		
20	-&gt; C	15	LAST(price, 1) is evaluated as the price of the row mapped to the B variable.
</code></pre><p>如果第二行没有映射到 B 变量，我们会有以下结果。</p>
<pre><code>price	Classifier	LAST(price, 1)	Comment
10	-&gt; A		
20	-&gt; C	10	LAST(price, 1) is evaluated as the price of the row mapped to the A variable.
</code></pre><p>也可以在 first/last 函数的第一个参数中使用多个模式变量引用。这样，就可以写一个访问多列的表达式。但是，所有这些表达式必须使用同一个模式变量。换句话说，LAST/FIRST 函数的值必须在单行中计算。</p>
<p>因此，可以使用 LAST(A.price * A.tax)，但不允许使用 LAST(A.price * B.tax)这样的表达式。</p>
<p>匹配后策略
AFTER MATCH SKIP 子句指定了在找到完整匹配后，在哪里开始一个新的匹配过程。</p>
<p>有四种不同的策略。</p>
<p>SKIP PAST LAST ROW - 在当前匹配的最后一行之后的下一行恢复模式匹配。
SKIP TO NEXT ROW - 从匹配起始行后的下一行开始继续搜索新的匹配。
SKIP TO LAST 变量&ndash;在映射到指定模式变量的最后一行恢复模式匹配。
SKIP TO FIRST 变量&ndash;在被映射到指定模式变量的第一行恢复模式匹配。
这也是一种指定一个事件可以属于多少个匹配的方式。例如，使用 SKIP PAST LAST ROW 策略，每个事件最多只能属于一个匹配。</p>
<p>例子</p>
<p>为了更好地理解这些策略之间的差异，可以看一下下面的例子。</p>
<p>对于以下输入行。</p>
<pre><code> symbol   tax   price         rowtime
======== ===== ======= =====================
 XYZ      1     7       2018-09-17 10:00:01
 XYZ      2     9       2018-09-17 10:00:02
 XYZ      1     10      2018-09-17 10:00:03
 XYZ      2     5       2018-09-17 10:00:04
 XYZ      2     17      2018-09-17 10:00:05
 XYZ      2     14      2018-09-17 10:00:06
</code></pre><p>我们用不同的策略评估以下查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">Ticker</span>
    <span class="n">MATCH_RECOGNIZE</span><span class="p">(</span>
        <span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">symbol</span>
        <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">rowtime</span>
        <span class="n">MEASURES</span>
            <span class="k">SUM</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="k">AS</span> <span class="n">sumPrice</span><span class="p">,</span>
            <span class="k">FIRST</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">startTime</span><span class="p">,</span>
            <span class="k">LAST</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">endTime</span>
        <span class="n">ONE</span> <span class="k">ROW</span> <span class="n">PER</span> <span class="k">MATCH</span>
        <span class="p">[</span><span class="k">AFTER</span> <span class="k">MATCH</span> <span class="n">STRATEGY</span><span class="p">]</span>
        <span class="n">PATTERN</span> <span class="p">(</span><span class="n">A</span><span class="o">+</span> <span class="k">C</span><span class="p">)</span>
        <span class="n">DEFINE</span>
            <span class="n">A</span> <span class="k">AS</span> <span class="k">SUM</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">price</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">30</span>
    <span class="p">)</span>
</code></pre></div><p>查询返回映射到 A 的所有行的价格总和，以及整体匹配的第一个和最后一个时间戳。</p>
<p>根据使用的 AFTER MATCH 策略，查询会产生不同的结果。</p>
<p>AFTER MATCH SKIP PAST ROW(跳过最后一行)</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>第一个结果与 1 号，2 号，3 号，4 号行相匹配。</p>
<p>第二个结果与#5, #6 行相匹配。</p>
<p>匹配后跳转到下一行。</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      24         2018-09-17 10:00:02   2018-09-17 10:00:05
 XYZ      15         2018-09-17 10:00:03   2018-09-17 10:00:05
 XYZ      22         2018-09-17 10:00:04   2018-09-17 10:00:06
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>同样，第一个结果对 1 号、2 号、3 号、4 号行进行匹配。</p>
<p>与之前的策略相比，接下来的匹配中又包含了 2 号行的匹配。因此，第二个结果与行#2，#3，#4，#5 相匹配。</p>
<p>第三个结果与 3 号，4 号，5 号行相匹配。</p>
<p>第四个结果与行#4，#5，#6 相匹配。</p>
<p>最后一个结果与行#5，#6 匹配。</p>
<p>匹配后跳转到最后一行。</p>
<pre><code> symbol   sumPrice        startTime              endTime
======== ========== ===================== =====================
 XYZ      26         2018-09-17 10:00:01   2018-09-17 10:00:04
 XYZ      15         2018-09-17 10:00:03   2018-09-17 10:00:05
 XYZ      22         2018-09-17 10:00:04   2018-09-17 10:00:06
 XYZ      17         2018-09-17 10:00:05   2018-09-17 10:00:06
</code></pre><p>同样，第一个结果针对 1 号、2 号、3 号、4 号行进行匹配。</p>
<p>与之前的策略相比，接下来的匹配只包括 3 号行（映射到 A 行），再次进行匹配。因此，第二个结果与行#3，#4，#5 相匹配。</p>
<p>第三个结果与#4，#5，#6 行相匹配。</p>
<p>最后一个结果与行#5,#6 匹配，因此第三个结果与行#4,#5,#6 匹配。</p>
<p>匹配后跳转到第一行 A。</p>
<p>这个组合会产生一个运行时异常，因为我们总是试图在上一个比赛开始的地方开始一个新的比赛。这将产生一个无限循环，因此是被禁止的。</p>
<p>我们必须记住，在使用 SKIP TO FIRST/LAST 变量策略的情况下，有可能没有记录映射到该变量上（例如模式 A*）。在这种情况下，将抛出一个运行时异常，因为标准要求有一条有效的记录来继续匹配。</p>
<p>时间属性
为了在 MATCH_RECOGNIZE 之上应用一些后续的查询，可能需要使用时间属性。为了选择这些属性，有两个函数可用。</p>
<p>功能描述
MATCH_ROWTIME()
返回被映射到给定模式的最后一行的时间戳。</p>
<p>所得到的属性是一个 rowtime 属性，它可以被用于后续的基于时间的操作，如区间连接和组窗口或窗口聚合。</p>
<p>MATCH_PROCTIME()
返回一个 proctime 属性，该属性可用于后续基于时间的操作，如区间连接和组窗口或窗口聚合。</p>
<p>控制内存消耗
在编写 MATCH_RECOGNIZE 查询时，内存消耗是一个重要的考虑因素，因为潜在的匹配空间是以类似广度优先的方式建立的。考虑到这一点，必须确保模式能够完成。最好是有合理数量的行映射到匹配中，因为它们必须适应内存。</p>
<p>例如，模式不能有一个没有上限的量化器，接受每一行。这样的模式可以是这样的。</p>
<pre><code>PATTERN (A B+ C)
DEFINE
  A as A.price &gt; 10,
  C as C.price &gt; 20
</code></pre><p>该查询将把每一条进入的记录映射到 B 变量上，因此永远不会结束。这个查询可以通过否定 C 的条件来解决。</p>
<pre><code>PATTERN (A B+ C)
DEFINE
  A as A.price &gt; 10,
  B as B.price &lt;= 20,
  C as C.price &gt; 20
</code></pre><p>或者通过使用勉强的定量器。</p>
<pre><code>PATTERN (A B+? C)
DEFINE
  A as A.price &gt; 10,
  C as C.price &gt; 20
</code></pre><p>注意 请注意，MATCH_RECOGNIZE 子句不使用配置的状态保留时间。人们可能希望使用 WITHIN 子句来达到这个目的。</p>
<p>已知限制
Flink 对 MATCH_RECOGNIZE 子句的实现是一项持续的努力，目前还不支持 SQL 标准的一些功能。</p>
<p>不支持的功能包括</p>
<p>模式表达式。
模式组&ndash;这意味着，例如量化符不能应用于模式的子序列。因此，（A (B C)+）不是有效的模式。
改变&ndash;像 PATTERN((A B | C D) E)这样的模式，这意味着在寻找 E 行之前必须先找到一个子序列 A B 或 C D。
PERMUTE 运算符&ndash;相当于它所应用的所有变量的排列组合，例如 PATTERN(PERMUTE (A, B, C))=PATTERN(A B C | A C B | B A C | B A C | C B A | C B A)。
锚 - ^, $，表示一个分区的开始/结束，这些在流媒体环境中没有意义，将不被支持。
排除 - PATTERN ({- A -} B) 意味着 A 将被查找，但不会参与输出。这只对 ALL ROWS PER MATCH 模式有效。
不情愿的可选量化符&ndash;PATTERN A?? 只支持贪婪的可选量化符。
ALL ROWS PER MATCH 输出模式&ndash;它为每一条参与创建发现匹配的记录产生一条输出行。这也意味着。
MEASURES 子句唯一支持的语义是 FINAL。
CLASSIFIER 函数，该函数返回某行被映射到的模式变量，目前还不支持。
SUBSET - 允许创建模式变量的逻辑组，并在 DEFINE 和 MEASURES 子句中使用这些组。
物理偏移&ndash;PREV/NEXT，它索引所有看到的事件，而不是只索引那些被映射到模式变量的事件（如逻辑偏移情况）。
提取时间属性&ndash;目前没有可能为后续基于时间的操作获取时间属性。
MATCH_RECOGNIZE 只支持 SQL。在 Table API 中没有等价物。
聚合。
不支持不同的聚合。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/match_recognize.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[概念和通用 API]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-concepts-and-common-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-concepts-and-common-api/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Concepts and Common API</blockquote><h2 id="概念和通用-api">概念和通用 API</h2>
<p>Table API 和 SQL 被集成在一个联合 API 中。这个 API 的核心概念是一个 Table，作为查询的输入和输出。本文档介绍了具有 Table API 和 SQL 查询的程序的常用结构，如何注册 Table，如何查询 Table，如何发出 Table。</p>
<h2 id="两种-planners-的主要区别">两种 Planners 的主要区别</h2>
<ol>
<li>Blink 将批处理作业视为流式作业的一种特殊情况。因此，也不支持 Table 和 DataSet 之间的转换，批处理作业不会被翻译成 DateSet 程序，而是翻译成 DataStream 程序，和流作业一样。</li>
<li>Blink 计划器不支持 BatchTableSource，请使用有界的 StreamTableSource 代替。</li>
<li>旧计划器和 Blink 计划器的 FilterableTableSource 的实现是不兼容的。旧的规划者会将 PlannerExpressions 推送到 FilterableTableSource 中，而 Blink 规划者会将 Expressions 推送下去。</li>
<li>基于字符串的键值<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/config.html">配置</a>选项(详情请看配置文档)只用于 Blink 规划器。</li>
<li>PlannerConfig 在两个规划器中的实现(CalciteConfig)是不同的。</li>
<li>Blink 规划师将在 TableEnvironment 和 StreamTableEnvironment 上把多个汇优化成一个 DAG。旧的规划器总是会将每个汇优化成一个新的 DAG，其中所有的 DAG 是相互独立的。</li>
<li>现在老的计划器不支持目录统计，而 Blink 计划器支持。</li>
</ol>
<h2 id="table-api-和-sql-程序的结构">Table API 和 SQL 程序的结构</h2>
<p>所有用于批处理和流处理的 Table API 和 SQL 程序都遵循相同的模式。下面的代码示例显示了 Table API 和 SQL 程序的共同结构。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// create a TableEnvironment for specific planner batch or streaming
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// create a Table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;table1&#34;</span><span class="o">)</span>
<span class="c1">// register an output Table
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span><span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>

<span class="c1">// create a Table from a Table API query
</span><span class="c1"></span><span class="k">val</span> <span class="n">tapiResult</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;table1&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
<span class="c1">// create a Table from a SQL query
</span><span class="c1"></span><span class="k">val</span> <span class="n">sqlResult</span>  <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT ... FROM table1 ...&#34;</span><span class="o">)</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableResult</span> <span class="k">=</span> <span class="n">tapiResult</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;outputTable&#34;</span><span class="o">)</span>
<span class="n">tableResult</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
</code></pre></div><p>注意：表 API 和 SQL 查询可以很容易地与 DataStream 或 DataSet 程序集成并嵌入其中。请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">与 DataStream 和 DataSet API 的集成</a>部分，了解如何将 DataStream 和 DataSets 转换为表，反之亦然。</p>
<h2 id="创建一个-tableenvironment">创建一个 TableEnvironment</h2>
<p>TableEnvironment 是 Table API 和 SQL 集成的核心概念。它负责</p>
<ul>
<li>在内部目录(catalog)中注册一个 Table</li>
<li>登记目录(catalog)</li>
<li>加载可插拔模块</li>
<li>执行 SQL 查询</li>
<li>注册一个用户定义的（标量、表或聚合）函数</li>
<li>将 DataStream 或 DataSet 转换为 Table</li>
<li>持有对 ExecutionEnvironment 或 StreamExecutionEnvironment 的引用。</li>
</ul>
<p>一个 Table 总是绑定在一个特定的 TableEnvironment 上。在同一个查询中，不可能将不同 TableEnvironments 的表组合起来，例如，将它们连接或联合起来。</p>
<p>通过调用静态的 <code>BatchTableEnvironment.create()</code> 或 <code>StreamTableEnvironment.create()</code> 方法创建一个 TableEnvironment，其中包含一个 StreamExecutionEnvironment 或 ExecutionEnvironment 和一个可选的 TableConfig。TableConfig 可以用来配置 TableEnvironment 或自定义查询优化和翻译过程（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#query-optimization">Query Optimization</a>）。</p>
<p>确保选择与你的编程语言相匹配的特定规划器 BatchTableEnvironment/StreamTableEnvironment。</p>
<p>如果这两个规划器 jar 都在 classpath 上（默认行为），你应该明确设置在当前程序中使用哪个规划器。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// **********************
</span><span class="c1"></span><span class="c1">// FLINK STREAMING QUERY
</span><span class="c1"></span><span class="c1">// **********************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="n">fsSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">useOldPlanner</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">inStreamingMode</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">fsEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">fsTableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">fsEnv</span><span class="o">,</span> <span class="n">fsSettings</span><span class="o">)</span>
<span class="c1">// or val fsTableEnv = TableEnvironment.create(fsSettings)
</span><span class="c1"></span>
<span class="c1">// ******************
</span><span class="c1"></span><span class="c1">// FLINK BATCH QUERY
</span><span class="c1"></span><span class="c1">// ******************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.ExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.BatchTableEnvironment</span>

<span class="k">val</span> <span class="n">fbEnv</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">fbTableEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">fbEnv</span><span class="o">)</span>

<span class="c1">// **********************
</span><span class="c1"></span><span class="c1">// BLINK STREAMING QUERY
</span><span class="c1"></span><span class="c1">// **********************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.EnvironmentSettings</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</span>

<span class="k">val</span> <span class="n">bsEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">bsSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">useBlinkPlanner</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">inStreamingMode</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">bsTableEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">bsEnv</span><span class="o">,</span> <span class="n">bsSettings</span><span class="o">)</span>
<span class="c1">// or val bsTableEnv = TableEnvironment.create(bsSettings)
</span><span class="c1"></span>
<span class="c1">// ******************
</span><span class="c1"></span><span class="c1">// BLINK BATCH QUERY
</span><span class="c1"></span><span class="c1">// ******************
</span><span class="c1"></span><span class="k">import</span> <span class="nn">org.apache.flink.table.api.</span><span class="o">{</span><span class="nc">EnvironmentSettings</span><span class="o">,</span> <span class="nc">TableEnvironment</span><span class="o">}</span>

<span class="k">val</span> <span class="n">bbSettings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">useBlinkPlanner</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">inBatchMode</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="o">)</span>
<span class="k">val</span> <span class="n">bbTableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">bbSettings</span><span class="o">)</span>
</code></pre></div><p>注意：如果在 <code>/lib</code> 目录下只有一个 planner jar，可以使用 <code>AnyPlanner(python 的 use_any_planner)</code> 来创建特定的环境设置。</p>
<h2 id="在目录catalog中创建表">在目录(Catalog)中创建表</h2>
<p>一个 TableEnvironment 维护着一个表的目录图，这些表是用一个标识符创建的。每个标识符由 3 部分组成：目录名、数据库名和对象名。如果没有指定目录或数据库，将使用当前的默认值（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#table-identifier-expanding">Table 标识符展开</a>部分的例子）。</p>
<p>表可以是虚拟的（VIEWS）或常规的（TABLES）。VIEWS 可以从现有的 Table 对象创建，通常是 Table API 或 SQL 查询的结果。TABLES 描述外部数据，如文件、数据库表或消息队列。</p>
<h3 id="临时表与永久表">临时表与永久表</h3>
<p>表可以是临时的，与单个 Flink 会话的生命周期挂钩，也可以是永久的，在多个 Flink 会话和集群中可见。</p>
<p>永久表需要一个<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/catalogs.html">目录</a>（如 Hive Metastore）来维护表的元数据。一旦创建了永久表，它对连接到目录的任何 Flink 会话都是可见的，并将继续存在，直到表被显式放弃。</p>
<p>另一方面，临时表总是存储在内存中，并且只在它们创建的 Flink 会话的持续时间内存在。这些表对其他会话不可见。它们不绑定到任何目录或数据库，但可以在一个目录或数据库的命名空间中创建。如果相应的数据库被删除，临时表不会被删除。</p>
<h3 id="shadowing">Shadowing</h3>
<p>可以用与现有永久表相同的标识符登记一个临时表。只要临时表存在，临时表就会对永久表产生遮盖，使永久表无法访问。所有使用该标识符的查询都将针对临时表执行。</p>
<p>这可能对实验很有用。它允许首先对临时表运行完全相同的查询，例如，只有一个数据子集，或者数据被混淆了。一旦验证了查询的正确性，就可以针对真正的生产表运行。</p>
<h2 id="创建一个-table">创建一个 Table</h2>
<h3 id="虚拟表">虚拟表</h3>
<p>表 API 对象对应于 SQL 术语中的 VIEW（虚拟表）。它封装了一个逻辑查询计划。它可以在一个目录中创建，具体如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// table is the result of a simple projection query 
</span><span class="c1"></span><span class="k">val</span> <span class="n">projTable</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;X&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// register the Table projTable as table &#34;projectedTable&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;projectedTable&#34;</span><span class="o">,</span> <span class="n">projTable</span><span class="o">)</span>
</code></pre></div><p>注意：Table 对象与关系型数据库系统中的 VIEW 类似，即定义 Table 的查询不进行优化，但当另一个查询引用注册的 Table 时，会被内联。如果多个查询引用同一个注册表，则会对每个引用查询进行内联，并执行多次，即注册表的结果不会被共享。</p>
<h3 id="连接器表">连接器表</h3>
<p>也可以从<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connect.html">连接器</a>声明中创建一个关系型数据库中已知的 TABLE。连接器描述的是存储表数据的外部系统。这里可以声明 Apacha Kafka 或普通文件系统等存储系统。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="nc">DDL</span>
<span class="n">tableEnvironment</span>
  <span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
  <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
  <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>
  <span class="o">.</span><span class="n">inAppendMode</span><span class="o">(</span><span class="o">)</span>
  <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="扩展-table-标识符">扩展 Table 标识符</h3>
<p>表总是用目录(catalog)、数据库、表名三部分组成的标识符进行注册。</p>
<p>用户可以将其中的一个目录和一个数据库设置为&quot;当前目录&quot;和&quot;当前数据库&rdquo;。其中，上述 3 部分标识符中的前两部分可以选择，如果不提供，则引用当前目录和当前数据库。用户可以通过表 API 或 SQL 切换当前目录和当前数据库。</p>
<p>标识符遵循 SQL 的要求，这意味着它们可以用反引号符(`)进行转义。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">TableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">;</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">useCatalog</span><span class="o">(</span><span class="s">&#34;custom_catalog&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">useDatabase</span><span class="o">(</span><span class="s">&#34;custom_database&#34;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">;</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1"></span><span class="c1">// in the database named &#39;custom_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1"></span><span class="c1">// in the database named &#39;other_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;other_database.exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;example.View&#39; in the catalog named &#39;custom_catalog&#39;
</span><span class="c1"></span><span class="c1">// in the database named &#39;custom_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;`example.View`&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>

<span class="c1">// register the view named &#39;exampleView&#39; in the catalog named &#39;other_catalog&#39;
</span><span class="c1"></span><span class="c1">// in the database named &#39;other_database&#39; 
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;other_catalog.other_database.exampleView&#34;</span><span class="o">,</span> <span class="n">table</span><span class="o">)</span>
</code></pre></div><h2 id="查询一个-table">查询一个 Table</h2>
<h3 id="table-api">Table API</h3>
<p>Table API 是 Scala 和 Java 的语言集成查询 API。与 SQL 不同的是，查询不是指定为 Strings，而是在宿主语言中一步步组成。</p>
<p>该 API 基于 Table 类，它表示一个表（流式或批处理），并提供了应用关系操作的方法。这些方法返回一个新的 Table 对象，该对象表示对输入的 Table 应用关系操作的结果。有些关系操作由多个方法调用组成，如 <code>table.groupBy(...).select()</code>，其中 <code>groupBy(...)</code> 指定表的分组，<code>select(...)</code> 是表的分组上的投影。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a> 文档描述了流式表和批处理表上支持的所有 Table API 操作。</p>
<p>下面的示例显示了一个简单的 Table API 聚合查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register Orders table
</span><span class="c1"></span>
<span class="c1">// scan registered Orders table
</span><span class="c1"></span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;Orders&#34;</span><span class="o">)</span>
<span class="c1">// compute revenue for all customers from France
</span><span class="c1"></span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cCountry&#34;</span> <span class="o">===</span> <span class="s">&#34;FRANCE&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cID&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;cName&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;cID&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;cName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;revenue&#34;</span><span class="o">.</span><span class="n">sum</span> <span class="nc">AS</span> <span class="s">&#34;revSum&#34;</span><span class="o">)</span>

<span class="c1">// emit or convert Table
</span><span class="c1"></span><span class="c1">// execute query
</span></code></pre></div><p>注意：Scala Table API 使用以美元符号（<code>$</code>）开头的 Scala 字符串插值来引用 Table 的属性。Table API 使用 Scala implicits。请确保导入</p>
<ul>
<li><code>org.apache.flink.table.api._</code> - 用于隐式表达式转换</li>
<li><code>org.apache.flink.api.scala._</code> 和 <code>org.apache.flink.table.api.bridge.scala._</code>，如果你想从 DataStream 转换到 DataStream。</li>
</ul>
<h2 id="sql">SQL</h2>
<p>Flink 的 SQL 集成是基于 <a href="https://calcite.apache.org/">Apache Calcite</a>，它实现了 SQL 标准。SQL 查询被指定为常规 Strings。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL</a> 文档描述了 Flink 对流和批处理表的 SQL 支持。</p>
<p>下面的例子展示了如何指定一个查询并将结果以表的形式返回。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register Orders table
</span><span class="c1"></span>
<span class="c1">// compute revenue for all customers from France
</span><span class="c1"></span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;&#34;&#34;
</span><span class="s">  |SELECT cID, cName, SUM(revenue) AS revSum
</span><span class="s">  |FROM Orders
</span><span class="s">  |WHERE cCountry = &#39;FRANCE&#39;
</span><span class="s">  |GROUP BY cID, cName
</span><span class="s">  &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="c1">// emit or convert Table
</span><span class="c1"></span><span class="c1">// execute query
</span></code></pre></div><p>下面的示例显示了如何指定一个更新查询，将其结果插入到注册表中。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// register &#34;Orders&#34; table
</span><span class="c1"></span><span class="c1">// register &#34;RevenueFrance&#34; output table
</span><span class="c1"></span>
<span class="c1">// compute revenue for all customers from France and emit to &#34;RevenueFrance&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;&#34;&#34;
</span><span class="s">  |INSERT INTO RevenueFrance
</span><span class="s">  |SELECT cID, cName, SUM(revenue) AS revSum
</span><span class="s">  |FROM Orders
</span><span class="s">  |WHERE cCountry = &#39;FRANCE&#39;
</span><span class="s">  |GROUP BY cID, cName
</span><span class="s">  &#34;&#34;&#34;</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>
</code></pre></div><h3 id="混合-table-api-和-sql">混合 Table API 和 SQL</h3>
<p>表 API 和 SQL 查询可以很容易地混合，因为两者都返回 Table 对象。</p>
<ul>
<li>可以在 SQL 查询返回的 Table 对象上定义 Table API 查询。</li>
<li>通过在 TableEnvironment 中<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#register-a-table">注册生成的 Table</a>并在 SQL 查询的 FROM 子句中引用它，可以在 Table API 查询的结果上定义一个 SQL 查询。</li>
</ul>
<h3 id="发出一个表">发出一个表</h3>
<p>一个 Table 是通过将其写入 TableSink 而发出的。TableSink 是一个通用接口，它支持多种文件格式（如 CSV、Apache Parquet、Apache Avro）、存储系统（如 JDBC、Apache HBase、Apache Cassandra、Elasticsearch）或消息系统（如 Apache Kafka、RabbitMQ）。</p>
<p>批量表只能写入 BatchTableSink，而流式表则需要 AppendStreamTableSink、RetractStreamTableSink 或 UpsertStreamTableSink。</p>
<p>请参阅有关 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html">Table Sources &amp; Sink</a> 的文档，以了解可用的 Sink 的详细信息以及如何实现自定义 TableSink 的说明。</p>
<p><code>Table.executeInsert(String tableName)</code> 方法将 Table 排放到一个注册的 TableSink 中。该方法通过名称从目录中查找 TableSink，并验证 Table 的模式与 TableSink 的模式是否相同。</p>
<p>下面的示例展示了如何发射 Table。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// create an output Table
</span><span class="c1"></span><span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">(</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;c&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">LONG</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>

<span class="n">tableEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/path/to/file&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">fieldDelimiter</span><span class="o">(</span><span class="sc">&#39;|&#39;</span><span class="o">)</span><span class="o">.</span><span class="n">deriveSchema</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;CsvSinkTable&#34;</span><span class="o">)</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// emit the result Table to the registered TableSink
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="n">executeInsert</span><span class="o">(</span><span class="s">&#34;CsvSinkTable&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="翻译和执行查询">翻译和执行查询</h3>
<p>两个规划器翻译和执行查询的行为是不同的。</p>
<ul>
<li>Blink 计划器</li>
</ul>
<p>表 API 和 SQL 查询无论其输入是流式还是批处理，都会被翻译成 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream</a> 程序。一个查询在内部表示为一个逻辑查询计划，并分两个阶段进行翻译。</p>
<ol>
<li>逻辑计划的优化。</li>
<li>翻译成 DataStream 程序。</li>
</ol>
<p>Table API 或 SQL 查询被翻译时:</p>
<ul>
<li><code>TableEnvironment.executeSql()</code> 被调用。这个方法用于执行给定的语句，一旦这个方法被调用，sql 查询就会立即被翻译。</li>
<li><code>Table.executeInsert()</code> 被调用。该方法用于将表的内容插入到给定的 sink 路径中，一旦调用该方法，Table API 立即被翻译。</li>
<li>调用 <code>Table.execute()</code>。该方法用于将表内容收集到本地客户端，一旦调用该方法，Table API 立即被翻译。</li>
<li><code>StatementSet.execute()</code> 被调用。一个 Table（通过 <code>StatementSet.addInsert()</code> 向 sink 发出）或一个 INSERT 语句（通过  <code>StatementSet.addInsertSql()</code> 指定）将首先在 StatementSet 中被缓冲。一旦 <code>StatementSet.execute()</code> 被调用，它们就会被翻译。所有接收器将被优化成一个 DAG。</li>
<li>当一个表被转换为 DataStream 时，它就会被翻译（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#integration-with-datastream-and-dataset-api">与 DataStream 和 DataSet API 的集成</a>）。一旦翻译完毕，它就是一个常规的 DataStream 程序，并在调用 StreamExecutionEnvironment.execut()时被执行。
注意: 从 1.11 版本开始，<code>sqlUpdate()</code> 方法和 <code>insertInto()</code> 方法已被废弃。如果 Table 程序是由这两个方法构建的，我们必须使用 <code>StreamTableEnvironment.execution()</code> 方法代替 <code>StreamExecutionEnvironment.execution()</code> 方法来执行。</li>
</ul>
<h2 id="与-datastream-和-dataset-api-的集成">与 DataStream 和 DataSet API 的集成</h2>
<p>两种流上的计划器都可以与 DataStream API 集成，只有老的计划器可以与 DataSet API 集成，批处理的 Blink 计划器不能与两者结合。只有旧的计划器可以与 DataSet API 集成，批处理的 Blink 计划器不能与两者结合。注：下面讨论的 DataSet API 只适用于批处理的旧版规划器。</p>
<p>Table API 和 SQL 查询可以很容易地与 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">DataStream</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch">DataSet</a> 程序集成并嵌入其中。例如，可以查询一个外部表（例如来自 RDBMS），做一些预处理，如过滤、投影、聚合或加入元数据，然后用 DataStream 或 DataSet API（以及建立在这些 API 之上的任何库，如 CEP 或 Gelly）进一步处理数据。反之，也可以在 DataStream 或 DataSet 程序的结果上应用 Table API 或 SQL 查询。</p>
<p>这种交互可以通过将 DataStream 或 DataSet 转换为表来实现，反之亦然。在本节中，我们将描述这些转换是如何完成的。</p>
<h3 id="scala-隐式转换">Scala 隐式转换</h3>
<p>Scala Table API 为 DataSet、DataStream 和 Table 类提供了隐式转换的功能。这些转换是通过导入包 <code>org.apache.flink.table.api.bridge.scala._</code> 来实现的，此外还可以导入 <code>org.apache.flink.api.scala._</code> 来实现 Scala DataStream API。</p>
<h3 id="从-datastream-或-dataset-创建视图">从 DataStream 或 DataSet 创建视图</h3>
<p>DataStream 或 DataSet 可以作为视图在 TableEnvironment 中注册。由此产生的视图的模式取决于注册的 DataStream 或 DataSet 的数据类型。请查看有关<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html#mapping-of-data-types-to-table-schema">数据类型到表模式的映射</a>部分以了解详情。</p>
<p>注意：从 DataStream 或 DataSet 创建的视图只能注册为临时视图。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
</span><span class="c1"></span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// register the DataStream as View &#34;myTable&#34; with fields &#34;f0&#34;, &#34;f1&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;myTable&#34;</span><span class="o">,</span> <span class="n">stream</span><span class="o">)</span>

<span class="c1">// register the DataStream as View &#34;myTable2&#34; with fields &#34;myLong&#34;, &#34;myString&#34;
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">createTemporaryView</span><span class="o">(</span><span class="s">&#34;myTable2&#34;</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> &#39;myLong<span class="o">,</span> &#39;myString<span class="o">)</span>
</code></pre></div><h3 id="将-datastream-或-dataset-转换为-table">将 DataStream 或 DataSet 转换为 Table</h3>
<p>不需要在 TableEnvironment 中注册一个 DataStream 或 DataSet，也可以直接将其转换为 Table。如果你想在 Table API 查询中使用 Table，这很方便。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment
</span><span class="c1"></span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert the DataStream into a Table with default fields &#34;_1&#34;, &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert the DataStream into a Table with fields &#34;myLong&#34;, &#34;myString&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myString&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="将-table-转换为-datastream-或-dataset">将 Table 转换为 DataStream 或 DataSet</h3>
<p>Table 可以被转换为 DataStream 或 DataSet。通过这种方式，可以在表 API 或 SQL 查询的结果上运行自定义 DataStream 或 DataSet 程序。</p>
<p>当将 Table 转换为 DataStream 或 DataSet 时，您需要指定生成的 DataStream 或 DataSet 的数据类型，即表的行要转换为的数据类型。通常，最方便的转换类型是 Row。下面的列表给出了不同选项的功能概述。</p>
<ul>
<li>Row：字段按位置映射，字段数量任意，支持 null 值，无类型安全访问。</li>
<li>POJO：字段按名称映射（POJO 字段必须与表字段一样命名），任意数量的字段，支持 null 值，类型安全访问。</li>
<li>Case Class：字段按位置映射，不支持 null 值，类型安全访问。</li>
<li>Tuple：字段按位置映射，限制为 22 个（Scala）或 25 个（Java）字段，不支持 null 值，类型安全访问。</li>
<li>原子类型：表必须有一个字段，不支持空值，类型安全访问。表必须有一个字段，不支持 null 值，类型安全访问。</li>
</ul>
<h3 id="将-table-转换为-datastream">将 Table 转换为 DataStream</h3>
<p>作为流式查询结果的表将被动态更新，即随着查询输入流中新记录的到达而变化。因此，将这种动态查询转换成的 DataStream 需要对表的更新进行编码。</p>
<p>有两种模式可以将表转换为 DataStream。</p>
<ol>
<li>Append 模式。只有当动态 Table 只被 INSERT 修改时，才可以使用这种模式，即只进行追加，之前发出的结果永远不会更新。</li>
<li>收回模式。这种模式可以一直使用。它将 INSERT 和 DELETE 更改用布尔标志编码。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment. 
</span><span class="c1"></span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert the Table into an append DataStream of Row
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2[String, Int]
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="n">dsTuple</span> <span class="k">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a retract DataStream of Row.
</span><span class="c1"></span><span class="c1">//   A retract stream of type X is a DataStream[(Boolean, X)]. 
</span><span class="c1"></span><span class="c1">//   The boolean field indicates the type of the change. 
</span><span class="c1"></span><span class="c1">//   True is INSERT, false is DELETE.
</span><span class="c1"></span><span class="k">val</span> <span class="n">retractStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Boolean</span>, <span class="kt">Row</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toRetractStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>
</code></pre></div><p>注意：关于动态表及其属性的详细讨论在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>文档中给出。</p>
<p>注意: 一旦表转换为 DataStream，请使用 <code>StreamExecutionEnvironment.execute()</code> 方法来执行 DataStream 程序。</p>
<h3 id="将-table-转换为-dataset">将 Table 转换为 DataSet</h3>
<p>Table 转换为 DataStream 的过程如下:</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
</span><span class="c1"></span><span class="c1">// registration of a DataSet is equivalent
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">BatchTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert the Table into a DataSet of Row
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toDataSet</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a DataSet of Tuple2[String, Int]
</span><span class="c1"></span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toDataSet</span><span class="o">[</span><span class="o">(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>
</code></pre></div><p>注意: 一旦 Table 转换为 DataSet，我们必须使用 <code>ExecutionEnvironment.execute</code> 方法来执行 DataSet 程序。</p>
<h3 id="数据类型到-table-schema-的映射">数据类型到 Table Schema 的映射</h3>
<p>Flink 的 DataStream 和 DataSet API 支持非常多样化的类型。复合类型，如 Tuples（内置的 Scala 和 Flink Java tuples）、POJOs、Scala case 类和 Flink 的 Row 类型，允许嵌套具有多个字段的数据结构，这些字段可以在 Table 表达式中访问。其他类型被视为原子类型。在下文中，我们将描述 Table API 如何将这些类型转换为内部行表示，并展示将 DataStream 转换为 Table 的例子。</p>
<p>数据类型到 Table Schema 的映射可以通过两种方式进行：基于字段位置或基于字段名。</p>
<ul>
<li>基于位置的映射</li>
</ul>
<p>基于位置的映射可以用来给字段一个更有意义的名字，同时保持字段顺序。这种映射可用于具有定义字段顺序的复合数据类型以及原子类型。复合数据类型如元组、行和 case 类都有这样的字段顺序。然而，POJO 的字段必须根据字段名进行映射（见下一节）。字段可以被投影出来，但不能使用别名作为重命名。</p>
<p>当定义基于位置的映射时，指定的名称必须不存在于输入数据类型中，否则 API 将假设映射应该基于字段名发生。如果没有指定字段名，则使用复合类型的默认字段名和字段顺序，对于原子类型则使用 f0。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field names &#34;_1&#34; and &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field &#34;myLong&#34; only
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#34;myLong&#34; and &#34;myInt&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myInt&#34;</span><span class="o">)</span>
</code></pre></div><ul>
<li>基于名称的映射</li>
</ul>
<p>基于名称的映射可以用于任何数据类型，包括 POJO。它是定义表模式映射的最灵活的方式。映射中的所有字段都是通过名称引用的，并可能使用别名重命名为。字段可以重新排序和投影出来。</p>
<p>如果没有指定字段名，则使用复合类型的默认字段名和字段顺序，对于原子类型则使用 f0。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field names &#34;_1&#34; and &#34;_2&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field &#34;_2&#34; only
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names &#34;myInt&#34; and &#34;myLong&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span> <span class="n">as</span> <span class="s">&#34;myInt&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span> <span class="n">as</span> <span class="s">&#34;myLong&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="原子类型">原子类型</h3>
<p>Flink 将原语（Integer、Double、String）或通用类型（不能分析和分解的类型）视为原子类型。原子类型的 DataStream 或 DataSet 会被转换为具有单一属性的 Table。属性的类型是从原子类型推断出来的，可以指定属性的名称。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field name &#34;f0&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field name &#34;myLong&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="tuplesscala-和-java和-case-类仅-scala">Tuples（Scala 和 Java）和 Case 类（仅 Scala）。</h3>
<p>Flink 支持 Scala 的内置元组，并为 Java 提供了自己的元组类。DataStreams 和 DataSets 这两种元组都可以转换为表。通过为所有字段提供名称（基于位置的映射），可以重命名字段。如果没有指定字段名，则使用默认的字段名。如果引用了原始的字段名（对于 Flink Tuples 来说是 f0, f1, &hellip;，对于 Scala Tuples 来说是 _1, _2, &hellip;），API 会假定映射是基于名称而不是基于位置的。基于名称的映射允许重新排序字段和用别名（as）进行投影。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="o">(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with renamed default field names &#39;_1, &#39;_2
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#34;myLong&#34;, &#34;myString&#34; (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myLong&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myString&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered fields &#34;_2&#34;, &#34;_1&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;_2&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields &#34;myString&#34;, &#34;myLong&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_2&#34;</span> <span class="n">as</span> <span class="s">&#34;myString&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;_1&#34;</span> <span class="n">as</span> <span class="s">&#34;myLong&#34;</span><span class="o">)</span>

<span class="c1">// define case class
</span><span class="c1"></span><span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">streamCC</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field names &#39;name, &#39;age
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names &#39;myName, &#39;myAge (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields &#34;myAge&#34;, &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="pojojava-和-scala">POJO（Java 和 Scala）</h3>
<p>Flink 支持 POJO 作为复合类型。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#pojos">这里</a>记录了确定 POJO 的规则。</p>
<p>当将 POJO DataStream 或 DataSet 转换为 Table 而不指定字段名时，会使用原始 POJO 字段的名称。名称映射需要原始名称，不能通过位置来完成。字段可以使用别名（使用 as 关键字）重命名，重新排序，并进行投影。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// Person is a POJO with field names &#34;name&#34; and &#34;age&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field names &#34;age&#34;, &#34;name&#34; (fields are ordered by name!)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields &#34;myAge&#34;, &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;name&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h3 id="row">Row</h3>
<p>Row 数据类型支持任意数量的字段和具有 null 值的字段。字段名可以通过 RowTypeInfo 来指定，也可以在将 Row DataStream 或 DataSet 转换为 Table 时指定。Row 类型支持通过位置和名称对字段进行映射。可以通过为所有字段提供名称（基于位置的映射）或单独选择字段进行投影/排序/重命名（基于名称的映射）来重命名字段。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="c1"></span><span class="k">val</span> <span class="n">tableEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span> <span class="c1">// see &#34;Create a TableEnvironment&#34; section
</span><span class="c1"></span>
<span class="c1">// DataStream of Row with two fields &#34;name&#34; and &#34;age&#34; specified in `RowTypeInfo`
</span><span class="c1"></span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// convert DataStream into Table with default field names &#34;name&#34;, &#34;age&#34;
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed field names &#34;myName&#34;, &#34;myAge&#34; (position-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields &#34;myName&#34;, &#34;myAge&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;age&#34;</span> <span class="n">as</span> <span class="s">&#34;myAge&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected field &#34;name&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field &#34;myName&#34; (name-based)
</span><span class="c1"></span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;name&#34;</span> <span class="n">as</span> <span class="s">&#34;myName&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="查询优化">查询优化</h2>
<ul>
<li>Blink 计划器</li>
</ul>
<p>Apache Flink 利用并扩展了 Apache Calcite 来执行复杂的查询优化。这包括一系列基于规则和成本的优化，如：</p>
<ul>
<li>基于 Apache Calcite 的子查询装饰相关。</li>
<li>投影修剪</li>
<li>分区修剪</li>
<li>过滤器下推</li>
<li>子计划重复复制，避免重复计算。</li>
<li>特殊子查询重写，包括两部分。
<ul>
<li>将 IN 和 EXISTS 转换为左半连接。</li>
<li>将 NOT IN 和 NOT EXISTS 转换为左反连接。</li>
</ul>
</li>
<li>可选的 join 重新排序
<ul>
<li>通过 <code>table.optimizer.join-reorder-enabled</code> 启用。</li>
</ul>
</li>
</ul>
<p>注：<code>IN/EXISTS/NOT IN/NOT EXISTS</code> 目前只支持子查询重写中的连词条件。</p>
<p>优化器做出智能决策，不仅基于计划，还基于数据源提供的丰富统计数据，以及每个操作符（如 io、cpu、网络和内存）的细粒度成本。</p>
<p>高级用户可以通过 CalciteConfig 对象提供自定义优化，该对象可以通过调用 <code>TableEnvironment#getConfig#setPlannerConfig</code> 提供给 table 环境。</p>
<h2 id="解释表">解释表</h2>
<p>Table API 提供了一种机制来解释计算 Table 的逻辑和优化查询计划。这是通过 <code>Table.explain()</code> 方法或 <code>StatementSet.explain()</code> 方法完成的。<code>Table.explain()</code> 返回一个 Table 的计划。<code>StatementSet.explain()</code> 返回多个接收器的计划。它返回一个描述三个计划的字符串。</p>
<ol>
<li>关系查询的抽象语法树，即未优化的逻辑查询计划。</li>
<li>优化的逻辑查询计划，以及</li>
<li>物理执行计划。</li>
</ol>
<p><code>TableEnvironment.explainSql()</code> 和 <code>TableEnvironment.executeSql()</code> 支持执行 EXPLAIN 语句来获取计划，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/explain.html">EXPLAIN</a> 页面。</p>
<p>下面的代码显示了一个使用 <code>Table.explain()</code> 方法给定 Table 的例子和相应的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">StreamTableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;hello&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&#34;hello&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">.</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">.</span><span class="n">like</span><span class="o">(</span><span class="s">&#34;F%&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">table</span><span class="o">.</span><span class="n">explain</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><p>上述例子的结果是:</p>
<pre><code>== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
    FlinkLogicalDataStreamScan(id=[1], fields=[count, word])
  FlinkLogicalDataStreamScan(id=[2], fields=[count, word])

== Optimized Logical Plan ==
DataStreamUnion(all=[true], union all=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')])
    DataStreamScan(id=[1], fields=[count, word])
  DataStreamScan(id=[2], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

Stage 2 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 3 : Operator
		content : from: (count, word)
		ship_strategy : REBALANCE

		Stage 4 : Operator
			content : where: (LIKE(word, _UTF-16LE'F%')), select: (count, word)
			ship_strategy : FORWARD

			Stage 5 : Operator
				content : from: (count, word)
				ship_strategy : REBALANCE
</code></pre><p>下面的代码显示了使用 <code>StatementSet.explain()</code> 方法进行多重接收器计划的一个例子和相应的输出。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">.</span><span class="n">useBlinkPlanner</span><span class="o">.</span><span class="n">inStreamingMode</span><span class="o">.</span><span class="n">build</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Schema</span><span class="o">(</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;count&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">field</span><span class="o">(</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>

<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/source/path1&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">deriveSchema</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySource1&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/source/path2&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">deriveSchema</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySource2&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/sink/path1&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">deriveSchema</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySink1&#34;</span><span class="o">)</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">connect</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileSystem</span><span class="o">(</span><span class="s">&#34;/sink/path2&#34;</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withFormat</span><span class="o">(</span><span class="k">new</span> <span class="nc">Csv</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="n">deriveSchema</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withSchema</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
    <span class="o">.</span><span class="n">createTemporaryTable</span><span class="o">(</span><span class="s">&#34;MySink2&#34;</span><span class="o">)</span>
    
<span class="k">val</span> <span class="n">stmtSet</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">createStatementSet</span><span class="o">(</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MySource1&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">.</span><span class="n">like</span><span class="o">(</span><span class="s">&#34;F%&#34;</span><span class="o">)</span><span class="o">)</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsert</span><span class="o">(</span><span class="s">&#34;MySink1&#34;</span><span class="o">,</span> <span class="n">table1</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">table1</span><span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">tEnv</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MySource2&#34;</span><span class="o">)</span><span class="o">)</span>
<span class="n">stmtSet</span><span class="o">.</span><span class="n">addInsert</span><span class="o">(</span><span class="s">&#34;MySink2&#34;</span><span class="o">,</span> <span class="n">table2</span><span class="o">)</span>

<span class="k">val</span> <span class="n">explanation</span> <span class="k">=</span> <span class="n">stmtSet</span><span class="o">.</span><span class="n">explain</span><span class="o">(</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span>
</code></pre></div><p>多重接收器计划的结果是:</p>
<pre><code>== Abstract Syntax Tree ==
LogicalLegacySink(name=[MySink1], fields=[count, word])
+- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])

LogicalLegacySink(name=[MySink2], fields=[count, word])
+- LogicalUnion(all=[true])
   :- LogicalFilter(condition=[LIKE($1, _UTF-16LE'F%')])
   :  +- LogicalTableScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]])
   +- LogicalTableScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]])

== Optimized Logical Plan ==
Calc(select=[count, word], where=[LIKE(word, _UTF-16LE'F%')], reuse_id=[1])
+- TableSourceScan(table=[[default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

LegacySink(name=[MySink1], fields=[count, word])
+- Reused(reference_id=[1])

LegacySink(name=[MySink2], fields=[count, word])
+- Union(all=[true], union=[count, word])
   :- Reused(reference_id=[1])
   +- TableSourceScan(table=[[default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]]], fields=[count, word])

== Physical Execution Plan ==
Stage 1 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 2 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 3 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource1, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 4 : Operator
				content : Calc(where: (word LIKE _UTF-16LE'F%'), select: (count, word))
				ship_strategy : FORWARD

				Stage 5 : Operator
					content : SinkConversionToRow
					ship_strategy : FORWARD

					Stage 6 : Operator
						content : Map
						ship_strategy : FORWARD

Stage 8 : Data Source
	content : collect elements with CollectionInputFormat

	Stage 9 : Operator
		content : CsvTableSource(read fields: count, word)
		ship_strategy : REBALANCE

		Stage 10 : Operator
			content : SourceConversion(table:Buffer(default_catalog, default_database, MySource2, source: [CsvTableSource(read fields: count, word)]), fields:(count, word))
			ship_strategy : FORWARD

			Stage 12 : Operator
				content : SinkConversionToRow
				ship_strategy : FORWARD

				Stage 13 : Operator
					content : Map
					ship_strategy : FORWARD

					Stage 7 : Data Sink
						content : Sink: CsvTableSink(count, word)
						ship_strategy : FORWARD

						Stage 14 : Data Sink
							content : Sink: CsvTableSink(count, word)
							ship_strategy : FORWARD
</code></pre><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/common.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[流的概念]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-streaming-concepts/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Streaming Concepts</blockquote><h2 id="流的概念">流的概念</h2>
<p>Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html">Table API</a>和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/index.html">SQL 支持</a>是批处理和流处理的统一 API。这意味着Table API 和 SQL 查询具有相同的语义，无论其输入是有界批处理输入还是无界流输入。由于关系代数和 SQL 最初是为批处理设计的，所以对无界流输入的关系查询不如对有界批输入的关系查询好理解。</p>
<p>下面几页解释了 Flink 的关系 API 在流数据上的概念、实际限制和特定流的配置参数。</p>
<h2 id="下一步该往哪里走">下一步该往哪里走？</h2>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>。描述动态表的概念。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>。解释时间属性，以及在表API和SQL中如何处理时间属性。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">连续查询中的连接</a>。连续查询中支持的不同类型的连接。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>。描述临时表的概念。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>。列出 Table API 和 SQL 特定配置选项。</li>
</ul>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[用户定义函数]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-functions/?utm_source=atom_feed" rel="related" type="text/html" title="函数" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-table-api-user-defined-functions/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>User Defined Functions</blockquote><h1 id="用户自定义函数">用户自定义函数</h1>
<p>用户自定义函数(UDFs)是扩展点，用于调用常用的逻辑或自定义逻辑，这些逻辑无法在查询中以其他方式表达。</p>
<p>用户定义函数可以用 JVM 语言（如 Java 或 Scala）或 Python 实现。实现者可以在 UDF 中使用任意的第三方库。本页将重点介绍基于 JVM 的语言。</p>
<h2 id="概述">概述</h2>
<p>目前，Flink 区分了以下几种函数。</p>
<ul>
<li>标量函数将标量值映射到一个新的标量值。</li>
<li>表函数将标量值映射到新的行(row)。</li>
<li>聚合函数将多行的标量值映射到新的标量值。</li>
<li>表聚合函数将多行的标量值映射到新的行上。</li>
<li>异步表函数是针对 table source 执行查找的特殊函数。</li>
</ul>
<p>注意: 标量函数和表函数已经更新为基于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>的新类型系统。聚合函数仍然使用基于 TypeInformation 的旧类型系统。</p>
<p>下面的示例展示了如何创建一个简单的标量函数，以及如何在表 API 和 SQL 中调用该函数。</p>
<p>对于 SQL 查询，一个函数必须始终以一个名字注册。对于 Table API，函数可以被注册，也可以直接内联使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="c1">// define function logic
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SubstringFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">begin</span><span class="o">,</span> <span class="n">end</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SubstringFunction</span><span class="o">]</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">SubstringFunction</span><span class="o">]</span><span class="o">)</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT SubstringFunction(myField, 5, 12) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><p>对于交互式会话，也可以在使用或注册函数之前对其进行参数化。在这种情况下，可以使用函数实例代替函数类作为临时函数。</p>
<p>它要求参数是可序列化的，以便将函数实例运送到集群。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="c1">// define parameterizable function logic
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="k">val</span> <span class="n">endInclusive</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">endInclusive</span> <span class="o">?</span> <span class="n">end</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">:</span> <span class="kt">end</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="k">new</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">12</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SubstringFunction&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SubstringFunction</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span><span class="o">)</span>
</code></pre></div><h2 id="实现指南">实现指南</h2>
<p>注意：本节目前只适用于标量函数和表函数；在集合函数更新到新的类型系统之前，本节只适用于标量函数。</p>
<p>无论函数的种类如何，所有用户定义的函数都遵循一些基本的实现原则。</p>
<h3 id="函数类">函数类</h3>
<p>一个实现类必须从一个可用的基类(例如 <code>org.apache.flink.table.function.ScalarFunction</code>)中扩展出来。</p>
<p>这个类必须被声明为 <code>public</code>，而不是 <code>abstract</code>，并且应该是全局访问的。因此，不允许使用非静态的内部类或匿名类。</p>
<p>对于在持久化目录中存储用户定义的函数，该类必须有一个默认的构造函数，并且在运行时必须是可实例化的。</p>
<h3 id="评估方法">评估方法</h3>
<p>基类提供了一组可以重写的方法，如 <code>open()</code>、<code>close()</code> 或 <code>isDeterministic()</code>。</p>
<p>然而，除了这些声明的方法外，应用于每个传入记录的主要运行时逻辑必须通过专门的评估方法来实现。</p>
<p>根据函数种类的不同，评价方法如 <code>eval()</code>、<code>accumulate()</code> 或 <code>retract()</code> 会在运行时被代码生成的操作符调用。</p>
<p>这些方法必须声明为 <code>public</code>，并接受一组定义明确的参数。</p>
<p>常规的 JVM 方法调用语义适用。因此，可以</p>
<ul>
<li>实现重载方法，如 <code>eval(Integer)</code> 和 <code>eval(LocalDateTime)</code>。</li>
<li>使用 var-args，如 <code>eval(Integer...)</code>。</li>
<li>使用对象继承，如 <code>eval(Object)</code>，它同时接受 <code>LocalDateTime</code> 和 <code>Integer</code>。</li>
<li>以及上述函数的组合，如 <code>eval(Object...)</code>，它可以接受所有类型的参数。</li>
</ul>
<p>如果你打算在 Scala 中实现函数，请在使用变量参数时添加 scala.annotation.varargs 注解。此外，建议使用盒状基元（如用 java.lang.Integer 代替 Int）来支持 NULL。</p>
<p>下面的代码段显示了一个重载函数的示例。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>
<span class="k">import</span> <span class="nn">java.lang.Integer</span>
<span class="k">import</span> <span class="nn">java.lang.Double</span>
<span class="k">import</span> <span class="nn">scala.annotation.varargs</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1"></span><span class="k">class</span> <span class="nc">SumFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Integer</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">a</span><span class="o">)</span> <span class="o">+</span> <span class="nc">Integer</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">b</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="nd">@varargs</span> <span class="c1">// generate var-args like Java
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">d</span><span class="k">:</span> <span class="kt">Double</span><span class="kt">*</span><span class="o">)</span><span class="k">:</span> <span class="kt">Integer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">d</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">toInt</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="类型推断">类型推断</h3>
<p>表生态系统（类似于 SQL 标准）是一个强类型的 API。因此，函数参数和返回类型都必须映射到<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html">数据类型</a>。</p>
<p>从逻辑的角度来看，规划师需要关于预期类型、精度和规模的信息。从 JVM 的角度来看，规划师需要了解当调用用户定义的函数时，内部数据结构如何被表示为 JVM 对象。</p>
<p>验证输入参数和推导出函数的参数和结果的数据类型的逻辑被总结在类型推理这个术语下。</p>
<p>Flink 的用户定义函数实现了自动类型推理提取，通过反射从函数的类和它的评估方法中导出数据类型。如果这种隐式反射提取方法不成功，可以通过用 <code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注释受影响的参数、类或方法来支持提取过程。更多关于如何注释函数的例子如下所示。</p>
<p>如果需要更高级的类型推理逻辑，实现者可以在每个用户定义的函数中显式覆盖 <code>getTypeInference()</code> 方法。然而，推荐使用注释方法，因为它将自定义类型推理逻辑保持在受影响的位置附近，并回落到其余实现的默认行为。</p>
<h4 id="自动类型推断">自动类型推断</h4>
<p>自动类型推理检查函数的类和评估方法，从而得出函数的参数和结果的数据类型。<code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注解支持自动提取。</p>
<p>关于可以隐式映射到数据类型的类的完整列表，请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/types.html#data-type-extraction">数据类型提取</a>部分。</p>
<h5 id="datatypehint">@DataTypeHint</h5>
<p>在很多情况下，需要支持对函数的参数和返回类型进行在线自动提取。</p>
<p>下面的示例展示了如何使用数据类型提示。更多信息可以在注解类的文档中找到。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.InputGroup</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>
<span class="k">import</span> <span class="nn">scala.annotation.varargs</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1"></span><span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="c1">// no hint required
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
  <span class="o">}</span>

  <span class="c1">// define the precision and scale of a decimal
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;DECIMAL(12, 3)&#34;</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">double</span> <span class="n">a</span><span class="o">,</span> <span class="n">double</span> <span class="n">b</span><span class="o">)</span><span class="k">:</span> <span class="kt">BigDecimal</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="nc">BigDecimal</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="c1">// define a nested data type
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;s STRING, t TIMESTAMP(3) WITH LOCAL TIME ZONE&gt;&#34;</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nc">Int</span> <span class="n">i</span><span class="o">)</span><span class="k">:</span> <span class="kt">Row</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="nc">String</span><span class="o">.</span><span class="n">valueOf</span><span class="o">(</span><span class="n">i</span><span class="o">)</span><span class="o">,</span> <span class="n">java</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="nc">Instant</span><span class="o">.</span><span class="n">ofEpochSecond</span><span class="o">(</span><span class="n">i</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="c1">// allow wildcard input and customly serialized output
</span><span class="c1"></span>  <span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">value</span> <span class="k">=</span> <span class="s">&#34;RAW&#34;</span><span class="o">,</span> <span class="n">bridgedTo</span> <span class="k">=</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">java</span><span class="kt">.</span><span class="kt">nio</span><span class="kt">.</span><span class="kt">ByteBuffer</span><span class="o">]</span><span class="o">)</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">inputGroup</span> <span class="k">=</span> <span class="nc">InputGroup</span><span class="o">.</span><span class="nc">ANY</span><span class="o">)</span> <span class="nc">Object</span> <span class="n">o</span><span class="o">)</span><span class="k">:</span> <span class="kt">java</span><span class="kt">.</span><span class="kt">nio</span><span class="kt">.</span><span class="kt">ByteBuffer</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">MyUtils</span><span class="o">.</span><span class="n">serializeToByteBuffer</span><span class="o">(</span><span class="n">o</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h5 id="functionhint">@FunctionHint</h5>
<p>在某些场景下，一个评估方法同时处理多种不同的数据类型是可取的。此外，在某些场景中，重载的评估方法有一个共同的结果类型，应该只声明一次。</p>
<p><code>@FunctionHint</code> 注解可以提供从参数数据类型到结果数据类型的映射。它可以为输入、累加器和结果数据类型注释整个函数类或评估方法。一个或多个注解可以在一个类的顶部声明，也可以为每个评估方法单独声明，以便重载函数签名。所有的提示参数都是可选的。如果没有定义参数，则使用默认的基于反射的提取方式。在函数类之上定义的提示参数会被所有的评估方法继承。</p>
<p>下面的例子展示了如何使用函数提示。更多信息可以在注解类的文档中找到。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.FunctionHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>

<span class="c1">// function with overloaded evaluation methods
</span><span class="c1"></span><span class="c1">// but globally defined output type
</span><span class="c1"></span><span class="nd">@FunctionHint</span><span class="o">(</span><span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;s STRING, i INT&gt;&#34;</span><span class="o">)</span><span class="o">)</span>
<span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="s">&#34;Sum&#34;</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="c1">// overloading of arguments is still possible
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="s">&#34;Empty args&#34;</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// decouples the type inference from evaluation methods,
</span><span class="c1"></span><span class="c1">// the type inference is entirely determined by the function hints
</span><span class="c1"></span><span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">,</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;INT&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">)</span><span class="o">,</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">)</span><span class="o">)</span><span class="o">,</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BIGINT&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="nd">@FunctionHint</span><span class="o">(</span>
  <span class="n">input</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="o">)</span><span class="o">,</span>
  <span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;BOOLEAN&#34;</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">class</span> <span class="nc">OverloadedFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">AnyRef</span><span class="o">]</span> <span class="o">{</span>

  <span class="c1">// an implementer just needs to make sure that a method exists
</span><span class="c1"></span>  <span class="c1">// that can be called by the JVM
</span><span class="c1"></span>  <span class="nd">@varargs</span>
  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">o</span><span class="k">:</span> <span class="kt">AnyRef</span><span class="kt">*</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">o</span><span class="o">.</span><span class="n">length</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">collect</span><span class="o">(</span><span class="nc">Boolean</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="n">collect</span><span class="o">(</span><span class="n">o</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h4 id="自定义类型推断">自定义类型推断</h4>
<p>对于大多数情况下，<code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 应该足以为用户定义的函数建模。然而，通过覆盖 <code>getTypeInference()</code> 中定义的自动类型推理，实现者可以创建任意的函数，这些函数的行为就像内置的系统函数一样。</p>
<p>下面这个用 Java 实现的例子说明了自定义类型推理逻辑的潜力。它使用一个字符串文字参数来确定一个函数的结果类型。该函数需要两个字符串参数：第一个参数代表要解析的字符串，第二个参数代表目标类型。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.flink.table.api.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.catalog.DataTypeFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.table.types.inference.TypeInference</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.flink.types.Row</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">LiteralFunction</span> <span class="kd">extends</span> <span class="n">ScalarFunction</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Object</span> <span class="nf">eval</span><span class="o">(</span><span class="n">String</span> <span class="n">s</span><span class="o">,</span> <span class="n">String</span> <span class="n">type</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">switch</span> <span class="o">(</span><span class="n">type</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">case</span> <span class="s">&#34;INT&#34;</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">s</span><span class="o">)</span><span class="o">;</span>
      <span class="k">case</span> <span class="s">&#34;DOUBLE&#34;</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">Double</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">s</span><span class="o">)</span><span class="o">;</span>
      <span class="k">case</span> <span class="s">&#34;STRING&#34;</span><span class="o">:</span>
      <span class="k">default</span><span class="o">:</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">;</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="c1">// the automatic, reflection-based type inference is disabled and
</span><span class="c1"></span>  <span class="c1">// replaced by the following logic
</span><span class="c1"></span>  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">TypeInference</span> <span class="nf">getTypeInference</span><span class="o">(</span><span class="n">DataTypeFactory</span> <span class="n">typeFactory</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">TypeInference</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">(</span><span class="o">)</span>
      <span class="c1">// specify typed arguments
</span><span class="c1"></span>      <span class="c1">// parameters will be casted implicitly to those types if necessary
</span><span class="c1"></span>      <span class="o">.</span><span class="na">typedArguments</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>
      <span class="c1">// specify a strategy for the result data type of the function
</span><span class="c1"></span>      <span class="o">.</span><span class="na">outputTypeStrategy</span><span class="o">(</span><span class="n">callContext</span> <span class="o">-</span><span class="o">&gt;</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="o">!</span><span class="n">callContext</span><span class="o">.</span><span class="na">isArgumentLiteral</span><span class="o">(</span><span class="n">1</span><span class="o">)</span> <span class="o">|</span><span class="o">|</span> <span class="n">callContext</span><span class="o">.</span><span class="na">isArgumentNull</span><span class="o">(</span><span class="n">1</span><span class="o">)</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">throw</span> <span class="n">callContext</span><span class="o">.</span><span class="na">newValidationError</span><span class="o">(</span><span class="s">&#34;Literal expected for second argument.&#34;</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="c1">// return a data type based on a literal
</span><span class="c1"></span>        <span class="kd">final</span> <span class="n">String</span> <span class="n">literal</span> <span class="o">=</span> <span class="n">callContext</span><span class="o">.</span><span class="na">getArgumentValue</span><span class="o">(</span><span class="n">1</span><span class="o">,</span> <span class="n">String</span><span class="o">.</span><span class="na">class</span><span class="o">)</span><span class="o">.</span><span class="na">orElse</span><span class="o">(</span><span class="s">&#34;STRING&#34;</span><span class="o">)</span><span class="o">;</span>
        <span class="k">switch</span> <span class="o">(</span><span class="n">literal</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">case</span> <span class="s">&#34;INT&#34;</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">notNull</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
          <span class="k">case</span> <span class="s">&#34;DOUBLE&#34;</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">DOUBLE</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="na">notNull</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
          <span class="k">case</span> <span class="s">&#34;STRING&#34;</span><span class="o">:</span>
          <span class="k">default</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">Optional</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">(</span><span class="o">)</span><span class="o">)</span><span class="o">;</span>
        <span class="o">}</span>
      <span class="o">}</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><h3 id="运行时集成">运行时集成</h3>
<p>有时可能需要用户自定义函数在实际工作前获取全局运行时信息或做一些设置/清理工作。用户自定义函数提供了 <code>open()</code> 和 <code>close()</code> 方法，这些方法可以被重写，并提供与 DataStream API 的 RichFunction 中的方法类似的功能。</p>
<p><code>open()</code> 方法在评估方法之前被调用一次。<code>close()</code> 方法在最后一次调用评估方法后调用。</p>
<p><code>open()</code> 方法提供了一个 FunctionContext，该 FunctionContext 包含了用户定义函数执行的上下文信息，如度量组、分布式缓存文件或全局作业参数。</p>
<p>通过调用 FunctionContext 的相应方法，可以获得以下信息。</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">getMetricGroup()</td>
<td align="left">该并行子任务的度量组。</td>
</tr>
<tr>
<td align="left">getCachedFile(name)</td>
<td align="left">分布式缓存文件的本地临时文件副本。</td>
</tr>
<tr>
<td align="left">getJobParameter(name, defaultValue)</td>
<td align="left">与给定键相关联的全局作业参数值。</td>
</tr>
</tbody>
</table>
<p>下面的示例片段展示了如何在标量函数中使用 FunctionContext 来访问全局工作参数。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.FunctionContext</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="k">class</span> <span class="nc">HashCodeFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="k">private</span> <span class="k">var</span> <span class="n">factor</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">context</span><span class="k">:</span> <span class="kt">FunctionContext</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// access the global &#34;hashcode_factor&#34; parameter
</span><span class="c1"></span>    <span class="c1">// &#34;12&#34; would be the default value if the parameter does not exist
</span><span class="c1"></span>    <span class="n">factor</span> <span class="k">=</span> <span class="n">context</span><span class="o">.</span><span class="n">getJobParameter</span><span class="o">(</span><span class="s">&#34;hashcode_factor&#34;</span><span class="o">,</span> <span class="s">&#34;12&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">toInt</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">s</span><span class="o">.</span><span class="n">hashCode</span> <span class="o">*</span> <span class="n">factor</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// add job parameter
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">getConfig</span><span class="o">.</span><span class="n">addJobParameter</span><span class="o">(</span><span class="s">&#34;hashcode_factor&#34;</span><span class="o">,</span> <span class="s">&#34;31&#34;</span><span class="o">)</span>

<span class="c1">// register the function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;hashCode&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">HashCodeFunction</span><span class="o">]</span><span class="o">)</span>

<span class="c1">// use the function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT myField, hashCode(myField) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="标量函数">标量函数</h2>
<p>用户定义的标量函数可以将零、一或多个标量值映射到一个新的标量值。数据类型一节中列出的任何数据类型都可以作为一个评估方法的参数或返回类型。</p>
<p>为了定义一个标量函数，必须扩展 org.apache.flink.table.function 中的基类 ScalarFunction，并实现一个或多个名为 <code>eval(...)</code> 的评估方法。</p>
<p>下面的例子展示了如何定义自己的哈希码函数并在查询中调用它。更多细节请参见实施指南。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.InputGroup</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.ScalarFunction</span>

<span class="k">class</span> <span class="nc">HashFunction</span> <span class="k">extends</span> <span class="nc">ScalarFunction</span> <span class="o">{</span>

  <span class="c1">// take any data type and return INT
</span><span class="c1"></span>  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="nd">@DataTypeHint</span><span class="o">(</span><span class="n">inputGroup</span> <span class="k">=</span> <span class="nc">InputGroup</span><span class="o">.</span><span class="nc">ANY</span><span class="o">)</span> <span class="n">o</span><span class="k">:</span> <span class="kt">AnyRef</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">{</span>
    <span class="kt">return</span> <span class="kt">o</span><span class="kt">.</span><span class="kt">hashCode</span><span class="o">(</span><span class="o">)</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">HashFunction</span><span class="o">]</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;HashFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">HashFunction</span><span class="o">]</span><span class="o">)</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;HashFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT HashFunction(myField) FROM MyTable&#34;</span><span class="o">)</span>
</code></pre></div><p>如果你打算用 Python 实现或调用函数，请参考 Python Scalar Functions 文档了解更多细节。</p>
<h2 id="表函数">表函数</h2>
<p>与用户定义的标量函数类似，用户定义的表函数将零、一个或多个标量值作为输入参数。然而，与标量函数不同的是，它可以返回任意数量的行（或结构化类型）作为输出，而不是单个值。返回的记录可能由一个或多个字段组成。如果一条输出记录只由一个字段组成，则可以省略结构化记录，并发出一个标量值。它将被运行时包装成一个隐式行。</p>
<p>为了定义一个表函数，必须扩展 org.apache.flink.table.function 中的基类 TableFunction，并实现一个或多个名为 <code>eval(...)</code> 的评估方法。与其他函数类似，输入和输出数据类型也是使用反射自动提取的。这包括类的通用参数 T，用于确定输出数据类型。与标量函数不同的是，评价方法本身不能有返回类型，相反，表函数提供了一个 <code>collect(T)</code> 方法，可以在每个评价方法内调用，用于发出零、一条或多条记录。</p>
<p>在表 API 中，表函数的使用方法是 <code>.joinLateral(...)</code> 或 <code>.leftOuterJoinLateral(...)</code>。joinLateral 运算符（cross）将外表（运算符左边的表）的每条记录与表值函数产生的所有记录（表值函数在运算符的右边）连接起来。leftOuterJoinLateral 操作符将外表（操作符左边的表）的每一条记录与表值函数产生的所有记录（它在操作符的右边）连接起来，并且保留那些表函数返回空表的外表。</p>
<p>在 SQL 中，使用 <code>LATERAL TABLE(&lt;TableFunction&gt;)</code> 与 JOIN 或 LEFT JOIN 与 ON TRUE 连接条件。</p>
<p>下面的示例展示了如何定义自己的拆分函数并在查询中调用它。更多细节请参见《实现指南》。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.DataTypeHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.annotation.FunctionHint</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api._</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableFunction</span>
<span class="k">import</span> <span class="nn">org.apache.flink.types.Row</span>

<span class="nd">@FunctionHint</span><span class="o">(</span><span class="n">output</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataTypeHint</span><span class="o">(</span><span class="s">&#34;ROW&lt;word STRING, length INT&gt;&#34;</span><span class="o">)</span><span class="o">)</span>
<span class="k">class</span> <span class="nc">SplitFunction</span> <span class="k">extends</span> <span class="nc">TableFunction</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">eval</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// use collect(...) to emit a row
</span><span class="c1"></span>    <span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">collect</span><span class="o">(</span><span class="nc">Row</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="nc">Int</span><span class="o">.</span><span class="n">box</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">length</span><span class="o">)</span><span class="o">)</span><span class="o">)</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="o">.</span><span class="o">.</span><span class="o">.</span><span class="o">)</span>

<span class="c1">// call function &#34;inline&#34; without registration in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">]</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>
<span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">]</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>

<span class="c1">// rename fields of the function in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">]</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;newWord&#34;</span><span class="o">,</span> <span class="s">&#34;newLength&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;newWord&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;newLength&#34;</span><span class="o">)</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">createTemporarySystemFunction</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">SplitFunction</span><span class="o">]</span><span class="o">)</span>

<span class="c1">// call registered function in Table API
</span><span class="c1"></span><span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>
<span class="n">env</span>
  <span class="o">.</span><span class="n">from</span><span class="o">(</span><span class="s">&#34;MyTable&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">leftOuterJoinLateral</span><span class="o">(</span><span class="n">call</span><span class="o">(</span><span class="s">&#34;SplitFunction&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;myField&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;word&#34;</span><span class="o">,</span> <span class="n">$</span><span class="s">&#34;length&#34;</span><span class="o">)</span>

<span class="c1">// call registered function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, word, length &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable, LATERAL TABLE(SplitFunction(myField))&#34;</span><span class="o">)</span><span class="o">;</span>
<span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, word, length &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable &#34;</span> <span class="o">+</span>
  <span class="s">&#34;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) ON TRUE&#34;</span><span class="o">)</span>

<span class="c1">// rename fields of the function in SQL
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span>
  <span class="s">&#34;SELECT myField, newWord, newLength &#34;</span> <span class="o">+</span>
  <span class="s">&#34;FROM MyTable &#34;</span> <span class="o">+</span>
  <span class="s">&#34;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) AS T(newWord, newLength) ON TRUE&#34;</span><span class="o">)</span>
</code></pre></div><p>如果你打算在 Scala 中实现函数，不要将表函数实现为 Scala 对象。Scala 对象是单子，会导致并发问题。</p>
<p>如果你打算用 Python 实现或调用函数，请参考 Python 表函数文档了解更多细节。</p>
<h2 id="聚合函数">聚合函数</h2>
<p>用户自定义聚合函数（UDAGG）将一个表（一个或多个具有一个或多个属性的行）聚合成一个标量值。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/udagg-mechanism.png" alt="img"></p>
<p>上图显示了一个聚合的例子。假设你有一个包含饮料数据的表。该表由 id、名称和价格三列和 5 行组成。想象一下，你需要找到表中所有饮料的最高价格，即执行 <code>max()</code> 聚合。你需要对 5 行中的每一行进行检查，结果将是一个单一的数值。</p>
<p>用户定义的聚合函数是通过扩展 AggregateFunction 类来实现的。AggregateFunction 的工作原理如下。首先，它需要一个累加器，它是存放聚合中间结果的数据结构。通过调用 AggregateFunction 的 <code>createAccumulator()</code> 方法创建一个空的累加器。随后，函数的 <code>accumulate()</code> 方法对每一条输入行进行调用，以更新累加器。一旦所有的行都被处理完毕，函数的 <code>getValue()</code> 方法就会被调用来计算并返回最终结果。</p>
<p>以下方法是每个 AggregateFunction 必须使用的。</p>
<ul>
<li>createAccumulator()</li>
<li>accumulate()</li>
<li>getValue()</li>
</ul>
<p>Flink 的类型提取设施可能无法识别复杂的数据类型，例如，如果它们不是基本类型或简单的 POJOs。所以与 ScalarFunction 和 TableFunction 类似，AggregateFunction 提供了指定结果类型（通过 AggregateFunction#getResultType()）和累加器类型（通过 AggregateFunction#getAccumulatorType()）的方法。</p>
<p>除了上述方法外，还有一些签约方法可以选择实现。这些方法中的一些方法可以让系统更高效地执行查询，而另一些方法则是某些用例所必须的。例如，如果聚合函数应该在会话组窗口的上下文中应用，那么 <code>merge()</code> 方法是强制性的（当观察到有一行 &ldquo;连接 &ldquo;它们时，需要将两个会话窗口的累加器连接起来）。</p>
<p>AggregateFunction 的以下方法是根据用例需要的。</p>
<ul>
<li><code>retract()</code> 对于有界 OVER 窗口上的聚合是需要的。</li>
<li><code>merge()</code> 是许多批次聚合和会话窗口聚合所需要的。</li>
<li><code>resetAccumulator()</code> 是许多批处理聚合所需要的。</li>
</ul>
<p>AggregateFunction 的所有方法都必须声明为 public，而不是 static，并且命名与上述名称完全一致。方法 createAccumulator、getValue、getResultType 和 getAccumulatorType 是在 AggregateFunction 抽象类中定义的，而其他方法则是合同方法。为了定义一个聚合函数，必须扩展基类 org.apache.flink.table.function.AggregateFunction，并实现一个（或多个）accumulate 方法。方法 accumulate 可以用不同的参数类型重载，并支持变量参数。</p>
<p>下面给出了 AggregateFunction 所有方法的详细文档。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> Base class for user-defined aggregates and table aggregates.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam T   the type of the aggregation result.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  </span><span class="cm">*/</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedFunction</span> <span class="o">{</span>

  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Creates and init the Accumulator for this (table)aggregate function.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return the accumulator with the initial value
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">ACC</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Returns the TypeInformation of the (table)aggregate function&#39;s result.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return The TypeInformation of the (table)aggregate function&#39;s result or null if the result
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">         type should be automatically inferred.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Returns the TypeInformation of the (table)aggregate function&#39;s accumulator.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return The TypeInformation of the (table)aggregate function&#39;s accumulator or null if the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">         accumulator type should be automatically inferred.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> Base class for aggregation functions. 
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam T   the type of the aggregation result
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             AggregateFunction represents its state using accumulator, thereby the state of the
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             AggregateFunction must be put into the accumulator.
</span><span class="cm">  </span><span class="cm">*/</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="o">{</span>

  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Processes the input values and update the provided accumulator instance. The method
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> accumulate can be overloaded with different custom types and arguments. An AggregateFunction
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> requires at least one accumulate() method.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Retracts the input values from the accumulator instance. The current design assumes the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> inputs are the values that have been previously accumulated. The method retract can be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> overloaded with different custom types and arguments. This function must be implemented for
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> datastream bounded over aggregate.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Merges a group of accumulator instances into one accumulator instance. This function must be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> implemented for datastream session window grouping aggregate and dataset grouping aggregate.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator  the accumulator which will keep the merged aggregate results. It should
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     be noted that the accumulator may contain the previous aggregated
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     results. Therefore user should not replace or clean this instance in the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     custom merge method.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param its          an [[java.lang.Iterable]] pointed to a group of accumulators that will be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     merged.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>  
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Called every time when an aggregation result should be materialized.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> The returned value could be either an early and incomplete result
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> (periodically emitted as data arrive) or the final result of the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> aggregation.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator the accumulator which contains the current
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                    aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return the aggregation result
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Resets the accumulator for this [[AggregateFunction]]. This function must be implemented for
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> dataset grouping aggregate.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator  the accumulator which needs to be reset
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Returns true if this AggregateFunction can only be applied in an OVER window.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return true if the AggregateFunction requires an OVER window, false otherwise.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">requiresOver</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="kc">false</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>
</code></pre></div><p>下面的例子说明了如何进行</p>
<ul>
<li>定义一个 AggregateFunction，用于计算给定列的加权平均值。</li>
<li>在 TableEnvironment 中注册该函数，并且</li>
<li>在查询中使用该函数。</li>
</ul>
<p>为了计算加权平均值，累加器需要存储所有已积累的数据的加权和和计数。在我们的例子中，我们定义了一个类 WeightedAvgAccum 作为累加器。累积器由 Flink 的检查点机制自动备份，并在故障时恢复，以保证精确的唯一性语义。</p>
<p>我们 WeightedAvg AggregateFunction 的 <code>accumulate()</code> 方法有三个输入。第一个是 WeightedAvgAccum 累加器，另外两个是用户自定义的输入：输入值 ivalue 和输入的权重 iweight。虽然 <code>retract()</code>、<code>merge()</code> 和 <code>resetAccumulator()</code> 方法对于大多数聚合类型来说并不是强制性的，但我们在下面提供它们作为例子。请注意，我们在 Scala 示例中使用了 Java 基元类型，并定义了 <code>getResultType()</code> 和  <code>getAccumulatorType()</code> 方法，因为 Flink 类型提取对于 Scala 类型并不十分有效。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Long</span> <span class="k">=&gt;</span> <span class="nc">JLong</span><span class="o">,</span> <span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.tuple.</span><span class="o">{</span><span class="nc">Tuple1</span> <span class="k">=&gt;</span> <span class="nc">JTuple1</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.typeutils.TupleTypeInfo</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.AggregateFunction</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> Accumulator for WeightedAvg.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">WeightedAvgAccum</span> <span class="k">extends</span> <span class="nc">JTuple1</span><span class="o">[</span><span class="kt">JLong</span>, <span class="kt">JInteger</span><span class="o">]</span> <span class="o">{</span>
  <span class="n">sum</span> <span class="k">=</span> <span class="mi">0L</span>
  <span class="n">count</span> <span class="k">=</span> <span class="mi">0</span>
<span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> Weighted Average user-defined aggregate function.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">WeightedAvg</span> <span class="k">extends</span> <span class="nc">AggregateFunction</span><span class="o">[</span><span class="kt">JLong</span>, <span class="kt">CountAccumulator</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">WeightedAvgAccum</span>
  <span class="o">}</span>
  
  <span class="k">override</span> <span class="k">def</span> <span class="n">getValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">)</span><span class="k">:</span> <span class="kt">JLong</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
        <span class="kc">null</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="n">acc</span><span class="o">.</span><span class="n">count</span>
    <span class="o">}</span>
  <span class="o">}</span>
  
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">iValue</span><span class="k">:</span> <span class="kt">JLong</span><span class="o">,</span> <span class="n">iWeight</span><span class="k">:</span> <span class="kt">JInteger</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">iValue</span> <span class="o">*</span> <span class="n">iWeight</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">iWeight</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">iValue</span><span class="k">:</span> <span class="kt">JLong</span><span class="o">,</span> <span class="n">iWeight</span><span class="k">:</span> <span class="kt">JInteger</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">-=</span> <span class="n">iValue</span> <span class="o">*</span> <span class="n">iWeight</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">-=</span> <span class="n">iWeight</span>
  <span class="o">}</span>
    
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">,</span> <span class="n">it</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">it</span><span class="o">.</span><span class="n">iterator</span><span class="o">(</span><span class="o">)</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">a</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="o">)</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">a</span><span class="o">.</span><span class="n">count</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">resetAccumulator</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">WeightedAvgAccum</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">count</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">sum</span> <span class="k">=</span> <span class="mi">0L</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">new</span> <span class="nc">TupleTypeInfo</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">WeightedAvgAccum</span><span class="o">]</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span><span class="o">,</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">INT</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">JLong</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Types</span><span class="o">.</span><span class="nc">LONG</span>
<span class="o">}</span>

<span class="c1">// register function
</span><span class="c1"></span><span class="k">val</span> <span class="n">tEnv</span><span class="k">:</span> <span class="kt">StreamTableEnvironment</span> <span class="o">=</span> <span class="o">???</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">registerFunction</span><span class="o">(</span><span class="s">&#34;wAvg&#34;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">WeightedAvg</span><span class="o">(</span><span class="o">)</span><span class="o">)</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">&#34;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&#34;</span><span class="o">)</span>
</code></pre></div><h2 id="表聚合函数">表聚合函数</h2>
<p>用户定义表聚合函数(UDTAGGs)将一个表(具有一个或多个属性的一行或多行)聚合到一个具有多行和多列的结果表。</p>
<p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/udtagg-mechanism.png" alt="img"></p>
<p>上图显示了一个表聚合的例子。假设你有一个包含饮料数据的表。该表由 id、名称和价格三列和 5 行组成。设想你需要找到表中所有饮料中价格最高的前 2 名，即执行 <code>top2()</code> 表聚合。你需要对 5 行中的每一行进行检查，结果将是一个具有前 2 个值的表。</p>
<p>用户定义的表聚合函数是通过扩展 TableAggregateFunction 类来实现的。TableAggregateFunction 的工作原理如下。首先，它需要一个累加器，它是存放聚合中间结果的数据结构。通过调用 TableAggregateFunction 的 <code>createAccumulator()</code> 方法创建一个空的累加器。随后，对每一条输入行调用函数的 <code>accumulate()</code> 方法来更新累加器。一旦所有的行都被处理完毕，函数的 <code>emitValue()</code> 方法就会被调用来计算并返回最终结果。</p>
<p>以下方法是每个 TableAggregateFunction 必须使用的。</p>
<ul>
<li>createAccumulator()</li>
<li>accumulate()</li>
</ul>
<p>Flink 的类型提取设施可能无法识别复杂的数据类型，例如，如果它们不是基本类型或简单的 POJOs。因此，与 ScalarFunction 和 TableFunction 类似，TableAggregateFunction 提供了指定结果类型（通过 <code>TableAggregateFunction#getResultType()</code>）和累积器类型（通过 <code>TableAggregateFunction#getAccumulatorType()</code>）的方法。</p>
<p>除了上述方法外，还有一些签约方法可以选择实现。这些方法中的一些方法可以让系统更高效地执行查询，而另一些方法则是某些用例所必须的。例如，如果聚合函数应该在会话组窗口的上下文中应用，那么 <code>merge()</code> 方法是强制性的（当观察到有一条记录&quot;连接&quot;它们时，需要将两个会话窗口的累加器连接起来）。</p>
<p>TableAggregateFunction 的以下方法是需要的，这取决于用例。</p>
<ul>
<li><code>retract()</code> 对于有界 OVER 窗口上的聚合是需要的。</li>
<li><code>merge()</code> 是许多批次聚合和会话窗口聚合所需要的。</li>
<li><code>resetAccumulator()</code> 是许多批处理聚合所需要的。</li>
<li><code>emitValue()</code> 是批处理和窗口聚合所需要的。</li>
</ul>
<p>TableAggregateFunction 的以下方法用于提高流作业的性能。</p>
<ul>
<li><code>emitUpdateWithRetract()</code> 用于发射在伸缩模式下更新的值。</li>
</ul>
<p>对于 emitValue 方法，则是根据累加器来发射完整的数据。以 TopN 为例，emitValue 每次都会发射所有前 n 个值。这可能会给流式作业带来性能问题。为了提高性能，用户也可以实现 emitUpdateWithRetract 方法来提高性能。该方法以回缩模式增量输出数据，即一旦有更新，我们必须在发送新的更新记录之前回缩旧记录。如果在表聚合函数中都定义了该方法，那么该方法将优先于 emitValue 方法使用，因为 emitUpdateWithRetract 被认为比 emitValue 更有效率，因为它可以增量输出值。</p>
<p>TableAggregateFunction 的所有方法都必须声明为 public，而不是 static，并完全按照上面提到的名字命名。方法 createAccumulator、getResultType 和 getAccumulatorType 是在 TableAggregateFunction 的父抽象类中定义的，而其他方法则是收缩的方法。为了定义一个表聚合函数，必须扩展基类 org.apache.flink.table.function.TableAggregateFunction，并实现一个（或多个）accumulate 方法。积累方法可以用不同的参数类型重载，并支持变量参数。</p>
<p>下面给出了 TableAggregateFunction 所有方法的详细文档。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> Base class for user-defined aggregates and table aggregates.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam T   the type of the aggregation result.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  </span><span class="cm">*/</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedFunction</span> <span class="o">{</span>

  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Creates and init the Accumulator for this (table)aggregate function.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return the accumulator with the initial value
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">ACC</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Returns the TypeInformation of the (table)aggregate function&#39;s result.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return The TypeInformation of the (table)aggregate function&#39;s result or null if the result
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">         type should be automatically inferred.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">getResultType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Returns the TypeInformation of the (table)aggregate function&#39;s accumulator.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @return The TypeInformation of the (table)aggregate function&#39;s accumulator or null if the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">         accumulator type should be automatically inferred.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">getAccumulatorType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span> <span class="k">=</span> <span class="kc">null</span> <span class="c1">// PRE-DEFINED
</span><span class="c1"></span><span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> Base class for table aggregation functions. 
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam T   the type of the aggregation result
</span><span class="cm">  </span><span class="cm">*</span><span class="cm"> @tparam ACC the type of the aggregation accumulator. The accumulator is used to keep the
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             aggregated values which are needed to compute an aggregation result.
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             TableAggregateFunction represents its state using accumulator, thereby the state of
</span><span class="cm">  </span><span class="cm">*</span><span class="cm">             the TableAggregateFunction must be put into the accumulator.
</span><span class="cm">  </span><span class="cm">*/</span>
<span class="k">abstract</span> <span class="k">class</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">UserDefinedAggregateFunction</span><span class="o">[</span><span class="kt">T</span>, <span class="kt">ACC</span><span class="o">]</span> <span class="o">{</span>

  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Processes the input values and update the provided accumulator instance. The method
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> accumulate can be overloaded with different custom types and arguments. A TableAggregateFunction
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> requires at least one accumulate() method.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// MANDATORY
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Retracts the input values from the accumulator instance. The current design assumes the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> inputs are the values that have been previously accumulated. The method retract can be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> overloaded with different custom types and arguments. This function must be implemented for
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> datastream bounded over aggregate.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator           the accumulator which contains the current aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param [user defined inputs] the input value (usually obtained from a new arrived data).
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="o">[</span><span class="kt">user</span> <span class="kt">defined</span> <span class="kt">inputs</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Merges a group of accumulator instances into one accumulator instance. This function must be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> implemented for datastream session window grouping aggregate and dataset grouping aggregate.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator  the accumulator which will keep the merged aggregate results. It should
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     be noted that the accumulator may contain the previous aggregated
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     results. Therefore user should not replace or clean this instance in the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     custom merge method.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param its          an [[java.lang.Iterable]] pointed to a group of accumulators that will be
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                     merged.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">java.lang.Iterable</span><span class="o">[</span><span class="kt">ACC</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>  
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Called every time when an aggregation result should be materialized. The returned value
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> could be either an early and incomplete result  (periodically emitted as data arrive) or
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> the final result of the  aggregation.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator the accumulator which contains the current
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                    aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param out         the collector used to output data
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span>
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Called every time when an aggregation result should be materialized. The returned value
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> could be either an early and incomplete result (periodically emitted as data arrive) or
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> the final result of the aggregation.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Different from emitValue, emitUpdateWithRetract is used to emit values that have been updated.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> This method outputs data incrementally in retract mode, i.e., once there is an update, we
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> have to retract old records before sending new updated ones. The emitUpdateWithRetract
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> method will be used in preference to the emitValue method if both methods are defined in the
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> table aggregate function, because the method is treated to be more efficient than emitValue
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> as it can outputvalues incrementally.
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param accumulator the accumulator which contains the current
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                    aggregated results
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> @param out         the retractable collector used to output data. Use collect method
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                    to output(add) records and use retract method to retract(delete)
</span><span class="cm">    </span><span class="cm">*</span><span class="cm">                    records.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">def</span> <span class="n">emitUpdateWithRetract</span><span class="o">(</span><span class="n">accumulator</span><span class="k">:</span> <span class="kt">ACC</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">RetractableCollector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="c1">// OPTIONAL
</span><span class="c1"></span> 
  <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> Collects a record and forwards it. The collector can output retract messages with the retract
</span><span class="cm">    </span><span class="cm">*</span><span class="cm"> method. Note: only use it in `emitRetractValueIncrementally`.
</span><span class="cm">    </span><span class="cm">*/</span>
  <span class="k">trait</span> <span class="nc">RetractableCollector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Collector</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="o">{</span>
    
    <span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm">      </span><span class="cm">*</span><span class="cm"> Retract a record.
</span><span class="cm">      </span><span class="cm">*</span><span class="cm">
</span><span class="cm">      </span><span class="cm">*</span><span class="cm"> @param record The record to retract.
</span><span class="cm">      </span><span class="cm">*/</span>
    <span class="k">def</span> <span class="n">retract</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p>下面的例子说明了如何进行</p>
<ul>
<li>定义一个 TableAggregateFunction，用于计算给定列上的前 2 个值。</li>
<li>在 TableEnvironment 中注册该函数，并且</li>
<li>在 Table API 查询中使用该函数(TableAggregateFunction 仅由 Table API 支持)。</li>
</ul>
<p>为了计算前 2 名的值，累加器需要存储所有已积累的数据中最大的 2 个值。在我们的例子中，我们定义了一个类 Top2Accum 作为累加器。累积器会被 Flink 的检查点机制自动备份，并在故障时恢复，以保证精确的 once 语义。</p>
<p>我们 Top2 TableAggregateFunction 的 <code>accumulate()</code> 方法有两个输入。第一个是 Top2Accum 累加器，另一个是用户定义的输入：输入值 v，虽然 <code>merge()</code> 方法对于大多数表聚合类型来说不是强制性的，但我们在下面提供它作为例子。请注意，我们在 Scala 示例中使用了 Java 基元类型，并定义了 <code>getResultType()</code> 和 <code>getAccumulatorType()</code> 方法，因为 Flink 类型提取对 Scala 类型的效果并不好。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> Accumulator for top2.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> The top2 user-defined table aggregate function.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">its</span><span class="k">:</span> <span class="kt">JIterable</span><span class="o">[</span><span class="kt">Top2Accum</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">iter</span> <span class="k">=</span> <span class="n">its</span><span class="o">.</span><span class="n">iterator</span><span class="o">(</span><span class="o">)</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">top2</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">(</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">first</span><span class="o">)</span>
      <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="o">,</span> <span class="n">top2</span><span class="o">.</span><span class="n">second</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitValue</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">out</span><span class="k">:</span> <span class="kt">Collector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span><span class="o">]</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="c1">// emit the value and rank
</span><span class="c1"></span>    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// init table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tab</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tab</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>&#39;key<span class="o">)</span>
  <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span>&#39;a<span class="o">)</span> <span class="n">as</span> <span class="o">(</span>&#39;v<span class="o">,</span> &#39;rank<span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span>&#39;key<span class="o">,</span> &#39;v<span class="o">,</span> &#39;rank<span class="o">)</span>
</code></pre></div><p>下面的例子展示了如何使用 emitUpdateWithRetract 方法来只发送更新。在我们的例子中，为了只发出更新，累加器同时保留新旧 top2 的值。注意：如果 topN 的 N 很大，那么同时保留新旧值的效率可能很低。解决这种情况的方法之一是在累加方法中把输入的记录存储到累加器中，然后在 emitUpdateWithRetract 中进行计算。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.</span><span class="o">{</span><span class="nc">Integer</span> <span class="k">=&gt;</span> <span class="nc">JInteger</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.api.Types</span>
<span class="k">import</span> <span class="nn">org.apache.flink.table.functions.TableAggregateFunction</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> Accumulator for top2.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2Accum</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">first</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">second</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">oldFirst</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
  <span class="k">var</span> <span class="n">oldSecond</span><span class="k">:</span> <span class="kt">JInteger</span> <span class="o">=</span> <span class="k">_</span>
<span class="o">}</span>

<span class="cm">/*</span><span class="cm">*</span><span class="cm">
</span><span class="cm"> </span><span class="cm">*</span><span class="cm"> The top2 user-defined table aggregate function.
</span><span class="cm"> </span><span class="cm">*/</span>
<span class="k">class</span> <span class="nc">Top2</span> <span class="k">extends</span> <span class="nc">TableAggregateFunction</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span>, <span class="kt">Top2Accum</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">createAccumulator</span><span class="o">(</span><span class="o">)</span><span class="k">:</span> <span class="kt">Top2Accum</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">acc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Top2Accum</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
    <span class="n">acc</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">accumulate</span><span class="o">(</span><span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span> <span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="k">=</span> <span class="n">v</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">emitUpdateWithRetract</span><span class="o">(</span>
    <span class="n">acc</span><span class="k">:</span> <span class="kt">Top2Accum</span><span class="o">,</span>
    <span class="n">out</span><span class="k">:</span> <span class="kt">RetractableCollector</span><span class="o">[</span><span class="kt">JTuple2</span><span class="o">[</span><span class="kt">JInteger</span>, <span class="kt">JInteger</span><span class="o">]</span><span class="o">]</span><span class="o">)</span>
  <span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span> <span class="o">!=</span> <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// if there is an update, retract old value then emit new value.
</span><span class="c1"></span>      <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="n">retract</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span><span class="o">)</span>
      <span class="o">}</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">first</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span><span class="o">)</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">oldFirst</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">first</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// if there is an update, retract old value then emit new value.
</span><span class="c1"></span>      <span class="k">if</span> <span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="o">!=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">out</span><span class="o">.</span><span class="n">retract</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span>
      <span class="o">}</span>
      <span class="n">out</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="nc">JTuple2</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">acc</span><span class="o">.</span><span class="n">second</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span><span class="o">)</span>
      <span class="n">acc</span><span class="o">.</span><span class="n">oldSecond</span> <span class="k">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">second</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c1">// init table
</span><span class="c1"></span><span class="k">val</span> <span class="n">tab</span> <span class="k">=</span> <span class="o">.</span><span class="o">.</span><span class="o">.</span>

<span class="c1">// use function
</span><span class="c1"></span><span class="n">tab</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>&#39;key<span class="o">)</span>
  <span class="o">.</span><span class="n">flatAggregate</span><span class="o">(</span><span class="n">top2</span><span class="o">(</span>&#39;a<span class="o">)</span> <span class="n">as</span> <span class="o">(</span>&#39;v<span class="o">,</span> &#39;rank<span class="o">)</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span>&#39;key<span class="o">,</span> &#39;v<span class="o">,</span> &#39;rank<span class="o">)</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/functions/udfs.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/function" term="function" label="Function" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[运行 Describe 语句]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-run-a-describe-statement/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Insert 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-sql-hints/?utm_source=atom_feed" rel="related" type="text/html" title="SQL 提示" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-run-a-describe-statement/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Run a Describe Statement</blockquote><h1 id="describe-语句">DESCRIBE 语句</h1>
<p>DESCRIBE 语句用于描述表或视图的模式。</p>
<h2 id="运行一个describe语句">运行一个DESCRIBE语句</h2>
<p>DESCRIBE语句可以用TableEnvironment的executeSql()方法执行，也可以在SQL CLI中执行。executeSql()方法对于一个成功的DESCRIBE操作会返回给定表的模式，否则会抛出一个异常。</p>
<p>下面的例子展示了如何在TableEnvironment和SQL CLI中运行DESCRIBE语句。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">settings</span> <span class="k">=</span> <span class="nc">EnvironmentSettings</span><span class="o">.</span><span class="n">newInstance</span><span class="o">(</span><span class="o">)</span><span class="o">.</span><span class="o">.</span><span class="o">.</span>
<span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">settings</span><span class="o">)</span>

<span class="c1">// register a table named &#34;Orders&#34;
</span><span class="c1"></span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span>
        <span class="s">&#34;CREATE TABLE Orders (&#34;</span> <span class="o">+</span>
        <span class="s">&#34; `user` BIGINT NOT NULl,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; product VARCHAR(32),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; amount INT,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; ts TIMESTAMP(3),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; ptime AS PROCTIME(),&#34;</span> <span class="o">+</span>
        <span class="s">&#34; PRIMARY KEY(`user`) NOT ENFORCED,&#34;</span> <span class="o">+</span>
        <span class="s">&#34; WATERMARK FOR ts AS ts - INTERVAL &#39;1&#39; SECONDS&#34;</span> <span class="o">+</span>
        <span class="s">&#34;) with (...)&#34;</span><span class="o">)</span>

<span class="c1">// print the schema
</span><span class="c1"></span><span class="n">tableEnv</span><span class="o">.</span><span class="n">executeSql</span><span class="o">(</span><span class="s">&#34;DESCRIBE Orders&#34;</span><span class="o">)</span><span class="o">.</span><span class="n">print</span><span class="o">(</span><span class="o">)</span>
</code></pre></div><pre><code>Flink SQL&gt; CREATE TABLE Orders (
&gt;  `user` BIGINT NOT NULl,
&gt;  product VARCHAR(32),
&gt;  amount INT,
&gt;  ts TIMESTAMP(3),
&gt;  ptime AS PROCTIME(),
&gt;  PRIMARY KEY(`user`) NOT ENFORCED,
&gt;  WATERMARK FOR ts AS ts - INTERVAL '1' SECONDS
&gt; ) with (
&gt;  ...
&gt; );
[INFO] Table has been created.

Flink SQL&gt; DESCRIBE Orders;
</code></pre><pre><code>root
 |-- user: BIGINT NOT NULL
 |-- product: VARCHAR(32)
 |-- amount: INT
 |-- ts: TIMESTAMP(3) *ROWTIME*
 |-- ptime: TIMESTAMP(3) NOT NULL *PROCTIME* AS PROCTIME()
 |-- WATERMARK FOR ts AS `ts` - INTERVAL '1' SECOND
 |-- CONSTRAINT PK_3599338 PRIMARY KEY (user)
</code></pre><p>上述例子的结果是：</p>
<pre><code>+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
|    name |                             type |  null |       key | computed column |                  watermark |
+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
|    user |                           BIGINT | false | PRI(user) |                 |                            |
| product |                      VARCHAR(32) |  true |           |                 |                            |
|  amount |                              INT |  true |           |                 |                            |
|      ts |           TIMESTAMP(3) *ROWTIME* |  true |           |                 | `ts` - INTERVAL '1' SECOND |
|   ptime | TIMESTAMP(3) NOT NULL *PROCTIME* | false |           |      PROCTIME() |                            |
+---------+----------------------------------+-------+-----------+-----------------+----------------------------+
5 rows in set
</code></pre><h2 id="语法">语法</h2>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">DESCRIBE</span> <span class="p">[</span><span class="k">catalog_name</span><span class="p">.</span><span class="p">]</span><span class="p">[</span><span class="n">db_name</span><span class="p">.</span><span class="p">]</span><span class="k">table_name</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/describe.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/sql" term="sql" label="SQL" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[连续查询中的 Join]]></title>
            <link href="https://ohmyweekly.github.io/notes/2020-08-22-join-in-continuous-queries/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-alter-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Alter 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-catalogs/?utm_source=atom_feed" rel="related" type="text/html" title="Catalogs" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-create-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Create 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-drop-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Drop 语句" />
                <link href="https://ohmyweekly.github.io/notes/2020-08-22-explan-statements/?utm_source=atom_feed" rel="related" type="text/html" title="Explan 语句" />
            
                <id>https://ohmyweekly.github.io/notes/2020-08-22-join-in-continuous-queries/</id>
            
            
                    <author>
                        <name>焉知非鱼</name>
                    </author>
            <published>2020-08-22T00:00:00+08:00</published>
            <updated>2020-08-22T00:00:00+08:00</updated>
            
            
            <content type="html"><![CDATA[<blockquote>Join in Continuous Queries</blockquote><h1 id="连续查询中的-join">连续查询中的 Join</h1>
<p>在批处理数据时，连接是一种常见的、好理解的操作，用来连接两个关系的行。然而，在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/dynamic_tables.html">动态表</a>上的连接的语义就不那么明显了，甚至是混乱的。</p>
<p>正因为如此，有几种方法可以使用 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 实际执行连接。</p>
<p>关于语法的更多信息，请查看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/tableApi.html#joins">Table API</a> 和 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sql/queries.html#joins">SQL</a> 中的连接部分。</p>
<h2 id="常规连接">常规连接</h2>
<p>常规联接是最通用的联接类型，联接输入的任何一条新记录或变化都是可见的，并影响整个联接结果。例如，如果左边有一条新记录，它将与右边所有以前和将来的记录一起连接。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span>
<span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">Product</span>
<span class="k">ON</span> <span class="n">Orders</span><span class="p">.</span><span class="n">productId</span> <span class="o">=</span> <span class="n">Product</span><span class="p">.</span><span class="n">id</span>
</code></pre></div><p>这些语义允许任何形式的更新（插入、更新、删除）输入表。</p>
<p>然而，这种操作有一个重要的含义：它需要将 <code>join</code> 输入的双方永远保持在 Flink 的状态中。因此，如果一个或两个输入表持续增长，资源使用量也会无限增长。</p>
<h2 id="区间连接">区间连接</h2>
<p>区间联接是由联接谓词定义的，它检查输入记录的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html">时间属性</a>是否在一定的时间限制内，即时间窗口。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="n">o</span><span class="p">,</span>
  <span class="n">Shipments</span> <span class="n">s</span>
<span class="k">WHERE</span> <span class="n">o</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">orderId</span> <span class="k">AND</span>
      <span class="n">o</span><span class="p">.</span><span class="n">ordertime</span> <span class="k">BETWEEN</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;</span><span class="s1">4</span><span class="s1">&#39;</span> <span class="n">HOUR</span> <span class="k">AND</span> <span class="n">s</span><span class="p">.</span><span class="n">shiptime</span>
</code></pre></div><p>与普通的 join 操作相比，这种 join 只支持带有时间属性的 append-only 表。由于时间属性是准单调递增的，所以 Flink 可以在不影响结果正确性的情况下，从其状态中删除旧值。</p>
<h2 id="用临时表函数进行联接">用临时表函数进行联接</h2>
<p>使用时态表函数的连接，将一个只附加表（左输入/探针侧）与一个时态表（右输入/建立侧）连接起来，即一个随时间变化的表，并跟踪其变化。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>的更多信息，请查看相应页面。</p>
<p>下面的例子显示了一个只附加表 Orders，它应该与不断变化的货币汇率表 RatesHistory 连接。</p>
<p>Orders 是一个只附加表，表示给定金额和给定货币的付款。例如在 10:15 有一个金额为 2 欧元的订单。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">amount</span> <span class="n">currency</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">15</span>        <span class="mi">2</span> <span class="n">Euro</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">30</span>        <span class="mi">1</span> <span class="n">US</span> <span class="n">Dollar</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">32</span>       <span class="mi">50</span> <span class="n">Yen</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">52</span>        <span class="mi">3</span> <span class="n">Euro</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">04</span>        <span class="mi">5</span> <span class="n">US</span> <span class="n">Dollar</span>
</code></pre></div><p>RatesHistory 代表了一个不断变化的对日元（汇率为 1）的货币汇率附加表。例如，从 09:00 到 10:45，欧元对日元的汇率是 114，从 10:45 到 11:15 是 116。从 10:45 到 11:15 是 116。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">RatesHistory</span><span class="p">;</span>

<span class="n">rowtime</span> <span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Euro</span>        <span class="mi">114</span>
<span class="mi">09</span><span class="p">:</span><span class="mi">00</span>   <span class="n">Yen</span>           <span class="mi">1</span>
<span class="mi">10</span><span class="p">:</span><span class="mi">45</span>   <span class="n">Euro</span>        <span class="mi">116</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">15</span>   <span class="n">Euro</span>        <span class="mi">119</span>
<span class="mi">11</span><span class="p">:</span><span class="mi">49</span>   <span class="n">Pounds</span>      <span class="mi">108</span>
</code></pre></div><p>我们想计算所有订单的金额，并将其换算成一种通用货币（日元）。</p>
<p>例如，我们想使用给定行时间(114)的适当换算率换算以下订单。</p>
<pre><code>rowtime amount currency
======= ====== =========
10:15        2 Euro
</code></pre><p>如果不使用<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表</a>的概念，就需要写一个类似的查询。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span> <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span><span class="p">,</span>
  <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
<span class="k">AND</span> <span class="n">r</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">=</span> <span class="p">(</span>
  <span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">rowtime</span><span class="p">)</span>
  <span class="k">FROM</span> <span class="n">RatesHistory</span> <span class="k">AS</span> <span class="n">r2</span>
  <span class="k">WHERE</span> <span class="n">r2</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
  <span class="k">AND</span> <span class="n">r2</span><span class="p">.</span><span class="n">rowtime</span> <span class="o">&lt;</span><span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span><span class="p">;</span>
</code></pre></div><p>在临时表函数 Rates over RatesHistory 的帮助下，我们可以将这样的查询用 SQL 表达为:</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">rowtime</span><span class="p">)</span><span class="p">)</span> <span class="k">AS</span> <span class="n">r</span>
<span class="k">WHERE</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>来自探针侧的每条记录将与构建侧表在探针侧记录的相关时间属性时的版本连接。为了支持更新（覆盖）构建侧表的先前值，表必须定义一个主键。</p>
<p>在我们的例子中，来自 Orders 的每条记录将与 Rates 的版本在时间 o.rowtime 连接。货币字段之前已经被定义为 Rates 的主键，在我们的例子中用来连接两个表。如果查询使用的是处理时间的概念，那么在执行操作时，新添加的订单将始终与 Rates 的最新版本连接。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#regular-joins">常规的连接</a>不同，这意味着如果在构建端有新的记录，不会影响之前的连接结果。这又使得 Flink 可以限制必须保留在状态中的元素数量。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#interval-joins">区间联接</a>相比，时间表联接并没有定义一个时间窗口，在这个时间窗口的范围内，记录将被加入。来自探针侧的记录总是在时间属性指定的时间与构建侧的版本进行连接。因此，构建侧的记录可能是任意的旧记录。随着时间的流逝，记录（对于给定的主键）以前的和不再需要的版本将从状态中删除。</p>
<p>这样的行为使得时间表连接成为用关系术语来表达流丰富的一个很好的候选。</p>
<h3 id="使用方法">使用方法</h3>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#defining-temporal-table-function">定义了临时表函数</a>之后，我们就可以开始使用它了。时间表函数的使用方法可以和普通表函数的使用方法一样。</p>
<p>下面的代码片段解决了我们的动机问题，即从订单表中转换货币。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o_amount</span> <span class="o">*</span> <span class="n">r_rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span><span class="p">,</span>
  <span class="k">LATERAL</span> <span class="k">TABLE</span> <span class="p">(</span><span class="n">Rates</span><span class="p">(</span><span class="n">o_proctime</span><span class="p">)</span><span class="p">)</span>
<span class="k">WHERE</span>
  <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// scala
</span><span class="c1"></span><span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">orders</span>
    <span class="o">.</span><span class="n">joinLateral</span><span class="o">(</span><span class="n">rates</span><span class="o">(</span>&#39;o_proctime<span class="o">)</span><span class="o">,</span> &#39;r_currency <span class="o">===</span> &#39;o_currency<span class="o">)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="o">(</span>&#39;o_amount <span class="o">*</span> &#39;r_rate<span class="o">)</span><span class="o">.</span><span class="n">sum</span> <span class="n">as</span> &#39;amount<span class="o">)</span>
</code></pre></div><p>注意：在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/query_configuration.html">查询配置</a>中定义的状态保留还没有实现时序连接。这意味着计算查询结果所需的状态可能会根据历史表的不同主键的数量而无限增长。</p>
<h3 id="处理时间的-temporal-连接">处理时间的 Temporal 连接</h3>
<p>有了处理时间时间属性，就不可能将过去的时间属性作为参数传递给时序表函数。根据定义，它总是当前的时间戳。因此，对处理时间时间表函数的调用将始终返回底层表的最新已知版本，底层历史表的任何更新也将立即覆盖当前值。</p>
<p>只有构建侧记录的最新版本（相对于定义的主键）才会保存在状态中。构建侧的更新不会对之前发出的连接结果产生影响。</p>
<p>我们可以把处理时的时空联接看成一个简单的 <code>HashMap&lt;K，V&gt;</code>，它存储了来自构建侧的所有记录。当来自构建侧的新记录与之前的某个记录具有相同的键时，旧的值只是简单地被覆盖。来自探针侧的每条记录总是根据 HashMap 的最近/当前状态进行评估。</p>
<h3 id="事件时间的-temporal-连接">事件时间的 Temporal 连接</h3>
<p>有了事件时间属性（即行时间属性），就可以将过去的时间属性传递给时间表函数。这样就可以在一个共同的时间点上连接两个表。</p>
<p>与处理时间的时空连接相比，时空表不仅保留了状态下构建方记录的最新版本（相对于定义的主键），而且还存储了自上次水印以来的所有版本（通过时间来识别）。</p>
<p>例如，一个事件时间时间戳为 12:30:00 的传入行被追加到探针侧表中，根据<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html">临时表的概念</a>，它与构建侧表中时间为 12:30:00 的版本连接。因此，传入的行只与时间戳小于或等于 12:30:00 的行连接，并根据主键应用更新，直到这个时间点。</p>
<p>根据事件时间的定义，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/event_time.html">水印</a>允许联接操作在时间上向前移动，并丢弃不再需要的构建表的版本，因为预计不会有时间戳较低或相等的传入行。</p>
<h3 id="用时间表进行联接">用时间表进行联接</h3>
<p>带时态表的连接将一个任意表（左输入/探针侧）与一个时态表（右输入/建立侧）连接起来，即一个随时间变化的外部维度表。关于<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#temporal-table">时间表</a>的详细信息，请查看相应页面。</p>
<p>注意: 用户不能使用任意表作为时间表，而是需要使用一个由 LookupableTableSource 支持的表。一个 LookupableTableSource 只能作为一个时态表用于时态连接。有关如何定义 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/sourceSinks.html#defining-a-tablesource-with-lookupable">LookupableTableSource</a> 的详细信息，请参见页面。</p>
<p>下面的示例显示了一个 Orders 流，它应该与不断变化的货币汇率表 LatestRates 进行连接。</p>
<p>LatestRates 是一个维度表，它是以最新的汇率来实现的。在时间 10:15、10:30、10:52，LatestRates 的内容如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>

<span class="mi">10</span><span class="p">:</span><span class="mi">30</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">114</span>
<span class="n">Yen</span>           <span class="mi">1</span>


<span class="mi">10</span><span class="p">:</span><span class="mi">52</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">LatestRates</span><span class="p">;</span>

<span class="n">currency</span>   <span class="n">rate</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
<span class="n">US</span> <span class="n">Dollar</span>   <span class="mi">102</span>
<span class="n">Euro</span>        <span class="mi">116</span>     <span class="o">&lt;</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="n">changed</span> <span class="k">from</span> <span class="mi">114</span> <span class="k">to</span> <span class="mi">116</span>
<span class="n">Yen</span>           <span class="mi">1</span>
</code></pre></div><p>时间 10:15 和 10:30 的 LastestRates 内容相等。欧元汇率在 10:52 从 114 变为 116。</p>
<p>订单是一个只附加的表，表示给定金额和给定货币的支付。例如在 10:15 有一个金额为 2 欧元的订单。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">Orders</span><span class="p">;</span>

<span class="n">amount</span> <span class="n">currency</span>
<span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span> <span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span><span class="o">=</span>
     <span class="mi">2</span> <span class="n">Euro</span>             <span class="o">&lt;</span><span class="o">=</span><span class="o">=</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">15</span>
     <span class="mi">1</span> <span class="n">US</span> <span class="n">Dollar</span>        <span class="o">&lt;</span><span class="o">=</span><span class="o">=</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">30</span>
     <span class="mi">2</span> <span class="n">Euro</span>             <span class="o">&lt;</span><span class="o">=</span><span class="o">=</span> <span class="n">arrived</span> <span class="k">at</span> <span class="n">time</span> <span class="mi">10</span><span class="p">:</span><span class="mi">52</span>
</code></pre></div><p>我们想计算所有订单的金额，并将其兑换成一种通用货币（日元）。</p>
<p>例如，我们想使用 LatestRates 中的最新汇率来转换以下订单。结果将是：</p>
<pre><code>amount currency     rate   amout*rate
====== ========= ======= ============
     2 Euro          114          228    &lt;== arrived at time 10:15
     1 US Dollar     102          102    &lt;== arrived at time 10:30
     2 Euro          116          232    &lt;== arrived at time 10:52
</code></pre><p>在时间表连接的帮助下，我们可以将这样的查询用 SQL 表达为。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="n">o</span><span class="p">.</span><span class="n">amout</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span><span class="p">,</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">amount</span> <span class="o">*</span> <span class="n">r</span><span class="p">.</span><span class="n">rate</span>
<span class="k">FROM</span>
  <span class="n">Orders</span> <span class="k">AS</span> <span class="n">o</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o</span><span class="p">.</span><span class="n">proctime</span> <span class="k">AS</span> <span class="n">r</span>
  <span class="k">ON</span> <span class="n">r</span><span class="p">.</span><span class="n">currency</span> <span class="o">=</span> <span class="n">o</span><span class="p">.</span><span class="n">currency</span>
</code></pre></div><p>来自探针侧的每一条记录都将与构建侧表的当前版本相连接。在我们的例子中，查询使用的是处理时间的概念，所以在执行操作时，新追加的订单将始终与最新版本的 LatestRates 连接。需要注意的是，结果并不是处理时间的确定性。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#regular-joins">常规联接</a>相比，尽管构建端发生了变化，但时态表联接之前的结果不会受到影响。另外，时态表连接操作符非常轻量级，不保留任何状态。</p>
<p>与<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#interval-joins">区间联接</a>相比，时态表联接不定义记录联接的时间窗口。在处理时，来自探针侧的记录总是与构建侧的最新版本连接。因此，构建侧的记录可能是任意旧的。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html#join-with-a-temporal-table-function">时态表函数连接</a>和时态表连接的动机都是一样的，但在 SQL 语法和运行时的实现上却有所不同。</p>
<ul>
<li>时间表函数 join 的 SQL 语法是 join UDTF，而时间表 join 使用 SQL:2011 中引入的标准时间表语法。</li>
<li>时态表函数 join 的实现实际上是将两个流连接起来并保持状态，而时态表 join 只是接收唯一的输入流，并根据记录中的键查找外部数据库。</li>
<li>时态表函数联接通常用于联接变更日志流，而时态表联接通常用于联接外部表（即维表）。</li>
</ul>
<p>这样的行为使得时态表连接成为用关系术语来表达流丰富的一个很好的候选。</p>
<p>在未来，时态表连接将支持时态表函数连接的特性，即支持时态连接 changelog 流。</p>
<h3 id="使用方法-1">使用方法</h3>
<p>时间表连接的语法如下。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span> <span class="p">[</span><span class="n">column_list</span><span class="p">]</span>
<span class="k">FROM</span> <span class="n">table1</span> <span class="p">[</span><span class="k">AS</span> <span class="o">&lt;</span><span class="n">alias1</span><span class="o">&gt;</span><span class="p">]</span>
<span class="p">[</span><span class="k">LEFT</span><span class="p">]</span> <span class="k">JOIN</span> <span class="n">table2</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">table1</span><span class="p">.</span><span class="n">proctime</span> <span class="p">[</span><span class="k">AS</span> <span class="o">&lt;</span><span class="n">alias2</span><span class="o">&gt;</span><span class="p">]</span>
<span class="k">ON</span> <span class="n">table1</span><span class="p">.</span><span class="k">column</span><span class="o">-</span><span class="n">name1</span> <span class="o">=</span> <span class="n">table2</span><span class="p">.</span><span class="k">column</span><span class="o">-</span><span class="n">name1</span>
</code></pre></div><p>目前只支持 INNER JOIN 和 LEFT JOIN。在 temporal 表后应跟上 FOR SYSTEM_TIME AS OF table1.proctime。proctime 是 table1 的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/time_attributes.html#processing-time">处理时间属性</a>。这意味着它在处理时间对时间表进行快照，当从左表连接每一条记录时，它就会对时间表进行快照。</p>
<p>例如，在<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html#defining-temporal-table">定义了 temporal 表</a>之后，我们可以按以下方式使用。</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">SELECT</span>
  <span class="k">SUM</span><span class="p">(</span><span class="n">o_amount</span> <span class="o">*</span> <span class="n">r_rate</span><span class="p">)</span> <span class="k">AS</span> <span class="n">amount</span>
<span class="k">FROM</span>
  <span class="n">Orders</span>
  <span class="k">JOIN</span> <span class="n">LatestRates</span> <span class="k">FOR</span> <span class="n">SYSTEM_TIME</span> <span class="k">AS</span> <span class="k">OF</span> <span class="n">o_proctime</span>
  <span class="k">ON</span> <span class="n">r_currency</span> <span class="o">=</span> <span class="n">o_currency</span>
</code></pre></div><p>注意: 这只在 Blink 计划器中支持。</p>
<p>注意: 目前只在 SQL 中支持，在 Table API 中还不支持。</p>
<p>注意: Flink 目前不支持事件时间的表连接。</p>
<p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/joins.html</a></p>
]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/categories/flink" term="flink" label="Flink" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink" term="flink" label="Flink" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" term="flink-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3" label="Flink 官方文档" />
                             
                                <category scheme="https://ohmyweekly.github.io/tags/table-api-sql" term="table-api-sql" label="Table API &amp; SQL" />
                            
                        
                    
                
            
        </entry>
    
</feed>
