{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io"},"children":[{"content":{"html":"\u003cp\u003eFlink 是一个分布式系统，为了执行流式应用，需要对计算资源进行有效的分配和管理。它集成了所有常见的集群资源管理器，如 \u003ca href=\"https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\"\u003eHadoop YARN\u003c/a\u003e、\u003ca href=\"https://mesos.apache.org/\"\u003eApache Mesos\u003c/a\u003e 和 \u003ca href=\"https://kubernetes.io/\"\u003eKubernetes\u003c/a\u003e，但也可以设置为独立集群甚至作为库运行。\u003c/p\u003e\n\u003cp\u003e本节包含 Flink 架构的概述，并描述了其主要组件如何交互执行应用程序并从故障中恢复。\u003c/p\u003e\n\u003ch2 id=\"flink-集群的解剖\"\u003eFlink 集群的解剖\u003c/h2\u003e\n\u003cp\u003eFlink 运行时由两种类型的进程组成：一个 JobManager 和一个或多个 TaskManagers。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/processes.svg\" alt=\"img\"\u003e\u003c/p\u003e\n\u003cp\u003e客户端不是运行时和程序执行的一部分，而是用来准备并向 JobManager 发送数据流。之后，客户端可以断开连接（分离模式），或者保持连接以接收进度报告（附加模式）。客户端既可以作为触发执行的 Java/Scala 程序的一部分运行，也可以在命令行进程 \u003ccode\u003e./bin/flink run\u003c/code\u003e \u0026hellip;中运行。\u003c/p\u003e\n\u003cp\u003eJobManager 和 TaskManagers 可以以各种方式启动：直接在机器上作为一个\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html\"\u003e独立的集群\u003c/a\u003e，在容器中，或由 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/yarn_setup.html\"\u003eYARN\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/mesos.html\"\u003eMesos\u003c/a\u003e 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作。\u003c/p\u003e\n\u003ch3 id=\"jobmanager\"\u003eJobManager\u003c/h3\u003e\n\u003cp\u003eJobManager 有一些与协调 Flink 应用的分布式执行有关的职责：它决定何时安排下一个任务（或一组任务），对已完成的任务或执行失败作出反应，协调检查点，并协调失败时的恢复等。这个过程由三个不同的组件组成。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e资源管理器(ResourceManager)\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eResourceManager 负责 Flink 集群中的资源去/分配和供应\u0026ndash;它管理任务槽(\u003cstrong\u003etask slots\u003c/strong\u003e)，任务槽是 Flink 集群中资源调度的单位（见 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#taskmanagers\"\u003eTaskManagers\u003c/a\u003e）。Flink 针对不同的环境和资源提供者（如 YARN、Mesos、Kubernetes 和独立部署）实现了多个 ResourceManagers。在独立设置中，ResourceManager 只能分配可用的 TaskManagers 的槽位，不能自行启动新的 TaskManagers。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDispatcher\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDispatcher 提供了一个 REST 接口来提交 Flink 应用执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 来提供作业执行的信息。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eJobMaster\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e一个 JobMaster 负责管理一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph\"\u003eJobGraph\u003c/a\u003e 的执行。在一个 Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。\u003c/p\u003e\n\u003cp\u003e总是至少有一个 JobManager。一个高可用性设置可能有多个 JobManagers，其中一个总是领导者，其他的是备用的（见\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/jobmanager_high_availability.html\"\u003e高可用性（HA）\u003c/a\u003e）。\u003c/p\u003e\n\u003ch3 id=\"taskmanagers\"\u003eTaskManagers\u003c/h3\u003e\n\u003cp\u003e任务管理器（TaskManagers）（也叫 worker）执行数据流的任务，并缓冲和交换数据流。\u003c/p\u003e\n\u003cp\u003e必须始终有至少一个TaskManager。TaskManager中资源调度的最小单位是一个任务槽。一个任务管理器中任务槽的数量表示并发处理任务的数量。请注意，一个任务槽中可以执行多个操作者（参见\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#tasks-and-operator-chains\"\u003eTasks 和 Operator 链\u003c/a\u003e）。\u003c/p\u003e\n\u003ch3 id=\"tasks-和-operator-chains\"\u003eTasks 和 Operator Chains\u003c/h3\u003e\n\u003cp\u003e对于分布式执行，Flink 将操作者的子任务链成任务。每个任务由一个线程执行。将运算符一起链入任务是一种有用的优化：它减少了线程到线程的交接和缓冲的开销，增加了整体的吞吐量，同时降低了延迟。链锁行为可以配置，详情请看\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/#task-chaining-and-resource-groups\"\u003echaining 文档\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e下图中的示例数据流是以五个子任务，也就是五个并行线程来执行的。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_chains.svg\" alt=\"img\"\u003e\u003c/p\u003e\n\u003ch2 id=\"任务槽和资源task-slots-和-resources\"\u003e任务槽和资源(Task Slots 和 Resources)\u003c/h2\u003e\n\u003cp\u003e每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个子任务。为了控制一个任务管理器接受多少任务，它有所谓的任务槽（至少一个）。\u003c/p\u003e\n\u003cp\u003e每个任务槽代表任务管理器的一个固定的资源子集。例如，一个有三个槽的任务管理器，将把其管理内存的1/3奉献给每个槽。槽位资源意味着一个子任务不会与其他任务的子任务争夺管理内存，而是拥有一定量的预留管理内存。需要注意的是，这里并没有发生 CPU 隔离，目前插槽只是将任务的管理内存分开。\u003c/p\u003e\n\u003cp\u003e通过调整任务槽的数量，用户可以定义子任务之间的隔离方式。每个任务管理器有一个插槽意味着每个任务组都在一个单独的 JVM 中运行（例如可以在一个单独的容器中启动）。拥有多个插槽意味着更多的子任务共享同一个 JVM。同一 JVM 中的任务共享 TCP 连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每个任务的开销。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_slots.svg\" alt=\"img\"\u003e\u003c/p\u003e\n\u003cp\u003e默认情况下，Flink 允许子任务共享槽，即使它们是不同任务的子任务，只要它们来自同一个作业。其结果是，一个槽可以容纳整个作业的流水线。允许这种槽位共享有两个主要好处。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e一个 Flink 集群需要的任务槽数量正好与作业中使用的最高并行度相同。不需要计算一个程序总共包含多少个任务（具有不同的并行度）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e更容易获得更好的资源利用率。如果没有槽位共享，非密集型的 \u003ccode\u003esource/map()\u003c/code\u003e 子任务和资源密集型的 window 子任务一样，会阻塞很多资源。有了槽位共享，在我们的例子中，将基础并行度从2个增加到6个，就会产生槽位资源的充分利用，同时确保重度子任务在 TaskManager 中公平分配。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/slot_sharing.svg\" alt=\"img\"\u003e\u003c/p\u003e\n\u003ch2 id=\"flink-应用执行\"\u003eFlink 应用执行\u003c/h2\u003e\n\u003cp\u003eFlink 应用程序是任何从其 \u003ccode\u003emain()\u003c/code\u003e 方法中生成一个或多个 Flink 作业的用户程序。这些作业的执行可以发生在本地 JVM（LocalEnvironment）中，也可以发生在多台机器的远程集群设置（RemoteEnvironment）中。对于每个程序，ExecutionEnvironment 提供了控制作业执行的方法（例如设置并行性）和与外界交互的方法（参见 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html#anatomy-of-a-flink-program\"\u003eAnatomy of a Flink Program\u003c/a\u003e）。\u003c/p\u003e\n\u003cp\u003eFlink 应用的作业可以提交到一个长期运行的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster\"\u003eFlink 会话集群\u003c/a\u003e、一个专门的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster\"\u003eFlink 作业集群\u003c/a\u003e或一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster\"\u003eFlink 应用集群\u003c/a\u003e。这些选项之间的区别主要与集群的生命周期和资源隔离保证有关。\u003c/p\u003e\n\u003ch3 id=\"flink-会话集群\"\u003eFlink 会话集群\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e集群生命周期：在 Flink 会话集群中，客户端连接到一个预先存在的、长期运行的集群，可以接受多个作业提交。即使在所有作业完成后，集群（和 JobManager）将继续运行，直到会话被手动停止。因此，一个 Flink 会话集群的寿命不受任何 Flink 作业寿命的约束。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e资源隔离。TaskManager 插槽由 ResourceManager 在作业提交时分配，作业完成后释放。因为所有作业都共享同一个集群，所以对集群资源有一定的竞争\u0026ndash;比如提交作业阶段的网络带宽。这种共享设置的一个限制是，如果一个任务管理器崩溃，那么所有在这个任务管理器上有任务运行的作业都会失败；同样，如果在作业管理器上发生一些致命的错误，也会影响集群中运行的所有作业。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e其他考虑因素：拥有一个预先存在的集群，可以节省大量申请资源和启动 TaskManagers 的时间。这在作业的执行时间非常短，高启动时间会对端到端的用户体验产生负面影响的场景中非常重要\u0026ndash;就像对短查询的交互式分析一样，希望作业能够利用现有资源快速执行计算。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e注：以前，Flink 会话集群也被称为会话模式下的 Flink 集群。\u003c/p\u003e\n\u003ch3 id=\"flink-作业集群\"\u003eFlink 作业集群\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e集群生命周期：在 Flink Job Cluster 中，可用的集群管理器（如 YARN 或 Kubernetes）为每个提交的作业旋转一个集群，这个集群只对该作业可用。在这里，客户端首先向集群管理器请求资源来启动 JobManager，并将作业提交给运行在这个进程内部的 Dispatcher。然后根据作业的资源需求，懒惰地分配 TaskManager。作业完成后，Flink Job Cluster 就会被拆掉。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e资源隔离：JobManager 的致命错误只影响该 Flink Job Cluster 中运行的一个作业。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e其他考虑因素：由于 ResourceManager 需要申请并等待外部资源管理组件来启动 TaskManager 进程并分配资源，因此 Flink Job Cluster 更适合运行时间长、稳定性要求高、对启动时间较长不敏感的大型作业。\u003c/p\u003e\n\u003cp\u003e注：以前，Flink Job Cluster 也被称为作业（或每作业）模式下的 Flink Cluster。\u003c/p\u003e\n\u003ch3 id=\"flink-应用集群flink-application-cluster\"\u003eFlink 应用集群(Flink Application Cluster)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e集群生命周期：Flink 应用集群是一个专用的 Flink 集群，它只执行来自一个 Flink 应用的作业，并且 \u003ccode\u003emain()\u003c/code\u003e 方法运行在集群上而不是客户端上。作业提交是一个一步到位的过程：你不需要先启动一个 Flink 集群，然后向现有的集群会话提交作业，而是将你的应用逻辑和依赖关系打包成一个可执行的作业 JAR，集群入口点(ApplicationClusterEntryPoint)负责调用 \u003ccode\u003emain()\u003c/code\u003e 方法来提取作业图。这样你就可以像在 Kubernetes 上部署其他应用一样部署 Flink 应用，例如。因此，Flink Application Cluster 的寿命与 Flink Application 的寿命是绑定的。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e资源隔离：在 Flink Application Cluster 中，ResourceManager 和 Dispatcher 的范围是单一的 Flink Application，这比 Flink Session Cluster 提供了更好的分离关注点。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e注：Flink Job Cluster 可以看作是 Flink Application Cluster 的 \u0026ldquo;run-on-client\u0026rdquo; 替代品。\u003c/p\u003e\n","text":"Flink 是一个分布式系统，为了执行流式应用，需要对计算资源进行有效的分配和管理。它集成了所有常见的集群资源管理器，如 Hadoop YARN、Apache Mesos 和 Kubernetes，但也可以设置为独立集群甚至作为库运行。\n本节包含 Flink 架构的概述，并描述了其主要组件如何交互执行应用程序并从故障中恢复。\nFlink 集群的解剖 Flink 运行时由两种类型的进程组成：一个 JobManager 和一个或多个 TaskManagers。\n客户端不是运行时和程序执行的一部分，而是用来准备并向 JobManager 发送数据流。之后，客户端可以断开连接（分离模式），或者保持连接以接收进度报告（附加模式）。客户端既可以作为触发执行的 Java/Scala 程序的一部分运行，也可以在命令行进程 ./bin/flink run \u0026hellip;中运行。\nJobManager 和 TaskManagers 可以以各种方式启动：直接在机器上作为一个独立的集群，在容器中，或由 YARN 或 Mesos 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作。\nJobManager JobManager 有一些与协调 Flink 应用的分布式执行有关的职责：它决定何时安排下一个任务（或一组任务），对已完成的任务或执行失败作出反应，协调检查点，并协调失败时的恢复等。这个过程由三个不同的组件组成。\n 资源管理器(ResourceManager)  ResourceManager 负责 Flink 集群中的资源去/分配和供应\u0026ndash;它管理任务槽(task slots)，任务槽是 Flink 集群中资源调度的单位（见 TaskManagers）。Flink 针对不同的环境和资源提供者（如 YARN、Mesos、Kubernetes 和独立部署）实现了多个 ResourceManagers。在独立设置中，ResourceManager 只能分配可用的 TaskManagers 的槽位，不能自行启动新的 TaskManagers。\n Dispatcher  Dispatcher 提供了一个 REST 接口来提交 Flink 应用执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 来提供作业执行的信息。\n JobMaster  一个 JobMaster 负责管理一个 JobGraph 的执行。在一个 Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。\n总是至少有一个 JobManager。一个高可用性设置可能有多个 JobManagers，其中一个总是领导者，其他的是备用的（见高可用性（HA））。\nTaskManagers 任务管理器（TaskManagers）（也叫 worker）执行数据流的任务，并缓冲和交换数据流。\n必须始终有至少一个TaskManager。TaskManager中资源调度的最小单位是一个任务槽。一个任务管理器中任务槽的数量表示并发处理任务的数量。请注意，一个任务槽中可以执行多个操作者（参见Tasks 和 Operator 链）。\nTasks 和 Operator Chains 对于分布式执行，Flink 将操作者的子任务链成任务。每个任务由一个线程执行。将运算符一起链入任务是一种有用的优化：它减少了线程到线程的交接和缓冲的开销，增加了整体的吞吐量，同时降低了延迟。链锁行为可以配置，详情请看chaining 文档。\n下图中的示例数据流是以五个子任务，也就是五个并行线程来执行的。\n任务槽和资源(Task Slots 和 Resources) 每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个子任务。为了控制一个任务管理器接受多少任务，它有所谓的任务槽（至少一个）。\n每个任务槽代表任务管理器的一个固定的资源子集。例如，一个有三个槽的任务管理器，将把其管理内存的1/3奉献给每个槽。槽位资源意味着一个子任务不会与其他任务的子任务争夺管理内存，而是拥有一定量的预留管理内存。需要注意的是，这里并没有发生 CPU 隔离，目前插槽只是将任务的管理内存分开。\n通过调整任务槽的数量，用户可以定义子任务之间的隔离方式。每个任务管理器有一个插槽意味着每个任务组都在一个单独的 JVM 中运行（例如可以在一个单独的容器中启动）。拥有多个插槽意味着更多的子任务共享同一个 JVM。同一 JVM 中的任务共享 TCP 连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每个任务的开销。\n默认情况下，Flink 允许子任务共享槽，即使它们是不同任务的子任务，只要它们来自同一个作业。其结果是，一个槽可以容纳整个作业的流水线。允许这种槽位共享有两个主要好处。\n  一个 Flink 集群需要的任务槽数量正好与作业中使用的最高并行度相同。不需要计算一个程序总共包含多少个任务（具有不同的并行度）。\n  更容易获得更好的资源利用率。如果没有槽位共享，非密集型的 source/map() 子任务和资源密集型的 window 子任务一样，会阻塞很多资源。有了槽位共享，在我们的例子中，将基础并行度从2个增加到6个，就会产生槽位资源的充分利用，同时确保重度子任务在 TaskManager 中公平分配。\n  Flink 应用执行 Flink 应用程序是任何从其 main() 方法中生成一个或多个 Flink 作业的用户程序。这些作业的执行可以发生在本地 JVM（LocalEnvironment）中，也可以发生在多台机器的远程集群设置（RemoteEnvironment）中。对于每个程序，ExecutionEnvironment 提供了控制作业执行的方法（例如设置并行性）和与外界交互的方法（参见 Anatomy of a Flink Program）。\nFlink 应用的作业可以提交到一个长期运行的 Flink 会话集群、一个专门的 Flink 作业集群或一个 Flink 应用集群。这些选项之间的区别主要与集群的生命周期和资源隔离保证有关。\nFlink 会话集群   集群生命周期：在 Flink 会话集群中，客户端连接到一个预先存在的、长期运行的集群，可以接受多个作业提交。即使在所有作业完成后，集群（和 JobManager）将继续运行，直到会话被手动停止。因此，一个 Flink 会话集群的寿命不受任何 Flink 作业寿命的约束。\n  资源隔离。TaskManager 插槽由 ResourceManager 在作业提交时分配，作业完成后释放。因为所有作业都共享同一个集群，所以对集群资源有一定的竞争\u0026ndash;比如提交作业阶段的网络带宽。这种共享设置的一个限制是，如果一个任务管理器崩溃，那么所有在这个任务管理器上有任务运行的作业都会失败；同样，如果在作业管理器上发生一些致命的错误，也会影响集群中运行的所有作业。\n  其他考虑因素：拥有一个预先存在的集群，可以节省大量申请资源和启动 TaskManagers 的时间。这在作业的执行时间非常短，高启动时间会对端到端的用户体验产生负面影响的场景中非常重要\u0026ndash;就像对短查询的交互式分析一样，希望作业能够利用现有资源快速执行计算。\n  注：以前，Flink 会话集群也被称为会话模式下的 Flink 集群。\nFlink 作业集群   集群生命周期：在 Flink Job Cluster 中，可用的集群管理器（如 YARN 或 Kubernetes）为每个提交的作业旋转一个集群，这个集群只对该作业可用。在这里，客户端首先向集群管理器请求资源来启动 JobManager，并将作业提交给运行在这个进程内部的 Dispatcher。然后根据作业的资源需求，懒惰地分配 TaskManager。作业完成后，Flink Job Cluster 就会被拆掉。\n  资源隔离：JobManager 的致命错误只影响该 Flink Job Cluster 中运行的一个作业。\n  其他考虑因素：由于 ResourceManager 需要申请并等待外部资源管理组件来启动 TaskManager 进程并分配资源，因此 Flink Job Cluster 更适合运行时间长、稳定性要求高、对启动时间较长不敏感的大型作业。\n注：以前，Flink Job Cluster 也被称为作业（或每作业）模式下的 Flink Cluster。\nFlink 应用集群(Flink Application Cluster)   集群生命周期：Flink 应用集群是一个专用的 Flink 集群，它只执行来自一个 Flink 应用的作业，并且 main() 方法运行在集群上而不是客户端上。作业提交是一个一步到位的过程：你不需要先启动一个 Flink 集群，然后向现有的集群会话提交作业，而是将你的应用逻辑和依赖关系打包成一个可执行的作业 JAR，集群入口点(ApplicationClusterEntryPoint)负责调用 main() 方法来提取作业图。这样你就可以像在 Kubernetes 上部署其他应用一样部署 Flink 应用，例如。因此，Flink Application Cluster 的寿命与 Flink Application 的寿命是绑定的。\n  资源隔离：在 Flink Application Cluster 中，ResourceManager 和 Dispatcher 的范围是单一的 Flink Application，这比 Flink Session Cluster 提供了更好的分离关注点。\n  注：Flink Job Cluster 可以看作是 Flink Application Cluster 的 \u0026ldquo;run-on-client\u0026rdquo; 替代品。\n"},"name":"Flink 的架构","published":"2020-08-20T00:00:00+08:00","summary":"Flink Architecture","type":"entry","url":"https://ohmyweekly.github.io/notes/2020-08-20-flink-architecture/"},{"content":{"html":"\u003cp\u003e\u003cstrong\u003eFlink Application Cluster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFlink 应用集群是一个专用的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink 集群\u003c/a\u003e，它只执行一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application\"\u003eFlink 应用\u003c/a\u003e的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink 作业\u003c/a\u003e。\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink 集群\u003c/a\u003e的寿命与 Flink 应用的寿命绑定。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink Job Cluster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFlink Job Cluster 是一个专用的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink Cluster\u003c/a\u003e，它只执行一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink Job\u003c/a\u003e。\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink Cluster\u003c/a\u003e 的寿命与 Flink Job 的寿命绑定。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink Cluster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个分布式系统由（通常）一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager\"\u003eJobManager\u003c/a\u003e 和一个或多个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-taskmanager\"\u003eFlink TaskManager\u003c/a\u003e 进程组成。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEvent\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e事件是关于应用程序所模拟的域的状态变化的声明。事件可以是流或批处理应用程序的输入和/或输出。事件是特殊类型的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record\"\u003e记录\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExecutionGraph\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e参见物理图(\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph\"\u003ePhysical Graph\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFunction\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e函数由用户实现，封装了 Flink 程序的应用逻辑。大多数 Functions 都由相应的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 封装。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eInstance\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e术语 instance 用于描述运行时特定类型（通常是 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function\"\u003eFunction\u003c/a\u003e）的具体实例。由于 Apache Flink 大部分是用 Java 编写的，所以对应于 Java 中的 Instance 或 Object 的定义。在 Apache Flink 的上下文中，并行实例这个术语也经常被用来强调同一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function\"\u003eFunction\u003c/a\u003e 类型的多个实例在并行运行。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink Application\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFlink 应用程序是一个 Java 应用程序，它从 \u003ccode\u003emain()\u003c/code\u003e 方法(或通过其他方式)提交一个或多个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink 作业\u003c/a\u003e。提交作业通常是通过调用执行环境上的 \u003ccode\u003eexecute()\u003c/code\u003e 来完成的。\u003c/p\u003e\n\u003cp\u003e应用程序的作业可以提交到一个长期运行的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-session-cluster\"\u003eFlink 会话集群\u003c/a\u003e，也可以提交到一个专门的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster\"\u003eFlink 应用集群\u003c/a\u003e，或者提交到一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job-cluster\"\u003eFlink 作业集群\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink Job\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFlink Job 是指在 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application\"\u003eFlink 应用\u003c/a\u003e中通过调用 \u003ccode\u003eexecute()\u003c/code\u003e 来创建和提交的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph\"\u003e逻辑图\u003c/a\u003e（也常称为数据流图）的运行时表示。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eJobGraph\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e参见逻辑图(\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph\"\u003eLogical Graph\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink JobManager\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eJobManager 是 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink 集群\u003c/a\u003e的协调器。它包含了三个不同的组件：Flink 资源管理器、Flink 调度器和每个运行的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink 作业\u003c/a\u003e 一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmaster\"\u003eFlink JobMaster\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink JobMaster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eJobMasters 是运行在 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager\"\u003eJobManager\u003c/a\u003e 中的组件之一。一个 JobMaster 负责监督单个作业的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task\"\u003eTasks\u003c/a\u003e 的执行情况。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLogical Graph\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e逻辑图是一个有向图，其中节点是 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperators\u003c/a\u003e，边缘定义了 operator 的输入/输出关系，并对应数据流或数据集。逻辑图是通过从 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application\"\u003eFlink 应用程序\u003c/a\u003e提交作业来创建的。\u003c/p\u003e\n\u003cp\u003e逻辑图也常被称为数据流图。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eManaged State\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eManaged State 描述的是已经在框架中注册的应用状态。对于托管状态，Apache Flink 将负责处理持久性和重新缩放等问题。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOperator\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph\"\u003e逻辑图\u003c/a\u003e的节点。Operator 执行某种操作，通常由 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function\"\u003eFunction\u003c/a\u003e 执行。源和接收器是数据摄入和数据输出的特殊 Operator。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOperator Chain\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个 Operator 链由两个或多个连续的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 组成，中间没有任何重新分区。同一 Operator 链内的 operattor 直接相互转发记录，而不需要经过序列化或 Flink 的网络栈。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePartition\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e分区是整个数据流或数据集的一个独立子集。通过将每条\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Record\"\u003e记录\u003c/a\u003e分配到一个或多个分区，将数据流或数据集划分为多个分区。数据流或数据集的分区在运行时由\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task\"\u003eTasks\u003c/a\u003e消耗。改变数据流或数据集分区方式的转换通常称为重新分区。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePhysical Graph\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e物理图是翻译\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#logical-graph\"\u003e逻辑图\u003c/a\u003e的结果，以便在分布式运行时执行。节点是\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task\"\u003eTasks\u003c/a\u003e，边缘表示输入/输出关系或数据流或数据集的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition\"\u003e分区\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRecord\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e记录是数据集或数据流的组成元素。\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 和 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#Function\"\u003eFunctions\u003c/a\u003e 接收记录作为输入，并发出记录作为输出。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink Session Cluster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个长期运行的 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink Cluster\u003c/a\u003e，它接受多个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink Job\u003c/a\u003e 的执行。该  Flink Cluster 的寿命不受任何 Flink Job 寿命的约束。以前，Flink Session Cluster 也被称为会话模式下的 Flink Cluster。与 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-application-cluster\"\u003eFlink Application Cluster\u003c/a\u003e 比较。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eState Backend\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于流处理程序来说，\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-job\"\u003eFlink Job\u003c/a\u003e 的状态后端决定了它的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#managed-state\"\u003e状态\u003c/a\u003e如何存储在每个 TaskManager 上（TaskManager 的 Java 堆或（嵌入式）RocksDB），以及它在检查点时的写入位置（\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-jobmanager\"\u003eJobManager\u003c/a\u003e 的 Java 堆或 Filesystem）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSub-Task\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e子任务( Sub-Task)是指负责处理数据流的一个\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#partition\"\u003e分区\u003c/a\u003e的任务(\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task\"\u003eTask\u003c/a\u003e)。术语\u0026quot;子任务\u0026quot;强调同一 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain\"\u003eOperator 链\u003c/a\u003e有多个并行的 Task。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTask\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#physical-graph\"\u003e物理图\u003c/a\u003e的节点。Task 是工作的基本单位，由 Flink 的运行时执行。任务正好封装了一个 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator-chain\"\u003eOperator 链\u003c/a\u003e 的一个并行实例。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFlink TaskManager\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTaskManager 是 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#flink-cluster\"\u003eFlink Cluster\u003c/a\u003e 的工作进程。\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#task\"\u003eTasks\u003c/a\u003e 被安排给 TaskManagers 执行。它们相互通信，在后续的 Task 之间交换数据。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTransformation\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e变换应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。变换可能会在每条记录的基础上改变数据流或数据集，但也可能只改变其分区或执行聚合。\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 或 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#function\"\u003eFunctions\u003c/a\u003e是 Flink 的 API 的 \u0026ldquo;物理\u0026quot;部分，而变换只是一个 API 概念。具体来说，大多数变换是由某些 \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/glossary.html#operator\"\u003eOperator\u003c/a\u003e 实现的。\u003c/p\u003e\n","text":"Flink Application Cluster\nFlink 应用集群是一个专用的 Flink 集群，它只执行一个 Flink 应用的 Flink 作业。Flink 集群的寿命与 Flink 应用的寿命绑定。\nFlink Job Cluster\nFlink Job Cluster 是一个专用的 Flink Cluster，它只执行一个 Flink Job。Flink Cluster 的寿命与 Flink Job 的寿命绑定。\nFlink Cluster\n一个分布式系统由（通常）一个 JobManager 和一个或多个 Flink TaskManager 进程组成。\nEvent\n事件是关于应用程序所模拟的域的状态变化的声明。事件可以是流或批处理应用程序的输入和/或输出。事件是特殊类型的记录。\nExecutionGraph\n参见物理图(Physical Graph)\nFunction\n函数由用户实现，封装了 Flink 程序的应用逻辑。大多数 Functions 都由相应的 Operator 封装。\nInstance\n术语 instance 用于描述运行时特定类型（通常是 Operator 或 Function）的具体实例。由于 Apache Flink 大部分是用 Java 编写的，所以对应于 Java 中的 Instance 或 Object 的定义。在 Apache Flink 的上下文中，并行实例这个术语也经常被用来强调同一个 Operator 或 Function 类型的多个实例在并行运行。\nFlink Application\nFlink 应用程序是一个 Java 应用程序，它从 main() 方法(或通过其他方式)提交一个或多个 Flink 作业。提交作业通常是通过调用执行环境上的 execute() 来完成的。\n应用程序的作业可以提交到一个长期运行的 Flink 会话集群，也可以提交到一个专门的 Flink 应用集群，或者提交到一个 Flink 作业集群。\nFlink Job\nFlink Job 是指在 Flink 应用中通过调用 execute() 来创建和提交的逻辑图（也常称为数据流图）的运行时表示。\nJobGraph\n参见逻辑图(Logical Graph)\nFlink JobManager\nJobManager 是 Flink 集群的协调器。它包含了三个不同的组件：Flink 资源管理器、Flink 调度器和每个运行的 Flink 作业 一个 Flink JobMaster。\nFlink JobMaster\nJobMasters 是运行在 JobManager 中的组件之一。一个 JobMaster 负责监督单个作业的 Tasks 的执行情况。\nLogical Graph\n逻辑图是一个有向图，其中节点是 Operators，边缘定义了 operator 的输入/输出关系，并对应数据流或数据集。逻辑图是通过从 Flink 应用程序提交作业来创建的。\n逻辑图也常被称为数据流图。\nManaged State\nManaged State 描述的是已经在框架中注册的应用状态。对于托管状态，Apache Flink 将负责处理持久性和重新缩放等问题。\nOperator\n逻辑图的节点。Operator 执行某种操作，通常由 Function 执行。源和接收器是数据摄入和数据输出的特殊 Operator。\nOperator Chain\n一个 Operator 链由两个或多个连续的 Operator 组成，中间没有任何重新分区。同一 Operator 链内的 operattor 直接相互转发记录，而不需要经过序列化或 Flink 的网络栈。\nPartition\n分区是整个数据流或数据集的一个独立子集。通过将每条记录分配到一个或多个分区，将数据流或数据集划分为多个分区。数据流或数据集的分区在运行时由Tasks消耗。改变数据流或数据集分区方式的转换通常称为重新分区。\nPhysical Graph\n物理图是翻译逻辑图的结果，以便在分布式运行时执行。节点是Tasks，边缘表示输入/输出关系或数据流或数据集的分区。\nRecord\n记录是数据集或数据流的组成元素。Operator 和 Functions 接收记录作为输入，并发出记录作为输出。\nFlink Session Cluster\n一个长期运行的 Flink Cluster，它接受多个 Flink Job 的执行。该 Flink Cluster 的寿命不受任何 Flink Job 寿命的约束。以前，Flink Session Cluster 也被称为会话模式下的 Flink Cluster。与 Flink Application Cluster 比较。\nState Backend\n对于流处理程序来说，Flink Job 的状态后端决定了它的状态如何存储在每个 TaskManager 上（TaskManager 的 Java 堆或（嵌入式）RocksDB），以及它在检查点时的写入位置（JobManager 的 Java 堆或 Filesystem）。\nSub-Task\n子任务( Sub-Task)是指负责处理数据流的一个分区的任务(Task)。术语\u0026quot;子任务\u0026quot;强调同一 Operator 或 Operator 链有多个并行的 Task。\nTask\n物理图的节点。Task 是工作的基本单位，由 Flink 的运行时执行。任务正好封装了一个 Operator 或 Operator 链 的一个并行实例。\nFlink TaskManager\nTaskManager 是 Flink Cluster 的工作进程。Tasks 被安排给 TaskManagers 执行。它们相互通信，在后续的 Task 之间交换数据。\nTransformation\n变换应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。变换可能会在每条记录的基础上改变数据流或数据集，但也可能只改变其分区或执行聚合。Operator 或 Functions是 Flink 的 API 的 \u0026ldquo;物理\u0026quot;部分，而变换只是一个 API 概念。具体来说，大多数变换是由某些 Operator 实现的。\n"},"name":"术语表","published":"2020-08-20T00:00:00+08:00","summary":"Glossary","type":"entry","url":"https://ohmyweekly.github.io/notes/2020-08-20-glossary/"}],"name":"architecture","type":"feed","url":"https://ohmyweekly.github.io/tags/architecture/"}