{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io/"},"content":{"html":"\u003cp\u003e我有个 Spark FileStreaming 程序，当监控到一个批次完成后，就执行 hdfs 的 mv  命令：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003escala.sys.process._\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eorg.apache.spark.streaming.StreamingContext\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eorg.apache.spark.streaming.scheduler.\u003c/span\u003e\u003cspan class=\"o\"\u003e{\u003c/span\u003e\u003cspan class=\"nc\"\u003eStreamingListener\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eStreamingListenerBatchCompleted\u003c/span\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eStreamingMonitor\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003essc\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eStreamingContext\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eStreamingListener\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eonBatchCompleted\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebatchCompleted\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eStreamingListenerBatchCompleted\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eUnit\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003etry\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003eday\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;sh\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;-c\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;hdfs dfs -cat /tmp/apps/days.txt | head -1\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).!!.\u003c/span\u003e\u003cspan class=\"n\"\u003etrim\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 取日期文本文件的第一行\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;sh\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;-c\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003es\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003eif hdfs dfs -test -e /a26_adapter_data/nation/vintype=A26/d=\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003eday\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e; then\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e    hdfs dfs -mv /a26_adapter_data/nation/vintype=A26/d=\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003eday\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e /daily_parquet/nation/vintype=A26\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003efi\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).!!\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;sh\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;-c\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003es\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003eif hdfs dfs -test -e /a26_adapter_data/enterprise/vintype=A26/dt=\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003eday\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e; then\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e    hdfs dfs -mv /a26_adapter_data/enterprise/vintype=A26/dt=\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003eday\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e /daily_parquet/enterprise/vintype=A26\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003efi\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).!!\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;sh\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;-c\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;hdfs dfs -cat /tmp/apps/days.txt | sed \u0026#39;1d\u0026#39; | hdfs dfs -put -f - /tmp/apps/days.txt\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).!!\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 删除第一行\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"o\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003ecatch\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eException\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e没成功， 查看日志，报了如下错误：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003emv: Permission denied: user=yarn, access=WRITE, inode=\u0026#34;/a26_adapter_data/nation/vintype=A26\u0026#34;:hdfs:supergroup:drwxr-xr-x\nmv: Permission denied: user=yarn, access=WRITE, inode=\u0026#34;/a26_adapter_data/nation/vintype=A26\u0026#34;:hdfs:supergroup:drwxr-xr-x\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e解决方法, 修改 mv 目的地址的权限为 \u003ccode\u003e777\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo -u hdfs hdfs dfs -chmod -R \u003cspan class=\"m\"\u003e777\u003c/span\u003e /a26_adapter_data/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","text":"我有个 Spark FileStreaming 程序，当监控到一个批次完成后，就执行 hdfs 的 mv 命令：\nimport scala.sys.process._ import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.scheduler.{StreamingListener, StreamingListenerBatchCompleted} class StreamingMonitor(ssc: StreamingContext) extends StreamingListener { override def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted): Unit = { try { val day = Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;hdfs dfs -cat /tmp/apps/days.txt | head -1\u0026#34;).!!.trim // 取日期文本文件的第一行 Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, s\u0026#34;\u0026#34;\u0026#34; if hdfs dfs -test -e /a26_adapter_data/nation/vintype=A26/d=${day}; then hdfs dfs -mv /a26_adapter_data/nation/vintype=A26/d=${day} /daily_parquet/nation/vintype=A26 fi \u0026#34;\u0026#34;\u0026#34;).!! Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, s\u0026#34;\u0026#34;\u0026#34; if hdfs dfs -test -e /a26_adapter_data/enterprise/vintype=A26/dt=${day}; then hdfs dfs -mv /a26_adapter_data/enterprise/vintype=A26/dt=${day} /daily_parquet/enterprise/vintype=A26 fi \u0026#34;\u0026#34;\u0026#34;).!! Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;hdfs dfs -cat /tmp/apps/days.txt | sed \u0026#39;1d\u0026#39; | hdfs dfs -put -f - /tmp/apps/days.txt\u0026#34;).!! // 删除第一行 } catch { case e: Exception =\u0026gt; println(e) } } } 没成功， 查看日志，报了如下错误：\nmv: Permission denied: user=yarn, access=WRITE, inode=\u0026#34;/a26_adapter_data/nation/vintype=A26\u0026#34;:hdfs:supergroup:drwxr-xr-x mv: Permission denied: user=yarn, access=WRITE, inode=\u0026#34;/a26_adapter_data/nation/vintype=A26\u0026#34;:hdfs:supergroup:drwxr-xr-x 解决方法, 修改 mv 目的地址的权限为 777:\nsudo -u hdfs hdfs dfs -chmod -R 777 /a26_adapter_data/ "},"name":"在 Spark Streaming 程序中执行 shell 命令","published":"2019-10-21T16:16:38Z","summary":"我有个 Spark FileStreaming 程序，当监控到一个批次完成后，就执行 hdfs 的 mv 命令：\nimport scala.sys.process._ import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.scheduler.{StreamingListener, StreamingListenerBatchCompleted} class StreamingMonitor(ssc: StreamingContext) extends StreamingListener { override def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted): Unit = { try { val day = Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;hdfs dfs -cat /tmp/apps/days.txt | head -1\u0026#34;).!!.trim // 取日期文本文件的第一行 Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, s\u0026#34;\u0026#34;\u0026#34; if hdfs dfs -test -e /a26_adapter_data/nation/vintype=A26/d=${day}; then hdfs dfs -mv /a26_adapter_data/nation/vintype=A26/d=${day} /daily_parquet/nation/vintype=A26 fi \u0026#34;\u0026#34;\u0026#34;).!! Seq(\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, s\u0026#34;\u0026#34;\u0026#34; if hdfs dfs -test -e /a26_adapter_data/enterprise/vintype=A26/dt=${day}; then hdfs dfs -mv /a26_adapter_data/enterprise/vintype=A26/dt=${day} /daily_parquet/enterprise/vintype=A26 fi \u0026#34;\u0026#34;\u0026#34;).","type":"entry","url":"https://ohmyweekly.github.io/notes/execute-shell-command-in-spark-streaming-application/"}