{"author":{"name":null,"type":"card","url":"http://localhost:1313/"},"content":{"html":"\u003ch1 id=\"introducing-pandas-udf-for-pysparkhttpsdatabrickscomblog20171030introducing-vectorized-udfs-for-pysparkhtmlfromtimeline\"\u003e\u003ca href=\"https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html?from=timeline\"\u003eIntroducing Pandas UDF for PySpark\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e更新\u003c/strong\u003e：此博客于 2018 年 2 月 22 日更新，以包含一些更改。\u003c/p\u003e\n\u003cp\u003e这篇博文在即将发布的 Apache Spark 2.3 版本中引入了 Pandas UDFs(即 Vectorized UDFs) 特性，这大大提高了 Python 中用户定义函数(UDF)的性能和可用性。\u003c/p\u003e\n\u003cp\u003e在过去的几年中，Python 已经成为数据科学家的\u003ca href=\"https://stackoverflow.blog/2017/09/14/python-growing-quickly/\"\u003e默认语言\u003c/a\u003e。像 \u003ca href=\"http://pandas.pydata.org/\"\u003epandas\u003c/a\u003e，\u003ca href=\"http://www.numpy.org/\"\u003enumpy\u003c/a\u003e，\u003ca href=\"http://www.statsmodels.org/stable/index.html\"\u003estatsmodel\u003c/a\u003e 和 \u003ca href=\"http://scikit-learn.org/stable/\"\u003escikit-learn\u003c/a\u003e 这样的软件包已经获得了广泛的采用并成为主流工具包。同时，\u003ca href=\"https://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e 已成为处理大数据的事实标准。为了使数据科学家能够利用大数据的价值，Spark 在 0.7 版中添加了 Python API，并支持\u003ca href=\"https://docs.databricks.com/spark/latest/spark-sql/udf-in-python.html\"\u003euser-defined functions\u003c/a\u003e。这些用户定义的函数一次只能操作一行，因此会遭遇高序列化和调用开销。因此，许多数据管道在 Java 和 Scala 中定义 UDF，然后从 Python 中调用它们。\u003c/p\u003e\n\u003cp\u003e基于 \u003ca href=\"https://arrow.apache.org/\"\u003eApache Arrow\u003c/a\u003e 构建的 Pandas UDF 为您提供了两全其美的功能 - 完全用 Python 定义低开销，高性能 UDF的能力。\u003c/p\u003e\n\u003cp\u003e在 Spark 2.3 中，将会有两种类型的 Pandas UDF: 标量(scalar)和分组映射(grouped map)。接下来，我们使用四个示例程序来说明它们的用法：Plus One，累积概率，减去平均值，普通最小二乘线性回归。\u003c/p\u003e\n\u003ch2 id=\"scalar-pandas-udfs\"\u003eScalar Pandas UDFs\u003c/h2\u003e\n\u003cp\u003eScalar Pandas UDFs 用于向量化标量运算。要定义一个标量 Pandas UDF，只需使用 \u003ccode\u003e@pandas_udf\u003c/code\u003e 来注释一个 Python 函数，该函数接受 \u003ccode\u003epandas.Series\u003c/code\u003e 作为参数并返回另一个相同大小的 \u003ccode\u003epandas.Series\u003c/code\u003e。下面我们用两个例子来说明：Plus One 和 Cumulative Probability。\u003c/p\u003e\n\u003ch3 id=\"plus-one\"\u003ePlus One\u003c/h3\u003e\n\u003cp\u003e计算 \u003cstrong\u003ev + 1\u003c/strong\u003e 是演示 row-at-a-time UDFs 和  scalar Pandas UDFs 之间差异的简单示例。请注意，在这种情况下内置的列运算符可能执行得更快。\u003c/p\u003e\n\u003cp\u003e使用一次一行的 UDF:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark.sql.functions\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eudf\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 使用 udf 定义一个 row-at-a-time 的 udf\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@udf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;double\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 输入/输出都是单个 double 类型的值\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eplus_one\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;v2\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eplus_one\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e使用 Pandas UDFs:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark.sql.functions\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003epandas_udf\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePandasUDFType\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 使用 pandas_udf 定义一个 Pandas UDF\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@pandas_udf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;double\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePandasUDFType\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSCALAR\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 输入/输出都是 double 类型的 pandas.Series\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epandas_plus_one\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;v2\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epandas_plus_one\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e上面的例子定义了一次一行的 UDF “plus_one” 和一个执行相同的“加一”计算的 scala Pandas UDF “pandas_plus_one”。除了函数装饰器之外，UDF 的定义是相同的：“udf” vs “pandas_udf”。\u003c/p\u003e\n\u003cp\u003e在一次一行的版本中，用户定义的函数接收一个 double 类型的参数 “v” 并将 “v + 1” 的结果作为 double 来返回。在 Pandas 版本中，用户定义函数接收 \u003ccode\u003epandas.Series\u003c/code\u003e 类型的参数 “v”，并将 “v + 1” 的结果作为\u003ccode\u003epandas.Series\u003c/code\u003e 返回。因为 “v + 1” 是在 \u003ccode\u003epandas.Series\u003c/code\u003e 上进行矢量化的，所以 Pandas 版本比 row-at-a-time 的版本快得多。\u003c/p\u003e\n\u003cp\u003e请注意，使用 scala pandas UDF 时有两个重要要求:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e输入和输出序列必须具有相同的大小。\u003c/li\u003e\n\u003cli\u003e如何将一列分割为多个 \u003ccode\u003epandas.Series\u003c/code\u003e 是Spark的内部的事，因此用户定义函数的结果必须独立于分割。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"累积概率\"\u003e累积概率\u003c/h3\u003e\n\u003cp\u003e这个例子展示了 scalar Pandas UDF 更实际的用法：使用 \u003ca href=\"https://www.scipy.org/\"\u003escipy\u003c/a\u003e 包计算正态分布 N(0,1) 中值的\u003ca href=\"https://en.wikipedia.org/wiki/Cumulative_distribution_function\"\u003e累积概率\u003c/a\u003e。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003epd\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003escipy\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003estats\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@pandas_udf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;double\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecdf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estats\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecdf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;cumulative_probability\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecdf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003ccode\u003estats.norm.cdf\u003c/code\u003e 在标量值和 \u003ccode\u003epandas.Series\u003c/code\u003e 上都是可用的，并且此示例也可以使用一次一行的 UDF 编写。与前面的例子类似，Pandas 版本运行速度更快，如后面的“性能比较”部分所示。\u003c/p\u003e\n\u003ch3 id=\"grouped-map-pandas-udfs\"\u003eGrouped Map Pandas UDFs\u003c/h3\u003e\n\u003cp\u003ePython 用户对数据分析中的 split-apply-combine 模式非常熟悉。Grouped Map Pandas UDF 是针对这种情况设计的，它们针对某些组的所有数据进行操作，例如“针对每个日期应用此操作”。\u003c/p\u003e\n\u003cp\u003eGrouped Map Pandas UDF 首先根据 groupby 运算符中指定的条件将 Spark \u003ccode\u003eDataFrame\u003c/code\u003e 分组，然后将用户定义的函数（\u003ccode\u003epandas.DataFrame\u003c/code\u003e  -\u0026gt; \u003ccode\u003epandas.DataFrame\u003c/code\u003e）应用于每个组，并将结果组合并作为新的 Spark \u003ccode\u003eDataFrame\u003c/code\u003e 返回。\u003c/p\u003e\n\u003cp\u003eGrouped map Pandas UDF 使用与 scalar Pandas UDF 使用相同的函数装饰器 \u003ccode\u003epandas_udf\u003c/code\u003e，但它们有一些区别：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e用户定义函数的输入:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalar: \u003ccode\u003epandas.Series\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eGrouped map: \u003ccode\u003epandas.DataFrame\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e用户定义函数的输出:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalar: \u003ccode\u003epandas.Series\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eGrouped map: \u003ccode\u003epandas.DataFrame\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e分组语义:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalar: 无分组语义\u003c/li\u003e\n\u003cli\u003eGrouped map: 由 “groupby” 从句定义\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e输出大小:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalar: 和输入大小一样\u003c/li\u003e\n\u003cli\u003eGrouped map: 任何尺寸\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e函数装饰器中的返回类型:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalar: 一个 \u003ccode\u003eDataType\u003c/code\u003e，用于指定返回的 \u003ccode\u003epandas.Series\u003c/code\u003e 的类型\u003c/li\u003e\n\u003cli\u003eGrouped map: 一个 \u003ccode\u003eStructType\u003c/code\u003e，用于指定返回的 \u003ccode\u003epandas.DataFrame\u003c/code\u003e 中每列的名称和类型\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e接下来，让我们通过两个示例来说明 grouped map Pandas UDF 的使用场景。\u003c/p\u003e\n\u003ch3 id=\"subtract-mean\"\u003eSubtract Mean\u003c/h3\u003e\n\u003cp\u003e此示例显示了简单使用 grouped map Pandas UDFs：从组中的每个值中减去平均值。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@pandas_udf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePandasUDFType\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eGROUPED_MAP\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Input/output are both a pandas.DataFrame\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003esubtract_mean\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eassign\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emean\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egroupby\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;id\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eapply\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esubtract_mean\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在这个例子中，我们从每个组的 v 值中减去 v 的均值。分组语义由 “groupby” 函数定义，即每个输入到用户定义函数的 \u003ccode\u003epandas.DataFrame\u003c/code\u003e 具有相同的 “id” 值。这个用户定义函数的输入和输出模式是相同的，所以我们将“df.schema” 传递给装饰器 \u003ccode\u003epandas_udf\u003c/code\u003e 来指定模式。\u003c/p\u003e\n\u003cp\u003eGrouped map Pandas UDF 也可以作为驱动程序上的独立 Python 函数调用。这对于调试非常有用，例如：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etoPandas\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Run as a standalone function on a pandas.DataFrame and verify result\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003esubtract_mean\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efunc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Now run with Spark\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egroupby\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;id\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eapply\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esubstract_mean\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在上面的示例中，我们首先将 Spark \u003ccode\u003eDataFrame\u003c/code\u003e 的一个小子集转换为 \u003ccode\u003epandas.DataFrame\u003c/code\u003e，然后将 \u003cem\u003esubtract_mean\u003c/em\u003e 作为独立的 Python 函数运行。验证函数逻辑后，我们可以在整个数据集上使用 Spark 调用 UDF。\u003c/p\u003e\n\u003ch3 id=\"普通最小二乘线性回归\"\u003e普通最小二乘线性回归\u003c/h3\u003e\n\u003cp\u003e最后一个示例显示了如何使用 statsmodels 为每个组运行 OLS 线性回归。对于每个组，我们根据统计模型 Y = bX + c 计算对于 X = (x1，x2) 的 beta b = (b1，b2)。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003estatsmodels.api\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003esm\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# df has four columns: id, y, x1, x2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003egroup_column\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;id\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ey_column\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;y\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex_columns\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;x1\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;x2\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egroup_column\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003ex_columns\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nd\"\u003e@pandas_udf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePandasUDFType\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eGROUPED_MAP\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Input/output are both a pandas.DataFrame\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eols\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003egroup_key\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003egroup_column\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eiloc\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ey_column\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ex_columns\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esm\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_constant\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esm\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eOLS\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"n\"\u003egroup_key\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparams\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e   \u003cspan class=\"n\"\u003ex_columns\u003c/span\u003e\u003cspan class=\"p\"\u003e]],\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003egroup_column\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003ex_columns\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ebeta\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egroupby\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egroup_column\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eapply\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eols\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e此示例演示了 grouped map Pandas UDF 可以与任何任意的 python 函数一起使用：\u003ccode\u003epandas.DataFrame\u003c/code\u003e  -\u0026gt; \u003ccode\u003epandas.DataFrame\u003c/code\u003e。返回的 \u003ccode\u003epandas.DataFrame\u003c/code\u003e 可以具有与输入不同的行数和列数。\u003c/p\u003e\n\u003ch2 id=\"性能比较\"\u003e性能比较\u003c/h2\u003e\n\u003cp\u003e最后，我们想要显示 row-at-a-time UDF 和 Pandas UDF 之间的性能比较。我们为以上三个示例运行微基准测试（plus one, cumulative probability 和 subtract mean）。\u003c/p\u003e\n\u003ch3 id=\"配置和方法\"\u003e配置和方法\u003c/h3\u003e\n\u003cp\u003e我们在 Databricks 社区版的单节点 Spark 群集上运行了基准测试。\u003c/p\u003e\n\u003cp\u003e配置细节：\n数据：带有 Int 列和 Double 列的 10M 行 DataFrame\n集群：6.0 GB 内存，0.88 核心，1 个 DBU\nDatabricks 运行时版本：Latest RC（4.0，Scala 2.11）\u003c/p\u003e\n\u003cp\u003e有关基准的详细实现，请查看 \u003ca href=\"https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1281142885375883/2174302049319883/7729323681064935/latest.html\"\u003ePandas UDF Notebook\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://upload-images.jianshu.io/upload_images/326727-e76d1aae8e1920c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"img\"\u003e\u003c/p\u003e\n\u003cp\u003e如图表所示，Pandas UDF 的表现比 row-at-a-time UDF 好得多，范围从 \u003cstrong\u003e3倍\u003c/strong\u003e到 \u003cstrong\u003e100倍\u003c/strong\u003e 不等。\u003c/p\u003e\n\u003ch2 id=\"结论和未来工作\"\u003e结论和未来工作\u003c/h2\u003e\n\u003cp\u003e即将推出的 Spark 2.3 版本为基本改进Python中用户定义函数的功能和性能奠定了基础。今后，我们计划在聚合和窗口函数中引入对 Pandas UDF 的支持。相关工作可以在 \u003ca href=\"https://issues.apache.org/jira/browse/SPARK-22216\"\u003eSPARK-22216\u003c/a\u003e 中进行跟踪。\u003c/p\u003e\n\u003cp\u003ePandas UDFs 是 Spark 社区努力的一个很好的例子。我们要感谢 Bryan Cutler, Hyukjin Kwon, Jeff Reback, Liang-Chi Hsieh, Leif Walsh, Li Jin, Reynold Xin, Takuya Ueshin, Wenchen Fan, Wes McKinney, Xiao Li 以及其他人的贡献。最后，特别感谢 Apache Arrow 社区让这项工作成为可能。\u003c/p\u003e\n\u003ch2 id=\"下一步是什么\"\u003e下一步是什么\u003c/h2\u003e\n\u003cp\u003e您可以尝试 \u003ca href=\"https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1281142885375883/2174302049319883/7729323681064935/latest.html\"\u003ePandas UDF notebook\u003c/a\u003e ，并且此功能现在作为 \u003ca href=\"https://databricks.com/try\"\u003eDatabricks Runtime 4.0\u003c/a\u003e 测试版的一部分提供.\u003c/p\u003e\n","text":"Introducing Pandas UDF for PySpark 更新：此博客于 2018 年 2 月 22 日更新，以包含一些更改。\n这篇博文在即将发布的 Apache Spark 2.3 版本中引入了 Pandas UDFs(即 Vectorized UDFs) 特性，这大大提高了 Python 中用户定义函数(UDF)的性能和可用性。\n在过去的几年中，Python 已经成为数据科学家的默认语言。像 pandas，numpy，statsmodel 和 scikit-learn 这样的软件包已经获得了广泛的采用并成为主流工具包。同时，Apache Spark 已成为处理大数据的事实标准。为了使数据科学家能够利用大数据的价值，Spark 在 0.7 版中添加了 Python API，并支持user-defined functions。这些用户定义的函数一次只能操作一行，因此会遭遇高序列化和调用开销。因此，许多数据管道在 Java 和 Scala 中定义 UDF，然后从 Python 中调用它们。\n基于 Apache Arrow 构建的 Pandas UDF 为您提供了两全其美的功能 - 完全用 Python 定义低开销，高性能 UDF的能力。\n在 Spark 2.3 中，将会有两种类型的 Pandas UDF: 标量(scalar)和分组映射(grouped map)。接下来，我们使用四个示例程序来说明它们的用法：Plus One，累积概率，减去平均值，普通最小二乘线性回归。\nScalar Pandas UDFs Scalar Pandas UDFs 用于向量化标量运算。要定义一个标量 Pandas UDF，只需使用 @pandas_udf 来注释一个 Python 函数，该函数接受 pandas.Series 作为参数并返回另一个相同大小的 pandas.Series。下面我们用两个例子来说明：Plus One 和 Cumulative Probability。\nPlus One 计算 v + 1 是演示 row-at-a-time UDFs 和 scalar Pandas UDFs 之间差异的简单示例。请注意，在这种情况下内置的列运算符可能执行得更快。\n使用一次一行的 UDF:\nfrom pyspark.sql.functions import udf # 使用 udf 定义一个 row-at-a-time 的 udf @udf(\u0026#39;double\u0026#39;) # 输入/输出都是单个 double 类型的值 def plus_one(v): return v + 1 df.withColumn(\u0026#39;v2\u0026#39;, plus_one(df.v)) 使用 Pandas UDFs:\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType # 使用 pandas_udf 定义一个 Pandas UDF @pandas_udf(\u0026#39;double\u0026#39;, PandasUDFType.SCALAR) # 输入/输出都是 double 类型的 pandas.Series def pandas_plus_one(v): return v + 1 df.withColumn(\u0026#39;v2\u0026#39;, pandas_plus_one(df.v)) 上面的例子定义了一次一行的 UDF “plus_one” 和一个执行相同的“加一”计算的 scala Pandas UDF “pandas_plus_one”。除了函数装饰器之外，UDF 的定义是相同的：“udf” vs “pandas_udf”。\n在一次一行的版本中，用户定义的函数接收一个 double 类型的参数 “v” 并将 “v + 1” 的结果作为 double 来返回。在 Pandas 版本中，用户定义函数接收 pandas.Series 类型的参数 “v”，并将 “v + 1” 的结果作为pandas.Series 返回。因为 “v + 1” 是在 pandas.Series 上进行矢量化的，所以 Pandas 版本比 row-at-a-time 的版本快得多。\n请注意，使用 scala pandas UDF 时有两个重要要求:\n输入和输出序列必须具有相同的大小。 如何将一列分割为多个 pandas.Series 是Spark的内部的事，因此用户定义函数的结果必须独立于分割。 累积概率 这个例子展示了 scalar Pandas UDF 更实际的用法：使用 scipy 包计算正态分布 N(0,1) 中值的累积概率。\nimport pandas as pd from scipy import stats @pandas_udf(\u0026#39;double\u0026#39;) def cdf(v): return pd.Series(stats.norm.cdf(v)) df.withColumn(\u0026#39;cumulative_probability\u0026#39;, cdf(df.v)) stats.norm.cdf 在标量值和 pandas.Series 上都是可用的，并且此示例也可以使用一次一行的 UDF 编写。与前面的例子类似，Pandas 版本运行速度更快，如后面的“性能比较”部分所示。\nGrouped Map Pandas UDFs Python 用户对数据分析中的 split-apply-combine 模式非常熟悉。Grouped Map Pandas UDF 是针对这种情况设计的，它们针对某些组的所有数据进行操作，例如“针对每个日期应用此操作”。\nGrouped Map Pandas UDF 首先根据 groupby 运算符中指定的条件将 Spark DataFrame 分组，然后将用户定义的函数（pandas.DataFrame -\u0026gt; pandas.DataFrame）应用于每个组，并将结果组合并作为新的 Spark DataFrame 返回。\nGrouped map Pandas UDF 使用与 scalar Pandas UDF 使用相同的函数装饰器 pandas_udf，但它们有一些区别：\n用户定义函数的输入:\nScalar: pandas.Series Grouped map: pandas.DataFrame 用户定义函数的输出:\nScalar: pandas.Series Grouped map: pandas.DataFrame 分组语义:\nScalar: 无分组语义 Grouped map: 由 “groupby” 从句定义 输出大小:\nScalar: 和输入大小一样 Grouped map: 任何尺寸 函数装饰器中的返回类型:\nScalar: 一个 DataType，用于指定返回的 pandas.Series 的类型 Grouped map: 一个 StructType，用于指定返回的 pandas.DataFrame 中每列的名称和类型 接下来，让我们通过两个示例来说明 grouped map Pandas UDF 的使用场景。\nSubtract Mean 此示例显示了简单使用 grouped map Pandas UDFs：从组中的每个值中减去平均值。\n@pandas_udf(df.schema, PandasUDFType.GROUPED_MAP) # Input/output are both a pandas.DataFrame def subtract_mean(pdf): return pdf.assign(v=pdf.v - pdf.v.mean()) df.groupby(\u0026#39;id\u0026#39;).apply(subtract_mean) 在这个例子中，我们从每个组的 v 值中减去 v 的均值。分组语义由 “groupby” 函数定义，即每个输入到用户定义函数的 pandas.DataFrame 具有相同的 “id” 值。这个用户定义函数的输入和输出模式是相同的，所以我们将“df.schema” 传递给装饰器 pandas_udf 来指定模式。\nGrouped map Pandas UDF 也可以作为驱动程序上的独立 Python 函数调用。这对于调试非常有用，例如：\nsample = df.filter(id == 1).toPandas() # Run as a standalone function on a pandas.DataFrame and verify result subtract_mean.func(sample) # Now run with Spark df.groupby(\u0026#39;id\u0026#39;).apply(substract_mean) 在上面的示例中，我们首先将 Spark DataFrame 的一个小子集转换为 pandas.DataFrame，然后将 subtract_mean 作为独立的 Python 函数运行。验证函数逻辑后，我们可以在整个数据集上使用 Spark 调用 UDF。\n普通最小二乘线性回归 最后一个示例显示了如何使用 statsmodels 为每个组运行 OLS 线性回归。对于每个组，我们根据统计模型 Y = bX + c 计算对于 X = (x1，x2) 的 beta b = (b1，b2)。\nimport statsmodels.api as sm # df has four columns: id, y, x1, x2 group_column = \u0026#39;id\u0026#39; y_column = \u0026#39;y\u0026#39; x_columns = [\u0026#39;x1\u0026#39;, \u0026#39;x2\u0026#39;] schema = df.select(group_column, *x_columns).schema @pandas_udf(schema, PandasUDFType.GROUPED_MAP) # Input/output are both a pandas.DataFrame def ols(pdf): group_key = pdf[group_column].iloc[0] y = pdf[y_column] X = pdf[x_columns] X = sm.add_constant(X) model = sm.OLS(y, X).fit() return pd.DataFrame([[group_key] + [model.params[i] for i in x_columns]], columns=[group_column] + x_columns) beta = df.groupby(group_column).apply(ols) 此示例演示了 grouped map Pandas UDF 可以与任何任意的 python 函数一起使用：pandas.DataFrame -\u0026gt; pandas.DataFrame。返回的 pandas.DataFrame 可以具有与输入不同的行数和列数。\n性能比较 最后，我们想要显示 row-at-a-time UDF 和 Pandas UDF 之间的性能比较。我们为以上三个示例运行微基准测试（plus one, cumulative probability 和 subtract mean）。\n配置和方法 我们在 Databricks 社区版的单节点 Spark 群集上运行了基准测试。\n配置细节： 数据：带有 Int 列和 Double 列的 10M 行 DataFrame 集群：6.0 GB 内存，0.88 核心，1 个 DBU Databricks 运行时版本：Latest RC（4.0，Scala 2.11）\n有关基准的详细实现，请查看 Pandas UDF Notebook。\n如图表所示，Pandas UDF 的表现比 row-at-a-time UDF 好得多，范围从 3倍到 100倍 不等。\n结论和未来工作 即将推出的 Spark 2.3 版本为基本改进Python中用户定义函数的功能和性能奠定了基础。今后，我们计划在聚合和窗口函数中引入对 Pandas UDF 的支持。相关工作可以在 SPARK-22216 中进行跟踪。\nPandas UDFs 是 Spark 社区努力的一个很好的例子。我们要感谢 Bryan Cutler, Hyukjin Kwon, Jeff Reback, Liang-Chi Hsieh, Leif Walsh, Li Jin, Reynold Xin, Takuya Ueshin, Wenchen Fan, Wes McKinney, Xiao Li 以及其他人的贡献。最后，特别感谢 Apache Arrow 社区让这项工作成为可能。\n下一步是什么 您可以尝试 Pandas UDF notebook ，并且此功能现在作为 Databricks Runtime 4.0 测试版的一部分提供.\n"},"name":"Introducing Pandas UDF for PySpark","published":"2017-03-08T16:36:25Z","summary":"Introducing Pandas UDF for PySpark 更新：此博客于 2018 年 2 月 22 日更新，以包含一些更改。\n这篇博文在即将发布的 Apache Spark 2.3 版本中引入了 Pandas UDFs(即 Vectorized UDFs) 特性，这大大提高了 Python 中用户定义函数(UDF)的性能和可用性。\n在过去的几年中，Python 已经成为数据科学家的默认语言。像 pandas，numpy，statsmodel 和 scikit-learn 这样的软件包已经获得了广泛的采用并成为主流工具包。同时，Apache Spark 已成为处理大数据的事实标准。为了使数据科学家能够利用大数据的价值，Spark 在 0.7 版中添加了 Python API，并支持user-defined functions。这些用户定义的函数一次只能操作一行，因此会遭遇高序列化和调用开销。因此，许多数据管道在 Java 和 Scala 中定义 UDF，然后从 Python 中调用它们。\n基于 Apache Arrow 构建的 Pandas UDF 为您提供了两全其美的功能 - 完全用 Python 定义低开销，高性能 UDF的能力。\n在 Spark 2.3 中，将会有两种类型的 Pandas UDF: 标量(scalar)和分组映射(grouped map)。接下来，我们使用四个示例程序来说明它们的用法：Plus One，累积概率，减去平均值，普通最小二乘线性回归。\nScalar Pandas UDFs Scalar Pandas UDFs 用于向量化标量运算。要定义一个标量 Pandas UDF，只需使用 @pandas_udf 来注释一个 Python 函数，该函数接受 pandas.","type":"entry","url":"http://localhost:1313/notes/introducing-pandas-udf-for-pyspark/"}