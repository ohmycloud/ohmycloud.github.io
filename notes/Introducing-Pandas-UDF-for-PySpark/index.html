<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    
    
    

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">

    
    <meta name="referrer" content="no-referrer">

    <title>
        
            Introducing Pandas UDF for PySpark ❚ 焉知非鱼
        
    </title>

    
    


    
    
    
    

    
    
    
    

    
    
    

    
    
    
    <style>
     
     
     :root {
         --theme-color: #ac4142;
         --theme-color-light: rgba(172, 65, 66, 0.2);
     }
     
     html {
         line-height: 1.5;
     }
    </style>

    
    

    
    
    
    
    <link rel="stylesheet" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css">
    
    <link rel="preload" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css" as="style">

    



    
        <style>
         
         /* Background */ .chroma { background-color: #ffffff }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

         
         /* Overrides on top of the theme and Chroma CSS */
/* Chroma-based lines highlighting in code blocks */
.chroma .hl {
    background-color: #e8e8e8;
    /* Extend highlight up to 100 characters (assuming that the code blocks never have more than 100 characters in a line) */
    min-width: 100ch;
}
/* GenericHeading */ .chroma .gh { color: #999999; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa; font-weight: bold }

         
        </style>
    

    

    
    
    

    
    <script src="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js"></script>
    
    <link rel="preload" href="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js" as="script">

    
    
    <script defer src="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js"></script>
    
    <link rel="preload" href="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js" as="script">

    

    

    
    
    

    
    
<!-- rel="me" links for IndieAuth -->







    
 
<meta property="og:title" content="Introducing Pandas UDF for PySpark" />
<meta property="og:description"
      content=" " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ohmyweekly.github.io/notes/introducing-pandas-udf-for-pyspark/" />


    
        <meta property="article:published_time" content="2017-03-08T16:36:25&#43;00:00"/>
    
    
        <meta property="article:modified_time" content="2017-03-08T16:36:25&#43;00:00"/>
    









    




     <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Introducing Pandas UDF for PySpark"/>
<meta name="twitter:description" content=" "/>


    
    
    <link rel="alternate" type="application/jf2post+json" href="https://ohmyweekly.github.io/notes/introducing-pandas-udf-for-pyspark/jf2post.json" title="Jf2post for 焉知非鱼" />
    
     



    
    
    
        
    


     
        
        <meta name="DC.Creator" content="焉知非鱼"/>
    



    
    
    
    <meta name="hugo-build-date" content="2024-03-01T16:16:06Z"/>
    <meta name="hugo-commit-hash" content="312735366b20d64bd61bff8627f593749f86c964"/>
    <meta name="generator" content="Hugo 0.123.7">
</head>


    
        <body lang="en">
    

        
        <div class="border" id="home"></div>

        <div class="wrapper">   
            
<nav id="nav" class="nav-collapse opened" aria-hidden="false">
    <ul class="navbar">
        <li><a class="" href="/">Home</a></li>
        
            
                <li><a class="" href="https://ohmyweekly.github.io/posts/">Posts</a></li>
            
        
            
                <li><a class="" href="https://ohmyweekly.github.io/notes/">Notes</a></li>
            
        
        
            <li><a class="" href="https://ohmyweekly.github.io/search/">Search</a></li>
        
    </ul>
</nav>

            <div class="container">
                <header class="masthead">
                    <div class="masthead-title no-text-decoration">
                        <a href="/">焉知非鱼</a> <span class="blinking-cursor">❚</span>
                    </div>
                    <div class="masthead-tagline">
                        Wait the light to fall
                    </div>
                </header>

                








<article class="post h-entry notes">
    <header>
        <div class="center">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>

        <h1 class="post-title p-name">Introducing Pandas UDF for PySpark</h1>

        
        <data class="u-url" value="https://ohmyweekly.github.io/notes/introducing-pandas-udf-for-pyspark/"></data>

        <div class="date-syndication">
            


    
    
    <div class="post-date">
        
        <time datetime="2017-03-08T16:36:25+0000" class="dt-published">Wed Mar 8, 2017</time>
        
        
    </div>


            




        </div>
         



    
    
    
        
    


    
        
        <span class="hide">
            &mdash; <a href="https://ohmyweekly.github.io/" class="u-author">焉知非鱼</a>
        </span>
    


    </header>

    <div class="content">
        


        





                       


        <div class="e-content">
            




<h1 id="introducing-pandas-udf-for-pysparkhttpsdatabrickscomblog20171030introducing-vectorized-udfs-for-pysparkhtmlfromtimeline"><a href="https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html?from=timeline">Introducing Pandas UDF for PySpark</a></h1>
<p><strong>更新</strong>：此博客于 2018 年 2 月 22 日更新，以包含一些更改。</p>
<p>这篇博文在即将发布的 Apache Spark 2.3 版本中引入了 Pandas UDFs(即 Vectorized UDFs) 特性，这大大提高了 Python 中用户定义函数(UDF)的性能和可用性。</p>
<p>在过去的几年中，Python 已经成为数据科学家的<a href="https://stackoverflow.blog/2017/09/14/python-growing-quickly/">默认语言</a>。像 <a href="http://pandas.pydata.org/">pandas</a>，<a href="http://www.numpy.org/">numpy</a>，<a href="http://www.statsmodels.org/stable/index.html">statsmodel</a> 和 <a href="http://scikit-learn.org/stable/">scikit-learn</a> 这样的软件包已经获得了广泛的采用并成为主流工具包。同时，<a href="https://spark.apache.org/">Apache Spark</a> 已成为处理大数据的事实标准。为了使数据科学家能够利用大数据的价值，Spark 在 0.7 版中添加了 Python API，并支持<a href="https://docs.databricks.com/spark/latest/spark-sql/udf-in-python.html">user-defined functions</a>。这些用户定义的函数一次只能操作一行，因此会遭遇高序列化和调用开销。因此，许多数据管道在 Java 和 Scala 中定义 UDF，然后从 Python 中调用它们。</p>
<p>基于 <a href="https://arrow.apache.org/">Apache Arrow</a> 构建的 Pandas UDF 为您提供了两全其美的功能 - 完全用 Python 定义低开销，高性能 UDF的能力。</p>
<p>在 Spark 2.3 中，将会有两种类型的 Pandas UDF: 标量(scalar)和分组映射(grouped map)。接下来，我们使用四个示例程序来说明它们的用法：Plus One，累积概率，减去平均值，普通最小二乘线性回归。</p>
<h2 id="scalar-pandas-udfs">Scalar Pandas UDFs&nbsp;<a class="headline-hash no-text-decoration" href="#scalar-pandas-udfs">#</a> </h2>
<p>Scalar Pandas UDFs 用于向量化标量运算。要定义一个标量 Pandas UDF，只需使用 <code>@pandas_udf</code> 来注释一个 Python 函数，该函数接受 <code>pandas.Series</code> 作为参数并返回另一个相同大小的 <code>pandas.Series</code>。下面我们用两个例子来说明：Plus One 和 Cumulative Probability。</p>
<h3 id="plus-one">Plus One&nbsp;<a class="headline-hash no-text-decoration" href="#plus-one">#</a> </h3>
<p>计算 <strong>v + 1</strong> 是演示 row-at-a-time UDFs 和  scalar Pandas UDFs 之间差异的简单示例。请注意，在这种情况下内置的列运算符可能执行得更快。</p>
<p>使用一次一行的 UDF:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 udf 定义一个 row-at-a-time 的 udf</span>
</span></span><span class="line"><span class="cl"><span class="nd">@udf</span><span class="p">(</span><span class="s1">&#39;double&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 输入/输出都是单个 double 类型的值</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">plus_one</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">,</span> <span class="n">plus_one</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span><span class="p">))</span>
</span></span></code></pre></div><p>使用 Pandas UDFs:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">pandas_udf</span><span class="p">,</span> <span class="n">PandasUDFType</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 pandas_udf 定义一个 Pandas UDF</span>
</span></span><span class="line"><span class="cl"><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s1">&#39;double&#39;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 输入/输出都是 double 类型的 pandas.Series</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">pandas_plus_one</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">,</span> <span class="n">pandas_plus_one</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span><span class="p">))</span>
</span></span></code></pre></div><p>上面的例子定义了一次一行的 UDF “plus_one” 和一个执行相同的“加一”计算的 scala Pandas UDF “pandas_plus_one”。除了函数装饰器之外，UDF 的定义是相同的：“udf” vs “pandas_udf”。</p>
<p>在一次一行的版本中，用户定义的函数接收一个 double 类型的参数 “v” 并将 “v + 1” 的结果作为 double 来返回。在 Pandas 版本中，用户定义函数接收 <code>pandas.Series</code> 类型的参数 “v”，并将 “v + 1” 的结果作为<code>pandas.Series</code> 返回。因为 “v + 1” 是在 <code>pandas.Series</code> 上进行矢量化的，所以 Pandas 版本比 row-at-a-time 的版本快得多。</p>
<p>请注意，使用 scala pandas UDF 时有两个重要要求:</p>
<ul>
<li>输入和输出序列必须具有相同的大小。</li>
<li>如何将一列分割为多个 <code>pandas.Series</code> 是Spark的内部的事，因此用户定义函数的结果必须独立于分割。</li>
</ul>
<h3 id="累积概率">累积概率&nbsp;<a class="headline-hash no-text-decoration" href="#累积概率">#</a> </h3>
<p>这个例子展示了 scalar Pandas UDF 更实际的用法：使用 <a href="https://www.scipy.org/">scipy</a> 包计算正态分布 N(0,1) 中值的<a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">累积概率</a>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s1">&#39;double&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cdf</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;cumulative_probability&#39;</span><span class="p">,</span> <span class="n">cdf</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span><span class="p">))</span>
</span></span></code></pre></div><p><code>stats.norm.cdf</code> 在标量值和 <code>pandas.Series</code> 上都是可用的，并且此示例也可以使用一次一行的 UDF 编写。与前面的例子类似，Pandas 版本运行速度更快，如后面的“性能比较”部分所示。</p>
<h3 id="grouped-map-pandas-udfs">Grouped Map Pandas UDFs&nbsp;<a class="headline-hash no-text-decoration" href="#grouped-map-pandas-udfs">#</a> </h3>
<p>Python 用户对数据分析中的 split-apply-combine 模式非常熟悉。Grouped Map Pandas UDF 是针对这种情况设计的，它们针对某些组的所有数据进行操作，例如“针对每个日期应用此操作”。</p>
<p>Grouped Map Pandas UDF 首先根据 groupby 运算符中指定的条件将 Spark <code>DataFrame</code> 分组，然后将用户定义的函数（<code>pandas.DataFrame</code>  -&gt; <code>pandas.DataFrame</code>）应用于每个组，并将结果组合并作为新的 Spark <code>DataFrame</code> 返回。</p>
<p>Grouped map Pandas UDF 使用与 scalar Pandas UDF 使用相同的函数装饰器 <code>pandas_udf</code>，但它们有一些区别：</p>
<ul>
<li>
<p><strong>用户定义函数的输入:</strong></p>
<ul>
<li>Scalar: <code>pandas.Series</code></li>
<li>Grouped map: <code>pandas.DataFrame</code></li>
</ul>
</li>
<li>
<p><strong>用户定义函数的输出:</strong></p>
<ul>
<li>Scalar: <code>pandas.Series</code></li>
<li>Grouped map: <code>pandas.DataFrame</code></li>
</ul>
</li>
<li>
<p><strong>分组语义:</strong></p>
<ul>
<li>Scalar: 无分组语义</li>
<li>Grouped map: 由 “groupby” 从句定义</li>
</ul>
</li>
<li>
<p><strong>输出大小:</strong></p>
<ul>
<li>Scalar: 和输入大小一样</li>
<li>Grouped map: 任何尺寸</li>
</ul>
</li>
<li>
<p><strong>函数装饰器中的返回类型:</strong></p>
<ul>
<li>Scalar: 一个 <code>DataType</code>，用于指定返回的 <code>pandas.Series</code> 的类型</li>
<li>Grouped map: 一个 <code>StructType</code>，用于指定返回的 <code>pandas.DataFrame</code> 中每列的名称和类型</li>
</ul>
</li>
</ul>
<p>接下来，让我们通过两个示例来说明 grouped map Pandas UDF 的使用场景。</p>
<h3 id="subtract-mean">Subtract Mean&nbsp;<a class="headline-hash no-text-decoration" href="#subtract-mean">#</a> </h3>
<p>此示例显示了简单使用 grouped map Pandas UDFs：从组中的每个值中减去平均值。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@pandas_udf</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_MAP</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Input/output are both a pandas.DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">subtract_mean</span><span class="p">(</span><span class="n">pdf</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">pdf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="n">pdf</span><span class="o">.</span><span class="n">v</span> <span class="o">-</span> <span class="n">pdf</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">subtract_mean</span><span class="p">)</span>
</span></span></code></pre></div><p>在这个例子中，我们从每个组的 v 值中减去 v 的均值。分组语义由 “groupby” 函数定义，即每个输入到用户定义函数的 <code>pandas.DataFrame</code> 具有相同的 “id” 值。这个用户定义函数的输入和输出模式是相同的，所以我们将“df.schema” 传递给装饰器 <code>pandas_udf</code> 来指定模式。</p>
<p>Grouped map Pandas UDF 也可以作为驱动程序上的独立 Python 函数调用。这对于调试非常有用，例如：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sample</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="nb">id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Run as a standalone function on a pandas.DataFrame and verify result</span>
</span></span><span class="line"><span class="cl"><span class="n">subtract_mean</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Now run with Spark</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">substract_mean</span><span class="p">)</span>
</span></span></code></pre></div><p>在上面的示例中，我们首先将 Spark <code>DataFrame</code> 的一个小子集转换为 <code>pandas.DataFrame</code>，然后将 <em>subtract_mean</em> 作为独立的 Python 函数运行。验证函数逻辑后，我们可以在整个数据集上使用 Spark 调用 UDF。</p>
<h3 id="普通最小二乘线性回归">普通最小二乘线性回归&nbsp;<a class="headline-hash no-text-decoration" href="#普通最小二乘线性回归">#</a> </h3>
<p>最后一个示例显示了如何使用 statsmodels 为每个组运行 OLS 线性回归。对于每个组，我们根据统计模型 Y = bX + c 计算对于 X = (x1，x2) 的 beta b = (b1，b2)。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
</span></span><span class="line"><span class="cl"><span class="c1"># df has four columns: id, y, x1, x2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">group_column</span> <span class="o">=</span> <span class="s1">&#39;id&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">y_column</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">x_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">schema</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">group_column</span><span class="p">,</span> <span class="o">*</span><span class="n">x_columns</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@pandas_udf</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_MAP</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Input/output are both a pandas.DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ols</span><span class="p">(</span><span class="n">pdf</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_key</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">group_column</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">y</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">y_column</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">x_columns</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">      <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="n">group_key</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span>   <span class="n">x_columns</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">group_column</span><span class="p">]</span> <span class="o">+</span> <span class="n">x_columns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">beta</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">group_column</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ols</span><span class="p">)</span>
</span></span></code></pre></div><p>此示例演示了 grouped map Pandas UDF 可以与任何任意的 python 函数一起使用：<code>pandas.DataFrame</code>  -&gt; <code>pandas.DataFrame</code>。返回的 <code>pandas.DataFrame</code> 可以具有与输入不同的行数和列数。</p>
<h2 id="性能比较">性能比较&nbsp;<a class="headline-hash no-text-decoration" href="#性能比较">#</a> </h2>
<p>最后，我们想要显示 row-at-a-time UDF 和 Pandas UDF 之间的性能比较。我们为以上三个示例运行微基准测试（plus one, cumulative probability 和 subtract mean）。</p>
<h3 id="配置和方法">配置和方法&nbsp;<a class="headline-hash no-text-decoration" href="#配置和方法">#</a> </h3>
<p>我们在 Databricks 社区版的单节点 Spark 群集上运行了基准测试。</p>
<p>配置细节：
数据：带有 Int 列和 Double 列的 10M 行 DataFrame
集群：6.0 GB 内存，0.88 核心，1 个 DBU
Databricks 运行时版本：Latest RC（4.0，Scala 2.11）</p>
<p>有关基准的详细实现，请查看 <a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1281142885375883/2174302049319883/7729323681064935/latest.html">Pandas UDF Notebook</a>。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/326727-e76d1aae8e1920c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="img"></p>
<p>如图表所示，Pandas UDF 的表现比 row-at-a-time UDF 好得多，范围从 <strong>3倍</strong>到 <strong>100倍</strong> 不等。</p>
<h2 id="结论和未来工作">结论和未来工作&nbsp;<a class="headline-hash no-text-decoration" href="#结论和未来工作">#</a> </h2>
<p>即将推出的 Spark 2.3 版本为基本改进Python中用户定义函数的功能和性能奠定了基础。今后，我们计划在聚合和窗口函数中引入对 Pandas UDF 的支持。相关工作可以在 <a href="https://issues.apache.org/jira/browse/SPARK-22216">SPARK-22216</a> 中进行跟踪。</p>
<p>Pandas UDFs 是 Spark 社区努力的一个很好的例子。我们要感谢 Bryan Cutler, Hyukjin Kwon, Jeff Reback, Liang-Chi Hsieh, Leif Walsh, Li Jin, Reynold Xin, Takuya Ueshin, Wenchen Fan, Wes McKinney, Xiao Li 以及其他人的贡献。最后，特别感谢 Apache Arrow 社区让这项工作成为可能。</p>
<h2 id="下一步是什么">下一步是什么&nbsp;<a class="headline-hash no-text-decoration" href="#下一步是什么">#</a> </h2>
<p>您可以尝试 <a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1281142885375883/2174302049319883/7729323681064935/latest.html">Pandas UDF notebook</a> ，并且此功能现在作为 <a href="https://databricks.com/try">Databricks Runtime 4.0</a> 测试版的一部分提供.</p>


        </div>
    </div>
</article>



                <footer>
                    




<div class="no-text-decoration">
    <div class="jump top"><a href="#" title="Top of this page">⮉</a></div>
    <div class="jump bottom"><a href="#bottom" title="Bottom of this page">⮋</a></div>
</div>


 
    
        <div class="hugotoc no-text-decoration">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#scalar-pandas-udfs">Scalar Pandas UDFs</a>
      <ul>
        <li><a href="#plus-one">Plus One</a></li>
        <li><a href="#累积概率">累积概率</a></li>
        <li><a href="#grouped-map-pandas-udfs">Grouped Map Pandas UDFs</a></li>
        <li><a href="#subtract-mean">Subtract Mean</a></li>
        <li><a href="#普通最小二乘线性回归">普通最小二乘线性回归</a></li>
      </ul>
    </li>
    <li><a href="#性能比较">性能比较</a>
      <ul>
        <li><a href="#配置和方法">配置和方法</a></li>
      </ul>
    </li>
    <li><a href="#结论和未来工作">结论和未来工作</a></li>
    <li><a href="#下一步是什么">下一步是什么</a></li>
  </ul>
</nav>
            <a href="#" class="back-to-top">Back to top</a>
        </div>
    
    
<script src="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js"></script>

<link rel="preload" href="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js" as="script">

<script type="application/javascript">(function() {
     var $window = $(window);
     if ($window.width() >= 1400) { 
         var $toc = $('#TableOfContents');
         if ($toc.length > 0) {
             function onScroll(){
                 var currentScroll = $window.scrollTop();
                 var h = $('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .h-feed h2');
                 var id = "";
                 h.each(function (i, e) {
                     e = $(e);
                     if (e.offset().top - 10 <= currentScroll) {
                         id = e.attr('id');
                     }
                 });
                 var current = $toc.find('a.current');
                 if (current.length == 1 && current.eq(0).attr('href') == '#' + id) return true;

                 current.each(function (i, e) {
                     $(e).removeClass('current').siblings('ul').hide();
                 });
                 $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                     $(e).children('a').addClass('current').siblings('ul').show();
                 });
             }
             $window.on('scroll', onScroll);
             $(document).ready(function() {
                 $toc.find('a').parent('li').find('ul').hide();
                 onScroll();
                 document.getElementsByClassName('hugotoc')[0].style.display = '';
             });}}})();</script>








<div class="backtotop center no-text-decoration">
    <a href="#">back to <span class="top">top</span></a>
</div>


<div class="right">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>
<div class="clear-float"></div>



<div class="prev-next-navigator clear-float">
    
        <span class="prev-post left no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/maven-%E5%88%9B%E5%BB%BA%E7%88%B6%E5%AD%90%E9%A1%B9%E7%9B%AE/" class="nobr">« 使用 IDEA 创建 maven 父子工程</a>
        </span>
    
    
        <span class="next-post right no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/idea%E5%8D%87%E7%BA%A7%E5%90%8E%E5%AF%BC%E8%87%B4%E6%8A%A5%E7%BA%A2/" class="nobr">IDEA 报红 »</a>
        </span>
    
</div>


<a id="bottom"></a>









                       







                    <ul class="no-bullets feed right inline">
    
        
        
    
</ul>
<div class="clear-float"></div>

                </footer>
                <hr />
            </div>               

            <footer> 
                

<ul class="social no-text-decoration">
    
</ul>










 
    
    



<p class="generated no-text-decoration">
    Generated using  <a href="https://gitlab.com/kaushalmodi/hugo-theme-refined"><code class="nobr">hugo-theme-refined</code></a> + <span class="nobr">Hugo <a href="https://github.com/gohugoio/hugo/commit/312735366b20d64bd61bff8627f593749f86c964">0.123.7</a></span>
</p>

<p>
    
</p>




<div class="badges no-text-decoration">
    
    

    
</div>




<script type="application/javascript">var nav=responsiveNav("#nav");</script>




<script defer src="/js/libs/fragmentions/wrapper.min.e8c468c89edc4f5dccaa8c720c6b220b3088a16cd7b1e4a1e3345985788260c9.js"></script>









            </footer>
        </div> 
    </body>
</html>
