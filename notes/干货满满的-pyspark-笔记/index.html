<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    
    
    

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">

    
    <meta name="referrer" content="no-referrer">

    <title>
        
            Pyspark 笔记 ❚ 焉知非鱼
        
    </title>

    
    


    
    
    
    

    
    
    
    

    
    
    

    
    
    
    <style>
     
     
     :root {
         --theme-color: #ac4142;
         --theme-color-light: rgba(172, 65, 66, 0.2);
     }
     
     html {
         line-height: 1.5;
     }
    </style>

    
    

    
    
    
    
    <link rel="stylesheet" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css">
    
    <link rel="preload" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css" as="style">

    



    
        <style>
         
         /* Background */ .chroma { background-color: #ffffff }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

         
         /* Overrides on top of the theme and Chroma CSS */
/* Chroma-based lines highlighting in code blocks */
.chroma .hl {
    background-color: #e8e8e8;
    /* Extend highlight up to 100 characters (assuming that the code blocks never have more than 100 characters in a line) */
    min-width: 100ch;
}
/* GenericHeading */ .chroma .gh { color: #999999; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa; font-weight: bold }

         
        </style>
    

    

    
    
    

    
    <script src="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js"></script>
    
    <link rel="preload" href="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js" as="script">

    
    
    <script defer src="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js"></script>
    
    <link rel="preload" href="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js" as="script">

    

    

    
    
    

    
    
<!-- rel="me" links for IndieAuth -->







    
 
<meta property="og:title" content="Pyspark 笔记" />
<meta property="og:description"
      content="PySpark" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ohmyweekly.github.io/notes/%E5%B9%B2%E8%B4%A7%E6%BB%A1%E6%BB%A1%E7%9A%84-pyspark-%E7%AC%94%E8%AE%B0/" />


    
        <meta property="article:published_time" content="2017-04-07T16:36:25&#43;00:00"/>
    
    
        <meta property="article:modified_time" content="2017-04-07T16:36:25&#43;00:00"/>
    









    




     <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pyspark 笔记"/>
<meta name="twitter:description" content="PySpark"/>


    
    
    <link rel="alternate" type="application/jf2post+json" href="https://ohmyweekly.github.io/notes/%E5%B9%B2%E8%B4%A7%E6%BB%A1%E6%BB%A1%E7%9A%84-pyspark-%E7%AC%94%E8%AE%B0/jf2post.json" title="Jf2post for 焉知非鱼" />
    
     



    
    
    
        
    


     
        
        <meta name="DC.Creator" content="焉知非鱼"/>
    



    
    
    
    <meta name="hugo-build-date" content="2024-03-01T16:16:06Z"/>
    <meta name="hugo-commit-hash" content="312735366b20d64bd61bff8627f593749f86c964"/>
    <meta name="generator" content="Hugo 0.123.7">
</head>


    
        <body lang="en">
    

        
        <div class="border" id="home"></div>

        <div class="wrapper">   
            
<nav id="nav" class="nav-collapse opened" aria-hidden="false">
    <ul class="navbar">
        <li><a class="" href="/">Home</a></li>
        
            
                <li><a class="" href="https://ohmyweekly.github.io/posts/">Posts</a></li>
            
        
            
                <li><a class="" href="https://ohmyweekly.github.io/notes/">Notes</a></li>
            
        
        
            <li><a class="" href="https://ohmyweekly.github.io/search/">Search</a></li>
        
    </ul>
</nav>

            <div class="container">
                <header class="masthead">
                    <div class="masthead-title no-text-decoration">
                        <a href="/">焉知非鱼</a> <span class="blinking-cursor">❚</span>
                    </div>
                    <div class="masthead-tagline">
                        rakulang, dartlang, nimlang, golang, rustlang, lang lang no see
                    </div>
                </header>

                








<article class="post h-entry notes">
    <header>
        <div class="center">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>

        <h1 class="post-title p-name">Pyspark 笔记</h1>

        
        <data class="u-url" value="https://ohmyweekly.github.io/notes/%E5%B9%B2%E8%B4%A7%E6%BB%A1%E6%BB%A1%E7%9A%84-pyspark-%E7%AC%94%E8%AE%B0/"></data>

        <div class="date-syndication">
            


    
    
    <div class="post-date">
        
        <time datetime="2017-04-07T16:36:25+0000" class="dt-published">Fri Apr 7, 2017</time>
        
        
    </div>


            




        </div>
         



    
    
    
        
    


    
        
        <span class="hide">
            &mdash; <a href="https://ohmyweekly.github.io/" class="u-author">焉知非鱼</a>
        </span>
    


    </header>

    <div class="content">
        
    <div class="description p-summary">
        
        
        
        
        
            
            
        
        <p>PySpark</p>
    </div>



        





                       


        <div class="e-content">
            




<h1 id="反向代理的配置">反向代理的配置</h1>
<p>在服务器中做如下配置:</p>
<pre tabindex="0"><code>server {                                                       
  listen 80;                                                   
  server_name test.aldwx.com;                                  
  location /app.launch.php {                                   
    proxy_pass http://127.0.0.1:3000;                          
  }                                                            
}
</code></pre><p>然后在服务器中的终端中输入</p>
<pre tabindex="0"><code>plackup -E deployment -s Starman --workers=1 -p 3000 -a app.pl
</code></pre><p>或者:</p>
<pre tabindex="0"><code>nohup plackup -E deployment -s Starman --workers=10 -p 3000 -a app.pl &amp;
</code></pre><p><code>app.pl</code> 是用 dancer 写的一个 demo 程序, 其中的内容如下:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-perl" data-lang="perl"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/perl</span>
</span></span><span class="line"><span class="cl"><span class="k">use</span> <span class="nn">Digest::MD5</span> <span class="sx">qw(md5_hex)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">use</span> <span class="nn">Dancer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">use</span> <span class="nn">JSON</span> <span class="sx">qw(encode_json)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># return the json format data</span>
</span></span><span class="line"><span class="cl"><span class="n">get</span>  <span class="s">&#34;/app.launch.info.php&#34;</span> <span class="o">=&gt;</span> <span class="k">sub</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">my</span> <span class="nv">$data</span> <span class="o">=</span> <span class="sb">`date`</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">  <span class="k">my</span> <span class="nv">$token</span> <span class="o">=</span> <span class="n">md5_hex</span><span class="p">(</span><span class="nv">$data</span><span class="p">);</span>   
</span></span><span class="line"><span class="cl">  <span class="k">my</span>  <span class="nv">$r</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s">&#39;error&#39;</span> <span class="o">=&gt;</span> <span class="s">&#39;0&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s">&#39;data&#39;</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="s">&#39;access_token&#39;</span> <span class="o">=&gt;</span> <span class="nv">$token</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">encode_json</span><span class="p">(</span><span class="nv">$r</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">get</span>  <span class="s">&#39;/hello&#39;</span>  <span class="o">=&gt;</span> <span class="k">sub</span>  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="s">&#34;Hello 小程序&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">get</span>  <span class="s">&#39;/l.html&#39;</span> <span class="o">=&gt;</span> <span class="k">sub</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="s">&#34;Hello, World&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dance</span><span class="p">;</span>
</span></span></code></pre></div><p>然后在浏览其中输入:</p>
<pre tabindex="0"><code>test.aldwx.com/app.launch.info.php
</code></pre><p>你会看到浏览器返给你返回一段 <code>json</code> 数据。</p>
<h2 id="查看端口号被哪个进程占用">查看端口号被哪个进程占用&nbsp;<a class="headline-hash no-text-decoration" href="#查看端口号被哪个进程占用">#</a> </h2>
<pre tabindex="0"><code>netstat -tulnp | grep &#39;:80 &#39;
tcp        0      0 0.0.0.0:80                  0.0.0.0:*                   LISTEN      4021/nginx.conf 
</code></pre><h1 id="nginx-error-open-alidataservernginxlogsnginxpid-failed-2-no-such-file-or-directory-错误">nginx: [error] open() &ldquo;/alidata/server/nginx/logs/nginx.pid&rdquo; failed (2: No such file or directory) 错误</h1>
<p>在使用的阿里云服务器上，进程性的 nginx -s stop后再次启动nginx -s reload ,总是会报错误nginx: [error] open() &ldquo;/alidata/server/nginx/logs/nginx.pid&rdquo; failed (2: No such file or directory)，这应该是因为把nginx进程杀死后pid丢失了，下一次再开启nginx -s reload时无法启动</p>
<pre tabindex="0"><code>nginx -c /path/to/config/nginx.conf
</code></pre><h1 id="查看被占用的端口号">查看被占用的端口号</h1>
<pre tabindex="0"><code>lsof -i | grep &#34;:7077&#34;
java       8927     root  230u  IPv6   100990      0t0  TCP 106.2.1.77:7077 (LISTEN)
</code></pre><h1 id="php-环境搭建">php 环境搭建</h1>
<pre tabindex="0"><code>sudo apt-get update
sudo apt-get install lib apache2-mod-php5 ...
</code></pre><h1 id="conf-文件的配置">.conf 文件的配置</h1>
<p><code>.conf</code> 文件一版放在 <code>sites-available</code> 目录中, 用的时候再软链接到 <code>sites-enabled</code> 中。</p>
<h1 id="免密码登录服务器">免密码登录服务器</h1>
<p>在服务器上的 <code>./ssh</code> 目录中添加 <code>ssh key</code>, 比如我更换了新电脑:</p>
<pre tabindex="0"><code>vim ~/.ssh/authorized_keys
</code></pre><p>删除掉旧的 ssh keys, 加入新生成的:</p>
<pre tabindex="0"><code>ssh-rsa AAACCQEEEEddfdfdffrrt3334QWAUUY1223xxxXXXXXXX wodefan@Mac-mini.local
</code></pre><h1 id="从本地上传下载文件文件夹到服务器">从本地上传/下载文件/文件夹到服务器</h1>
<p>上传和下载都是在本地打开命令行终端。</p>
<ul>
<li>上传</li>
</ul>
<pre tabindex="0"><code>scp ./app.py root@108.2.5.98:/daly/apk/myapp/ # 从本地上传单个文件到服务器
scp -r myjobs root@108.2.5.98:/daly/apk/      # 从本地上传整个文件夹到服务器
</code></pre><ul>
<li>下载</li>
</ul>
<pre tabindex="0"><code>scp root@108.2.5.98:/daly/apk/myapp/today.txt . # 从服务器下载指定文件到本地目录
scp -r root@108.2.5.98:/daly/apk/apk/ .         # 从服务器下载整个文件夹到本地 
</code></pre><h1 id="在-pyspark-中连接数据库">在 pyspark 中连接数据库</h1>
<ul>
<li>启动 pyspark 时附加上相应的 mysql jar 包:</li>
</ul>
<pre tabindex="0"><code>/data/app/spark/bin/pyspark --driver-class-path mysql-connector-java-5.1.40-bin.jar --jars mysql-connector-java-5.1.40-bin.jar
</code></pre><ul>
<li>使用用户名和密码连接 mysql, 并创建一个数据框:</li>
</ul>
<pre tabindex="0"><code>df = spark.read.format(&#34;jdbc&#34;).option(&#34;url&#34;, &#34;jdbc:mysql://8.8.8.8/ald_xinen&#34;).option(&#34;dbtable&#34;, &#34;(select * from ald_session_logs) as df&#34;).option(&#39;user&#39;, &#34;root&#34;).option(&#39;password&#39;, &#34;fish@sky&#34;).load()
df.take(2) # 取出前两行
</code></pre><blockquote>
<p>如果已经启动了一个连接 mysql 数据库的 pyspark, 再重新启动一个时会报错, 这个时候就要把之前的启动的杀掉:</p>
</blockquote>
<pre tabindex="0"><code>ps aux | grep &#39;spark&#39;
</code></pre><p>然后找到 <code>pyspark-shell</code> 的 进程 id, <code>kill -9 xxxx</code></p>
<ul>
<li>toDF(*cols) 返回一新的数据框, 指定新的列名。</li>
</ul>
<pre tabindex="0"><code>df.select(&#34;app_key&#34;, &#34;uuid&#34;).toDF(&#34;f1&#34;, &#39;f2&#39;).take(2) 
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(f1=u&#39;2323423dsfds&#39;, f2=u&#39;14797409227806341000&#39;), Row(f1=u&#39;2323423dsfds&#39;, f2=u&#39;14797409227806341000&#39;)]
</code></pre><ul>
<li>toJSON() 将数据框转换为字符串 RDD。每一行都被转换为 JSON 文档, 作为所返回的 RDD 中的一个元素。</li>
</ul>
<pre tabindex="0"><code>df.select(&#34;app_key&#34;, &#34;uuid&#34;).toJSON().first()        
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>u&#39;{&#34;app_key&#34;:&#34;2323423dsfds&#34;,&#34;uuid&#34;:&#34;14797409227806341000&#34;}&#39;
</code></pre><ul>
<li>toLocalIterator()</li>
</ul>
<p>返回一个包含该数据框所有行的迭代器。这个迭代器会在该数据框的最大分区中消耗尽可能多的内存。</p>
<pre tabindex="0"><code>list(df.toLocalIterator())
</code></pre><ul>
<li>withColumn(colName, col)</li>
</ul>
<p>通过为原数据框<strong>添加一个新列</strong>或<strong>替换已存在的同名列</strong>而返回一个新数据框。<code>colName</code> 是一个字符串, 为新列的名字。
<code>col</code> 为这个新列的 <strong>Column</strong> 表达式。<code>withColumn</code> 的第一个参数必须是已存在的列的名字,　<code>withColumn</code> 的第二个参数必须是含有列的表达式。如果不是它会报错 <code>AssertionError: col should be Column</code>。</p>
<pre tabindex="0"><code>df.withColumn(&#39;page_count&#39;, df.page_count+100).select(&#34;app_key&#34;,&#34;page_count&#34;).take(2)
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;2323423dsfds&#39;, page_count=110), Row(app_key=u&#39;2323423dsfds&#39;, page_count=104)]
</code></pre><p><code>col</code> 表达式可以使用多个其他列:</p>
<pre tabindex="0"><code>df.withColumn(&#39;avg&#39;, df.page_count/df.duration).select(&#34;app_key&#34;,&#34;avg&#34;).take(2)
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;2323423dsfds&#39;, avg=0.00012387736141220192), Row(app_key=u&#39;2323423dsfds&#39;, avg=0.16666666666666666)]
</code></pre><p><code>withColumn</code> 可以添加一个常数列,   但是要使用 <code>pyspark.sql.functions</code> 中的函数, 例如: <code>unix_timestamp</code>.</p>
<p>可以参考</p>
<ul>
<li>
<p><a href="http://stackoverflow.com/questions/33681487/how-do-i-add-a-new-column-to-a-spark-dataframe-using-pyspark">How do I add a new column to a Spark DataFrame (using PySpark)?</a></p>
</li>
<li>
<p><a href="http://stackoverflow.com/questions/32788322/how-to-add-a-constant-column-in-a-spark-dataframe">How to add a constant column in a Spark DataFrame?</a></p>
</li>
<li>
<p>withColumnRenamed(existing, new)</p>
</li>
</ul>
<p>重命名已存在的列并返回一个新数据框。<code>existing</code> 为已存在的要重命名的列, <code>col</code> 为新列的名字。</p>
<p>将 <em>duration</em> 列重命名为 <em>time_take</em> 列:</p>
<pre tabindex="0"><code>df.withColumnRenamed(&#39;duration&#39;, &#39;time_take&#39;).select(&#39;app_key&#39;, &#39;time_take&#39;).take(2)
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;2323423dsfds&#39;, time_take=80725), Row(app_key=u&#39;2323423dsfds&#39;, time_take=24)]
</code></pre><h1 id="groupby-之后可以使用的方法">groupBy 之后可以使用的方法</h1>
<ul>
<li>agg(*exprs)</li>
</ul>
<p>聚合计算并将结果返回为 <strong>DataFrame</strong>。</p>
<p>可用的聚合函数有 <em>avg</em>, <em>max</em>, <em>min</em>, <em>sum</em>, &lsquo;count&rsquo;.</p>
<p>如果 <code>expr</code> 是从字符串到字符串的单个 <strong>dict</strong> 映射, 那么其键就是要执行聚合的列, 其值就是该聚合函数。</p>
<p>可选地, <code>expr</code> 还可以是一组聚合<strong>列</strong> 表达式。</p>
<p><strong>参数</strong>: <strong>exprs</strong> - 一个从列名(字符串)到聚合函数(字符串)的字典映射, 或者是一个 <strong>Column</strong> 列表。</p>
<pre tabindex="0"><code>gdf = df.groupBy(df.app_key)
gdf.agg({&#34;*&#34; : &#39;count&#39; } ).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, count(1)=1), Row(app_key=u&#39;AAAAAAAAAAAAAA&#39;, count(1)=1), Row(app_key=u&#39;6c4396a7eec8f081e890ef0adbf5090d&#39;, count(1)=4), Row(app_key=u&#39;7c8ccee05d025bb85f15f9d45c83aba8&#39;, count(1)=12), Row(app_key=u&#39;6428c8aa20672b64386fc1d2ce60ef3f&#39;, count(1)=3), Row(app_key=u&#39;2323423dsfds&#39;, count(1)=66), Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, count(1)=490), Row(app_key=u&#39;f05883cf4dd8c6016ac55d9380f568d2&#39;, count(1)=17), Row(app_key=u&#39;dc9c30b87aa07834ffb7736f715b9caa&#39;, count(1)=5)]
</code></pre><p>对 app_key 排序下:</p>
<pre tabindex="0"><code>sorted(gdf.agg({&#34;*&#34;: &#34;count&#34;}).collect())
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, count(1)=490), Row(app_key=u&#39;2323423dsfds&#39;, count(1)=66), Row(app_key=u&#39;6428c8aa20672b64386fc1d2ce60ef3f&#39;, count(1)=3), Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, count(1)=1), Row(app_key=u&#39;6c4396a7eec8f081e890ef0adbf5090d&#39;, count(1)=4), Row(app_key=u&#39;7c8ccee05d025bb85f15f9d45c83aba8&#39;, count(1)=12), Row(app_key=u&#39;AAAAAAAAAAAAAA&#39;, count(1)=1), Row(app_key=u&#39;dc9c30b87aa07834ffb7736f715b9caa&#39;, count(1)=5), Row(app_key=u&#39;f05883cf4dd8c6016ac55d9380f568d2&#39;, count(1)=17)]
</code></pre><pre tabindex="0"><code>from pyspark.sql import functions as F
sorted(gdf.agg(F.max(df.duration)).collect())
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, max(duration)=28498), Row(app_key=u&#39;2323423dsfds&#39;, max(duration)=80725), Row(app_key=u&#39;6428c8aa20672b64386fc1d2ce60ef3f&#39;, max(duration)=352), Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, max(duration)=150), Row(app_key=u&#39;6c4396a7eec8f081e890ef0adbf5090d&#39;, max(duration)=33), Row(app_key=u&#39;7c8ccee05d025bb85f15f9d45c83aba8&#39;, max(duration)=168), Row(app_key=u&#39;AAAAAAAAAAAAAA&#39;, max(duration)=23), Row(app_key=u&#39;dc9c30b87aa07834ffb7736f715b9caa&#39;, max(duration)=87), Row(app_key=u&#39;f05883cf4dd8c6016ac55d9380f568d2&#39;, max(duration)=7789)]
</code></pre><ul>
<li>avg(*cols)</li>
</ul>
<p>为每一组的每个数值列计算平均值。</p>
<p><code>mean</code> 是 <code>avg</code> 的别名。</p>
<p><strong>参数: cols</strong> - 一组列的名字(字符串)。非数值列被忽略。</p>
<pre tabindex="0"><code>df.groupBy(&#39;app_key&#39;).avg(&#39;duration&#39;).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, avg(duration)=150.0),Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, avg(duration)=153.81428571428572) ...]
</code></pre><pre tabindex="0"><code>df.groupBy(&#39;app_key&#39;).avg(&#39;duration&#39;, &#39;page_count&#39;).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, avg(duration)=150.0, avg(page_count)=12.0), avg(page_count)=5.681818181818182), Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, avg(duration)=153.81428571428572, avg(page_count)=8.059183673469388) ...]
</code></pre><ul>
<li>count()</li>
</ul>
<p>计算每组的记录数。</p>
<pre tabindex="0"><code>sorted(df.groupBy(df.app_key).count().collect())
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, count=490), Row(app_key=u&#39;2323423dsfds&#39;, count=66) ...]
</code></pre><ul>
<li>max(*cols)</li>
</ul>
<p>计算每组每个数值列的最大值。</p>
<pre tabindex="0"><code>df.groupBy(&#39;app_key&#39;).max(&#39;duration&#39;).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, max(duration)=150) ...]
</code></pre><pre tabindex="0"><code>df.groupBy(&#39;app_key&#39;).max(&#39;duration&#39;, &#39;page_count&#39;).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, max(duration)=150, max(page_count)=12)...]
</code></pre><ul>
<li>
<p>mean() 求平均数, 同 avg</p>
</li>
<li>
<p>min() 参考 max</p>
</li>
<li>
<p>pivot(pivot_col, values=None)</p>
</li>
</ul>
<p>透视当前[[DataFrame]]的列并执行指定的聚合。有两个版本的pivot函数：一个需要调用者指定不同值的列表以便进行透视，而另一个不指定。后者更简洁但效率较低，因为Spark需要首先在内部计算不同值的列表。</p>
<p><strong>参数</strong>: <strong>pivot_col</strong> - 要透视的列名; <strong>values</strong> - 将转换为输出 DataFrame 中的列的值列表。</p>
<p>计算每个 app 下，每个渠道的总停留时长, 每个渠道的结果占一列:</p>
<pre tabindex="0"><code>df.groupBy(&#39;app_key&#39;).pivot(&#34;source&#34;, [&#34;1&#34;, &#34;2&#34;, &#34;3&#34;, &#34;4&#34; ]).sum(&#34;duration&#34;).collect()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;64a7f2b033fb593a8598bbc48c3b8486&#39;, 1=None, 2=None, 3=None, 4=150), Row(app_key=u&#39;21e689e6bb76a213b21fc61147db1bab&#39;, 1=7208, 2=54929, 3=7078, 4=6139), Row(app_key=u&#39;dc9c30b87aa07834ffb7736f715b9caa&#39;, 1=None, 2=94, 3=29, 4=87) ...]
</code></pre><p>官方的例子:</p>
<pre tabindex="0"><code># Compute the sum of earnings for each year by course with each course as a separate column
df4.groupBy(&#34;year&#34;).pivot(&#34;course&#34;, [&#34;dotNET&#34;, &#34;Java&#34;]).sum(&#34;earnings&#34;).collect()
[Row(year=2012, dotNET=15000, Java=20000), Row(year=2013, dotNET=48000, Java=30000)]
</code></pre><p>或者不指定列的值（不够有效率）</p>
<pre tabindex="0"><code>df4.groupBy(&#34;year&#34;).pivot(&#34;course&#34;).sum(&#34;earnings&#34;).collect()
[Row(year=2012, Java=20000, dotNET=15000), Row(year=2013, Java=30000, dotNET=48000)]
</code></pre><ul>
<li>sum(*cols)</li>
</ul>
<p>为每组计算每个数值列的总和。</p>
<p><strong>参数</strong>: cols - 一组列的名字（字符串）。非数值列被忽略。</p>
<pre tabindex="0"><code># 官方例子：
df.groupBy().sum(&#39;age&#39;).collect()
# [Row(sum(age)=7)]
df3.groupBy().sum(&#39;age&#39;, &#39;height&#39;).collect()
# [Row(sum(age)=7, sum(height)=165)]
</code></pre><ul>
<li>class pyspark.sql.Column(jc)</li>
</ul>
<p>数据框中的一列。 <strong>Column</strong> 实例可以通过如下的代码创建：</p>
<pre tabindex="0"><code>#1. 选择数据框中的一列
df.colName
df[&#34;colName&#34;]

#2. 从表达式创建
df.colName + 1
1 / df.colName 
</code></pre><ul>
<li>alias(*alias)</li>
</ul>
<p>返回这个列的新的别名或别名们(在表达式返回多列的情况下, 例如爆炸)。</p>
<pre tabindex="0"><code>df.select(df.duration.alias(&#34;time_take&#34;)).collect()
</code></pre><ul>
<li>asc()</li>
</ul>
<p>返回一个排序过的表达式, 基于给定列的名字的升序进行排列。</p>
<ul>
<li>
<p>astype() 是 cast() 的别名。</p>
</li>
<li>
<p>between(lowerBound, upperBound)</p>
</li>
</ul>
<p>如果这个表达式的值在给定的列的值之间，则计算结果为布尔真。</p>
<pre tabindex="0"><code>df.select(df.app_key, df.duration.between(60,80)).show(50)
</code></pre><p>show()函数输出前 20 行:</p>
<pre tabindex="0"><code>+--------------------+---------------------------------------+
|             app_key|((duration &gt;= 60) AND (duration &lt;= 80))|
+--------------------+---------------------------------------+
|        2323423dsfds|                                  false|
|        2323423dsfds|                                  false|
|        2323423dsfds|                                  false|
|        2323423dsfds|                                  false|
|        2323423dsfds|                                   true|
...
</code></pre><ul>
<li>cast(dataType)</li>
</ul>
<p>将列转换为 <code>dataType</code> 类型。</p>
<pre tabindex="0"><code># 官方例子:
df.select(df.age.cast(&#34;string&#34;).alias(&#39;ages&#39;)).collect()
# [Row(ages=u&#39;2&#39;), Row(ages=u&#39;5&#39;)]
df.select(df.age.cast(StringType()).alias(&#39;ages&#39;)).collect()
# [Row(ages=u&#39;2&#39;), Row(ages=u&#39;5&#39;)]
</code></pre><pre tabindex="0"><code># 将字符串转为 int 型
df.select(df.source.cast(&#34;int&#34;).alias(&#39;sources&#39;)).take(20)
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(sources=1), Row(sources=2),...]
</code></pre><ul>
<li>desc()</li>
</ul>
<p>根据给定列的名字的倒序返回排序后的表达式。</p>
<ul>
<li>getField(name)</li>
</ul>
<p>在StructField中按名称获取字段的表达式。</p>
<pre tabindex="0"><code>from pyspark.sql import Row
df = sc.parallelize([Row(r=Row(a=1, b=&#34;b&#34;))]).toDF()
df.select(df.r.getField(&#34;b&#34;)).show()
</code></pre><pre tabindex="0"><code>+---+
|r.b|
+---+
|  b|
+---+
</code></pre><pre tabindex="0"><code>df.select(df.r.a).show()
</code></pre><pre tabindex="0"><code>+---+
|r.a|
+---+
|  1|
+---+
</code></pre><ul>
<li>isNotNull()</li>
</ul>
<p>如果当前的表达式不为 null 则为真。</p>
<ul>
<li>isNull()</li>
</ul>
<p>如果当前的表达式为 null 则为真。</p>
<ul>
<li>isin(*cols)</li>
</ul>
<p>如果这个表达式的值被包含在参数的计算值之中,则该表达式为真。</p>
<pre tabindex="0"><code>df[df.network_type.isin(&#34;Wifi&#34;, &#34;4g&#34;)].select(&#39;app_key&#39;, &#39;network_type&#39;).take(2)
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>[Row(app_key=u&#39;2323423dsfds&#39;, network_type=u&#39;wifi&#39;), Row(app_key=u&#39;2323423dsfds&#39;, network_type=u&#39;4g&#39;)]
</code></pre><ul>
<li>
<p>name() 是 alias() 的别名</p>
</li>
<li>
<p>otherwise(value)</p>
</li>
</ul>
<p>计算一组条件，并返回多个可能的结果表达式之一。如果未调用 <code>Column.otherwise()</code>，则为不匹配的条件返回 None。</p>
<p>有关使用示例，请参阅 pyspark.sql.functions.when()。</p>
<p>参数：<strong>value</strong>  - 字面值或 <strong>Column</strong> 表达式。</p>
<pre tabindex="0"><code>from pyspark.sql import functions as F
df.select(df.duration, F.when(df.page_count &gt; 10, 1).otherwise(0)).show()
</code></pre><p><strong>输出</strong>:</p>
<pre tabindex="0"><code>+--------+---------------------------------------------+
|duration|CASE WHEN (page_count &gt; 10) THEN 1 ELSE 0 END|
+--------+---------------------------------------------+
|   80725|                                            0|
|      24|                                            0|
|      21|                                            0|
|      21|                                            1|
|      66|                                            1|
|      17|                                            0|
|      31|                                            0|
|       1|                                            0|
|      80|                                            1|
|       3|                                            0|
|      11|                                            1|
|       6|                                            0|
|      23|                                            1|
|       4|                                            0|
|       2|                                            0|
|      23|                                            0|
|      60|                                            1|
|      16|                                            0|
|       4|                                            0|
|       4|                                            0|
+--------+---------------------------------------------+
</code></pre><ul>
<li>
<p>from_unixtime</p>
<p>将 unix 格式的时间戳转换为指定格式的日期</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">from_unixtime</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="s1">&#39;1486461323&#39;</span><span class="p">,)],</span> <span class="p">[</span><span class="s1">&#39;start_time&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="n">from_unixtime</span><span class="p">(</span> <span class="n">df</span><span class="o">.</span><span class="n">start_time</span> <span class="p">,</span> <span class="s1">&#39;yyyy-MM-dd&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>上面的代码中的<code>createDataFrame</code> 方法创建了一个只有一列的数据框, <code>withColumn</code> 方法为该数据框添加了一个新的名为 <strong>day</strong> 的列, <code>from_unixtime</code> 方法将该数据框中原来的 <em>start_time</em> 列转换为指定格式的日期。<code>show()</code> 方法打印输出。</p>
</li>
<li>
<p>pyspark.sql.functions.col(col)</p>
<p><code>col</code> 方法接收一个字符串列名作为参数, 根据指定的列名返回一个 <strong>Column</strong>. 作用和 <code>df.columnName</code> 相同。</p>
</li>
<li>
<p>pyspark.sql.functions.when(condition, value)</p>
<p>计算一组条件并返回多个可能结果的表达式的其中之一。如果 <strong>Column.otherwise</strong> 没有被调用, 那么对未匹配的条件会返回 <code>None</code>。</p>
<p><strong>参数:</strong></p>
<ul>
<li><strong>condition</strong> - 一个布尔 <strong>Column</strong> 表达式。</li>
<li><strong>value</strong> - 一个字面值, 或者一个 <strong>Column</strong> 表达式。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span> <span class="n">when</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&#34;age&#34;</span><span class="p">)</span> <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># [Row(age=3), Row(age=4)]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span> <span class="n">when</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span><span class="o">==</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">age</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&#34;age&#34;</span><span class="p">)</span> <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># [Row(age=3), Row(age=None)]-pyspark.sql.Column.when</span>
</span></span></code></pre></div></li>
<li>
<p>pyspark.sql.Column.when(condition, value)</p>
<p>计算一组条件并返回多个可能结果的表达式的其中之一。如果 <strong>Column.otherwise</strong> 没有被调用, 那么对未匹配的条件会返回 <code>None</code>。当 when 中有多个条件时,要用 <code>&amp;</code> 或 <code>|</code> 连接起来。<a href="http://stackoverflow.com/questions/37707305/pyspark-multiple-conditions-in-when-clause">Pyspark: multiple conditions in when clause</a></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>从 df 数据框中选择出 <em>name</em> 和 <em>age</em> 这两列。如果 <code>age&gt;4</code> 则把 age 置为 1; 如果 <code>age&lt;3</code> 就把 age 置为 -1, 否则置为 0。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="o">+</span><span class="c1">-----+------------------------------------------------------------+
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="o">|</span><span class="w"> </span><span class="n">name</span><span class="o">|</span><span class="k">CASE</span><span class="w"> </span><span class="k">WHEN</span><span class="w"> </span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">WHEN</span><span class="w"> </span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="w"> </span><span class="k">ELSE</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">END</span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">+</span><span class="c1">-----+------------------------------------------------------------+
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="o">|</span><span class="n">Alice</span><span class="o">|</span><span class="w">                                                          </span><span class="o">-</span><span class="mi">1</span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="n">Bob</span><span class="o">|</span><span class="w">                                                           </span><span class="mi">1</span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">+</span><span class="c1">-----+------------------------------------------------------------+
</span></span></span></code></pre></div><ul>
<li>
<p>left_outer join</p>
<p>左连接之后如果有重复的列, 则使用 <code>drop</code> 删除不了重复的列。需要用 <code>select</code>。　</p>
</li>
<li>
<p>udf 方法</p>
<p>定义一个 <code>udf</code> 方法, 用来返回今天的日期(yyyy-MM-dd):</p>
</li>
</ul>
<pre tabindex="0"><code>from pyspark.sql.functions import udf
from pyspark.sql.types import StringType
import datetime

# 定义一个 udf 函数 
def today(day):
    if day==None:
        return datetime.datetime.fromtimestamp(int(time.time())).strftime(&#39;%Y-%m-%d&#39;)
    else:
        return day

# 返回类型为字符串类型
udfday = udf(today, StringType())
# 使用
df.withColumn(&#39;day&#39;, udfday(df.day))
          
</code></pre><ul>
<li>
<p>drop</p>
<p>有时候使用 drop 来删除某一列时, 会出现错误, 而用 select 就可以。</p>
</li>
</ul>
<h1 id="将-map-转换为-select">将 map 转换为 select</h1>
<p>之前一直使用 map 方法来做转换, 添加新的列:</p>
<pre tabindex="0"><code> # 今天的新访问用户数, 访问人数, 访问次数
 _time_slot_df = spark.createDataFrame(slot_session_df.rdd.map(map_sessions)) \
                      .groupBy(&#39;app_key&#39;, &#39;day&#39;) \
                      .agg(
                           sum(&#39;is_first_open&#39;).alias(&#39;today_new_user_count&#39;), # 新访问用户数
                           countDistinct(&#39;uuid&#39;).alias(&#39;today_user_count&#39;),    # 访问人数
                           sum(&#39;page_count&#39;).alias(&#39;today_visits_count&#39;),      # 访问次数
                       )
                         
# 对 session_logs 日志做 map 操作, 生成需要的字段    
def map_sessions(row):
    if row[&#39;is_first_open&#39;]:
        is_first_open = 1
    else:
        is_first_open = 0
        
    return Row(
        app_key       = row[&#39;app_key&#39;],
        uuid          = row[&#39;uuid&#39;],       # 访问人数
        is_first_open = is_first_open,     # 新访问用户数
        page_count    = row[&#39;page_count&#39;], # 访问次数
        day        = datetime.datetime.fromtimestamp(int(row[&#39;start_time&#39;])).strftime(&#39;%Y-%m-%d&#39;)
    )  
</code></pre><p>现在我们有 select, withColumn, when 来做:</p>
<pre tabindex="0"><code>        _result_active_df = aladdin_id_df.join(_result_df, _result_df.app_key==aladdin_id_df.app_key, &#39;left_outer&#39;) \
                                         .drop(&#34;_result_df.app_key&#34;,&#34;_result_df.uid&#34;)
</code></pre><p>先用 <code>select</code> 方法从数据框中选择出已经存在的列(s)，这就是临时的新的数据框, 再用 <code>withColumn</code> 向该临时数据框中添加新的列。对于需要进行转换的列, 可以使用 <code>when</code> 方法来做运算。</p>
<pre tabindex="0"><code></code></pre><p>　<a href="http://stackoverflow.com/questions/40099706/splitting-a-row-in-a-pyspark-dataframe-into-multiple-rows">Splitting a row in a PySpark Dataframe into multiple rows</a></p>
<ul>
<li>pyspark.functions.sql.explode</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Create dummy data</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;a b c&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                     <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;d e f&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                     <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">&#39;g h i&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">,</span> <span class="s1">&#39;col3&#39;</span><span class="p">,</span><span class="s1">&#39;col4&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Explode column</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">split</span><span class="p">,</span> <span class="n">explode</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;col4&#39;</span><span class="p">,</span><span class="n">explode</span><span class="p">(</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;col4&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">)))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="o">+----+----+----+----+</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span><span class="n">col1</span><span class="o">|</span><span class="n">col2</span><span class="o">|</span><span class="n">col3</span><span class="o">|</span><span class="n">col4</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">+----+----+----+----+</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">1</span><span class="o">|</span>   <span class="mi">2</span><span class="o">|</span>   <span class="mi">3</span><span class="o">|</span>   <span class="n">a</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">1</span><span class="o">|</span>   <span class="mi">2</span><span class="o">|</span>   <span class="mi">3</span><span class="o">|</span>   <span class="n">b</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">1</span><span class="o">|</span>   <span class="mi">2</span><span class="o">|</span>   <span class="mi">3</span><span class="o">|</span>   <span class="n">c</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">4</span><span class="o">|</span>   <span class="mi">5</span><span class="o">|</span>   <span class="mi">6</span><span class="o">|</span>   <span class="n">d</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">4</span><span class="o">|</span>   <span class="mi">5</span><span class="o">|</span>   <span class="mi">6</span><span class="o">|</span>   <span class="n">e</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">4</span><span class="o">|</span>   <span class="mi">5</span><span class="o">|</span>   <span class="mi">6</span><span class="o">|</span>   <span class="n">f</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">7</span><span class="o">|</span>   <span class="mi">8</span><span class="o">|</span>   <span class="mi">9</span><span class="o">|</span>   <span class="n">g</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">7</span><span class="o">|</span>   <span class="mi">8</span><span class="o">|</span>   <span class="mi">9</span><span class="o">|</span>   <span class="n">h</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">|</span>   <span class="mi">7</span><span class="o">|</span>   <span class="mi">8</span><span class="o">|</span>   <span class="mi">9</span><span class="o">|</span>   <span class="n">i</span><span class="o">|</span>
</span></span><span class="line"><span class="cl"><span class="o">+----+----+----+----+</span>
</span></span></code></pre></div><p>这样就不用使用 <code>flatMap</code> 函数了, 它代替了 map 函数:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 每个电话号码一行     </span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">map_phones</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">phone</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;phones&#39;</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">        <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Row</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">app_key</span>     <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;app_key&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">phones</span>      <span class="o">=</span> <span class="n">phone</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">sms_content</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;sms_content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">r</span>
</span></span></code></pre></div><h2 id="一个-empty-引发的异常">一个 empty 引发的异常&nbsp;<a class="headline-hash no-text-decoration" href="#一个-empty-引发的异常">#</a> </h2>
<p>在脚本中加入这么一句:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">yesterday_session_df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">isEmpty</span><span class="p">:</span> <span class="k">return</span>
</span></span></code></pre></div><p>上面的 <code>isEmpty</code> 方法没有带圆括号,但是执行没有报错,但是这个语句后面的语句好像都没有执行。</p>
<h2 id="本机测试">本机测试&nbsp;<a class="headline-hash no-text-decoration" href="#本机测试">#</a> </h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;/Users/ohmyfish/mdl0731&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">page_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">./</span><span class="nb">bin</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="n">master</span> <span class="n">local</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">~/</span><span class="n">data_check</span><span class="o">.</span><span class="n">py</span> <span class="mi">0</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">def</span> <span class="n">calc_convert_rate</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="n">one_day</span><span class="o">)</span><span class="k">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">json_df</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&#34;hdfs://10.0.0.55:9000/ald_log_etl/&#34;</span> <span class="o">+</span> <span class="n">str</span><span class="o">(</span><span class="n">the_day</span><span class="o">))</span>
</span></span></code></pre></div>

        </div>
    </div>
</article>



                <footer>
                    




<div class="no-text-decoration">
    <div class="jump top"><a href="#" title="Top of this page">⮉</a></div>
    <div class="jump bottom"><a href="#bottom" title="Bottom of this page">⮋</a></div>
</div>


 
    
        <div class="hugotoc no-text-decoration">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#查看端口号被哪个进程占用">查看端口号被哪个进程占用</a></li>
  </ul>

  <ul>
    <li><a href="#一个-empty-引发的异常">一个 empty 引发的异常</a></li>
    <li><a href="#本机测试">本机测试</a></li>
  </ul>
</nav>
            <a href="#" class="back-to-top">Back to top</a>
        </div>
    
    
<script src="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js"></script>

<link rel="preload" href="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js" as="script">

<script type="application/javascript">(function() {
     var $window = $(window);
     if ($window.width() >= 1400) { 
         var $toc = $('#TableOfContents');
         if ($toc.length > 0) {
             function onScroll(){
                 var currentScroll = $window.scrollTop();
                 var h = $('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .h-feed h2');
                 var id = "";
                 h.each(function (i, e) {
                     e = $(e);
                     if (e.offset().top - 10 <= currentScroll) {
                         id = e.attr('id');
                     }
                 });
                 var current = $toc.find('a.current');
                 if (current.length == 1 && current.eq(0).attr('href') == '#' + id) return true;

                 current.each(function (i, e) {
                     $(e).removeClass('current').siblings('ul').hide();
                 });
                 $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                     $(e).children('a').addClass('current').siblings('ul').show();
                 });
             }
             $window.on('scroll', onScroll);
             $(document).ready(function() {
                 $toc.find('a').parent('li').find('ul').hide();
                 onScroll();
                 document.getElementsByClassName('hugotoc')[0].style.display = '';
             });}}})();</script>








<div class="backtotop center no-text-decoration">
    <a href="#">back to <span class="top">top</span></a>
</div>


<div class="right">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>
<div class="clear-float"></div>



<div class="prev-next-navigator clear-float">
    
        <span class="prev-post left no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0-kafka-%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/" class="nobr">« 搭建本地 Kafka 测试环境</a>
        </span>
    
    
        <span class="next-post right no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/%E5%9C%A8-idea-%E4%B8%AD%E9%85%8D%E7%BD%AE-pyspark/" class="nobr">在 IDEA 中配置 Pyspark »</a>
        </span>
    
</div>


<a id="bottom"></a>









                       







                    <ul class="no-bullets feed right inline">
    
        
        
    
</ul>
<div class="clear-float"></div>

                </footer>
                <hr />
            </div>               

            <footer> 
                

<ul class="social no-text-decoration">
    
</ul>










 
    
    



<p class="generated no-text-decoration">
    Generated using  <a href="https://gitlab.com/kaushalmodi/hugo-theme-refined"><code class="nobr">hugo-theme-refined</code></a> + <span class="nobr">Hugo <a href="https://github.com/gohugoio/hugo/commit/312735366b20d64bd61bff8627f593749f86c964">0.123.7</a></span>
</p>

<p>
    
</p>




<div class="badges no-text-decoration">
    
    

    
</div>




<script type="application/javascript">var nav=responsiveNav("#nav");</script>




<script defer src="/js/libs/fragmentions/wrapper.min.e8c468c89edc4f5dccaa8c720c6b220b3088a16cd7b1e4a1e3345985788260c9.js"></script>









            </footer>
        </div> 
    </body>
</html>
