{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io/"},"content":{"html":"\u003ch1 id=\"反向代理的配置\"\u003e反向代理的配置\u003c/h1\u003e\n\u003cp\u003e在服务器中做如下配置:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eserver {                                                       \n  listen 80;                                                   \n  server_name test.aldwx.com;                                  \n  location /app.launch.php {                                   \n    proxy_pass http://127.0.0.1:3000;                          \n  }                                                            \n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e然后在服务器中的终端中输入\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eplackup -E deployment -s Starman --workers=1 -p 3000 -a app.pl\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e或者:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enohup plackup -E deployment -s Starman --workers=10 -p 3000 -a app.pl \u0026amp;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eapp.pl\u003c/code\u003e 是用 dancer 写的一个 demo 程序, 其中的内容如下:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-perl\" data-lang=\"perl\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"ch\"\u003e#!/usr/bin/perl\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003euse\u003c/span\u003e \u003cspan class=\"nn\"\u003eDigest::MD5\u003c/span\u003e \u003cspan class=\"sx\"\u003eqw(md5_hex)\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003euse\u003c/span\u003e \u003cspan class=\"nn\"\u003eDancer\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003euse\u003c/span\u003e \u003cspan class=\"nn\"\u003eJSON\u003c/span\u003e \u003cspan class=\"sx\"\u003eqw(encode_json)\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# return the json format data\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e  \u003cspan class=\"s\"\u003e\u0026#34;/app.launch.info.php\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"k\"\u003esub\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003emy\u003c/span\u003e \u003cspan class=\"nv\"\u003e$data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"sb\"\u003e`date`\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003emy\u003c/span\u003e \u003cspan class=\"nv\"\u003e$token\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emd5_hex\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nv\"\u003e$data\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e   \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003emy\u003c/span\u003e  \u003cspan class=\"nv\"\u003e$r\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s\"\u003e\u0026#39;error\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s\"\u003e\u0026#39;data\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"s\"\u003e\u0026#39;access_token\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"nv\"\u003e$token\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eencode_json\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nv\"\u003e$r\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e  \u003cspan class=\"s\"\u003e\u0026#39;/hello\u0026#39;\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"k\"\u003esub\u003c/span\u003e  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Hello 小程序\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e  \u003cspan class=\"s\"\u003e\u0026#39;/l.html\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"k\"\u003esub\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Hello, World\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edance\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e然后在浏览其中输入:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etest.aldwx.com/app.launch.info.php\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e你会看到浏览器返给你返回一段 \u003ccode\u003ejson\u003c/code\u003e 数据。\u003c/p\u003e\n\u003ch2 id=\"查看端口号被哪个进程占用\"\u003e查看端口号被哪个进程占用\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enetstat -tulnp | grep \u0026#39;:80 \u0026#39;\ntcp        0      0 0.0.0.0:80                  0.0.0.0:*                   LISTEN      4021/nginx.conf \n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"nginx-error-open-alidataservernginxlogsnginxpid-failed-2-no-such-file-or-directory-错误\"\u003enginx: [error] open() \u0026ldquo;/alidata/server/nginx/logs/nginx.pid\u0026rdquo; failed (2: No such file or directory) 错误\u003c/h1\u003e\n\u003cp\u003e在使用的阿里云服务器上，进程性的 nginx -s stop后再次启动nginx -s reload ,总是会报错误nginx: [error] open() \u0026ldquo;/alidata/server/nginx/logs/nginx.pid\u0026rdquo; failed (2: No such file or directory)，这应该是因为把nginx进程杀死后pid丢失了，下一次再开启nginx -s reload时无法启动\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enginx -c /path/to/config/nginx.conf\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"查看被占用的端口号\"\u003e查看被占用的端口号\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003elsof -i | grep \u0026#34;:7077\u0026#34;\njava       8927     root  230u  IPv6   100990      0t0  TCP 106.2.1.77:7077 (LISTEN)\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"php-环境搭建\"\u003ephp 环境搭建\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003esudo apt-get update\nsudo apt-get install lib apache2-mod-php5 ...\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"conf-文件的配置\"\u003e.conf 文件的配置\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003e.conf\u003c/code\u003e 文件一版放在 \u003ccode\u003esites-available\u003c/code\u003e 目录中, 用的时候再软链接到 \u003ccode\u003esites-enabled\u003c/code\u003e 中。\u003c/p\u003e\n\u003ch1 id=\"免密码登录服务器\"\u003e免密码登录服务器\u003c/h1\u003e\n\u003cp\u003e在服务器上的 \u003ccode\u003e./ssh\u003c/code\u003e 目录中添加 \u003ccode\u003essh key\u003c/code\u003e, 比如我更换了新电脑:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003evim ~/.ssh/authorized_keys\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e删除掉旧的 ssh keys, 加入新生成的:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003essh-rsa AAACCQEEEEddfdfdffrrt3334QWAUUY1223xxxXXXXXXX wodefan@Mac-mini.local\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"从本地上传下载文件文件夹到服务器\"\u003e从本地上传/下载文件/文件夹到服务器\u003c/h1\u003e\n\u003cp\u003e上传和下载都是在本地打开命令行终端。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上传\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escp ./app.py root@108.2.5.98:/daly/apk/myapp/ # 从本地上传单个文件到服务器\nscp -r myjobs root@108.2.5.98:/daly/apk/      # 从本地上传整个文件夹到服务器\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e下载\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escp root@108.2.5.98:/daly/apk/myapp/today.txt . # 从服务器下载指定文件到本地目录\nscp -r root@108.2.5.98:/daly/apk/apk/ .         # 从服务器下载整个文件夹到本地 \n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"在-pyspark-中连接数据库\"\u003e在 pyspark 中连接数据库\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e启动 pyspark 时附加上相应的 mysql jar 包:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/data/app/spark/bin/pyspark --driver-class-path mysql-connector-java-5.1.40-bin.jar --jars mysql-connector-java-5.1.40-bin.jar\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e使用用户名和密码连接 mysql, 并创建一个数据框:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf = spark.read.format(\u0026#34;jdbc\u0026#34;).option(\u0026#34;url\u0026#34;, \u0026#34;jdbc:mysql://8.8.8.8/ald_xinen\u0026#34;).option(\u0026#34;dbtable\u0026#34;, \u0026#34;(select * from ald_session_logs) as df\u0026#34;).option(\u0026#39;user\u0026#39;, \u0026#34;root\u0026#34;).option(\u0026#39;password\u0026#39;, \u0026#34;fish@sky\u0026#34;).load()\ndf.take(2) # 取出前两行\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e如果已经启动了一个连接 mysql 数据库的 pyspark, 再重新启动一个时会报错, 这个时候就要把之前的启动的杀掉:\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eps aux | grep \u0026#39;spark\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e然后找到 \u003ccode\u003epyspark-shell\u003c/code\u003e 的 进程 id, \u003ccode\u003ekill -9 xxxx\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etoDF(*cols) 返回一新的数据框, 指定新的列名。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.select(\u0026#34;app_key\u0026#34;, \u0026#34;uuid\u0026#34;).toDF(\u0026#34;f1\u0026#34;, \u0026#39;f2\u0026#39;).take(2) \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(f1=u\u0026#39;2323423dsfds\u0026#39;, f2=u\u0026#39;14797409227806341000\u0026#39;), Row(f1=u\u0026#39;2323423dsfds\u0026#39;, f2=u\u0026#39;14797409227806341000\u0026#39;)]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003etoJSON() 将数据框转换为字符串 RDD。每一行都被转换为 JSON 文档, 作为所返回的 RDD 中的一个元素。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.select(\u0026#34;app_key\u0026#34;, \u0026#34;uuid\u0026#34;).toJSON().first()        \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eu\u0026#39;{\u0026#34;app_key\u0026#34;:\u0026#34;2323423dsfds\u0026#34;,\u0026#34;uuid\u0026#34;:\u0026#34;14797409227806341000\u0026#34;}\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003etoLocalIterator()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e返回一个包含该数据框所有行的迭代器。这个迭代器会在该数据框的最大分区中消耗尽可能多的内存。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003elist(df.toLocalIterator())\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003ewithColumn(colName, col)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e通过为原数据框\u003cstrong\u003e添加一个新列\u003c/strong\u003e或\u003cstrong\u003e替换已存在的同名列\u003c/strong\u003e而返回一个新数据框。\u003ccode\u003ecolName\u003c/code\u003e 是一个字符串, 为新列的名字。\n\u003ccode\u003ecol\u003c/code\u003e 为这个新列的 \u003cstrong\u003eColumn\u003c/strong\u003e 表达式。\u003ccode\u003ewithColumn\u003c/code\u003e 的第一个参数必须是已存在的列的名字,　\u003ccode\u003ewithColumn\u003c/code\u003e 的第二个参数必须是含有列的表达式。如果不是它会报错 \u003ccode\u003eAssertionError: col should be Column\u003c/code\u003e。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.withColumn(\u0026#39;page_count\u0026#39;, df.page_count+100).select(\u0026#34;app_key\u0026#34;,\u0026#34;page_count\u0026#34;).take(2)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, page_count=110), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, page_count=104)]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003ecol\u003c/code\u003e 表达式可以使用多个其他列:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.withColumn(\u0026#39;avg\u0026#39;, df.page_count/df.duration).select(\u0026#34;app_key\u0026#34;,\u0026#34;avg\u0026#34;).take(2)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, avg=0.00012387736141220192), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, avg=0.16666666666666666)]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003ewithColumn\u003c/code\u003e 可以添加一个常数列,   但是要使用 \u003ccode\u003epyspark.sql.functions\u003c/code\u003e 中的函数, 例如: \u003ccode\u003eunix_timestamp\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e可以参考\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://stackoverflow.com/questions/33681487/how-do-i-add-a-new-column-to-a-spark-dataframe-using-pyspark\"\u003eHow do I add a new column to a Spark DataFrame (using PySpark)?\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://stackoverflow.com/questions/32788322/how-to-add-a-constant-column-in-a-spark-dataframe\"\u003eHow to add a constant column in a Spark DataFrame?\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ewithColumnRenamed(existing, new)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e重命名已存在的列并返回一个新数据框。\u003ccode\u003eexisting\u003c/code\u003e 为已存在的要重命名的列, \u003ccode\u003ecol\u003c/code\u003e 为新列的名字。\u003c/p\u003e\n\u003cp\u003e将 \u003cem\u003eduration\u003c/em\u003e 列重命名为 \u003cem\u003etime_take\u003c/em\u003e 列:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.withColumnRenamed(\u0026#39;duration\u0026#39;, \u0026#39;time_take\u0026#39;).select(\u0026#39;app_key\u0026#39;, \u0026#39;time_take\u0026#39;).take(2)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, time_take=80725), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, time_take=24)]\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"groupby-之后可以使用的方法\"\u003egroupBy 之后可以使用的方法\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eagg(*exprs)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e聚合计算并将结果返回为 \u003cstrong\u003eDataFrame\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e可用的聚合函数有 \u003cem\u003eavg\u003c/em\u003e, \u003cem\u003emax\u003c/em\u003e, \u003cem\u003emin\u003c/em\u003e, \u003cem\u003esum\u003c/em\u003e, \u0026lsquo;count\u0026rsquo;.\u003c/p\u003e\n\u003cp\u003e如果 \u003ccode\u003eexpr\u003c/code\u003e 是从字符串到字符串的单个 \u003cstrong\u003edict\u003c/strong\u003e 映射, 那么其键就是要执行聚合的列, 其值就是该聚合函数。\u003c/p\u003e\n\u003cp\u003e可选地, \u003ccode\u003eexpr\u003c/code\u003e 还可以是一组聚合\u003cstrong\u003e列\u003c/strong\u003e 表达式。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e参数\u003c/strong\u003e: \u003cstrong\u003eexprs\u003c/strong\u003e - 一个从列名(字符串)到聚合函数(字符串)的字典映射, 或者是一个 \u003cstrong\u003eColumn\u003c/strong\u003e 列表。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003egdf = df.groupBy(df.app_key)\ngdf.agg({\u0026#34;*\u0026#34; : \u0026#39;count\u0026#39; } ).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, count(1)=4), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, count(1)=12), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, count(1)=3), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count(1)=66), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count(1)=490), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, count(1)=17), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, count(1)=5)]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e对 app_key 排序下:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003esorted(gdf.agg({\u0026#34;*\u0026#34;: \u0026#34;count\u0026#34;}).collect())\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count(1)=490), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count(1)=66), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, count(1)=3), Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, count(1)=4), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, count(1)=12), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, count(1)=5), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, count(1)=17)]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom pyspark.sql import functions as F\nsorted(gdf.agg(F.max(df.duration)).collect())\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, max(duration)=28498), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, max(duration)=80725), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, max(duration)=352), Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, max(duration)=33), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, max(duration)=168), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, max(duration)=23), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, max(duration)=87), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, max(duration)=7789)]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003eavg(*cols)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为每一组的每个数值列计算平均值。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003emean\u003c/code\u003e 是 \u003ccode\u003eavg\u003c/code\u003e 的别名。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e参数: cols\u003c/strong\u003e - 一组列的名字(字符串)。非数值列被忽略。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.groupBy(\u0026#39;app_key\u0026#39;).avg(\u0026#39;duration\u0026#39;).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, avg(duration)=150.0),Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, avg(duration)=153.81428571428572) ...]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.groupBy(\u0026#39;app_key\u0026#39;).avg(\u0026#39;duration\u0026#39;, \u0026#39;page_count\u0026#39;).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, avg(duration)=150.0, avg(page_count)=12.0), avg(page_count)=5.681818181818182), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, avg(duration)=153.81428571428572, avg(page_count)=8.059183673469388) ...]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003ecount()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e计算每组的记录数。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003esorted(df.groupBy(df.app_key).count().collect())\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count=490), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count=66) ...]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003emax(*cols)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e计算每组每个数值列的最大值。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.groupBy(\u0026#39;app_key\u0026#39;).max(\u0026#39;duration\u0026#39;).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150) ...]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.groupBy(\u0026#39;app_key\u0026#39;).max(\u0026#39;duration\u0026#39;, \u0026#39;page_count\u0026#39;).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150, max(page_count)=12)...]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003emean() 求平均数, 同 avg\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003emin() 参考 max\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003epivot(pivot_col, values=None)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e透视当前[[DataFrame]]的列并执行指定的聚合。有两个版本的pivot函数：一个需要调用者指定不同值的列表以便进行透视，而另一个不指定。后者更简洁但效率较低，因为Spark需要首先在内部计算不同值的列表。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e参数\u003c/strong\u003e: \u003cstrong\u003epivot_col\u003c/strong\u003e - 要透视的列名; \u003cstrong\u003evalues\u003c/strong\u003e - 将转换为输出 DataFrame 中的列的值列表。\u003c/p\u003e\n\u003cp\u003e计算每个 app 下，每个渠道的总停留时长, 每个渠道的结果占一列:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.groupBy(\u0026#39;app_key\u0026#39;).pivot(\u0026#34;source\u0026#34;, [\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34; ]).sum(\u0026#34;duration\u0026#34;).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, 1=None, 2=None, 3=None, 4=150), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, 1=7208, 2=54929, 3=7078, 4=6139), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, 1=None, 2=94, 3=29, 4=87) ...]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e官方的例子:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# Compute the sum of earnings for each year by course with each course as a separate column\ndf4.groupBy(\u0026#34;year\u0026#34;).pivot(\u0026#34;course\u0026#34;, [\u0026#34;dotNET\u0026#34;, \u0026#34;Java\u0026#34;]).sum(\u0026#34;earnings\u0026#34;).collect()\n[Row(year=2012, dotNET=15000, Java=20000), Row(year=2013, dotNET=48000, Java=30000)]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e或者不指定列的值（不够有效率）\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf4.groupBy(\u0026#34;year\u0026#34;).pivot(\u0026#34;course\u0026#34;).sum(\u0026#34;earnings\u0026#34;).collect()\n[Row(year=2012, Java=20000, dotNET=15000), Row(year=2013, Java=30000, dotNET=48000)]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003esum(*cols)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为每组计算每个数值列的总和。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e参数\u003c/strong\u003e: cols - 一组列的名字（字符串）。非数值列被忽略。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# 官方例子：\ndf.groupBy().sum(\u0026#39;age\u0026#39;).collect()\n# [Row(sum(age)=7)]\ndf3.groupBy().sum(\u0026#39;age\u0026#39;, \u0026#39;height\u0026#39;).collect()\n# [Row(sum(age)=7, sum(height)=165)]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003eclass pyspark.sql.Column(jc)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e数据框中的一列。 \u003cstrong\u003eColumn\u003c/strong\u003e 实例可以通过如下的代码创建：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e#1. 选择数据框中的一列\ndf.colName\ndf[\u0026#34;colName\u0026#34;]\n\n#2. 从表达式创建\ndf.colName + 1\n1 / df.colName \n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003ealias(*alias)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e返回这个列的新的别名或别名们(在表达式返回多列的情况下, 例如爆炸)。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.select(df.duration.alias(\u0026#34;time_take\u0026#34;)).collect()\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003easc()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e返回一个排序过的表达式, 基于给定列的名字的升序进行排列。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eastype() 是 cast() 的别名。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ebetween(lowerBound, upperBound)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果这个表达式的值在给定的列的值之间，则计算结果为布尔真。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.select(df.app_key, df.duration.between(60,80)).show(50)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eshow()函数输出前 20 行:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e+--------------------+---------------------------------------+\n|             app_key|((duration \u0026gt;= 60) AND (duration \u0026lt;= 80))|\n+--------------------+---------------------------------------+\n|        2323423dsfds|                                  false|\n|        2323423dsfds|                                  false|\n|        2323423dsfds|                                  false|\n|        2323423dsfds|                                  false|\n|        2323423dsfds|                                   true|\n...\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003ecast(dataType)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e将列转换为 \u003ccode\u003edataType\u003c/code\u003e 类型。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# 官方例子:\ndf.select(df.age.cast(\u0026#34;string\u0026#34;).alias(\u0026#39;ages\u0026#39;)).collect()\n# [Row(ages=u\u0026#39;2\u0026#39;), Row(ages=u\u0026#39;5\u0026#39;)]\ndf.select(df.age.cast(StringType()).alias(\u0026#39;ages\u0026#39;)).collect()\n# [Row(ages=u\u0026#39;2\u0026#39;), Row(ages=u\u0026#39;5\u0026#39;)]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# 将字符串转为 int 型\ndf.select(df.source.cast(\u0026#34;int\u0026#34;).alias(\u0026#39;sources\u0026#39;)).take(20)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(sources=1), Row(sources=2),...]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003edesc()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e根据给定列的名字的倒序返回排序后的表达式。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003egetField(name)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在StructField中按名称获取字段的表达式。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom pyspark.sql import Row\ndf = sc.parallelize([Row(r=Row(a=1, b=\u0026#34;b\u0026#34;))]).toDF()\ndf.select(df.r.getField(\u0026#34;b\u0026#34;)).show()\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e+---+\n|r.b|\n+---+\n|  b|\n+---+\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf.select(df.r.a).show()\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e+---+\n|r.a|\n+---+\n|  1|\n+---+\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003eisNotNull()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果当前的表达式不为 null 则为真。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eisNull()\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果当前的表达式为 null 则为真。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eisin(*cols)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果这个表达式的值被包含在参数的计算值之中,则该表达式为真。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edf[df.network_type.isin(\u0026#34;Wifi\u0026#34;, \u0026#34;4g\u0026#34;)].select(\u0026#39;app_key\u0026#39;, \u0026#39;network_type\u0026#39;).take(2)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, network_type=u\u0026#39;wifi\u0026#39;), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, network_type=u\u0026#39;4g\u0026#39;)]\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ename() 是 alias() 的别名\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eotherwise(value)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e计算一组条件，并返回多个可能的结果表达式之一。如果未调用 \u003ccode\u003eColumn.otherwise()\u003c/code\u003e，则为不匹配的条件返回 None。\u003c/p\u003e\n\u003cp\u003e有关使用示例，请参阅 pyspark.sql.functions.when()。\u003c/p\u003e\n\u003cp\u003e参数：\u003cstrong\u003evalue\u003c/strong\u003e  - 字面值或 \u003cstrong\u003eColumn\u003c/strong\u003e 表达式。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom pyspark.sql import functions as F\ndf.select(df.duration, F.when(df.page_count \u0026gt; 10, 1).otherwise(0)).show()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e+--------+---------------------------------------------+\n|duration|CASE WHEN (page_count \u0026gt; 10) THEN 1 ELSE 0 END|\n+--------+---------------------------------------------+\n|   80725|                                            0|\n|      24|                                            0|\n|      21|                                            0|\n|      21|                                            1|\n|      66|                                            1|\n|      17|                                            0|\n|      31|                                            0|\n|       1|                                            0|\n|      80|                                            1|\n|       3|                                            0|\n|      11|                                            1|\n|       6|                                            0|\n|      23|                                            1|\n|       4|                                            0|\n|       2|                                            0|\n|      23|                                            0|\n|      60|                                            1|\n|      16|                                            0|\n|       4|                                            0|\n|       4|                                            0|\n+--------+---------------------------------------------+\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003efrom_unixtime\u003c/p\u003e\n\u003cp\u003e将 unix 格式的时间戳转换为指定格式的日期\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark.sql.functions\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003efrom_unixtime\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreateDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e([(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;1486461323\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,)],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;start_time\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;day\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003efrom_unixtime\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estart_time\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;yyyy-MM-dd\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e上面的代码中的\u003ccode\u003ecreateDataFrame\u003c/code\u003e 方法创建了一个只有一列的数据框, \u003ccode\u003ewithColumn\u003c/code\u003e 方法为该数据框添加了一个新的名为 \u003cstrong\u003eday\u003c/strong\u003e 的列, \u003ccode\u003efrom_unixtime\u003c/code\u003e 方法将该数据框中原来的 \u003cem\u003estart_time\u003c/em\u003e 列转换为指定格式的日期。\u003ccode\u003eshow()\u003c/code\u003e 方法打印输出。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003epyspark.sql.functions.col(col)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ecol\u003c/code\u003e 方法接收一个字符串列名作为参数, 根据指定的列名返回一个 \u003cstrong\u003eColumn\u003c/strong\u003e. 作用和 \u003ccode\u003edf.columnName\u003c/code\u003e 相同。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003epyspark.sql.functions.when(condition, value)\u003c/p\u003e\n\u003cp\u003e计算一组条件并返回多个可能结果的表达式的其中之一。如果 \u003cstrong\u003eColumn.otherwise\u003c/strong\u003e 没有被调用, 那么对未匹配的条件会返回 \u003ccode\u003eNone\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e参数:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003econdition\u003c/strong\u003e - 一个布尔 \u003cstrong\u003eColumn\u003c/strong\u003e 表达式。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003evalue\u003c/strong\u003e - 一个字面值, 或者一个 \u003cstrong\u003eColumn\u003c/strong\u003e 表达式。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ewhen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;age\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eotherwise\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ealias\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;age\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecollect\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# [Row(age=3), Row(age=4)]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ewhen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ealias\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;age\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecollect\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# [Row(age=3), Row(age=None)]-pyspark.sql.Column.when\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003epyspark.sql.Column.when(condition, value)\u003c/p\u003e\n\u003cp\u003e计算一组条件并返回多个可能结果的表达式的其中之一。如果 \u003cstrong\u003eColumn.otherwise\u003c/strong\u003e 没有被调用, 那么对未匹配的条件会返回 \u003ccode\u003eNone\u003c/code\u003e。当 when 中有多个条件时,要用 \u003ccode\u003e\u0026amp;\u003c/code\u003e 或 \u003ccode\u003e|\u003c/code\u003e 连接起来。\u003ca href=\"http://stackoverflow.com/questions/37707305/pyspark-multiple-conditions-in-when-clause\"\u003ePyspark: multiple conditions in when clause\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark.sql\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003efunctions\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eF\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eF\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewhen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewhen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eotherwise\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e从 df 数据框中选择出 \u003cem\u003ename\u003c/em\u003e 和 \u003cem\u003eage\u003c/em\u003e 这两列。如果 \u003ccode\u003eage\u0026gt;4\u003c/code\u003e 则把 age 置为 1; 如果 \u003ccode\u003eage\u0026lt;3\u003c/code\u003e 就把 age 置为 -1, 否则置为 0。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"c1\"\u003e-----+------------------------------------------------------------+\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"k\"\u003eCASE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eWHEN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTHEN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eWHEN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTHEN\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eELSE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eEND\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"c1\"\u003e-----+------------------------------------------------------------+\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"n\"\u003eAlice\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e                                                          \u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"n\"\u003eBob\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e                                                           \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"c1\"\u003e-----+------------------------------------------------------------+\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eleft_outer join\u003c/p\u003e\n\u003cp\u003e左连接之后如果有重复的列, 则使用 \u003ccode\u003edrop\u003c/code\u003e 删除不了重复的列。需要用 \u003ccode\u003eselect\u003c/code\u003e。　\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eudf 方法\u003c/p\u003e\n\u003cp\u003e定义一个 \u003ccode\u003eudf\u003c/code\u003e 方法, 用来返回今天的日期(yyyy-MM-dd):\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\nimport datetime\n\n# 定义一个 udf 函数 \ndef today(day):\n    if day==None:\n        return datetime.datetime.fromtimestamp(int(time.time())).strftime(\u0026#39;%Y-%m-%d\u0026#39;)\n    else:\n        return day\n\n# 返回类型为字符串类型\nudfday = udf(today, StringType())\n# 使用\ndf.withColumn(\u0026#39;day\u0026#39;, udfday(df.day))\n          \n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003edrop\u003c/p\u003e\n\u003cp\u003e有时候使用 drop 来删除某一列时, 会出现错误, 而用 select 就可以。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"将-map-转换为-select\"\u003e将 map 转换为 select\u003c/h1\u003e\n\u003cp\u003e之前一直使用 map 方法来做转换, 添加新的列:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e # 今天的新访问用户数, 访问人数, 访问次数\n _time_slot_df = spark.createDataFrame(slot_session_df.rdd.map(map_sessions)) \\\n                      .groupBy(\u0026#39;app_key\u0026#39;, \u0026#39;day\u0026#39;) \\\n                      .agg(\n                           sum(\u0026#39;is_first_open\u0026#39;).alias(\u0026#39;today_new_user_count\u0026#39;), # 新访问用户数\n                           countDistinct(\u0026#39;uuid\u0026#39;).alias(\u0026#39;today_user_count\u0026#39;),    # 访问人数\n                           sum(\u0026#39;page_count\u0026#39;).alias(\u0026#39;today_visits_count\u0026#39;),      # 访问次数\n                       )\n                         \n# 对 session_logs 日志做 map 操作, 生成需要的字段    \ndef map_sessions(row):\n    if row[\u0026#39;is_first_open\u0026#39;]:\n        is_first_open = 1\n    else:\n        is_first_open = 0\n        \n    return Row(\n        app_key       = row[\u0026#39;app_key\u0026#39;],\n        uuid          = row[\u0026#39;uuid\u0026#39;],       # 访问人数\n        is_first_open = is_first_open,     # 新访问用户数\n        page_count    = row[\u0026#39;page_count\u0026#39;], # 访问次数\n        day        = datetime.datetime.fromtimestamp(int(row[\u0026#39;start_time\u0026#39;])).strftime(\u0026#39;%Y-%m-%d\u0026#39;)\n    )  \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e现在我们有 select, withColumn, when 来做:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e        _result_active_df = aladdin_id_df.join(_result_df, _result_df.app_key==aladdin_id_df.app_key, \u0026#39;left_outer\u0026#39;) \\\n                                         .drop(\u0026#34;_result_df.app_key\u0026#34;,\u0026#34;_result_df.uid\u0026#34;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e先用 \u003ccode\u003eselect\u003c/code\u003e 方法从数据框中选择出已经存在的列(s)，这就是临时的新的数据框, 再用 \u003ccode\u003ewithColumn\u003c/code\u003e 向该临时数据框中添加新的列。对于需要进行转换的列, 可以使用 \u003ccode\u003ewhen\u003c/code\u003e 方法来做运算。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e　\u003ca href=\"http://stackoverflow.com/questions/40099706/splitting-a-row-in-a-pyspark-dataframe-into-multiple-rows\"\u003eSplitting a row in a PySpark Dataframe into multiple rows\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epyspark.functions.sql.explode\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Create dummy data\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esc\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparallelize\u003c/span\u003e\u003cspan class=\"p\"\u003e([(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;a b c\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                     \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;d e f\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                     \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;g h i\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etoDF\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;col1\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;col2\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;col3\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;col4\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Explode column\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark.sql.functions\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexplode\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;col4\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eexplode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;col4\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39; \u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)))\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+----+----+----+----+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"n\"\u003ecol1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"n\"\u003ecol2\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"n\"\u003ecol3\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"n\"\u003ecol4\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+----+----+----+----+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003eg\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003eh\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e   \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+----+----+----+----+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这样就不用使用 \u003ccode\u003eflatMap\u003c/code\u003e 函数了, 它代替了 map 函数:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 每个电话号码一行     \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emap_phones\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003er\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ephone\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003ere\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;,\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;phones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003eapp_key\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;app_key\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003ephones\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ephone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003esms_content\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;sms_content\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003er\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"一个-empty-引发的异常\"\u003e一个 empty 引发的异常\u003c/h2\u003e\n\u003cp\u003e在脚本中加入这么一句:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eyesterday_session_df\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erdd\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eisEmpty\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e上面的 \u003ccode\u003eisEmpty\u003c/code\u003e 方法没有带圆括号,但是执行没有报错,但是这个语句后面的语句好像都没有执行。\u003c/p\u003e\n\u003ch2 id=\"本机测试\"\u003e本机测试\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epath\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;/Users/ohmyfish/mdl0731\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epage_df\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e./\u003c/span\u003e\u003cspan class=\"nb\"\u003ebin\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003esubmit\u003c/span\u003e \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003emaster\u003c/span\u003e \u003cspan class=\"n\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e~/\u003c/span\u003e\u003cspan class=\"n\"\u003edata_check\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epy\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003ecalc_convert_rate\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eone_day\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003ejson_df\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;hdfs://10.0.0.55:9000/ald_log_etl/\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003estr\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ethe_day\u003c/span\u003e\u003cspan class=\"o\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","text":"反向代理的配置 在服务器中做如下配置:\nserver { listen 80; server_name test.aldwx.com; location /app.launch.php { proxy_pass http://127.0.0.1:3000; } } 然后在服务器中的终端中输入\nplackup -E deployment -s Starman --workers=1 -p 3000 -a app.pl 或者:\nnohup plackup -E deployment -s Starman --workers=10 -p 3000 -a app.pl \u0026amp; app.pl 是用 dancer 写的一个 demo 程序, 其中的内容如下:\n#!/usr/bin/perl use Digest::MD5 qw(md5_hex); use Dancer; use JSON qw(encode_json); # return the json format data get \u0026#34;/app.launch.info.php\u0026#34; =\u0026gt; sub { my $data = `date`; my $token = md5_hex($data); my $r = { \u0026#39;error\u0026#39; =\u0026gt; \u0026#39;0\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; { \u0026#39;access_token\u0026#39; =\u0026gt; $token }, }; return encode_json($r); }; get \u0026#39;/hello\u0026#39; =\u0026gt; sub { return \u0026#34;Hello 小程序\u0026#34;; }; get \u0026#39;/l.html\u0026#39; =\u0026gt; sub { return \u0026#34;Hello, World\u0026#34;; }; dance; 然后在浏览其中输入:\ntest.aldwx.com/app.launch.info.php 你会看到浏览器返给你返回一段 json 数据。\n查看端口号被哪个进程占用 netstat -tulnp | grep \u0026#39;:80 \u0026#39; tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 4021/nginx.conf nginx: [error] open() \u0026ldquo;/alidata/server/nginx/logs/nginx.pid\u0026rdquo; failed (2: No such file or directory) 错误 在使用的阿里云服务器上，进程性的 nginx -s stop后再次启动nginx -s reload ,总是会报错误nginx: [error] open() \u0026ldquo;/alidata/server/nginx/logs/nginx.pid\u0026rdquo; failed (2: No such file or directory)，这应该是因为把nginx进程杀死后pid丢失了，下一次再开启nginx -s reload时无法启动\nnginx -c /path/to/config/nginx.conf 查看被占用的端口号 lsof -i | grep \u0026#34;:7077\u0026#34; java 8927 root 230u IPv6 100990 0t0 TCP 106.2.1.77:7077 (LISTEN) php 环境搭建 sudo apt-get update sudo apt-get install lib apache2-mod-php5 ... .conf 文件的配置 .conf 文件一版放在 sites-available 目录中, 用的时候再软链接到 sites-enabled 中。\n免密码登录服务器 在服务器上的 ./ssh 目录中添加 ssh key, 比如我更换了新电脑:\nvim ~/.ssh/authorized_keys 删除掉旧的 ssh keys, 加入新生成的:\nssh-rsa AAACCQEEEEddfdfdffrrt3334QWAUUY1223xxxXXXXXXX wodefan@Mac-mini.local 从本地上传/下载文件/文件夹到服务器 上传和下载都是在本地打开命令行终端。\n上传 scp ./app.py root@108.2.5.98:/daly/apk/myapp/ # 从本地上传单个文件到服务器 scp -r myjobs root@108.2.5.98:/daly/apk/ # 从本地上传整个文件夹到服务器 下载 scp root@108.2.5.98:/daly/apk/myapp/today.txt . # 从服务器下载指定文件到本地目录 scp -r root@108.2.5.98:/daly/apk/apk/ . # 从服务器下载整个文件夹到本地 在 pyspark 中连接数据库 启动 pyspark 时附加上相应的 mysql jar 包: /data/app/spark/bin/pyspark --driver-class-path mysql-connector-java-5.1.40-bin.jar --jars mysql-connector-java-5.1.40-bin.jar 使用用户名和密码连接 mysql, 并创建一个数据框: df = spark.read.format(\u0026#34;jdbc\u0026#34;).option(\u0026#34;url\u0026#34;, \u0026#34;jdbc:mysql://8.8.8.8/ald_xinen\u0026#34;).option(\u0026#34;dbtable\u0026#34;, \u0026#34;(select * from ald_session_logs) as df\u0026#34;).option(\u0026#39;user\u0026#39;, \u0026#34;root\u0026#34;).option(\u0026#39;password\u0026#39;, \u0026#34;fish@sky\u0026#34;).load() df.take(2) # 取出前两行 如果已经启动了一个连接 mysql 数据库的 pyspark, 再重新启动一个时会报错, 这个时候就要把之前的启动的杀掉:\nps aux | grep \u0026#39;spark\u0026#39; 然后找到 pyspark-shell 的 进程 id, kill -9 xxxx\ntoDF(*cols) 返回一新的数据框, 指定新的列名。 df.select(\u0026#34;app_key\u0026#34;, \u0026#34;uuid\u0026#34;).toDF(\u0026#34;f1\u0026#34;, \u0026#39;f2\u0026#39;).take(2) 输出:\n[Row(f1=u\u0026#39;2323423dsfds\u0026#39;, f2=u\u0026#39;14797409227806341000\u0026#39;), Row(f1=u\u0026#39;2323423dsfds\u0026#39;, f2=u\u0026#39;14797409227806341000\u0026#39;)] toJSON() 将数据框转换为字符串 RDD。每一行都被转换为 JSON 文档, 作为所返回的 RDD 中的一个元素。 df.select(\u0026#34;app_key\u0026#34;, \u0026#34;uuid\u0026#34;).toJSON().first() 输出:\nu\u0026#39;{\u0026#34;app_key\u0026#34;:\u0026#34;2323423dsfds\u0026#34;,\u0026#34;uuid\u0026#34;:\u0026#34;14797409227806341000\u0026#34;}\u0026#39; toLocalIterator() 返回一个包含该数据框所有行的迭代器。这个迭代器会在该数据框的最大分区中消耗尽可能多的内存。\nlist(df.toLocalIterator()) withColumn(colName, col) 通过为原数据框添加一个新列或替换已存在的同名列而返回一个新数据框。colName 是一个字符串, 为新列的名字。 col 为这个新列的 Column 表达式。withColumn 的第一个参数必须是已存在的列的名字,　withColumn 的第二个参数必须是含有列的表达式。如果不是它会报错 AssertionError: col should be Column。\ndf.withColumn(\u0026#39;page_count\u0026#39;, df.page_count+100).select(\u0026#34;app_key\u0026#34;,\u0026#34;page_count\u0026#34;).take(2) 输出:\n[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, page_count=110), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, page_count=104)] col 表达式可以使用多个其他列:\ndf.withColumn(\u0026#39;avg\u0026#39;, df.page_count/df.duration).select(\u0026#34;app_key\u0026#34;,\u0026#34;avg\u0026#34;).take(2) 输出:\n[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, avg=0.00012387736141220192), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, avg=0.16666666666666666)] withColumn 可以添加一个常数列, 但是要使用 pyspark.sql.functions 中的函数, 例如: unix_timestamp.\n可以参考\nHow do I add a new column to a Spark DataFrame (using PySpark)?\nHow to add a constant column in a Spark DataFrame?\nwithColumnRenamed(existing, new)\n重命名已存在的列并返回一个新数据框。existing 为已存在的要重命名的列, col 为新列的名字。\n将 duration 列重命名为 time_take 列:\ndf.withColumnRenamed(\u0026#39;duration\u0026#39;, \u0026#39;time_take\u0026#39;).select(\u0026#39;app_key\u0026#39;, \u0026#39;time_take\u0026#39;).take(2) 输出:\n[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, time_take=80725), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, time_take=24)] groupBy 之后可以使用的方法 agg(*exprs) 聚合计算并将结果返回为 DataFrame。\n可用的聚合函数有 avg, max, min, sum, \u0026lsquo;count\u0026rsquo;.\n如果 expr 是从字符串到字符串的单个 dict 映射, 那么其键就是要执行聚合的列, 其值就是该聚合函数。\n可选地, expr 还可以是一组聚合列 表达式。\n参数: exprs - 一个从列名(字符串)到聚合函数(字符串)的字典映射, 或者是一个 Column 列表。\ngdf = df.groupBy(df.app_key) gdf.agg({\u0026#34;*\u0026#34; : \u0026#39;count\u0026#39; } ).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, count(1)=4), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, count(1)=12), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, count(1)=3), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count(1)=66), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count(1)=490), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, count(1)=17), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, count(1)=5)] 对 app_key 排序下:\nsorted(gdf.agg({\u0026#34;*\u0026#34;: \u0026#34;count\u0026#34;}).collect()) 输出:\n[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count(1)=490), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count(1)=66), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, count(1)=3), Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, count(1)=4), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, count(1)=12), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, count(1)=1), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, count(1)=5), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, count(1)=17)] from pyspark.sql import functions as F sorted(gdf.agg(F.max(df.duration)).collect()) 输出:\n[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, max(duration)=28498), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, max(duration)=80725), Row(app_key=u\u0026#39;6428c8aa20672b64386fc1d2ce60ef3f\u0026#39;, max(duration)=352), Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150), Row(app_key=u\u0026#39;6c4396a7eec8f081e890ef0adbf5090d\u0026#39;, max(duration)=33), Row(app_key=u\u0026#39;7c8ccee05d025bb85f15f9d45c83aba8\u0026#39;, max(duration)=168), Row(app_key=u\u0026#39;AAAAAAAAAAAAAA\u0026#39;, max(duration)=23), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, max(duration)=87), Row(app_key=u\u0026#39;f05883cf4dd8c6016ac55d9380f568d2\u0026#39;, max(duration)=7789)] avg(*cols) 为每一组的每个数值列计算平均值。\nmean 是 avg 的别名。\n参数: cols - 一组列的名字(字符串)。非数值列被忽略。\ndf.groupBy(\u0026#39;app_key\u0026#39;).avg(\u0026#39;duration\u0026#39;).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, avg(duration)=150.0),Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, avg(duration)=153.81428571428572) ...] df.groupBy(\u0026#39;app_key\u0026#39;).avg(\u0026#39;duration\u0026#39;, \u0026#39;page_count\u0026#39;).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, avg(duration)=150.0, avg(page_count)=12.0), avg(page_count)=5.681818181818182), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, avg(duration)=153.81428571428572, avg(page_count)=8.059183673469388) ...] count() 计算每组的记录数。\nsorted(df.groupBy(df.app_key).count().collect()) 输出:\n[Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, count=490), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, count=66) ...] max(*cols) 计算每组每个数值列的最大值。\ndf.groupBy(\u0026#39;app_key\u0026#39;).max(\u0026#39;duration\u0026#39;).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150) ...] df.groupBy(\u0026#39;app_key\u0026#39;).max(\u0026#39;duration\u0026#39;, \u0026#39;page_count\u0026#39;).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, max(duration)=150, max(page_count)=12)...] mean() 求平均数, 同 avg\nmin() 参考 max\npivot(pivot_col, values=None)\n透视当前[[DataFrame]]的列并执行指定的聚合。有两个版本的pivot函数：一个需要调用者指定不同值的列表以便进行透视，而另一个不指定。后者更简洁但效率较低，因为Spark需要首先在内部计算不同值的列表。\n参数: pivot_col - 要透视的列名; values - 将转换为输出 DataFrame 中的列的值列表。\n计算每个 app 下，每个渠道的总停留时长, 每个渠道的结果占一列:\ndf.groupBy(\u0026#39;app_key\u0026#39;).pivot(\u0026#34;source\u0026#34;, [\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34; ]).sum(\u0026#34;duration\u0026#34;).collect() 输出:\n[Row(app_key=u\u0026#39;64a7f2b033fb593a8598bbc48c3b8486\u0026#39;, 1=None, 2=None, 3=None, 4=150), Row(app_key=u\u0026#39;21e689e6bb76a213b21fc61147db1bab\u0026#39;, 1=7208, 2=54929, 3=7078, 4=6139), Row(app_key=u\u0026#39;dc9c30b87aa07834ffb7736f715b9caa\u0026#39;, 1=None, 2=94, 3=29, 4=87) ...] 官方的例子:\n# Compute the sum of earnings for each year by course with each course as a separate column df4.groupBy(\u0026#34;year\u0026#34;).pivot(\u0026#34;course\u0026#34;, [\u0026#34;dotNET\u0026#34;, \u0026#34;Java\u0026#34;]).sum(\u0026#34;earnings\u0026#34;).collect() [Row(year=2012, dotNET=15000, Java=20000), Row(year=2013, dotNET=48000, Java=30000)] 或者不指定列的值（不够有效率）\ndf4.groupBy(\u0026#34;year\u0026#34;).pivot(\u0026#34;course\u0026#34;).sum(\u0026#34;earnings\u0026#34;).collect() [Row(year=2012, Java=20000, dotNET=15000), Row(year=2013, Java=30000, dotNET=48000)] sum(*cols) 为每组计算每个数值列的总和。\n参数: cols - 一组列的名字（字符串）。非数值列被忽略。\n# 官方例子： df.groupBy().sum(\u0026#39;age\u0026#39;).collect() # [Row(sum(age)=7)] df3.groupBy().sum(\u0026#39;age\u0026#39;, \u0026#39;height\u0026#39;).collect() # [Row(sum(age)=7, sum(height)=165)] class pyspark.sql.Column(jc) 数据框中的一列。 Column 实例可以通过如下的代码创建：\n#1. 选择数据框中的一列 df.colName df[\u0026#34;colName\u0026#34;] #2. 从表达式创建 df.colName + 1 1 / df.colName alias(*alias) 返回这个列的新的别名或别名们(在表达式返回多列的情况下, 例如爆炸)。\ndf.select(df.duration.alias(\u0026#34;time_take\u0026#34;)).collect() asc() 返回一个排序过的表达式, 基于给定列的名字的升序进行排列。\nastype() 是 cast() 的别名。\nbetween(lowerBound, upperBound)\n如果这个表达式的值在给定的列的值之间，则计算结果为布尔真。\ndf.select(df.app_key, df.duration.between(60,80)).show(50) show()函数输出前 20 行:\n+--------------------+---------------------------------------+ | app_key|((duration \u0026gt;= 60) AND (duration \u0026lt;= 80))| +--------------------+---------------------------------------+ | 2323423dsfds| false| | 2323423dsfds| false| | 2323423dsfds| false| | 2323423dsfds| false| | 2323423dsfds| true| ... cast(dataType) 将列转换为 dataType 类型。\n# 官方例子: df.select(df.age.cast(\u0026#34;string\u0026#34;).alias(\u0026#39;ages\u0026#39;)).collect() # [Row(ages=u\u0026#39;2\u0026#39;), Row(ages=u\u0026#39;5\u0026#39;)] df.select(df.age.cast(StringType()).alias(\u0026#39;ages\u0026#39;)).collect() # [Row(ages=u\u0026#39;2\u0026#39;), Row(ages=u\u0026#39;5\u0026#39;)] # 将字符串转为 int 型 df.select(df.source.cast(\u0026#34;int\u0026#34;).alias(\u0026#39;sources\u0026#39;)).take(20) 输出:\n[Row(sources=1), Row(sources=2),...] desc() 根据给定列的名字的倒序返回排序后的表达式。\ngetField(name) 在StructField中按名称获取字段的表达式。\nfrom pyspark.sql import Row df = sc.parallelize([Row(r=Row(a=1, b=\u0026#34;b\u0026#34;))]).toDF() df.select(df.r.getField(\u0026#34;b\u0026#34;)).show() +---+ |r.b| +---+ | b| +---+ df.select(df.r.a).show() +---+ |r.a| +---+ | 1| +---+ isNotNull() 如果当前的表达式不为 null 则为真。\nisNull() 如果当前的表达式为 null 则为真。\nisin(*cols) 如果这个表达式的值被包含在参数的计算值之中,则该表达式为真。\ndf[df.network_type.isin(\u0026#34;Wifi\u0026#34;, \u0026#34;4g\u0026#34;)].select(\u0026#39;app_key\u0026#39;, \u0026#39;network_type\u0026#39;).take(2) 输出:\n[Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, network_type=u\u0026#39;wifi\u0026#39;), Row(app_key=u\u0026#39;2323423dsfds\u0026#39;, network_type=u\u0026#39;4g\u0026#39;)] name() 是 alias() 的别名\notherwise(value)\n计算一组条件，并返回多个可能的结果表达式之一。如果未调用 Column.otherwise()，则为不匹配的条件返回 None。\n有关使用示例，请参阅 pyspark.sql.functions.when()。\n参数：value - 字面值或 Column 表达式。\nfrom pyspark.sql import functions as F df.select(df.duration, F.when(df.page_count \u0026gt; 10, 1).otherwise(0)).show() 输出:\n+--------+---------------------------------------------+ |duration|CASE WHEN (page_count \u0026gt; 10) THEN 1 ELSE 0 END| +--------+---------------------------------------------+ | 80725| 0| | 24| 0| | 21| 0| | 21| 1| | 66| 1| | 17| 0| | 31| 0| | 1| 0| | 80| 1| | 3| 0| | 11| 1| | 6| 0| | 23| 1| | 4| 0| | 2| 0| | 23| 0| | 60| 1| | 16| 0| | 4| 0| | 4| 0| +--------+---------------------------------------------+ from_unixtime\n将 unix 格式的时间戳转换为指定格式的日期\nfrom pyspark.sql.functions import from_unixtime df = spark.createDataFrame([(\u0026#39;1486461323\u0026#39;,)], [\u0026#39;start_time\u0026#39;]) df.withColumn(\u0026#39;day\u0026#39;, from_unixtime( df.start_time , \u0026#39;yyyy-MM-dd\u0026#39;)).show() 上面的代码中的createDataFrame 方法创建了一个只有一列的数据框, withColumn 方法为该数据框添加了一个新的名为 day 的列, from_unixtime 方法将该数据框中原来的 start_time 列转换为指定格式的日期。show() 方法打印输出。\npyspark.sql.functions.col(col)\ncol 方法接收一个字符串列名作为参数, 根据指定的列名返回一个 Column. 作用和 df.columnName 相同。\npyspark.sql.functions.when(condition, value)\n计算一组条件并返回多个可能结果的表达式的其中之一。如果 Column.otherwise 没有被调用, 那么对未匹配的条件会返回 None。\n参数:\ncondition - 一个布尔 Column 表达式。 value - 一个字面值, 或者一个 Column 表达式。 df.select( when(df[\u0026#39;age\u0026#39;]==2, 3).otherwise(4).alias(\u0026#34;age\u0026#34;) ).collect() # [Row(age=3), Row(age=4)] df.select( when(df.age==2, df.age + 1).alias(\u0026#34;age\u0026#34;) ).collect() # [Row(age=3), Row(age=None)]-pyspark.sql.Column.when pyspark.sql.Column.when(condition, value)\n计算一组条件并返回多个可能结果的表达式的其中之一。如果 Column.otherwise 没有被调用, 那么对未匹配的条件会返回 None。当 when 中有多个条件时,要用 \u0026amp; 或 | 连接起来。Pyspark: multiple conditions in when clause\nfrom pyspark.sql import functions as F df.select(df.name, F.when(df.age \u0026gt; 4, 1).when(df.age \u0026lt; 3, -1).otherwise(0)).show() 从 df 数据框中选择出 name 和 age 这两列。如果 age\u0026gt;4 则把 age 置为 1; 如果 age\u0026lt;3 就把 age 置为 -1, 否则置为 0。\n+-----+------------------------------------------------------------+ | name|CASE WHEN (age \u0026gt; 4) THEN 1 WHEN (age \u0026lt; 3) THEN -1 ELSE 0 END| +-----+------------------------------------------------------------+ |Alice| -1| | Bob| 1| +-----+------------------------------------------------------------+ left_outer join\n左连接之后如果有重复的列, 则使用 drop 删除不了重复的列。需要用 select。　udf 方法\n定义一个 udf 方法, 用来返回今天的日期(yyyy-MM-dd):\nfrom pyspark.sql.functions import udf from pyspark.sql.types import StringType import datetime # 定义一个 udf 函数 def today(day): if day==None: return datetime.datetime.fromtimestamp(int(time.time())).strftime(\u0026#39;%Y-%m-%d\u0026#39;) else: return day # 返回类型为字符串类型 udfday = udf(today, StringType()) # 使用 df.withColumn(\u0026#39;day\u0026#39;, udfday(df.day)) drop\n有时候使用 drop 来删除某一列时, 会出现错误, 而用 select 就可以。\n将 map 转换为 select 之前一直使用 map 方法来做转换, 添加新的列:\n# 今天的新访问用户数, 访问人数, 访问次数 _time_slot_df = spark.createDataFrame(slot_session_df.rdd.map(map_sessions)) \\ .groupBy(\u0026#39;app_key\u0026#39;, \u0026#39;day\u0026#39;) \\ .agg( sum(\u0026#39;is_first_open\u0026#39;).alias(\u0026#39;today_new_user_count\u0026#39;), # 新访问用户数 countDistinct(\u0026#39;uuid\u0026#39;).alias(\u0026#39;today_user_count\u0026#39;), # 访问人数 sum(\u0026#39;page_count\u0026#39;).alias(\u0026#39;today_visits_count\u0026#39;), # 访问次数 ) # 对 session_logs 日志做 map 操作, 生成需要的字段 def map_sessions(row): if row[\u0026#39;is_first_open\u0026#39;]: is_first_open = 1 else: is_first_open = 0 return Row( app_key = row[\u0026#39;app_key\u0026#39;], uuid = row[\u0026#39;uuid\u0026#39;], # 访问人数 is_first_open = is_first_open, # 新访问用户数 page_count = row[\u0026#39;page_count\u0026#39;], # 访问次数 day = datetime.datetime.fromtimestamp(int(row[\u0026#39;start_time\u0026#39;])).strftime(\u0026#39;%Y-%m-%d\u0026#39;) ) 现在我们有 select, withColumn, when 来做:\n_result_active_df = aladdin_id_df.join(_result_df, _result_df.app_key==aladdin_id_df.app_key, \u0026#39;left_outer\u0026#39;) \\ .drop(\u0026#34;_result_df.app_key\u0026#34;,\u0026#34;_result_df.uid\u0026#34;) 先用 select 方法从数据框中选择出已经存在的列(s)，这就是临时的新的数据框, 再用 withColumn 向该临时数据框中添加新的列。对于需要进行转换的列, 可以使用 when 方法来做运算。\nSplitting a row in a PySpark Dataframe into multiple rows\npyspark.functions.sql.explode # Create dummy data df = sc.parallelize([(1, 2, 3, \u0026#39;a b c\u0026#39;), (4, 5, 6, \u0026#39;d e f\u0026#39;), (7, 8, 9, \u0026#39;g h i\u0026#39;)]).toDF([\u0026#39;col1\u0026#39;, \u0026#39;col2\u0026#39;, \u0026#39;col3\u0026#39;,\u0026#39;col4\u0026#39;]) # Explode column from pyspark.sql.functions import split, explode df.withColumn(\u0026#39;col4\u0026#39;,explode(split(\u0026#39;col4\u0026#39;,\u0026#39; \u0026#39;))).show() +----+----+----+----+ |col1|col2|col3|col4| +----+----+----+----+ | 1| 2| 3| a| | 1| 2| 3| b| | 1| 2| 3| c| | 4| 5| 6| d| | 4| 5| 6| e| | 4| 5| 6| f| | 7| 8| 9| g| | 7| 8| 9| h| | 7| 8| 9| i| +----+----+----+----+ 这样就不用使用 flatMap 函数了, 它代替了 map 函数:\n# 每个电话号码一行 def map_phones(row): r = [] for phone in re.split(\u0026#39;,\u0026#39;, row[\u0026#39;phones\u0026#39;]): r.append(Row( app_key = row[\u0026#39;app_key\u0026#39;], phones = phone, sms_content = row[\u0026#39;sms_content\u0026#39;] )) return r 一个 empty 引发的异常 在脚本中加入这么一句:\nif yesterday_session_df.rdd.isEmpty: return 上面的 isEmpty 方法没有带圆括号,但是执行没有报错,但是这个语句后面的语句好像都没有执行。\n本机测试 path = \u0026#34;/Users/ohmyfish/mdl0731\u0026#34; page_df = spark.read.json(path) ./bin/spark-submit --master local[4] ~/data_check.py 0 def calc_convert_rate(spark, one_day): json_df=spark.read.json(\u0026#34;hdfs://10.0.0.55:9000/ald_log_etl/\u0026#34; + str(the_day)) "},"name":"Pyspark 笔记","published":"2017-04-07T16:36:25Z","summary":"反向代理的配置 在服务器中做如下配置:\nserver { listen 80; server_name test.aldwx.com; location /app.launch.php { proxy_pass http://127.0.0.1:3000; } } 然后在服务器中的终端中输入\nplackup -E deployment -s Starman --workers=1 -p 3000 -a app.pl 或者:\nnohup plackup -E deployment -s Starman --workers=10 -p 3000 -a app.pl \u0026amp; app.pl 是用 dancer 写的一个 demo 程序, 其中的内容如下:\n#!/usr/bin/perl use Digest::MD5 qw(md5_hex); use Dancer; use JSON qw(encode_json); # return the json format data get \u0026#34;/app.launch.info.php\u0026#34; =\u0026gt; sub { my $data = `date`; my $token = md5_hex($data); my $r = { \u0026#39;error\u0026#39; =\u0026gt; \u0026#39;0\u0026#39;, \u0026#39;data\u0026#39; =\u0026gt; { \u0026#39;access_token\u0026#39; =\u0026gt; $token }, }; return encode_json($r); }; get \u0026#39;/hello\u0026#39; =\u0026gt; sub { return \u0026#34;Hello 小程序\u0026#34;; }; get \u0026#39;/l.","type":"entry","url":"https://ohmyweekly.github.io/notes/%E5%B9%B2%E8%B4%A7%E6%BB%A1%E6%BB%A1%E7%9A%84-pyspark-%E7%AC%94%E8%AE%B0/"}