{"author":{"name":null,"type":"card","url":"https://ohmycloud.github.io/"},"content":{"html":"\u003ch1 id=\"hivecatalog\"\u003eHiveCatalog\u003c/h1\u003e\n\u003cp\u003eHive Metastore 经过多年的发展，已经成为 Hadoop 生态系统中事实上的元数据中心。很多公司在生产中都有一个 Hive Metastore 服务实例来管理他们所有的元数据，无论是 Hive 元数据还是非 Hive 元数据，都是真理的来源。\u003c/p\u003e\n\u003cp\u003e对于同时部署了 Hive 和 Flink 的用户，HiveCatalog 可以让他们使用 Hive Metastore 来管理 Flink 的元数据。\u003c/p\u003e\n\u003cp\u003e对于只有 Flink 部署的用户来说，HiveCatalog 是 Flink 开箱即用的唯一持久化目录。如果没有持久化目录，用户使用 \u003ca href=\"https://ohmyweekly.github.io/notes/2020-08-22-create-statements\"\u003eFlink SQL CREATE DDL\u003c/a\u003e 必须在每个会话中反复创建元对象，比如 Kafka 表，这就浪费了很多时间。HiveCatalog 填补了这一空白，使用户只需创建一次表和其他元对象，以后就可以跨会话方便地引用和管理它们。\u003c/p\u003e\n\u003ch2 id=\"设置-hivecatalog\"\u003e设置 HiveCatalog\u003c/h2\u003e\n\u003ch3 id=\"依赖性\"\u003e依赖性\u003c/h3\u003e\n\u003cp\u003e在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#dependencies\"\u003e依赖关系\u003c/a\u003e。\u003c/p\u003e\n\u003ch3 id=\"配置\"\u003e配置\u003c/h3\u003e\n\u003cp\u003e在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#connecting-to-hive\"\u003e配置\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"如何使用-hivecatalog\"\u003e如何使用 HiveCatalog\u003c/h2\u003e\n\u003cp\u003e一旦配置得当，HiveCatalog 应该可以直接使用。用户可以用 DDL 创建 Flink 元对象，并在创建后立即看到它们。\u003c/p\u003e\n\u003cp\u003eHiveCatalog 可以用来处理两种表。Hive 兼容表和通用表。Hive-compatible 表是指那些以 Hive 兼容的方式存储的表，在存储层的元数据和数据方面都是如此。因此，通过 Flink 创建的 Hive 兼容表可以从 Hive 端进行查询。\u003c/p\u003e\n\u003cp\u003e而通用表则是针对 Flink 的。当使用 HiveCatalog 创建通用表时，我们只是使用 HMS 来持久化元数据。虽然这些表对 Hive 是可见的，但 Hive 不太可能理解这些元数据。因此在 Hive 中使用这样的表会导致未定义的行为。\u003c/p\u003e\n\u003cp\u003eFlink 使用属性 \u0026ldquo;is_generic\u0026rdquo; 来判断一个表是与 Hive 兼容还是通用。当用 HiveCatalog 创建一个表时，它默认被认为是通用的。如果你想创建一个 Hive 兼容的表，请确保在你的表属性中把 is_generic 设置为 false。\u003c/p\u003e\n\u003cp\u003e如上所述，通用表不应该从 Hive 使用。在 Hive CLI 中，你可以调用 describe FORMATTED 对一个表进行检查，通过检查 is_generic 属性来决定它是否是通用的。通用表会有 is_generic=true。\u003c/p\u003e\n\u003ch3 id=\"例子\"\u003e例子\u003c/h3\u003e\n\u003cp\u003e我们在这里将通过一个简单的例子进行讲解。\u003c/p\u003e\n\u003cp\u003e第 1 步：设置 Hive Metastore。\u003c/p\u003e\n\u003cp\u003e有一个 Hive Metastore 在运行。\u003c/p\u003e\n\u003cp\u003e在这里，我们在本地路径 \u003ccode\u003e/opt/hive-conf/hive-site.xml\u003c/code\u003e 中设置一个本地 Hive Metastore 和我们的 hive-site.xml 文件。我们有如下的一些配置。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-xml\" data-lang=\"xml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003e\u0026lt;configuration\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ejavax.jdo.option.ConnectionURL\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003ejdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;description\u0026gt;\u003c/span\u003emetadata is stored in a MySQL server\u003cspan class=\"nt\"\u003e\u0026lt;/description\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ejavax.jdo.option.ConnectionDriverName\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003ecom.mysql.jdbc.Driver\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;description\u0026gt;\u003c/span\u003eMySQL JDBC driver class\u003cspan class=\"nt\"\u003e\u0026lt;/description\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ejavax.jdo.option.ConnectionUserName\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003e...\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;description\u0026gt;\u003c/span\u003euser name for connecting to mysql server\u003cspan class=\"nt\"\u003e\u0026lt;/description\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ejavax.jdo.option.ConnectionPassword\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003e...\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026lt;description\u0026gt;\u003c/span\u003epassword for connecting to mysql server\u003cspan class=\"nt\"\u003e\u0026lt;/description\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ehive.metastore.uris\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003ethrift://localhost:9083\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"nt\"\u003e\u0026lt;description\u0026gt;\u003c/span\u003eIP address (or fully-qualified domain name) and port of the metastore host\u003cspan class=\"nt\"\u003e\u0026lt;/description\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"nt\"\u003e\u0026lt;name\u0026gt;\u003c/span\u003ehive.metastore.schema.verification\u003cspan class=\"nt\"\u003e\u0026lt;/name\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       \u003cspan class=\"nt\"\u003e\u0026lt;value\u0026gt;\u003c/span\u003etrue\u003cspan class=\"nt\"\u003e\u0026lt;/value\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   \u003cspan class=\"nt\"\u003e\u0026lt;/property\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003e\u0026lt;/configuration\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e用 Hive Cli 测试连接到 HMS。运行一些命令，我们可以看到我们有一个名为 default 的数据库，里面没有表。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehive\u0026gt; show databases\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOK\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edefault\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTime taken: 0.032 seconds, Fetched: \u003cspan class=\"m\"\u003e1\u003c/span\u003e row\u003cspan class=\"o\"\u003e(\u003c/span\u003es\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehive\u0026gt; show tables\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOK\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTime taken: 0.028 seconds, Fetched: \u003cspan class=\"m\"\u003e0\u003c/span\u003e row\u003cspan class=\"o\"\u003e(\u003c/span\u003es\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e步骤 2：配置 Flink 集群和 SQL CLI\u003c/p\u003e\n\u003cp\u003e将所有 Hive 的依赖关系添加到 Flink 发行版的 \u003ccode\u003e/lib\u003c/code\u003e 目录下，并修改 SQL CLI 的 yaml 配置文件 sql-cli-defaults.yaml 如下。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003eexecution\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003eplanner\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eblink\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003etype\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003estreaming\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"l\"\u003e...\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003ecurrent-catalog\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003emyhive \u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c\"\u003e# set the HiveCatalog as the current catalog of the session\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003ecurrent-database\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003emydatabase\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"nt\"\u003ecatalogs\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e- \u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003emyhive\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"nt\"\u003etype\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehive\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"nt\"\u003ehive-conf-dir\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/opt/hive-conf \u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c\"\u003e# contains hive-site.xml\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e第三步：建立 Kafka 集群\u003c/p\u003e\n\u003cp\u003eBootstrap 一个本地的 Kafka 2.3.0 集群，主题命名为 \u0026ldquo;test\u0026rdquo;，并以 name 和 age 的元组形式向主题产生一些简单的数据。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocalhost$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic \u003cspan class=\"nb\"\u003etest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u0026gt;tom,15\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u0026gt;john,21\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这些消息可以通过启动 Kafka 控制台消费者看到。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocalhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic \u003cspan class=\"nb\"\u003etest\u003c/span\u003e --from-beginning\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etom,15\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ejohn,21\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e第四步：启动 SQL Client，用 Flink SQL DDL 创建一个 Kafka 表。\u003c/p\u003e\n\u003cp\u003e启动 Flink SQL Client，通过 DDL 创建一个简单的 Kafka 2.3.0 表，并验证其模式。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eFlink\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eSQL\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eCREATE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTABLE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003emykafka\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eInt\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eWITH\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;connector.type\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;kafka\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;connector.version\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;universal\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;connector.topic\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;test\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;connector.properties.bootstrap.servers\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;localhost:9092\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;format.type\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;csv\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;update-mode\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;append\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eINFO\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehas\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebeen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecreated\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eFlink\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eSQL\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDESCRIBE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003emykafka\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eroot\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"c1\"\u003e-- name: STRING\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"c1\"\u003e-- age: INT\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e验证该表也是通过 Hive Cli 对 Hive 可见的，注意该表有属性 is_generic=true。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehive\u0026gt; show tables\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOK\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emykafka\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTime taken: 0.038 seconds, Fetched: \u003cspan class=\"m\"\u003e1\u003c/span\u003e row\u003cspan class=\"o\"\u003e(\u003c/span\u003es\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehive\u0026gt; describe formatted mykafka\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOK\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# col_name            \tdata_type           \tcomment\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Detailed Table Information\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eDatabase:           \tdefault\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOwner:              \tnull\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eCreateTime:         \t......\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eLastAccessTime:     \tUNKNOWN\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eRetention:          \t\u003cspan class=\"m\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eLocation:           \t......\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTable Type:         \tMANAGED_TABLE\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTable Parameters:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.connector.properties.bootstrap.servers\tlocalhost:9092\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.connector.topic\t\u003cspan class=\"nb\"\u003etest\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.connector.type\tkafka\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.connector.version\tuniversal\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.format.type   \tcsv\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.generic.table.schema.0.data-type\tVARCHAR\u003cspan class=\"o\"\u003e(\u003c/span\u003e2147483647\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.generic.table.schema.0.name\tname\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.generic.table.schema.1.data-type\tINT\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.generic.table.schema.1.name\tage\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tflink.update-mode   \tappend\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tis_generic          \t\u003cspan class=\"nb\"\u003etrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\ttransient_lastDdlTime\t......\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Storage Information\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eSerDe Library:      \torg.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eInputFormat:        \torg.apache.hadoop.mapred.TextInputFormat\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eOutputFormat:       \torg.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eCompressed:         \tNo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eNum Buckets:        \t-1\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eBucket Columns:     \t\u003cspan class=\"o\"\u003e[]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eSort Columns:       \t\u003cspan class=\"o\"\u003e[]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eStorage Desc Params:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\tserialization.format\t\u003cspan class=\"m\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eTime taken: 0.158 seconds, Fetched: \u003cspan class=\"m\"\u003e36\u003c/span\u003e row\u003cspan class=\"o\"\u003e(\u003c/span\u003es\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e第五步：运行 Flink SQL 查询 Kakfa 表。\u003c/p\u003e\n\u003cp\u003e在 Flink 集群中，无论是单机还是 yarn-session，从 Flink SQL Client 中运行一个简单的选择查询。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eFlink SQL\u0026gt; \u003cspan class=\"k\"\u003eselect\u003c/span\u003e * from mykafka\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在 Kafka 主题中多产生一些信息。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocalhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic \u003cspan class=\"nb\"\u003etest\u003c/span\u003e --from-beginning\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etom,15\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ejohn,21\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekitty,30\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eamy,24\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekaiky,18\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e你现在应该可以在 SQL Client 中看到 Flink 产生的结果，如。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e             SQL Query Result (Table)\n Refresh: 1 s    Page: Last of 1     \n\n        name                       age\n         tom                        15\n        john                        21\n       kitty                        30\n         amy                        24\n       kaiky                        18\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"支持的类型\"\u003e支持的类型\u003c/h2\u003e\n\u003cp\u003eHiveCatalog 支持通用表的所有 Flink 类型。\u003c/p\u003e\n\u003cp\u003e对于 Hive 兼容的表，HiveCatalog 需要将 Flink 数据类型映射到相应的 Hive 类型，如下表所述。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align:left\"\u003eFlink Data Type\u003c/th\u003e\n\u003cth style=\"text-align:left\"\u003eHive Data Type\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eCHAR(p)\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eCHAR(p)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eVARCHAR(p)\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eVARCHAR(p)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eSTRING\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eSTRING\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eBOOLEAN\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eBOOLEAN\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eTINYINT\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eTINYINT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eSMALLINT\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eSMALLINT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eINT\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eINT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eBIGINT\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eLONG\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eFLOAT\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eFLOAT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eDOUBLE\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eDOUBLE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eDECIMAL(p, s)\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eDECIMAL(p, s)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eDATE\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eDATE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eTIMESTAMP(9)\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eTIMESTAMP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eBYTES\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eBINARY\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eARRAY\u003c!-- raw HTML omitted --\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eLIST\u003c!-- raw HTML omitted --\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eMAP\u0026lt;K, V\u0026gt;\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eMAP\u0026lt;K, V\u0026gt;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:left\"\u003eROW\u003c/td\u003e\n\u003ctd style=\"text-align:left\"\u003eSTRUCT\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e关于类型映射需要注意的地方。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHive 的 CHAR(p) 最大长度为 255。\u003c/li\u003e\n\u003cli\u003eHive 的 VARCHAR(p) 最大长度为 65535。\u003c/li\u003e\n\u003cli\u003eHive 的 MAP 只支持基元键类型，而 Flink 的 MAP 可以是任何数据类型。\u003c/li\u003e\n\u003cli\u003e不支持 Hive 的 UNION 类型。\u003c/li\u003e\n\u003cli\u003eHive 的 TIMESTAMP 的精度总是 9，不支持其他精度。而 Hive 的 UDF 则可以处理精度\u0026lt;=9 的 TIMESTAMP 值。\u003c/li\u003e\n\u003cli\u003eHive 不支持 Flink 的 TIMESTAMP_WITH_TIME_ZONE、TIMESTAMP_WITH_LOCAL_TIME_ZONE 和 MULTISET。\u003c/li\u003e\n\u003cli\u003eFlink 的 INTERVAL 类型还不能映射到 Hive 的 INTERVAL 类型。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"scala-shell\"\u003eScala Shell\u003c/h2\u003e\n\u003cp\u003e注意：由于目前 Scala Shell 并不支持 blink planner，所以不建议在 Scala Shell 中使用 Hive 连接器。\u003c/p\u003e\n\u003cp\u003e原文链接: \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html\"\u003ehttps://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html\u003c/a\u003e\u003c/p\u003e\n","text":"HiveCatalog Hive Metastore 经过多年的发展，已经成为 Hadoop 生态系统中事实上的元数据中心。很多公司在生产中都有一个 Hive Metastore 服务实例来管理他们所有的元数据，无论是 Hive 元数据还是非 Hive 元数据，都是真理的来源。\n对于同时部署了 Hive 和 Flink 的用户，HiveCatalog 可以让他们使用 Hive Metastore 来管理 Flink 的元数据。\n对于只有 Flink 部署的用户来说，HiveCatalog 是 Flink 开箱即用的唯一持久化目录。如果没有持久化目录，用户使用 Flink SQL CREATE DDL 必须在每个会话中反复创建元对象，比如 Kafka 表，这就浪费了很多时间。HiveCatalog 填补了这一空白，使用户只需创建一次表和其他元对象，以后就可以跨会话方便地引用和管理它们。\n设置 HiveCatalog 依赖性 在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的依赖关系。\n配置 在 Flink 中设置 HiveCatalog 需要与 Flink-Hive 集成相同的配置。\n如何使用 HiveCatalog 一旦配置得当，HiveCatalog 应该可以直接使用。用户可以用 DDL 创建 Flink 元对象，并在创建后立即看到它们。\nHiveCatalog 可以用来处理两种表。Hive 兼容表和通用表。Hive-compatible 表是指那些以 Hive 兼容的方式存储的表，在存储层的元数据和数据方面都是如此。因此，通过 Flink 创建的 Hive 兼容表可以从 Hive 端进行查询。\n而通用表则是针对 Flink 的。当使用 HiveCatalog 创建通用表时，我们只是使用 HMS 来持久化元数据。虽然这些表对 Hive 是可见的，但 Hive 不太可能理解这些元数据。因此在 Hive 中使用这样的表会导致未定义的行为。\nFlink 使用属性 \u0026ldquo;is_generic\u0026rdquo; 来判断一个表是与 Hive 兼容还是通用。当用 HiveCatalog 创建一个表时，它默认被认为是通用的。如果你想创建一个 Hive 兼容的表，请确保在你的表属性中把 is_generic 设置为 false。\n如上所述，通用表不应该从 Hive 使用。在 Hive CLI 中，你可以调用 describe FORMATTED 对一个表进行检查，通过检查 is_generic 属性来决定它是否是通用的。通用表会有 is_generic=true。\n例子 我们在这里将通过一个简单的例子进行讲解。\n第 1 步：设置 Hive Metastore。\n有一个 Hive Metastore 在运行。\n在这里，我们在本地路径 /opt/hive-conf/hive-site.xml 中设置一个本地 Hive Metastore 和我们的 hive-site.xml 文件。我们有如下的一些配置。\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;javax.jdo.option.ConnectionURL\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;metadata is stored in a MySQL server\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;javax.jdo.option.ConnectionDriverName\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;com.mysql.jdbc.Driver\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;MySQL JDBC driver class\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;javax.jdo.option.ConnectionUserName\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;...\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;user name for connecting to mysql server\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;javax.jdo.option.ConnectionPassword\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;...\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;password for connecting to mysql server\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hive.metastore.uris\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;thrift://localhost:9083\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;IP address (or fully-qualified domain name) and port of the metastore host\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hive.metastore.schema.verification\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 用 Hive Cli 测试连接到 HMS。运行一些命令，我们可以看到我们有一个名为 default 的数据库，里面没有表。\nhive\u0026gt; show databases; OK default Time taken: 0.032 seconds, Fetched: 1 row(s) hive\u0026gt; show tables; OK Time taken: 0.028 seconds, Fetched: 0 row(s) 步骤 2：配置 Flink 集群和 SQL CLI\n将所有 Hive 的依赖关系添加到 Flink 发行版的 /lib 目录下，并修改 SQL CLI 的 yaml 配置文件 sql-cli-defaults.yaml 如下。\nexecution: planner: blink type: streaming ... current-catalog: myhive # set the HiveCatalog as the current catalog of the session current-database: mydatabase catalogs: - name: myhive type: hive hive-conf-dir: /opt/hive-conf # contains hive-site.xml 第三步：建立 Kafka 集群\nBootstrap 一个本地的 Kafka 2.3.0 集群，主题命名为 \u0026ldquo;test\u0026rdquo;，并以 name 和 age 的元组形式向主题产生一些简单的数据。\nlocalhost$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test \u0026gt;tom,15 \u0026gt;john,21 这些消息可以通过启动 Kafka 控制台消费者看到。\nlocalhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning tom,15 john,21 第四步：启动 SQL Client，用 Flink SQL DDL 创建一个 Kafka 表。\n启动 Flink SQL Client，通过 DDL 创建一个简单的 Kafka 2.3.0 表，并验证其模式。\nFlink SQL\u0026gt; CREATE TABLE mykafka (name String, age Int) WITH ( \u0026#39;connector.type\u0026#39; = \u0026#39;kafka\u0026#39;, \u0026#39;connector.version\u0026#39; = \u0026#39;universal\u0026#39;, \u0026#39;connector.topic\u0026#39; = \u0026#39;test\u0026#39;, \u0026#39;connector.properties.bootstrap.servers\u0026#39; = \u0026#39;localhost:9092\u0026#39;, \u0026#39;format.type\u0026#39; = \u0026#39;csv\u0026#39;, \u0026#39;update-mode\u0026#39; = \u0026#39;append\u0026#39; ); [INFO] Table has been created. Flink SQL\u0026gt; DESCRIBE mykafka; root |-- name: STRING |-- age: INT 验证该表也是通过 Hive Cli 对 Hive 可见的，注意该表有属性 is_generic=true。\nhive\u0026gt; show tables; OK mykafka Time taken: 0.038 seconds, Fetched: 1 row(s) hive\u0026gt; describe formatted mykafka; OK # col_name data_type comment # Detailed Table Information Database: default Owner: null CreateTime: ...... LastAccessTime: UNKNOWN Retention: 0 Location: ...... Table Type: MANAGED_TABLE Table Parameters: flink.connector.properties.bootstrap.servers\tlocalhost:9092 flink.connector.topic\ttest flink.connector.type\tkafka flink.connector.version\tuniversal flink.format.type csv flink.generic.table.schema.0.data-type\tVARCHAR(2147483647) flink.generic.table.schema.0.name\tname flink.generic.table.schema.1.data-type\tINT flink.generic.table.schema.1.name\tage flink.update-mode append is_generic true transient_lastDdlTime\t...... # Storage Information SerDe Library: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe InputFormat: org.apache.hadoop.mapred.TextInputFormat OutputFormat: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat Compressed: No Num Buckets: -1 Bucket Columns: [] Sort Columns: [] Storage Desc Params: serialization.format\t1 Time taken: 0.158 seconds, Fetched: 36 row(s) 第五步：运行 Flink SQL 查询 Kakfa 表。\n在 Flink 集群中，无论是单机还是 yarn-session，从 Flink SQL Client 中运行一个简单的选择查询。\nFlink SQL\u0026gt; select * from mykafka; 在 Kafka 主题中多产生一些信息。\nlocalhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning tom,15 john,21 kitty,30 amy,24 kaiky,18 你现在应该可以在 SQL Client 中看到 Flink 产生的结果，如。\nSQL Query Result (Table) Refresh: 1 s Page: Last of 1 name age tom 15 john 21 kitty 30 amy 24 kaiky 18 支持的类型 HiveCatalog 支持通用表的所有 Flink 类型。\n对于 Hive 兼容的表，HiveCatalog 需要将 Flink 数据类型映射到相应的 Hive 类型，如下表所述。\nFlink Data Type Hive Data Type CHAR(p) CHAR(p) VARCHAR(p) VARCHAR(p) STRING STRING BOOLEAN BOOLEAN TINYINT TINYINT SMALLINT SMALLINT INT INT BIGINT LONG FLOAT FLOAT DOUBLE DOUBLE DECIMAL(p, s) DECIMAL(p, s) DATE DATE TIMESTAMP(9) TIMESTAMP BYTES BINARY ARRAY LIST MAP\u0026lt;K, V\u0026gt; MAP\u0026lt;K, V\u0026gt; ROW STRUCT 关于类型映射需要注意的地方。\nHive 的 CHAR(p) 最大长度为 255。 Hive 的 VARCHAR(p) 最大长度为 65535。 Hive 的 MAP 只支持基元键类型，而 Flink 的 MAP 可以是任何数据类型。 不支持 Hive 的 UNION 类型。 Hive 的 TIMESTAMP 的精度总是 9，不支持其他精度。而 Hive 的 UDF 则可以处理精度\u0026lt;=9 的 TIMESTAMP 值。 Hive 不支持 Flink 的 TIMESTAMP_WITH_TIME_ZONE、TIMESTAMP_WITH_LOCAL_TIME_ZONE 和 MULTISET。 Flink 的 INTERVAL 类型还不能映射到 Hive 的 INTERVAL 类型。 Scala Shell 注意：由于目前 Scala Shell 并不支持 blink planner，所以不建议在 Scala Shell 中使用 Hive 连接器。\n原文链接: https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_catalog.html\n"},"name":"HiveCatalog","published":"2020-08-25T00:00:00Z","summary":"HiveCatalog","type":"entry","url":"https://ohmycloud.github.io/notes/2020-08-25-hivecatalog/"}