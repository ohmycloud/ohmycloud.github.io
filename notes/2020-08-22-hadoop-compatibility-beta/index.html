<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    
    
    

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">

    
    <meta name="referrer" content="no-referrer">

    <title>
        
            Hadoop 的兼容性 ❚ 焉知非鱼
        
    </title>

    
    


    
    
    
    

    
    
    
    

    
    
    

    
    
    
    <style>
     
     
     :root {
         --theme-color: #ac4142;
         --theme-color-light: rgba(172, 65, 66, 0.2);
     }
     
     html {
         line-height: 1.5;
     }
    </style>

    
    

    
    
    
    
    <link rel="stylesheet" href="/css/refined.min.61b1de55623520dab99b70e9e2298001fb97241583a47396e2f10feb789e300d.css">
    
    <link rel="preload" href="/css/refined.min.61b1de55623520dab99b70e9e2298001fb97241583a47396e2f10feb789e300d.css" as="style">

    



    
        <style>
         
         /* Background */ .chroma { background-color: #ffffff }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

         
         /* Overrides on top of the theme and Chroma CSS */
/* Chroma-based lines highlighting in code blocks */
.chroma .hl {
    background-color: #e8e8e8;
    /* Extend highlight up to 100 characters (assuming that the code blocks never have more than 100 characters in a line) */
    min-width: 100ch;
}
/* GenericHeading */ .chroma .gh { color: #999999; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa; font-weight: bold }

         
        </style>
    

    

    
    
    

    
    <script src="/js/responsive-nav-orig.min.355eebd835ac8071d56b337f68ffbbddc0f6487625599895e3e0b0461e791ebb.js"></script>
    
    <link rel="preload" href="/js/responsive-nav-orig.min.355eebd835ac8071d56b337f68ffbbddc0f6487625599895e3e0b0461e791ebb.js" as="script">

    
    
    <script defer src="/js/libs/fa/fontawesome-all.min.78bd3583027f40ce4330d39e1f1df56bda5f4af819aac2d0214ba529918c9e95.js"></script>
    
    <link rel="preload" href="/js/libs/fa/fontawesome-all.min.78bd3583027f40ce4330d39e1f1df56bda5f4af819aac2d0214ba529918c9e95.js" as="script">

    

    

    
    
    

    
    
<!-- rel="me" links for IndieAuth -->







    
 
<meta property="og:title" content="Hadoop 的兼容性" />
<meta property="og:description"
      content="Hadoop Compatibility Beta" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/" />


    
        <meta property="article:published_time" content="2020-08-22T00:00:00&#43;08:00"/>
    
    
        <meta property="article:modified_time" content="2020-08-22T00:00:00&#43;08:00"/>
    









    




     <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Hadoop 的兼容性"/>
<meta name="twitter:description" content="Hadoop Compatibility Beta"/>


    
    
    <link rel="alternate" type="application/jf2post+json" href="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/jf2post.json" title="Jf2post for 焉知非鱼" />
    
     



    
    
    
        
    


     
        
        <meta name="DC.Creator" content="焉知非鱼"/>
    



    
    
    
    <meta name="hugo-build-date" content=""/>
    <meta name="hugo-commit-hash" content=""/>
    <meta name="generator" content="Hugo 0.79.0" />
</head>


    
        <body lang="en">
    

        
        <div class="border" id="home"></div>

        <div class="wrapper">   
            
<nav id="nav" class="nav-collapse opened" aria-hidden="false">
    <ul class="navbar">
        <li><a class="" href="/">Home</a></li>
        
            
                <li><a class="" href="https://ohmyweekly.github.io/posts/">Posts</a></li>
            
        
            
                <li><a class="" href="https://ohmyweekly.github.io/notes/">Notes</a></li>
            
        
        
            <li><a class="" href="https://ohmyweekly.github.io/search/">Search</a></li>
        
    </ul>
</nav>

            <div class="container">
                <header class="masthead">
                    <div class="masthead-title no-text-decoration">
                        <a href="/">焉知非鱼</a> <span class="blinking-cursor">❚</span>
                    </div>
                    <div class="masthead-tagline">
                        rakulang, dartlang, nimlang, golang, rustlang, lang lang no see
                    </div>
                </header>

                








<article class="post h-entry notes">
    <header>
        <div class="center">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__flink__"
                                
                                
                                title="See all 75 posts categorized in ‘Flink’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/flink/">Flink</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__flink__"
                                
                                
                                title="See all 93 posts tagged with ‘Flink’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/flink/">Flink</a>
                            </li>
                        
                    
                        
                        
                        
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__dataset-api__"
                                
                                
                                title="See all 7 posts tagged with ‘DataSet API’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/dataset-api/">DataSet API</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>

        <h1 class="post-title p-name">Hadoop 的兼容性</h1>

        
        <data class="u-url" value="https://ohmyweekly.github.io/notes/2020-08-22-hadoop-compatibility-beta/"></data>

        <div class="date-syndication">
            


    
    
    <div class="post-date">
        
        <time datetime="2020-08-22T00:00:00+0800" class="dt-published">Sat Aug 22, 2020</time>
        
        
    </div>


            




        </div>
         



    
    
    
        
    


    
        
        <span class="hide">
            &mdash; <a href="https://ohmyweekly.github.io" class="u-author">焉知非鱼</a>
        </span>
    


    </header>

    <div class="content">
        
    <div class="description p-summary">
        
        
        
        
        
            
            
        
        <p>Hadoop Compatibility Beta</p>
    </div>



        





                       


        <div class="e-content">
            




<h2 id="hadoop-兼容性测试版">Hadoop 兼容性测试版&nbsp;<a class="headline-hash no-text-decoration" href="#hadoop-兼容性测试版">#</a> </h2>
<p>Flink 与 Apache Hadoop MapReduce 接口兼容，因此允许重用为 Hadoop MapReduce 实现的代码。</p>
<p>您可以:</p>
<ul>
<li>在 Flink 程序中使用 Hadoop 的可写<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/types_serialization.html#supported-data-types">数据类型</a>。</li>
<li>使用任何 Hadoop InputFormat 作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#data-sources">数据源</a>。</li>
<li>使用任何 Hadoop 输出格式作为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/index.html#data-sinks">数据接收器</a>。</li>
<li>将 Hadoop Mapper 用作 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunction</a>。</li>
<li>使用 Hadoop Reducer 作为 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunction</a>。</li>
</ul>
<p>本文档展示了如何将现有的 Hadoop MapReduce 代码与 Flink 一起使用。从 Hadoop 支持的文件系统读取代码，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/filesystems/index.html#hadoop-file-system-hdfs-and-its-other-implementations">连接到其他系统</a>指南。</p>
<h3 id="项目配置">项目配置&nbsp;<a class="headline-hash no-text-decoration" href="#项目配置">#</a> </h3>
<p>对 Hadoop 输入/输出格式的支持是 flink-java 和 flink-scala Maven 模块的一部分，这些模块在编写 Flink 作业时总是需要的。这些代码位于 <code>org.apache.flink.api.java.hadoop</code> 和 <code>org.apache.flink.api.scala.hadoop</code> 中的 mapred 和 mapreduce API 的附加子包中。</p>
<p>对 Hadoop Mappers 和 Reducers 的支持包含在 <code>flink-hadoop-compatibility</code> Maven 模块中。这段代码位于 <code>org.apache.flink.hadoopcompatibility</code> 包中。</p>
<p>如果您想重用 Mappers 和 Reducers，请在 pom.xml 中添加以下依赖关系。</p>
<div class="highlight"><pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>flink-hadoop-compatibility_2.11<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>1.11.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div><p>另请参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/hadoop.html#add-hadoop-classpaths">如何配置 hadoop 依赖关系</a>。</p>
<h3 id="使用-hadoop-输入格式">使用 Hadoop 输入格式&nbsp;<a class="headline-hash no-text-decoration" href="#使用-hadoop-输入格式">#</a> </h3>
<p>要使用 Flink 的 Hadoop InputFormats，必须先使用 HadoopInputs 实用程序类的 readHadoopFile 或 createHadoopInput 来包装格式。前者用于从 FileInputFormat 派生的输入格式，而后者必须用于通用的输入格式。通过使用 <code>ExecutionEnvironmen#createInput</code>，产生的 InputFormat 可以用来创建数据源。</p>
<p>生成的 DataSet 包含 2 个元组，其中第一个字段是键，第二个字段是从 Hadoop InputFormat 中检索的值。</p>
<p>下面的示例展示了如何使用 Hadoop 的 TextInputFormat。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">LongWritable</span>, <span class="kt">Text</span><span class="o">)]</span> <span class="k">=</span>
  <span class="n">env</span><span class="o">.</span><span class="n">createInput</span><span class="o">(</span><span class="nc">HadoopInputs</span><span class="o">.</span><span class="n">readHadoopFile</span><span class="o">(</span>
                    <span class="k">new</span> <span class="nc">TextInputFormat</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">LongWritable</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Text</span><span class="o">],</span> <span class="n">textPath</span><span class="o">))</span>

<span class="c1">// Do something with the data.
</span><span class="c1"></span><span class="o">[</span><span class="kt">...</span><span class="o">]</span>
</code></pre></div><h3 id="使用-hadoop-输出格式">使用 Hadoop 输出格式&nbsp;<a class="headline-hash no-text-decoration" href="#使用-hadoop-输出格式">#</a> </h3>
<p>Flink 为 Hadoop OutputFormat 提供了一个兼容性封装器，它支持任何实现 org.apache.hadoop.mapred.OutputFormat 或扩展 org.apache.hadoop.mapreduce.OutputFormat 的类。OutputFormat 包装器希望它的输入数据是一个包含2个key和value的 DataSet。这些数据将由 Hadoop OutputFormat 处理。</p>
<p>下面的示例展示了如何使用 Hadoop 的 TextOutputFormat。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Obtain your result to emit.
</span><span class="c1"></span><span class="k">val</span> <span class="n">hadoopResult</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">)]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>

<span class="k">val</span> <span class="n">hadoopOF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HadoopOutputFormat</span><span class="o">[</span><span class="kt">Text</span>,<span class="kt">IntWritable</span><span class="o">](</span>
  <span class="k">new</span> <span class="nc">TextOutputFormat</span><span class="o">[</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">],</span>
  <span class="k">new</span> <span class="nc">JobConf</span><span class="o">)</span>

<span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&#34;mapred.textoutputformat.separator&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">)</span>
<span class="nc">FileOutputFormat</span><span class="o">.</span><span class="n">setOutputPath</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">resultPath</span><span class="o">))</span>

<span class="n">hadoopResult</span><span class="o">.</span><span class="n">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">)</span>
</code></pre></div><h3 id="使用-hadoop-mappers-和-reducers">使用 Hadoop Mappers 和 Reducers&nbsp;<a class="headline-hash no-text-decoration" href="#使用-hadoop-mappers-和-reducers">#</a> </h3>
<p>Hadoop Mappers 在语义上等同于 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunctions</a>，Hadoop Reducers 等同于 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunctions</a>。Flink 为 Hadoop MapReduce 的 Mapper 和 Reducer 接口的实现提供了封装器，也就是说，你可以在常规的 Flink 程序中重用你的 Hadoop Mapper 和 Reducer。目前，只支持 Hadoop 的 mapred API（org.apache.hadoop.mapred）的 Mapper 和 Reduce 接口。</p>
<p>包装器将一个 <code>DataSet&lt;Tuple2&lt;KEYIN,VALUEIN&gt;</code> 作为输入，并产生一个 <code>DataSet&lt;Tuple2&lt;KEYOUT,VALUEOUT&gt;</code> 作为输出，其中 KEYIN 和 KEYOUT 是键，VALUEIN 和 VALUEOUT 是 Hadoop 函数处理的 Hadoop 键值对的值。对于 Reducers，Flink 提供了一个包装器，用于带（HadoopReduceCombineFunction）和不带 Combiner（HadoopReduceFunction）的 GroupReduceFunction。包装器接受一个可选的 JobConf 对象来配置 Hadoop Mapper 或 Reducer。</p>
<p>Flink 的函数包装器有:</p>
<ul>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopMapFunction,</li>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopReduceFunction, 和</li>
<li>sorg.apache.flink.hadoopcompatibility.mapred.HadoopReduceCombineFunction.</li>
</ul>
<p>并可作为常规的 Flink <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#flatmap">FlatMapFunctions</a> 或 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunctions</a> 使用。</p>
<p>下面的例子展示了如何使用 Hadoop Mapper 和 Reducer 函数:</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="c1">// Obtain data to process somehow.
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// use Hadoop Mapper (Tokenizer) as MapFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
  <span class="c1">// use Hadoop Reducer (Counter) as Reduce- and CombineFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="n">Counter</span><span class="o">()</span>
  <span class="o">));</span>
</code></pre></div><p>请注意：Reducer 包装器工作在 Flink 的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/dataset_transformations.html#transformations-on-grouped-dataset">groupBy()</a> 操作所定义的组上。它不考虑您在 JobConf 中设置的任何自定义分区器、排序或分组比较器。</p>
<h3 id="完整的-hadoop-wordcount-示例">完整的 Hadoop WordCount 示例&nbsp;<a class="headline-hash no-text-decoration" href="#完整的-hadoop-wordcount-示例">#</a> </h3>
<p>下面的示例展示了使用 Hadoop 数据类型、Input-和 OutputFormats 以及 Mapper 和 Reducer 实现的完整 WordCount 实现。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// Set up the Hadoop TextInputFormat.
</span><span class="c1"></span><span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span>
<span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="n">hadoopIF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">TextInputFormat</span><span class="o">(),</span> <span class="n">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">TextInputFormat</span><span class="o">.</span><span class="na">addInputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">inputPath</span><span class="o">));</span>

<span class="c1">// Read data using the Hadoop TextInputFormat.
</span><span class="c1"></span><span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span><span class="n">hadoopIF</span><span class="o">);</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// use Hadoop Mapper (Tokenizer) as MapFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="n">0</span><span class="o">)</span>
  <span class="c1">// use Hadoop Reducer (Counter) as Reduce- and CombineFunction
</span><span class="c1"></span>  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="n">Counter</span><span class="o">()</span>
  <span class="o">));</span>

<span class="c1">// Set up the Hadoop TextOutputFormat.
</span><span class="c1"></span><span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;</span> <span class="n">hadoopOF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">TextOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(),</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">hadoopOF</span><span class="o">.</span><span class="na">getConfiguration</span><span class="o">().</span><span class="na">set</span><span class="o">(</span><span class="s">&#34;mapreduce.output.textoutputformat.separator&#34;</span><span class="o">,</span> <span class="s">&#34; &#34;</span><span class="o">);</span>
<span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">));</span>

<span class="c1">// Emit data using the Hadoop TextOutputFormat.
</span><span class="c1"></span><span class="n">result</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">);</span>

<span class="c1">// Execute Program
</span><span class="c1"></span><span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&#34;Hadoop WordCount&#34;</span><span class="o">);</span>
</code></pre></div><p>原文链接: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/hadoop_compatibility.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/batch/hadoop_compatibility.html</a></p>


        </div>
    </div>
</article>



                <footer>
                    




<div class="no-text-decoration">
    <div class="jump top"><a href="#" title="Top of this page">⮉</a></div>
    <div class="jump bottom"><a href="#bottom" title="Bottom of this page">⮋</a></div>
</div>


 
    
        <div class="hugotoc no-text-decoration">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#hadoop-兼容性测试版">Hadoop 兼容性测试版</a>
      <ul>
        <li><a href="#项目配置">项目配置</a></li>
        <li><a href="#使用-hadoop-输入格式">使用 Hadoop 输入格式</a></li>
        <li><a href="#使用-hadoop-输出格式">使用 Hadoop 输出格式</a></li>
        <li><a href="#使用-hadoop-mappers-和-reducers">使用 Hadoop Mappers 和 Reducers</a></li>
        <li><a href="#完整的-hadoop-wordcount-示例">完整的 Hadoop WordCount 示例</a></li>
      </ul>
    </li>
  </ul>
</nav>
            <a href="#" class="back-to-top">Back to top</a>
        </div>
    
    
<script src="/js/libs/jquery/3.3.1/jquery.slim.min.min.528a9ce56371729e50605653bf72b1e933574cdb97519529bf8fab01b63f9703.js"></script>

<link rel="preload" href="/js/libs/jquery/3.3.1/jquery.slim.min.min.528a9ce56371729e50605653bf72b1e933574cdb97519529bf8fab01b63f9703.js" as="script">

<script type="application/javascript">(function() {
     var $window = $(window);
     if ($window.width() >= 1400) { 
         var $toc = $('#TableOfContents');
         if ($toc.length > 0) {
             function onScroll(){
                 var currentScroll = $window.scrollTop();
                 var h = $('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .h-feed h2');
                 var id = "";
                 h.each(function (i, e) {
                     e = $(e);
                     if (e.offset().top - 10 <= currentScroll) {
                         id = e.attr('id');
                     }
                 });
                 var current = $toc.find('a.current');
                 if (current.length == 1 && current.eq(0).attr('href') == '#' + id) return true;

                 current.each(function (i, e) {
                     $(e).removeClass('current').siblings('ul').hide();
                 });
                 $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                     $(e).children('a').addClass('current').siblings('ul').show();
                 });
             }
             $window.on('scroll', onScroll);
             $(document).ready(function() {
                 $toc.find('a').parent('li').find('ul').hide();
                 onScroll();
                 document.getElementsByClassName('hugotoc')[0].style.display = '';
             });}}})();</script>








<div class="backtotop center no-text-decoration">
    <a href="#">back to <span class="top">top</span></a>
</div>


<div class="right">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__flink__"
                                
                                
                                title="See all 75 posts categorized in ‘Flink’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/categories/flink/">Flink</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__flink__"
                                
                                
                                title="See all 93 posts tagged with ‘Flink’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/flink/">Flink</a>
                            </li>
                        
                    
                        
                        
                        
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__dataset-api__"
                                
                                
                                title="See all 7 posts tagged with ‘DataSet API’"
                                
                            >
                                <a class="p-category" href="https://ohmyweekly.github.io/tags/dataset-api/">DataSet API</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>
<div class="clear-float"></div>



<div class="prev-next-navigator clear-float">
    
        <span class="prev-post left no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/2020-08-22-flink-dataset-api-programming-guide/" class="nobr">« Flink Dataset API 编程指南</a>
        </span>
    
    
        <span class="next-post right no-text-decoration">
            <a href="https://ohmyweekly.github.io/notes/2020-08-22-insert-statements/" class="nobr">Insert 语句 »</a>
        </span>
    
</div>


<a id="bottom"></a>









                       







                    <ul class="no-bullets feed right inline">
    
        
        
    
</ul>
<div class="clear-float"></div>

                </footer>
                <hr />
            </div>               

            <footer> 
                

<ul class="social no-text-decoration">
    
</ul>













<p class="generated no-text-decoration">
    Generated using  <a href="https://gitlab.com/kaushalmodi/hugo-theme-refined"><code class="nobr">hugo-theme-refined</code></a> + <span class="nobr">Hugo 0.79.0</span>
</p>

<p>
    
</p>




<div class="badges no-text-decoration">
    
    

    
</div>




<script type="application/javascript">var nav=responsiveNav("#nav");</script>




<script defer src="/js/libs/fragmentions/wrapper.min.4c511209cd3786314b251d891c8da528b47a972669aa4eea416b64d4be01eee2.js"></script>









            </footer>
        </div> 
    </body>
</html>
