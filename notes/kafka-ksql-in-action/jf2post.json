{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io/"},"content":{"html":"\u003cp\u003e有一次, 在威马项目, 项目经理说, xxx, 你能不能给我查一下 kafka 中, 这个车某一时间段的数据？ 我说不好查, 查询 Kafka 中某一条记录, 需要 Consumer 程序来消费。虽然 \u003ca href=\"https://github.com/fgeller/kt\"\u003ekt\u003c/a\u003e 之类的 Kafka 命令行工具可以查询 Kafka 中数据. 但是能力有限, 它只能从某个 offset 开始查询, 满足不了我们的过滤条件。\u003c/p\u003e\n\u003cp\u003e幸运的是, \u003ca href=\"https://www.confluent.io/product/ksql/\"\u003eksql\u003c/a\u003e 可以让我们像查询 sql 一样来查询 kafka, 毕竟写 sql, 谁不会呢？于是我们到它的官网, 看到 ksql 这个产品的宣传是 \u003cstrong\u003eStreaming SQL for Apache Kafka\u003c/strong\u003e。 毕竟底层用的是 Kafka-Streams, 所以 ksql 支持流式查询。我们下载最新的 ksql。我们将程序解压到 ~/opt/confluent-5.0.0\u003c/p\u003e\n\u003ch2 id=\"启动-zk\"\u003e启动 zk\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebin/zookeeper-server-start -daemon etc/kafka/zookeeper.properties\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"启动-kafka\"\u003e启动 kafka\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebin/kafka-server-start -daemon etc/kafka/server.properties\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"创建-topic-和-data\"\u003e创建 topic 和 data\u003c/h2\u003e\n\u003cp\u003econfluent 自带了一个 ksql-datagen 工具，可以创建和产生相关的 topic 和数据，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e创建 pageviews，数据格式为 delimited\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0/bin\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e./ksql-datagen \u003cspan class=\"nv\"\u003equickstart\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003epageviews \u003cspan class=\"nv\"\u003eformat\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003edelimited \u003cspan class=\"nv\"\u003etopic\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003epageviews \u003cspan class=\"nv\"\u003emaxInterval\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e500\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e创建 users，数据格式为 json\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0/bin\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e./ksql-datagen \u003cspan class=\"nv\"\u003equickstart\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eusers \u003cspan class=\"nv\"\u003eformat\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ejson \u003cspan class=\"nv\"\u003etopic\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eusers \u003cspan class=\"nv\"\u003emaxInterval\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e100\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"启动-ksql\"\u003e启动 ksql\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebin/ksql-server-start -daemon etc/ksql/ksql-server.properties\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"连接-ksql\"\u003e连接 ksql\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebin/ksql http://127.0.0.1:8088\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"创建-stream-和-table\"\u003e创建 stream 和 table\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003estream\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e根据 topic pageviews 创建一个 stream 为 pageviews_original，value_format 为 DELIMITED\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt;CREATE STREAM pageviews_original \u003cspan class=\"o\"\u003e(\u003c/span\u003eviewtime bigint, userid varchar, pageid varchar\u003cspan class=\"o\"\u003e)\u003c/span\u003e WITH \u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"nv\"\u003ekafka_topic\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;pageviews\u0026#39;\u003c/span\u003e, \u003cspan class=\"nv\"\u003evalue_format\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;DELIMITED\u0026#39;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003etable\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e根据 topic users 创建一个 table 为 users_original，value_format 为 json\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt;CREATE TABLE users_original \u003cspan class=\"o\"\u003e(\u003c/span\u003eregistertime BIGINT, gender VARCHAR, regionid VARCHAR, userid VARCHAR\u003cspan class=\"o\"\u003e)\u003c/span\u003e WITH \u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"nv\"\u003ekafka_topic\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;users\u0026#39;\u003c/span\u003e, \u003cspan class=\"nv\"\u003evalue_format\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;JSON\u0026#39;\u003c/span\u003e, \u003cspan class=\"nv\"\u003ekey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;userid\u0026#39;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"查询数据\"\u003e查询数据\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; SELECT * FROM USERS_ORIGINAL LIMIT 3\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; SELECT * FROM pageviews_original LIMIT 3\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eksql 默认是从 kafka 最新的数据查询消费的，如果你想从开头查询，则需要在会话上进行设置：SET \u0026lsquo;auto.offset.reset\u0026rsquo; = \u0026rsquo;earliest\u0026rsquo;;\u003c/p\u003e\n\u003ch2 id=\"持久化查询\"\u003e持久化查询\u003c/h2\u003e\n\u003cp\u003e持久化查询可以源源不断的把查询出的数据发送到你指定的 topic 中去，查询的时候在 select 前面添加 create stream 关键字即可创建持久化查询。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; CREATE STREAM pageviews2 AS SELECT userid FROM pageviews_original\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e查询新 stream\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; SHOW STREAMS\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e可以看到新创建了stream PAGEVIEWS2，并且创建了topic PAGEVIEWS2\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e查询执行任务\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; SHOW QUERIES\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e可以看到 ID 为 CSAS_PAGEVIEWS2_0 的任务在执行，并且有显示执行的语句。\u003c/p\u003e\n\u003ch2 id=\"消费新数据\"\u003e消费新数据\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e \u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ~/opt/confluent-5.0.0/bin\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e./kafka-console-consumer --bootstrap-server 10.205.151.145:9092 --from-beginning --topic PAGEVIEWS2\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e可以看到PAGEVIEWS2 topic里面正是我们通过select筛选出来的数据\u003c/p\u003e\n\u003ch2 id=\"终止查询任务\"\u003e终止查询任务\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eksql\u0026gt; TERMINATE CSAS_PAGEVIEWS2_0\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","text":"有一次, 在威马项目, 项目经理说, xxx, 你能不能给我查一下 kafka 中, 这个车某一时间段的数据？ 我说不好查, 查询 Kafka 中某一条记录, 需要 Consumer 程序来消费。虽然 kt 之类的 Kafka 命令行工具可以查询 Kafka 中数据. 但是能力有限, 它只能从某个 offset 开始查询, 满足不了我们的过滤条件。\n幸运的是, ksql 可以让我们像查询 sql 一样来查询 kafka, 毕竟写 sql, 谁不会呢？于是我们到它的官网, 看到 ksql 这个产品的宣传是 Streaming SQL for Apache Kafka。 毕竟底层用的是 Kafka-Streams, 所以 ksql 支持流式查询。我们下载最新的 ksql。我们将程序解压到 ~/opt/confluent-5.0.0\n启动 zk cd ~/opt/confluent-5.0.0 bin/zookeeper-server-start -daemon etc/kafka/zookeeper.properties 启动 kafka cd ~/opt/confluent-5.0.0 bin/kafka-server-start -daemon etc/kafka/server.properties 创建 topic 和 data confluent 自带了一个 ksql-datagen 工具，可以创建和产生相关的 topic 和数据，\n创建 pageviews，数据格式为 delimited cd ~/opt/confluent-5.0.0/bin ./ksql-datagen quickstart=pageviews format=delimited topic=pageviews maxInterval=500 创建 users，数据格式为 json cd ~/opt/confluent-5.0.0/bin ./ksql-datagen quickstart=users format=json topic=users maxInterval=100 启动 ksql cd ~/opt/confluent-5.0.0/ bin/ksql-server-start -daemon etc/ksql/ksql-server.properties 连接 ksql cd ~/opt/confluent-5.0.0/ bin/ksql http://127.0.0.1:8088 创建 stream 和 table stream 根据 topic pageviews 创建一个 stream 为 pageviews_original，value_format 为 DELIMITED\nksql\u0026gt;CREATE STREAM pageviews_original (viewtime bigint, userid varchar, pageid varchar) WITH (kafka_topic=\u0026#39;pageviews\u0026#39;, value_format=\u0026#39;DELIMITED\u0026#39;); table 根据 topic users 创建一个 table 为 users_original，value_format 为 json\nksql\u0026gt;CREATE TABLE users_original (registertime BIGINT, gender VARCHAR, regionid VARCHAR, userid VARCHAR) WITH (kafka_topic=\u0026#39;users\u0026#39;, value_format=\u0026#39;JSON\u0026#39;, key = \u0026#39;userid\u0026#39;); 查询数据 ksql\u0026gt; SELECT * FROM USERS_ORIGINAL LIMIT 3; ksql\u0026gt; SELECT * FROM pageviews_original LIMIT 3; ksql 默认是从 kafka 最新的数据查询消费的，如果你想从开头查询，则需要在会话上进行设置：SET \u0026lsquo;auto.offset.reset\u0026rsquo; = \u0026rsquo;earliest\u0026rsquo;;\n持久化查询 持久化查询可以源源不断的把查询出的数据发送到你指定的 topic 中去，查询的时候在 select 前面添加 create stream 关键字即可创建持久化查询。\nksql\u0026gt; CREATE STREAM pageviews2 AS SELECT userid FROM pageviews_original; 查询新 stream ksql\u0026gt; SHOW STREAMS; 可以看到新创建了stream PAGEVIEWS2，并且创建了topic PAGEVIEWS2\n查询执行任务 ksql\u0026gt; SHOW QUERIES; 可以看到 ID 为 CSAS_PAGEVIEWS2_0 的任务在执行，并且有显示执行的语句。\n消费新数据 cd cd ~/opt/confluent-5.0.0/bin ./kafka-console-consumer --bootstrap-server 10.205.151.145:9092 --from-beginning --topic PAGEVIEWS2 可以看到PAGEVIEWS2 topic里面正是我们通过select筛选出来的数据\n终止查询任务 ksql\u0026gt; TERMINATE CSAS_PAGEVIEWS2_0; "},"name":"Kafka KSQL 用例","published":"2019-05-15T15:18:18Z","summary":"有一次, 在威马项目, 项目经理说, xxx, 你能不能给我查一下 kafka 中, 这个车某一时间段的数据？ 我说不好查, 查询 Kafka 中某一条记录, 需要 Consumer 程序来消费。虽然 kt 之类的 Kafka 命令行工具可以查询 Kafka 中数据. 但是能力有限, 它只能从某个 offset 开始查询, 满足不了我们的过滤条件。\n幸运的是, ksql 可以让我们像查询 sql 一样来查询 kafka, 毕竟写 sql, 谁不会呢？于是我们到它的官网, 看到 ksql 这个产品的宣传是 Streaming SQL for Apache Kafka。 毕竟底层用的是 Kafka-Streams, 所以 ksql 支持流式查询。我们下载最新的 ksql。我们将程序解压到 ~/opt/confluent-5.0.0\n启动 zk cd ~/opt/confluent-5.0.0 bin/zookeeper-server-start -daemon etc/kafka/zookeeper.properties 启动 kafka cd ~/opt/confluent-5.0.0 bin/kafka-server-start -daemon etc/kafka/server.properties 创建 topic 和 data confluent 自带了一个 ksql-datagen 工具，可以创建和产生相关的 topic 和数据，","type":"entry","url":"https://ohmyweekly.github.io/notes/kafka-ksql-in-action/"}