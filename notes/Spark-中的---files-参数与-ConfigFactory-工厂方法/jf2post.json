{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io/"},"content":{"html":"\u003ch2 id=\"spark-中的---files-参数与-configfactory-工厂方法\"\u003eSpark 中的 \u0026ndash;files 参数与 ConfigFactory 工厂方法\u003c/h2\u003e\n\u003ch2 id=\"scala-对象\"\u003escala 对象\u003c/h2\u003e\n\u003cp\u003e以前有个大数据项目做小程序统计，读取 HDFS 上的 Parquet 文件，统计完毕后，将结果写入到 MySQL 数据库。首先想到的是将 MySQL 的配置写在代码里面:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003ejdbcUrl\u003c/span\u003e  \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;jdbc:mysql://127.0.0.1:6606/test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;useSSL=false\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003euser\u003c/span\u003e     \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;root\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003epassword\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;averyloooooongword\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003edriver\u003c/span\u003e   \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;com.mysql.jdbc.Driver\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"properties-文件\"\u003eproperties 文件\u003c/h2\u003e\n\u003cp\u003e如果是测试，生产环境各有一套，那上面的代码就要分别复制俩份，不便于维护！后来知道了可以把配置放在 \u003ccode\u003eresources\u003c/code\u003e 目录下, 针对本地，测试和生产环境，分别创建不同的 \u003cstrong\u003eproperties\u003c/strong\u003e 文件：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003econf.properties  \nconf_product.properties \nenv.properties  \nlocal.properties\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e例如其中的 \u003cstrong\u003econf.properties\u003c/strong\u003e 内容如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e#  测试环境配置\n\n## 数据库配置\njdbc.url=jdbc:mysql://10.0.0.11:3306/ald_xinen_test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\njdbc.user=aldwx\njdbc.pwd=123456\njdbc.driver=com.mysql.jdbc.Driver\n\n# parquet 文件目录\ntongji.parquet=hdfs://10.0.0.212:9000/ald_log_parquet\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e然后在代码里面读取 resource 文件中的配置：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"cm\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e     * 根据 key 获取 properties 文件中的 value\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e     * @param key properties 文件中等号左边的键\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e     * @return 返回 properties 文件中等号右边的值\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e     */\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003egetProperty\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eProperties\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eproperties\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eProperties\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eInputStream\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ein\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eConfigurationUtil\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetClassLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"na\"\u003egetResourceAsStream\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egetEnvProperty\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;env.conf\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e            \u003c/span\u003e\u003cspan class=\"n\"\u003eproperties\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ein\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e            \u003c/span\u003e\u003cspan class=\"n\"\u003ein\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eclose\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecatch\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eIOException\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e            \u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintStackTrace\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eproperties\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这样解决了多个环境中配置不同的问题，只需要复制多个 properties 文件，根据需要修改就行。但是这种方法不是最优的，因为配置不是结构化的，而是通过注释分割了不同的配置。\u003c/p\u003e\n\u003ch2 id=\"conf-文件\"\u003econf 文件\u003c/h2\u003e\n\u003cp\u003eresources 目录下的文件如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eapplication.conf              \napplication.production.conf      \napplication.local.conf             \nlog4j.properties              \nmetrics.properties\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eConfigFactory\u003c/code\u003e 工厂方法默认会读取 \u003ccode\u003eresources\u003c/code\u003e 目录下面名为 \u003cstrong\u003eapplication.conf\u003c/strong\u003e 的文件：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# Spark 相关配置\nspark {\n  master                   = \u0026#34;local[2]\u0026#34;\n  streaming.batch.duration = 5001  // Would normally be `ms` in config but Spark just wants the Long\n  eventLog.enabled         = true\n  ui.enabled               = true\n  ui.port                  = 4040\n  metrics.conf             = metrics.properties\n  checkpoint.path          = \u0026#34;/tmp/checkpoint/telematics-local\u0026#34;\n  stopper.port             = 12345\n  spark.cleaner.ttl        = 3600\n  spark.cleaner.referenceTracking.cleanCheckpoints = true\n}\n\n# Kafka 相关配置\nkafka {\n\n  metadata.broker.list = \u0026#34;localhost:9092\u0026#34;\n  zookeeper.connect    = \u0026#34;localhost:2181\u0026#34;\n\n  topic.dtcdata {\n    name = \u0026#34;dc-diagnostic-report\u0026#34;\n    partition.num = 1      \n    replication.factor = 1  \n  }\n\n  group.id             = \u0026#34;group-rds\u0026#34;\n  timeOut              = \u0026#34;3000\u0026#34;\n  bufferSize           = \u0026#34;100\u0026#34;\n  clientId             = \u0026#34;telematics\u0026#34;\n  key.serializer.class = \u0026#34;kafka.serializer.StringEncoder\u0026#34;\n  serializer.class     = \u0026#34;com.wm.dtc.pipeline.kafka.SourceDataSerializer\u0026#34;\n//  serializer.class     = \u0026#34;kafka.serializer.DefaultEncoder\u0026#34;\n}\n\n# MySQL 配置\nmysql {\n  dataSource.maxLifetime              = 800000\n  dataSource.idleTimeout              = 600000\n  dataSource.maximumPoolSize          = 10\n  dataSource.cachePrepStmts           = true\n  dataSource.prepStmtCacheSize        = 250\n  dataSource.prepStmtCacheSqlLimit    = 204800\n  dataSource.useServerPrepStmts       = true\n  dataSource.useLocalSessionState     = true\n  dataSource.rewriteBatchedStatements = true\n  dataSource.cacheResultSetMetadata   = true\n  dataSource.cacheServerConfiguration = true\n  dataSource.elideSetAutoCommits      = true\n  dataSource.maintainTimeStats        = false\n\n  jdbcUrl=\u0026#34;jdbc:mysql://127.0.0.1:6606/wmdtc?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;useSSL=false\u0026#34;\n  jdbcDriver=\u0026#34;com.mysql.jdbc.Driver\u0026#34;\n  dataSource.user=\u0026#34;root\u0026#34;\n  dataSource.password=\u0026#34;123456\u0026#34;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e为了验证，我创建了一个 Object 对象：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003epackage\u003c/span\u003e \u003cspan class=\"nn\"\u003eallinone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecom.typesafe.config.ConfigFactory\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003escopt.OptionParser\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eobject\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkFilesArgs\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eApp\u003c/span\u003e  \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003econfig\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eConfigFactory\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003esparkConf\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetConfig\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;spark\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003esparkMaster\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esparkConf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetString\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;master\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003esparkDuration\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esparkConf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetLong\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;streaming.batch.duration\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esparkMaster\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esparkDuration\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e如果我直接运行就会打印：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e(local[2],5001)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e确实是 \u003cstrong\u003eapplication.conf\u003c/strong\u003e 文件中 Spark 的配置。\u003c/p\u003e\n\u003cp\u003e但是生产环境我们打算使用另外一个配置文件 \u003cstrong\u003eapplication.production.conf\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003espark {\n  master = \u0026#34;yarn\u0026#34;\n  streaming.batch.duration = 5002\n  eventLog.enabled=true\n  ui.enabled = true\n  ui.port = 4040\n  metrics.conf = metrics.properties\n  checkpoint.path = \u0026#34;/tmp/telematics\u0026#34;\n  stopper.port = 12345\n  spark.cleaner.ttl = 3600\n  spark.cleaner.referenceTracking.cleanCheckpoints = true\n\n  trajectory.path = \u0026#34;hdfs://CRRCNameservice/road_matching/output/road_match_result\u0026#34;\n  city.path = \u0026#34;hdfs://CRRCNameservice/user/root/telematics/data/city.csv\u0026#34;\n}\n\n##cassandra相关配置\ncassandra {\n  keyspace = wmdtc\n  cardata.name = can_signal\n  trip.name = trip\n  latest.name = latest\n  latest.interval = 15000\n\n  connection.host = \u0026#34;WMBigdata2,WMBigdata3,WMBigdata4,WMBigdata5,WMBigdata6\u0026#34;\n  write.consistency_level = LOCAL_ONE\n  read.consistency_level = LOCAL_ONE\n  concurrent.writes = 24\n  batch.size.bytes = 65536\n  batch.grouping.buffer.size = 1000\n  connection.keep_alive_ms = 300000\n  auth.username = cihon\n  auth.password = cihon\n}\n\nkafka {\n  metadata.broker.list = \u0026#34;WMBigdata2:9092,WMBigdata3:9092,WMBigdata4:9092,WMBigdata5:9092,WMBigdata6:9092\u0026#34;\n  zookeeper.connect = \u0026#34;WMBigdata2:2181,WMBigdata3:2181,WMBigdata4:2181\u0026#34;\n\n  topic.obddata {\n    name = \u0026#34;wmdtc\u0026#34;\n  }\n\n  group.id = \u0026#34;can_signal\u0026#34;\n  timeOut = \u0026#34;3000\u0026#34;\n  bufferSize = \u0026#34;100\u0026#34;\n  clientId = \u0026#34;telematics\u0026#34;\n\n  key.serializer.class = \u0026#34;kafka.serializer.StringEncoder\u0026#34;\n  serializer.class = \u0026#34;com.wm.telematics.pipeline.kafka.SourceDataSerializer\u0026#34;\n\n}\n\nakka {\n  loglevel = INFO\n  stdout-loglevel = WARNING\n  loggers = [\u0026#34;akka.event.slf4j.Slf4jLogger\u0026#34;]\n}\n\n##geoService接口URL\nwebservice {\n  url = \u0026#34;http://101.201.108.155:8088/map/roadmessage\u0026#34;\n}\n\n##geoService相关配置\ngeoservice {\n  timeout = 3\n  useRealData = false\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e既然 ConfigFactory 方法默认读取 \u003ccode\u003eapplication.conf\u003c/code\u003e 文件，但是\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eval config = ConfigFactory.load()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e相当于：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eval config = ConfigFactory.load(\u0026#34;application.conf\u0026#34;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e但是 \u003ccode\u003eload\u003c/code\u003e 方法也接受参数：\u003cem\u003eresourceBasename\u003c/em\u003e:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eval config = ConfigFactory.load(\u0026#34;application.production\u0026#34;) // 加载生产环境的配置\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e这样在代码里面通过加载不同的配置文件实现本地、测试、生产环境的切换和部署，但是在代码里面读取配置还是不够优美！所以我们有 Spark 的 \u003ccode\u003e--files\u003c/code\u003e 命令行选项。顾名思义，显而易见，也正如\u003ca href=\"http://spark.apache.org/docs/latest/submitting-applications.html\"\u003e官网\u003c/a\u003e所描述的那样, \u003ccode\u003e--files\u003c/code\u003e 参数后面的值是逗号分割的文本文件, 里面有一个 \u003cem\u003e.conf\u003c/em\u003e 文件, load 方法会加载 \u003ccode\u003e--files\u003c/code\u003e 选项传递过来的配置文件：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#!/bin/sh\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eCONF_DIR\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e/root/telematics/resources\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eAPP_CONF\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapplication.production.conf\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eEXECUTOR_JMX_PORT\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e23339\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eDRIVER_JMX_PORT\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e2340\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003espark-submit \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --name WM_telematics \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --class allinone.SparkFilesArgs \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --master local\u003cspan class=\"o\"\u003e[\u003c/span\u003e*\u003cspan class=\"o\"\u003e]\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --deploy-mode client \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --driver-memory 2g \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --driver-cores \u003cspan class=\"m\"\u003e2\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --executor-memory 1g \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --executor-cores \u003cspan class=\"m\"\u003e3\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --num-executors \u003cspan class=\"m\"\u003e3\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf \u003cspan class=\"s2\"\u003e\u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.port=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$EXECUTOR_JMX_PORT\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf \u003cspan class=\"s2\"\u003e\u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.port=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$DRIVER_JMX_PORT\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.executor.memoryOverhead\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e4096\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.driver.memoryOverhead\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e2048\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.yarn.maxAppAttempts\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e2\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.yarn.submit.waitAppCompletion\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nb\"\u003efalse\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.network.timeout\u003cspan class=\"o\"\u003e=\u003c/span\u003e1800s \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.scheduler.executorTaskBlacklistTime\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e30000\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.core.connection.ack.wait.timeout\u003cspan class=\"o\"\u003e=\u003c/span\u003e300s \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --files \u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e,\u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/log4j.properties,\u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/metrics.properties \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  /Users/ohmycloud/work/cihon/sxw/all-in-one/target/allinone-1.0-SNAPSHOT.jar\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e它打印：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e(local[*],5002)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e因为我在命令行选项中指定了 master 为 \u003ccode\u003elocal[*]\u003c/code\u003e, 配置文件为 \u003ccode\u003eapplication.production.conf\u003c/code\u003e。\u003c/p\u003e\n\u003ch2 id=\"resource-not-found-on-classpath-applicationconf\"\u003eresource not found on classpath: application.conf\u003c/h2\u003e\n\u003ch3 id=\"本地-localhost\"\u003e本地 localhost\u003c/h3\u003e\n\u003cp\u003ejar 包里面我把 application.conf 给删除了，用 \u003ccode\u003e--files\u003c/code\u003e 传参数给 spark-submit 的方式，但是报：在 classpath 下找不到 application.conf 这个文件了。\u003c/p\u003e\n\u003cp\u003ecat spark-submit.sh:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e#!/\u003c/span\u003e\u003cspan class=\"n\"\u003ebin\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003esh\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nc\"\u003eCONF_DIR\u003c/span\u003e\u003cspan class=\"o\"\u003e=/\u003c/span\u003e\u003cspan class=\"nc\"\u003eUsers\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003eohmycloud\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003ework\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003ecihon\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003egac\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003esources\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nc\"\u003eAPP_CONF\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eapplication\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nc\"\u003eEXECUTOR_JMX_PORT\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e23333\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nc\"\u003eDRIVER_JMX_PORT\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e2334\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003esubmit\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003e$1\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003emaster\u003c/span\u003e \u003cspan class=\"n\"\u003elocal\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"err\"\u003e2\u003c/span\u003e\u003cspan class=\"o\"\u003e]\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003edeploy\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e \u003cspan class=\"n\"\u003eclient\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003edriver\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003ememory\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"n\"\u003eg\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003edriver\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003ecores\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003ememory\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"n\"\u003eg\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003ecores\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003enum\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutors\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eyarn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ememoryOverhead\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eyarn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edriver\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ememoryOverhead\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eyarn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emaxAppAttempts\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eyarn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esubmit\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewaitAppCompletion\u003c/span\u003e\u003cspan class=\"k\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003efalse\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003efiles\u003c/span\u003e \u003cspan class=\"nc\"\u003e$CONF_DIR\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"nc\"\u003e$APP_CONF\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"nc\"\u003eUsers\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003eohmycloud\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003edemo\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"nc\"\u003eSpark\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"nc\"\u003eWriteParquet2Kafka\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003esocket\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003estructured\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003estreaming\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mf\"\u003e1.0\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"nc\"\u003eSNAPSHOT\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejar\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e原因是 \u003cstrong\u003eapplication.conf\u003c/strong\u003e 文件所在的路径 \u003cstrong\u003e/Users/ohmycloud/work/cihon/gac/sources\u003c/strong\u003e 不在 \u003cstrong\u003eclasspath\u003c/strong\u003e 里面！\u003c/p\u003e\n\u003cp\u003e使用\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e --driver-class-path /Users/ohmycloud/work/cihon/gac/sources \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e而非\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e --driver-class-path /Users/ohmycloud/work/cihon/gac/sources/application.conf \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e来添加 class path。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e#!/bin/sh\n\nCONF_DIR=/Users/ohmycloud/work/cihon/gac/sources\nAPP_CONF=application.conf\nEXECUTOR_JMX_PORT=23333\nDRIVER_JMX_PORT=2334\n\nspark-submit \\\n  --class $1 \\\n  --master local[2] \\\n  --deploy-mode client \\\n  --driver-memory 2g \\\n  --driver-cores 2 \\\n  --executor-memory 2g \\\n  --executor-cores 2 \\\n  --num-executors 4 \\\n  --conf \u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\\n  --conf \u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\\n  --conf spark.yarn.executor.memoryOverhead=1024 \\\n  --conf spark.yarn.driver.memoryOverhead=1024 \\\n  --conf spark.yarn.maxAppAttempts=2 \\\n  --conf spark.yarn.submit.waitAppCompletion=false \\\n  --driver-class-path /Users/ohmycloud/work/cihon/gac/sources \\\n  --files $CONF_DIR/$APP_CONF \\\n  /Users/ohmycloud/demo/Spark/WriteParquet2Kafka/target/socket-structured-streaming-1.0-SNAPSHOT.jar\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"yarn-模式\"\u003eyarn 模式\u003c/h3\u003e\n\u003cp\u003eyarn 模式下，不需要添加 driver-class-path 了:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#!/bin/sh\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eCONF_DIR\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e/root/resources\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eAPP_CONF\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapplication.test.conf\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eEXECUTOR_JMX_PORT\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e23333\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eDRIVER_JMX_PORT\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e2334\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003espark2-submit \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --class \u003cspan class=\"nv\"\u003e$1\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --master yarn \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --deploy-mode cluster \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --driver-memory 2g \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --driver-cores \u003cspan class=\"m\"\u003e2\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --executor-memory 2g \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --executor-cores \u003cspan class=\"m\"\u003e2\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --num-executors \u003cspan class=\"m\"\u003e4\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0 \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf \u003cspan class=\"s2\"\u003e\u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.port=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$EXECUTOR_JMX_PORT\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf \u003cspan class=\"s2\"\u003e\u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.port=\u003c/span\u003e\u003cspan class=\"nv\"\u003e$DRIVER_JMX_PORT\u003c/span\u003e\u003cspan class=\"s2\"\u003e -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34;\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.executor.memoryOverhead\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e1024\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.driver.memoryOverhead\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e1024\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.yarn.maxAppAttempts\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e2\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --conf spark.yarn.submit.waitAppCompletion\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nb\"\u003efalse\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  --files \u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/\u003cspan class=\"nv\"\u003e$APP_CONF\u003c/span\u003e,\u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/log4j.properties,\u003cspan class=\"nv\"\u003e$CONF_DIR\u003c/span\u003e/metrics.properties \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  target/socket-structured-streaming-1.0-SNAPSHOT.jar\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e但是实际上， 后来发现有时候不行，所以最好还是加上 \u003ccode\u003edriver-class-path\u003c/code\u003e!\u003c/p\u003e\n\u003ch2 id=\"attention\"\u003eAttention\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://stackoverflow.com/questions/27972232/no-configuration-setting-found-for-key-typesafe-config\"\u003eattention\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e我在一个离线程序中给配置文件起了一个不带 \u003cstrong\u003eapplication\u003c/strong\u003e 的名字后，程序就报【找不到某个键了】，该成 \u003ccode\u003eapplication.conf\u003c/code\u003e 之后就可以了。\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://stackoverflow.com/questions/40507436/using-typesafe-config-with-spark-on-yarn\"\u003eUsing typesafe config with Spark on Yarn\u003c/a\u003e\n\u003ca href=\"http://www.itversity.com/topic/externalize-properties-typesafe-config/\"\u003eExternalize properties – typesafe config\u003c/a\u003e\n\u003ca href=\"http://www.itversity.com/topic/spark-context-and-spark-configuration/\"\u003eSpark Context and Spark Configuration\u003c/a\u003e\n\u003ca href=\"https://stackoverflow.com/questions/43430596/how-to-specify-custom-conf-file-for-spark-standalones-master\"\u003eHow to specify custom conf file for Spark Standalone\u0026rsquo;s master?\u003c/a\u003e\n\u003ca href=\"https://dzone.com/articles/scala-load-configuration-with-pureconfig\"\u003eScala Load Configuration With PureConfig\u003c/a\u003e\n\u003ca href=\"https://console.bluemix.net/docs/services/AnalyticsforApacheSpark/spark_submit_example.html#example-running-a-spark-application-with-optional-parameters\"\u003eExample: Running a Spark application with optional parameters\u003c/a\u003e\u003c/p\u003e\n","text":"Spark 中的 \u0026ndash;files 参数与 ConfigFactory 工厂方法 scala 对象 以前有个大数据项目做小程序统计，读取 HDFS 上的 Parquet 文件，统计完毕后，将结果写入到 MySQL 数据库。首先想到的是将 MySQL 的配置写在代码里面:\nval jdbcUrl = \u0026#34;jdbc:mysql://127.0.0.1:6606/test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;useSSL=false\u0026#34; val user = \u0026#34;root\u0026#34; val password = \u0026#34;averyloooooongword\u0026#34; val driver = \u0026#34;com.mysql.jdbc.Driver\u0026#34; properties 文件 如果是测试，生产环境各有一套，那上面的代码就要分别复制俩份，不便于维护！后来知道了可以把配置放在 resources 目录下, 针对本地，测试和生产环境，分别创建不同的 properties 文件：\nconf.properties conf_product.properties env.properties local.properties 例如其中的 conf.properties 内容如下：\n# 测试环境配置 ## 数据库配置 jdbc.url=jdbc:mysql://10.0.0.11:3306/ald_xinen_test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false jdbc.user=aldwx jdbc.pwd=123456 jdbc.driver=com.mysql.jdbc.Driver # parquet 文件目录 tongji.parquet=hdfs://10.0.0.212:9000/ald_log_parquet 然后在代码里面读取 resource 文件中的配置：\n/** * 根据 key 获取 properties 文件中的 value * @param key properties 文件中等号左边的键 * @return 返回 properties 文件中等号右边的值 */ public static String getProperty(String key) { Properties properties = new Properties(); InputStream in = ConfigurationUtil.class.getClassLoader().getResourceAsStream(getEnvProperty(\u0026#34;env.conf\u0026#34;)); try { properties.load(in); in.close(); } catch (IOException e) { e.printStackTrace(); } return (String) properties.get(key); } 这样解决了多个环境中配置不同的问题，只需要复制多个 properties 文件，根据需要修改就行。但是这种方法不是最优的，因为配置不是结构化的，而是通过注释分割了不同的配置。\nconf 文件 resources 目录下的文件如下：\napplication.conf application.production.conf application.local.conf log4j.properties metrics.properties ConfigFactory 工厂方法默认会读取 resources 目录下面名为 application.conf 的文件：\n# Spark 相关配置 spark { master = \u0026#34;local[2]\u0026#34; streaming.batch.duration = 5001 // Would normally be `ms` in config but Spark just wants the Long eventLog.enabled = true ui.enabled = true ui.port = 4040 metrics.conf = metrics.properties checkpoint.path = \u0026#34;/tmp/checkpoint/telematics-local\u0026#34; stopper.port = 12345 spark.cleaner.ttl = 3600 spark.cleaner.referenceTracking.cleanCheckpoints = true } # Kafka 相关配置 kafka { metadata.broker.list = \u0026#34;localhost:9092\u0026#34; zookeeper.connect = \u0026#34;localhost:2181\u0026#34; topic.dtcdata { name = \u0026#34;dc-diagnostic-report\u0026#34; partition.num = 1 replication.factor = 1 } group.id = \u0026#34;group-rds\u0026#34; timeOut = \u0026#34;3000\u0026#34; bufferSize = \u0026#34;100\u0026#34; clientId = \u0026#34;telematics\u0026#34; key.serializer.class = \u0026#34;kafka.serializer.StringEncoder\u0026#34; serializer.class = \u0026#34;com.wm.dtc.pipeline.kafka.SourceDataSerializer\u0026#34; // serializer.class = \u0026#34;kafka.serializer.DefaultEncoder\u0026#34; } # MySQL 配置 mysql { dataSource.maxLifetime = 800000 dataSource.idleTimeout = 600000 dataSource.maximumPoolSize = 10 dataSource.cachePrepStmts = true dataSource.prepStmtCacheSize = 250 dataSource.prepStmtCacheSqlLimit = 204800 dataSource.useServerPrepStmts = true dataSource.useLocalSessionState = true dataSource.rewriteBatchedStatements = true dataSource.cacheResultSetMetadata = true dataSource.cacheServerConfiguration = true dataSource.elideSetAutoCommits = true dataSource.maintainTimeStats = false jdbcUrl=\u0026#34;jdbc:mysql://127.0.0.1:6606/wmdtc?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;useSSL=false\u0026#34; jdbcDriver=\u0026#34;com.mysql.jdbc.Driver\u0026#34; dataSource.user=\u0026#34;root\u0026#34; dataSource.password=\u0026#34;123456\u0026#34; } 为了验证，我创建了一个 Object 对象：\npackage allinone import com.typesafe.config.ConfigFactory import scopt.OptionParser object SparkFilesArgs extends App { val config = ConfigFactory.load() val sparkConf = config.getConfig(\u0026#34;spark\u0026#34;) val sparkMaster = sparkConf.getString(\u0026#34;master\u0026#34;) val sparkDuration = sparkConf.getLong(\u0026#34;streaming.batch.duration\u0026#34;) println(sparkMaster, sparkDuration) } 如果我直接运行就会打印：\n(local[2],5001) 确实是 application.conf 文件中 Spark 的配置。\n但是生产环境我们打算使用另外一个配置文件 application.production.conf:\nspark { master = \u0026#34;yarn\u0026#34; streaming.batch.duration = 5002 eventLog.enabled=true ui.enabled = true ui.port = 4040 metrics.conf = metrics.properties checkpoint.path = \u0026#34;/tmp/telematics\u0026#34; stopper.port = 12345 spark.cleaner.ttl = 3600 spark.cleaner.referenceTracking.cleanCheckpoints = true trajectory.path = \u0026#34;hdfs://CRRCNameservice/road_matching/output/road_match_result\u0026#34; city.path = \u0026#34;hdfs://CRRCNameservice/user/root/telematics/data/city.csv\u0026#34; } ##cassandra相关配置 cassandra { keyspace = wmdtc cardata.name = can_signal trip.name = trip latest.name = latest latest.interval = 15000 connection.host = \u0026#34;WMBigdata2,WMBigdata3,WMBigdata4,WMBigdata5,WMBigdata6\u0026#34; write.consistency_level = LOCAL_ONE read.consistency_level = LOCAL_ONE concurrent.writes = 24 batch.size.bytes = 65536 batch.grouping.buffer.size = 1000 connection.keep_alive_ms = 300000 auth.username = cihon auth.password = cihon } kafka { metadata.broker.list = \u0026#34;WMBigdata2:9092,WMBigdata3:9092,WMBigdata4:9092,WMBigdata5:9092,WMBigdata6:9092\u0026#34; zookeeper.connect = \u0026#34;WMBigdata2:2181,WMBigdata3:2181,WMBigdata4:2181\u0026#34; topic.obddata { name = \u0026#34;wmdtc\u0026#34; } group.id = \u0026#34;can_signal\u0026#34; timeOut = \u0026#34;3000\u0026#34; bufferSize = \u0026#34;100\u0026#34; clientId = \u0026#34;telematics\u0026#34; key.serializer.class = \u0026#34;kafka.serializer.StringEncoder\u0026#34; serializer.class = \u0026#34;com.wm.telematics.pipeline.kafka.SourceDataSerializer\u0026#34; } akka { loglevel = INFO stdout-loglevel = WARNING loggers = [\u0026#34;akka.event.slf4j.Slf4jLogger\u0026#34;] } ##geoService接口URL webservice { url = \u0026#34;http://101.201.108.155:8088/map/roadmessage\u0026#34; } ##geoService相关配置 geoservice { timeout = 3 useRealData = false } 既然 ConfigFactory 方法默认读取 application.conf 文件，但是\nval config = ConfigFactory.load() 相当于：\nval config = ConfigFactory.load(\u0026#34;application.conf\u0026#34;) 但是 load 方法也接受参数：resourceBasename:\nval config = ConfigFactory.load(\u0026#34;application.production\u0026#34;) // 加载生产环境的配置 这样在代码里面通过加载不同的配置文件实现本地、测试、生产环境的切换和部署，但是在代码里面读取配置还是不够优美！所以我们有 Spark 的 --files 命令行选项。顾名思义，显而易见，也正如官网所描述的那样, --files 参数后面的值是逗号分割的文本文件, 里面有一个 .conf 文件, load 方法会加载 --files 选项传递过来的配置文件：\n#!/bin/sh CONF_DIR=/root/telematics/resources APP_CONF=application.production.conf EXECUTOR_JMX_PORT=23339 DRIVER_JMX_PORT=2340 spark-submit \\ --name WM_telematics \\ --class allinone.SparkFilesArgs \\ --master local[*] \\ --deploy-mode client \\ --driver-memory 2g \\ --driver-cores 2 \\ --executor-memory 1g \\ --executor-cores 3 \\ --num-executors 3 \\ --conf \u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf \u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf spark.executor.memoryOverhead=4096 \\ --conf spark.driver.memoryOverhead=2048 \\ --conf spark.yarn.maxAppAttempts=2 \\ --conf spark.yarn.submit.waitAppCompletion=false \\ --conf spark.network.timeout=1800s \\ --conf spark.scheduler.executorTaskBlacklistTime=30000 \\ --conf spark.core.connection.ack.wait.timeout=300s \\ --files $CONF_DIR/$APP_CONF,$CONF_DIR/log4j.properties,$CONF_DIR/metrics.properties \\ /Users/ohmycloud/work/cihon/sxw/all-in-one/target/allinone-1.0-SNAPSHOT.jar 它打印：\n(local[*],5002) 因为我在命令行选项中指定了 master 为 local[*], 配置文件为 application.production.conf。\nresource not found on classpath: application.conf 本地 localhost jar 包里面我把 application.conf 给删除了，用 --files 传参数给 spark-submit 的方式，但是报：在 classpath 下找不到 application.conf 这个文件了。\ncat spark-submit.sh:\n#!/bin/sh CONF_DIR=/Users/ohmycloud/work/cihon/gac/sources APP_CONF=application.conf EXECUTOR_JMX_PORT=23333 DRIVER_JMX_PORT=2334 spark-submit \\ --class $1 \\ --master local[2] \\ --deploy-mode client \\ --driver-memory 2g \\ --driver-cores 2 \\ --executor-memory 2g \\ --executor-cores 2 \\ --num-executors 4 \\ --conf \u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf \u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf spark.yarn.executor.memoryOverhead=1024 \\ --conf spark.yarn.driver.memoryOverhead=1024 \\ --conf spark.yarn.maxAppAttempts=2 \\ --conf spark.yarn.submit.waitAppCompletion=false \\ --files $CONF_DIR/$APP_CONF \\ /Users/ohmycloud/demo/Spark/WriteParquet2Kafka/target/socket-structured-streaming-1.0-SNAPSHOT.jar 原因是 application.conf 文件所在的路径 /Users/ohmycloud/work/cihon/gac/sources 不在 classpath 里面！\n使用\n--driver-class-path /Users/ohmycloud/work/cihon/gac/sources 而非\n--driver-class-path /Users/ohmycloud/work/cihon/gac/sources/application.conf 来添加 class path。\n#!/bin/sh CONF_DIR=/Users/ohmycloud/work/cihon/gac/sources APP_CONF=application.conf EXECUTOR_JMX_PORT=23333 DRIVER_JMX_PORT=2334 spark-submit \\ --class $1 \\ --master local[2] \\ --deploy-mode client \\ --driver-memory 2g \\ --driver-cores 2 \\ --executor-memory 2g \\ --executor-cores 2 \\ --num-executors 4 \\ --conf \u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf \u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf spark.yarn.executor.memoryOverhead=1024 \\ --conf spark.yarn.driver.memoryOverhead=1024 \\ --conf spark.yarn.maxAppAttempts=2 \\ --conf spark.yarn.submit.waitAppCompletion=false \\ --driver-class-path /Users/ohmycloud/work/cihon/gac/sources \\ --files $CONF_DIR/$APP_CONF \\ /Users/ohmycloud/demo/Spark/WriteParquet2Kafka/target/socket-structured-streaming-1.0-SNAPSHOT.jar yarn 模式 yarn 模式下，不需要添加 driver-class-path 了:\n#!/bin/sh CONF_DIR=/root/resources APP_CONF=application.test.conf EXECUTOR_JMX_PORT=23333 DRIVER_JMX_PORT=2334 spark2-submit \\ --class $1 \\ --master yarn \\ --deploy-mode cluster \\ --driver-memory 2g \\ --driver-cores 2 \\ --executor-memory 2g \\ --executor-cores 2 \\ --num-executors 4 \\ --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0 \\ --conf \u0026#34;spark.executor.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$EXECUTOR_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf \u0026#34;spark.driver.extraJavaOptions=-Dconfig.resource=$APP_CONF -Dcom.sun.management.jmxremote.port=$DRIVER_JMX_PORT -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=`hostname`\u0026#34; \\ --conf spark.executor.memoryOverhead=1024 \\ --conf spark.driver.memoryOverhead=1024 \\ --conf spark.yarn.maxAppAttempts=2 \\ --conf spark.yarn.submit.waitAppCompletion=false \\ --files $CONF_DIR/$APP_CONF,$CONF_DIR/log4j.properties,$CONF_DIR/metrics.properties \\ target/socket-structured-streaming-1.0-SNAPSHOT.jar 但是实际上， 后来发现有时候不行，所以最好还是加上 driver-class-path!\nAttention attention\n我在一个离线程序中给配置文件起了一个不带 application 的名字后，程序就报【找不到某个键了】，该成 application.conf 之后就可以了。\nReferences Using typesafe config with Spark on Yarn Externalize properties – typesafe config Spark Context and Spark Configuration How to specify custom conf file for Spark Standalone\u0026rsquo;s master? Scala Load Configuration With PureConfig Example: Running a Spark application with optional parameters\n"},"name":"Spark 中的 --files 参数与 ConfigFactory 工厂方法","published":"2017-03-18T16:36:25Z","summary":"Spark 中的 \u0026ndash;files 参数与 ConfigFactory 工厂方法 scala 对象 以前有个大数据项目做小程序统计，读取 HDFS 上的 Parquet 文件，统计完毕后，将结果写入到 MySQL 数据库。首先想到的是将 MySQL 的配置写在代码里面:\nval jdbcUrl = \u0026#34;jdbc:mysql://127.0.0.1:6606/test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;useSSL=false\u0026#34; val user = \u0026#34;root\u0026#34; val password = \u0026#34;averyloooooongword\u0026#34; val driver = \u0026#34;com.mysql.jdbc.Driver\u0026#34; properties 文件 如果是测试，生产环境各有一套，那上面的代码就要分别复制俩份，不便于维护！后来知道了可以把配置放在 resources 目录下, 针对本地，测试和生产环境，分别创建不同的 properties 文件：\nconf.properties conf_product.properties env.properties local.properties 例如其中的 conf.properties 内容如下：\n# 测试环境配置 ## 数据库配置 jdbc.url=jdbc:mysql://10.0.0.11:3306/ald_xinen_test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false jdbc.user=aldwx jdbc.pwd=123456 jdbc.driver=com.mysql.jdbc.Driver # parquet 文件目录 tongji.parquet=hdfs://10.0.0.212:9000/ald_log_parquet 然后在代码里面读取 resource 文件中的配置：\n/** * 根据 key 获取 properties 文件中的 value * @param key properties 文件中等号左边的键 * @return 返回 properties 文件中等号右边的值 */ public static String getProperty(String key) { Properties properties = new Properties(); InputStream in = ConfigurationUtil.","type":"entry","url":"https://ohmyweekly.github.io/notes/spark-%E4%B8%AD%E7%9A%84---files-%E5%8F%82%E6%95%B0%E4%B8%8E-configfactory-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95/"}