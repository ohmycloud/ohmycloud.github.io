{"author":{"name":null,"type":"card","url":"https://ohmyweekly.github.io/"},"content":{"html":"\u003cp\u003e升级了一下 IDEA， 运行 spark 程序的时候给我报错了，\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eNoClassDefFound : Scala/xml/metadata\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e解决方法， 在pom 文件里面添加如下依赖：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e        \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.scala-lang\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;scala-library\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;2.11.8\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n\n        \u0026lt;!-- https://mvnrepository.com/artifact/org.scala-lang.modules/scala-xml --\u0026gt;\n        \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.scala-lang.modules\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;scala-xml_2.11\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;1.1.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eCDH 集群，Spark 升级到 2.3 后，运行任务报错：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eError: A JNI error has occurred, please check your installation and try again\nException in thread \u0026#34;main\u0026#34; java.lang.NoClassDefFoundError: org/slf4j/Logger\n\tat java.lang.Class.getDeclaredMethods0(Native Method)\n\tat java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n\tat java.lang.Class.privateGetMethodRecursive(Class.java:3048)\n\tat java.lang.Class.getMethod0(Class.java:3018)\n\tat java.lang.Class.getMethod(Class.java:1784)\n\tat sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)\n\tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)\nCaused by: java.lang.ClassNotFoundException: org.slf4j.Logger\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e运行 spark-shell 也会报错，原因是，分配 spark2 的角色时， 没有为所有机器分配该角色。\u003c/p\u003e\n\u003cp\u003e解决方法： 给每一台机器都添加上 gateway 角色。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eService \u0026#39;sparkDriver\u0026#39; failed after 16 retries!\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e解决办法\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://stackoverflow.com/questions/30085779/apache-spark-error-while-start/30952312#30952312\"\u003ehttps://stackoverflow.com/questions/30085779/apache-spark-error-while-start/30952312#30952312\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026lt;dependency\u0026gt;\n    \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt;\n    \u0026lt;artifactId\u0026gt;spark-streaming_2.11\u0026lt;/artifactId\u0026gt;\n    \u0026lt;version\u0026gt;2.3.0\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eartifact\u003c/code\u003e =\u0026gt; 工件\u003c/p\u003e\n\u003cp\u003emvn 命令行打包：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003emvn clean package -DskipTests=true\n\u003c/code\u003e\u003c/pre\u003e","text":"升级了一下 IDEA， 运行 spark 程序的时候给我报错了，\nNoClassDefFound : Scala/xml/metadata 解决方法， 在pom 文件里面添加如下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.scala-lang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-library\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.11.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.scala-lang.modules/scala-xml --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.scala-lang.modules\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-xml_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; CDH 集群，Spark 升级到 2.3 后，运行任务报错：\nError: A JNI error has occurred, please check your installation and try again Exception in thread \u0026#34;main\u0026#34; java.lang.NoClassDefFoundError: org/slf4j/Logger at java.lang.Class.getDeclaredMethods0(Native Method) at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) at java.lang.Class.privateGetMethodRecursive(Class.java:3048) at java.lang.Class.getMethod0(Class.java:3018) at java.lang.Class.getMethod(Class.java:1784) at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526) Caused by: java.lang.ClassNotFoundException: org.slf4j.Logger at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) 运行 spark-shell 也会报错，原因是，分配 spark2 的角色时， 没有为所有机器分配该角色。\n解决方法： 给每一台机器都添加上 gateway 角色。\nService \u0026#39;sparkDriver\u0026#39; failed after 16 retries! 解决办法\nhttps://stackoverflow.com/questions/30085779/apache-spark-error-while-start/30952312#30952312\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spark-streaming_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; artifact =\u0026gt; 工件\nmvn 命令行打包：\nmvn clean package -DskipTests=true "},"name":"NoClassDefFound","published":"2017-03-12T16:36:25Z","summary":"升级了一下 IDEA， 运行 spark 程序的时候给我报错了，\nNoClassDefFound : Scala/xml/metadata 解决方法， 在pom 文件里面添加如下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.scala-lang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-library\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.11.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.scala-lang.modules/scala-xml --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.scala-lang.modules\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-xml_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; CDH 集群，Spark 升级到 2.3 后，运行任务报错：\nError: A JNI error has occurred, please check your installation and try again Exception in thread \u0026#34;main\u0026#34; java.lang.NoClassDefFoundError: org/slf4j/Logger at java.lang.Class.getDeclaredMethods0(Native Method) at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) at java.lang.Class.privateGetMethodRecursive(Class.java:3048) at java.lang.Class.getMethod0(Class.java:3018) at java.lang.Class.getMethod(Class.java:1784) at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526) Caused by: java.lang.ClassNotFoundException: org.slf4j.Logger at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.","type":"entry","url":"https://ohmyweekly.github.io/notes/noclassdeffound---scala-xml-metadata/"}