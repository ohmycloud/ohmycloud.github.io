{"author":{"name":null,"type":"card","url":"https://ohmycloud.github.io/"},"content":{"html":"\u003ch1 id=\"cassandra-sink-for-spark-structured-streaminghttpsdzonecomarticlescassandra-sink-for-spark-structured-streaming\"\u003e\u003ca href=\"https://dzone.com/articles/cassandra-sink-for-spark-structured-streaming\"\u003eCassandra Sink for Spark Structured Streaming\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e我最近开始使用 Spark，并且必须将结构化流式 API 生成的结果存储在 Cassandra 数据库中。\u003c/p\u003e\n\u003cp\u003e在这篇文章中，我提供了一个如何在 Spark Structured Streaming 中创建和使用 Cassandra 接收器的简单示例。 我希望它对那些刚刚开始使用 Structured Streaming API 并想知道如何将它与数据库连接的人有用。\u003c/p\u003e\n\u003cp\u003e应用程序的想法非常简单。 它从 Kafka 读取消息，解析它们并将它们保存到 Cassandra 中。\u003c/p\u003e\n\u003ch1 id=\"why-structured-streaming\"\u003eWhy Structured Streaming?\u003c/h1\u003e\n\u003cp\u003e从\u003ca href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\"\u003e文档\u003c/a\u003e中可以看出，Structured Streaming 是一个基于 Spark SQL 引擎的可扩展且容错的流处理引擎。 您可以使用 Dataset/DataFrame API 来表示流聚合，事件时间窗口，流到批处理连接等。在 Spark 中进行流式计算，并允许使用熟悉的 SQL 处理流数据。\u003c/p\u003e\n\u003ch1 id=\"what-is-the-problem\"\u003eWhat Is the Problem?\u003c/h1\u003e\n\u003cp\u003eSpark Structured Streaming 在 2017 年已经被标记为稳定。因此，它是一个相对较新的 API，并不是所有功能都在那里。例如，有几种类型的内置输出接收器：File，Kafka，Console 和内存接收器。但是，如果您想将流式计算的结果输出到数据库中，则需要使用 foreach 接收器并实现 ForeachWriter 接口。从 Spark 2.3.1 开始，这仅适用于 Scala 和 Java。\u003c/p\u003e\n\u003cp\u003e在这里，我假设您已经大致了解 Structured Streaming 如何工作，并且知道如何读取和处理流数据，现在可以将其输出到数据库中。如果上述某些步骤不清楚，可以使用一些很好的在线资源来帮助您开始使用结构化流。特别是，官方文档是一个很好的起点。在本文中，我想关注您需要将结果存储在数据库中的最后一步。\u003c/p\u003e\n\u003cp\u003e我将描述如何为结构化流实现 Cassandra 接收器，提供一个简单示例，并解释如何在集群上运行它。完整代码可在\u003ca href=\"https://github.com/epishova/Structured-Streaming-Cassandra-Sink\"\u003e此处\u003c/a\u003e获得。\u003c/p\u003e\n\u003cp\u003e当我最初遇到上述问题时，这个\u003ca href=\"https://github.com/polomarcus/Spark-Structured-Streaming-Examples\"\u003e项目\u003c/a\u003e非常有帮助。但是，如果您刚开始使用结构化流媒体并且需要一个如何将数据输出到 Cassandra 的简单示例，那么该回购可能看起来很复杂。此外，该代码在 Spark 本地模式下工作，并且需要在群集上运行一些更改。\u003c/p\u003e\n\u003cp\u003e此外，还有很好的示例说明如何为结构化流创建 \u003ca href=\"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html\"\u003eJDBC 接收器\u003c/a\u003e和 \u003ca href=\"https://jira.mongodb.org/browse/SPARK-134\"\u003eMongoDB 接收器\u003c/a\u003e。\u003c/p\u003e\n\u003ch1 id=\"simple-solution\"\u003eSimple Solution\u003c/h1\u003e\n\u003cp\u003e要将数据发送到外部系统，您需要使用 \u003cem\u003eforeach\u003c/em\u003e 接收器。 你可以在\u003ca href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#using-foreach\"\u003e这里\u003c/a\u003e读更多关于它的内容。 简而言之，您需要实现 \u003cem\u003eForeachWriter\u003c/em\u003e 接口。 那就是定义如何打开连接，处理每个数据分区，以及在处理结束时关闭连接。 源代码如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraSinkForeach\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eForeachWriter\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"kt\"\u003eorg.apache.spark.sql.Row\u003c/span\u003e\u003cspan class=\"o\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// This class implements the interface ForeachWriter, which has methods that get called \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// whenever there is a sequence of rows generated as output\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003ecassandraDriver\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraDriver\u003c/span\u003e\u003cspan class=\"o\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eopen\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epartitionId\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eLong\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eversion\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eLong\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eBoolean\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// open connection\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003es\u0026#34;Open connection\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eprocess\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erecord\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eorg.apache.spark.sql.Row\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003es\u0026#34;Process new \u003c/span\u003e\u003cspan class=\"si\"\u003e$record\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ecassandraDriver\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econnector\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithSessionDo\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esession\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003esession\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003es\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e       insert into \u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003ecassandraDriver\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enamespace\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e.\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003ecassandraDriver\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eforeachTableSink\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e (fx_marker, timestamp_ms, timestamp_dt)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s\"\u003e       values(\u0026#39;\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003erecord\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;, \u0026#39;\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003erecord\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;, \u0026#39;\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"n\"\u003erecord\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;)\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eclose\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eerrorOrNull\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eThrowable\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eUnit\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// close the connection\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003es\u0026#34;Close connection\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e你会发现 CassandraDriver 的定义和下面的输出表，但在此之前让我们仔细看看上面的代码是如何工作的。 在这里，为了从 Spark 连接到 Cassandra，我创建了 CassandraDriver 对象，该对象提供对 CassandraConnector 的访问 -  CassandraConnector 是 DataStax 中广泛使用的连接器。 你可以在这里读更多关于它的内容。 CassandraConnector 负责打开和关闭与数据库的连接，因此我只需在 CassandraSinkForeach 类中的 open 和 close 方法中打印调试消息。\u003c/p\u003e\n\u003cp\u003e上面的代码在主应用程序中调用如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003esink\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparsed\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewriteStream\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equeryName\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;KafkaToCassandraForeach\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputMode\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;update\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eforeach\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraSinkForeach\u003c/span\u003e\u003cspan class=\"o\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estart\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e将为每一行创建 CassandraSinkForeach，每个 worker 将其部分行插入到数据库中。 所以，每个 worker 都运行 \u003cem\u003eval cassandraDriver = new CassandraDriver()\u003c/em\u003e; 这就是 CassandraDriver 类的样子：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraDriver\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkSessionBuilder\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// This object will be used in CassandraSinkForeach to connect to Cassandra DB from an executor.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// It extends SparkSessionBuilder so to use the same SparkSession on each node.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ebuildSparkSession\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003espark.implicits._\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003econnector\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraConnector\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esparkContext\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetConf\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Define Cassandra\u0026#39;s table which will be used as a sink\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"cm\"\u003e/* For this app I used the following table:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e       CREATE TABLE fx.spark_struct_stream_sink (\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e       fx_marker text,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e       timestamp_ms timestamp,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e       timestamp_dt date,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e       primary key (fx_marker));\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e  */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003enamespace\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;fx\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003eforeachTableSink\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;spark_struct_stream_sink\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e让我们仔细看看上面代码中的 spark 对象。 这是 SparkSessionBuilder 的代码：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkSessionBuilder\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eSerializable\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Build a spark session. Class is made serializable so to get access to SparkSession in a driver and executors. \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// Note here the usage of @transient lazy val \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003ebuildSparkSession\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eSparkSession\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nd\"\u003e@transient\u003c/span\u003e \u003cspan class=\"k\"\u003elazy\u003c/span\u003e \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003econf\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eSparkConf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkConf\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esetAppName\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Structured Streaming from Kafka to Cassandra\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eset\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;spark.cassandra.connection.host\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;ec2-52-23-103-178.compute-1.amazonaws.com\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eset\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;spark.sql.streaming.checkpointLocation\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;checkpoint\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nd\"\u003e@transient\u003c/span\u003e \u003cspan class=\"k\"\u003elazy\u003c/span\u003e \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkSession\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebuilder\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econf\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetOrCreate\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003espark\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在每个 worker 上，SparkSessionBuilder 提供对在驱动程序上创建的SparkSession的访问。 为了使它工作，我们需要使SparkSessionBuilder可序列化并使用@transient lazy val，它允许序列化系统忽略conf和spark对象。 现在，buildSparkSession正在被序列化并发送给每个worker，但是当worker需要conf和spark对象时，它们正在被解析。\u003c/p\u003e\n\u003cp\u003e现在让我们看一下应用程序主体：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eobject\u003c/span\u003e \u003cspan class=\"nc\"\u003eKafkaToCassandra\u003c/span\u003e \u003cspan class=\"k\"\u003eextends\u003c/span\u003e \u003cspan class=\"nc\"\u003eSparkSessionBuilder\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Main body of the app. It also extends SparkSessionBuilder.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003emain\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eArray\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"kt\"\u003eString\u003c/span\u003e\u003cspan class=\"o\"\u003e])\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ebuildSparkSession\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003espark.implicits._\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Define location of Kafka brokers:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003ebroker\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;ec2-18-209-75-68.compute-1.amazonaws.com:9092,ec2-18-205-142-57.compute-1.amazonaws.com:9092,ec2-50-17-32-144.compute-1.amazonaws.com:9092\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"cm\"\u003e/*Here is an example massage which I get from a Kafka stream. It contains multiple jsons separated by \\n \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e    {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100936\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;EUR/GBP\u0026#34;}\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e    {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100815\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;USD/CHF\u0026#34;}\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e    {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100969\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;EUR/CHF\u0026#34;}\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e    {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100011\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;USD/CAD\u0026#34;}\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cm\"\u003e    */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Read incoming stream\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003edfraw\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ereadStream\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eformat\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;kafka\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eoption\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;kafka.bootstrap.servers\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebroker\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eoption\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;subscribe\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;currency_exchange\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003eschema\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eStructType\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nc\"\u003eStructField\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;fx_marker\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eStringType\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"o\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nc\"\u003eStructField\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;timestamp_ms\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eStringType\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edfraw\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselectExpr\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;CAST(value AS STRING)\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eas\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"kt\"\u003eString\u003c/span\u003e\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eflatMap\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003e_\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\\n\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003ejsons\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_json\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e$\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;value\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eas\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;data\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eselect\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;data.*\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Process data. Create a new date column\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003eparsed\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejsons\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewithColumn\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;timestamp_dt\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eto_date\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_unixtime\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e$\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;timestamp_ms\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"mf\"\u003e1000.0\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;yyyy-MM-dd HH:mm:ss.SSS\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilter\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;fx_marker != \u0026#39;\u0026#39;\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Output results into a database\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003esink\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparsed\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewriteStream\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equeryName\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;KafkaToCassandraForeach\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputMode\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;update\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eforeach\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eCassandraSinkForeach\u003c/span\u003e\u003cspan class=\"o\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estart\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003esink\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eawaitTermination\u003c/span\u003e\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e当应用程序被发送到执行时，buildSparkSession 被序列化并发送给 worker，但是，conf 和 spark 对象尚未解决。 接下来，driver 在 KafkaToCassandra 中创建 spark 对象，并在 executors 之间分配工作。 worker 从 Kafka 读取数据，进行简单的转换，当 worker 准备将结果写入数据库时，他们解析 conf 和 spark 对象，从而访问在 driver 上创建的 SparkSession。\u003c/p\u003e\n\u003ch1 id=\"how-to-build-and-run-the-app\"\u003eHow to Build and Run the App?\u003c/h1\u003e\n\u003cp\u003e当我从 PySpark 迁移到 Scala 时，我花了一些时间来了解如何构建应用程序。 所以，我将 Maven pom.xml 包含在 repo 中。\u003c/p\u003e\n\u003cp\u003e您可以通过运行 mvn package 命令使用 Maven 构建应用程序。 之后，您可以使用执行应用程序\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e./\u003c/span\u003e\u003cspan class=\"n\"\u003ebin\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003esubmit\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003epackages\u003c/span\u003e \u003cspan class=\"n\"\u003eorg\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eapache\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e\u003cspan class=\"kt\"\u003espark-sql-kafka-\u003c/span\u003e\u003cspan class=\"err\"\u003e0\u003c/span\u003e\u003cspan class=\"kt\"\u003e-\u003c/span\u003e\u003cspan class=\"err\"\u003e10\u003c/span\u003e\u003cspan class=\"k\"\u003e_\u003c/span\u003e\u003cspan class=\"err\"\u003e2\u003c/span\u003e\u003cspan class=\"kt\"\u003e.\u003c/span\u003e\u003cspan class=\"err\"\u003e11\u003c/span\u003e\u003cspan class=\"kt\"\u003e:\u003c/span\u003e\u003cspan class=\"err\"\u003e2\u003c/span\u003e\u003cspan class=\"kt\"\u003e.\u003c/span\u003e\u003cspan class=\"err\"\u003e3\u003c/span\u003e\u003cspan class=\"kt\"\u003e.\u003c/span\u003e\u003cspan class=\"err\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003edatastax\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e\u003cspan class=\"kt\"\u003espark-cassandra-connector:\u003c/span\u003e\u003cspan class=\"err\"\u003e2\u003c/span\u003e\u003cspan class=\"kt\"\u003e.\u003c/span\u003e\u003cspan class=\"err\"\u003e3\u003c/span\u003e\u003cspan class=\"kt\"\u003e.\u003c/span\u003e\u003cspan class=\"err\"\u003e0\u003c/span\u003e\u003cspan class=\"kt\"\u003e-s_2.\u003c/span\u003e\u003cspan class=\"err\"\u003e11\u003c/span\u003e \u003cspan class=\"kt\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003ecom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einsight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"nc\"\u003eCassandraSink\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"nc\"\u003eKafkaToCassandra\u003c/span\u003e \u003cspan class=\"n\"\u003e\\\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"n\"\u003emaster\u003c/span\u003e \u003cspan class=\"n\"\u003espark\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//ec2-18-232-26-53.compute-1.amazonaws.com:7077 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003ecassandra\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003esink\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.0\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"nc\"\u003eSNAPSHOT\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejar\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e此示例在 AWS 群集上运行，因此，如果您要测试它，只需用您的 AWS 实例替换我的 AWS 实例的地址（所有内容类似于ec2-xx-xxx-xx-xx.compute-1.amazonaws.com）。\u003c/p\u003e\n","text":"Cassandra Sink for Spark Structured Streaming 我最近开始使用 Spark，并且必须将结构化流式 API 生成的结果存储在 Cassandra 数据库中。\n在这篇文章中，我提供了一个如何在 Spark Structured Streaming 中创建和使用 Cassandra 接收器的简单示例。 我希望它对那些刚刚开始使用 Structured Streaming API 并想知道如何将它与数据库连接的人有用。\n应用程序的想法非常简单。 它从 Kafka 读取消息，解析它们并将它们保存到 Cassandra 中。\nWhy Structured Streaming? 从文档中可以看出，Structured Streaming 是一个基于 Spark SQL 引擎的可扩展且容错的流处理引擎。 您可以使用 Dataset/DataFrame API 来表示流聚合，事件时间窗口，流到批处理连接等。在 Spark 中进行流式计算，并允许使用熟悉的 SQL 处理流数据。\nWhat Is the Problem? Spark Structured Streaming 在 2017 年已经被标记为稳定。因此，它是一个相对较新的 API，并不是所有功能都在那里。例如，有几种类型的内置输出接收器：File，Kafka，Console 和内存接收器。但是，如果您想将流式计算的结果输出到数据库中，则需要使用 foreach 接收器并实现 ForeachWriter 接口。从 Spark 2.3.1 开始，这仅适用于 Scala 和 Java。\n在这里，我假设您已经大致了解 Structured Streaming 如何工作，并且知道如何读取和处理流数据，现在可以将其输出到数据库中。如果上述某些步骤不清楚，可以使用一些很好的在线资源来帮助您开始使用结构化流。特别是，官方文档是一个很好的起点。在本文中，我想关注您需要将结果存储在数据库中的最后一步。\n我将描述如何为结构化流实现 Cassandra 接收器，提供一个简单示例，并解释如何在集群上运行它。完整代码可在此处获得。\n当我最初遇到上述问题时，这个项目非常有帮助。但是，如果您刚开始使用结构化流媒体并且需要一个如何将数据输出到 Cassandra 的简单示例，那么该回购可能看起来很复杂。此外，该代码在 Spark 本地模式下工作，并且需要在群集上运行一些更改。\n此外，还有很好的示例说明如何为结构化流创建 JDBC 接收器和 MongoDB 接收器。\nSimple Solution 要将数据发送到外部系统，您需要使用 foreach 接收器。 你可以在这里读更多关于它的内容。 简而言之，您需要实现 ForeachWriter 接口。 那就是定义如何打开连接，处理每个数据分区，以及在处理结束时关闭连接。 源代码如下：\nclass CassandraSinkForeach() extends ForeachWriter[org.apache.spark.sql.Row] { // This class implements the interface ForeachWriter, which has methods that get called // whenever there is a sequence of rows generated as output val cassandraDriver = new CassandraDriver(); def open(partitionId: Long, version: Long): Boolean = { // open connection println(s\u0026#34;Open connection\u0026#34;) true } def process(record: org.apache.spark.sql.Row) = { println(s\u0026#34;Process new $record\u0026#34;) cassandraDriver.connector.withSessionDo(session =\u0026gt; session.execute(s\u0026#34;\u0026#34;\u0026#34; insert into ${cassandraDriver.namespace}.${cassandraDriver.foreachTableSink} (fx_marker, timestamp_ms, timestamp_dt) values(\u0026#39;${record(0)}\u0026#39;, \u0026#39;${record(1)}\u0026#39;, \u0026#39;${record(2)}\u0026#39;)\u0026#34;\u0026#34;\u0026#34;) ) } def close(errorOrNull: Throwable): Unit = { // close the connection println(s\u0026#34;Close connection\u0026#34;) } } 你会发现 CassandraDriver 的定义和下面的输出表，但在此之前让我们仔细看看上面的代码是如何工作的。 在这里，为了从 Spark 连接到 Cassandra，我创建了 CassandraDriver 对象，该对象提供对 CassandraConnector 的访问 - CassandraConnector 是 DataStax 中广泛使用的连接器。 你可以在这里读更多关于它的内容。 CassandraConnector 负责打开和关闭与数据库的连接，因此我只需在 CassandraSinkForeach 类中的 open 和 close 方法中打印调试消息。\n上面的代码在主应用程序中调用如下：\nval sink = parsed .writeStream .queryName(\u0026#34;KafkaToCassandraForeach\u0026#34;) .outputMode(\u0026#34;update\u0026#34;) .foreach(new CassandraSinkForeach()) .start() 将为每一行创建 CassandraSinkForeach，每个 worker 将其部分行插入到数据库中。 所以，每个 worker 都运行 val cassandraDriver = new CassandraDriver(); 这就是 CassandraDriver 类的样子：\nclass CassandraDriver extends SparkSessionBuilder { // This object will be used in CassandraSinkForeach to connect to Cassandra DB from an executor. // It extends SparkSessionBuilder so to use the same SparkSession on each node. val spark = buildSparkSession import spark.implicits._ val connector = CassandraConnector(spark.sparkContext.getConf) // Define Cassandra\u0026#39;s table which will be used as a sink /* For this app I used the following table: CREATE TABLE fx.spark_struct_stream_sink ( fx_marker text, timestamp_ms timestamp, timestamp_dt date, primary key (fx_marker)); */ val namespace = \u0026#34;fx\u0026#34; val foreachTableSink = \u0026#34;spark_struct_stream_sink\u0026#34; } 让我们仔细看看上面代码中的 spark 对象。 这是 SparkSessionBuilder 的代码：\nclass SparkSessionBuilder extends Serializable { // Build a spark session. Class is made serializable so to get access to SparkSession in a driver and executors. // Note here the usage of @transient lazy val def buildSparkSession: SparkSession = { @transient lazy val conf: SparkConf = new SparkConf() .setAppName(\u0026#34;Structured Streaming from Kafka to Cassandra\u0026#34;) .set(\u0026#34;spark.cassandra.connection.host\u0026#34;, \u0026#34;ec2-52-23-103-178.compute-1.amazonaws.com\u0026#34;) .set(\u0026#34;spark.sql.streaming.checkpointLocation\u0026#34;, \u0026#34;checkpoint\u0026#34;) @transient lazy val spark = SparkSession .builder() .config(conf) .getOrCreate() spark } } 在每个 worker 上，SparkSessionBuilder 提供对在驱动程序上创建的SparkSession的访问。 为了使它工作，我们需要使SparkSessionBuilder可序列化并使用@transient lazy val，它允许序列化系统忽略conf和spark对象。 现在，buildSparkSession正在被序列化并发送给每个worker，但是当worker需要conf和spark对象时，它们正在被解析。\n现在让我们看一下应用程序主体：\nobject KafkaToCassandra extends SparkSessionBuilder { // Main body of the app. It also extends SparkSessionBuilder. def main(args: Array[String]) { val spark = buildSparkSession import spark.implicits._ // Define location of Kafka brokers: val broker = \u0026#34;ec2-18-209-75-68.compute-1.amazonaws.com:9092,ec2-18-205-142-57.compute-1.amazonaws.com:9092,ec2-50-17-32-144.compute-1.amazonaws.com:9092\u0026#34; /*Here is an example massage which I get from a Kafka stream. It contains multiple jsons separated by \\n {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100936\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;EUR/GBP\u0026#34;} {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100815\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;USD/CHF\u0026#34;} {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100969\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;EUR/CHF\u0026#34;} {\u0026#34;timestamp_ms\u0026#34;: \u0026#34;1530305100011\u0026#34;, \u0026#34;fx_marker\u0026#34;: \u0026#34;USD/CAD\u0026#34;} */ // Read incoming stream val dfraw = spark .readStream .format(\u0026#34;kafka\u0026#34;) .option(\u0026#34;kafka.bootstrap.servers\u0026#34;, broker) .option(\u0026#34;subscribe\u0026#34;, \u0026#34;currency_exchange\u0026#34;) .load() val schema = StructType( Seq( StructField(\u0026#34;fx_marker\u0026#34;, StringType, false), StructField(\u0026#34;timestamp_ms\u0026#34;, StringType, false) ) ) val df = dfraw .selectExpr(\u0026#34;CAST(value AS STRING)\u0026#34;).as[String] .flatMap(_.split(\u0026#34;\\n\u0026#34;)) val jsons = df.select(from_json($\u0026#34;value\u0026#34;, schema) as \u0026#34;data\u0026#34;).select(\u0026#34;data.*\u0026#34;) // Process data. Create a new date column val parsed = jsons .withColumn(\u0026#34;timestamp_dt\u0026#34;, to_date(from_unixtime($\u0026#34;timestamp_ms\u0026#34;/1000.0, \u0026#34;yyyy-MM-dd HH:mm:ss.SSS\u0026#34;))) .filter(\u0026#34;fx_marker != \u0026#39;\u0026#39;\u0026#34;) // Output results into a database val sink = parsed .writeStream .queryName(\u0026#34;KafkaToCassandraForeach\u0026#34;) .outputMode(\u0026#34;update\u0026#34;) .foreach(new CassandraSinkForeach()) .start() sink.awaitTermination() } } 当应用程序被发送到执行时，buildSparkSession 被序列化并发送给 worker，但是，conf 和 spark 对象尚未解决。 接下来，driver 在 KafkaToCassandra 中创建 spark 对象，并在 executors 之间分配工作。 worker 从 Kafka 读取数据，进行简单的转换，当 worker 准备将结果写入数据库时，他们解析 conf 和 spark 对象，从而访问在 driver 上创建的 SparkSession。\nHow to Build and Run the App? 当我从 PySpark 迁移到 Scala 时，我花了一些时间来了解如何构建应用程序。 所以，我将 Maven pom.xml 包含在 repo 中。\n您可以通过运行 mvn package 命令使用 Maven 构建应用程序。 之后，您可以使用执行应用程序\n./bin/spark-submit \\ --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.1,datastax:spark-cassandra-connector:2.3.0-s_2.11 \\ --class com.insight.app.CassandraSink.KafkaToCassandra \\ --master spark://ec2-18-232-26-53.compute-1.amazonaws.com:7077 \\ target/cassandra-sink-0.0.1-SNAPSHOT.jar 此示例在 AWS 群集上运行，因此，如果您要测试它，只需用您的 AWS 实例替换我的 AWS 实例的地址（所有内容类似于ec2-xx-xxx-xx-xx.compute-1.amazonaws.com）。\n"},"name":"用于 Spark 结构化流的 Cassandra 接收器","published":"2018-11-29T17:17:58Z","summary":"Cassandra Sink for Spark Structured Streaming 我最近开始使用 Spark，并且必须将结构化流式 API 生成的结果存储在 Cassandra 数据库中。\n在这篇文章中，我提供了一个如何在 Spark Structured Streaming 中创建和使用 Cassandra 接收器的简单示例。 我希望它对那些刚刚开始使用 Structured Streaming API 并想知道如何将它与数据库连接的人有用。\n应用程序的想法非常简单。 它从 Kafka 读取消息，解析它们并将它们保存到 Cassandra 中。\nWhy Structured Streaming? 从文档中可以看出，Structured Streaming 是一个基于 Spark SQL 引擎的可扩展且容错的流处理引擎。 您可以使用 Dataset/DataFrame API 来表示流聚合，事件时间窗口，流到批处理连接等。在 Spark 中进行流式计算，并允许使用熟悉的 SQL 处理流数据。\nWhat Is the Problem? Spark Structured Streaming 在 2017 年已经被标记为稳定。因此，它是一个相对较新的 API，并不是所有功能都在那里。例如，有几种类型的内置输出接收器：File，Kafka，Console 和内存接收器。但是，如果您想将流式计算的结果输出到数据库中，则需要使用 foreach 接收器并实现 ForeachWriter 接口。从 Spark 2.3.1 开始，这仅适用于 Scala 和 Java。\n在这里，我假设您已经大致了解 Structured Streaming 如何工作，并且知道如何读取和处理流数据，现在可以将其输出到数据库中。如果上述某些步骤不清楚，可以使用一些很好的在线资源来帮助您开始使用结构化流。特别是，官方文档是一个很好的起点。在本文中，我想关注您需要将结果存储在数据库中的最后一步。","type":"entry","url":"https://ohmycloud.github.io/notes/cassandra-sink-for-spark-structured-streaming/"}