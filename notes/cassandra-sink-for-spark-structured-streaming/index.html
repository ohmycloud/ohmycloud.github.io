<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    
    
    

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">

    
    <meta name="referrer" content="no-referrer">

    <title>
        
            用于 Spark 结构化流的 Cassandra 接收器 ❚ 焉知非鱼
        
    </title>

    
    


    
    
    
    

    
    
    
    

    
    
    

    
    
    
    <style>
     
     
     :root {
         --theme-color: #ac4142;
         --theme-color-light: rgba(172, 65, 66, 0.2);
     }
     
     html {
         line-height: 1.5;
     }
    </style>

    
    

    
    
    
    
    <link rel="stylesheet" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css">
    
    <link rel="preload" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css" as="style">

    



    
        <style>
         
         /* Background */ .chroma { background-color: #ffffff }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

         
         /* Overrides on top of the theme and Chroma CSS */
/* Chroma-based lines highlighting in code blocks */
.chroma .hl {
    background-color: #e8e8e8;
    /* Extend highlight up to 100 characters (assuming that the code blocks never have more than 100 characters in a line) */
    min-width: 100ch;
}
/* GenericHeading */ .chroma .gh { color: #999999; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa; font-weight: bold }

         
        </style>
    

    

    
    
    

    
    <script src="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js"></script>
    
    <link rel="preload" href="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js" as="script">

    
    
    <script defer src="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js"></script>
    
    <link rel="preload" href="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js" as="script">

    

    

    
    
    

    
    
<!-- rel="me" links for IndieAuth -->







    
 
<meta property="og:title" content="用于 Spark 结构化流的 Cassandra 接收器" />
<meta property="og:description"
      content=" " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ohmycloud.github.io/notes/cassandra-sink-for-spark-structured-streaming/" />


    
        <meta property="article:published_time" content="2018-11-29T17:17:58&#43;00:00"/>
    
    
        <meta property="article:modified_time" content="2018-11-29T17:17:58&#43;00:00"/>
    









    




     <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用于 Spark 结构化流的 Cassandra 接收器"/>
<meta name="twitter:description" content=" "/>


    
    
    <link rel="alternate" type="application/jf2post+json" href="https://ohmycloud.github.io/notes/cassandra-sink-for-spark-structured-streaming/jf2post.json" title="Jf2post for 焉知非鱼" />
    
     



    
    
    
        
    


     
        
        <meta name="DC.Creator" content="焉知非鱼"/>
    



    
    
    
    <meta name="hugo-build-date" content="2024-03-01T16:16:06Z"/>
    <meta name="hugo-commit-hash" content="312735366b20d64bd61bff8627f593749f86c964"/>
    <meta name="generator" content="Hugo 0.123.7">
</head>


    
        <body lang="en">
    

        
        <div class="border" id="home"></div>

        <div class="wrapper">   
            
<nav id="nav" class="nav-collapse opened" aria-hidden="false">
    <ul class="navbar">
        <li><a class="" href="/">Home</a></li>
        
            
                <li><a class="" href="https://ohmycloud.github.io/posts/">Posts</a></li>
            
        
            
                <li><a class="" href="https://ohmycloud.github.io/notes/">Notes</a></li>
            
        
        
            <li><a class="" href="https://ohmycloud.github.io/search/">Search</a></li>
        
    </ul>
</nav>

            <div class="container">
                <header class="masthead">
                    <div class="masthead-title no-text-decoration">
                        <a href="/">焉知非鱼</a> <span class="blinking-cursor">❚</span>
                    </div>
                    <div class="masthead-tagline">
                        Wait the light to fall
                    </div>
                </header>

                








<article class="post h-entry notes">
    <header>
        <div class="center">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>

        <h1 class="post-title p-name">用于 Spark 结构化流的 Cassandra 接收器</h1>

        
        <data class="u-url" value="https://ohmycloud.github.io/notes/cassandra-sink-for-spark-structured-streaming/"></data>

        <div class="date-syndication">
            


    
    
    <div class="post-date">
        
        <time datetime="2018-11-29T17:17:58+0000" class="dt-published">Thu Nov 29, 2018</time>
        
        
    </div>


            




        </div>
         



    
    
    
        
    


    
        
        <span class="hide">
            &mdash; <a href="https://ohmycloud.github.io/" class="u-author">焉知非鱼</a>
        </span>
    


    </header>

    <div class="content">
        


        





                       


        <div class="e-content">
            




<h1 id="cassandra-sink-for-spark-structured-streaminghttpsdzonecomarticlescassandra-sink-for-spark-structured-streaming"><a href="https://dzone.com/articles/cassandra-sink-for-spark-structured-streaming">Cassandra Sink for Spark Structured Streaming</a></h1>
<p>我最近开始使用 Spark，并且必须将结构化流式 API 生成的结果存储在 Cassandra 数据库中。</p>
<p>在这篇文章中，我提供了一个如何在 Spark Structured Streaming 中创建和使用 Cassandra 接收器的简单示例。 我希望它对那些刚刚开始使用 Structured Streaming API 并想知道如何将它与数据库连接的人有用。</p>
<p>应用程序的想法非常简单。 它从 Kafka 读取消息，解析它们并将它们保存到 Cassandra 中。</p>
<h1 id="why-structured-streaming">Why Structured Streaming?</h1>
<p>从<a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">文档</a>中可以看出，Structured Streaming 是一个基于 Spark SQL 引擎的可扩展且容错的流处理引擎。 您可以使用 Dataset/DataFrame API 来表示流聚合，事件时间窗口，流到批处理连接等。在 Spark 中进行流式计算，并允许使用熟悉的 SQL 处理流数据。</p>
<h1 id="what-is-the-problem">What Is the Problem?</h1>
<p>Spark Structured Streaming 在 2017 年已经被标记为稳定。因此，它是一个相对较新的 API，并不是所有功能都在那里。例如，有几种类型的内置输出接收器：File，Kafka，Console 和内存接收器。但是，如果您想将流式计算的结果输出到数据库中，则需要使用 foreach 接收器并实现 ForeachWriter 接口。从 Spark 2.3.1 开始，这仅适用于 Scala 和 Java。</p>
<p>在这里，我假设您已经大致了解 Structured Streaming 如何工作，并且知道如何读取和处理流数据，现在可以将其输出到数据库中。如果上述某些步骤不清楚，可以使用一些很好的在线资源来帮助您开始使用结构化流。特别是，官方文档是一个很好的起点。在本文中，我想关注您需要将结果存储在数据库中的最后一步。</p>
<p>我将描述如何为结构化流实现 Cassandra 接收器，提供一个简单示例，并解释如何在集群上运行它。完整代码可在<a href="https://github.com/epishova/Structured-Streaming-Cassandra-Sink">此处</a>获得。</p>
<p>当我最初遇到上述问题时，这个<a href="https://github.com/polomarcus/Spark-Structured-Streaming-Examples">项目</a>非常有帮助。但是，如果您刚开始使用结构化流媒体并且需要一个如何将数据输出到 Cassandra 的简单示例，那么该回购可能看起来很复杂。此外，该代码在 Spark 本地模式下工作，并且需要在群集上运行一些更改。</p>
<p>此外，还有很好的示例说明如何为结构化流创建 <a href="https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html">JDBC 接收器</a>和 <a href="https://jira.mongodb.org/browse/SPARK-134">MongoDB 接收器</a>。</p>
<h1 id="simple-solution">Simple Solution</h1>
<p>要将数据发送到外部系统，您需要使用 <em>foreach</em> 接收器。 你可以在<a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#using-foreach">这里</a>读更多关于它的内容。 简而言之，您需要实现 <em>ForeachWriter</em> 接口。 那就是定义如何打开连接，处理每个数据分区，以及在处理结束时关闭连接。 源代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">CassandraSinkForeach</span><span class="o">()</span> <span class="k">extends</span> <span class="nc">ForeachWriter</span><span class="o">[</span><span class="kt">org.apache.spark.sql.Row</span><span class="o">]</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// This class implements the interface ForeachWriter, which has methods that get called 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// whenever there is a sequence of rows generated as output
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">val</span> <span class="n">cassandraDriver</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CassandraDriver</span><span class="o">();</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="n">open</span><span class="o">(</span><span class="n">partitionId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">version</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// open connection
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">println</span><span class="o">(</span><span class="s">s&#34;Open connection&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="kc">true</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.Row</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">println</span><span class="o">(</span><span class="s">s&#34;Process new </span><span class="si">$record</span><span class="s">&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">cassandraDriver</span><span class="o">.</span><span class="n">connector</span><span class="o">.</span><span class="n">withSessionDo</span><span class="o">(</span><span class="n">session</span> <span class="k">=&gt;</span>
</span></span><span class="line"><span class="cl">      <span class="n">session</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">s&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">       insert into </span><span class="si">${</span><span class="n">cassandraDriver</span><span class="o">.</span><span class="n">namespace</span><span class="si">}</span><span class="s">.</span><span class="si">${</span><span class="n">cassandraDriver</span><span class="o">.</span><span class="n">foreachTableSink</span><span class="si">}</span><span class="s"> (fx_marker, timestamp_ms, timestamp_dt)
</span></span></span><span class="line"><span class="cl"><span class="s">       values(&#39;</span><span class="si">${</span><span class="n">record</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span><span class="si">}</span><span class="s">&#39;, &#39;</span><span class="si">${</span><span class="n">record</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span><span class="si">}</span><span class="s">&#39;, &#39;</span><span class="si">${</span><span class="n">record</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span><span class="si">}</span><span class="s">&#39;)&#34;&#34;&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="n">close</span><span class="o">(</span><span class="n">errorOrNull</span><span class="k">:</span> <span class="kt">Throwable</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// close the connection
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">println</span><span class="o">(</span><span class="s">s&#34;Close connection&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><p>你会发现 CassandraDriver 的定义和下面的输出表，但在此之前让我们仔细看看上面的代码是如何工作的。 在这里，为了从 Spark 连接到 Cassandra，我创建了 CassandraDriver 对象，该对象提供对 CassandraConnector 的访问 -  CassandraConnector 是 DataStax 中广泛使用的连接器。 你可以在这里读更多关于它的内容。 CassandraConnector 负责打开和关闭与数据库的连接，因此我只需在 CassandraSinkForeach 类中的 open 和 close 方法中打印调试消息。</p>
<p>上面的代码在主应用程序中调用如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">val</span> <span class="n">sink</span> <span class="k">=</span> <span class="n">parsed</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">writeStream</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">queryName</span><span class="o">(</span><span class="s">&#34;KafkaToCassandraForeach&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">outputMode</span><span class="o">(</span><span class="s">&#34;update&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="k">new</span> <span class="nc">CassandraSinkForeach</span><span class="o">())</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">start</span><span class="o">()</span>
</span></span></code></pre></div><p>将为每一行创建 CassandraSinkForeach，每个 worker 将其部分行插入到数据库中。 所以，每个 worker 都运行 <em>val cassandraDriver = new CassandraDriver()</em>; 这就是 CassandraDriver 类的样子：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">CassandraDriver</span> <span class="k">extends</span> <span class="nc">SparkSessionBuilder</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// This object will be used in CassandraSinkForeach to connect to Cassandra DB from an executor.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// It extends SparkSessionBuilder so to use the same SparkSession on each node.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="n">buildSparkSession</span>
</span></span><span class="line"><span class="cl">  <span class="k">import</span> <span class="nn">spark.implicits._</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">connector</span> <span class="k">=</span> <span class="nc">CassandraConnector</span><span class="o">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">getConf</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Define Cassandra&#39;s table which will be used as a sink
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="cm">/* For this app I used the following table:
</span></span></span><span class="line"><span class="cl"><span class="cm">       CREATE TABLE fx.spark_struct_stream_sink (
</span></span></span><span class="line"><span class="cl"><span class="cm">       fx_marker text,
</span></span></span><span class="line"><span class="cl"><span class="cm">       timestamp_ms timestamp,
</span></span></span><span class="line"><span class="cl"><span class="cm">       timestamp_dt date,
</span></span></span><span class="line"><span class="cl"><span class="cm">       primary key (fx_marker));
</span></span></span><span class="line"><span class="cl"><span class="cm">  */</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">namespace</span> <span class="k">=</span> <span class="s">&#34;fx&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">foreachTableSink</span> <span class="k">=</span> <span class="s">&#34;spark_struct_stream_sink&#34;</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><p>让我们仔细看看上面代码中的 spark 对象。 这是 SparkSessionBuilder 的代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SparkSessionBuilder</span> <span class="k">extends</span> <span class="nc">Serializable</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Build a spark session. Class is made serializable so to get access to SparkSession in a driver and executors. 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// Note here the usage of @transient lazy val 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">def</span> <span class="n">buildSparkSession</span><span class="k">:</span> <span class="kt">SparkSession</span> <span class="o">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">conf</span><span class="k">:</span> <span class="kt">SparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&#34;Structured Streaming from Kafka to Cassandra&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&#34;spark.cassandra.connection.host&#34;</span><span class="o">,</span> <span class="s">&#34;ec2-52-23-103-178.compute-1.amazonaws.com&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&#34;spark.sql.streaming.checkpointLocation&#34;</span><span class="o">,</span> <span class="s">&#34;checkpoint&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">spark</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><p>在每个 worker 上，SparkSessionBuilder 提供对在驱动程序上创建的SparkSession的访问。 为了使它工作，我们需要使SparkSessionBuilder可序列化并使用@transient lazy val，它允许序列化系统忽略conf和spark对象。 现在，buildSparkSession正在被序列化并发送给每个worker，但是当worker需要conf和spark对象时，它们正在被解析。</p>
<p>现在让我们看一下应用程序主体：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">object</span> <span class="nc">KafkaToCassandra</span> <span class="k">extends</span> <span class="nc">SparkSessionBuilder</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Main body of the app. It also extends SparkSessionBuilder.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="n">buildSparkSession</span>
</span></span><span class="line"><span class="cl">    <span class="k">import</span> <span class="nn">spark.implicits._</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Define location of Kafka brokers:
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">val</span> <span class="n">broker</span> <span class="k">=</span> <span class="s">&#34;ec2-18-209-75-68.compute-1.amazonaws.com:9092,ec2-18-205-142-57.compute-1.amazonaws.com:9092,ec2-50-17-32-144.compute-1.amazonaws.com:9092&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/*Here is an example massage which I get from a Kafka stream. It contains multiple jsons separated by \n 
</span></span></span><span class="line"><span class="cl"><span class="cm">    {&#34;timestamp_ms&#34;: &#34;1530305100936&#34;, &#34;fx_marker&#34;: &#34;EUR/GBP&#34;}
</span></span></span><span class="line"><span class="cl"><span class="cm">    {&#34;timestamp_ms&#34;: &#34;1530305100815&#34;, &#34;fx_marker&#34;: &#34;USD/CHF&#34;}
</span></span></span><span class="line"><span class="cl"><span class="cm">    {&#34;timestamp_ms&#34;: &#34;1530305100969&#34;, &#34;fx_marker&#34;: &#34;EUR/CHF&#34;}
</span></span></span><span class="line"><span class="cl"><span class="cm">    {&#34;timestamp_ms&#34;: &#34;1530305100011&#34;, &#34;fx_marker&#34;: &#34;USD/CAD&#34;}
</span></span></span><span class="line"><span class="cl"><span class="cm">    */</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Read incoming stream
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">val</span> <span class="n">dfraw</span> <span class="k">=</span> <span class="n">spark</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">readStream</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&#34;kafka&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&#34;kafka.bootstrap.servers&#34;</span><span class="o">,</span> <span class="n">broker</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&#34;subscribe&#34;</span><span class="o">,</span> <span class="s">&#34;currency_exchange&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">load</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">val</span> <span class="n">schema</span> <span class="k">=</span> <span class="nc">StructType</span><span class="o">(</span>
</span></span><span class="line"><span class="cl">      <span class="nc">Seq</span><span class="o">(</span>
</span></span><span class="line"><span class="cl">        <span class="nc">StructField</span><span class="o">(</span><span class="s">&#34;fx_marker&#34;</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
</span></span><span class="line"><span class="cl">        <span class="nc">StructField</span><span class="o">(</span><span class="s">&#34;timestamp_ms&#34;</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">      <span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">dfraw</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&#34;CAST(value AS STRING)&#34;</span><span class="o">).</span><span class="n">as</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;\n&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">val</span> <span class="n">jsons</span> <span class="k">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">from_json</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;value&#34;</span><span class="o">,</span> <span class="n">schema</span><span class="o">)</span> <span class="n">as</span> <span class="s">&#34;data&#34;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&#34;data.*&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Process data. Create a new date column
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">val</span> <span class="n">parsed</span> <span class="k">=</span> <span class="n">jsons</span>
</span></span><span class="line"><span class="cl">      <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&#34;timestamp_dt&#34;</span><span class="o">,</span> <span class="n">to_date</span><span class="o">(</span><span class="n">from_unixtime</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;timestamp_ms&#34;</span><span class="o">/</span><span class="mf">1000.0</span><span class="o">,</span> <span class="s">&#34;yyyy-MM-dd HH:mm:ss.SSS&#34;</span><span class="o">)))</span>
</span></span><span class="line"><span class="cl">      <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="s">&#34;fx_marker != &#39;&#39;&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Output results into a database
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">val</span> <span class="n">sink</span> <span class="k">=</span> <span class="n">parsed</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">writeStream</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">queryName</span><span class="o">(</span><span class="s">&#34;KafkaToCassandraForeach&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">outputMode</span><span class="o">(</span><span class="s">&#34;update&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="k">new</span> <span class="nc">CassandraSinkForeach</span><span class="o">())</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">start</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">sink</span><span class="o">.</span><span class="n">awaitTermination</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><p>当应用程序被发送到执行时，buildSparkSession 被序列化并发送给 worker，但是，conf 和 spark 对象尚未解决。 接下来，driver 在 KafkaToCassandra 中创建 spark 对象，并在 executors 之间分配工作。 worker 从 Kafka 读取数据，进行简单的转换，当 worker 准备将结果写入数据库时，他们解析 conf 和 spark 对象，从而访问在 driver 上创建的 SparkSession。</p>
<h1 id="how-to-build-and-run-the-app">How to Build and Run the App?</h1>
<p>当我从 PySpark 迁移到 Scala 时，我花了一些时间来了解如何构建应用程序。 所以，我将 Maven pom.xml 包含在 repo 中。</p>
<p>您可以通过运行 mvn package 命令使用 Maven 构建应用程序。 之后，您可以使用执行应用程序</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="o">./</span><span class="n">bin</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="n">\</span> 
</span></span><span class="line"><span class="cl"><span class="o">--</span><span class="n">packages</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="k">:</span><span class="kt">spark-sql-kafka-</span><span class="err">0</span><span class="kt">-</span><span class="err">10</span><span class="k">_</span><span class="err">2</span><span class="kt">.</span><span class="err">11</span><span class="kt">:</span><span class="err">2</span><span class="kt">.</span><span class="err">3</span><span class="kt">.</span><span class="err">1</span><span class="o">,</span><span class="n">datastax</span><span class="k">:</span><span class="kt">spark-cassandra-connector:</span><span class="err">2</span><span class="kt">.</span><span class="err">3</span><span class="kt">.</span><span class="err">0</span><span class="kt">-s_2.</span><span class="err">11</span> <span class="kt">\</span>
</span></span><span class="line"><span class="cl"><span class="o">--</span><span class="k">class</span> <span class="nc">com</span><span class="o">.</span><span class="n">insight</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="nc">CassandraSink</span><span class="o">.</span><span class="nc">KafkaToCassandra</span> <span class="n">\</span>
</span></span><span class="line"><span class="cl"><span class="o">--</span><span class="n">master</span> <span class="n">spark</span><span class="k">:</span><span class="c1">//ec2-18-232-26-53.compute-1.amazonaws.com:7077 \
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">target</span><span class="o">/</span><span class="n">cassandra</span><span class="o">-</span><span class="n">sink</span><span class="o">-</span><span class="mf">0.0</span><span class="o">.</span><span class="mi">1</span><span class="o">-</span><span class="nc">SNAPSHOT</span><span class="o">.</span><span class="n">jar</span>
</span></span></code></pre></div><p>此示例在 AWS 群集上运行，因此，如果您要测试它，只需用您的 AWS 实例替换我的 AWS 实例的地址（所有内容类似于ec2-xx-xxx-xx-xx.compute-1.amazonaws.com）。</p>


        </div>
    </div>
</article>



                <footer>
                    




<div class="no-text-decoration">
    <div class="jump top"><a href="#" title="Top of this page">⮉</a></div>
    <div class="jump bottom"><a href="#bottom" title="Bottom of this page">⮋</a></div>
</div>


 
    
        <div class="hugotoc no-text-decoration">
            <nav id="TableOfContents"></nav>
            <a href="#" class="back-to-top">Back to top</a>
        </div>
    
    
<script src="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js"></script>

<link rel="preload" href="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js" as="script">

<script type="application/javascript">(function() {
     var $window = $(window);
     if ($window.width() >= 1400) { 
         var $toc = $('#TableOfContents');
         if ($toc.length > 0) {
             function onScroll(){
                 var currentScroll = $window.scrollTop();
                 var h = $('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .h-feed h2');
                 var id = "";
                 h.each(function (i, e) {
                     e = $(e);
                     if (e.offset().top - 10 <= currentScroll) {
                         id = e.attr('id');
                     }
                 });
                 var current = $toc.find('a.current');
                 if (current.length == 1 && current.eq(0).attr('href') == '#' + id) return true;

                 current.each(function (i, e) {
                     $(e).removeClass('current').siblings('ul').hide();
                 });
                 $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                     $(e).children('a').addClass('current').siblings('ul').show();
                 });
             }
             $window.on('scroll', onScroll);
             $(document).ready(function() {
                 $toc.find('a').parent('li').find('ul').hide();
                 onScroll();
                 document.getElementsByClassName('hugotoc')[0].style.display = '';
             });}}})();</script>








<div class="backtotop center no-text-decoration">
    <a href="#">back to <span class="top">top</span></a>
</div>


<div class="right">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>
<div class="clear-float"></div>



<div class="prev-next-navigator clear-float">
    
        <span class="prev-post left no-text-decoration">
            <a href="https://ohmycloud.github.io/notes/working-with-complex-data-formats-with-structured-streaming-in-apache-spark-2-1/" class="nobr">« 在结构化流中使用复杂数据格式</a>
        </span>
    
    
        <span class="next-post right no-text-decoration">
            <a href="https://ohmycloud.github.io/notes/a-tour-of-spark-structured-streaming/" class="nobr">Spark 结构化流之旅 »</a>
        </span>
    
</div>


<a id="bottom"></a>









                       







                    <ul class="no-bullets feed right inline">
    
        
        
    
</ul>
<div class="clear-float"></div>

                </footer>
                <hr />
            </div>               

            <footer> 
                

<ul class="social no-text-decoration">
    
</ul>










 
    
    



<p class="generated no-text-decoration">
    Generated using  <a href="https://gitlab.com/kaushalmodi/hugo-theme-refined"><code class="nobr">hugo-theme-refined</code></a> + <span class="nobr">Hugo <a href="https://github.com/gohugoio/hugo/commit/312735366b20d64bd61bff8627f593749f86c964">0.123.7</a></span>
</p>

<p>
    
</p>




<div class="badges no-text-decoration">
    
    

    
</div>




<script type="application/javascript">var nav=responsiveNav("#nav");</script>




<script defer src="/js/libs/fragmentions/wrapper.min.e8c468c89edc4f5dccaa8c720c6b220b3088a16cd7b1e4a1e3345985788260c9.js"></script>









            </footer>
        </div> 
    </body>
</html>
