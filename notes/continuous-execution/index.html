<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    
    
    

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">

    
    <meta name="referrer" content="no-referrer">

    <title>
        
            Spark Structured Streaming 中的持续执行 ❚ 焉知非鱼
        
    </title>

    
    


    
    
    
    

    
    
    
    

    
    
    

    
    
    
    <style>
     
     
     :root {
         --theme-color: #ac4142;
         --theme-color-light: rgba(172, 65, 66, 0.2);
     }
     
     html {
         line-height: 1.5;
     }
    </style>

    
    

    
    
    
    
    <link rel="stylesheet" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css">
    
    <link rel="preload" href="/css/refined.min.7f6d3ee611034e4ebcbc063f1db3bc042fecdc8901afbedad80ff02bae409204.css" as="style">

    



    
        <style>
         
         /* Background */ .chroma { background-color: #ffffff }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

         
         /* Overrides on top of the theme and Chroma CSS */
/* Chroma-based lines highlighting in code blocks */
.chroma .hl {
    background-color: #e8e8e8;
    /* Extend highlight up to 100 characters (assuming that the code blocks never have more than 100 characters in a line) */
    min-width: 100ch;
}
/* GenericHeading */ .chroma .gh { color: #999999; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa; font-weight: bold }

         
        </style>
    

    

    
    
    

    
    <script src="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js"></script>
    
    <link rel="preload" href="/js/responsive-nav-orig.min.e2b5f2a956b488f466da513820636134defdc38b90ed566248960593f2bb4ba5.js" as="script">

    
    
    <script defer src="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js"></script>
    
    <link rel="preload" href="/js/libs/fa/fontawesome-all.min.08916ac0fd078adfb58edc890460e2c8990729aee02bca7586404b56805f5219.js" as="script">

    

    

    
    
    

    
    
<!-- rel="me" links for IndieAuth -->







    
 
<meta property="og:title" content="Spark Structured Streaming 中的持续执行" />
<meta property="og:description"
      content=" " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ohmycloud.github.io/notes/continuous-execution/" />


    
        <meta property="article:published_time" content="2019-10-03T14:35:22&#43;00:00"/>
    
    
        <meta property="article:modified_time" content="2019-10-03T14:35:22&#43;00:00"/>
    









    




     <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Spark Structured Streaming 中的持续执行"/>
<meta name="twitter:description" content=" "/>


    
    
    <link rel="alternate" type="application/jf2post+json" href="https://ohmycloud.github.io/notes/continuous-execution/jf2post.json" title="Jf2post for 焉知非鱼" />
    
     



    
    
    
        
    


     
        
        <meta name="DC.Creator" content="焉知非鱼"/>
    



    
    
    
    <meta name="hugo-build-date" content="2024-03-01T16:16:06Z"/>
    <meta name="hugo-commit-hash" content="312735366b20d64bd61bff8627f593749f86c964"/>
    <meta name="generator" content="Hugo 0.123.7">
</head>


    
        <body lang="en">
    

        
        <div class="border" id="home"></div>

        <div class="wrapper">   
            
<nav id="nav" class="nav-collapse opened" aria-hidden="false">
    <ul class="navbar">
        <li><a class="" href="/">Home</a></li>
        
            
                <li><a class="" href="https://ohmycloud.github.io/posts/">Posts</a></li>
            
        
            
                <li><a class="" href="https://ohmycloud.github.io/notes/">Notes</a></li>
            
        
        
            <li><a class="" href="https://ohmycloud.github.io/search/">Search</a></li>
        
    </ul>
</nav>

            <div class="container">
                <header class="masthead">
                    <div class="masthead-title no-text-decoration">
                        <a href="/">焉知非鱼</a> <span class="blinking-cursor">❚</span>
                    </div>
                    <div class="masthead-tagline">
                        Wait the light to fall
                    </div>
                </header>

                








<article class="post h-entry notes">
    <header>
        <div class="center">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>

        <h1 class="post-title p-name">Spark Structured Streaming 中的持续执行</h1>

        
        <data class="u-url" value="https://ohmycloud.github.io/notes/continuous-execution/"></data>

        <div class="date-syndication">
            


    
    
    <div class="post-date">
        
        <time datetime="2019-10-03T14:35:22+0000" class="dt-published">Thu Oct 3, 2019</time>
        
        
    </div>


            




        </div>
         



    
    
    
        
    


    
        
        <span class="hide">
            &mdash; <a href="https://ohmycloud.github.io/" class="u-author">焉知非鱼</a>
        </span>
    


    </header>

    <div class="content">
        


        





                       


        <div class="e-content">
            




<p>这些年来，Apache Spark 的流媒体被认为是与微批处理一起工作的。但是，版本 2.3.0 试图对此进行更改，并提出了一种称为“连续”的新执行模型。即使它仍处于实验状态，还是值得更多了解它。</p>
<p>这篇文章介绍了连续流处理的新实验功能。第一部分解释并与微批执行策略进行比较。下一个显示一些内部细节。在第三部分中，我们可以了解至少一次保证。最后一部分在基于比率的源示例中显示了一个简单的连续执行用例。</p>
<h2 id="连续流">连续流&nbsp;<a class="headline-hash no-text-decoration" href="#连续流">#</a> </h2>
<p>毕竟为什么要替换微批​​处理的 Spark 区别标记（与允许连续流处理的 Apache Flink 或 Apache Beam 不同）？答案很简单-延迟。使用微批处理时，延迟很高。在最坏的情况下，等待时间是批处理时间与任务启动时间的总和，估计为几毫秒。连续处理将数据到达与其处理之间的等待时间减少到几毫秒。延迟减少是此（仍）实验特性背后的主要动机。</p>
<p>从鸟瞰来看，连续查询在多个线程中执行。每个线程负责不同的分区。因此，为了保证最佳的并行性，集群中可用核心的数量必须等于要处理的分区的数量。在处理期间，这些线程将结果连续写入结果表。</p>
<p>从技术上讲，可以通过 <code>.trigger(Trigger.Continuous(&quot;1 second&quot;))</code> 使用连续触发来启用连续处理。但必须强调的是，在当前（2.3.0）Spark 版本中，并非所有操作都暴露于此模式下。在可用的转换中，我们只能区分投影（<code>select</code>，映射函数）和选择（过滤器子句）。</p>
<p>但是，降低延迟并不是没有代价的。实际上，更快的处理将交付保证从正好一次下降到了至少一次。因此，对于处理延迟比交付保证更为重要的系统，建议执行连续执行。</p>
<h2 id="continuousexecution-类">ContinuousExecution 类&nbsp;<a class="headline-hash no-text-decoration" href="#continuousexecution-类">#</a> </h2>
<p>最初，在结构化流中，StreamExecution 包含整个执行逻辑。仅在 2.3.0 版本中，它才成为由 MicroBatchExecution 和 ContinuousExecution 扩展的抽象类。这两个类的出发点都是 org.apache.spark.sql.execution.streaming.StreamExecution#runStream()，在执行一些初始化步骤之后，该类将激活每个执行策略中实现的流查询，方法为 runActivatedStream(sparkSessionForStream: SparkSession)` 方法。</p>
<p>由于以下代码，ContinuousExecution 连续运行查询：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="k">do</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">runContinuous</span><span class="o">(</span><span class="n">sparkSessionForStream</span><span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span> <span class="k">while</span> <span class="o">(</span><span class="n">state</span><span class="o">.</span><span class="n">updateAndGet</span><span class="o">(</span><span class="n">stateUpdate</span><span class="o">)</span> <span class="o">==</span> <span class="nc">ACTIVE</span><span class="o">)</span>
</span></span></code></pre></div><p>在此 runContinuous 方法内部，发生了许多操作。第一个步骤包括将查询逻辑计划转换为一系列 ContinuousReaders。此接口定义是否可以连续方式读取给定的数据源。当前仅支持 Apache Kafka 和基于速率的源（该源以固定的Y间隔每秒生成 X（行，计数器）行，其中 X 和 Y 是配置参数）。如果某些源或操作不支持连续模式，则在启动查询之前会引发 UnsupportedOperationException。</p>
<p>在创建源之后，将解析起始偏移量，以确定何时开始执行给定执行的处理。如果查询是第一次启动，则偏移量自然为空。但是，再次执行查询时，将从提交日志中检索偏移量。稍后，将为每个映射到读取偏移量的数据源创建一个 StreamingDataSourceV2Relation 实例。接下来，创建数据读取器和写入器，并以与微批处理方法完全相同的方式生成执行计划。</p>
<p>在下一步中，引擎通过 EpochCoordinator 实例以纪元（与微批处理中的批处理类似）进行播放。这是连续处理的杰作。此 RPC 端点负责处理以下消息：</p>
<ul>
<li>生成新的纪元ID-通过消息 IncrementAndGetEpoch，该纪元 ID 会自动增加。然后，在 runContinuous 方法中返回新值。</li>
<li>返回当前纪元ID-表示为 GetCurrentEpoch 实例的此 getter 消息由定期执行 EpochPollRunnable 中定义的逻辑的线程使用。在此逻辑中，引擎检索当前已知的纪元并将其添加到要处理的消息的内部队列中。在此列表下面的模式中将对此进行详细说明。</li>
<li>在纪元下提交分区-在给定时期内对分区的处理终止时，会将 CommitPartitionEpoch 消息发送给 EpochCoordinator 以发出信号。如果所有纪元的分区都已处理，则 ContinuousExecution 将此纪元标记为已提交。这意味着该纪元被保留在提交日志中，并且在重新处理的情况下，与之关联的偏移量被用作起始偏移量（请参见上一段）。</li>
</ul>
<p>这些涉及纪元协调器的连续处理逻辑可以在以下简化模式中恢复：</p>
<p><img src="https://www.waitingforcode.com/public/images/articles/spark_continuous_processing_schema.png" alt="img"></p>
<h2 id="至少一次保证">至少一次保证&nbsp;<a class="headline-hash no-text-decoration" href="#至少一次保证">#</a> </h2>
<p>您可能想知道为什么连续模式至少一次保证？ 如前所述，主要理由是减少延迟。 在代码中，它是在解析每个源的起始偏移量的那一刻进行翻译的。 您可以在以下模式中看到这一点，该模式显示了微批处理和连续处理的执行的最初时刻：</p>
<p><img src="https://www.waitingforcode.com/public/images/articles/spark_starting_offsets_microbatch_vs_continuous.png" alt="img"></p>
<p>如您所见，两种模式的起始偏移量生成都略有不同。微批处理基于偏移日志和提交日志，而连续批处理仅使用提交日志。从写入部分（图中未显示）开始，偏移量始终在提交日志之前保留。仅在成功处理给定纪元或微批处理后，才保存后一个。鉴于两种处理的写作工作流程相同，因此阅读部分的差异突出了连续策略中的至少一次保证。</p>
<p>要理解它，没有什么比一个示例更好。假设提交日志中的最后一个批处理/纪元ID是＃2，并且它对应于偏移量（4、5、6）（= 3个Kafka分区）。偏移日志中的最新值是（7、8、9），它们对应于批次/时期＃3。现在，连续执行将读取提交日志，并查看最后一个时期＃2。然后，它检索与其对应的偏移量（（4，5，6））。因此它将重新处理（4，5，6）。微批处理执行更多步骤。首先，它获取最后的偏移量日志（（7，8，9））。接下来，将它们与最后提交的偏移量（（4，5，6））进行比较。由于两者具有不同的批次ID，因此保留与最新批次ID对应的偏移量以进行处理。</p>
<h2 id="偏移细微差别">偏移细微差别&nbsp;<a class="headline-hash no-text-decoration" href="#偏移细微差别">#</a> </h2>
<p>实际上，Apache Spark 结构化流处理的偏移范围包括：开始偏移（包括）和结束偏移（不包括）。结束偏移量用作下一个处理的起点。您可以在 org.apache.spark.sql.sql.kafka010.KafkaSource＃getBatch 中根据注释查看该实例：“返回偏移量之间的数据[<code>start.get.partitionToOffsets</code>，<code>end.partitionToOffsets</code>） ，即 end.partitionToOffsets 是互斥的。”
上面示例中的单个值仅用于简化情况。</p>
<h2 id="连续处理实例">连续处理实例&nbsp;<a class="headline-hash no-text-decoration" href="#连续处理实例">#</a> </h2>
<p>以下片段中呈现的用例将很快介绍连续处理：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl"><span class="s">&#34;continuous execution&#34;</span> <span class="n">should</span> <span class="s">&#34;execute trigger at regular interval independently on data processing&#34;</span> <span class="n">in</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">messageSeparator</span> <span class="k">=</span> <span class="s">&#34;SEPARATOR&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">logAppender</span> <span class="k">=</span> <span class="nc">InMemoryLogAppender</span><span class="o">.</span><span class="n">createLogAppender</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">&#34;New epoch&#34;</span><span class="o">,</span> <span class="s">&#34;has offsets reported from all partitions&#34;</span><span class="o">,</span>
</span></span><span class="line"><span class="cl">    <span class="s">&#34;has received commits from all partitions. Committing globally.&#34;</span><span class="o">,</span> <span class="s">&#34;Committing batch&#34;</span><span class="o">),</span>
</span></span><span class="line"><span class="cl">    <span class="o">(</span><span class="n">loggingEvent</span><span class="k">:</span> <span class="kt">LoggingEvent</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">LogMessage</span><span class="o">(</span><span class="s">s&#34;</span><span class="si">${</span><span class="n">loggingEvent</span><span class="o">.</span><span class="n">timeStamp</span><span class="si">}</span><span class="s"> </span><span class="si">${</span><span class="n">messageSeparator</span><span class="si">}</span><span class="s"> </span><span class="si">${</span><span class="n">loggingEvent</span><span class="o">.</span><span class="n">getMessage</span><span class="si">}</span><span class="s">&#34;</span><span class="o">,</span> <span class="s">&#34;&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">rateStream</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&#34;rate&#34;</span><span class="o">).</span><span class="n">option</span><span class="o">(</span><span class="s">&#34;rowsPerSecond&#34;</span><span class="o">,</span> <span class="s">&#34;10&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&#34;numPartitions&#34;</span><span class="o">,</span> <span class="s">&#34;2&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">val</span> <span class="n">numbers</span> <span class="k">=</span> <span class="n">rateStream</span><span class="o">.</span><span class="n">load</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">rateRow</span> <span class="k">=&gt;</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Slow down the processing to show that the epochs don&#39;t wait commits
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="nc">Thread</span><span class="o">.</span><span class="n">sleep</span><span class="o">(</span><span class="mi">500L</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">      <span class="s">&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="o">})</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">  <span class="n">numbers</span><span class="o">.</span><span class="n">writeStream</span><span class="o">.</span><span class="n">outputMode</span><span class="o">(</span><span class="s">&#34;append&#34;</span><span class="o">).</span><span class="n">trigger</span><span class="o">(</span><span class="nc">Trigger</span><span class="o">.</span><span class="nc">Continuous</span><span class="o">(</span><span class="s">&#34;2 second&#34;</span><span class="o">)).</span><span class="n">format</span><span class="o">(</span><span class="s">&#34;memory&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">queryName</span><span class="o">(</span><span class="s">&#34;test_accumulation&#34;</span><span class="o">).</span><span class="n">start</span><span class="o">().</span><span class="n">awaitTermination</span><span class="o">(</span><span class="mi">60000L</span><span class="o">)</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">  <span class="c1">// A sample output of accumulated messages could be:
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:50:58 CET 2018 :  New epoch 1 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:00 CET 2018 :  New epoch 2 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:00 CET 2018 :  Epoch 0 has offsets reported from all partitions: ArrayBuffer(
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">//  RateStreamPartitionOffset(1,-1,1521958543518), RateStreamPartitionOffset(0,-2,1521958543518))
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:00 CET 2018 :  Epoch 0 has received commits from all partitions. Committing globally.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:01 CET 2018 :  Committing batch 0 to MemorySink
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:01 CET 2018 :  Epoch 1 has offsets reported from all partitions: ArrayBuffer(
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">//  RateStreamPartitionOffset(0,24,1521958546118), RateStreamPartitionOffset(1,25,1521958546118))
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:01 CET 2018 :  Epoch 1 has received commits from all partitions. Committing globally.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:01 CET 2018 :  Committing batch 1 to MemorySink
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:02 CET 2018 :  New epoch 3 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:04 CET 2018 :  New epoch 4 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:06 CET 2018 :  New epoch 5 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 13:51:08 CET 2018 :  New epoch 6 is starting.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// As you can see, the epochs start according to the defined trigger and not after committing given epoch.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// Even if given executor is in late for the processing, it polls the information about the epochs regularly through
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// org.apache.spark.sql.execution.streaming.continuous.EpochPollRunnable
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">var</span> <span class="n">startedEpoch</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">  <span class="k">var</span> <span class="n">startedEpochTimestamp</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1L</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="o">(</span><span class="n">message</span> <span class="k">&lt;-</span> <span class="n">logAppender</span><span class="o">.</span><span class="n">getMessagesText</span><span class="o">())</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">msgTimestamp</span><span class="o">,</span> <span class="n">messageContent</span><span class="o">,</span> <span class="k">_</span> <span class="nd">@_*</span><span class="o">)</span> <span class="k">=</span> <span class="n">message</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="n">messageSeparator</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="o">(</span><span class="n">messageContent</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&#34;New epoch&#34;</span><span class="o">))</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Here we check that the epochs are increasing
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">val</span> <span class="n">newEpoch</span> <span class="k">=</span> <span class="n">messageContent</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)(</span><span class="mi">3</span><span class="o">).</span><span class="n">toInt</span>
</span></span><span class="line"><span class="cl">      <span class="k">val</span> <span class="n">startedNewEpochTimestamp</span> <span class="k">=</span> <span class="n">msgTimestamp</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">toLong</span>
</span></span><span class="line"><span class="cl">      <span class="n">newEpoch</span> <span class="n">should</span> <span class="n">be</span> <span class="o">&gt;</span> <span class="n">startedEpoch</span>
</span></span><span class="line"><span class="cl">      <span class="n">startedNewEpochTimestamp</span> <span class="n">should</span> <span class="n">be</span> <span class="o">&gt;</span> <span class="n">startedEpochTimestamp</span>
</span></span><span class="line"><span class="cl">      <span class="n">startedEpoch</span> <span class="k">=</span> <span class="n">newEpoch</span>
</span></span><span class="line"><span class="cl">      <span class="n">startedEpochTimestamp</span> <span class="k">=</span> <span class="n">startedNewEpochTimestamp</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">messageContent</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&#34;Committing globally&#34;</span><span class="o">))</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Here we prove that the epoch commit is decoupled from the starting of the new
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// epoch processing. In fact the new epoch starts according to the delay defined
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// in the continuous trigger but the commit happens only when all records are processed
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// And both concepts are independent
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">val</span> <span class="n">committedEpoch</span> <span class="k">=</span> <span class="n">messageContent</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34; &#34;</span><span class="o">)(</span><span class="mi">2</span><span class="o">).</span><span class="n">toInt</span>
</span></span><span class="line"><span class="cl">      <span class="n">startedEpoch</span> <span class="n">should</span> <span class="n">be</span> <span class="o">&gt;</span> <span class="n">committedEpoch</span>
</span></span><span class="line"><span class="cl">      <span class="n">msgTimestamp</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">toLong</span> <span class="n">should</span> <span class="n">be</span> <span class="o">&gt;</span> <span class="n">startedEpochTimestamp</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><p>连续处理是 Apache Spark 向社区提出的另一个有趣的解决方案。 通过经典的面向微批处理的执行，流处理具有一次保证的能力。 但是，如第一部分所示，代价是等待时间。 连续处理是一种替代方法，可以牺牲一次保证以减少等待时间。 正如在接下来的2部分中介绍的那样，它通过将 StreamExecution 类分成代表每个策略的 2 个类来进行传递。 在连续执行的情况下，差异取决于偏移量分辨率。 它仅基于提交日志，而在微批处理的情况下，将偏移日志和提交日志混合使用以减少不必要的重新处理。 最后一部分介绍了使用连续执行的简单测试案例。</p>


        </div>
    </div>
</article>



                <footer>
                    




<div class="no-text-decoration">
    <div class="jump top"><a href="#" title="Top of this page">⮉</a></div>
    <div class="jump bottom"><a href="#bottom" title="Bottom of this page">⮋</a></div>
</div>


 
    
        <div class="hugotoc no-text-decoration">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#连续流">连续流</a></li>
    <li><a href="#continuousexecution-类">ContinuousExecution 类</a></li>
    <li><a href="#至少一次保证">至少一次保证</a></li>
    <li><a href="#偏移细微差别">偏移细微差别</a></li>
    <li><a href="#连续处理实例">连续处理实例</a></li>
  </ul>
</nav>
            <a href="#" class="back-to-top">Back to top</a>
        </div>
    
    
<script src="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js"></script>

<link rel="preload" href="/js/libs/jquery/3.3.1/jquery.slim.min.min.22ee3db0c0e99fd0fbce3aee19672bd53d25469daf734bd4c165649f6eaf7d7f.js" as="script">

<script type="application/javascript">(function() {
     var $window = $(window);
     if ($window.width() >= 1400) { 
         var $toc = $('#TableOfContents');
         if ($toc.length > 0) {
             function onScroll(){
                 var currentScroll = $window.scrollTop();
                 var h = $('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6, .h-feed h2');
                 var id = "";
                 h.each(function (i, e) {
                     e = $(e);
                     if (e.offset().top - 10 <= currentScroll) {
                         id = e.attr('id');
                     }
                 });
                 var current = $toc.find('a.current');
                 if (current.length == 1 && current.eq(0).attr('href') == '#' + id) return true;

                 current.each(function (i, e) {
                     $(e).removeClass('current').siblings('ul').hide();
                 });
                 $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
                     $(e).children('a').addClass('current').siblings('ul').show();
                 });
             }
             $window.on('scroll', onScroll);
             $(document).ready(function() {
                 $toc.find('a').parent('li').find('ul').hide();
                 onScroll();
                 document.getElementsByClassName('hugotoc')[0].style.display = '';
             });}}})();</script>








<div class="backtotop center no-text-decoration">
    <a href="#">back to <span class="top">top</span></a>
</div>


<div class="right">
    <div class="taxo no-text-decoration">
         
            
                <ul class="no-bullets inline categories">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts categorized in ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/categories/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
         
            
                <ul class="no-bullets inline tags">
                    
                        
                        
                        
                            
                            
                            
                            
                            
                            <li class="__rakulang__"
                                
                                
                                title="See all 0 posts tagged with ‘rakulang’"
                                
                            >
                                <a class="p-category" href="https://ohmycloud.github.io/tags/rakulang/">rakulang</a>
                            </li>
                        
                    
                </ul>
            
        
    </div>

</div>
<div class="clear-float"></div>



<div class="prev-next-navigator clear-float">
    
        <span class="prev-post left no-text-decoration">
            <a href="https://ohmycloud.github.io/notes/foreach-batch/" class="nobr">« Apache Spark 2.4.0 特性  - foreachBatch</a>
        </span>
    
    
        <span class="next-post right no-text-decoration">
            <a href="https://ohmycloud.github.io/notes/watermark-configuration/" class="nobr">Apache Spark 2.4.0 特性 - Watermark Configuration »</a>
        </span>
    
</div>


<a id="bottom"></a>









                       







                    <ul class="no-bullets feed right inline">
    
        
        
    
</ul>
<div class="clear-float"></div>

                </footer>
                <hr />
            </div>               

            <footer> 
                

<ul class="social no-text-decoration">
    
</ul>










 
    
    



<p class="generated no-text-decoration">
    Generated using  <a href="https://gitlab.com/kaushalmodi/hugo-theme-refined"><code class="nobr">hugo-theme-refined</code></a> + <span class="nobr">Hugo <a href="https://github.com/gohugoio/hugo/commit/312735366b20d64bd61bff8627f593749f86c964">0.123.7</a></span>
</p>

<p>
    
</p>




<div class="badges no-text-decoration">
    
    

    
</div>




<script type="application/javascript">var nav=responsiveNav("#nav");</script>




<script defer src="/js/libs/fragmentions/wrapper.min.e8c468c89edc4f5dccaa8c720c6b220b3088a16cd7b1e4a1e3345985788260c9.js"></script>









            </footer>
        </div> 
    </body>
</html>
